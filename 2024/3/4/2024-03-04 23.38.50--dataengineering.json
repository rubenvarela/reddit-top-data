{"kind": "Listing", "data": {"after": "t3_1b6cazx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI've been a data engineer for a few years now and I just dont think I have what it takes anymore.\n\nThe discipline requires immense concentration, and the amount that needs to be learned constantly has left me burned out. There's no end to it.\n\nI understand that every job has an element of constant learning, but I think it's the combination of the lack of acknowledgement of my work (a classic occurrence in data engineering I know), and the fact that despite the amount I've worked and learned, I still only earn slightly more than average (London wages/life are a scam). I have a lot of friends who work classic jobs (think estate agent, operations assistant, administration manager who earn just as much as I do, but the work and the skill involved is much less)\n\nTo cut a long story short, I'm looking for some encouragement or reasons to stay in the field if you could offer some. I was thinking of transitioning into a business analyst role or to become some kind of project manager, because my mental health is taking a big hit.\n\nThank you for reading.", "author_fullname": "t2_lovh9cgne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Giving up data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b67xnz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709548923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a data engineer for a few years now and I just dont think I have what it takes anymore.&lt;/p&gt;\n\n&lt;p&gt;The discipline requires immense concentration, and the amount that needs to be learned constantly has left me burned out. There&amp;#39;s no end to it.&lt;/p&gt;\n\n&lt;p&gt;I understand that every job has an element of constant learning, but I think it&amp;#39;s the combination of the lack of acknowledgement of my work (a classic occurrence in data engineering I know), and the fact that despite the amount I&amp;#39;ve worked and learned, I still only earn slightly more than average (London wages/life are a scam). I have a lot of friends who work classic jobs (think estate agent, operations assistant, administration manager who earn just as much as I do, but the work and the skill involved is much less)&lt;/p&gt;\n\n&lt;p&gt;To cut a long story short, I&amp;#39;m looking for some encouragement or reasons to stay in the field if you could offer some. I was thinking of transitioning into a business analyst role or to become some kind of project manager, because my mental health is taking a big hit.&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b67xnz", "is_robot_indexable": true, "report_reasons": null, "author": "Two_5536", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/", "subreddit_subscribers": 165822, "created_utc": 1709548923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I accepted an offer with a decent comp at a bank. Role is remote I started and got my work laptop mailed and have been going through on boarding. \n\nNow I've just gotten an offer from another company which I thought ghosted me and I'm in a bit of a dilemma. The offer is 60% more than my current comp. I'm not even questioning it tbh I am definitely going to accept, I know my current company can't match and of course they won't I literally just started. \n\nWhats my best course of action? Just tell them about the job? Bullshit something else (like medical issue) and say I can't work anymore?\n\nEdit: while the job is remote they did fly me out for my first week so I can meet the core team so that does add another insult when I leave. ", "author_fullname": "t2_cyr5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accepted an offer, 2 weeks later got dream offer from another company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ghh6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709573525.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709572757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I accepted an offer with a decent comp at a bank. Role is remote I started and got my work laptop mailed and have been going through on boarding. &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;ve just gotten an offer from another company which I thought ghosted me and I&amp;#39;m in a bit of a dilemma. The offer is 60% more than my current comp. I&amp;#39;m not even questioning it tbh I am definitely going to accept, I know my current company can&amp;#39;t match and of course they won&amp;#39;t I literally just started. &lt;/p&gt;\n\n&lt;p&gt;Whats my best course of action? Just tell them about the job? Bullshit something else (like medical issue) and say I can&amp;#39;t work anymore?&lt;/p&gt;\n\n&lt;p&gt;Edit: while the job is remote they did fly me out for my first week so I can meet the core team so that does add another insult when I leave. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6ghh6", "is_robot_indexable": true, "report_reasons": null, "author": "bigYman", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ghh6/accepted_an_offer_2_weeks_later_got_dream_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ghh6/accepted_an_offer_2_weeks_later_got_dream_offer/", "subreddit_subscribers": 165822, "created_utc": 1709572757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I help companies build and scale machine learning and analytics applications, with Spark being a core part of our data processing toolkit. While Python is generally the go-to language for data processing, libraries like Pandas &amp; NumPy come with a LOT of sharp edges. This is especially true if you're trying to read someone else's code. \n\nIMO Spark (&amp; PySpark) has an edge over other data processing tools for a few reasons: it reads more like SQL (making it a easier to understand without digging through obscure documentation), it's well-supported across cloud platforms, and it's dead simple to scale to handle any size data you need to throw at it.\n\nI wanted to create a resource that anyone with basic Python and SQL knowledge can use to get up and running quickly with Spark (you can probably learn 80% of what you need in a day or two). I also wanted to include some suggestions around code conventions to help with readability and avoiding gotchas that trip a lot of folks up (e.g. duplicating columns when doing joins).\n\nYou can get started with either a web notebook or locally with a batteries-included Docker container. \n\nYou can access it at [SparkMadeEasy.com](https://sparkmadeeasy.com/).\n\nThis is still a work-in-progress, with more topics to come (e.g. Spark-ML). Happy to hear any feedback!", "author_fullname": "t2_uyd9mc1b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an open-source microsite to help analysts and SQL-heavy devs get started with Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6dgsp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709571490.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709565598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I help companies build and scale machine learning and analytics applications, with Spark being a core part of our data processing toolkit. While Python is generally the go-to language for data processing, libraries like Pandas &amp;amp; NumPy come with a LOT of sharp edges. This is especially true if you&amp;#39;re trying to read someone else&amp;#39;s code. &lt;/p&gt;\n\n&lt;p&gt;IMO Spark (&amp;amp; PySpark) has an edge over other data processing tools for a few reasons: it reads more like SQL (making it a easier to understand without digging through obscure documentation), it&amp;#39;s well-supported across cloud platforms, and it&amp;#39;s dead simple to scale to handle any size data you need to throw at it.&lt;/p&gt;\n\n&lt;p&gt;I wanted to create a resource that anyone with basic Python and SQL knowledge can use to get up and running quickly with Spark (you can probably learn 80% of what you need in a day or two). I also wanted to include some suggestions around code conventions to help with readability and avoiding gotchas that trip a lot of folks up (e.g. duplicating columns when doing joins).&lt;/p&gt;\n\n&lt;p&gt;You can get started with either a web notebook or locally with a batteries-included Docker container. &lt;/p&gt;\n\n&lt;p&gt;You can access it at &lt;a href=\"https://sparkmadeeasy.com/\"&gt;SparkMadeEasy.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;This is still a work-in-progress, with more topics to come (e.g. Spark-ML). Happy to hear any feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6dgsp", "is_robot_indexable": true, "report_reasons": null, "author": "zchtsk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6dgsp/i_created_an_opensource_microsite_to_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6dgsp/i_created_an_opensource_microsite_to_help/", "subreddit_subscribers": 165822, "created_utc": 1709565598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why do data warehouses usually use tools like snowflake, BigQuery, etc? Couldn't they just use regular SQL databases like PostgreSQL or MySQL?", "author_fullname": "t2_tfmsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could regular databases be used in data warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b68gbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709550891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why do data warehouses usually use tools like snowflake, BigQuery, etc? Couldn&amp;#39;t they just use regular SQL databases like PostgreSQL or MySQL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b68gbb", "is_robot_indexable": true, "report_reasons": null, "author": "DanteIsBack", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b68gbb/could_regular_databases_be_used_in_data_warehouses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b68gbb/could_regular_databases_be_used_in_data_warehouses/", "subreddit_subscribers": 165822, "created_utc": 1709550891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Open for interpretation.\n\nDon't think, just answer", "author_fullname": "t2_nypbpupk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you could wave a magic wand and have a \"how-to\" guide for anything in DE, what would it be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5ze8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709519004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Open for interpretation.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t think, just answer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5ze8q", "is_robot_indexable": true, "report_reasons": null, "author": "Techxpeare", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5ze8q/if_you_could_wave_a_magic_wand_and_have_a_howto/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5ze8q/if_you_could_wave_a_magic_wand_and_have_a_howto/", "subreddit_subscribers": 165822, "created_utc": 1709519004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB vs Polars - Thunderdome. 16GB on 4GB machine Challenge.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6cit9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Svhr6NvgsWl6waTwFmf_nAjL2WUOo8md6NzezDK14Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709563296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/duckdb-vs-polars-thunderdome", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?auto=webp&amp;s=b4a8e242d446aae1036387391700f0aabd59d711", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9e41e77a1a626e46ede2193743a478491b672f9", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=05d57e59619c7f14c81472cbb98bc9b9d294ae4e", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63e67f98f88582af1ef591d1ad1a17b1b9416872", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e385565c14dd165c96841dd34329ddf8125f54c", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36ac2596b5f88b7cf188f2f8c71b8f88ce6ad291", "width": 960, "height": 562}], "variants": {}, "id": "AGIJ8LXJRs-Gx1gN_z0Bvyhy42cce5TV-f-S_Opo_f8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6cit9", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6cit9/duckdb_vs_polars_thunderdome_16gb_on_4gb_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/duckdb-vs-polars-thunderdome", "subreddit_subscribers": 165822, "created_utc": 1709563296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI have 2 offers and don't know what to do?!\n\n1. the first offer : lower salary , they are mostly using SAS DI for ETL (which is my concern as It's legacy and would limit where I could grow as a data engineer-at least this my understanding-), but the team is more organized and have good structure with team lead with experience more than 10 years and DE seniors where i can learn from.\n2. the second offer has better salary and benefits, stack is spark and python and on-prem Hadoop cluster, using Nifi and python code for ETL pipelines, the team will only be one other than me with the same experience, the team is big but mostly focused on data analysis and data science.\n\nmy concern with the second offer is that there won't be someone with a lot more experience to learn from, is that critical or can I work on that myself even if it requires more effort.\n\n&amp;#x200B;\n\ncurrent experience 2 years in DE/data analysis using python, snowflake and Azure data factory.\n\nIt would be desirable to land a remote job in Europe or to be hired there in the future so which is better to pursue in terms of career and skills?  \n\n\nsorry for the wordy post, I appreciate any advice on this.\n\nthank you", "author_fullname": "t2_1kvyym2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice with next move", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6b2sa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709559465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I have 2 offers and don&amp;#39;t know what to do?!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;the first offer : lower salary , they are mostly using SAS DI for ETL (which is my concern as It&amp;#39;s legacy and would limit where I could grow as a data engineer-at least this my understanding-), but the team is more organized and have good structure with team lead with experience more than 10 years and DE seniors where i can learn from.&lt;/li&gt;\n&lt;li&gt;the second offer has better salary and benefits, stack is spark and python and on-prem Hadoop cluster, using Nifi and python code for ETL pipelines, the team will only be one other than me with the same experience, the team is big but mostly focused on data analysis and data science.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;my concern with the second offer is that there won&amp;#39;t be someone with a lot more experience to learn from, is that critical or can I work on that myself even if it requires more effort.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;current experience 2 years in DE/data analysis using python, snowflake and Azure data factory.&lt;/p&gt;\n\n&lt;p&gt;It would be desirable to land a remote job in Europe or to be hired there in the future so which is better to pursue in terms of career and skills?  &lt;/p&gt;\n\n&lt;p&gt;sorry for the wordy post, I appreciate any advice on this.&lt;/p&gt;\n\n&lt;p&gt;thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6b2sa", "is_robot_indexable": true, "report_reasons": null, "author": "ossama59", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6b2sa/career_advice_with_next_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6b2sa/career_advice_with_next_move/", "subreddit_subscribers": 165822, "created_utc": 1709559465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, looking for some advice on my current situation.\n\nI'm a software engineer with 5+ years of experience. I actually started my career in a non-software role but luckily got into data engineering after a year (I was in a rotational program and had self-taught programming so expressed my interest and fortunately got placed in a data engineering role). I worked in that role for roughly 1.5 years, briefly moved to a startup as a data engineer, then left to try starting my own software development agency. I was naive at the time and simply had this notion that I wanted to work for myself without any clear vision.\n\nWell after 2 years now of having started and closed my agency, working freelance gigs, joining a pre-seed startup as the only software developer, and subsequently being laid off after a failed raise, I've decided I want to refocus my career on pursuing data engineering for the long haul and have started applying to strictly data engineering roles. During the last 2 years I've worked in a full-stack capacity with a slight backend bias, developing JavaScript framework-based web apps, backend tooling in Python and Rust, APIs for mobile apps, cloud services implementation, and even dabbled in blockchain smart contract development. Recently I started working on personal projects that leverage data engineering skillsets.\n\nHow should I go about speaking to the last couple of years of software engineering experience and how do I leverage it in the context of wanting to get back into the data engineering field? Are the last couple of years even relevant at all or am I essentially looking to start over in data engineering? If it's worth anything, I'm a couple of classes away from finishing the Online Master of Science in Analytics degree from Georgia Tech (I started the degree as my former employer sponsored it but took a break to focus on my company).\n\nAny advice is much appreciated as I'm a bit lost on what my next steps are. Thanks!", "author_fullname": "t2_556v1ete", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice - Getting back into data engineering after a slight career pivot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b62ekj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709528173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, looking for some advice on my current situation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a software engineer with 5+ years of experience. I actually started my career in a non-software role but luckily got into data engineering after a year (I was in a rotational program and had self-taught programming so expressed my interest and fortunately got placed in a data engineering role). I worked in that role for roughly 1.5 years, briefly moved to a startup as a data engineer, then left to try starting my own software development agency. I was naive at the time and simply had this notion that I wanted to work for myself without any clear vision.&lt;/p&gt;\n\n&lt;p&gt;Well after 2 years now of having started and closed my agency, working freelance gigs, joining a pre-seed startup as the only software developer, and subsequently being laid off after a failed raise, I&amp;#39;ve decided I want to refocus my career on pursuing data engineering for the long haul and have started applying to strictly data engineering roles. During the last 2 years I&amp;#39;ve worked in a full-stack capacity with a slight backend bias, developing JavaScript framework-based web apps, backend tooling in Python and Rust, APIs for mobile apps, cloud services implementation, and even dabbled in blockchain smart contract development. Recently I started working on personal projects that leverage data engineering skillsets.&lt;/p&gt;\n\n&lt;p&gt;How should I go about speaking to the last couple of years of software engineering experience and how do I leverage it in the context of wanting to get back into the data engineering field? Are the last couple of years even relevant at all or am I essentially looking to start over in data engineering? If it&amp;#39;s worth anything, I&amp;#39;m a couple of classes away from finishing the Online Master of Science in Analytics degree from Georgia Tech (I started the degree as my former employer sponsored it but took a break to focus on my company).&lt;/p&gt;\n\n&lt;p&gt;Any advice is much appreciated as I&amp;#39;m a bit lost on what my next steps are. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b62ekj", "is_robot_indexable": true, "report_reasons": null, "author": "rebeccas_run", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b62ekj/advice_getting_back_into_data_engineering_after_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b62ekj/advice_getting_back_into_data_engineering_after_a/", "subreddit_subscribers": 165822, "created_utc": 1709528173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I'm a software developer that want to try data engineering.  \nI'm attending Data Engineering Zoomcamp by [Datatalks.club](https://Datatalks.club). I just complete the week 5 about batch data processing. I just want to elaborate my knowledge from orchestration ([mage.ai](http://mage.ai/)) and spark (or pyspark whatever).  \nI want to know, is it possible to dockerize [mage.ai](http://mage.ai/) and spark? because in the material spark only running on local machine.", "author_fullname": "t2_2lvigk1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to dockerize spark and mage.ai", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b69w5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709555825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m a software developer that want to try data engineering.&lt;br/&gt;\nI&amp;#39;m attending Data Engineering Zoomcamp by &lt;a href=\"https://Datatalks.club\"&gt;Datatalks.club&lt;/a&gt;. I just complete the week 5 about batch data processing. I just want to elaborate my knowledge from orchestration (&lt;a href=\"http://mage.ai/\"&gt;mage.ai&lt;/a&gt;) and spark (or pyspark whatever).&lt;br/&gt;\nI want to know, is it possible to dockerize &lt;a href=\"http://mage.ai/\"&gt;mage.ai&lt;/a&gt; and spark? because in the material spark only running on local machine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?auto=webp&amp;s=55508cb4a6b874b5e37fb7a170c14ef80487d34a", "width": 1032, "height": 525}, "resolutions": [{"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e0506d70e4b9f19621088472046f607e0ba8a98", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e15327ab0f10ac05a6fbe11716943248cd455b8", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0209ccd362987edc89a8e99578c1678c0ed89bd5", "width": 320, "height": 162}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d7c5620225f62e43b180c1b88c3f0278dc5b01ec", "width": 640, "height": 325}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=225bf591f1c42dc8b05b34b3d75b6662896814c1", "width": 960, "height": 488}], "variants": {}, "id": "YfWijtKzkVKJWYfcR7I0BVyJCG-El7IkWyz6doaqagU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b69w5a", "is_robot_indexable": true, "report_reasons": null, "author": "muh_ilhamfajar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b69w5a/how_to_dockerize_spark_and_mageai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b69w5a/how_to_dockerize_spark_and_mageai/", "subreddit_subscribers": 165822, "created_utc": 1709555825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have implemented a large scale project for a hospital and the entire infrastructure was built on Azure. I set up the ELT pipelines using ADF and pyspark(for data manipulation and enrichment) and the company created API endpoints around their data sources. And so I used to extract data from the API and load it into a data lake. I then use this weekly generated data to create a dashboard which then auto refreshes weekly. I've never had to use SQL and even if I did have to use it, OpenAI's GPT-4-Turbo-preview model via the API has been absolutely great. \n\nNot to mention that I do know basics of SQL, doing transformations, Window functions, etc. But since OpenAI was able to write the queries exactly how I needed it, I wanted to know if it is worth investing significant amount of time to master SQL.  Yes, OpenAI may get expensive and I need to kno0w when to step in to get the correct O/P, but whenever I put in the schema, what I want, and an example of input and output, it gets the query right 95% of the time in the first go. So is it worth going into advanced SQL or to learn more about the different technologies involved in DE? Any advice would be great, thank you!", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Important is SQL for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6iw84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709578443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have implemented a large scale project for a hospital and the entire infrastructure was built on Azure. I set up the ELT pipelines using ADF and pyspark(for data manipulation and enrichment) and the company created API endpoints around their data sources. And so I used to extract data from the API and load it into a data lake. I then use this weekly generated data to create a dashboard which then auto refreshes weekly. I&amp;#39;ve never had to use SQL and even if I did have to use it, OpenAI&amp;#39;s GPT-4-Turbo-preview model via the API has been absolutely great. &lt;/p&gt;\n\n&lt;p&gt;Not to mention that I do know basics of SQL, doing transformations, Window functions, etc. But since OpenAI was able to write the queries exactly how I needed it, I wanted to know if it is worth investing significant amount of time to master SQL.  Yes, OpenAI may get expensive and I need to kno0w when to step in to get the correct O/P, but whenever I put in the schema, what I want, and an example of input and output, it gets the query right 95% of the time in the first go. So is it worth going into advanced SQL or to learn more about the different technologies involved in DE? Any advice would be great, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6iw84", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6iw84/how_important_is_sql_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6iw84/how_important_is_sql_for_data_engineers/", "subreddit_subscribers": 165822, "created_utc": 1709578443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's \"Modern\" in the Modern Data Stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1b69inb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/q1egZ4ZVa1gwL3t7A4aLCoGrcZaxl44lTpI-gSfCqY4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709554605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/whats-modern-in-the-modern-data-stack", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?auto=webp&amp;s=99929a7c3b23b09f4937a54adca9f06e69f0a8f4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6379b2d37eb79f77b5c016a93186f471855a4734", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46f7430807195c599b95cee1927fd6eae8e9f15f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=74c303178f071c6c6c8a5d9a543da50dd5b727c1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aac42f5f61e174f72a4bb47815326b1c59a97914", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=73d224331b54e3000ce208078154f8f55c6bf154", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=51d6ee39e2a410d4af83c04a9f8600e1674e6778", "width": 1080, "height": 540}], "variants": {}, "id": "2OHr9EogUDUSkv0pbBvY1Y2IP6gjwsgfB-3Jot5YbVc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b69inb", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b69inb/whats_modern_in_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/whats-modern-in-the-modern-data-stack", "subreddit_subscribers": 165822, "created_utc": 1709554605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have data coming from an API for the buses running daily within the country. The data for a particular bus looks like this:\n\n    [{'busNumber': 1,\n    'departureDate': '2024-01-01',\n    'operatorCode': 1,\n    'busType': 'ev',\n    'busCategory': 'Long-distance',\n    'timeTableRows': [{'stationCode': 'B01',\n                       'type': 'DEPARTURE',     \n                       'busStopping': True,     \n                       'confirmedStop': True,   \n                       'scheduledTime': '2024-01-01T12:24:00.000Z',     \n                       'actualTime': '2024-01-01T12:24:58.000Z'},\n                      {'stationCode': 'B02',     \n                       'type': 'ARRIVAL',     \n                       'busStopping': True,     \n                       'confirmedStop': True,  \n                       'scheduledTime': '2024-01-01T12:29:00.000Z',     \n                       'actualTime': '2024-01-01T12:30:53.000Z'}\n                     ]\n\nI understand that because of the already present structure, relational db like postgres, mySQL would be the best databases. But, can this data be considered like a timeseries and be stored in NoSQL databases like Cassandra/HBase?", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can data fetched on a per day basis be treated like timeseries data and stored in Cassandra/HBase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b67asb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709546487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have data coming from an API for the buses running daily within the country. The data for a particular bus looks like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[{&amp;#39;busNumber&amp;#39;: 1,\n&amp;#39;departureDate&amp;#39;: &amp;#39;2024-01-01&amp;#39;,\n&amp;#39;operatorCode&amp;#39;: 1,\n&amp;#39;busType&amp;#39;: &amp;#39;ev&amp;#39;,\n&amp;#39;busCategory&amp;#39;: &amp;#39;Long-distance&amp;#39;,\n&amp;#39;timeTableRows&amp;#39;: [{&amp;#39;stationCode&amp;#39;: &amp;#39;B01&amp;#39;,\n                   &amp;#39;type&amp;#39;: &amp;#39;DEPARTURE&amp;#39;,     \n                   &amp;#39;busStopping&amp;#39;: True,     \n                   &amp;#39;confirmedStop&amp;#39;: True,   \n                   &amp;#39;scheduledTime&amp;#39;: &amp;#39;2024-01-01T12:24:00.000Z&amp;#39;,     \n                   &amp;#39;actualTime&amp;#39;: &amp;#39;2024-01-01T12:24:58.000Z&amp;#39;},\n                  {&amp;#39;stationCode&amp;#39;: &amp;#39;B02&amp;#39;,     \n                   &amp;#39;type&amp;#39;: &amp;#39;ARRIVAL&amp;#39;,     \n                   &amp;#39;busStopping&amp;#39;: True,     \n                   &amp;#39;confirmedStop&amp;#39;: True,  \n                   &amp;#39;scheduledTime&amp;#39;: &amp;#39;2024-01-01T12:29:00.000Z&amp;#39;,     \n                   &amp;#39;actualTime&amp;#39;: &amp;#39;2024-01-01T12:30:53.000Z&amp;#39;}\n                 ]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I understand that because of the already present structure, relational db like postgres, mySQL would be the best databases. But, can this data be considered like a timeseries and be stored in NoSQL databases like Cassandra/HBase?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b67asb", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b67asb/can_data_fetched_on_a_per_day_basis_be_treated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b67asb/can_data_fetched_on_a_per_day_basis_be_treated/", "subreddit_subscribers": 165822, "created_utc": 1709546487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading Design data intensive applications and in 3rd chapter they mentioned 3 types of indexes in databases.\n\n1. Hash based.\n2. B Trees.\n3. LSM Trees.\n\nIn lsm trees first we check in memtable if data is not present there then we check sparse index to check in which sstable segment will be present. And then we can apply binary search on that segment  for our key.  \nMy question is, Binary search we apply based on address arithmetic right because if we load complete segment in memory and then do bs then it will be a costly operation ?\n\nEdit 1 - Sorry I messed up title, now i can't edit :).", "author_fullname": "t2_aqmxwdoy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSM Trees vs B indexes indexing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5z1l1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709517975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading Design data intensive applications and in 3rd chapter they mentioned 3 types of indexes in databases.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Hash based.&lt;/li&gt;\n&lt;li&gt;B Trees.&lt;/li&gt;\n&lt;li&gt;LSM Trees.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In lsm trees first we check in memtable if data is not present there then we check sparse index to check in which sstable segment will be present. And then we can apply binary search on that segment  for our key.&lt;br/&gt;\nMy question is, Binary search we apply based on address arithmetic right because if we load complete segment in memory and then do bs then it will be a costly operation ?&lt;/p&gt;\n\n&lt;p&gt;Edit 1 - Sorry I messed up title, now i can&amp;#39;t edit :).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5z1l1", "is_robot_indexable": true, "report_reasons": null, "author": "AggravatingParsnip89", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5z1l1/lsm_trees_vs_b_indexes_indexing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5z1l1/lsm_trees_vs_b_indexes_indexing/", "subreddit_subscribers": 165822, "created_utc": 1709517975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nTrying to give guidance to a company in mid market 600 FTE. They have heard about Mage AI and are interested in it. Any experiences with it? Does it solve certain problems that Airflow/Prefect/Astronomer doesn\u2019t? ", "author_fullname": "t2_putygiix7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mage AI experiences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6k06l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709581113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Trying to give guidance to a company in mid market 600 FTE. They have heard about Mage AI and are interested in it. Any experiences with it? Does it solve certain problems that Airflow/Prefect/Astronomer doesn\u2019t? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6k06l", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantParty6489", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6k06l/mage_ai_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6k06l/mage_ai_experiences/", "subreddit_subscribers": 165822, "created_utc": 1709581113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nWe made a tool for BigQuery users. You can generate a view from a JSON object if you are storing your data as us in a JSON field, it's very useful!\n\nAny feedback is welcome! :)\n\nThe tool is here: [https://vg.persio.io](https://vg.persio.io)", "author_fullname": "t2_1mwhn72z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free RAW Json to View tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6i9st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709580170.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709576950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;We made a tool for BigQuery users. You can generate a view from a JSON object if you are storing your data as us in a JSON field, it&amp;#39;s very useful!&lt;/p&gt;\n\n&lt;p&gt;Any feedback is welcome! :)&lt;/p&gt;\n\n&lt;p&gt;The tool is here: &lt;a href=\"https://vg.persio.io\"&gt;https://vg.persio.io&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?auto=webp&amp;s=5e69c52008196472a67548003a28f8f20d609d3b", "width": 878, "height": 460}, "resolutions": [{"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f75eb1a72319934c5328dd4c88160047a46ebfc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61e2acfe92daa0f3277fe698099d56f6738b5c23", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47742f25f6f66e00357e66fb8567f3b30e58c0fa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=19fa8ef1b854a514192bdd51e9b6981d77bc8bc6", "width": 640, "height": 335}], "variants": {}, "id": "5z7wVcO2sxef0OZxRjwC5Wp8rwhxWzWvcKNb8uUTPeI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b6i9st", "is_robot_indexable": true, "report_reasons": null, "author": "pigri", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6i9st/free_raw_json_to_view_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6i9st/free_raw_json_to_view_tool/", "subreddit_subscribers": 165822, "created_utc": 1709576950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Greetings all. Experienced data engineer, but AWS Novice and looking for best practices (if any)\n\nI have a MySQL RDS db, which I want to create a real- or near realtime CDC into a new Aurora PostgreSQL db. This is a database replatform, and both databases will be in use for some time. (The old MySQL db will still be having data written to it, but over time, we'll be migrating code over to the Postgres db.) In addition, the Postgres db is not even close to the same schema as the MySQL db, and significant ETL will be needed.\n\nIt doesn't look like anything in AWS really accomplishes both a realtime data migration *and* complex ETL. What are tried and tested third-party tools that can accomplish this?\n\nMany thanks in advance.", "author_fullname": "t2_9h42b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complex CDC ETL from RDS MySQL to Aurora Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b6niyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709589619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings all. Experienced data engineer, but AWS Novice and looking for best practices (if any)&lt;/p&gt;\n\n&lt;p&gt;I have a MySQL RDS db, which I want to create a real- or near realtime CDC into a new Aurora PostgreSQL db. This is a database replatform, and both databases will be in use for some time. (The old MySQL db will still be having data written to it, but over time, we&amp;#39;ll be migrating code over to the Postgres db.) In addition, the Postgres db is not even close to the same schema as the MySQL db, and significant ETL will be needed.&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t look like anything in AWS really accomplishes both a realtime data migration &lt;em&gt;and&lt;/em&gt; complex ETL. What are tried and tested third-party tools that can accomplish this?&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6niyw", "is_robot_indexable": true, "report_reasons": null, "author": "Lightsider", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6niyw/complex_cdc_etl_from_rds_mysql_to_aurora_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6niyw/complex_cdc_etl_from_rds_mysql_to_aurora_postgres/", "subreddit_subscribers": 165822, "created_utc": 1709589619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Erwin can reverse engineer a view but it doesn't seem to handle CASE statements and errors out. This is for Hive. Does anyone know if reverse engineering of views can handle CASE statements?", "author_fullname": "t2_kkmygn8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse engineering using Erwin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b6ndyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709589281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Erwin can reverse engineer a view but it doesn&amp;#39;t seem to handle CASE statements and errors out. This is for Hive. Does anyone know if reverse engineering of views can handle CASE statements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6ndyb", "is_robot_indexable": true, "report_reasons": null, "author": "KarmicDharmic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ndyb/reverse_engineering_using_erwin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ndyb/reverse_engineering_using_erwin/", "subreddit_subscribers": 165822, "created_utc": 1709589281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_h5f0hf69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leaving LinkedIn Choosing Engineering Excellence Over Expediency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6knkl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u2WIp0qVmte5zZpGDuvaxFPzvWfGHew0tlvX2d2bjJs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709582703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "corecursive.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://corecursive.com/leaving-linkedin-with-chris-krycho/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?auto=webp&amp;s=f2bf0cbe65da496b817ac521d7b445ce3a640c52", "width": 3000, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6ba4534e076b2a552d554914e7f2f1ab47cdbd2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=68168466948db838f259ac962f62e32249f13341", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b60a3029a4e936d726404e90a07e0c3d6c5935f8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=992e33224246ec291bc5c5c9f0abc3bea7bd4dd4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=244679e83e78b02b413ddf087c4210a09b77ff09", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b431f38ed2a74205726ec83df7acf37b049b4f47", "width": 1080, "height": 540}], "variants": {}, "id": "rUXfOjVKsNPs5APIrbXZ7tIgl9QCoEGUScE1VM2-GKo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6knkl", "is_robot_indexable": true, "report_reasons": null, "author": "mowaptpop", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6knkl/leaving_linkedin_choosing_engineering_excellence/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://corecursive.com/leaving-linkedin-with-chris-krycho/", "subreddit_subscribers": 165822, "created_utc": 1709582703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI'm looking for some advice and I'm hoping this is the right spot. \n\n&amp;#x200B;\n\nI've recently started a new role as a Machine Learning Engineer for a R&amp;D team focusing on computer vision applications. It has become clear that the biggest weakness in our operation stems from our approach to data. We have \\~terabytes of proprietary image and video data in various formats and no system to efficiently process and label it.  I have been assigned the task of developing a data pipeline to curate custom datasets for our CV models but I don't have any real expertise in data engineering other than some experience with SQL/NoSQL databases. \n\n&amp;#x200B;\n\nI'm aware that a team of dedicated Data Engineers is really what's required for such a task but unfortunately I am the only one available to work on this problem. With that in mind, I'd very much appreciate any guidance on the following: \n\n1. What resources are available for learning Data Engineering for CV? I have spent a lot of time researching this area now but most resources that I've come across really only focus on structured tabular data. I haven't come across any resource that discusses best practices when dealing with video or image data. \n2. How do I decide on what tools to use? I am overwhelmed by the choice of tools relating to the 'modern data stack'. I have come across Activeloop's DeepLake which seems promising but then Delta Lake seems to be more popular. Do I even need a Lakehouse architecture? \n3. I have set up CVAT for image annotation with semi-automatic labelling to improve efficiency. Are there better tools out there for labelling? I have seen LabelBox mentioned as a viable alternative. \n\n&amp;#x200B;\n\nOf course I have many other questions but I'll keep this short as the main thing I'm looking for is advice on how to improve and learn. Any information would be much appreciated! ", "author_fullname": "t2_a1k94kfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering for Computer Vision - Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6kgk6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709582238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some advice and I&amp;#39;m hoping this is the right spot. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started a new role as a Machine Learning Engineer for a R&amp;amp;D team focusing on computer vision applications. It has become clear that the biggest weakness in our operation stems from our approach to data. We have ~terabytes of proprietary image and video data in various formats and no system to efficiently process and label it.  I have been assigned the task of developing a data pipeline to curate custom datasets for our CV models but I don&amp;#39;t have any real expertise in data engineering other than some experience with SQL/NoSQL databases. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that a team of dedicated Data Engineers is really what&amp;#39;s required for such a task but unfortunately I am the only one available to work on this problem. With that in mind, I&amp;#39;d very much appreciate any guidance on the following: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What resources are available for learning Data Engineering for CV? I have spent a lot of time researching this area now but most resources that I&amp;#39;ve come across really only focus on structured tabular data. I haven&amp;#39;t come across any resource that discusses best practices when dealing with video or image data. &lt;/li&gt;\n&lt;li&gt;How do I decide on what tools to use? I am overwhelmed by the choice of tools relating to the &amp;#39;modern data stack&amp;#39;. I have come across Activeloop&amp;#39;s DeepLake which seems promising but then Delta Lake seems to be more popular. Do I even need a Lakehouse architecture? &lt;/li&gt;\n&lt;li&gt;I have set up CVAT for image annotation with semi-automatic labelling to improve efficiency. Are there better tools out there for labelling? I have seen LabelBox mentioned as a viable alternative. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Of course I have many other questions but I&amp;#39;ll keep this short as the main thing I&amp;#39;m looking for is advice on how to improve and learn. Any information would be much appreciated! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6kgk6", "is_robot_indexable": true, "report_reasons": null, "author": "distracted-ferret", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6kgk6/data_engineering_for_computer_vision_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6kgk6/data_engineering_for_computer_vision_advice/", "subreddit_subscribers": 165822, "created_utc": 1709582238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to prep for some upcoming interviews.\n\nAll I know is confluence, Jira, Jenkins, airflow and data bricks are what are being used.\n\nAny advice is appreciated. ", "author_fullname": "t2_p7krf9ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to prep for upcoming connect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6jflr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709579735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to prep for some upcoming interviews.&lt;/p&gt;\n\n&lt;p&gt;All I know is confluence, Jira, Jenkins, airflow and data bricks are what are being used.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6jflr", "is_robot_indexable": true, "report_reasons": null, "author": "Poyal_Rines", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6jflr/trying_to_prep_for_upcoming_connect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6jflr/trying_to_prep_for_upcoming_connect/", "subreddit_subscribers": 165822, "created_utc": 1709579735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At [PeerDB](https://peerdb.io/), we commonly get asked from customers on the preferred Postgres managed service. In that spirit, we are releasing our first part of Comparing Postgres Managed Services.\n\nThe blog includes 4 popular options\u00a0 - AWS RDS Postgres, Azure Flexible Server Postgres, GCP CloudSQL Postgres and Supabase and compares them against 3 main dimensions of Performance, Costs and Features. [https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase](https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase)\n\nA couple of disclaimers:  \nThe blog serves as an initial checklist for developers considering managed services. It's an overview, not an exhaustive analysis.  \nThe blog doesn't cover other managed services like Tembo, Crunchy, Neon, TimescaleDB, Aiven, etc. We'll include them in future posts.", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Postgres Managed Services: AWS, Azure, GCP and Supabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6h1cm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709574031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At &lt;a href=\"https://peerdb.io/\"&gt;PeerDB&lt;/a&gt;, we commonly get asked from customers on the preferred Postgres managed service. In that spirit, we are releasing our first part of Comparing Postgres Managed Services.&lt;/p&gt;\n\n&lt;p&gt;The blog includes 4 popular options\u00a0 - AWS RDS Postgres, Azure Flexible Server Postgres, GCP CloudSQL Postgres and Supabase and compares them against 3 main dimensions of Performance, Costs and Features. &lt;a href=\"https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase\"&gt;https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A couple of disclaimers:&lt;br/&gt;\nThe blog serves as an initial checklist for developers considering managed services. It&amp;#39;s an overview, not an exhaustive analysis.&lt;br/&gt;\nThe blog doesn&amp;#39;t cover other managed services like Tembo, Crunchy, Neon, TimescaleDB, Aiven, etc. We&amp;#39;ll include them in future posts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6h1cm", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6h1cm/comparing_postgres_managed_services_aws_azure_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6h1cm/comparing_postgres_managed_services_aws_azure_gcp/", "subreddit_subscribers": 165822, "created_utc": 1709574031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Guys, I am trying to setup cdc for our warehouse.  \nI have set it up on dev but the challenge on stage is that the stage db i.e source gets refreshed bi monthly that means the db is restored from prod anonimysed db snapshot.  \n\n\nThe challenge that i see is, every time that refresh will happen we will loose those publication and replication slot. We can create both the things at time of restore but the LSN would be different and might cause some problems.   \n\n\nThe subscriber at the other side is a debezium connector on top of kafka.\n\nPlease don't suggest any architecture changes. Can't implement those.", "author_fullname": "t2_ry9gwrc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setup CDC For changing source replication slot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6gq4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709573321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Guys, I am trying to setup cdc for our warehouse.&lt;br/&gt;\nI have set it up on dev but the challenge on stage is that the stage db i.e source gets refreshed bi monthly that means the db is restored from prod anonimysed db snapshot.  &lt;/p&gt;\n\n&lt;p&gt;The challenge that i see is, every time that refresh will happen we will loose those publication and replication slot. We can create both the things at time of restore but the LSN would be different and might cause some problems.   &lt;/p&gt;\n\n&lt;p&gt;The subscriber at the other side is a debezium connector on top of kafka.&lt;/p&gt;\n\n&lt;p&gt;Please don&amp;#39;t suggest any architecture changes. Can&amp;#39;t implement those.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6gq4k", "is_robot_indexable": true, "report_reasons": null, "author": "_Gangadhar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6gq4k/setup_cdc_for_changing_source_replication_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6gq4k/setup_cdc_for_changing_source_replication_slot/", "subreddit_subscribers": 165822, "created_utc": 1709573321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nUp until recently, I was a Sr DE at FAANG (7YOE). However, I was part of the recent layoffs and found myself contemplating my next steps sooner than expected. To add a twist to the plot, I just tore my achilles tendon playing basketball, which means I'll be spending quite a bit of time on my butt at home recovering. Not exactly the kind of break I had in mind, but here we are.\n\nPost layoff, I was already planning to take a significant break to reset and figure out what I want to do next. The injury just extended this timeline a bit. I'm pretty comfortable with the Leetcode grind, system design, and all that jazz. But for this break, I want to focus on learning and exploring - diving into new tech, maybe picking up some skills that are just for fun, and generally getting reinvigorated about the field.\n\nI've spent a good part of my career leading projects, primarily working with AWS, Python, SQL, mainly with ETL platforms. While I'm pondering whether to return to FAANG or venture into something smaller where I can have a bigger impact (perhaps lead a larger team), I'm not quite sure where to direct my learning energy.\n\nSo, I'm reaching out for suggestions on how to make the most of this time. Are there any books, courses, or personal projects you would recommend? Any emerging tech or tools I should get my hands on? Or perhaps some advice on making a transition that could allow me to be more impactful and fulfill my desire to work closely with a team?\n\nI'm all ears and really appreciate any thoughts or guidance you can share. Thank you!", "author_fullname": "t2_1swxdf76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice for a Sr DE's Learning Journey Post-FAANG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6fxq9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709571506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;Up until recently, I was a Sr DE at FAANG (7YOE). However, I was part of the recent layoffs and found myself contemplating my next steps sooner than expected. To add a twist to the plot, I just tore my achilles tendon playing basketball, which means I&amp;#39;ll be spending quite a bit of time on my butt at home recovering. Not exactly the kind of break I had in mind, but here we are.&lt;/p&gt;\n\n&lt;p&gt;Post layoff, I was already planning to take a significant break to reset and figure out what I want to do next. The injury just extended this timeline a bit. I&amp;#39;m pretty comfortable with the Leetcode grind, system design, and all that jazz. But for this break, I want to focus on learning and exploring - diving into new tech, maybe picking up some skills that are just for fun, and generally getting reinvigorated about the field.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve spent a good part of my career leading projects, primarily working with AWS, Python, SQL, mainly with ETL platforms. While I&amp;#39;m pondering whether to return to FAANG or venture into something smaller where I can have a bigger impact (perhaps lead a larger team), I&amp;#39;m not quite sure where to direct my learning energy.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m reaching out for suggestions on how to make the most of this time. Are there any books, courses, or personal projects you would recommend? Any emerging tech or tools I should get my hands on? Or perhaps some advice on making a transition that could allow me to be more impactful and fulfill my desire to work closely with a team?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m all ears and really appreciate any thoughts or guidance you can share. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6fxq9", "is_robot_indexable": true, "report_reasons": null, "author": "hairbear1234", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6fxq9/seeking_advice_for_a_sr_des_learning_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6fxq9/seeking_advice_for_a_sr_des_learning_journey/", "subreddit_subscribers": 165822, "created_utc": 1709571506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n&amp;#x200B;\n\nHi everyone,\n\nI'm in the process of designing an online data analytics architecture and could use some guidance. My current setup is based on the Kappa architecture. Here's a brief overview:\n\n* **Source:** Events are published to a Kafka topic.\n* **Processing:** These events are processed using Apache Flink.\n* **Storage:** Processed results are ingested into ClickHouse for analytics.\n\nI'm aiming to create a robust and scalable solution. However, I'm facing a challenge regarding data storage. Specifically, I want to store raw data in a deep storage solution like Amazon S3 without duplicating the processing steps already handled by Apache Flink.\n\nMy question to the community is: Is there an efficient way to integrate deep storage (like S3) into this pipeline, ensuring that raw data is preserved without reprocessing it? I'm looking for strategies or best practices that might help in achieving this, ideally without complicating the pipeline or introducing significant overhead.\n\nAny insights, experiences, or advice on tools and techniques to streamline this process would be greatly appreciated. I'm particularly interested in any configurations or integrations that have worked well for you in similar setups.\n\nThanks in advance for your help!", "author_fullname": "t2_tn6js66um", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Guidance on Designing an Online Data Analytics Pipeline with Kafka, Apache Flink, and ClickHouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6exrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709569115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the process of designing an online data analytics architecture and could use some guidance. My current setup is based on the Kappa architecture. Here&amp;#39;s a brief overview:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Source:&lt;/strong&gt; Events are published to a Kafka topic.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Processing:&lt;/strong&gt; These events are processed using Apache Flink.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt; Processed results are ingested into ClickHouse for analytics.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m aiming to create a robust and scalable solution. However, I&amp;#39;m facing a challenge regarding data storage. Specifically, I want to store raw data in a deep storage solution like Amazon S3 without duplicating the processing steps already handled by Apache Flink.&lt;/p&gt;\n\n&lt;p&gt;My question to the community is: Is there an efficient way to integrate deep storage (like S3) into this pipeline, ensuring that raw data is preserved without reprocessing it? I&amp;#39;m looking for strategies or best practices that might help in achieving this, ideally without complicating the pipeline or introducing significant overhead.&lt;/p&gt;\n\n&lt;p&gt;Any insights, experiences, or advice on tools and techniques to streamline this process would be greatly appreciated. I&amp;#39;m particularly interested in any configurations or integrations that have worked well for you in similar setups.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6exrn", "is_robot_indexable": true, "report_reasons": null, "author": "More-Ad-5207", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6exrn/seeking_guidance_on_designing_an_online_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6exrn/seeking_guidance_on_designing_an_online_data/", "subreddit_subscribers": 165822, "created_utc": 1709569115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The term \"framework\" is thrown around a lot, and I would like to understand, what do we mean by that.", "author_fullname": "t2_28hb9aog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do we mean by \"framework\" in the context of Hadoop being a big data open source framework?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6cazx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709562753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The term &amp;quot;framework&amp;quot; is thrown around a lot, and I would like to understand, what do we mean by that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6cazx", "is_robot_indexable": true, "report_reasons": null, "author": "abhinavb2001", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6cazx/what_do_we_mean_by_framework_in_the_context_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6cazx/what_do_we_mean_by_framework_in_the_context_of/", "subreddit_subscribers": 165822, "created_utc": 1709562753.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}