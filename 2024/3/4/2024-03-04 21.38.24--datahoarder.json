{"kind": "Listing", "data": {"after": "t3_1b5y3vr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nClose your eyes and imagine a 3.5\" hard drive. I what you imagine has a chrome/metal gray lid and black painted sides - right?\n\nBecause they all have. But why? \n\nI mean, why paint the aluminium box that hosts the platters black? Why always black? And why paint it at all? \n\nExample of what I mean?\nhttps://cdn.mos.cms.futurecdn.net/NWGNV7VmFfj2XwgNWjGez9-970-80.jpg\n\n\nIs there a technical reason to paint this? It is painted on the inside too - so I guess it is not (only) about looks?\n\nAnd why always black? Why wouldn't WD make WD REDs use red paint, WD GREEN use green paint and so on?", "author_fullname": "t2_nlx42kb0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why black paint on hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6iuhu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709578322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Close your eyes and imagine a 3.5&amp;quot; hard drive. I what you imagine has a chrome/metal gray lid and black painted sides - right?&lt;/p&gt;\n\n&lt;p&gt;Because they all have. But why? &lt;/p&gt;\n\n&lt;p&gt;I mean, why paint the aluminium box that hosts the platters black? Why always black? And why paint it at all? &lt;/p&gt;\n\n&lt;p&gt;Example of what I mean?\n&lt;a href=\"https://cdn.mos.cms.futurecdn.net/NWGNV7VmFfj2XwgNWjGez9-970-80.jpg\"&gt;https://cdn.mos.cms.futurecdn.net/NWGNV7VmFfj2XwgNWjGez9-970-80.jpg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there a technical reason to paint this? It is painted on the inside too - so I guess it is not (only) about looks?&lt;/p&gt;\n\n&lt;p&gt;And why always black? Why wouldn&amp;#39;t WD make WD REDs use red paint, WD GREEN use green paint and so on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jBTsyujQOAk5-krAcwdVyUbxT68cEkI7ZR2YPLiAtjQ.jpg?auto=webp&amp;s=a3dd306538a30697cb8578546f1d52fbe34c1f0f", "width": 970, "height": 712}, "resolutions": [{"url": "https://external-preview.redd.it/jBTsyujQOAk5-krAcwdVyUbxT68cEkI7ZR2YPLiAtjQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee58bb8bb11afe7eb1cd2d76641b375d143f9da4", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/jBTsyujQOAk5-krAcwdVyUbxT68cEkI7ZR2YPLiAtjQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=205388ad01c6be51ed030a93ba53dc155a522c91", "width": 216, "height": 158}, {"url": "https://external-preview.redd.it/jBTsyujQOAk5-krAcwdVyUbxT68cEkI7ZR2YPLiAtjQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dab71a03b7abf1db7410f9547ec7807aee0fa6f9", "width": 320, "height": 234}, {"url": "https://external-preview.redd.it/jBTsyujQOAk5-krAcwdVyUbxT68cEkI7ZR2YPLiAtjQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ff2a429fc81e8f64bfb9b586a12bef1dc749833", "width": 640, "height": 469}, {"url": "https://external-preview.redd.it/jBTsyujQOAk5-krAcwdVyUbxT68cEkI7ZR2YPLiAtjQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5893e0fb8941e9e2ac54d5d107a9da8c4fd0f29f", "width": 960, "height": 704}], "variants": {}, "id": "83t3KyPlaArWqu2DEa8mAsMavI9qz1wBYDht05-aD7I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b6iuhu", "is_robot_indexable": true, "report_reasons": null, "author": "PM_Me_Food_Pics_", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6iuhu/why_black_paint_on_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6iuhu/why_black_paint_on_hard_drives/", "subreddit_subscribers": 736125, "created_utc": 1709578322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "good morning, nice community!\n\nthe context: there is a Dell R730xd ( with 24x 2.5\u201d drive slots ) and HBA330. I am thinking of populating these 24 slots with sas ssds. Found the one on the picture.\n\nthe question: should I expect any sort of incompatibility between the HBA330 in the Dell server and this drive?\n\nbest regards,\nDmitry", "author_fullname": "t2_w4mwm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "sas ssd labelled as Sun", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6dvt7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 22, "domain": "i.redd.it", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jeuyEA07UqKP5vpE2sHojmxnBqaEeAgJE57sOEwXG_Q.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709566619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;good morning, nice community!&lt;/p&gt;\n\n&lt;p&gt;the context: there is a Dell R730xd ( with 24x 2.5\u201d drive slots ) and HBA330. I am thinking of populating these 24 slots with sas ssds. Found the one on the picture.&lt;/p&gt;\n\n&lt;p&gt;the question: should I expect any sort of incompatibility between the HBA330 in the Dell server and this drive?&lt;/p&gt;\n\n&lt;p&gt;best regards,\nDmitry&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/z8sf471a7cmc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/z8sf471a7cmc1.jpeg?auto=webp&amp;s=1ca6eca4ca5caa1bf39ecef852e3b4da4c09d09b", "width": 750, "height": 1334}, "resolutions": [{"url": "https://preview.redd.it/z8sf471a7cmc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a154727bd445d65b2b0267f7251ab8016135050", "width": 108, "height": 192}, {"url": "https://preview.redd.it/z8sf471a7cmc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17d9fc0d2460c7c44f7620c5ebea7e4f864109ff", "width": 216, "height": 384}, {"url": "https://preview.redd.it/z8sf471a7cmc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4c9bfff9bb578abe70030aac65dd4d9d42007cb", "width": 320, "height": 569}, {"url": "https://preview.redd.it/z8sf471a7cmc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=891bb8c1d2ce60f47f03785c0f9e36772a27968a", "width": 640, "height": 1138}], "variants": {}, "id": "btFl8Q8QAC4PYSGD6_nishfu7ZVpWURQQ3dxfNxL-F4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6dvt7", "is_robot_indexable": true, "report_reasons": null, "author": "dmitry-n-medvedev", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6dvt7/sas_ssd_labelled_as_sun/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/z8sf471a7cmc1.jpeg", "subreddit_subscribers": 736125, "created_utc": 1709566619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It looks like [Yuzu](https://yuzu-emu.org) settled their lawsuit with Nintendo and will be handing over everything to them. What's the best way to archive the entire site and their repositories (which I assume are going to be deleted)?", "author_fullname": "t2_3zh9k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "request: archive Yuzu website and repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ira2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709578103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It looks like &lt;a href=\"https://yuzu-emu.org\"&gt;Yuzu&lt;/a&gt; settled their lawsuit with Nintendo and will be handing over everything to them. What&amp;#39;s the best way to archive the entire site and their repositories (which I assume are going to be deleted)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6ira2", "is_robot_indexable": true, "report_reasons": null, "author": "hysan", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6ira2/request_archive_yuzu_website_and_repositories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6ira2/request_archive_yuzu_website_and_repositories/", "subreddit_subscribers": 736125, "created_utc": 1709578103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I never gave it much thought until today- had a bit of a shower thought. Is the caption and/or girl from an anime or comic series I take it? I looked up \"what do you mean delete\", in quotes, on that ducky search engine and found nothing.", "author_fullname": "t2_zfbqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Meta] What's the sauce of this sub's banner image?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b68s2k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709552077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I never gave it much thought until today- had a bit of a shower thought. Is the caption and/or girl from an anime or comic series I take it? I looked up &amp;quot;what do you mean delete&amp;quot;, in quotes, on that ducky search engine and found nothing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "I got 99 movies, but I ain't watched one.", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b68s2k", "is_robot_indexable": true, "report_reasons": null, "author": "tapdancingwhale", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b68s2k/meta_whats_the_sauce_of_this_subs_banner_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b68s2k/meta_whats_the_sauce_of_this_subs_banner_image/", "subreddit_subscribers": 736125, "created_utc": 1709552077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a lot of files I want to archive eventually, and seeing how you can pay very little for LTO tape disks for a lot of storage, I'm considering trying it out. What reader/tapes should I get? My budget is pretty high, and this is solely for archival purposes.", "author_fullname": "t2_9qvbu0wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do i get started to tape drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6i3kg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709576542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a lot of files I want to archive eventually, and seeing how you can pay very little for LTO tape disks for a lot of storage, I&amp;#39;m considering trying it out. What reader/tapes should I get? My budget is pretty high, and this is solely for archival purposes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6i3kg", "is_robot_indexable": true, "report_reasons": null, "author": "meemkade", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6i3kg/how_do_i_get_started_to_tape_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6i3kg/how_do_i_get_started_to_tape_drives/", "subreddit_subscribers": 736125, "created_utc": 1709576542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nAfter having refined my processes for checking for fake disks, I wanted to share my process.\n\n**BEFORE BEGINNING** most of these tests can be destructive, particularly for capacity tests. This means you *may* lose any data already on the flash drive. Make a backup of any files you wish to keep or an image of the drive prior to starting any tests. This guide is best-suited for new drives recently-purchased to ensure they meet expectations.\n\nAlso, I hope this goes without saying, but don't use the disk or otherwise cause any reads/writes with another program during testing...\n\n# Ensuring Your Rig is Isn't Bottlenecked\n\nPrior to running tests, you need to make sure you don't have any bottlenecks preventing speed transfers (e.g., USB 2.0 somewhere preventing optimal transfers).\n\nTo do this, click the Apple icon at the top-left of the screen and choose **About this Mac:**\n\n[Select \\\\\"About This Mac\\\\\" from the Apple main menu](https://preview.redd.it/z9na0hb0l6mc1.png?width=564&amp;format=png&amp;auto=webp&amp;s=fabf1e7f2d23454b026f95e7be1af16467187bcc)\n\nIn the **About** modal that appears, choose the **More Info...** button.\n\n&amp;#x200B;\n\n[Click the \\\\\"More Info...\\\\\" button.](https://preview.redd.it/bds1fgfcl6mc1.png?width=560&amp;format=png&amp;auto=webp&amp;s=0e9d18885a466f108e5551450df2a8a53ac5b5e3)\n\nAt the bottom of the Preferences pane that appears, click **System Report**:\n\n[Click the \\\\\"System Report...\\\\\" button at the bottom of this page.](https://preview.redd.it/m1fiehogl6mc1.png?width=658&amp;format=png&amp;auto=webp&amp;s=c3f26d9c7451778693a7baddde5e9a0c84fd8709)\n\nIn the System Report pane, choose **USB** from the left and navigate to your selected drive:\n\n[Ensure your \\\\\"Speed\\\\\" doesn't bottleneck your disk through any of the USB hubs. Notice the SanDisk disk is USB 3.2, but the parent USB 3.1 Bus may further-limit speeds.](https://preview.redd.it/roleuofxr6mc1.png?width=1396&amp;format=png&amp;auto=webp&amp;s=474db6bef0dd7ab27fede361d7740059d6a0579a)\n\nWhat you want to look for here are any devices in the USB chain (including all parent hubs, connection points, etc - all the way up) that limit the USB speeds. You can see this as **Up to 5 Gb/s** in my example above. If you see something that is slower than your drive is capable of, you may have a part of your chain limited to USB 2.0 or similar and need to find a better adapter.\n\n*Don't skip this step!* You may think you have a USB 3.2 5Gb/s drive when it is actually limited to 400MB/s or less. You need to check every link in the chain before running a test.\n\n# Read and Write Speed Stress Testing\n\n&gt;**Note** \\- if you are also testing capacity, the section, below will also provide read- and write-speeds; however, capacity tests take significantly longer to complete. This section is useful if you are *only* looking to stress test a drive relatively-quickly. If you plan on testing capacity, as well as transfer speeds, you can likely skip this section.\n\nNearly all disks have caches wherein simply writing a 1GB file to and fro will give unrealistic speeds. Additionally, most manufacturers only list their read speeds, as they are often an order of magnitude faster than write transfers. That's where a realism-test is important.\n\nAt time of writing, the best, free utility for this is the [BlackMagic Disk Utility](https://apps.apple.com/us/app/blackmagic-disk-speed-test/id425264550?mt=12), which is intended for stress-testing media for high-throughput video. This is freeware, and BlackMagic is a well-respected company with great software. As BlackMagic specifically caters to high-end video processing customers, this utility is specifically designed to stress-test drives in realistic environments that will bypass many cache scenarios.\n\nI recommend running their default **5GB** test - that is, you don't need to do anything other than select your correct drive and run the test. Simply choose your disk (Click the **Gear** icon **Select Target Drive...**) under the `/Volumes` directory and press **Start**. Occasionally, for new drives, I've found that the first test, for whatever reason, is often a bit slower than subsequent tests that more-accurately represent the read- and write-speeds of the disk. I generally let it repeat the test 2-3 times to get a realistic result. The test will repeat over and over until you click the **Start** button, again:\n\n[A very-expected result for a USB 3.2 basic SanDisk \\\\\"Up to 400MB\\/s\\\\\" flash key.](https://preview.redd.it/qc966z0zn6mc1.png?width=1392&amp;format=png&amp;auto=webp&amp;s=3b970b8d07f518aa9839c179e66cedac1e835159)\n\nThe lower portion of the results really only apply to video producers. The read and write speed are of note for this disk testing.\n\n# Capacity Testing\n\nWhile speeds can be faked, capacity is almost always the area of concern for most phony drives. Fake drives will report they have larger capacity than they actually do and perform one of two actions when you try to write more than what they physically can contain:\n\n1. They will simply \"drop\" the data you write to it past a certain point, and simply not tell you\n2. They will \"loop around\" and start overwriting data at the front of the disk, also without telling you\n\nEither way, the result is corrupted or missing data on the disk. We will use a tool called `f3` to check for both of these. You will need to be comfortable using the macOS terminal for the remainder of this guide.\n\n&amp;#x200B;\n\n&gt;**Note** \\- if you will be testing a large number of drives, or are otherwise Linux-savvy, comfortable with configuring and using Docker, and seeking a more efficient, advanced approach, I recommend reading up on how to use [`f3probe`](https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html) in a Docker container on the targeted device.  Unfortunately, this tool is not available as part of the macOS f3 package.\n&gt;  \n&gt;Take note, however, that the Docker Machine used by macOS is part of a virtual machine that cannot have host devices attached to it, so it takes some [advanced configuration](https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#drive-permissions-passthrough) via VirtualBox (or another VM provider) to make this work. While this is a much more efficient test, it also is best-suited for more-advanced users and will not be covered in this guide.\n\n&amp;#x200B;\n\nFor the sake of completeness, I highly recommend completely [erasing and reformatting](https://support.apple.com/guide/disk-utility/erase-and-reformat-a-storage-device-dskutl14079/mac) your disk prior to starting an **f3** test. Use whatever filesystem type you expect to use on the disk in real life. A simple erase is more than sufficient.\n\nThe way **f3** works is to fill the drive with data and then read that data back and test it for various failure modes for fake disks. This can take some time, depending on the write/read speeds of your device and the size of the drive, but is very thorough.\n\nThe easiest way to install **f3** is via Homebrew, but there are [other methods](https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#compile-stable-software-on-apple-mac) if you do not have Homebrew installed:\n\n    ~ $ brew install f3\n\nThis will install the **f3write** and **f3read** tools we will use to write and read data to and from the disk.\n\nTo start the test, navigate to the mounted Volume and run **f3write**, which will fill the drive with 1GB files of a particular, checkable format:\n\n    ~ $ cd /Volumes/TestDisk\n    \n    /Volumes/TestDisk $ f3write ./\n    \n    F3 write 8.0\n    Copyright (C) 2010 Digirati Internet LTDA.\n    This is free software; see the source for copying conditions.\n    \n    Free space: 116.55 GB\n    Creating file 1.h2w ... OK!\n    Creating file 2.h2w ... OK!\n    Creating file 3.h2w ... OK!\n    Creating file 4.h2w ... OK!\n    Creating file 5.h2w ... OK!\n    \n    ...\n    \n    Creating file 115.h2w ... OK!\n    Creating file 116.h2w ... OK!\n    Creating file 117.h2w ... OK!\n    Free space: 1.62 MB\n    Average writing speed: 82.57 MB/s\n    \n    /Volumes/TestDisk $\n\nFor the 128GB USB 3.2 disk I showed above, because of \\~90MB/s write speeds, this took about 20-25 minutes. Also note that I realized \\~90MB/s in this utility because the files were smaller, while 5GB \"stress\" files above limited speeds to \\~65MB/s. This is where both utilities can be useful, depending on the types of writes you will be making to your disk\n\nUltimately, this will write a number of files **\\*.h2w** files to the disk that we will then verify with the **f3read** utility, which should run much more quickly for most disks:\n\n    /Volumes/TestDisk $ f3read ./\n    F3 read 8.0\n    Copyright (C) 2010 Digirati Internet LTDA.\n    This is free software; see the source for copying conditions.\n    \n                      SECTORS      ok/corrupted/changed/overwritten\n    Validating file 1.h2w ... 2097152/        0/      0/      0\n    Validating file 2.h2w ... 2097152/        0/      0/      0\n    Validating file 3.h2w ... 2097152/        0/      0/      0\n    Validating file 4.h2w ... 2097152/        0/      0/      0\n    Validating file 5.h2w ... 2097152/        0/      0/      0\n    \n    ...\n    \n    Validating file 115.h2w ... 2097152/        0/      0/      0\n    Validating file 116.h2w ... 2097152/        0/      0/      0\n    Validating file 117.h2w ... 1112633/        0/      0/      0\n    \n      Data OK: 116.53 GB (244382265 sectors)\n    Data LOST: 0.00 Byte (0 sectors)\n    \t       Corrupted: 0.00 Byte (0 sectors)\n    \tSlightly changed: 0.00 Byte (0 sectors)\n    \t     Overwritten: 0.00 Byte (0 sectors)\n    Average reading speed: 290.67 MB/s\n    \n    /Volumes/TestDisk $\n\nIf your disk is healthy and accurate, you should receive no overwrite or missing errors. If **f3read** shows any problems, you likely have a fake disk.\n\nUnfortunately, I do not have any phony drives to show what a fake result would look like; but, if you happen to run across one, please add what the **f3read** output looks like in the comments!\n\nBest of luck, and may the odds be ever in your favor.", "author_fullname": "t2_43498", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guide for Identifying Fake Flash Disks (macOS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z9na0hb0l6mc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 94, "x": 108, "u": "https://preview.redd.it/z9na0hb0l6mc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae0a1e59adbec233383c47327bdc17e2ed5039f1"}, {"y": 189, "x": 216, "u": "https://preview.redd.it/z9na0hb0l6mc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d6731b59db0abac9055f11fcbb759b37bd079b0"}, {"y": 280, "x": 320, "u": "https://preview.redd.it/z9na0hb0l6mc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7128aa5132a51f4cc9f969957eabb13b9eb1ce10"}], "s": {"y": 494, "x": 564, "u": "https://preview.redd.it/z9na0hb0l6mc1.png?width=564&amp;format=png&amp;auto=webp&amp;s=fabf1e7f2d23454b026f95e7be1af16467187bcc"}, "id": "z9na0hb0l6mc1"}, "m1fiehogl6mc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/m1fiehogl6mc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d7d34cd6072e10989ba3d0b126ad48dfab0c6f0"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/m1fiehogl6mc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=25b47a974bc41a4d554b7e16cca83d4b809cef5f"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/m1fiehogl6mc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=803b2223f96dd7fe0d28078942eb8b57fd6f2847"}, {"y": 215, "x": 640, "u": "https://preview.redd.it/m1fiehogl6mc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=02109d91582fac999f01b615beb87eb1afafe08d"}], "s": {"y": 222, "x": 658, "u": "https://preview.redd.it/m1fiehogl6mc1.png?width=658&amp;format=png&amp;auto=webp&amp;s=c3f26d9c7451778693a7baddde5e9a0c84fd8709"}, "id": "m1fiehogl6mc1"}, "bds1fgfcl6mc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/bds1fgfcl6mc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b98892396ce03ef4059a7b59375c1b6702b695f2"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/bds1fgfcl6mc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=edb37737490a2844c4889f50a194e75cda1775ce"}, {"y": 570, "x": 320, "u": "https://preview.redd.it/bds1fgfcl6mc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=38483f41dcc041fdfe72d7cdc44b5a0b27da904d"}], "s": {"y": 998, "x": 560, "u": "https://preview.redd.it/bds1fgfcl6mc1.png?width=560&amp;format=png&amp;auto=webp&amp;s=0e9d18885a466f108e5551450df2a8a53ac5b5e3"}, "id": "bds1fgfcl6mc1"}, "roleuofxr6mc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 100, "x": 108, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=36adf51e70159ca006e2be20e4de17f585a10b85"}, {"y": 201, "x": 216, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a07720da49f8d08c8442b1795cf1fbef83432bc"}, {"y": 298, "x": 320, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3fe8d4b525d07786419cecd5a43c17a3083b476"}, {"y": 597, "x": 640, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc921de21711072593ad8a42ccc05e2756e881ef"}, {"y": 896, "x": 960, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=91fecc299752ba5ec5a8547280339a7b3aa46b59"}, {"y": 1008, "x": 1080, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=71dfbd275cc5d946fe3b148990143a427e3d5d3e"}], "s": {"y": 1304, "x": 1396, "u": "https://preview.redd.it/roleuofxr6mc1.png?width=1396&amp;format=png&amp;auto=webp&amp;s=474db6bef0dd7ab27fede361d7740059d6a0579a"}, "id": "roleuofxr6mc1"}, "qc966z0zn6mc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 111, "x": 108, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=873ab675e0ac7ce0042fa903dded2c098ef54a46"}, {"y": 223, "x": 216, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=241c51195b9aafa22df682356a4a169981c83713"}, {"y": 330, "x": 320, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=303e33de9e1119d7a57c0a3b80e13c47cb72b6da"}, {"y": 661, "x": 640, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=03ffb28e42c761683d05474fc3f3c2c7e6391387"}, {"y": 991, "x": 960, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f09822da8db7e96308e2ab7ec9c3b86dba9e013b"}, {"y": 1115, "x": 1080, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69651ac5c010b8aa0b14b1c30d237aaccff0e863"}], "s": {"y": 1438, "x": 1392, "u": "https://preview.redd.it/qc966z0zn6mc1.png?width=1392&amp;format=png&amp;auto=webp&amp;s=3b970b8d07f518aa9839c179e66cedac1e835159"}, "id": "qc966z0zn6mc1"}}, "name": "t3_1b5t837", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wkYBw_eVdFrFKUohAW3AhZfmWQPRj49mG4-tMvQ7Bbk.jpg", "edited": 1709509329.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709502813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;After having refined my processes for checking for fake disks, I wanted to share my process.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;BEFORE BEGINNING&lt;/strong&gt; most of these tests can be destructive, particularly for capacity tests. This means you &lt;em&gt;may&lt;/em&gt; lose any data already on the flash drive. Make a backup of any files you wish to keep or an image of the drive prior to starting any tests. This guide is best-suited for new drives recently-purchased to ensure they meet expectations.&lt;/p&gt;\n\n&lt;p&gt;Also, I hope this goes without saying, but don&amp;#39;t use the disk or otherwise cause any reads/writes with another program during testing...&lt;/p&gt;\n\n&lt;h1&gt;Ensuring Your Rig is Isn&amp;#39;t Bottlenecked&lt;/h1&gt;\n\n&lt;p&gt;Prior to running tests, you need to make sure you don&amp;#39;t have any bottlenecks preventing speed transfers (e.g., USB 2.0 somewhere preventing optimal transfers).&lt;/p&gt;\n\n&lt;p&gt;To do this, click the Apple icon at the top-left of the screen and choose &lt;strong&gt;About this Mac:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z9na0hb0l6mc1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fabf1e7f2d23454b026f95e7be1af16467187bcc\"&gt;Select \\&amp;quot;About This Mac\\&amp;quot; from the Apple main menu&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In the &lt;strong&gt;About&lt;/strong&gt; modal that appears, choose the &lt;strong&gt;More Info...&lt;/strong&gt; button.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bds1fgfcl6mc1.png?width=560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e9d18885a466f108e5551450df2a8a53ac5b5e3\"&gt;Click the \\&amp;quot;More Info...\\&amp;quot; button.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;At the bottom of the Preferences pane that appears, click &lt;strong&gt;System Report&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m1fiehogl6mc1.png?width=658&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c3f26d9c7451778693a7baddde5e9a0c84fd8709\"&gt;Click the \\&amp;quot;System Report...\\&amp;quot; button at the bottom of this page.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In the System Report pane, choose &lt;strong&gt;USB&lt;/strong&gt; from the left and navigate to your selected drive:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/roleuofxr6mc1.png?width=1396&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=474db6bef0dd7ab27fede361d7740059d6a0579a\"&gt;Ensure your \\&amp;quot;Speed\\&amp;quot; doesn&amp;#39;t bottleneck your disk through any of the USB hubs. Notice the SanDisk disk is USB 3.2, but the parent USB 3.1 Bus may further-limit speeds.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What you want to look for here are any devices in the USB chain (including all parent hubs, connection points, etc - all the way up) that limit the USB speeds. You can see this as &lt;strong&gt;Up to 5 Gb/s&lt;/strong&gt; in my example above. If you see something that is slower than your drive is capable of, you may have a part of your chain limited to USB 2.0 or similar and need to find a better adapter.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Don&amp;#39;t skip this step!&lt;/em&gt; You may think you have a USB 3.2 5Gb/s drive when it is actually limited to 400MB/s or less. You need to check every link in the chain before running a test.&lt;/p&gt;\n\n&lt;h1&gt;Read and Write Speed Stress Testing&lt;/h1&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; - if you are also testing capacity, the section, below will also provide read- and write-speeds; however, capacity tests take significantly longer to complete. This section is useful if you are &lt;em&gt;only&lt;/em&gt; looking to stress test a drive relatively-quickly. If you plan on testing capacity, as well as transfer speeds, you can likely skip this section.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Nearly all disks have caches wherein simply writing a 1GB file to and fro will give unrealistic speeds. Additionally, most manufacturers only list their read speeds, as they are often an order of magnitude faster than write transfers. That&amp;#39;s where a realism-test is important.&lt;/p&gt;\n\n&lt;p&gt;At time of writing, the best, free utility for this is the &lt;a href=\"https://apps.apple.com/us/app/blackmagic-disk-speed-test/id425264550?mt=12\"&gt;BlackMagic Disk Utility&lt;/a&gt;, which is intended for stress-testing media for high-throughput video. This is freeware, and BlackMagic is a well-respected company with great software. As BlackMagic specifically caters to high-end video processing customers, this utility is specifically designed to stress-test drives in realistic environments that will bypass many cache scenarios.&lt;/p&gt;\n\n&lt;p&gt;I recommend running their default &lt;strong&gt;5GB&lt;/strong&gt; test - that is, you don&amp;#39;t need to do anything other than select your correct drive and run the test. Simply choose your disk (Click the &lt;strong&gt;Gear&lt;/strong&gt; icon &lt;strong&gt;Select Target Drive...&lt;/strong&gt;) under the &lt;code&gt;/Volumes&lt;/code&gt; directory and press &lt;strong&gt;Start&lt;/strong&gt;. Occasionally, for new drives, I&amp;#39;ve found that the first test, for whatever reason, is often a bit slower than subsequent tests that more-accurately represent the read- and write-speeds of the disk. I generally let it repeat the test 2-3 times to get a realistic result. The test will repeat over and over until you click the &lt;strong&gt;Start&lt;/strong&gt; button, again:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qc966z0zn6mc1.png?width=1392&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3b970b8d07f518aa9839c179e66cedac1e835159\"&gt;A very-expected result for a USB 3.2 basic SanDisk \\&amp;quot;Up to 400MB/s\\&amp;quot; flash key.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The lower portion of the results really only apply to video producers. The read and write speed are of note for this disk testing.&lt;/p&gt;\n\n&lt;h1&gt;Capacity Testing&lt;/h1&gt;\n\n&lt;p&gt;While speeds can be faked, capacity is almost always the area of concern for most phony drives. Fake drives will report they have larger capacity than they actually do and perform one of two actions when you try to write more than what they physically can contain:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;They will simply &amp;quot;drop&amp;quot; the data you write to it past a certain point, and simply not tell you&lt;/li&gt;\n&lt;li&gt;They will &amp;quot;loop around&amp;quot; and start overwriting data at the front of the disk, also without telling you&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Either way, the result is corrupted or missing data on the disk. We will use a tool called &lt;code&gt;f3&lt;/code&gt; to check for both of these. You will need to be comfortable using the macOS terminal for the remainder of this guide.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; - if you will be testing a large number of drives, or are otherwise Linux-savvy, comfortable with configuring and using Docker, and seeking a more efficient, advanced approach, I recommend reading up on how to use &lt;a href=\"https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html\"&gt;&lt;code&gt;f3probe&lt;/code&gt;&lt;/a&gt; in a Docker container on the targeted device.  Unfortunately, this tool is not available as part of the macOS f3 package.&lt;/p&gt;\n\n&lt;p&gt;Take note, however, that the Docker Machine used by macOS is part of a virtual machine that cannot have host devices attached to it, so it takes some &lt;a href=\"https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#drive-permissions-passthrough\"&gt;advanced configuration&lt;/a&gt; via VirtualBox (or another VM provider) to make this work. While this is a much more efficient test, it also is best-suited for more-advanced users and will not be covered in this guide.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For the sake of completeness, I highly recommend completely &lt;a href=\"https://support.apple.com/guide/disk-utility/erase-and-reformat-a-storage-device-dskutl14079/mac\"&gt;erasing and reformatting&lt;/a&gt; your disk prior to starting an &lt;strong&gt;f3&lt;/strong&gt; test. Use whatever filesystem type you expect to use on the disk in real life. A simple erase is more than sufficient.&lt;/p&gt;\n\n&lt;p&gt;The way &lt;strong&gt;f3&lt;/strong&gt; works is to fill the drive with data and then read that data back and test it for various failure modes for fake disks. This can take some time, depending on the write/read speeds of your device and the size of the drive, but is very thorough.&lt;/p&gt;\n\n&lt;p&gt;The easiest way to install &lt;strong&gt;f3&lt;/strong&gt; is via Homebrew, but there are &lt;a href=\"https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#compile-stable-software-on-apple-mac\"&gt;other methods&lt;/a&gt; if you do not have Homebrew installed:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;~ $ brew install f3\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This will install the &lt;strong&gt;f3write&lt;/strong&gt; and &lt;strong&gt;f3read&lt;/strong&gt; tools we will use to write and read data to and from the disk.&lt;/p&gt;\n\n&lt;p&gt;To start the test, navigate to the mounted Volume and run &lt;strong&gt;f3write&lt;/strong&gt;, which will fill the drive with 1GB files of a particular, checkable format:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;~ $ cd /Volumes/TestDisk\n\n/Volumes/TestDisk $ f3write ./\n\nF3 write 8.0\nCopyright (C) 2010 Digirati Internet LTDA.\nThis is free software; see the source for copying conditions.\n\nFree space: 116.55 GB\nCreating file 1.h2w ... OK!\nCreating file 2.h2w ... OK!\nCreating file 3.h2w ... OK!\nCreating file 4.h2w ... OK!\nCreating file 5.h2w ... OK!\n\n...\n\nCreating file 115.h2w ... OK!\nCreating file 116.h2w ... OK!\nCreating file 117.h2w ... OK!\nFree space: 1.62 MB\nAverage writing speed: 82.57 MB/s\n\n/Volumes/TestDisk $\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;For the 128GB USB 3.2 disk I showed above, because of ~90MB/s write speeds, this took about 20-25 minutes. Also note that I realized ~90MB/s in this utility because the files were smaller, while 5GB &amp;quot;stress&amp;quot; files above limited speeds to ~65MB/s. This is where both utilities can be useful, depending on the types of writes you will be making to your disk&lt;/p&gt;\n\n&lt;p&gt;Ultimately, this will write a number of files &lt;strong&gt;*.h2w&lt;/strong&gt; files to the disk that we will then verify with the &lt;strong&gt;f3read&lt;/strong&gt; utility, which should run much more quickly for most disks:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;/Volumes/TestDisk $ f3read ./\nF3 read 8.0\nCopyright (C) 2010 Digirati Internet LTDA.\nThis is free software; see the source for copying conditions.\n\n                  SECTORS      ok/corrupted/changed/overwritten\nValidating file 1.h2w ... 2097152/        0/      0/      0\nValidating file 2.h2w ... 2097152/        0/      0/      0\nValidating file 3.h2w ... 2097152/        0/      0/      0\nValidating file 4.h2w ... 2097152/        0/      0/      0\nValidating file 5.h2w ... 2097152/        0/      0/      0\n\n...\n\nValidating file 115.h2w ... 2097152/        0/      0/      0\nValidating file 116.h2w ... 2097152/        0/      0/      0\nValidating file 117.h2w ... 1112633/        0/      0/      0\n\n  Data OK: 116.53 GB (244382265 sectors)\nData LOST: 0.00 Byte (0 sectors)\n           Corrupted: 0.00 Byte (0 sectors)\n    Slightly changed: 0.00 Byte (0 sectors)\n         Overwritten: 0.00 Byte (0 sectors)\nAverage reading speed: 290.67 MB/s\n\n/Volumes/TestDisk $\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If your disk is healthy and accurate, you should receive no overwrite or missing errors. If &lt;strong&gt;f3read&lt;/strong&gt; shows any problems, you likely have a fake disk.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, I do not have any phony drives to show what a fake result would look like; but, if you happen to run across one, please add what the &lt;strong&gt;f3read&lt;/strong&gt; output looks like in the comments!&lt;/p&gt;\n\n&lt;p&gt;Best of luck, and may the odds be ever in your favor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kxUUUE6yFOZUUeJMRYvL5J3lNsSD4lg4-7kOBzMapgU.jpg?auto=webp&amp;s=08e4a0ea5b11bcb3b8e3f2b57418a07b096e685c", "width": 630, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/kxUUUE6yFOZUUeJMRYvL5J3lNsSD4lg4-7kOBzMapgU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae93335b6ef642e6a3cc45abb75dc1b6b9a2d8ca", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/kxUUUE6yFOZUUeJMRYvL5J3lNsSD4lg4-7kOBzMapgU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92dd1fad255e0a44d74ef7209b1500b172cc1113", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/kxUUUE6yFOZUUeJMRYvL5J3lNsSD4lg4-7kOBzMapgU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=566be2cd4386c8f8197517c5be60f6067eff1e1a", "width": 320, "height": 320}], "variants": {}, "id": "UFT3rIqq282EOrZLQX8F9hWeb8DaXYU6jmDc7DmwgRI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b5t837", "is_robot_indexable": true, "report_reasons": null, "author": "wspnut", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b5t837/guide_for_identifying_fake_flash_disks_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b5t837/guide_for_identifying_fake_flash_disks_macos/", "subreddit_subscribers": 736125, "created_utc": 1709502813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I mostly hoard stuff that i created or things that can be erased by just 1 person. I recently downloaded a whole youtube channel with 1000+ videos since i loved to watch that channel ever since i was a kid. Sure the most popular videos would get reuploaded, but if that person running that channel decided to erase every video, most of it would be gone forever. Now my question:\n\nWhy do you hoard *popular* media? Why download Dune (2021), when that movie will presumably always be available (At least in our life times)? Why hoard anything that isn't unknown or really niche? Why do some people run plex servers with hundreds of TB's and even back that up... . You could view the same torrent you downloaded with a debrid service for example, but wouldn't need to pay for the space nor maintain it, so why? Christopher Nolan movies will always be found in the best quality, so why bother \"wasting\" space on them?\n\nI am asking out of genuine curiosity. I just see money spent on drives upon drives for media that isn't meaningful to you. Isn't in danger of getting lost, isn't \"worth\" the time and money spent on keeping it. So why?\n\n**Edit:** 2 hours into answering most comments i have an answer, that answer being... \"because i can\". I still didn't see any logical reason for the scenarios i listed, so its really just a thing people like to do, whether its logical or not, i respect that. I am going to retire from the comment section i think, i invite you though to glimpse at the discussions down below, i for one enjoyed them. Have fun folks :D", "author_fullname": "t2_kht4ovrc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do you hoard media?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b6k7zz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709588091.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709581649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mostly hoard stuff that i created or things that can be erased by just 1 person. I recently downloaded a whole youtube channel with 1000+ videos since i loved to watch that channel ever since i was a kid. Sure the most popular videos would get reuploaded, but if that person running that channel decided to erase every video, most of it would be gone forever. Now my question:&lt;/p&gt;\n\n&lt;p&gt;Why do you hoard &lt;em&gt;popular&lt;/em&gt; media? Why download Dune (2021), when that movie will presumably always be available (At least in our life times)? Why hoard anything that isn&amp;#39;t unknown or really niche? Why do some people run plex servers with hundreds of TB&amp;#39;s and even back that up... . You could view the same torrent you downloaded with a debrid service for example, but wouldn&amp;#39;t need to pay for the space nor maintain it, so why? Christopher Nolan movies will always be found in the best quality, so why bother &amp;quot;wasting&amp;quot; space on them?&lt;/p&gt;\n\n&lt;p&gt;I am asking out of genuine curiosity. I just see money spent on drives upon drives for media that isn&amp;#39;t meaningful to you. Isn&amp;#39;t in danger of getting lost, isn&amp;#39;t &amp;quot;worth&amp;quot; the time and money spent on keeping it. So why?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; 2 hours into answering most comments i have an answer, that answer being... &amp;quot;because i can&amp;quot;. I still didn&amp;#39;t see any logical reason for the scenarios i listed, so its really just a thing people like to do, whether its logical or not, i respect that. I am going to retire from the comment section i think, i invite you though to glimpse at the discussions down below, i for one enjoyed them. Have fun folks :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6k7zz", "is_robot_indexable": true, "report_reasons": null, "author": "TengokuDaimakyo", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6k7zz/why_do_you_hoard_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6k7zz/why_do_you_hoard_media/", "subreddit_subscribers": 736125, "created_utc": 1709581649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently my Plex library sits on a measly total of 4 TB, with 1 TB in my PC HDD, another TB in an external HDD and the rest 2 TB in the cloud. I now want to centralize all this data to one place and I've also realized that 4 TB will **not** suffice if I want to expand my library.\n\nFor this, I'm looking to get two 8 TB drives for the time being, one as the main storage and the other for backup, and set them up in a dual bay enclosure. Once I hit the 8 TB limit, I plan to get another dual bay with two more 8 TB drives, and I'll then separate my main storage and backup storage (both of 16 TB chunks) into separate bays. Before I even move to product recommendations.... is my plan of how I want to expand stupid? I'm taking a pretty simple-minded approach to this, so please tell me if there are better and/or more effective/efficient way of doing this.\n\nNow for product recommendations, these are the ones I chose. The enclosure is nice and cheap and it's just under $100, which is my budget for the enclosure. The drives are also quite cheap and just under $200 each. Do let me know if there are better alternatives, as long as the price is near my mentioned budget ($500 in total), or if you have any experience/review on these products:\n\nHDD: [Western Digital WD60PURZ 8TB 3.5\" Purple Hard Disk](https://www.techlandbd.com/western-digital-8tb-hdd)  \nEnclosure: [ORICO NS200C3 3.5 inch 2 Bay Type-C Hard Drive Enclosure](https://www.startech.com.bd/orico-ns200c3-2-bay-type-c-hard-drive-enclosure)\n\nAlso tell me if the enclosure I've chosen is overkill and if I could do away with something cheaper for my use case. Looking forward to your feedback!", "author_fullname": "t2_k77hz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stepping into the world of data hoarding, need advice on which hard drive enclosure to get!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b67en3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709547135.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709546880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently my Plex library sits on a measly total of 4 TB, with 1 TB in my PC HDD, another TB in an external HDD and the rest 2 TB in the cloud. I now want to centralize all this data to one place and I&amp;#39;ve also realized that 4 TB will &lt;strong&gt;not&lt;/strong&gt; suffice if I want to expand my library.&lt;/p&gt;\n\n&lt;p&gt;For this, I&amp;#39;m looking to get two 8 TB drives for the time being, one as the main storage and the other for backup, and set them up in a dual bay enclosure. Once I hit the 8 TB limit, I plan to get another dual bay with two more 8 TB drives, and I&amp;#39;ll then separate my main storage and backup storage (both of 16 TB chunks) into separate bays. Before I even move to product recommendations.... is my plan of how I want to expand stupid? I&amp;#39;m taking a pretty simple-minded approach to this, so please tell me if there are better and/or more effective/efficient way of doing this.&lt;/p&gt;\n\n&lt;p&gt;Now for product recommendations, these are the ones I chose. The enclosure is nice and cheap and it&amp;#39;s just under $100, which is my budget for the enclosure. The drives are also quite cheap and just under $200 each. Do let me know if there are better alternatives, as long as the price is near my mentioned budget ($500 in total), or if you have any experience/review on these products:&lt;/p&gt;\n\n&lt;p&gt;HDD: &lt;a href=\"https://www.techlandbd.com/western-digital-8tb-hdd\"&gt;Western Digital WD60PURZ 8TB 3.5&amp;quot; Purple Hard Disk&lt;/a&gt;&lt;br/&gt;\nEnclosure: &lt;a href=\"https://www.startech.com.bd/orico-ns200c3-2-bay-type-c-hard-drive-enclosure\"&gt;ORICO NS200C3 3.5 inch 2 Bay Type-C Hard Drive Enclosure&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also tell me if the enclosure I&amp;#39;ve chosen is overkill and if I could do away with something cheaper for my use case. Looking forward to your feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Mwcllsd2gh8eNzswtCRvmEopQoLVSl800LfCzpY5sqc.jpg?auto=webp&amp;s=1e445ada6d56bff3d4408cee4232e0ffac29cc7d", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/Mwcllsd2gh8eNzswtCRvmEopQoLVSl800LfCzpY5sqc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4acccc7d044128c48bda17456ae5b48f203c28ba", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Mwcllsd2gh8eNzswtCRvmEopQoLVSl800LfCzpY5sqc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae04f808cd3a2a874dadb8e7cc1a1c334a3ac1e8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Mwcllsd2gh8eNzswtCRvmEopQoLVSl800LfCzpY5sqc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5bbfd9d66be68c70fb95f70856713660e1aefa98", "width": 320, "height": 168}], "variants": {}, "id": "UR5UErOOEmGg29ZfzRiEvbe4iBNosdtaw4qnojlJqdo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b67en3", "is_robot_indexable": true, "report_reasons": null, "author": "ninjapotato59", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b67en3/stepping_into_the_world_of_data_hoarding_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b67en3/stepping_into_the_world_of_data_hoarding_need/", "subreddit_subscribers": 736125, "created_utc": 1709546880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So logged into my unraid and was presented with this.. I'm guessing this Seagate 8TB drive is destined for the bin?  \nAlthough at the same time, a second 8TB Seagate drive popped up with 3x Reallocated Sector Counts.\n\n&amp;#x200B;\n\nIs it just a coincidence the've both had these errors? They're both about 5 years old or maybe more with a ton of hours.  \n\n\nHappy to replace them, just making sure that I don't have an external issue that needs rectification before I throw some new shiny drives in\n\nhttps://preview.redd.it/7o7ba1q459mc1.jpg?width=1945&amp;format=pjpg&amp;auto=webp&amp;s=94b19eefd73bbd58a82b506197421c2db5d60eb5", "author_fullname": "t2_7zq0yx1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UNRAID. All of a sudden have some SMART errors. Replace?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 47, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7o7ba1q459mc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ebb2a23b0cf273d82bc1c2bb13bd210d7f128bb"}, {"y": 73, "x": 216, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=003867fee7eef4b8a8f95d91b24908bd926157ed"}, {"y": 109, "x": 320, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c2f16c5667a8a1051baf98d232f562f89e4c21df"}, {"y": 219, "x": 640, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a4da1e2e7a70329d1b4bebeb6a30bcda484262d9"}, {"y": 328, "x": 960, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e74d3cbb9522a74edbe39a0992d90163de74c35"}, {"y": 369, "x": 1080, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa84d01bb792b2691d42e38c3791127847c483b7"}], "s": {"y": 666, "x": 1945, "u": "https://preview.redd.it/7o7ba1q459mc1.jpg?width=1945&amp;format=pjpg&amp;auto=webp&amp;s=94b19eefd73bbd58a82b506197421c2db5d60eb5"}, "id": "7o7ba1q459mc1"}}, "name": "t3_1b62wn2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nPAiR6qz254CU7fV-L_eIHl3Tqa_Sm7O4Dp5gEd_qO0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709529792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So logged into my unraid and was presented with this.. I&amp;#39;m guessing this Seagate 8TB drive is destined for the bin?&lt;br/&gt;\nAlthough at the same time, a second 8TB Seagate drive popped up with 3x Reallocated Sector Counts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is it just a coincidence the&amp;#39;ve both had these errors? They&amp;#39;re both about 5 years old or maybe more with a ton of hours.  &lt;/p&gt;\n\n&lt;p&gt;Happy to replace them, just making sure that I don&amp;#39;t have an external issue that needs rectification before I throw some new shiny drives in&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7o7ba1q459mc1.jpg?width=1945&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=94b19eefd73bbd58a82b506197421c2db5d60eb5\"&gt;https://preview.redd.it/7o7ba1q459mc1.jpg?width=1945&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=94b19eefd73bbd58a82b506197421c2db5d60eb5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b62wn2", "is_robot_indexable": true, "report_reasons": null, "author": "Few_Ad_1079", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b62wn2/unraid_all_of_a_sudden_have_some_smart_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b62wn2/unraid_all_of_a_sudden_have_some_smart_errors/", "subreddit_subscribers": 736125, "created_utc": 1709529792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 3.5 inch disks for backup with few TB's capacity. Im doing incremental backup with rsync to add new backup to it regularly and only read it for restore. Because it is long term backup and disk can be used for lot of years I need something very reliable.\n\nFor the source it is btrfs and I have never had problem with data loss like people have. For the backup it is ext4 but if there is some bits error I will never know and if I restore from it I will have corrupted file that I will not discover until maybe long time later. Should I change backup disk to btrfs?\n\nBtrfs source doesn't mean I have to use btrfs replication for backup to btrfs disk. If I am using rsync only for backup is it better from btrfs to ext4 like I do now or btrfs to btrfs?\n\nBtrfs in backup disk mean I can use scrub and if it pass I know nothing is corrupted which is very nice feature. With ext4 I never can know. Any disadvantage for using btrfs as backup?\n\nAny other file system to consider for this purpose? Maybe not Zfs because of licensing and Bcachefs because too new.", "author_fullname": "t2_uyolch9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ext4 or btrfs for backup disk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ha93", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709574611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3.5 inch disks for backup with few TB&amp;#39;s capacity. Im doing incremental backup with rsync to add new backup to it regularly and only read it for restore. Because it is long term backup and disk can be used for lot of years I need something very reliable.&lt;/p&gt;\n\n&lt;p&gt;For the source it is btrfs and I have never had problem with data loss like people have. For the backup it is ext4 but if there is some bits error I will never know and if I restore from it I will have corrupted file that I will not discover until maybe long time later. Should I change backup disk to btrfs?&lt;/p&gt;\n\n&lt;p&gt;Btrfs source doesn&amp;#39;t mean I have to use btrfs replication for backup to btrfs disk. If I am using rsync only for backup is it better from btrfs to ext4 like I do now or btrfs to btrfs?&lt;/p&gt;\n\n&lt;p&gt;Btrfs in backup disk mean I can use scrub and if it pass I know nothing is corrupted which is very nice feature. With ext4 I never can know. Any disadvantage for using btrfs as backup?&lt;/p&gt;\n\n&lt;p&gt;Any other file system to consider for this purpose? Maybe not Zfs because of licensing and Bcachefs because too new.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6ha93", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Log5632", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6ha93/ext4_or_btrfs_for_backup_disk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6ha93/ext4_or_btrfs_for_backup_disk/", "subreddit_subscribers": 736125, "created_utc": 1709574611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "l have a lenova thinkcentre m93p tiny i5 4570t 2.9ghz 8gb 128gb ssd, and 3x seagate barracuda 2TB hard drives, also a WD 3TB &amp; 2TB hard drives all gathering dust, was wondering the best use for these, was hoping to use as a jellyfin server, any advise on the good setup for these, O/S to use, TrueNAS, Ubuntu, connecting the drives, ect, ect. have seen Mediasonic Probox 4 bay hard drive enclosure &amp; Orico 5 bay hard drive USB 3.0 enclosures on amazon, would these be suitable for the drives, l already have a mycloud ex2 ultra with all my media and backup files on it so access to this with the build would be better as well,\n\nany idea's welcome, Cheers, Steve", "author_fullname": "t2_ot1i18fam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guide. best use of old pc, &amp; some old hard drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6f4ms", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709571215.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709569561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;l have a lenova thinkcentre m93p tiny i5 4570t 2.9ghz 8gb 128gb ssd, and 3x seagate barracuda 2TB hard drives, also a WD 3TB &amp;amp; 2TB hard drives all gathering dust, was wondering the best use for these, was hoping to use as a jellyfin server, any advise on the good setup for these, O/S to use, TrueNAS, Ubuntu, connecting the drives, ect, ect. have seen Mediasonic Probox 4 bay hard drive enclosure &amp;amp; Orico 5 bay hard drive USB 3.0 enclosures on amazon, would these be suitable for the drives, l already have a mycloud ex2 ultra with all my media and backup files on it so access to this with the build would be better as well,&lt;/p&gt;\n\n&lt;p&gt;any idea&amp;#39;s welcome, Cheers, Steve&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6f4ms", "is_robot_indexable": true, "report_reasons": null, "author": "GetsKilledAlot2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6f4ms/guide_best_use_of_old_pc_some_old_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6f4ms/guide_best_use_of_old_pc_some_old_hard_drives/", "subreddit_subscribers": 736125, "created_utc": 1709569561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Right now, I always leave the HDD plugged into the wall and attached to my pc. I\u2019m wondering if this is the best practice. Should I be unplugging the power from the wall before/after I shut my computer off or ejecting it before shutting my computer off or is it fine to just shut off the pc while not doing anything to the HDD? Thanks for the advice!", "author_fullname": "t2_3o9ul6ln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I leave an external HDD plugged in my PC 24/7?  I have a 18TB WD External HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6cltb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709564546.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709563507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now, I always leave the HDD plugged into the wall and attached to my pc. I\u2019m wondering if this is the best practice. Should I be unplugging the power from the wall before/after I shut my computer off or ejecting it before shutting my computer off or is it fine to just shut off the pc while not doing anything to the HDD? Thanks for the advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6cltb", "is_robot_indexable": true, "report_reasons": null, "author": "Piepop101", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6cltb/can_i_leave_an_external_hdd_plugged_in_my_pc_247/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6cltb/can_i_leave_an_external_hdd_plugged_in_my_pc_247/", "subreddit_subscribers": 736125, "created_utc": 1709563507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So NordLocker basically says: you cannot upload anything that breaks any laws / you can't use our service to aid you in breaking the law. But what law is this exactly? Panama law, or the law wherever the user happens to be, or the law in the user's country of citizenship, or residence, or what? And also, do they actually check what you upload to see if it breaks the law / can they check? Wouldn't that break their privacy policy that says they don't have access to the data uploaded by user beyond anonimized technical data and such? Asking for a friend.\n\nSorry if this is not the place to ask this. ", "author_fullname": "t2_4ph2a7gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terms of use NordLocker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5wcnk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709510452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So NordLocker basically says: you cannot upload anything that breaks any laws / you can&amp;#39;t use our service to aid you in breaking the law. But what law is this exactly? Panama law, or the law wherever the user happens to be, or the law in the user&amp;#39;s country of citizenship, or residence, or what? And also, do they actually check what you upload to see if it breaks the law / can they check? Wouldn&amp;#39;t that break their privacy policy that says they don&amp;#39;t have access to the data uploaded by user beyond anonimized technical data and such? Asking for a friend.&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is not the place to ask this. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b5wcnk", "is_robot_indexable": true, "report_reasons": null, "author": "RunDiscombobulated67", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b5wcnk/terms_of_use_nordlocker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b5wcnk/terms_of_use_nordlocker/", "subreddit_subscribers": 736125, "created_utc": 1709510452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI have no idea how to to this.  \nI found a similiar post on this sub from a year ago, but the recommended ways like LG software do not seem to work/exist.\n\nI went through every folder on the SD card but to no avail.\n\nThanks in advance!", "author_fullname": "t2_n5er6xfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extract SMS from LG P500", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b6l85h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709584067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have no idea how to to this.&lt;br/&gt;\nI found a similiar post on this sub from a year ago, but the recommended ways like LG software do not seem to work/exist.&lt;/p&gt;\n\n&lt;p&gt;I went through every folder on the SD card but to no avail.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6l85h", "is_robot_indexable": true, "report_reasons": null, "author": "Empty-Occasion1337", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6l85h/extract_sms_from_lg_p500/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6l85h/extract_sms_from_lg_p500/", "subreddit_subscribers": 736125, "created_utc": 1709584067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve been doing research and for the life of me I can\u2019t figure out a good motherboard or way to build a system with at least 4 m.2 and also ability to have 10gbe.  \n\nWould love it even more if I could add an additional pci card for another 4 m.2 drives.  Size doesn\u2019t really matter, but smaller is better.  Want to use it for a router/nas.", "author_fullname": "t2_4dx55sw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheapest 4-5 m2 build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b6l3ye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709583785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been doing research and for the life of me I can\u2019t figure out a good motherboard or way to build a system with at least 4 m.2 and also ability to have 10gbe.  &lt;/p&gt;\n\n&lt;p&gt;Would love it even more if I could add an additional pci card for another 4 m.2 drives.  Size doesn\u2019t really matter, but smaller is better.  Want to use it for a router/nas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6l3ye", "is_robot_indexable": true, "report_reasons": null, "author": "PositiveEnergyMatter", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6l3ye/cheapest_45_m2_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6l3ye/cheapest_45_m2_build/", "subreddit_subscribers": 736125, "created_utc": 1709583785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two vdevs with 4x16TB WD RED PROs. I want to add 2 drives one to each vdev and rebuild it but using an HC550 drive from serverpartdeals as they\u2019re half the price. Is there any issue in doing so? All are the same size. I have 10 bays so want to take this opportunity to add some capacity while I rework some datasets and pools", "author_fullname": "t2_vsbo9omx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mixed HDD in ZFS of Same Size", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6jpfy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709580393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two vdevs with 4x16TB WD RED PROs. I want to add 2 drives one to each vdev and rebuild it but using an HC550 drive from serverpartdeals as they\u2019re half the price. Is there any issue in doing so? All are the same size. I have 10 bays so want to take this opportunity to add some capacity while I rework some datasets and pools&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6jpfy", "is_robot_indexable": true, "report_reasons": null, "author": "Kltpzyxmm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6jpfy/mixed_hdd_in_zfs_of_same_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6jpfy/mixed_hdd_in_zfs_of_same_size/", "subreddit_subscribers": 736125, "created_utc": 1709580393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I'm looking for recommendations for a dedicated scanner (needs to use TWAIN) as I typically scan about 30 pages a day. I have an older Epson ES200 scanner and I noticed it would sometimes take in two pages at once, so if there's one that would detect that so I don't have to worry about missing pages, that would be great.\n\nI came across NAPS2 that will allow me to scan and OCR at the same time which is perfect so I plan on using that software. Does anyone have any other recommendation to look at?  \n\n\nAfter the scanned documents (e.g. receipts) are saved as a PDF, I'd like to be able to search the pdfs without opening them for words or numbers. I came across Paperless-NGX but looks like that's for linux only.I'm on windows and the easier it is to use the better.\n\n&amp;#x200B;\n\nThanks!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_a3qeniqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for dedicated Scanner, OCR, and searching scanned documents", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6hayw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709576716.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709574654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m looking for recommendations for a dedicated scanner (needs to use TWAIN) as I typically scan about 30 pages a day. I have an older Epson ES200 scanner and I noticed it would sometimes take in two pages at once, so if there&amp;#39;s one that would detect that so I don&amp;#39;t have to worry about missing pages, that would be great.&lt;/p&gt;\n\n&lt;p&gt;I came across NAPS2 that will allow me to scan and OCR at the same time which is perfect so I plan on using that software. Does anyone have any other recommendation to look at?  &lt;/p&gt;\n\n&lt;p&gt;After the scanned documents (e.g. receipts) are saved as a PDF, I&amp;#39;d like to be able to search the pdfs without opening them for words or numbers. I came across Paperless-NGX but looks like that&amp;#39;s for linux only.I&amp;#39;m on windows and the easier it is to use the better.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6hayw", "is_robot_indexable": true, "report_reasons": null, "author": "humpty2019", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6hayw/recommendations_for_dedicated_scanner_ocr_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6hayw/recommendations_for_dedicated_scanner_ocr_and/", "subreddit_subscribers": 736125, "created_utc": 1709574654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi , I would like to know what\u2019s your opinion or experience with some HDD external dock ?\n\nRight now , I use a couple of external drives like the WD passport 5tb , WD easystore 14tb and other WD elements 14tb as part of my 321 backup. \n\nI would like to know if it\u2019s recommended to use something like that :\n\nOWC HDD dock USBC 3.2 Gen2 \nOr\nTerramaster D2-320 (raid1 mode )\nOr \n\nSome Orico and Sabrent dock ? \n\nThanks for your comments and advices. \n\n", "author_fullname": "t2_p67lkkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use HDD external dock as part of your 321 backup ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6h4by", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709574226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi , I would like to know what\u2019s your opinion or experience with some HDD external dock ?&lt;/p&gt;\n\n&lt;p&gt;Right now , I use a couple of external drives like the WD passport 5tb , WD easystore 14tb and other WD elements 14tb as part of my 321 backup. &lt;/p&gt;\n\n&lt;p&gt;I would like to know if it\u2019s recommended to use something like that :&lt;/p&gt;\n\n&lt;p&gt;OWC HDD dock USBC 3.2 Gen2 \nOr\nTerramaster D2-320 (raid1 mode )\nOr &lt;/p&gt;\n\n&lt;p&gt;Some Orico and Sabrent dock ? &lt;/p&gt;\n\n&lt;p&gt;Thanks for your comments and advices. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6h4by", "is_robot_indexable": true, "report_reasons": null, "author": "d2racing911", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6h4by/do_you_use_hdd_external_dock_as_part_of_your_321/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6h4by/do_you_use_hdd_external_dock_as_part_of_your_321/", "subreddit_subscribers": 736125, "created_utc": 1709574226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know nowadays of a good cross-platform disk catalog/search applications they could recommend?\n\nI have a bunch of spare drives with content over them. I mainly use them for long term archives and I regularly use them to get stuff out. They follow a specific logic but I still need to be able to know what content is on them. So I need a UI so I can browse and search content. No need for fancy metadata or thumbnails / previews.\n\nWe're talking about 50TB across 12 drives with mixed media content. I use Mac for work, Linux, Mac and Windows at home so crossplatform is a must (else I'd have Everything on Windows, Neofinder on a Mac for example).\n\nI\u2019ve tried VVV, but it sadly keeps crashing on a regular basis (too much files?). Thanks for any recommendations", "author_fullname": "t2_12etmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disk indexing Recommendations (FOSS, cross platform)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b69oya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709555169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know nowadays of a good cross-platform disk catalog/search applications they could recommend?&lt;/p&gt;\n\n&lt;p&gt;I have a bunch of spare drives with content over them. I mainly use them for long term archives and I regularly use them to get stuff out. They follow a specific logic but I still need to be able to know what content is on them. So I need a UI so I can browse and search content. No need for fancy metadata or thumbnails / previews.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re talking about 50TB across 12 drives with mixed media content. I use Mac for work, Linux, Mac and Windows at home so crossplatform is a must (else I&amp;#39;d have Everything on Windows, Neofinder on a Mac for example).&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried VVV, but it sadly keeps crashing on a regular basis (too much files?). Thanks for any recommendations&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b69oya", "is_robot_indexable": true, "report_reasons": null, "author": "I-need-a-proper-nick", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b69oya/disk_indexing_recommendations_foss_cross_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b69oya/disk_indexing_recommendations_foss_cross_platform/", "subreddit_subscribers": 736125, "created_utc": 1709555169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone,\n\nThis is my first post here, and I'm excited to share a project born out of my passion for movies and a desire for better video management. My wife and I, being film enthusiasts, have amassed a considerable collection that we cherish. However, managing this growing library became a challenge. I've tried various software on the market, but they were either too cumbersome or had privacy concerns.\n\nSo, after about a year of personal development, I've created a cross-platform desktop application (built with Tauri + Vue3) that's nearing the end of its first usable version and is almost ready for release. But before I do, I\u2019d love to get some feedback and suggestions from this knowledgeable community.\n\nHere are some of the features that I think you'll find interesting:\n\n* Web scraping capabilities for any site (cover images, basic info, etc.). Yes, you can configure it for any site (while respecting robot.txt rules).\n* All scraping is done locally to ensure privacy and security.\n* Multi-device usage: Open it on the desktop, and use it on your mobile via a QR code (web-based interface).\n* DLNA support for easy connection and streaming to various devices.\n* Cross-platform desktop application (supports the three major platforms) with mobile integration (Web) to use local players for playback.\n* No built-in player; it leverages your system's default player for what it does best.\n* Lightweight (thanks to the Tauri team), currently under 10 MB.\n* Simple, modern UI (kudos to the Vue3 team), with sleek animations.\n\nI'm working on uploading some demo videos to give you a better idea of how it works. In the meantime, I would greatly appreciate any feedback, advice, or questions you might have.\n\nThank you for reading, and I'm looking forward to hearing your thoughts!", "author_fullname": "t2_73asr8vfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hamster: A Lightweight Video Manager with Universal Scraping Capabilities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b66mlv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709543776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;This is my first post here, and I&amp;#39;m excited to share a project born out of my passion for movies and a desire for better video management. My wife and I, being film enthusiasts, have amassed a considerable collection that we cherish. However, managing this growing library became a challenge. I&amp;#39;ve tried various software on the market, but they were either too cumbersome or had privacy concerns.&lt;/p&gt;\n\n&lt;p&gt;So, after about a year of personal development, I&amp;#39;ve created a cross-platform desktop application (built with Tauri + Vue3) that&amp;#39;s nearing the end of its first usable version and is almost ready for release. But before I do, I\u2019d love to get some feedback and suggestions from this knowledgeable community.&lt;/p&gt;\n\n&lt;p&gt;Here are some of the features that I think you&amp;#39;ll find interesting:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Web scraping capabilities for any site (cover images, basic info, etc.). Yes, you can configure it for any site (while respecting robot.txt rules).&lt;/li&gt;\n&lt;li&gt;All scraping is done locally to ensure privacy and security.&lt;/li&gt;\n&lt;li&gt;Multi-device usage: Open it on the desktop, and use it on your mobile via a QR code (web-based interface).&lt;/li&gt;\n&lt;li&gt;DLNA support for easy connection and streaming to various devices.&lt;/li&gt;\n&lt;li&gt;Cross-platform desktop application (supports the three major platforms) with mobile integration (Web) to use local players for playback.&lt;/li&gt;\n&lt;li&gt;No built-in player; it leverages your system&amp;#39;s default player for what it does best.&lt;/li&gt;\n&lt;li&gt;Lightweight (thanks to the Tauri team), currently under 10 MB.&lt;/li&gt;\n&lt;li&gt;Simple, modern UI (kudos to the Vue3 team), with sleek animations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m working on uploading some demo videos to give you a better idea of how it works. In the meantime, I would greatly appreciate any feedback, advice, or questions you might have.&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading, and I&amp;#39;m looking forward to hearing your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b66mlv", "is_robot_indexable": true, "report_reasons": null, "author": "Mother-Pain-6166", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b66mlv/hamster_a_lightweight_video_manager_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b66mlv/hamster_a_lightweight_video_manager_with/", "subreddit_subscribers": 736125, "created_utc": 1709543776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I'm looking to send all my OneDrive photos (1TB+) to Amazon Photos, to take advantage of the latter's unlimited space. Currently the only option I've found is to download from OneDrive to my PC, then reupload into Amazon Photos (this is manual and slow). \n\nIs there a better way, such as connecting directly cloud to cloud? I've used [https://app.mover.io/](https://app.mover.io/) successfully before, however it doesn't seem to support OneDrive to Amazon Photos (or vice versa). Thanks!", "author_fullname": "t2_vedhl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sending photos from OneDrive to Amazon Photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b66b39", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709542499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m looking to send all my OneDrive photos (1TB+) to Amazon Photos, to take advantage of the latter&amp;#39;s unlimited space. Currently the only option I&amp;#39;ve found is to download from OneDrive to my PC, then reupload into Amazon Photos (this is manual and slow). &lt;/p&gt;\n\n&lt;p&gt;Is there a better way, such as connecting directly cloud to cloud? I&amp;#39;ve used &lt;a href=\"https://app.mover.io/\"&gt;https://app.mover.io/&lt;/a&gt; successfully before, however it doesn&amp;#39;t seem to support OneDrive to Amazon Photos (or vice versa). Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b66b39", "is_robot_indexable": true, "report_reasons": null, "author": "niner4nine", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b66b39/sending_photos_from_onedrive_to_amazon_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b66b39/sending_photos_from_onedrive_to_amazon_photos/", "subreddit_subscribers": 736125, "created_utc": 1709542499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.amazon.co.uk/UGREEN-External-Transfer-Supported-Compatible/dp/B082HF8C56/ref=sr\\_1\\_3?crid=6AII8VXKP23G&amp;dib=eyJ2IjoiMSJ9.s\\_ErIUmi1JQzQ2pyySuRY-m\\_sJjxxmjh0FP4R2qH\\_LgeqBQYu221gJZrpPKEyahe861ETaMSKqoE1HrtourntchS4O5Ek2sAkF-6xDSU1E3Elz2UdfwfxeE5poXQLPZJR0l3ZWXkR4UXSdFhv6qa4wCkGtQBCktwsTQCs102sGfmyxat3q2D4TwxULgjwoV9Pa6rcQQxsFen4tfOR7fZ74nKyfUC4eYS0GjbC4OO-ak.JOYZCIsPFl4EcD-33rrmt9zV5hBl-AFI4hTFQMEwtlw&amp;dib\\_tag=se&amp;keywords=Sata+to+usb+c&amp;qid=1709503118&amp;sprefix=sata+to+usb+c+%2Caps%2C79&amp;sr=8-3](https://www.amazon.co.uk/UGREEN-External-Transfer-Supported-Compatible/dp/B082HF8C56/ref=sr_1_3?crid=6AII8VXKP23G&amp;dib=eyJ2IjoiMSJ9.s_ErIUmi1JQzQ2pyySuRY-m_sJjxxmjh0FP4R2qH_LgeqBQYu221gJZrpPKEyahe861ETaMSKqoE1HrtourntchS4O5Ek2sAkF-6xDSU1E3Elz2UdfwfxeE5poXQLPZJR0l3ZWXkR4UXSdFhv6qa4wCkGtQBCktwsTQCs102sGfmyxat3q2D4TwxULgjwoV9Pa6rcQQxsFen4tfOR7fZ74nKyfUC4eYS0GjbC4OO-ak.JOYZCIsPFl4EcD-33rrmt9zV5hBl-AFI4hTFQMEwtlw&amp;dib_tag=se&amp;keywords=Sata+to+usb+c&amp;qid=1709503118&amp;sprefix=sata+to+usb+c+%2Caps%2C79&amp;sr=8-3) \n\n&amp;#x200B;\n\nInternal Blu-ray drive: [https://www.amazon.co.uk/LG-WH16NS40-optical-Desktop-Blu-Ray/dp/B00E7B08MS/ref=sr\\_1\\_9?crid=ALZQDNWQJ9U4&amp;dib=eyJ2IjoiMSJ9.yizkq6NdcKv2zvHIyjrkV-aU8s5oXPOYyNg8csGd6-YiI2PvZTuxcdgPnqhwuxuzfJy2XPlZI92vJtiOn2DF9HDP\\_\\_yPS382q7teXIHtwGY9eYN2DzyDQjgCsZW6x6qBY9xGD2wxQUQ\\_eCEfYCT9r3fHoe3RopTWOAUsbWneoXCGhfcAypdsMW-mKCItULQJwl\\_5CFtbkaM66LxaUwQ8Nc-tj7T98PSaXKH0uD\\_0Z38.gESxlg5kLe5uhrvrySFhTF\\_Gk05jYpL4tyqLmAIV\\_eU&amp;dib\\_tag=se&amp;keywords=Blu-ray+drive+4k+uhd&amp;qid=1709502750&amp;sprefix=blu-ray+drive+4k+uhd%2Caps%2C79&amp;sr=8-9](https://www.amazon.co.uk/LG-WH16NS40-optical-Desktop-Blu-Ray/dp/B00E7B08MS/ref=sr_1_9?crid=ALZQDNWQJ9U4&amp;dib=eyJ2IjoiMSJ9.yizkq6NdcKv2zvHIyjrkV-aU8s5oXPOYyNg8csGd6-YiI2PvZTuxcdgPnqhwuxuzfJy2XPlZI92vJtiOn2DF9HDP__yPS382q7teXIHtwGY9eYN2DzyDQjgCsZW6x6qBY9xGD2wxQUQ_eCEfYCT9r3fHoe3RopTWOAUsbWneoXCGhfcAypdsMW-mKCItULQJwl_5CFtbkaM66LxaUwQ8Nc-tj7T98PSaXKH0uD_0Z38.gESxlg5kLe5uhrvrySFhTF_Gk05jYpL4tyqLmAIV_eU&amp;dib_tag=se&amp;keywords=Blu-ray+drive+4k+uhd&amp;qid=1709502750&amp;sprefix=blu-ray+drive+4k+uhd%2Caps%2C79&amp;sr=8-9)", "author_fullname": "t2_l1wr83uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would this work with an internal blu-ray player with 4k?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6501h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709537301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/UGREEN-External-Transfer-Supported-Compatible/dp/B082HF8C56/ref=sr_1_3?crid=6AII8VXKP23G&amp;amp;dib=eyJ2IjoiMSJ9.s_ErIUmi1JQzQ2pyySuRY-m_sJjxxmjh0FP4R2qH_LgeqBQYu221gJZrpPKEyahe861ETaMSKqoE1HrtourntchS4O5Ek2sAkF-6xDSU1E3Elz2UdfwfxeE5poXQLPZJR0l3ZWXkR4UXSdFhv6qa4wCkGtQBCktwsTQCs102sGfmyxat3q2D4TwxULgjwoV9Pa6rcQQxsFen4tfOR7fZ74nKyfUC4eYS0GjbC4OO-ak.JOYZCIsPFl4EcD-33rrmt9zV5hBl-AFI4hTFQMEwtlw&amp;amp;dib_tag=se&amp;amp;keywords=Sata+to+usb+c&amp;amp;qid=1709503118&amp;amp;sprefix=sata+to+usb+c+%2Caps%2C79&amp;amp;sr=8-3\"&gt;https://www.amazon.co.uk/UGREEN-External-Transfer-Supported-Compatible/dp/B082HF8C56/ref=sr_1_3?crid=6AII8VXKP23G&amp;amp;dib=eyJ2IjoiMSJ9.s_ErIUmi1JQzQ2pyySuRY-m_sJjxxmjh0FP4R2qH_LgeqBQYu221gJZrpPKEyahe861ETaMSKqoE1HrtourntchS4O5Ek2sAkF-6xDSU1E3Elz2UdfwfxeE5poXQLPZJR0l3ZWXkR4UXSdFhv6qa4wCkGtQBCktwsTQCs102sGfmyxat3q2D4TwxULgjwoV9Pa6rcQQxsFen4tfOR7fZ74nKyfUC4eYS0GjbC4OO-ak.JOYZCIsPFl4EcD-33rrmt9zV5hBl-AFI4hTFQMEwtlw&amp;amp;dib_tag=se&amp;amp;keywords=Sata+to+usb+c&amp;amp;qid=1709503118&amp;amp;sprefix=sata+to+usb+c+%2Caps%2C79&amp;amp;sr=8-3&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Internal Blu-ray drive: &lt;a href=\"https://www.amazon.co.uk/LG-WH16NS40-optical-Desktop-Blu-Ray/dp/B00E7B08MS/ref=sr_1_9?crid=ALZQDNWQJ9U4&amp;amp;dib=eyJ2IjoiMSJ9.yizkq6NdcKv2zvHIyjrkV-aU8s5oXPOYyNg8csGd6-YiI2PvZTuxcdgPnqhwuxuzfJy2XPlZI92vJtiOn2DF9HDP__yPS382q7teXIHtwGY9eYN2DzyDQjgCsZW6x6qBY9xGD2wxQUQ_eCEfYCT9r3fHoe3RopTWOAUsbWneoXCGhfcAypdsMW-mKCItULQJwl_5CFtbkaM66LxaUwQ8Nc-tj7T98PSaXKH0uD_0Z38.gESxlg5kLe5uhrvrySFhTF_Gk05jYpL4tyqLmAIV_eU&amp;amp;dib_tag=se&amp;amp;keywords=Blu-ray+drive+4k+uhd&amp;amp;qid=1709502750&amp;amp;sprefix=blu-ray+drive+4k+uhd%2Caps%2C79&amp;amp;sr=8-9\"&gt;https://www.amazon.co.uk/LG-WH16NS40-optical-Desktop-Blu-Ray/dp/B00E7B08MS/ref=sr_1_9?crid=ALZQDNWQJ9U4&amp;amp;dib=eyJ2IjoiMSJ9.yizkq6NdcKv2zvHIyjrkV-aU8s5oXPOYyNg8csGd6-YiI2PvZTuxcdgPnqhwuxuzfJy2XPlZI92vJtiOn2DF9HDP__yPS382q7teXIHtwGY9eYN2DzyDQjgCsZW6x6qBY9xGD2wxQUQ_eCEfYCT9r3fHoe3RopTWOAUsbWneoXCGhfcAypdsMW-mKCItULQJwl_5CFtbkaM66LxaUwQ8Nc-tj7T98PSaXKH0uD_0Z38.gESxlg5kLe5uhrvrySFhTF_Gk05jYpL4tyqLmAIV_eU&amp;amp;dib_tag=se&amp;amp;keywords=Blu-ray+drive+4k+uhd&amp;amp;qid=1709502750&amp;amp;sprefix=blu-ray+drive+4k+uhd%2Caps%2C79&amp;amp;sr=8-9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6501h", "is_robot_indexable": true, "report_reasons": null, "author": "Jayparm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6501h/would_this_work_with_an_internal_bluray_player/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6501h/would_this_work_with_an_internal_bluray_player/", "subreddit_subscribers": 736125, "created_utc": 1709537301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As a passionate book collector and data hoarder, I worry about the possibility of losing access to certain books as they disappear from the internet and libraries. However, as my collection grows, I've come to realize that some books hold little meaning or value, such as poorly written novels or explicit content. I'm seeking a way to efficiently eliminate these books from my vast collection without risking the removal of books that I may actually need or enjoy. While I understand that I won't be able to read all the books in my lifetime, I still have a strong desire to collect them and hesitate to give up any. The manual process of sorting through millions of books is time-consuming and inefficient. I would greatly appreciate any suggestions or advice on how to approach this problem.", "author_fullname": "t2_409c23x3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Striking a Balance Between Meaningful Content and Eliminating Unwanted Books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b62b1u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709527857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a passionate book collector and data hoarder, I worry about the possibility of losing access to certain books as they disappear from the internet and libraries. However, as my collection grows, I&amp;#39;ve come to realize that some books hold little meaning or value, such as poorly written novels or explicit content. I&amp;#39;m seeking a way to efficiently eliminate these books from my vast collection without risking the removal of books that I may actually need or enjoy. While I understand that I won&amp;#39;t be able to read all the books in my lifetime, I still have a strong desire to collect them and hesitate to give up any. The manual process of sorting through millions of books is time-consuming and inefficient. I would greatly appreciate any suggestions or advice on how to approach this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b62b1u", "is_robot_indexable": true, "report_reasons": null, "author": "NavyandEnvy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b62b1u/striking_a_balance_between_meaningful_content_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b62b1u/striking_a_balance_between_meaningful_content_and/", "subreddit_subscribers": 736125, "created_utc": 1709527857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I expect a lot of the files are the same.  Is there a good program that can help me consolidate files?  I expect a lot of repeat files and/or photos of various resolutions but being the same photo.\n\nWindows OS", "author_fullname": "t2_irmir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a bunch of backup CDs/DVDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5yfn9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709516252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I expect a lot of the files are the same.  Is there a good program that can help me consolidate files?  I expect a lot of repeat files and/or photos of various resolutions but being the same photo.&lt;/p&gt;\n\n&lt;p&gt;Windows OS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b5yfn9", "is_robot_indexable": true, "report_reasons": null, "author": "Ottomatica", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b5yfn9/i_have_a_bunch_of_backup_cdsdvds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b5yfn9/i_have_a_bunch_of_backup_cdsdvds/", "subreddit_subscribers": 736125, "created_utc": 1709516252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m moving to Unraid for my server from Ubuntu &amp; am transferring about ~20TB of movies/tv shows to a new drive. Doing all of this locally on Ubuntu so not doing anything over the network but both rsync jobs for both my movies &amp; tv shows (currently have 2 going at the same time for both folders) are stuck at \u201cbuilding file list\u2026\u201d\n\nThe command I used is the following \u201crsync -acviz \u2014no-i-r \u2014info=progress2 \u201cyour source\u201d \u201cyour destination\u201d\u201d\n\nJust wondering if it\u2019s normal for it to take several hours on just the building file list portion or not. I used the -c because I\u2019ll be clearing the original drive afterwards &amp; want to make sure everything transfers all the way before erasing original drive. If there\u2019s another way I should go about it, please feel free to let me know.", "author_fullname": "t2_18bv7jlr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "rsync stuck on \u201cBuilding File List\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5y3vr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709515305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m moving to Unraid for my server from Ubuntu &amp;amp; am transferring about ~20TB of movies/tv shows to a new drive. Doing all of this locally on Ubuntu so not doing anything over the network but both rsync jobs for both my movies &amp;amp; tv shows (currently have 2 going at the same time for both folders) are stuck at \u201cbuilding file list\u2026\u201d&lt;/p&gt;\n\n&lt;p&gt;The command I used is the following \u201crsync -acviz \u2014no-i-r \u2014info=progress2 \u201cyour source\u201d \u201cyour destination\u201d\u201d&lt;/p&gt;\n\n&lt;p&gt;Just wondering if it\u2019s normal for it to take several hours on just the building file list portion or not. I used the -c because I\u2019ll be clearing the original drive afterwards &amp;amp; want to make sure everything transfers all the way before erasing original drive. If there\u2019s another way I should go about it, please feel free to let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b5y3vr", "is_robot_indexable": true, "report_reasons": null, "author": "lilcowboy", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b5y3vr/rsync_stuck_on_building_file_list/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b5y3vr/rsync_stuck_on_building_file_list/", "subreddit_subscribers": 736125, "created_utc": 1709515305.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}