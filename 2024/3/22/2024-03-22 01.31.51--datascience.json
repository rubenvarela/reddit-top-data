{"kind": "Listing", "data": {"after": null, "dist": 5, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there,\n\nI\u2019d rank myself as intermediate-senior data scientist and I\u2019ve never had to learn object oriented programming since functional approach worked most of the time.\n\nDuring this period I\u2019m thinking to invest some time in it. What could be good reasons to learn it for a data scientist?\n", "author_fullname": "t2_agbj58l8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I learn OOP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkbz8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711041734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I\u2019d rank myself as intermediate-senior data scientist and I\u2019ve never had to learn object oriented programming since functional approach worked most of the time.&lt;/p&gt;\n\n&lt;p&gt;During this period I\u2019m thinking to invest some time in it. What could be good reasons to learn it for a data scientist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1bkbz8i", "is_robot_indexable": true, "report_reasons": null, "author": "jujuman1313", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bkbz8i/why_should_i_learn_oop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bkbz8i/why_should_i_learn_oop/", "subreddit_subscribers": 1445922, "created_utc": 1711041734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We (a small startup) have recently seen considerable success fine-tuning LLMs (primarily OpenAI models) to generate data explorations and reports based on user requests. We provide relevant details of data schema as input and expect the LLM to generate a response written in our custom domain-specific language, which we then convert into a UI exploration.\n\nWe've shared more details in a blog post: https://www.supersimple.io/blog/gpt-4-fine-tuning-early-access\n\nI'm curious if anyone has explored similar approaches in other domains or perhaps used entirely different techniques within a similar context. Additionally, are there ways we could potentially streamline our own pipeline?", "author_fullname": "t2_enrdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using GPT-4 fine-tuning to generate data explorations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk5bek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711023933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We (a small startup) have recently seen considerable success fine-tuning LLMs (primarily OpenAI models) to generate data explorations and reports based on user requests. We provide relevant details of data schema as input and expect the LLM to generate a response written in our custom domain-specific language, which we then convert into a UI exploration.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve shared more details in a blog post: &lt;a href=\"https://www.supersimple.io/blog/gpt-4-fine-tuning-early-access\"&gt;https://www.supersimple.io/blog/gpt-4-fine-tuning-early-access&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious if anyone has explored similar approaches in other domains or perhaps used entirely different techniques within a similar context. Additionally, are there ways we could potentially streamline our own pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?auto=webp&amp;s=0ee07fbbbd7692266034b4913b6423b26962370a", "width": 2048, "height": 1406}, "resolutions": [{"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=07e836d5fc8f9f706764a778893d4b6f8d498178", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=49194c79bb2bf3fe78bffecf9d8ee5fdb31e3f99", "width": 216, "height": 148}, {"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=673f5f8c91f8bd74389551fe0b1a3df8740975ec", "width": 320, "height": 219}, {"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce75c8674aad2a1c24110208bbb39be1cea398a2", "width": 640, "height": 439}, {"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a96a5e6ec2a324e0636ac8df8aa3dae5d48d9ec", "width": 960, "height": 659}, {"url": "https://external-preview.redd.it/LEDKTf1QOWpceq2zjtt3Sqc9T2F372W60lmsAUstGxE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1e9b66dc99b2ce360abf60023c52b77e3844bc5", "width": 1080, "height": 741}], "variants": {}, "id": "6OrW-HKmKI82VRXQ_A3KtPNQ_q2hh0bvL2KUUmNGu1Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1bk5bek", "is_robot_indexable": true, "report_reasons": null, "author": "PipeTrance", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bk5bek/using_gpt4_finetuning_to_generate_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bk5bek/using_gpt4_finetuning_to_generate_data/", "subreddit_subscribers": 1445922, "created_utc": 1711023933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I mean, can I tell the head of operations this: if we run the experiment again, it's only 2.1% chance that the differences we observed is by chance, if we run the experiment again, it's a 97.8% chance that we would get values as or more extreme than what we saw?\n\nCan we even make it simpler?\n\nOtherwise, if he heard the word hypothesis, he starts making \"fuck it I should have stayed home\" noise", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it OKAY if I simplified p-valur to non tech stakeholders to the extent it no longer a statistical term?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkj9nh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711059549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean, can I tell the head of operations this: if we run the experiment again, it&amp;#39;s only 2.1% chance that the differences we observed is by chance, if we run the experiment again, it&amp;#39;s a 97.8% chance that we would get values as or more extreme than what we saw?&lt;/p&gt;\n\n&lt;p&gt;Can we even make it simpler?&lt;/p&gt;\n\n&lt;p&gt;Otherwise, if he heard the word hypothesis, he starts making &amp;quot;fuck it I should have stayed home&amp;quot; noise&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1bkj9nh", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 25, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bkj9nh/is_it_okay_if_i_simplified_pvalur_to_non_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bkj9nh/is_it_okay_if_i_simplified_pvalur_to_non_tech/", "subreddit_subscribers": 1445922, "created_utc": 1711059549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_40t1gisl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A systematic overview of prompt engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkhlhe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vsz9L2gkTvAbVdPdssXcojL-1VE8Buc3NXk1705MUSc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711055484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ploomber.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ploomber.io/blog/prompt-engineering-techniques/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lQSNVDdckRZKYP4WRw7dq8G5cvw7n1XerMvdk2EJM6w.jpg?auto=webp&amp;s=cd0abad98bf2a3932ea71db44799612fc28e38dc", "width": 1020, "height": 773}, "resolutions": [{"url": "https://external-preview.redd.it/lQSNVDdckRZKYP4WRw7dq8G5cvw7n1XerMvdk2EJM6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c8a45888b2f6f0a68478b6a5c7a0a231c6b48ea", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/lQSNVDdckRZKYP4WRw7dq8G5cvw7n1XerMvdk2EJM6w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b33a18cca948446c9ee76e932b670cad6d5fe4a7", "width": 216, "height": 163}, {"url": "https://external-preview.redd.it/lQSNVDdckRZKYP4WRw7dq8G5cvw7n1XerMvdk2EJM6w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=95e09ff0991f19589b45adaadc7921e885400e90", "width": 320, "height": 242}, {"url": "https://external-preview.redd.it/lQSNVDdckRZKYP4WRw7dq8G5cvw7n1XerMvdk2EJM6w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c7752000ecf364368eeff84954d23e8b15cb29e", "width": 640, "height": 485}, {"url": "https://external-preview.redd.it/lQSNVDdckRZKYP4WRw7dq8G5cvw7n1XerMvdk2EJM6w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e97dd2c1fa34de95ea5e5e975215fb435cb7cc13", "width": 960, "height": 727}], "variants": {}, "id": "H2wKXepHGX-AiYcb4KPKux97-ajAmUBzCqQcxVmYTV8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1bkhlhe", "is_robot_indexable": true, "report_reasons": null, "author": "databot_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bkhlhe/a_systematic_overview_of_prompt_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ploomber.io/blog/prompt-engineering-techniques/", "subreddit_subscribers": 1445922, "created_utc": 1711055484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand the concept of targeting likely buyers. It\u2019s a pretty straightforward solution. \n\nI\u2019m trying to find some literature on identifying the likely buyers/purchasers of a specific brand. \n\nI think this is a bit more challenging than the traditional propensity to purchase model because you can have many brands and you can also have very sparse data associated with a single brand. \n\nI can\u2019t find anything about this online. I\u2019m wondering if anyone can share some research on the topic if there is any. ", "author_fullname": "t2_jrhff4f29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Likely buyer of a specific brand", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkhge4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711055127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand the concept of targeting likely buyers. It\u2019s a pretty straightforward solution. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to find some literature on identifying the likely buyers/purchasers of a specific brand. &lt;/p&gt;\n\n&lt;p&gt;I think this is a bit more challenging than the traditional propensity to purchase model because you can have many brands and you can also have very sparse data associated with a single brand. &lt;/p&gt;\n\n&lt;p&gt;I can\u2019t find anything about this online. I\u2019m wondering if anyone can share some research on the topic if there is any. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1bkhge4", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible-Hamster-342", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bkhge4/likely_buyer_of_a_specific_brand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bkhge4/likely_buyer_of_a_specific_brand/", "subreddit_subscribers": 1445922, "created_utc": 1711055127.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}