{"kind": "Listing", "data": {"after": "t3_1bkmpk7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi /r/dataengineering,\n\nI'm Pete, the CEO at Dagster Labs. We're launching our new product, Dagster+, in a few weeks, and are having launch parties in SF and NYC to preview the release with the community and enjoy some food, drinks, and good company.\n\nThis subreddit has been very supportive of us over the past few years, and we'd love to see you there! They're happening the evening of April 12th, and you can sign up [here](https://share.hsforms.com/10i2u9WzCRyK77-D0MCn89gq55vz).\n\nSpots are limited, so we\u2019ll reach out to confirm attendance as available closer to the date of the parties. Thanks in advance for expressing your interest!", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We (Dagster) are throwing a party", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkebv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 160, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 160, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711050842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711047477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Pete, the CEO at Dagster Labs. We&amp;#39;re launching our new product, Dagster+, in a few weeks, and are having launch parties in SF and NYC to preview the release with the community and enjoy some food, drinks, and good company.&lt;/p&gt;\n\n&lt;p&gt;This subreddit has been very supportive of us over the past few years, and we&amp;#39;d love to see you there! They&amp;#39;re happening the evening of April 12th, and you can sign up &lt;a href=\"https://share.hsforms.com/10i2u9WzCRyK77-D0MCn89gq55vz\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Spots are limited, so we\u2019ll reach out to confirm attendance as available closer to the date of the parties. Thanks in advance for expressing your interest!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bkebv5", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkebv5/we_dagster_are_throwing_a_party/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkebv5/we_dagster_are_throwing_a_party/", "subreddit_subscribers": 170793, "created_utc": 1711047477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm 27(F) and I've been working in data engineering for a good 5 years now. I recently started working for a Canadian company where I already knew my boss from another place we worked together. When we were discussing the opportunity he had told me that the salary would be around 7500 dollars a month, but after a conversation with the founders of the company I received the offer with a salary of 5800, but I managed to cry for 6500. From what my boss said, it was because Canadians think I'm too young, but I'm sure part of it was because I'm a woman too.\n\nNow that I've been with the company for a year, I've made some great deliveries and I give a lot of support to other people whose technical level is well below mine, but who earn more, I'd like to ask for a decent raise. I've already talked to my boss, but he tells me to be patient because HR is working on a career plan, but that should take another 6 months at least.\n\nI'd like some help in approaching my boss more firmly, but without sounding like an ultimatum. I'd like him to talk directly to the founders, as I think this would make it easier to get a raise (the founders are aware of the work I've been doing).\n\nI wouldn't want to change jobs now, because I like the company, I'd just like a fair salary on a par with that of my colleagues.", "author_fullname": "t2_mjzy4r5fx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ask for a salary increase that I deserve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk5tkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711025592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 27(F) and I&amp;#39;ve been working in data engineering for a good 5 years now. I recently started working for a Canadian company where I already knew my boss from another place we worked together. When we were discussing the opportunity he had told me that the salary would be around 7500 dollars a month, but after a conversation with the founders of the company I received the offer with a salary of 5800, but I managed to cry for 6500. From what my boss said, it was because Canadians think I&amp;#39;m too young, but I&amp;#39;m sure part of it was because I&amp;#39;m a woman too.&lt;/p&gt;\n\n&lt;p&gt;Now that I&amp;#39;ve been with the company for a year, I&amp;#39;ve made some great deliveries and I give a lot of support to other people whose technical level is well below mine, but who earn more, I&amp;#39;d like to ask for a decent raise. I&amp;#39;ve already talked to my boss, but he tells me to be patient because HR is working on a career plan, but that should take another 6 months at least.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like some help in approaching my boss more firmly, but without sounding like an ultimatum. I&amp;#39;d like him to talk directly to the founders, as I think this would make it easier to get a raise (the founders are aware of the work I&amp;#39;ve been doing).&lt;/p&gt;\n\n&lt;p&gt;I wouldn&amp;#39;t want to change jobs now, because I like the company, I&amp;#39;d just like a fair salary on a par with that of my colleagues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bk5tkj", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Engineering-5752", "discussion_type": null, "num_comments": 103, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk5tkj/how_to_ask_for_a_salary_increase_that_i_deserve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk5tkj/how_to_ask_for_a_salary_increase_that_i_deserve/", "subreddit_subscribers": 170793, "created_utc": 1711025592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI was wondering if anyone started out with a new DE job with a MacBook when they\u2019ve used windows most of their life? If so, was it easy to adjust and did it impact your work at all as a DE?\n\nI\u2019ve always wanted to code and work on a MacBook Pro but I\u2019m worried I might hit roadblocks I\u2019m not used to vs working in windows. \n\nOne thing that worries me is I know MacBook isn\u2019t compatible with SSMS which is one of my bread and butter. But I read online that you can access a container with windows installed and use SSMS that way? Something to do with docker?\n\nDid anyone else face these concerns or issues converting to MacBook? And if so, did you overcome it and adjust quickly?", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you have the option to switch to MacBook for work would you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkcret", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711043627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone started out with a new DE job with a MacBook when they\u2019ve used windows most of their life? If so, was it easy to adjust and did it impact your work at all as a DE?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve always wanted to code and work on a MacBook Pro but I\u2019m worried I might hit roadblocks I\u2019m not used to vs working in windows. &lt;/p&gt;\n\n&lt;p&gt;One thing that worries me is I know MacBook isn\u2019t compatible with SSMS which is one of my bread and butter. But I read online that you can access a container with windows installed and use SSMS that way? Something to do with docker?&lt;/p&gt;\n\n&lt;p&gt;Did anyone else face these concerns or issues converting to MacBook? And if so, did you overcome it and adjust quickly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bkcret", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bkcret/if_you_have_the_option_to_switch_to_macbook_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkcret/if_you_have_the_option_to_switch_to_macbook_for/", "subreddit_subscribers": 170793, "created_utc": 1711043627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to get opinions on what I could've done better here.\n\nI am mid level data consultant. A little over a year ago a client approached us, I was the most senior person on this one and was kinda left on my own.\n\nBasically his company was launching a new subsidiary (brand) and app to go with it. He wanted proper dashboards and reporting in place from day 1, so no exports and spreadsheets.\n\nHe had the app running on flutter, MS SQL DB, an ERP system and at some stage was going to get a CRM system.\n\nWith limited funds he needed a proof of concept, that would form the basis of Enterprise reporting in future.\n\nWe started with reporting for the app database. So new users, products, revenue, etc.\n\nI proposed migrating the SQL DB to AWS S3 and using Athena for queries and connecting to Tableau for dashboards. Granted we could have just plugged Tableau into the DB but the idea was that in future we would migrate data from the other sources to S3 and then we could start running queries across data sets.\n\nI recently found out he has decommissioned all of this and is getting the app dev team to build dashboards directly into the admin portal.\n\nWas my solution bad?\n\nIn hindsight maybe I could've used a virtualization tool like Denodo or Azure Data fabric to achieve the same result. Or gone with a smaller POC and just plugged in Tableau.\n\n\n", "author_fullname": "t2_jvfyd0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Client replaced my solution, want opinions on what I could've changed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk1870", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711007616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to get opinions on what I could&amp;#39;ve done better here.&lt;/p&gt;\n\n&lt;p&gt;I am mid level data consultant. A little over a year ago a client approached us, I was the most senior person on this one and was kinda left on my own.&lt;/p&gt;\n\n&lt;p&gt;Basically his company was launching a new subsidiary (brand) and app to go with it. He wanted proper dashboards and reporting in place from day 1, so no exports and spreadsheets.&lt;/p&gt;\n\n&lt;p&gt;He had the app running on flutter, MS SQL DB, an ERP system and at some stage was going to get a CRM system.&lt;/p&gt;\n\n&lt;p&gt;With limited funds he needed a proof of concept, that would form the basis of Enterprise reporting in future.&lt;/p&gt;\n\n&lt;p&gt;We started with reporting for the app database. So new users, products, revenue, etc.&lt;/p&gt;\n\n&lt;p&gt;I proposed migrating the SQL DB to AWS S3 and using Athena for queries and connecting to Tableau for dashboards. Granted we could have just plugged Tableau into the DB but the idea was that in future we would migrate data from the other sources to S3 and then we could start running queries across data sets.&lt;/p&gt;\n\n&lt;p&gt;I recently found out he has decommissioned all of this and is getting the app dev team to build dashboards directly into the admin portal.&lt;/p&gt;\n\n&lt;p&gt;Was my solution bad?&lt;/p&gt;\n\n&lt;p&gt;In hindsight maybe I could&amp;#39;ve used a virtualization tool like Denodo or Azure Data fabric to achieve the same result. Or gone with a smaller POC and just plugged in Tableau.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk1870", "is_robot_indexable": true, "report_reasons": null, "author": "FlyContrapuntist", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk1870/client_replaced_my_solution_want_opinions_on_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk1870/client_replaced_my_solution_want_opinions_on_what/", "subreddit_subscribers": 170793, "created_utc": 1711007616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, this question might be a bit out of context for this sub but I'm really confused and don't know what to do :\n\nSo im a 4th Year software engineering student(out of 5 years in total) and up until this point I've been focusing only on software development and all the projects internships I did consisted mainly of web, mobile development and recently I started to get introduced to data engineering and data analysis as they added some new subjects to the curriculum and I sort of liked them but I don't know if it would be a better career path If I shift my focus to data engineering instead of focusing solely on software develoment, \nPlease help me I need advices and opinions.\n", "author_fullname": "t2_kjvbhqyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE vs Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk5yyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711026058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, this question might be a bit out of context for this sub but I&amp;#39;m really confused and don&amp;#39;t know what to do :&lt;/p&gt;\n\n&lt;p&gt;So im a 4th Year software engineering student(out of 5 years in total) and up until this point I&amp;#39;ve been focusing only on software development and all the projects internships I did consisted mainly of web, mobile development and recently I started to get introduced to data engineering and data analysis as they added some new subjects to the curriculum and I sort of liked them but I don&amp;#39;t know if it would be a better career path If I shift my focus to data engineering instead of focusing solely on software develoment, \nPlease help me I need advices and opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bk5yyi", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic_Battle876", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk5yyi/swe_vs_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk5yyi/swe_vs_data_engineer/", "subreddit_subscribers": 170793, "created_utc": 1711026058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Saw a post that required a Minimum of 10 Years of experience in Azure to warehouse snowflake Data. This technology itself is not that old! What is your suggestion for someone with little experience to be a DE?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/tlz3ihwt3spc1.png?width=1226&amp;format=png&amp;auto=webp&amp;s=663c7b400835533e57fb459459619bde04984c7d", "author_fullname": "t2_65gcymee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break into a Data Engineering Job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tlz3ihwt3spc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=79493bde33c3ba3fe41292490888a129232dca9a"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ebea4e82e057ce8133d05fd93bd7b2be5b583d31"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4902b81a61bc6dd0cf45360af3e27b57ec1ddfc0"}, {"y": 401, "x": 640, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=85f2b45b588cf989e642d28a186aeec85b8b83e8"}, {"y": 602, "x": 960, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ebe07f5f5522491daf3c9d660e79e5dbf0d78da8"}, {"y": 678, "x": 1080, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e54ff27b24e19738cdafbd3a34bfe1f0c7c2b1a4"}], "s": {"y": 770, "x": 1226, "u": "https://preview.redd.it/tlz3ihwt3spc1.png?width=1226&amp;format=png&amp;auto=webp&amp;s=663c7b400835533e57fb459459619bde04984c7d"}, "id": "tlz3ihwt3spc1"}}, "name": "t3_1bkm10r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UvSIJshNf6bBVZc-HLmbAfwKmmg20vUZJTGr5J3bDnA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711066775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw a post that required a Minimum of 10 Years of experience in Azure to warehouse snowflake Data. This technology itself is not that old! What is your suggestion for someone with little experience to be a DE?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tlz3ihwt3spc1.png?width=1226&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=663c7b400835533e57fb459459619bde04984c7d\"&gt;https://preview.redd.it/tlz3ihwt3spc1.png?width=1226&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=663c7b400835533e57fb459459619bde04984c7d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bkm10r", "is_robot_indexable": true, "report_reasons": null, "author": "BrownChubbyDoggy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkm10r/how_to_break_into_a_data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkm10r/how_to_break_into_a_data_engineering_job/", "subreddit_subscribers": 170793, "created_utc": 1711066775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm on my way to learn DE, and this sub has helped me a lot to understand better many concepts, but one thing I see very often is that Postgres seems to be the best DWH in most cases, so my question is, which are those cases where Postgres is NOT recommended? What alternatives are better suited for that situation and Why? \n\nThank you! ", "author_fullname": "t2_4iz2pipg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When NOT to use PostgreSQL? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bklthc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711066181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m on my way to learn DE, and this sub has helped me a lot to understand better many concepts, but one thing I see very often is that Postgres seems to be the best DWH in most cases, so my question is, which are those cases where Postgres is NOT recommended? What alternatives are better suited for that situation and Why? &lt;/p&gt;\n\n&lt;p&gt;Thank you! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bklthc", "is_robot_indexable": true, "report_reasons": null, "author": "_Lavender_Brown_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bklthc/when_not_to_use_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bklthc/when_not_to_use_postgresql/", "subreddit_subscribers": 170793, "created_utc": 1711066181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a company that's heavily relying on databricks for ETL and modeling. I am expected to become an expert using databricks, but I do not have permissions to create new clusters, workspaces, etc. And, when I attempt to create a \"training profile\", the system will still only log me in to these limited profiles.  \n  \nDoes anyone know how to access/create a student-tier workspace that capable of handling the demands of Databrick's own learning modules? Does Databricks provide access to something like this for people training to use their systems?  \n  \nAny help would be appreciated.  \nI did check online and everything points toward having admin access, which leads me to believe I will need to set up a personal azure account and pay for databricks itself. I'm trying to avoid that.", "author_fullname": "t2_8ehj9bag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I learn databricks without admin rights / or at a low cost?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkeepi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711047663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a company that&amp;#39;s heavily relying on databricks for ETL and modeling. I am expected to become an expert using databricks, but I do not have permissions to create new clusters, workspaces, etc. And, when I attempt to create a &amp;quot;training profile&amp;quot;, the system will still only log me in to these limited profiles.  &lt;/p&gt;\n\n&lt;p&gt;Does anyone know how to access/create a student-tier workspace that capable of handling the demands of Databrick&amp;#39;s own learning modules? Does Databricks provide access to something like this for people training to use their systems?  &lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;br/&gt;\nI did check online and everything points toward having admin access, which leads me to believe I will need to set up a personal azure account and pay for databricks itself. I&amp;#39;m trying to avoid that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bkeepi", "is_robot_indexable": true, "report_reasons": null, "author": "ExpertlyAmateur", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkeepi/how_can_i_learn_databricks_without_admin_rights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkeepi/how_can_i_learn_databricks_without_admin_rights/", "subreddit_subscribers": 170793, "created_utc": 1711047663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I currently new in this field and want to ask for some advice on this problem.\n\n  \nGiven N items (N \\~ 10\\^8), each item has a list of unique items that is \"related\" to it. The average size of the \"related\" list of an item is about 10^3. The problem is, each time, a list of items is given with size \\~ 10\\^3 items, we have to return the number of unique items in the concatenated list of all the \"related\" items of at least 1 item in the given list.\n\n* Input: Each line is the item id and its \"related\" items. So the input matrix is around 10\\^8 \\* 10\\^3. \n* Output:\n   * When given a list of X (X \\~ 10\\^3) items, we have to concatenate the lists of \"related\" items of X items, and return the number of unique items.\n   * For each query, the inference time is &lt;= 1s.\n\nExample:\n\nInput: \n\n1 2 3 4\n\n2 1 3 5\n\n3 1 2\n\n4 2 5\n\n5 1 4\n\nSo the item 1 is related to 2, 3, 4. item 2 is related to 1, 3, 5. item 3 is related to 1, 2 and so on.  \nIf the query is (1, 4), then the answer is 4. (the list is (2, 3, 4, 5) = (2, 3, 4) + (2, 5)).\n\n&amp;#x200B;\n\nRequirements:\n\n* Exact solution with inference time &lt;= 1s\n* Cannot use cloud computing (must run with my own hardwares)\n\nPriority (top to bottom is most prioritized to least)\n\n* Inference time\n* Use the least memory\n* Simplicity\n* Scalability...\n\nWhat might be the most probable solutions for this? Thanks in advance.  \n", "author_fullname": "t2_mnodayhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help on a data problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk10ch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711019029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711006646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I currently new in this field and want to ask for some advice on this problem.&lt;/p&gt;\n\n&lt;p&gt;Given N items (N ~ 10^8), each item has a list of unique items that is &amp;quot;related&amp;quot; to it. The average size of the &amp;quot;related&amp;quot; list of an item is about 10&lt;sup&gt;3.&lt;/sup&gt; The problem is, each time, a list of items is given with size ~ 10^3 items, we have to return the number of unique items in the concatenated list of all the &amp;quot;related&amp;quot; items of at least 1 item in the given list.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Input: Each line is the item id and its &amp;quot;related&amp;quot; items. So the input matrix is around 10^8 * 10^3. &lt;/li&gt;\n&lt;li&gt;Output:\n\n&lt;ul&gt;\n&lt;li&gt;When given a list of X (X ~ 10^3) items, we have to concatenate the lists of &amp;quot;related&amp;quot; items of X items, and return the number of unique items.&lt;/li&gt;\n&lt;li&gt;For each query, the inference time is &amp;lt;= 1s.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;p&gt;Input: &lt;/p&gt;\n\n&lt;p&gt;1 2 3 4&lt;/p&gt;\n\n&lt;p&gt;2 1 3 5&lt;/p&gt;\n\n&lt;p&gt;3 1 2&lt;/p&gt;\n\n&lt;p&gt;4 2 5&lt;/p&gt;\n\n&lt;p&gt;5 1 4&lt;/p&gt;\n\n&lt;p&gt;So the item 1 is related to 2, 3, 4. item 2 is related to 1, 3, 5. item 3 is related to 1, 2 and so on.&lt;br/&gt;\nIf the query is (1, 4), then the answer is 4. (the list is (2, 3, 4, 5) = (2, 3, 4) + (2, 5)).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Exact solution with inference time &amp;lt;= 1s&lt;/li&gt;\n&lt;li&gt;Cannot use cloud computing (must run with my own hardwares)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Priority (top to bottom is most prioritized to least)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inference time&lt;/li&gt;\n&lt;li&gt;Use the least memory&lt;/li&gt;\n&lt;li&gt;Simplicity&lt;/li&gt;\n&lt;li&gt;Scalability...&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What might be the most probable solutions for this? Thanks in advance.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk10ch", "is_robot_indexable": true, "report_reasons": null, "author": "HynDuf", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk10ch/need_help_on_a_data_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk10ch/need_help_on_a_data_problem/", "subreddit_subscribers": 170793, "created_utc": 1711006646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was recently hired as a data analyst in a small company and I want to help out in restructuring our data systems (we don't have data engineers or the like). We're pulling CSV's regularly (about 4-5 times a day) and we use it to update our BigQuery tables. These CSV's however, are highly overlapping and duplicates across multiple CSV's are common. Our approach right now is just outright deleting a portion of our main table corresponding to the recent previous pulls and then repopulating them with the latest one. This main table is also what we use for regular reporting and visualizations. There are a lot of joins across other tables as well but all tables don't have keys and indices. The joins are also usually on derived columns.\n\nJust started learning about data warehousing and dimensional modelling and I wonder if this is applicable in our case. Should I: create a more efficient fully-functioning database (not necessarily conforming to dimensional modeling frameworks), or design a data warehouse pulling the CSV's that conforms to dimensional modeling, or both, ie. having a database and a separate data warehouse pulling from that database?\n\nOur team is mostly using Google Cloud and I was wondering if BigQuery or Cloud SQL or maybe a combination of both would be the ideal tool to use. Thanks!", "author_fullname": "t2_98q4cvf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on restructuring of data infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bka37v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711037093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was recently hired as a data analyst in a small company and I want to help out in restructuring our data systems (we don&amp;#39;t have data engineers or the like). We&amp;#39;re pulling CSV&amp;#39;s regularly (about 4-5 times a day) and we use it to update our BigQuery tables. These CSV&amp;#39;s however, are highly overlapping and duplicates across multiple CSV&amp;#39;s are common. Our approach right now is just outright deleting a portion of our main table corresponding to the recent previous pulls and then repopulating them with the latest one. This main table is also what we use for regular reporting and visualizations. There are a lot of joins across other tables as well but all tables don&amp;#39;t have keys and indices. The joins are also usually on derived columns.&lt;/p&gt;\n\n&lt;p&gt;Just started learning about data warehousing and dimensional modelling and I wonder if this is applicable in our case. Should I: create a more efficient fully-functioning database (not necessarily conforming to dimensional modeling frameworks), or design a data warehouse pulling the CSV&amp;#39;s that conforms to dimensional modeling, or both, ie. having a database and a separate data warehouse pulling from that database?&lt;/p&gt;\n\n&lt;p&gt;Our team is mostly using Google Cloud and I was wondering if BigQuery or Cloud SQL or maybe a combination of both would be the ideal tool to use. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bka37v", "is_robot_indexable": true, "report_reasons": null, "author": "MushroomDegenerate", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bka37v/advice_on_restructuring_of_data_infrastructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bka37v/advice_on_restructuring_of_data_infrastructure/", "subreddit_subscribers": 170793, "created_utc": 1711037093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I recently started playing with airflow since the project I work on is migrating to GCP where we will be using Composer.\n\nTill now I was playing on my personal device with Pop OS. Recently I tried to create some dags from my organisation's windows machine and found out airflow tests won't run on Windows, it just supports POSIX systems.\n\nI saw people running airflow on windows with Docker or WSL, but since I am using a company provided laptop, due to restrictions I cannot enable WSL, and not sure how tedious it will be to setup docker here.\n\nJust being able to run unit tests on DAGs and tasks should do the job for me. Anyone have faced similar issue ? Any suggestions here are welcome. \n\nIf nothing, I will have to maybe setup some scripts that will sync my code with a compute engine instance which will run those tests for me. Not sure how feasible this is though ..", "author_fullname": "t2_aaa2s820a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to run airflow tests on local windows machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkaqt4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711038719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I recently started playing with airflow since the project I work on is migrating to GCP where we will be using Composer.&lt;/p&gt;\n\n&lt;p&gt;Till now I was playing on my personal device with Pop OS. Recently I tried to create some dags from my organisation&amp;#39;s windows machine and found out airflow tests won&amp;#39;t run on Windows, it just supports POSIX systems.&lt;/p&gt;\n\n&lt;p&gt;I saw people running airflow on windows with Docker or WSL, but since I am using a company provided laptop, due to restrictions I cannot enable WSL, and not sure how tedious it will be to setup docker here.&lt;/p&gt;\n\n&lt;p&gt;Just being able to run unit tests on DAGs and tasks should do the job for me. Anyone have faced similar issue ? Any suggestions here are welcome. &lt;/p&gt;\n\n&lt;p&gt;If nothing, I will have to maybe setup some scripts that will sync my code with a compute engine instance which will run those tests for me. Not sure how feasible this is though ..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bkaqt4", "is_robot_indexable": true, "report_reasons": null, "author": "Suitable-Side-4133", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkaqt4/what_is_the_best_way_to_run_airflow_tests_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkaqt4/what_is_the_best_way_to_run_airflow_tests_on/", "subreddit_subscribers": 170793, "created_utc": 1711038719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Note: This isn't about Extract/Load data in delta mode but rather the Transform part.\n\nLet's say I'm loading orders and I'm joining the header and detail together.\n\nI'm trying to figure out how to handle scenarios where either table gets a change.\n\nLet's say the Order header changes, I'd want to reload the entire Order by joining the header/detail but, only the order currently has delta data.\n\nThere's also the scenario where a new order line appears and I need to reload the entire order because, let's say I'm performing window functions or any similar workload.\n\n&amp;#x200B;\n\nI also have scenarios where more than 2 tables get joined together and all of them are deltas.\n\n&amp;#x200B;\n\nI'm currently using SSIS with most of the workload being pure SQL or Stored Procedures.\n\nI'm aware the tool is old and we are looking into new tools but I still need to develop new stuff right now, plus I assume the issue would remain in other tools.\n\n&amp;#x200B;\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_6293r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performing delta/incremental loads with header/detail relationships", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk8637", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711032214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Note: This isn&amp;#39;t about Extract/Load data in delta mode but rather the Transform part.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I&amp;#39;m loading orders and I&amp;#39;m joining the header and detail together.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out how to handle scenarios where either table gets a change.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say the Order header changes, I&amp;#39;d want to reload the entire Order by joining the header/detail but, only the order currently has delta data.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also the scenario where a new order line appears and I need to reload the entire order because, let&amp;#39;s say I&amp;#39;m performing window functions or any similar workload.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I also have scenarios where more than 2 tables get joined together and all of them are deltas.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using SSIS with most of the workload being pure SQL or Stored Procedures.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware the tool is old and we are looking into new tools but I still need to develop new stuff right now, plus I assume the issue would remain in other tools.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk8637", "is_robot_indexable": true, "report_reasons": null, "author": "meatmick", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk8637/performing_deltaincremental_loads_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk8637/performing_deltaincremental_loads_with/", "subreddit_subscribers": 170793, "created_utc": 1711032214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am the only data engineer at a small company with not too much experience, and I have to figure out a system to supply the data for our BI platform and other reports, from various sources (APIs, csv files, SQL databases, etc.).\n\nI looked around and I found Apache NiFi (which has already been recommended by other people on this sub). I've already played around with it a little bit and it seems to be what I'm looking for. It was also important that I can run python scripts with any dependencies, and it seems to be allowing it through the ExecuteStreamCommand processor, but what I don't know is how I should organize these scripts and where to store them.\n\nWe will run NiFi in Kubernetes, and according to our DevOps guy, it would be very bad practice if we just kept adding these python scripts / virtual environments (in case we really need that complexity) to the container of NiFi. \n\nWhat would be the best practice here? We want to keep the python scripts version controlled, so it would be pushed to our own gitlab. Of course we don't want to deploy each python script individually and create a bunch of pods either, but we're struggling to find our way.\n\nThank you in advance!", "author_fullname": "t2_bcsbesiv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing scripts in Apache NiFi", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk45ct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711019860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am the only data engineer at a small company with not too much experience, and I have to figure out a system to supply the data for our BI platform and other reports, from various sources (APIs, csv files, SQL databases, etc.).&lt;/p&gt;\n\n&lt;p&gt;I looked around and I found Apache NiFi (which has already been recommended by other people on this sub). I&amp;#39;ve already played around with it a little bit and it seems to be what I&amp;#39;m looking for. It was also important that I can run python scripts with any dependencies, and it seems to be allowing it through the ExecuteStreamCommand processor, but what I don&amp;#39;t know is how I should organize these scripts and where to store them.&lt;/p&gt;\n\n&lt;p&gt;We will run NiFi in Kubernetes, and according to our DevOps guy, it would be very bad practice if we just kept adding these python scripts / virtual environments (in case we really need that complexity) to the container of NiFi. &lt;/p&gt;\n\n&lt;p&gt;What would be the best practice here? We want to keep the python scripts version controlled, so it would be pushed to our own gitlab. Of course we don&amp;#39;t want to deploy each python script individually and create a bunch of pods either, but we&amp;#39;re struggling to find our way.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk45ct", "is_robot_indexable": true, "report_reasons": null, "author": "csicskagyasz00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk45ct/organizing_scripts_in_apache_nifi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk45ct/organizing_scripts_in_apache_nifi/", "subreddit_subscribers": 170793, "created_utc": 1711019860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nI am currently a Junior in college and am doing an end-to-end analytics project that requires data extraction (web scraping), data cleaning, EDA, etc... Right now I was wondering if there's any way to schedule the [extraction.py](https://extraction.py) file to run every 2 weeks, then trigger the data\\_cleaning.py file to run after the [extraction.py](https://extraction.py) file. Also, I am open to any feedback regarding my project. Since I am an MIS major instead of CS, my code might not be as clean as it is supposed to be, but I am trying my best to work on it daily. Truly appreciate the feedback and the help.\n\n[Project Link](https://github.com/MarkPhamm/British-Airway)", "author_fullname": "t2_7vqsib1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asking for help with side Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bkq5yk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711079233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I am currently a Junior in college and am doing an end-to-end analytics project that requires data extraction (web scraping), data cleaning, EDA, etc... Right now I was wondering if there&amp;#39;s any way to schedule the &lt;a href=\"https://extraction.py\"&gt;extraction.py&lt;/a&gt; file to run every 2 weeks, then trigger the data_cleaning.py file to run after the &lt;a href=\"https://extraction.py\"&gt;extraction.py&lt;/a&gt; file. Also, I am open to any feedback regarding my project. Since I am an MIS major instead of CS, my code might not be as clean as it is supposed to be, but I am trying my best to work on it daily. Truly appreciate the feedback and the help.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/MarkPhamm/British-Airway\"&gt;Project Link&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bkq5yk", "is_robot_indexable": true, "report_reasons": null, "author": "SmartPersonality1862", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkq5yk/asking_for_help_with_side_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkq5yk/asking_for_help_with_side_project/", "subreddit_subscribers": 170793, "created_utc": 1711079233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am developing a medium data warehouse with size about 100 GB, using Postgres as database. At the moment I  running a generic postgresql server for dev environment, but I wonder if that version will hold up on production.\n\nSo, what is your setup? Please share!", "author_fullname": "t2_125mdi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your Postgres setup for data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkpfx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711076883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am developing a medium data warehouse with size about 100 GB, using Postgres as database. At the moment I  running a generic postgresql server for dev environment, but I wonder if that version will hold up on production.&lt;/p&gt;\n\n&lt;p&gt;So, what is your setup? Please share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bkpfx3", "is_robot_indexable": true, "report_reasons": null, "author": "dreamingfighter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkpfx3/what_is_your_postgres_setup_for_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkpfx3/what_is_your_postgres_setup_for_data_warehouse/", "subreddit_subscribers": 170793, "created_utc": 1711076883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, we're recently undergoing a bit of a project to extract data from a SAAS platform. Just a few API endpoints. It's pretty niche, so no managed EL services (Fivetran, Airbyte), so we gotta do it in-house. Fine.\n\nBecause the dataset is relatively small, for 9/10 endpoints, we can just do a full extract (~300 pages) every 6 hours or so using a Google Cloud Function and overwrite our BQ tables. \n\nFor one of the endpoints, however, we're talking 3000+ API calls for a full data dump. Not great. Cloud function execution time is 10 minutes so it times out. We could move the script to Cloud Run, but I feel we're going to come up against the same issues.\n\nNow, there is a /changes endpoint, which only returns records that have changed since the provided date, but in terms of EL strategy, we still need to somehow consolidate the data into a source of truth that mirrors the source.\n\nI'm for a bit of a sense-check. I propose that \n\n* Every 6 hours (or any arbitrary cycle time), we ask for any data that's changed at source for the last four* cycle periods.\n* We take those changed records and dump them into Google Cloud Storage in JSON/Avro, whatever.\n* A BQ data transfer job appends all records into a table\n* We create a Dataform/DBT SQL pipeline that picks out all of the most recent records for every record ID into a staging table.\n* Downstream BI can use that staging table as a 'mirrored' source of truth from the SAAS platform.\n\nWhy four*? Contingency. If an EL fails, it can fail for 4 cycles before we need manual intervention.\n\nAm I overcomplicating this?", "author_fullname": "t2_hpuhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting from API strategy - what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkiai1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711057173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, we&amp;#39;re recently undergoing a bit of a project to extract data from a SAAS platform. Just a few API endpoints. It&amp;#39;s pretty niche, so no managed EL services (Fivetran, Airbyte), so we gotta do it in-house. Fine.&lt;/p&gt;\n\n&lt;p&gt;Because the dataset is relatively small, for 9/10 endpoints, we can just do a full extract (~300 pages) every 6 hours or so using a Google Cloud Function and overwrite our BQ tables. &lt;/p&gt;\n\n&lt;p&gt;For one of the endpoints, however, we&amp;#39;re talking 3000+ API calls for a full data dump. Not great. Cloud function execution time is 10 minutes so it times out. We could move the script to Cloud Run, but I feel we&amp;#39;re going to come up against the same issues.&lt;/p&gt;\n\n&lt;p&gt;Now, there is a /changes endpoint, which only returns records that have changed since the provided date, but in terms of EL strategy, we still need to somehow consolidate the data into a source of truth that mirrors the source.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m for a bit of a sense-check. I propose that &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Every 6 hours (or any arbitrary cycle time), we ask for any data that&amp;#39;s changed at source for the last four* cycle periods.&lt;/li&gt;\n&lt;li&gt;We take those changed records and dump them into Google Cloud Storage in JSON/Avro, whatever.&lt;/li&gt;\n&lt;li&gt;A BQ data transfer job appends all records into a table&lt;/li&gt;\n&lt;li&gt;We create a Dataform/DBT SQL pipeline that picks out all of the most recent records for every record ID into a staging table.&lt;/li&gt;\n&lt;li&gt;Downstream BI can use that staging table as a &amp;#39;mirrored&amp;#39; source of truth from the SAAS platform.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Why four*? Contingency. If an EL fails, it can fail for 4 cycles before we need manual intervention.&lt;/p&gt;\n\n&lt;p&gt;Am I overcomplicating this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bkiai1", "is_robot_indexable": true, "report_reasons": null, "author": "wiktor1800", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkiai1/extracting_from_api_strategy_what_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkiai1/extracting_from_api_strategy_what_to_do/", "subreddit_subscribers": 170793, "created_utc": 1711057173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I was wondering if yall can explain the difference between data analyst and business intelligence analyst. From the job descriptions, they seem really similar. ", "author_fullname": "t2_y1h3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between DA and BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkeojr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711048312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I was wondering if yall can explain the difference between data analyst and business intelligence analyst. From the job descriptions, they seem really similar. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bkeojr", "is_robot_indexable": true, "report_reasons": null, "author": "xloserr", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkeojr/difference_between_da_and_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkeojr/difference_between_da_and_bi/", "subreddit_subscribers": 170793, "created_utc": 1711048312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "AI is almost like a buzz word these days and I understand hopelessly little. What should I read to get up to speed? Ideally related to data engineering. ", "author_fullname": "t2_da8v38boh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to read to get up to speed with AI? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkd6t0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711044665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AI is almost like a buzz word these days and I understand hopelessly little. What should I read to get up to speed? Ideally related to data engineering. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bkd6t0", "is_robot_indexable": true, "report_reasons": null, "author": "Cultural-Ideal-7924", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkd6t0/what_to_read_to_get_up_to_speed_with_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkd6t0/what_to_read_to_get_up_to_speed_with_ai/", "subreddit_subscribers": 170793, "created_utc": 1711044665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "    FROM python:3.10.6-slim-buster\n    \n    WORKDIR /orchestration\n    \n    COPY . /orchestration\n    \n    RUN apt-get update \\\n        &amp;&amp; apt-get -y install libpq-dev gcc \\\n        &amp;&amp; pip install psycopg2 \\\n        &amp;&amp; pip install --no-cache-dir -r requirements.txt\n    \n    EXPOSE 4200\n    \n    # Run the Python application\n    ENTRYPOINT [\"python\", \"data_orchestration/staging_workloads/main.py\"]\n    RUN prefect server start\n\nI can't build the docker image because it gets stuck in the \"prefect server start\" endlessly. I've seen other repos and I think there is nothing wrong with my code.\n\n&amp;#x200B;\n\nCan you please help me?", "author_fullname": "t2_a9360hkx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help deploying prefect to EC2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk78d2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711029686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;FROM python:3.10.6-slim-buster\n\nWORKDIR /orchestration\n\nCOPY . /orchestration\n\nRUN apt-get update \\\n    &amp;amp;&amp;amp; apt-get -y install libpq-dev gcc \\\n    &amp;amp;&amp;amp; pip install psycopg2 \\\n    &amp;amp;&amp;amp; pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 4200\n\n# Run the Python application\nENTRYPOINT [&amp;quot;python&amp;quot;, &amp;quot;data_orchestration/staging_workloads/main.py&amp;quot;]\nRUN prefect server start\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I can&amp;#39;t build the docker image because it gets stuck in the &amp;quot;prefect server start&amp;quot; endlessly. I&amp;#39;ve seen other repos and I think there is nothing wrong with my code.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you please help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk78d2", "is_robot_indexable": true, "report_reasons": null, "author": "Different_Fee6785", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk78d2/help_deploying_prefect_to_ec2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk78d2/help_deploying_prefect_to_ec2/", "subreddit_subscribers": 170793, "created_utc": 1711029686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, maybe you have faced this. I have to send some data to an endpoint where the batch size limit is 10k, we were doing ok using python on airflow (single core) but now the data size increased to 10M so it\u2019s taking too long because of the 1000s requests\n\nWe could use spark but I would like to avoid it (as 10M fits in one worker perfectly) but not sure how, not really used to python multi threading or how to implement on airflow ", "author_fullname": "t2_79l5nq82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paralelize requests to insert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk57gv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711023575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, maybe you have faced this. I have to send some data to an endpoint where the batch size limit is 10k, we were doing ok using python on airflow (single core) but now the data size increased to 10M so it\u2019s taking too long because of the 1000s requests&lt;/p&gt;\n\n&lt;p&gt;We could use spark but I would like to avoid it (as 10M fits in one worker perfectly) but not sure how, not really used to python multi threading or how to implement on airflow &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bk57gv", "is_robot_indexable": true, "report_reasons": null, "author": "Obvious-Phrase-657", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk57gv/paralelize_requests_to_insert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk57gv/paralelize_requests_to_insert/", "subreddit_subscribers": 170793, "created_utc": 1711023575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for information, documentation plus videos preferable in English Apache Doris. This is an upcoming field I am venturing to and would like to have as much info. as possible on the subject matter. ", "author_fullname": "t2_cxzdcift", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk50f2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711022912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for information, documentation plus videos preferable in English Apache Doris. This is an upcoming field I am venturing to and would like to have as much info. as possible on the subject matter. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bk50f2", "is_robot_indexable": true, "report_reasons": null, "author": "Lazy_Secret8626", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk50f2/apache_doris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk50f2/apache_doris/", "subreddit_subscribers": 170793, "created_utc": 1711022912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI\u2019m a Software Engineer and in this last month in my company I\u2019ve been working as a Data Engineer manipulating data and setting pipelines with Postgres, Airflow, ELK and Kafka.\nThe thing is I need learn more and get a certification to improve my early expertise.\n\nDo you guys know any cloud or platform certification the could be worth it for freshmen in the data engineering field?\n\nThanks in advance", "author_fullname": "t2_617m3t2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you guys know any online certification for junior engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk1j5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711008989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a Software Engineer and in this last month in my company I\u2019ve been working as a Data Engineer manipulating data and setting pipelines with Postgres, Airflow, ELK and Kafka.\nThe thing is I need learn more and get a certification to improve my early expertise.&lt;/p&gt;\n\n&lt;p&gt;Do you guys know any cloud or platform certification the could be worth it for freshmen in the data engineering field?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bk1j5e", "is_robot_indexable": true, "report_reasons": null, "author": "Moradisten", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk1j5e/do_you_guys_know_any_online_certification_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk1j5e/do_you_guys_know_any_online_certification_for/", "subreddit_subscribers": 170793, "created_utc": 1711008989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \nI am currently trying to run Spark through Docker as part of my learning journey. It's giving me a bit of a headache though. Therefore, here I am, asking for some knowledge I know I'm missing.\n\nThe goal: Get Spark UI to work in order to analyze how tasks are handled  \nPurpose: Get Spark to work as part of a larger Apache Airflow setup.\n\nProblems:\n\n* Not sure I understand the difference between a Spark Master and a standalone Spark Cluster that has access to Spark UI. Is the Spark Master UI a 1:1 functionality match for Spark UI? Is it something different altogether?\n* Not sure if using the bitnami version of the docker image is the best way forward. How do you set it up usually (or do you go for another version)?\n* What is not right in the way I set up my spark?\n* Is there a need for a Spark UI dedicated container?\n\nBonus round:\n\n* While exploring worker tasks I get hit with web addresses I can't access (either localhost/172.x.x.x type of networks or docker internal links). How can I work my way around that?  \nKubernetes seems to be a suggested solution but I am still unsure if I should go ahead and sink into that.\n\nIf anyone sees this and answers, it would make my day. Thank you very much! :)\n\nFor reference, this is a snippet under services of how I set it up:\n\n \n\n`spark-ui:`  \n `image: bitnami/spark:latest`  \n `environment:`  \n `# needs to be updated whenever I relocate the raspberry pi`  \n `SPARK_DRIVER_HOST: \"0.0.0.0\"`  \n `SPARK_DRIVER_BINDADDRESS: \"0.0.0.0\"`  \n `SPARK_MASTER: spark://spark-master:7077`  \n `MAIN_CLASS: Main`  \n `ports:`  \n`- \"4040:4040\"`  \n`- \"4041:8080\"`  \n `networks:`  \n`- spark-network`  \n   \n `spark-master:`  \n `image: bitnami/spark:latest`  \n `ports:`  \n`- \"9092:8080\"`  \n`- \"7077:7077\"`  \n`- \"4043:4040\"`  \n`- \"8998:8998\"`  \n`- \"8887:8888\"`  \n `networks:`  \n`- spark-network`  \n `spark-worker-1:`  \n `image: bitnami/spark:latest`  \n `depends_on:`  \n`- spark-master`  \n `environment:`  \n `SPARK_MODE: worker`  \n `SPARK_WORKER_CORES: 1`  \n `SPARK_WORKER_MEMORY: 4g`  \n `SPARK_MASTER_URL: spark://spark-master:7077`  \n `ports:`  \n`- \"8081:8081\"`  \n`- \"4042:4040\"`  \n `networks:`  \n`- spark-network`  \n `# # spark-worker-2:`  \n `# # \u00a0 \u00a0 image: apache/spark-py:latest`  \n `# # \u00a0 \u00a0 depends_on:`  \n `# # \u00a0 \u00a0 \u00a0 - spark-master`  \n `# # \u00a0 \u00a0 environment:`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_MODE: worker`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_CORES: 1`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_MEMORY: 4g`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_MASTER_URL: spark://spark-master:7077`  \n `# # \u00a0 \u00a0 networks:`  \n `# # \u00a0 \u00a0 \u00a0 - spark-network`  \n `# # \u00a0 \u00a0 ports:`  \n `# # \u00a0 \u00a0 \u00a0 - \"8082:8081\"`  \n `# # \u00a0 \u00a0 \u00a0 - \"4043:4040\"`  \n`volumes:`  \n `spark-data:`  \n `name: spark-data`  \n`networks:`  \n `spark-network:`  \n `name: spark-network`", "author_fullname": "t2_n75h7s91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark docker-compose questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk11x5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711006845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;br/&gt;\nI am currently trying to run Spark through Docker as part of my learning journey. It&amp;#39;s giving me a bit of a headache though. Therefore, here I am, asking for some knowledge I know I&amp;#39;m missing.&lt;/p&gt;\n\n&lt;p&gt;The goal: Get Spark UI to work in order to analyze how tasks are handled&lt;br/&gt;\nPurpose: Get Spark to work as part of a larger Apache Airflow setup.&lt;/p&gt;\n\n&lt;p&gt;Problems:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Not sure I understand the difference between a Spark Master and a standalone Spark Cluster that has access to Spark UI. Is the Spark Master UI a 1:1 functionality match for Spark UI? Is it something different altogether?&lt;/li&gt;\n&lt;li&gt;Not sure if using the bitnami version of the docker image is the best way forward. How do you set it up usually (or do you go for another version)?&lt;/li&gt;\n&lt;li&gt;What is not right in the way I set up my spark?&lt;/li&gt;\n&lt;li&gt;Is there a need for a Spark UI dedicated container?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Bonus round:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;While exploring worker tasks I get hit with web addresses I can&amp;#39;t access (either localhost/172.x.x.x type of networks or docker internal links). How can I work my way around that?&lt;br/&gt;\nKubernetes seems to be a suggested solution but I am still unsure if I should go ahead and sink into that.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If anyone sees this and answers, it would make my day. Thank you very much! :)&lt;/p&gt;\n\n&lt;p&gt;For reference, this is a snippet under services of how I set it up:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;spark-ui:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;image: bitnami/spark:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;environment:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# needs to be updated whenever I relocate the raspberry pi&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_DRIVER_HOST: &amp;quot;0.0.0.0&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_DRIVER_BINDADDRESS: &amp;quot;0.0.0.0&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_MASTER: spark://spark-master:7077&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;MAIN_CLASS: Main&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;ports:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4040:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4041:8080&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-network&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;spark-master:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;image: bitnami/spark:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;ports:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;9092:8080&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;7077:7077&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4043:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;8998:8998&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;8887:8888&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-network&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;spark-worker-1:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;image: bitnami/spark:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;depends_on:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-master&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;environment:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_MODE: worker&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_WORKER_CORES: 1&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_WORKER_MEMORY: 4g&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_MASTER_URL: spark://spark-master:7077&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;ports:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;8081:8081&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4042:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-network&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # spark-worker-2:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 image: apache/spark-py:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 depends_on:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - spark-master&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 environment:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_MODE: worker&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_CORES: 1&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_MEMORY: 4g&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_MASTER_URL: spark://spark-master:7077&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 networks:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - spark-network&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 ports:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - &amp;quot;8082:8081&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - &amp;quot;4043:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;volumes:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;spark-data:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;name: spark-data&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;spark-network:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;name: spark-network&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk11x5", "is_robot_indexable": true, "report_reasons": null, "author": "Cheeky-owlet", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk11x5/spark_dockercompose_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk11x5/spark_dockercompose_questions/", "subreddit_subscribers": 170793, "created_utc": 1711006845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nSo currently I'm building a deep learning model to detect &amp; classify some brain-tumors using CT images. The dataset I got was retrieved from Kaggle, and I'm trying to replicating a research paper using transfer learning from EfficientNet. However, I've been thinking that I want to do something with ELT the data from a more reliable source and came across the NCI portal for Imaging data commons. It appears that they do provide RESTful API for mining their data (which are open-access), so I've been wanting to create a pipeline for extracting, downloading them and use the data for my model instead. I did learn a very beginning tutorial about creating a data pipeline for this, so in my head it's these steps:\n\n1. Create a script to query and search for images using the API with the keywords I want, in this case, a specific brain-tumor types.\n2. Since this dataset might be large and complex, I need some place to store them so I'm thinking about using MongoDB or BigQuery?\n3. Then I'll build another script that fetches them down and run them through the model I'm building and output some prediction/classification.\n\nI wonder if that's a good approach or not, if you have any experiences regarding those topics, I would be extremely happy to learn and know! Thank you so much!", "author_fullname": "t2_yf059sf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Needs some feedbacks/advice on the feasibility of building a data pipeline for my deep learning project.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bkqnmn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711080871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;So currently I&amp;#39;m building a deep learning model to detect &amp;amp; classify some brain-tumors using CT images. The dataset I got was retrieved from Kaggle, and I&amp;#39;m trying to replicating a research paper using transfer learning from EfficientNet. However, I&amp;#39;ve been thinking that I want to do something with ELT the data from a more reliable source and came across the NCI portal for Imaging data commons. It appears that they do provide RESTful API for mining their data (which are open-access), so I&amp;#39;ve been wanting to create a pipeline for extracting, downloading them and use the data for my model instead. I did learn a very beginning tutorial about creating a data pipeline for this, so in my head it&amp;#39;s these steps:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a script to query and search for images using the API with the keywords I want, in this case, a specific brain-tumor types.&lt;/li&gt;\n&lt;li&gt;Since this dataset might be large and complex, I need some place to store them so I&amp;#39;m thinking about using MongoDB or BigQuery?&lt;/li&gt;\n&lt;li&gt;Then I&amp;#39;ll build another script that fetches them down and run them through the model I&amp;#39;m building and output some prediction/classification.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I wonder if that&amp;#39;s a good approach or not, if you have any experiences regarding those topics, I would be extremely happy to learn and know! Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bkqnmn", "is_robot_indexable": true, "report_reasons": null, "author": "immikey0299", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkqnmn/needs_some_feedbacksadvice_on_the_feasibility_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkqnmn/needs_some_feedbacksadvice_on_the_feasibility_of/", "subreddit_subscribers": 170793, "created_utc": 1711080871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to connect my database to SQL Server with Apache Kafka, but I can't receive update messages to my Kafka topic. I would like to know if I should do anything additional when enabling CDC in my database", "author_fullname": "t2_4c4mn6nc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to enable CDC in SQL Server to implement Debezium connector?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkmpk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711068701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to connect my database to SQL Server with Apache Kafka, but I can&amp;#39;t receive update messages to my Kafka topic. I would like to know if I should do anything additional when enabling CDC in my database&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bkmpk7", "is_robot_indexable": true, "report_reasons": null, "author": "_thonyan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkmpk7/how_to_enable_cdc_in_sql_server_to_implement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkmpk7/how_to_enable_cdc_in_sql_server_to_implement/", "subreddit_subscribers": 170793, "created_utc": 1711068701.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}