{"kind": "Listing", "data": {"after": "t3_1bl203n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data analyst by profession and majority of the time I spend time in building power bi reports. One of the SQL database we get data from is getting deprecated and the client team moved the data to Azure data lake. The client just asked our team (IT services) to figure how do we setup the data pipelines (they suggested  synapse)\n\nBeing the individual contributor in project I sought help from my company  management for a data engineer to pitch in to set this up or at least guide, instead I got shamed that I should have figured everything by now and I shouldn't have accepted to synapse approach in first place. They kept on asking questions about the data lake storage which I don't have experience working on.\n\nAm I supposed to know data engineering as well, is it a bad move that I sought help as I don't have experience in data engineering. My management literally bullied me for saying I don't know data engineering. Am I wrong for not figuring it out, I know the data roles overlap but this was completely out of my expertise. Felt so bad and demotivated.\n\nEdited(added more details) - I have been highlighting this to the management for almost a month, They arranged a data engineer from another project to give a 30 minutes lecture on synapse and its possibilities and vanished from the scene. I needed more help which my company didnt want to accommodate as it didnt involve extra billing. Customer was not ready to give extra money citing  SOW. I took over the project 4 months back with the roles and responsibilities aligned to descriptive stats and dashboards.", "author_fullname": "t2_cg0kwbzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I learn data engineering? Got shamed in a team meeting.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bleg24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711156269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711152541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst by profession and majority of the time I spend time in building power bi reports. One of the SQL database we get data from is getting deprecated and the client team moved the data to Azure data lake. The client just asked our team (IT services) to figure how do we setup the data pipelines (they suggested  synapse)&lt;/p&gt;\n\n&lt;p&gt;Being the individual contributor in project I sought help from my company  management for a data engineer to pitch in to set this up or at least guide, instead I got shamed that I should have figured everything by now and I shouldn&amp;#39;t have accepted to synapse approach in first place. They kept on asking questions about the data lake storage which I don&amp;#39;t have experience working on.&lt;/p&gt;\n\n&lt;p&gt;Am I supposed to know data engineering as well, is it a bad move that I sought help as I don&amp;#39;t have experience in data engineering. My management literally bullied me for saying I don&amp;#39;t know data engineering. Am I wrong for not figuring it out, I know the data roles overlap but this was completely out of my expertise. Felt so bad and demotivated.&lt;/p&gt;\n\n&lt;p&gt;Edited(added more details) - I have been highlighting this to the management for almost a month, They arranged a data engineer from another project to give a 30 minutes lecture on synapse and its possibilities and vanished from the scene. I needed more help which my company didnt want to accommodate as it didnt involve extra billing. Customer was not ready to give extra money citing  SOW. I took over the project 4 months back with the roles and responsibilities aligned to descriptive stats and dashboards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bleg24", "is_robot_indexable": true, "report_reasons": null, "author": "urbanguy22", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bleg24/should_i_learn_data_engineering_got_shamed_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bleg24/should_i_learn_data_engineering_got_shamed_in_a/", "subreddit_subscribers": 171117, "created_utc": 1711152541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, r/dataengineering!   \n\nOver the last ten years, I've written tons of SQL and learned a few lessons. I [summarize them in a blog post.](https://ploomber.io/blog/sql/)\n\nA few things I discuss:   \n\n* When should I use Python/R over SQL? (and vice versa)   \n* How to write clean SQL queries   \n* How to document queries   \n* Auto-formatting   \n* Debugging   \n* Templating   \n* Testing   \n\nI hope you enjoy it!   ", "author_fullname": "t2_40t1gisl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing effective SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl3n3r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 85, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 85, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711125480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!   &lt;/p&gt;\n\n&lt;p&gt;Over the last ten years, I&amp;#39;ve written tons of SQL and learned a few lessons. I &lt;a href=\"https://ploomber.io/blog/sql/\"&gt;summarize them in a blog post.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A few things I discuss:   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When should I use Python/R over SQL? (and vice versa)&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;How to write clean SQL queries&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;How to document queries&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Auto-formatting&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Debugging&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Templating&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Testing&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I hope you enjoy it!   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bl3n3r", "is_robot_indexable": true, "report_reasons": null, "author": "databot_", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl3n3r/writing_effective_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl3n3r/writing_effective_sql/", "subreddit_subscribers": 171117, "created_utc": 1711125480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa5dw92do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Not Run a $12,000 Query on Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl1j5k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/1GdweO6OB9ixjhp8vNoJ6q3DSS5mwdjQRrMEannJoi8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711120159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "baselit.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://baselit.ai/blog/how-to-not-run-a-12-000-query-on-snowflake", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?auto=webp&amp;s=a1c6f18447dde18e1ebf0c54186ad305832ea3f2", "width": 4096, "height": 2731}, "resolutions": [{"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2858a576acfd1407493a054435451b9025b7cdd2", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3743c9c263eb0397467d04d255c76ea2958ee919", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=303361fad79d3a329688add4d0e7caf55c8aed4e", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f0c149c09a357a63edb8173e0729a334d0f6d69", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffb74d66c8ea2f7d508ac778344d8092031e26b1", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/7SBt48cgQXAL30En_lDW9_joyuoEunbKAdVESu6zQJg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17c53c9a6403761ce98c71b3802e595205ede32f", "width": 1080, "height": 720}], "variants": {}, "id": "BzltQecOGowQaXLG7pSLGEO_CMpQbsWKE1efbZI8up4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bl1j5k", "is_robot_indexable": true, "report_reasons": null, "author": "sahil_singla", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl1j5k/how_to_not_run_a_12000_query_on_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://baselit.ai/blog/how-to-not-run-a-12-000-query-on-snowflake", "subreddit_subscribers": 171117, "created_utc": 1711120159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to hear about the Databricks projects that pushed the limits. Enough with the medallion architecture and simple ETL/ELT demos...", "author_fullname": "t2_3tzpeuhd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Share your Databricks war stories: What were your toughest use cases/projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bky3mv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711110665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to hear about the Databricks projects that pushed the limits. Enough with the medallion architecture and simple ETL/ELT demos...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bky3mv", "is_robot_indexable": true, "report_reasons": null, "author": "randomusicjunkie", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bky3mv/share_your_databricks_war_stories_what_were_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bky3mv/share_your_databricks_war_stories_what_were_your/", "subreddit_subscribers": 171117, "created_utc": 1711110665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ttr4u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafbat UI for Apache Kafka v1.0 is out!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkzmhm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/05kD2p_pWfJr-IigG2Fge1Vmk5GjbuF7hUBBMk0Imaw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711115180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/kafbat/kafka-ui/releases/tag/v1.0.0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?auto=webp&amp;s=bc937b62e21690f6720517607ea4c0a209743e21", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ea26a819ae59cc24c216fb7791b7c9649d85dde", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc472d2d1ea3dd1d589a053d0ee27e236915545d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2841154d2c8eb11266025cdcab9c992447e6fe5b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4376484e5ea4012782073d754caae178a069693f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=62bf5dc0e3422533120ae230bb5af5f8e36b5eab", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/bUp5P3_PUyhrpNYB1Si_-78Y1dwhKOgTjipd6HmzH5I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0669f1e58cf3b62e2e35f01202d76e947bded301", "width": 1080, "height": 540}], "variants": {}, "id": "DhM3cmUsbInNpFXOIBOdyOHnwT20L_SpF0eRBJFiok8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bkzmhm", "is_robot_indexable": true, "report_reasons": null, "author": "Haarolean", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkzmhm/kafbat_ui_for_apache_kafka_v10_is_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/kafbat/kafka-ui/releases/tag/v1.0.0", "subreddit_subscribers": 171117, "created_utc": 1711115180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI\u2019m starting a job where I have to extract json files from API and then put the data in azure SQL DB.\n\nI was thinking on running the scripts on VM and setting the API key as environment variable, but would like best practices when it comes to similar scenarios?\n\n\n", "author_fullname": "t2_8b259b71", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extract data from API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl0iho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711117519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m starting a job where I have to extract json files from API and then put the data in azure SQL DB.&lt;/p&gt;\n\n&lt;p&gt;I was thinking on running the scripts on VM and setting the API key as environment variable, but would like best practices when it comes to similar scenarios?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bl0iho", "is_robot_indexable": true, "report_reasons": null, "author": "andreeva_2", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl0iho/extract_data_from_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl0iho/extract_data_from_api/", "subreddit_subscribers": 171117, "created_utc": 1711117519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.\n\nOn the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. \n\nI started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. \n\nAnother problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets \n\nWe do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. \n\nIm expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis\n\nIhv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. \n", "author_fullname": "t2_83gq3oxts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google sheets \u2014-&gt; ???? \u2014\u2014-&gt; PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bliedv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711166291.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711164059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.&lt;/p&gt;\n\n&lt;p&gt;On the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. &lt;/p&gt;\n\n&lt;p&gt;I started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. &lt;/p&gt;\n\n&lt;p&gt;Another problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets &lt;/p&gt;\n\n&lt;p&gt;We do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. &lt;/p&gt;\n\n&lt;p&gt;Im expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis&lt;/p&gt;\n\n&lt;p&gt;Ihv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bliedv", "is_robot_indexable": true, "report_reasons": null, "author": "FigTraditional1201", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "subreddit_subscribers": 171117, "created_utc": 1711164059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Atscale is not pulling any punches here about the limitations of Fabric when it comes to Power BI + big data.\n\n  \nBased on their report, their CTO and founder is saying that its a half-baked solution for large workloads. It might work with smaller data sets, but it falls flat (query performance &amp; timeouts) after 100+ GBs of data if you are using the Direct Lake interface.\n\n  \nIs anyone else running into these types of scalability challenges?\n\n  \n[https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/](https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/)", "author_fullname": "t2_tm7h4ttv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone using PowerBI + Fabric at an Enterprise Scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl8vbz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711138359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Atscale is not pulling any punches here about the limitations of Fabric when it comes to Power BI + big data.&lt;/p&gt;\n\n&lt;p&gt;Based on their report, their CTO and founder is saying that its a half-baked solution for large workloads. It might work with smaller data sets, but it falls flat (query performance &amp;amp; timeouts) after 100+ GBs of data if you are using the Direct Lake interface.&lt;/p&gt;\n\n&lt;p&gt;Is anyone else running into these types of scalability challenges?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/\"&gt;https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?auto=webp&amp;s=ef0167fbc5df2624b364f3d35bc4868f14fac173", "width": 2048, "height": 1072}, "resolutions": [{"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=584825f0568b23db2c7f4a7f7aa761f044b8e671", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e92d06480e6e2d7c0cb05c1213908d59bbb80dbe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34433847663248873a7618e96a8c37c00c9184e1", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10dc1855235265aca1ee21174ea3ce5522330112", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a2de35d1299a6a3849b4b0a88932ba631a7302bb", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=81a76fab2c2e71a702f63cad6157ee0b26d55dde", "width": 1080, "height": 565}], "variants": {}, "id": "dsus145I8c2mn6MwIGR4yyru8X7lKi3WqnbhPCocRUg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bl8vbz", "is_robot_indexable": true, "report_reasons": null, "author": "ProgramFriendly6608", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl8vbz/is_anyone_using_powerbi_fabric_at_an_enterprise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl8vbz/is_anyone_using_powerbi_fabric_at_an_enterprise/", "subreddit_subscribers": 171117, "created_utc": 1711138359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?", "author_fullname": "t2_wksnouv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you when your organization gives you scripts or tasks from exemployees in a language you don\u2019t really understand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blke3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711175205.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711170679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blke3g", "is_robot_indexable": true, "report_reasons": null, "author": "Ivan_GL7", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "subreddit_subscribers": 171117, "created_utc": 1711170679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\n\nI have been struggling for hours to get this simple real-time streaming feature to work and desperately need some help.  \n\n\nI am trying to achieve a real-time streaming application with Spark Structured Streaming to calculate the average value of power aggregated over the latest minute. So say if the time now is 18:15:00, I only want the application to write the average value calculated between 18:14:00 - 18:15:00 to the console. The frequency to write to console is set to 10 seconds and it should only output the MOST UPDATED averaged value.  \n\n\nThis is the simplified code: \n\n    aggregated_df = input_df \\\n        .groupBy(\n            F.window(\"engine_time\", \"60 seconds\", \"10 seconds\"),\n        ).agg(\n            F.format_number(F.avg(\"power\"), 2)\n    \u00a0 \u00a0 )\n    \n    # Some more transformation\n    \n    output = res_df.writeStream \\\n    \u00a0   .outputMode(\"update\") \\\n    \u00a0   .format(\"console\") \\\n    \u00a0 \u00a0 .option(\"truncate\", False) \\\n    \u00a0   .trigger(processingTime='10 seconds') \\\n    \u00a0 \u00a0 .start()\n\nThe problem with this is that the averaging window depends on the event time (i.e. engine\\_time) instead of the actual time now. The engine\\_time can sometimes be delayed. If it's 15 seconds delayed, the whole averaging window will be shifted by the same amount.  \n\n\nIf the outputMode is set to \"complete\", all past rows are shown which is not helpful.\n\nIf the outputMode is set to \"update\", it will show the 10-second-window rows that are updated which is not helpful either.\n\nIf the outputMode is set to \"append\", it will show 1 row at a time which is good but there is a 10 seconds delay.  \n\n\nHOW DO I GET IT TO FREAKING WORK!!?!?\n\nAny help much appreciated!\n\n&amp;#x200B;\n\nNOTE: Late data can be completely ignored which is why I am not using watermark.", "author_fullname": "t2_e6ol6ewl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cannot realtime streaming with Spark Structured Streaming!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl73gj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711134017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I have been struggling for hours to get this simple real-time streaming feature to work and desperately need some help.  &lt;/p&gt;\n\n&lt;p&gt;I am trying to achieve a real-time streaming application with Spark Structured Streaming to calculate the average value of power aggregated over the latest minute. So say if the time now is 18:15:00, I only want the application to write the average value calculated between 18:14:00 - 18:15:00 to the console. The frequency to write to console is set to 10 seconds and it should only output the MOST UPDATED averaged value.  &lt;/p&gt;\n\n&lt;p&gt;This is the simplified code: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;aggregated_df = input_df \\\n    .groupBy(\n        F.window(&amp;quot;engine_time&amp;quot;, &amp;quot;60 seconds&amp;quot;, &amp;quot;10 seconds&amp;quot;),\n    ).agg(\n        F.format_number(F.avg(&amp;quot;power&amp;quot;), 2)\n\u00a0 \u00a0 )\n\n# Some more transformation\n\noutput = res_df.writeStream \\\n\u00a0   .outputMode(&amp;quot;update&amp;quot;) \\\n\u00a0   .format(&amp;quot;console&amp;quot;) \\\n\u00a0 \u00a0 .option(&amp;quot;truncate&amp;quot;, False) \\\n\u00a0   .trigger(processingTime=&amp;#39;10 seconds&amp;#39;) \\\n\u00a0 \u00a0 .start()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The problem with this is that the averaging window depends on the event time (i.e. engine_time) instead of the actual time now. The engine_time can sometimes be delayed. If it&amp;#39;s 15 seconds delayed, the whole averaging window will be shifted by the same amount.  &lt;/p&gt;\n\n&lt;p&gt;If the outputMode is set to &amp;quot;complete&amp;quot;, all past rows are shown which is not helpful.&lt;/p&gt;\n\n&lt;p&gt;If the outputMode is set to &amp;quot;update&amp;quot;, it will show the 10-second-window rows that are updated which is not helpful either.&lt;/p&gt;\n\n&lt;p&gt;If the outputMode is set to &amp;quot;append&amp;quot;, it will show 1 row at a time which is good but there is a 10 seconds delay.  &lt;/p&gt;\n\n&lt;p&gt;HOW DO I GET IT TO FREAKING WORK!!?!?&lt;/p&gt;\n\n&lt;p&gt;Any help much appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;NOTE: Late data can be completely ignored which is why I am not using watermark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bl73gj", "is_robot_indexable": true, "report_reasons": null, "author": "rpi_hy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl73gj/cannot_realtime_streaming_with_spark_structured/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl73gj/cannot_realtime_streaming_with_spark_structured/", "subreddit_subscribers": 171117, "created_utc": 1711134017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently I found myself having to try find the causes of slowness in an AWS Glue Spark job. Eventually I landed on a stage that had 99% skew (see screenshot).\n\nhttps://preview.redd.it/pb4bgm4zywpc1.png?width=1884&amp;format=png&amp;auto=webp&amp;s=8aa8e7c3c8da88bcf751f3278b6e9b73432c852c\n\nIt's my first time having to dig this deep into Spark so I was a bit out of my depth. The job itself also didn't help, because it's basically a single step like this:\n\n    spark.sql(a_700_lines_sql_query)\n\nThe query isn't even that esoteric, but it joins many wide (and relatively long) tables, all at once at the end of it.\n\nBy looking at the DAG, I found out that this specific stage (which is also the longest one), happens in correspondence of one of those joins. Knowing that skews happen (also?) because of uneven distribution of partition keys, I've checked the join keys of the 2 involved tables, but found nothing dodgy.\n\nI'm a bit at a loss here so my question to you is: in general, how do you address situations of this kind?\n\nAssume that I can't touch the SQL query itself because it was written by another team we have no control over.", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you generally debug a heavy skew in a spark job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 24, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pb4bgm4zywpc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 18, "x": 108, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=470e9af5e2738244d53301f07f4c96121c4680d2"}, {"y": 37, "x": 216, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=143007123498fd7566145a6ab5955790fe287def"}, {"y": 55, "x": 320, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=240601d32ebdba4a55b4d5fbda38f898541a3aa1"}, {"y": 110, "x": 640, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9255adac2be8776555fb92c3b807164f607597d"}, {"y": 165, "x": 960, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f2ab7c648add162b32ae6095257f54b85f6c90a"}, {"y": 186, "x": 1080, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=93d098d50d8fe61de8e24e17453ef0a388a7babf"}], "s": {"y": 325, "x": 1884, "u": "https://preview.redd.it/pb4bgm4zywpc1.png?width=1884&amp;format=png&amp;auto=webp&amp;s=8aa8e7c3c8da88bcf751f3278b6e9b73432c852c"}, "id": "pb4bgm4zywpc1"}}, "name": "t3_1bl3z33", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tOprnMASS_NcqtfZkpRrjd_hKBoRPgG3py1YphXdlnw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711126302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently I found myself having to try find the causes of slowness in an AWS Glue Spark job. Eventually I landed on a stage that had 99% skew (see screenshot).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pb4bgm4zywpc1.png?width=1884&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8aa8e7c3c8da88bcf751f3278b6e9b73432c852c\"&gt;https://preview.redd.it/pb4bgm4zywpc1.png?width=1884&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8aa8e7c3c8da88bcf751f3278b6e9b73432c852c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s my first time having to dig this deep into Spark so I was a bit out of my depth. The job itself also didn&amp;#39;t help, because it&amp;#39;s basically a single step like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;spark.sql(a_700_lines_sql_query)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The query isn&amp;#39;t even that esoteric, but it joins many wide (and relatively long) tables, all at once at the end of it.&lt;/p&gt;\n\n&lt;p&gt;By looking at the DAG, I found out that this specific stage (which is also the longest one), happens in correspondence of one of those joins. Knowing that skews happen (also?) because of uneven distribution of partition keys, I&amp;#39;ve checked the join keys of the 2 involved tables, but found nothing dodgy.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit at a loss here so my question to you is: in general, how do you address situations of this kind?&lt;/p&gt;\n\n&lt;p&gt;Assume that I can&amp;#39;t touch the SQL query itself because it was written by another team we have no control over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bl3z33", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl3z33/how_would_you_generally_debug_a_heavy_skew_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl3z33/how_would_you_generally_debug_a_heavy_skew_in_a/", "subreddit_subscribers": 171117, "created_utc": 1711126302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a professional in automation testing, I've encountered a new requirement in my current project that necessitates learning Apache Airflow. I'm seeking high-quality references or courses that could guide me through this learning process. If you're aware of any resources, I would greatly appreciate your recommendations.", "author_fullname": "t2_3mhkzvqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find some good resources based on Apache Airflow? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blglio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711158625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a professional in automation testing, I&amp;#39;ve encountered a new requirement in my current project that necessitates learning Apache Airflow. I&amp;#39;m seeking high-quality references or courses that could guide me through this learning process. If you&amp;#39;re aware of any resources, I would greatly appreciate your recommendations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blglio", "is_robot_indexable": true, "report_reasons": null, "author": "aatish_tandel", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "subreddit_subscribers": 171117, "created_utc": 1711158625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company, we restrict certain tables to certain people in the company, depending on their clearance to see the tables.  \n\n\nWe have implemented IAM permissions at the table level. Say data engineer X should not see finance records, so he is not on the list of people who can view the tables.\n\nThe dilemma comes in when using service accounts. Airflow needs access to the tables for extraction and DBT for modelling. What's stopping engineer X from using such to gain access to the private tables?\n", "author_fullname": "t2_2gfm4wqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery IAM dilemma", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl0kxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711118975.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711117703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company, we restrict certain tables to certain people in the company, depending on their clearance to see the tables.  &lt;/p&gt;\n\n&lt;p&gt;We have implemented IAM permissions at the table level. Say data engineer X should not see finance records, so he is not on the list of people who can view the tables.&lt;/p&gt;\n\n&lt;p&gt;The dilemma comes in when using service accounts. Airflow needs access to the tables for extraction and DBT for modelling. What&amp;#39;s stopping engineer X from using such to gain access to the private tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bl0kxw", "is_robot_indexable": true, "report_reasons": null, "author": "5pitt4", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl0kxw/bigquery_iam_dilemma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl0kxw/bigquery_iam_dilemma/", "subreddit_subscribers": 171117, "created_utc": 1711117703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.\n\nNow I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. ", "author_fullname": "t2_4geyh6db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering with inefficient practices: What is your perspective on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blnf39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711182938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.&lt;/p&gt;\n\n&lt;p&gt;Now I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blnf39", "is_robot_indexable": true, "report_reasons": null, "author": "bloatedboat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "subreddit_subscribers": 171117, "created_utc": 1711182938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am having a little trouble understanding the tradeoffs between two dataprocessing methodologies.  I am not a data engineer by trade, and I am trying to understand the cases where different ETL approaches are warranted.\n\nSuppose I have a whole bunch of files that I want to process and then dump the output into a typical SQL db.  I want to understand the differences between deploying a cluster of pods and using ETL tools to process this data.\n\n&amp;#x200B;\n\n1) I can dump my processing code into a docker container and deploy the container in kubernetes to process the files in parallel.  Each pod would process a single file, upload the result to the table, and exit.\n\n2) I can use something like apache beam to define a pipeline with a single batch corresponding to a single input file (Is this true?).  Is there any advantage to going this route?  Will dataflow/Glue handle resource scaling for me, or is it pretty much the same as provisioning a kubernetes cluster?\n\n&amp;#x200B;\n\nI guess the final question is if I changed the input data - think one giant parquet file or an SQL database with all the data from the fragmented pieces in the first scenario as the input - is this where the batch processing approach with beam would really shine, or would I be better off in the original scenario with smaller pieces that are already broken up?", "author_fullname": "t2_a51is1rz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache beam (batch based processing) vs. docker + kubernetes cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blccwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711147137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am having a little trouble understanding the tradeoffs between two dataprocessing methodologies.  I am not a data engineer by trade, and I am trying to understand the cases where different ETL approaches are warranted.&lt;/p&gt;\n\n&lt;p&gt;Suppose I have a whole bunch of files that I want to process and then dump the output into a typical SQL db.  I want to understand the differences between deploying a cluster of pods and using ETL tools to process this data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1) I can dump my processing code into a docker container and deploy the container in kubernetes to process the files in parallel.  Each pod would process a single file, upload the result to the table, and exit.&lt;/p&gt;\n\n&lt;p&gt;2) I can use something like apache beam to define a pipeline with a single batch corresponding to a single input file (Is this true?).  Is there any advantage to going this route?  Will dataflow/Glue handle resource scaling for me, or is it pretty much the same as provisioning a kubernetes cluster?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess the final question is if I changed the input data - think one giant parquet file or an SQL database with all the data from the fragmented pieces in the first scenario as the input - is this where the batch processing approach with beam would really shine, or would I be better off in the original scenario with smaller pieces that are already broken up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blccwy", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Resist-54", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blccwy/apache_beam_batch_based_processing_vs_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blccwy/apache_beam_batch_based_processing_vs_docker/", "subreddit_subscribers": 171117, "created_utc": 1711147137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have a unique case where I cannot find much information on how to architect or provide a good enough solution (which may be due to **how** I am looking for a solution). Most if not all of my background comes from the standard BI/analytics/internal use case DE, and I'm presently working in an environment where DE supports a product itself.\n\nEssentially, we have the following requirements:\n\n1.) Dynamic DAG generation, taking the data and either aggregating it further into a very denormalized structure and then also into OLTP to be consumed by an RDS instance. By dynamic, I mean that the tables created in the database follow a DAG generated by variables passed plus a configuration template. So if customer XYZ signed up, we would create table \"agg\\_XYZ\\_stuff\".\n\n2.) Multi-tenant (customer) DAG execution, where the DAG executions need to be separated by the specific customer, So from the first requirement, customer XYZ's DAG would execute on an interval set by their timezone (likely daily batch, but again, by their timezone).\n\n3.) As little human involvement beyond the config files or templates. Trying to stay away from manually having to create customer specific files/tables/models in order for \"agg\\_XYZ\\_stuff\" to exist. \n\nMost of my recent experience is using dbt-core, Meltano+Dagster, GBQ/Snowflake, but this is a whole new beast to begin with. I know that dbt can support pre-post hooks, but I don't know if it could handle the complexity of generating new models at runtime without invoking a PR to manually create the models. It seems to me that this kind of work falls under \"software engineer, data\" type work.\n\nAny advice is very much appreciated.  ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-tenant dynamic DAG options for a series of requirements?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blao2n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711142888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a unique case where I cannot find much information on how to architect or provide a good enough solution (which may be due to &lt;strong&gt;how&lt;/strong&gt; I am looking for a solution). Most if not all of my background comes from the standard BI/analytics/internal use case DE, and I&amp;#39;m presently working in an environment where DE supports a product itself.&lt;/p&gt;\n\n&lt;p&gt;Essentially, we have the following requirements:&lt;/p&gt;\n\n&lt;p&gt;1.) Dynamic DAG generation, taking the data and either aggregating it further into a very denormalized structure and then also into OLTP to be consumed by an RDS instance. By dynamic, I mean that the tables created in the database follow a DAG generated by variables passed plus a configuration template. So if customer XYZ signed up, we would create table &amp;quot;agg_XYZ_stuff&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;2.) Multi-tenant (customer) DAG execution, where the DAG executions need to be separated by the specific customer, So from the first requirement, customer XYZ&amp;#39;s DAG would execute on an interval set by their timezone (likely daily batch, but again, by their timezone).&lt;/p&gt;\n\n&lt;p&gt;3.) As little human involvement beyond the config files or templates. Trying to stay away from manually having to create customer specific files/tables/models in order for &amp;quot;agg_XYZ_stuff&amp;quot; to exist. &lt;/p&gt;\n\n&lt;p&gt;Most of my recent experience is using dbt-core, Meltano+Dagster, GBQ/Snowflake, but this is a whole new beast to begin with. I know that dbt can support pre-post hooks, but I don&amp;#39;t know if it could handle the complexity of generating new models at runtime without invoking a PR to manually create the models. It seems to me that this kind of work falls under &amp;quot;software engineer, data&amp;quot; type work.&lt;/p&gt;\n\n&lt;p&gt;Any advice is very much appreciated.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blao2n", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blao2n/multitenant_dynamic_dag_options_for_a_series_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blao2n/multitenant_dynamic_dag_options_for_a_series_of/", "subreddit_subscribers": 171117, "created_utc": 1711142888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to move up in the ranks at my current organization to the next level. Therefore, I need to further my knowledge in the data engineering topic; in regards to system design. I am looking for good courses that teach system design for data engineering related systems/applications. Can anyone recommend me a good course to pursue on sites like Udemy, Coursera, Pluralsight, etc? I have a background in DevOps, so I am experienced with some engineering (automation, CI/CD, scripting, etc.) Thank you in advance!", "author_fullname": "t2_100mg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Courses for Data Engineering System Design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl90gl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711138726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to move up in the ranks at my current organization to the next level. Therefore, I need to further my knowledge in the data engineering topic; in regards to system design. I am looking for good courses that teach system design for data engineering related systems/applications. Can anyone recommend me a good course to pursue on sites like Udemy, Coursera, Pluralsight, etc? I have a background in DevOps, so I am experienced with some engineering (automation, CI/CD, scripting, etc.) Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bl90gl", "is_robot_indexable": true, "report_reasons": null, "author": "-DropTheMike-", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl90gl/best_courses_for_data_engineering_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl90gl/best_courses_for_data_engineering_system_design/", "subreddit_subscribers": 171117, "created_utc": 1711138726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the pros and cons of using tools like Starburst and Dremio for data virtualization when the data sources are on prem or cloud relational databases? Can MPP help with such sources in any way or will it just act as performance bottleneck? Anyone has any experience with such setup?", "author_fullname": "t2_k1sl1lu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data mesh/ virtualization using tools like Starburst and Dremio for data virtualization when the data sources are on prem or cloud relational databases? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl39nc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711124549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the pros and cons of using tools like Starburst and Dremio for data virtualization when the data sources are on prem or cloud relational databases? Can MPP help with such sources in any way or will it just act as performance bottleneck? Anyone has any experience with such setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bl39nc", "is_robot_indexable": true, "report_reasons": null, "author": "SeriousShoppr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl39nc/data_mesh_virtualization_using_tools_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl39nc/data_mesh_virtualization_using_tools_like/", "subreddit_subscribers": 171117, "created_utc": 1711124549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your take on AI plug-ins for Databases ? Do you use it regularly and has it improved productivity? \n", "author_fullname": "t2_aryc45smm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI plugins for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1blph0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711191346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your take on AI plug-ins for Databases ? Do you use it regularly and has it improved productivity? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blph0c", "is_robot_indexable": true, "report_reasons": null, "author": "Paperplaneflyr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blph0c/ai_plugins_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blph0c/ai_plugins_for_de/", "subreddit_subscribers": 171117, "created_utc": 1711191346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included *courses, seminars, workcenters, associations, conferences, certifications, \u2026* and the like, without any particular budget, where would you start looking?\n\nI\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? \n\nI have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.\n\nFor context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026\n\nMore recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.\n\n\nWhat do you think? Thanks for any input. ", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you allocate an (positively) ambiguously capped professional development budget?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blhvrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711163283.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711162450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included &lt;em&gt;courses, seminars, workcenters, associations, conferences, certifications, \u2026&lt;/em&gt; and the like, without any particular budget, where would you start looking?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? &lt;/p&gt;\n\n&lt;p&gt;I have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.&lt;/p&gt;\n\n&lt;p&gt;For context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026&lt;/p&gt;\n\n&lt;p&gt;More recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Thanks for any input. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blhvrx", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "subreddit_subscribers": 171117, "created_utc": 1711162450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I interviewed for a law firm that had consultants build a data warehouse for them. It isn't exactly clear to me what the law firm is doing and my questions in the first round didn't uncover much. I do know they are using azure synapse and power bi for visualizations. They want me to improve the efficiency of existing pipelines and bring in more information. I plan to ask how much bi work will be expected of the role. Can you help me think of other questions to figure out if this role will help me level up technically? The pay would be a significant increase per the recruiter, but I'm very wary of what I'll be doing. Thanks for the help.\n\nfor contrast in my current position i work in python, airflow, and sql in an Oracle on prem database. We are moving to Snowflake but that isn't being handled by my team. I'll have an opportunity to work in snowflake. I am looking for a position that will allow me to use a cloud platform, maybe databricks, and work within a modern data team.", "author_fullname": "t2_f1q7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me ask questions about the tech stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blfxnq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711177523.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711156689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I interviewed for a law firm that had consultants build a data warehouse for them. It isn&amp;#39;t exactly clear to me what the law firm is doing and my questions in the first round didn&amp;#39;t uncover much. I do know they are using azure synapse and power bi for visualizations. They want me to improve the efficiency of existing pipelines and bring in more information. I plan to ask how much bi work will be expected of the role. Can you help me think of other questions to figure out if this role will help me level up technically? The pay would be a significant increase per the recruiter, but I&amp;#39;m very wary of what I&amp;#39;ll be doing. Thanks for the help.&lt;/p&gt;\n\n&lt;p&gt;for contrast in my current position i work in python, airflow, and sql in an Oracle on prem database. We are moving to Snowflake but that isn&amp;#39;t being handled by my team. I&amp;#39;ll have an opportunity to work in snowflake. I am looking for a position that will allow me to use a cloud platform, maybe databricks, and work within a modern data team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1blfxnq", "is_robot_indexable": true, "report_reasons": null, "author": "machinegunke11y", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blfxnq/help_me_ask_questions_about_the_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blfxnq/help_me_ask_questions_about_the_tech_stack/", "subreddit_subscribers": 171117, "created_utc": 1711156689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm inheriting a system that is all buckets and functions with an SQL flavor for running queries. There are a few VMs for some persistent jobs. Are there any tools that would help this system with observability, maintenance, extension, and reliability? It's more data heavy then it is compute heavy.  \nThanks for your thoughts.", "author_fullname": "t2_3lqaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "buckets of blobs and cloudy functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blbtxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711145801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m inheriting a system that is all buckets and functions with an SQL flavor for running queries. There are a few VMs for some persistent jobs. Are there any tools that would help this system with observability, maintenance, extension, and reliability? It&amp;#39;s more data heavy then it is compute heavy.&lt;br/&gt;\nThanks for your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blbtxo", "is_robot_indexable": true, "report_reasons": null, "author": "Someoneoldbutnew", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blbtxo/buckets_of_blobs_and_cloudy_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blbtxo/buckets_of_blobs_and_cloudy_functions/", "subreddit_subscribers": 171117, "created_utc": 1711145801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, im a mineral processing engineer and i want to learn where can i use data and ai engineering in my field.\n\n\u0130n mineral processing, we are crushing, grinding,  hydrometallurgically and pyrometallurgically enchanting the raw ore. \n\nWe are currently using USIM PAC and minitab for predicting plant feed and concentrate.\n\nThank you.", "author_fullname": "t2_4j6plq2q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The usage of data eng. in mineral processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bkxj2n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711108781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, im a mineral processing engineer and i want to learn where can i use data and ai engineering in my field.&lt;/p&gt;\n\n&lt;p&gt;\u0130n mineral processing, we are crushing, grinding,  hydrometallurgically and pyrometallurgically enchanting the raw ore. &lt;/p&gt;\n\n&lt;p&gt;We are currently using USIM PAC and minitab for predicting plant feed and concentrate.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bkxj2n", "is_robot_indexable": true, "report_reasons": null, "author": "Designer_Nebula", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bkxj2n/the_usage_of_data_eng_in_mineral_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bkxj2n/the_usage_of_data_eng_in_mineral_processing/", "subreddit_subscribers": 171117, "created_utc": 1711108781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For several years now, while reading Hacker News and Xitter every day, I've been collecting lots of tools, projects and technical blog posts to \"try out later\". Most of them are never used, or stop being developed.\n\nBut quite a few end up resurfacing, or being useful for new projects I start.\n\n**What do you use to keep track of these things you want to check out later?**\n\nBookmarking services is the usual answer, but I don't feel like they're good enough. I want something that can extract the value prop when you save it, and ideally auto-categorise it.\n\nDesigners have a ton of options like https://eagle.cool. Is there something similar for tech / data tools?", "author_fullname": "t2_5gn9soxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you tracking all tooling / technolgies to check out later?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl26ct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711121808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For several years now, while reading Hacker News and Xitter every day, I&amp;#39;ve been collecting lots of tools, projects and technical blog posts to &amp;quot;try out later&amp;quot;. Most of them are never used, or stop being developed.&lt;/p&gt;\n\n&lt;p&gt;But quite a few end up resurfacing, or being useful for new projects I start.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What do you use to keep track of these things you want to check out later?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Bookmarking services is the usual answer, but I don&amp;#39;t feel like they&amp;#39;re good enough. I want something that can extract the value prop when you save it, and ideally auto-categorise it.&lt;/p&gt;\n\n&lt;p&gt;Designers have a ton of options like &lt;a href=\"https://eagle.cool\"&gt;https://eagle.cool&lt;/a&gt;. Is there something similar for tech / data tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?auto=webp&amp;s=9d452566e6873937a58d779770a93a0d3de0f739", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8359702cb078eb2ef571382803201cf7be843e7f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=70698e8f4a65115908ba9272e68a81071b888abd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1cb9951af2441d184ce3714ae8fa1ee5b036b539", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bfe7dc5dbf5ca1c12c135e3ba3a17cb9e6d32641", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a1c7bfa9a9a814536ee7885b7b8afa25f8b9e1fa", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/XcQJkAJVH-mM1C5DjR7J3GNcHXfQBrjH8aR89-_P0p0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=13a2e89d789f71debdf3dfe05f4044aeb1294d4e", "width": 1080, "height": 567}], "variants": {}, "id": "KWS-lipuruUrdb82lBAtSXc0yvZE6D1eDrWRGnBV5kc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bl26ct", "is_robot_indexable": true, "report_reasons": null, "author": "ResponsibleYou7", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl26ct/how_are_you_tracking_all_tooling_technolgies_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl26ct/how_are_you_tracking_all_tooling_technolgies_to/", "subreddit_subscribers": 171117, "created_utc": 1711121808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! How's it going?  \nThis project involves integrating the company's business areas with Data Engineering, where we'll map out opportunities for digitizing and automating databases. This ensures that all company sectors maintain data quality, security, and operational efficiency.  \nThe company utilizes various data sources; some departments use Excel spreadsheets, others rely on SharePoint, and some utilize our database system.\n\nTo clarify our infrastructure:\n\n* DataBricks:  Database construction\n* Data Lake:  Storage for completed databases\n* Data Factory:  Automation of our code\n\nI've mapped some things that i found useful like:\n\n1st Phase: Define how many areas we have, which one will be chosen and who we will talk to\n\n  \n2nd Phase: Define standard processes to be used in all areas\n\n* Interviews with key employees for development.\n* Documentation\n\n3rd Phase: Opportunity mapping\n\n* Mapped opportunities\n* Future opportunities\n* Prioritized opportunities \n\n4th Phase: Development\n\n* Develop\n* Validate\n* Quality Assurance\n* Implement\n* Clone\n* Document \n\n5th Phase: Final evaluation and improvements for the next ones\n\n* Stakeholder evaluation and feedback\n* Observations (How to improve?, Errors encountered, Continue what worked well)\n\nConsidering this, I'd like to draw from your experience: What actions can we take to ensure success in this project? We're grappling with how to initiate, execute, and conclude it.\n\nI welcome any comments or insights. Thanks for your time and assistance!", "author_fullname": "t2_92l760sy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategies for Identifying and Migrating Databases to a Data Engineering Structure.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl203n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711123006.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711121379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! How&amp;#39;s it going?&lt;br/&gt;\nThis project involves integrating the company&amp;#39;s business areas with Data Engineering, where we&amp;#39;ll map out opportunities for digitizing and automating databases. This ensures that all company sectors maintain data quality, security, and operational efficiency.&lt;br/&gt;\nThe company utilizes various data sources; some departments use Excel spreadsheets, others rely on SharePoint, and some utilize our database system.&lt;/p&gt;\n\n&lt;p&gt;To clarify our infrastructure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DataBricks:  Database construction&lt;/li&gt;\n&lt;li&gt;Data Lake:  Storage for completed databases&lt;/li&gt;\n&lt;li&gt;Data Factory:  Automation of our code&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve mapped some things that i found useful like:&lt;/p&gt;\n\n&lt;p&gt;1st Phase: Define how many areas we have, which one will be chosen and who we will talk to&lt;/p&gt;\n\n&lt;p&gt;2nd Phase: Define standard processes to be used in all areas&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Interviews with key employees for development.&lt;/li&gt;\n&lt;li&gt;Documentation&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;3rd Phase: Opportunity mapping&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mapped opportunities&lt;/li&gt;\n&lt;li&gt;Future opportunities&lt;/li&gt;\n&lt;li&gt;Prioritized opportunities &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;4th Phase: Development&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Develop&lt;/li&gt;\n&lt;li&gt;Validate&lt;/li&gt;\n&lt;li&gt;Quality Assurance&lt;/li&gt;\n&lt;li&gt;Implement&lt;/li&gt;\n&lt;li&gt;Clone&lt;/li&gt;\n&lt;li&gt;Document &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;5th Phase: Final evaluation and improvements for the next ones&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Stakeholder evaluation and feedback&lt;/li&gt;\n&lt;li&gt;Observations (How to improve?, Errors encountered, Continue what worked well)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Considering this, I&amp;#39;d like to draw from your experience: What actions can we take to ensure success in this project? We&amp;#39;re grappling with how to initiate, execute, and conclude it.&lt;/p&gt;\n\n&lt;p&gt;I welcome any comments or insights. Thanks for your time and assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bl203n", "is_robot_indexable": true, "report_reasons": null, "author": "HotDouguinho", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl203n/strategies_for_identifying_and_migrating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl203n/strategies_for_identifying_and_migrating/", "subreddit_subscribers": 171117, "created_utc": 1711121379.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}