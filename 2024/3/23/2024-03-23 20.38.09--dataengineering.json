{"kind": "Listing", "data": {"after": "t3_1bltvss", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data analyst by profession and majority of the time I spend time in building power bi reports. One of the SQL database we get data from is getting deprecated and the client team moved the data to Azure data lake. The client just asked our team (IT services) to figure how do we setup the data pipelines (they suggested  synapse)\n\nBeing the individual contributor in project I sought help from my company  management for a data engineer to pitch in to set this up or at least guide, instead I got shamed that I should have figured everything by now and I shouldn't have accepted to synapse approach in first place. They kept on asking questions about the data lake storage which I don't have experience working on.\n\nAm I supposed to know data engineering as well, is it a bad move that I sought help as I don't have experience in data engineering. My management literally bullied me for saying I don't know data engineering. Am I wrong for not figuring it out, I know the data roles overlap but this was completely out of my expertise. Felt so bad and demotivated.\n\nEdited(added more details) - I have been highlighting this to the management for almost a month, They arranged a data engineer from another project to give a 30 minutes lecture on synapse and its possibilities and vanished from the scene. I needed more help which my company didnt want to accommodate as it didnt involve extra billing. Customer was not ready to give extra money citing  SOW. I took over the project 4 months back with the roles and responsibilities aligned to descriptive stats and dashboards.", "author_fullname": "t2_cg0kwbzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I learn data engineering? Got shamed in a team meeting.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bleg24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 120, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 120, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711156269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711152541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst by profession and majority of the time I spend time in building power bi reports. One of the SQL database we get data from is getting deprecated and the client team moved the data to Azure data lake. The client just asked our team (IT services) to figure how do we setup the data pipelines (they suggested  synapse)&lt;/p&gt;\n\n&lt;p&gt;Being the individual contributor in project I sought help from my company  management for a data engineer to pitch in to set this up or at least guide, instead I got shamed that I should have figured everything by now and I shouldn&amp;#39;t have accepted to synapse approach in first place. They kept on asking questions about the data lake storage which I don&amp;#39;t have experience working on.&lt;/p&gt;\n\n&lt;p&gt;Am I supposed to know data engineering as well, is it a bad move that I sought help as I don&amp;#39;t have experience in data engineering. My management literally bullied me for saying I don&amp;#39;t know data engineering. Am I wrong for not figuring it out, I know the data roles overlap but this was completely out of my expertise. Felt so bad and demotivated.&lt;/p&gt;\n\n&lt;p&gt;Edited(added more details) - I have been highlighting this to the management for almost a month, They arranged a data engineer from another project to give a 30 minutes lecture on synapse and its possibilities and vanished from the scene. I needed more help which my company didnt want to accommodate as it didnt involve extra billing. Customer was not ready to give extra money citing  SOW. I took over the project 4 months back with the roles and responsibilities aligned to descriptive stats and dashboards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bleg24", "is_robot_indexable": true, "report_reasons": null, "author": "urbanguy22", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bleg24/should_i_learn_data_engineering_got_shamed_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bleg24/should_i_learn_data_engineering_got_shamed_in_a/", "subreddit_subscribers": 171228, "created_utc": 1711152541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.\n\nI completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. \n\nI\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.\n\nIdk why in posting this it\u2019s basically just a rant.", "author_fullname": "t2_89to7nqdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel like an absolute loser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.&lt;/p&gt;\n\n&lt;p&gt;I completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.&lt;/p&gt;\n\n&lt;p&gt;Idk why in posting this it\u2019s basically just a rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bly2h0", "is_robot_indexable": true, "report_reasons": null, "author": "seikoalpinist197", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "subreddit_subscribers": 171228, "created_utc": 1711215831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Atscale is not pulling any punches here about the limitations of Fabric when it comes to Power BI + big data.\n\n  \nBased on their report, their CTO and founder is saying that its a half-baked solution for large workloads. It might work with smaller data sets, but it falls flat (query performance &amp; timeouts) after 100+ GBs of data if you are using the Direct Lake interface.\n\n  \nIs anyone else running into these types of scalability challenges?\n\n  \n[https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/](https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/)", "author_fullname": "t2_tm7h4ttv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone using PowerBI + Fabric at an Enterprise Scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl8vbz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711138359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Atscale is not pulling any punches here about the limitations of Fabric when it comes to Power BI + big data.&lt;/p&gt;\n\n&lt;p&gt;Based on their report, their CTO and founder is saying that its a half-baked solution for large workloads. It might work with smaller data sets, but it falls flat (query performance &amp;amp; timeouts) after 100+ GBs of data if you are using the Direct Lake interface.&lt;/p&gt;\n\n&lt;p&gt;Is anyone else running into these types of scalability challenges?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/\"&gt;https://www.atscale.com/blog/power-bi-face-off-databricks-vs-microsoft-fabric/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?auto=webp&amp;s=ef0167fbc5df2624b364f3d35bc4868f14fac173", "width": 2048, "height": 1072}, "resolutions": [{"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=584825f0568b23db2c7f4a7f7aa761f044b8e671", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e92d06480e6e2d7c0cb05c1213908d59bbb80dbe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34433847663248873a7618e96a8c37c00c9184e1", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10dc1855235265aca1ee21174ea3ce5522330112", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a2de35d1299a6a3849b4b0a88932ba631a7302bb", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/EhGRy1JXOPFa3ospqKYinDjctxvl5W_DXL-ih6sMbPI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=81a76fab2c2e71a702f63cad6157ee0b26d55dde", "width": 1080, "height": 565}], "variants": {}, "id": "dsus145I8c2mn6MwIGR4yyru8X7lKi3WqnbhPCocRUg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bl8vbz", "is_robot_indexable": true, "report_reasons": null, "author": "ProgramFriendly6608", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl8vbz/is_anyone_using_powerbi_fabric_at_an_enterprise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl8vbz/is_anyone_using_powerbi_fabric_at_an_enterprise/", "subreddit_subscribers": 171228, "created_utc": 1711138359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?", "author_fullname": "t2_wksnouv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you when your organization gives you scripts or tasks from exemployees in a language you don\u2019t really understand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blke3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711175205.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711170679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blke3g", "is_robot_indexable": true, "report_reasons": null, "author": "Ivan_GL7", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "subreddit_subscribers": 171228, "created_utc": 1711170679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.\n\nOn the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. \n\nI started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. \n\nAnother problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets \n\nWe do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. \n\nIm expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis\n\nIhv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. \n", "author_fullname": "t2_83gq3oxts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google sheets \u2014-&gt; ???? \u2014\u2014-&gt; PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bliedv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711166291.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711164059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.&lt;/p&gt;\n\n&lt;p&gt;On the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. &lt;/p&gt;\n\n&lt;p&gt;I started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. &lt;/p&gt;\n\n&lt;p&gt;Another problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets &lt;/p&gt;\n\n&lt;p&gt;We do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. &lt;/p&gt;\n\n&lt;p&gt;Im expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis&lt;/p&gt;\n\n&lt;p&gt;Ihv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bliedv", "is_robot_indexable": true, "report_reasons": null, "author": "FigTraditional1201", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "subreddit_subscribers": 171228, "created_utc": 1711164059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.\n\nNow I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. ", "author_fullname": "t2_4geyh6db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering with inefficient practices: What is your perspective on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blnf39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711182938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.&lt;/p&gt;\n\n&lt;p&gt;Now I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blnf39", "is_robot_indexable": true, "report_reasons": null, "author": "bloatedboat", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "subreddit_subscribers": 171228, "created_utc": 1711182938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. \n\nOur next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).\n\nPlease let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!", "author_fullname": "t2_aszk65qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Dimensional Modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blt82x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711203415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. &lt;/p&gt;\n\n&lt;p&gt;Our next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blt82x", "is_robot_indexable": true, "report_reasons": null, "author": "No_Promotion_729", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "subreddit_subscribers": 171228, "created_utc": 1711203415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.\n\nDo you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).\n\nIs there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call \"advanced\", like window functions, CTEs, regex, etc. \n\nWhere does one learn how to get better at this process?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organize and plan complex SQL transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blx4lh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711213439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.&lt;/p&gt;\n\n&lt;p&gt;Do you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).&lt;/p&gt;\n\n&lt;p&gt;Is there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call &amp;quot;advanced&amp;quot;, like window functions, CTEs, regex, etc. &lt;/p&gt;\n\n&lt;p&gt;Where does one learn how to get better at this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blx4lh", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "subreddit_subscribers": 171228, "created_utc": 1711213439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a professional in automation testing, I've encountered a new requirement in my current project that necessitates learning Apache Airflow. I'm seeking high-quality references or courses that could guide me through this learning process. If you're aware of any resources, I would greatly appreciate your recommendations.", "author_fullname": "t2_3mhkzvqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find some good resources based on Apache Airflow? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blglio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711158625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a professional in automation testing, I&amp;#39;ve encountered a new requirement in my current project that necessitates learning Apache Airflow. I&amp;#39;m seeking high-quality references or courses that could guide me through this learning process. If you&amp;#39;re aware of any resources, I would greatly appreciate your recommendations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blglio", "is_robot_indexable": true, "report_reasons": null, "author": "aatish_tandel", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "subreddit_subscribers": 171228, "created_utc": 1711158625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am having a little trouble understanding the tradeoffs between two dataprocessing methodologies.  I am not a data engineer by trade, and I am trying to understand the cases where different ETL approaches are warranted.\n\nSuppose I have a whole bunch of files that I want to process and then dump the output into a typical SQL db.  I want to understand the differences between deploying a cluster of pods and using ETL tools to process this data.\n\n&amp;#x200B;\n\n1) I can dump my processing code into a docker container and deploy the container in kubernetes to process the files in parallel.  Each pod would process a single file, upload the result to the table, and exit.\n\n2) I can use something like apache beam to define a pipeline with a single batch corresponding to a single input file (Is this true?).  Is there any advantage to going this route?  Will dataflow/Glue handle resource scaling for me, or is it pretty much the same as provisioning a kubernetes cluster?\n\n&amp;#x200B;\n\nI guess the final question is if I changed the input data - think one giant parquet file or an SQL database with all the data from the fragmented pieces in the first scenario as the input - is this where the batch processing approach with beam would really shine, or would I be better off in the original scenario with smaller pieces that are already broken up?", "author_fullname": "t2_a51is1rz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache beam (batch based processing) vs. docker + kubernetes cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blccwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711147137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am having a little trouble understanding the tradeoffs between two dataprocessing methodologies.  I am not a data engineer by trade, and I am trying to understand the cases where different ETL approaches are warranted.&lt;/p&gt;\n\n&lt;p&gt;Suppose I have a whole bunch of files that I want to process and then dump the output into a typical SQL db.  I want to understand the differences between deploying a cluster of pods and using ETL tools to process this data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1) I can dump my processing code into a docker container and deploy the container in kubernetes to process the files in parallel.  Each pod would process a single file, upload the result to the table, and exit.&lt;/p&gt;\n\n&lt;p&gt;2) I can use something like apache beam to define a pipeline with a single batch corresponding to a single input file (Is this true?).  Is there any advantage to going this route?  Will dataflow/Glue handle resource scaling for me, or is it pretty much the same as provisioning a kubernetes cluster?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess the final question is if I changed the input data - think one giant parquet file or an SQL database with all the data from the fragmented pieces in the first scenario as the input - is this where the batch processing approach with beam would really shine, or would I be better off in the original scenario with smaller pieces that are already broken up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blccwy", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Resist-54", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blccwy/apache_beam_batch_based_processing_vs_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blccwy/apache_beam_batch_based_processing_vs_docker/", "subreddit_subscribers": 171228, "created_utc": 1711147137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_58s0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a tool to run classification directly on a database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_1blz3t4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713818289%2CNjM4ZWY2NjE4N2U3NTQzMTdmYTJkNmViOTM1ZDZiZDA1NmFiNjFlNjljNDQ3NjFiZjRhZDRmMTQ2MTJkMGY4YQ%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713818289%2CMTlhYWUxNDNmZjU3OWMxNDFhMGRlMTQxYWNmOGE1ZmMxOTYwYzBjNjc2ZjkzMTYyNTQzYWFjNjAzNmYzMGYyYw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=140&amp;height=94&amp;crop=140:94,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d719b9ba6a6729a031d95dd0818e175959675a1", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711218453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/et58xk3um4qc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?format=pjpg&amp;auto=webp&amp;s=744d369b4b92d8aad1b50a0097cf2f36f32fc2e9", "width": 1592, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2f0a11fcd4a3f4cbe68554a5c3f3ce9a84dbc3f0", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9030be02b75e305f96099b52f581240703373ef0", "width": 216, "height": 146}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0fc2a544f4ee9fdb87c4dbd4b9a83551297a65a1", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9706fb48dbab31f4da91c2cb8afd30ea9b65b224", "width": 640, "height": 434}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25862ffa68335478a0425d41756ea4c430dcac7f", "width": 960, "height": 651}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8809e081cc61b4526c196ef22cce1a52cc65025b", "width": 1080, "height": 732}], "variants": {}, "id": "MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1blz3t4", "is_robot_indexable": true, "report_reasons": null, "author": "Tylernator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blz3t4/i_built_a_tool_to_run_classification_directly_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/et58xk3um4qc1", "subreddit_subscribers": 171228, "created_utc": 1711218453.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713818289%2CNjM4ZWY2NjE4N2U3NTQzMTdmYTJkNmViOTM1ZDZiZDA1NmFiNjFlNjljNDQ3NjFiZjRhZDRmMTQ2MTJkMGY4YQ%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713818289%2CMTlhYWUxNDNmZjU3OWMxNDFhMGRlMTQxYWNmOGE1ZmMxOTYwYzBjNjc2ZjkzMTYyNTQzYWFjNjAzNmYzMGYyYw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to move up in the ranks at my current organization to the next level. Therefore, I need to further my knowledge in the data engineering topic; in regards to system design. I am looking for good courses that teach system design for data engineering related systems/applications. Can anyone recommend me a good course to pursue on sites like Udemy, Coursera, Pluralsight, etc? I have a background in DevOps, so I am experienced with some engineering (automation, CI/CD, scripting, etc.) Thank you in advance!", "author_fullname": "t2_100mg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Courses for Data Engineering System Design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bl90gl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711138726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to move up in the ranks at my current organization to the next level. Therefore, I need to further my knowledge in the data engineering topic; in regards to system design. I am looking for good courses that teach system design for data engineering related systems/applications. Can anyone recommend me a good course to pursue on sites like Udemy, Coursera, Pluralsight, etc? I have a background in DevOps, so I am experienced with some engineering (automation, CI/CD, scripting, etc.) Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bl90gl", "is_robot_indexable": true, "report_reasons": null, "author": "-DropTheMike-", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bl90gl/best_courses_for_data_engineering_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bl90gl/best_courses_for_data_engineering_system_design/", "subreddit_subscribers": 171228, "created_utc": 1711138726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I'm interested in gathering tips to assist data engineers or data scientists. ", "author_fullname": "t2_dxtbgbxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some under-discussed topics within the data engineering community that deserve more focus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bm0v2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711222809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I&amp;#39;m interested in gathering tips to assist data engineers or data scientists. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm0v2c", "is_robot_indexable": true, "report_reasons": null, "author": "jessedata", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "subreddit_subscribers": 171228, "created_utc": 1711222809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Data flow](https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc)\n\nHi,\n\n&amp;#x200B;\n\nI am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:\n\n1) how do I notify the next container(s) that the images have been processed and ready for transfer? \n\n2) how do I transfer the images for further processing between the containers? \n\nI am open to any and all suggestions but the tools/tech need to be free to use.", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on how to efficiently create a pipeline for images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"85qi28f2n4qc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc6bf22cdd9ee210f26981146b90037c6a8f312f"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05da27ad865391a874ce7e66a439af7db06c1fe8"}, {"y": 198, "x": 320, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac853bedb09e7b6de92f353cba5479ae88bd713e"}, {"y": 397, "x": 640, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1f10e5a1791c9891025c20e3740b1651addacc5"}], "s": {"y": 471, "x": 759, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc"}, "id": "85qi28f2n4qc1"}}, "name": "t3_1blzcx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a31C2UUcyPPK-DQYONOvSz6oNMlzbV00yDZL1QZENWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711219085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc\"&gt;Data flow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:&lt;/p&gt;\n\n&lt;p&gt;1) how do I notify the next container(s) that the images have been processed and ready for transfer? &lt;/p&gt;\n\n&lt;p&gt;2) how do I transfer the images for further processing between the containers? &lt;/p&gt;\n\n&lt;p&gt;I am open to any and all suggestions but the tools/tech need to be free to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blzcx2", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "subreddit_subscribers": 171228, "created_utc": 1711219085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.", "author_fullname": "t2_ryxoz6of4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there good scope in data engineering in a non profit healthcare company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2lq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bly2lq", "is_robot_indexable": true, "report_reasons": null, "author": "UnfairDiscount8331", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "subreddit_subscribers": 171228, "created_utc": 1711215842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.", "author_fullname": "t2_5y5mt5wer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will learning kotlin be beneficial in my data engineering career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blsz6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711202763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blsz6g", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient_Example30", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "subreddit_subscribers": 171228, "created_utc": 1711202763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an use case where I have to create STM document(Source to Target Mapping). \n\nI want to get the business logic which is being applied on a column, along with the column lineage.\n\nUsing databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you", "author_fullname": "t2_4njp7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column level Business rule along with Lineage in Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bls2gy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711200191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an use case where I have to create STM document(Source to Target Mapping). &lt;/p&gt;\n\n&lt;p&gt;I want to get the business logic which is being applied on a column, along with the column lineage.&lt;/p&gt;\n\n&lt;p&gt;Using databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bls2gy", "is_robot_indexable": true, "report_reasons": null, "author": "ravitejasurla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "subreddit_subscribers": 171228, "created_utc": 1711200191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included *courses, seminars, workcenters, associations, conferences, certifications, \u2026* and the like, without any particular budget, where would you start looking?\n\nI\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? \n\nI have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.\n\nFor context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026\n\nMore recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.\n\n\nWhat do you think? Thanks for any input. ", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you allocate an (positively) ambiguously capped professional development budget?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blhvrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711163283.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711162450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included &lt;em&gt;courses, seminars, workcenters, associations, conferences, certifications, \u2026&lt;/em&gt; and the like, without any particular budget, where would you start looking?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? &lt;/p&gt;\n\n&lt;p&gt;I have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.&lt;/p&gt;\n\n&lt;p&gt;For context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026&lt;/p&gt;\n\n&lt;p&gt;More recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Thanks for any input. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blhvrx", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "subreddit_subscribers": 171228, "created_utc": 1711162450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm inheriting a system that is all buckets and functions with an SQL flavor for running queries. There are a few VMs for some persistent jobs. Are there any tools that would help this system with observability, maintenance, extension, and reliability? It's more data heavy then it is compute heavy.  \nThanks for your thoughts.", "author_fullname": "t2_3lqaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "buckets of blobs and cloudy functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blbtxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711145801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m inheriting a system that is all buckets and functions with an SQL flavor for running queries. There are a few VMs for some persistent jobs. Are there any tools that would help this system with observability, maintenance, extension, and reliability? It&amp;#39;s more data heavy then it is compute heavy.&lt;br/&gt;\nThanks for your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blbtxo", "is_robot_indexable": true, "report_reasons": null, "author": "Someoneoldbutnew", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blbtxo/buckets_of_blobs_and_cloudy_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blbtxo/buckets_of_blobs_and_cloudy_functions/", "subreddit_subscribers": 171228, "created_utc": 1711145801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have a unique case where I cannot find much information on how to architect or provide a good enough solution (which may be due to **how** I am looking for a solution). Most if not all of my background comes from the standard BI/analytics/internal use case DE, and I'm presently working in an environment where DE supports a product itself.\n\nEssentially, we have the following requirements:\n\n1.) Dynamic DAG generation, taking the data and either aggregating it further into a very denormalized structure and then also into OLTP to be consumed by an RDS instance. By dynamic, I mean that the tables created in the database follow a DAG generated by variables passed plus a configuration template. So if customer XYZ signed up, we would create table \"agg\\_XYZ\\_stuff\".\n\n2.) Multi-tenant (customer) DAG execution, where the DAG executions need to be separated by the specific customer, So from the first requirement, customer XYZ's DAG would execute on an interval set by their timezone (likely daily batch, but again, by their timezone).\n\n3.) As little human involvement beyond the config files or templates. Trying to stay away from manually having to create customer specific files/tables/models in order for \"agg\\_XYZ\\_stuff\" to exist. \n\nMost of my recent experience is using dbt-core, Meltano+Dagster, GBQ/Snowflake, but this is a whole new beast to begin with. I know that dbt can support pre-post hooks, but I don't know if it could handle the complexity of generating new models at runtime without invoking a PR to manually create the models. It seems to me that this kind of work falls under \"software engineer, data\" type work.\n\nAny advice is very much appreciated.  ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-tenant dynamic DAG options for a series of requirements?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blao2n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711142888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a unique case where I cannot find much information on how to architect or provide a good enough solution (which may be due to &lt;strong&gt;how&lt;/strong&gt; I am looking for a solution). Most if not all of my background comes from the standard BI/analytics/internal use case DE, and I&amp;#39;m presently working in an environment where DE supports a product itself.&lt;/p&gt;\n\n&lt;p&gt;Essentially, we have the following requirements:&lt;/p&gt;\n\n&lt;p&gt;1.) Dynamic DAG generation, taking the data and either aggregating it further into a very denormalized structure and then also into OLTP to be consumed by an RDS instance. By dynamic, I mean that the tables created in the database follow a DAG generated by variables passed plus a configuration template. So if customer XYZ signed up, we would create table &amp;quot;agg_XYZ_stuff&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;2.) Multi-tenant (customer) DAG execution, where the DAG executions need to be separated by the specific customer, So from the first requirement, customer XYZ&amp;#39;s DAG would execute on an interval set by their timezone (likely daily batch, but again, by their timezone).&lt;/p&gt;\n\n&lt;p&gt;3.) As little human involvement beyond the config files or templates. Trying to stay away from manually having to create customer specific files/tables/models in order for &amp;quot;agg_XYZ_stuff&amp;quot; to exist. &lt;/p&gt;\n\n&lt;p&gt;Most of my recent experience is using dbt-core, Meltano+Dagster, GBQ/Snowflake, but this is a whole new beast to begin with. I know that dbt can support pre-post hooks, but I don&amp;#39;t know if it could handle the complexity of generating new models at runtime without invoking a PR to manually create the models. It seems to me that this kind of work falls under &amp;quot;software engineer, data&amp;quot; type work.&lt;/p&gt;\n\n&lt;p&gt;Any advice is very much appreciated.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blao2n", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blao2n/multitenant_dynamic_dag_options_for_a_series_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blao2n/multitenant_dynamic_dag_options_for_a_series_of/", "subreddit_subscribers": 171228, "created_utc": 1711142888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I need help solving a problem. I need to convert Solitidy ByteCodes to OpCodes. I have several datasets storing ByteCodes and i'm looking for a way to automate the transformation of these ByteCodes into Opcodes in bulk rather than treating them individually. Any guidance or support you can provide would be greatly appreciated. Thanks!", "author_fullname": "t2_qrqs3bpd7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ByteCodes to OpCodes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bm0cj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711221531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I need help solving a problem. I need to convert Solitidy ByteCodes to OpCodes. I have several datasets storing ByteCodes and i&amp;#39;m looking for a way to automate the transformation of these ByteCodes into Opcodes in bulk rather than treating them individually. Any guidance or support you can provide would be greatly appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm0cj4", "is_robot_indexable": true, "report_reasons": null, "author": "iwasalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm0cj4/bytecodes_to_opcodes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm0cj4/bytecodes_to_opcodes/", "subreddit_subscribers": 171228, "created_utc": 1711221531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!", "author_fullname": "t2_8phjzgjz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blyr09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711217558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blyr09", "is_robot_indexable": true, "report_reasons": null, "author": "spoonorfork1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blyr09/learning_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blyr09/learning_databricks/", "subreddit_subscribers": 171228, "created_utc": 1711217558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI recently attended the Gartner Data &amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. \n\nThe summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. \n\nMost of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.\n\nOne of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball's first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball's work. \n\nWhile the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.\n\nThis year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I'm excited to attend next year's summit to stay updated on the latest trends and best practices.\n\nIf you have any questions or need more details about the conference, feel free to ask. I'd be happy to share more about my experience.", "author_fullname": "t2_rdorl0euo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gartner Data &amp; Analytics Summit 2024 - My Experience &amp; Key Takeaways", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blwtyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711212706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently attended the Gartner Data &amp;amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. &lt;/p&gt;\n\n&lt;p&gt;The summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. &lt;/p&gt;\n\n&lt;p&gt;Most of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.&lt;/p&gt;\n\n&lt;p&gt;One of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball&amp;#39;s first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball&amp;#39;s work. &lt;/p&gt;\n\n&lt;p&gt;While the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.&lt;/p&gt;\n\n&lt;p&gt;This year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I&amp;#39;m excited to attend next year&amp;#39;s summit to stay updated on the latest trends and best practices.&lt;/p&gt;\n\n&lt;p&gt;If you have any questions or need more details about the conference, feel free to ask. I&amp;#39;d be happy to share more about my experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blwtyr", "is_robot_indexable": true, "report_reasons": null, "author": "data-pro-wizard", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "subreddit_subscribers": 171228, "created_utc": 1711212706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There's this local (Southeast Asia) cohort-based 15-week data science bootcamp that I've been considering joining, but I'm wondering if I'd be better off investing that money and time elsewhere. If you wanna check it out, it's at [https://www.eskwelabs.com/data-science-fellowship.](https://www.eskwelabs.com/data-science-fellowship)\n\nThe main advantage with this option are the connections/network opportunities as this is an EdTech startup trusted by the local industry. Many former students go on to be successful data professionals. I know it's not for data engineering, but my hope is that it would at least get my foot in the door because where data analysts and data scientists are, data engineers should be too. I could just study on my own, but I would be forgoing the benefits I just mentioned.\n\nI've been struggling to consistently self-learn because I'm so indecisive about exactly what I want to learn. I'm kind of set on data engineering now because it seems to be the better fit vs. data analysis or data science. I also really need a structured learning environment to motivate me, which is why I'm seriously considering taking up a bootcamp.\n\nAny advice is welcome.\n\nP.S.\n\nFor more context, I'm currently an independent contractor for a small company, working with Machine Learning engineers to create datasets for training their computer vision models. Before this, I graduated with a geology degree but it burnt me the hell out. The one thing I held on to was my skill in GIS. I love GIS, the part I like most about GIS is the technical side, using a myriad of tools and data sources to come up with maps. But I'm not happy about the job market. To move up the ladder, you'd need SWE skills to become a GIS developer. I was going to study full stack development, but the number of available GIS developer roles here is scant. At least with how things are looking, there will always be a need for data engineers.", "author_fullname": "t2_6k8yfl9c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I join this $1000 bootcamp or invest in cloud provider certifications and MOOCs instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blvxfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711210419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s this local (Southeast Asia) cohort-based 15-week data science bootcamp that I&amp;#39;ve been considering joining, but I&amp;#39;m wondering if I&amp;#39;d be better off investing that money and time elsewhere. If you wanna check it out, it&amp;#39;s at &lt;a href=\"https://www.eskwelabs.com/data-science-fellowship\"&gt;https://www.eskwelabs.com/data-science-fellowship.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The main advantage with this option are the connections/network opportunities as this is an EdTech startup trusted by the local industry. Many former students go on to be successful data professionals. I know it&amp;#39;s not for data engineering, but my hope is that it would at least get my foot in the door because where data analysts and data scientists are, data engineers should be too. I could just study on my own, but I would be forgoing the benefits I just mentioned.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been struggling to consistently self-learn because I&amp;#39;m so indecisive about exactly what I want to learn. I&amp;#39;m kind of set on data engineering now because it seems to be the better fit vs. data analysis or data science. I also really need a structured learning environment to motivate me, which is why I&amp;#39;m seriously considering taking up a bootcamp.&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome.&lt;/p&gt;\n\n&lt;p&gt;P.S.&lt;/p&gt;\n\n&lt;p&gt;For more context, I&amp;#39;m currently an independent contractor for a small company, working with Machine Learning engineers to create datasets for training their computer vision models. Before this, I graduated with a geology degree but it burnt me the hell out. The one thing I held on to was my skill in GIS. I love GIS, the part I like most about GIS is the technical side, using a myriad of tools and data sources to come up with maps. But I&amp;#39;m not happy about the job market. To move up the ladder, you&amp;#39;d need SWE skills to become a GIS developer. I was going to study full stack development, but the number of available GIS developer roles here is scant. At least with how things are looking, there will always be a need for data engineers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?auto=webp&amp;s=96aff65dba75c56f1bed0f8f99b250dfcde2ba4c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49efc40b1d79a0c094b86ce16c84c72235512a95", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7fab185ecc225430bc48b0acda3de550f4e9a41b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05d8cca46de10ff43ab761403d110861e5d1d5f8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8b5dcb9aa5509fd95552f64dd0148ea7f33b34b6", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=516628c5208d3a1fd0d86d5c343f7fceac1f2e14", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2dd964e97e162e92278d4de258bf4aa595da83ec", "width": 1080, "height": 567}], "variants": {}, "id": "TsI3dGx42LkLb5P7V4Nov50XsoHJ_KsQetLC-BDcRSE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1blvxfn", "is_robot_indexable": true, "report_reasons": null, "author": "justlikeutoo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blvxfn/should_i_join_this_1000_bootcamp_or_invest_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blvxfn/should_i_join_this_1000_bootcamp_or_invest_in/", "subreddit_subscribers": 171228, "created_utc": 1711210419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was hoping someone could give me a realistic perspective of how far I need to go to get my foot in the door as a Jr. Data Engineer. I am hoping to make a career change out of consulting - I am currently a Senior Product Analyst. Prior to this I was a mechanical engineer for five years. I've found I still don't want anything to do with the political world of business execs, I want to get back in the weeds where I belong and build glorious elegant solutions to weird problems. Efficiency makes me happy.\n\nWhere I am currently:\n\n* I have built a few full-stack applications and am very familiar with React and Postgres.\n* At work I use Python (often starting with a first pass generated by ChatGPT to save time, then refining from there -- everything has to happen fast, and everyone thinks we should just use Excel for everything) to automate a lot of my tasks and try to build leave-behind tools to help others process data. \n   * While I may skimp on the implementation step since I am cheating with AI, I do have to understand:\n      * What is possible\n      * What's the specific set of steps I want to take to achieve this\n      * What data structures will be useful in getting me there\n      * What edge cases and other issues do I need to account for to make this generally applicable\n   * These have included Powerpoint slide generators that take data from an Excel file and populate pre-defined templates to save time in re-spins, an automatic Pareto analyzer for spend data, a variant tree generator for product portfolios, and a bill of materials re-formatter to transform various formats to a consistent hierarchical pattern, enabling further downstream analysis\n* I also use Alteryx a lot at work for a wide variety of tasks, usually for quickly parsing and getting insights from large datasets, and setting up repeatable transformations. \n\n&amp;#x200B;\n\nI understand most of this is Analysis and not Engineering, but I'm wondering if I may be close enough that I could get into a job and learn on the fly after spending a few months doing some self-learning and practice with the basic concepts of data engineering. \n\n**Would appreciate any and all feedback -- don't hold back!**\n\n&amp;#x200B;", "author_fullname": "t2_5i451", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How far do I have to go to become a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bltvss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711205156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was hoping someone could give me a realistic perspective of how far I need to go to get my foot in the door as a Jr. Data Engineer. I am hoping to make a career change out of consulting - I am currently a Senior Product Analyst. Prior to this I was a mechanical engineer for five years. I&amp;#39;ve found I still don&amp;#39;t want anything to do with the political world of business execs, I want to get back in the weeds where I belong and build glorious elegant solutions to weird problems. Efficiency makes me happy.&lt;/p&gt;\n\n&lt;p&gt;Where I am currently:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have built a few full-stack applications and am very familiar with React and Postgres.&lt;/li&gt;\n&lt;li&gt;At work I use Python (often starting with a first pass generated by ChatGPT to save time, then refining from there -- everything has to happen fast, and everyone thinks we should just use Excel for everything) to automate a lot of my tasks and try to build leave-behind tools to help others process data. \n\n&lt;ul&gt;\n&lt;li&gt;While I may skimp on the implementation step since I am cheating with AI, I do have to understand:\n\n&lt;ul&gt;\n&lt;li&gt;What is possible&lt;/li&gt;\n&lt;li&gt;What&amp;#39;s the specific set of steps I want to take to achieve this&lt;/li&gt;\n&lt;li&gt;What data structures will be useful in getting me there&lt;/li&gt;\n&lt;li&gt;What edge cases and other issues do I need to account for to make this generally applicable&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;These have included Powerpoint slide generators that take data from an Excel file and populate pre-defined templates to save time in re-spins, an automatic Pareto analyzer for spend data, a variant tree generator for product portfolios, and a bill of materials re-formatter to transform various formats to a consistent hierarchical pattern, enabling further downstream analysis&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;I also use Alteryx a lot at work for a wide variety of tasks, usually for quickly parsing and getting insights from large datasets, and setting up repeatable transformations. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I understand most of this is Analysis and not Engineering, but I&amp;#39;m wondering if I may be close enough that I could get into a job and learn on the fly after spending a few months doing some self-learning and practice with the basic concepts of data engineering. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Would appreciate any and all feedback -- don&amp;#39;t hold back!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bltvss", "is_robot_indexable": true, "report_reasons": null, "author": "Pawtang", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bltvss/how_far_do_i_have_to_go_to_become_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bltvss/how_far_do_i_have_to_go_to_become_a_data_engineer/", "subreddit_subscribers": 171228, "created_utc": 1711205156.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}