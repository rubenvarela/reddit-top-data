{"kind": "Listing", "data": {"after": "t3_1bm1kyn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data analyst by profession and majority of the time I spend time in building power bi reports. One of the SQL database we get data from is getting deprecated and the client team moved the data to Azure data lake. The client just asked our team (IT services) to figure how do we setup the data pipelines (they suggested  synapse)\n\nBeing the individual contributor in project I sought help from my company  management for a data engineer to pitch in to set this up or at least guide, instead I got shamed that I should have figured everything by now and I shouldn't have accepted to synapse approach in first place. They kept on asking questions about the data lake storage which I don't have experience working on.\n\nAm I supposed to know data engineering as well, is it a bad move that I sought help as I don't have experience in data engineering. My management literally bullied me for saying I don't know data engineering. Am I wrong for not figuring it out, I know the data roles overlap but this was completely out of my expertise. Felt so bad and demotivated.\n\nEdited(added more details) - I have been highlighting this to the management for almost a month, They arranged a data engineer from another project to give a 30 minutes lecture on synapse and its possibilities and vanished from the scene. I needed more help which my company didnt want to accommodate as it didnt involve extra billing. Customer was not ready to give extra money citing  SOW. I took over the project 4 months back with the roles and responsibilities aligned to descriptive stats and dashboards.", "author_fullname": "t2_cg0kwbzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I learn data engineering? Got shamed in a team meeting.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bleg24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711156269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711152541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst by profession and majority of the time I spend time in building power bi reports. One of the SQL database we get data from is getting deprecated and the client team moved the data to Azure data lake. The client just asked our team (IT services) to figure how do we setup the data pipelines (they suggested  synapse)&lt;/p&gt;\n\n&lt;p&gt;Being the individual contributor in project I sought help from my company  management for a data engineer to pitch in to set this up or at least guide, instead I got shamed that I should have figured everything by now and I shouldn&amp;#39;t have accepted to synapse approach in first place. They kept on asking questions about the data lake storage which I don&amp;#39;t have experience working on.&lt;/p&gt;\n\n&lt;p&gt;Am I supposed to know data engineering as well, is it a bad move that I sought help as I don&amp;#39;t have experience in data engineering. My management literally bullied me for saying I don&amp;#39;t know data engineering. Am I wrong for not figuring it out, I know the data roles overlap but this was completely out of my expertise. Felt so bad and demotivated.&lt;/p&gt;\n\n&lt;p&gt;Edited(added more details) - I have been highlighting this to the management for almost a month, They arranged a data engineer from another project to give a 30 minutes lecture on synapse and its possibilities and vanished from the scene. I needed more help which my company didnt want to accommodate as it didnt involve extra billing. Customer was not ready to give extra money citing  SOW. I took over the project 4 months back with the roles and responsibilities aligned to descriptive stats and dashboards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bleg24", "is_robot_indexable": true, "report_reasons": null, "author": "urbanguy22", "discussion_type": null, "num_comments": 86, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bleg24/should_i_learn_data_engineering_got_shamed_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bleg24/should_i_learn_data_engineering_got_shamed_in_a/", "subreddit_subscribers": 171241, "created_utc": 1711152541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.\n\nI completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. \n\nI\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.\n\nIdk why in posting this it\u2019s basically just a rant.", "author_fullname": "t2_89to7nqdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel like an absolute loser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.&lt;/p&gt;\n\n&lt;p&gt;I completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.&lt;/p&gt;\n\n&lt;p&gt;Idk why in posting this it\u2019s basically just a rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bly2h0", "is_robot_indexable": true, "report_reasons": null, "author": "seikoalpinist197", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "subreddit_subscribers": 171241, "created_utc": 1711215831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?", "author_fullname": "t2_wksnouv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you when your organization gives you scripts or tasks from exemployees in a language you don\u2019t really understand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blke3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711175205.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711170679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blke3g", "is_robot_indexable": true, "report_reasons": null, "author": "Ivan_GL7", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "subreddit_subscribers": 171241, "created_utc": 1711170679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.\n\nOn the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. \n\nI started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. \n\nAnother problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets \n\nWe do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. \n\nIm expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis\n\nIhv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. \n", "author_fullname": "t2_83gq3oxts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google sheets \u2014-&gt; ???? \u2014\u2014-&gt; PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bliedv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711166291.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711164059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.&lt;/p&gt;\n\n&lt;p&gt;On the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. &lt;/p&gt;\n\n&lt;p&gt;I started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. &lt;/p&gt;\n\n&lt;p&gt;Another problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets &lt;/p&gt;\n\n&lt;p&gt;We do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. &lt;/p&gt;\n\n&lt;p&gt;Im expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis&lt;/p&gt;\n\n&lt;p&gt;Ihv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bliedv", "is_robot_indexable": true, "report_reasons": null, "author": "FigTraditional1201", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "subreddit_subscribers": 171241, "created_utc": 1711164059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.\n\nNow I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. ", "author_fullname": "t2_4geyh6db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering with inefficient practices: What is your perspective on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blnf39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711182938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.&lt;/p&gt;\n\n&lt;p&gt;Now I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blnf39", "is_robot_indexable": true, "report_reasons": null, "author": "bloatedboat", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "subreddit_subscribers": 171241, "created_utc": 1711182938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. \n\nOur next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).\n\nPlease let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!", "author_fullname": "t2_aszk65qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Dimensional Modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blt82x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711203415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. &lt;/p&gt;\n\n&lt;p&gt;Our next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blt82x", "is_robot_indexable": true, "report_reasons": null, "author": "No_Promotion_729", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "subreddit_subscribers": 171241, "created_utc": 1711203415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I'm interested in gathering tips to assist data engineers or data scientists. ", "author_fullname": "t2_dxtbgbxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some under-discussed topics within the data engineering community that deserve more focus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm0v2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711222809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I&amp;#39;m interested in gathering tips to assist data engineers or data scientists. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm0v2c", "is_robot_indexable": true, "report_reasons": null, "author": "jessedata", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "subreddit_subscribers": 171241, "created_utc": 1711222809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_58s0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a tool to run classification directly on a database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_1blz3t4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713825502%2CZGI4NmNmMTRjMWQ2NjI3NzdiNGI4NDIyN2FkZjMxYzRkNzNlODBmZTBlYjI2ODVhNzFhZmU4MzljNDk3MzZhNQ%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713825502%2CZTJiMmQ2YmNkMzJlZDViMmU5MTZmY2U5ZDU2Mzg4NDVhNDA2NjVkNmE4ZGFiMWU1NmI3MzIxNDk1YmZhMzdlNQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=140&amp;height=94&amp;crop=140:94,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d719b9ba6a6729a031d95dd0818e175959675a1", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711218453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/et58xk3um4qc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?format=pjpg&amp;auto=webp&amp;s=744d369b4b92d8aad1b50a0097cf2f36f32fc2e9", "width": 1592, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2f0a11fcd4a3f4cbe68554a5c3f3ce9a84dbc3f0", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9030be02b75e305f96099b52f581240703373ef0", "width": 216, "height": 146}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0fc2a544f4ee9fdb87c4dbd4b9a83551297a65a1", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9706fb48dbab31f4da91c2cb8afd30ea9b65b224", "width": 640, "height": 434}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25862ffa68335478a0425d41756ea4c430dcac7f", "width": 960, "height": 651}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8809e081cc61b4526c196ef22cce1a52cc65025b", "width": 1080, "height": 732}], "variants": {}, "id": "MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1blz3t4", "is_robot_indexable": true, "report_reasons": null, "author": "Tylernator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blz3t4/i_built_a_tool_to_run_classification_directly_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/et58xk3um4qc1", "subreddit_subscribers": 171241, "created_utc": 1711218453.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713825502%2CZGI4NmNmMTRjMWQ2NjI3NzdiNGI4NDIyN2FkZjMxYzRkNzNlODBmZTBlYjI2ODVhNzFhZmU4MzljNDk3MzZhNQ%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713825502%2CZTJiMmQ2YmNkMzJlZDViMmU5MTZmY2U5ZDU2Mzg4NDVhNDA2NjVkNmE4ZGFiMWU1NmI3MzIxNDk1YmZhMzdlNQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.\n\nDo you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).\n\nIs there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call \"advanced\", like window functions, CTEs, regex, etc. \n\nWhere does one learn how to get better at this process?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organize and plan complex SQL transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blx4lh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711213439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.&lt;/p&gt;\n\n&lt;p&gt;Do you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).&lt;/p&gt;\n\n&lt;p&gt;Is there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call &amp;quot;advanced&amp;quot;, like window functions, CTEs, regex, etc. &lt;/p&gt;\n\n&lt;p&gt;Where does one learn how to get better at this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blx4lh", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "subreddit_subscribers": 171241, "created_utc": 1711213439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI recently attended the Gartner Data &amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. \n\nThe summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. \n\nMost of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.\n\nOne of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball's first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball's work. \n\nWhile the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.\n\nThis year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I'm excited to attend next year's summit to stay updated on the latest trends and best practices.\n\nIf you have any questions or need more details about the conference, feel free to ask. I'd be happy to share more about my experience.", "author_fullname": "t2_rdorl0euo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gartner Data &amp; Analytics Summit 2024 - My Experience &amp; Key Takeaways", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blwtyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711212706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently attended the Gartner Data &amp;amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. &lt;/p&gt;\n\n&lt;p&gt;The summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. &lt;/p&gt;\n\n&lt;p&gt;Most of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.&lt;/p&gt;\n\n&lt;p&gt;One of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball&amp;#39;s first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball&amp;#39;s work. &lt;/p&gt;\n\n&lt;p&gt;While the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.&lt;/p&gt;\n\n&lt;p&gt;This year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I&amp;#39;m excited to attend next year&amp;#39;s summit to stay updated on the latest trends and best practices.&lt;/p&gt;\n\n&lt;p&gt;If you have any questions or need more details about the conference, feel free to ask. I&amp;#39;d be happy to share more about my experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blwtyr", "is_robot_indexable": true, "report_reasons": null, "author": "data-pro-wizard", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "subreddit_subscribers": 171241, "created_utc": 1711212706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a professional in automation testing, I've encountered a new requirement in my current project that necessitates learning Apache Airflow. I'm seeking high-quality references or courses that could guide me through this learning process. If you're aware of any resources, I would greatly appreciate your recommendations.", "author_fullname": "t2_3mhkzvqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find some good resources based on Apache Airflow? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blglio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711158625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a professional in automation testing, I&amp;#39;ve encountered a new requirement in my current project that necessitates learning Apache Airflow. I&amp;#39;m seeking high-quality references or courses that could guide me through this learning process. If you&amp;#39;re aware of any resources, I would greatly appreciate your recommendations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blglio", "is_robot_indexable": true, "report_reasons": null, "author": "aatish_tandel", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "subreddit_subscribers": 171241, "created_utc": 1711158625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am having a little trouble understanding the tradeoffs between two dataprocessing methodologies.  I am not a data engineer by trade, and I am trying to understand the cases where different ETL approaches are warranted.\n\nSuppose I have a whole bunch of files that I want to process and then dump the output into a typical SQL db.  I want to understand the differences between deploying a cluster of pods and using ETL tools to process this data.\n\n&amp;#x200B;\n\n1) I can dump my processing code into a docker container and deploy the container in kubernetes to process the files in parallel.  Each pod would process a single file, upload the result to the table, and exit.\n\n2) I can use something like apache beam to define a pipeline with a single batch corresponding to a single input file (Is this true?).  Is there any advantage to going this route?  Will dataflow/Glue handle resource scaling for me, or is it pretty much the same as provisioning a kubernetes cluster?\n\n&amp;#x200B;\n\nI guess the final question is if I changed the input data - think one giant parquet file or an SQL database with all the data from the fragmented pieces in the first scenario as the input - is this where the batch processing approach with beam would really shine, or would I be better off in the original scenario with smaller pieces that are already broken up?", "author_fullname": "t2_a51is1rz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache beam (batch based processing) vs. docker + kubernetes cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blccwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711147137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am having a little trouble understanding the tradeoffs between two dataprocessing methodologies.  I am not a data engineer by trade, and I am trying to understand the cases where different ETL approaches are warranted.&lt;/p&gt;\n\n&lt;p&gt;Suppose I have a whole bunch of files that I want to process and then dump the output into a typical SQL db.  I want to understand the differences between deploying a cluster of pods and using ETL tools to process this data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1) I can dump my processing code into a docker container and deploy the container in kubernetes to process the files in parallel.  Each pod would process a single file, upload the result to the table, and exit.&lt;/p&gt;\n\n&lt;p&gt;2) I can use something like apache beam to define a pipeline with a single batch corresponding to a single input file (Is this true?).  Is there any advantage to going this route?  Will dataflow/Glue handle resource scaling for me, or is it pretty much the same as provisioning a kubernetes cluster?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess the final question is if I changed the input data - think one giant parquet file or an SQL database with all the data from the fragmented pieces in the first scenario as the input - is this where the batch processing approach with beam would really shine, or would I be better off in the original scenario with smaller pieces that are already broken up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blccwy", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Resist-54", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blccwy/apache_beam_batch_based_processing_vs_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blccwy/apache_beam_batch_based_processing_vs_docker/", "subreddit_subscribers": 171241, "created_utc": 1711147137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.", "author_fullname": "t2_5y5mt5wer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will learning kotlin be beneficial in my data engineering career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blsz6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711202763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blsz6g", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient_Example30", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "subreddit_subscribers": 171241, "created_utc": 1711202763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe are going to start on a new project where we will be provided data for 9 different clients in csv formats. Data will then need to go through a fairly normal dataflow\n\n1. Data passed to us via the clients' \"drop boxes\"\n2. Data validation and ETL stuff\n3. Stored in Azure SQL\n4. A fairly complex calculation will be applied to the data\n5. Results of calculation stored back in to Azure SQL\n6. Various reporting etc\n7. Process repeated periodically (say twice a month)\n\nOther than being different datasets, the logical steps will be the same for each client. It is likely that throughout the life of the project there will need to be changes to the methodology in step 2 and step 4, when that happens any changes will apply to all clients simultaneously.\n\nLastly, it is critical that there is never a mix up between the 9 clients' data.\n\nThe most robust would seem to be to have completely separate instances of everything, but conversely having 9 copies of python / Spark ETL and calculation code doesn't seem like a good way to do things when it gets updated.\n\nAppreciate any thoughts or any reading I could do.", "author_fullname": "t2_76xailgf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Maintaining separation of data for different clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bm2fm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are going to start on a new project where we will be provided data for 9 different clients in csv formats. Data will then need to go through a fairly normal dataflow&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data passed to us via the clients&amp;#39; &amp;quot;drop boxes&amp;quot;&lt;/li&gt;\n&lt;li&gt;Data validation and ETL stuff&lt;/li&gt;\n&lt;li&gt;Stored in Azure SQL&lt;/li&gt;\n&lt;li&gt;A fairly complex calculation will be applied to the data&lt;/li&gt;\n&lt;li&gt;Results of calculation stored back in to Azure SQL&lt;/li&gt;\n&lt;li&gt;Various reporting etc&lt;/li&gt;\n&lt;li&gt;Process repeated periodically (say twice a month)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other than being different datasets, the logical steps will be the same for each client. It is likely that throughout the life of the project there will need to be changes to the methodology in step 2 and step 4, when that happens any changes will apply to all clients simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Lastly, it is critical that there is never a mix up between the 9 clients&amp;#39; data.&lt;/p&gt;\n\n&lt;p&gt;The most robust would seem to be to have completely separate instances of everything, but conversely having 9 copies of python / Spark ETL and calculation code doesn&amp;#39;t seem like a good way to do things when it gets updated.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any thoughts or any reading I could do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm2fm9", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Isopod4493", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm2fm9/maintaining_separation_of_data_for_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm2fm9/maintaining_separation_of_data_for_different/", "subreddit_subscribers": 171241, "created_utc": 1711226697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am checking out DuckDB but it seems like DataFusion can do everything DuckDB can do except some built in extensions provided by DuckDB like postgres.\n\nWhat are some cases for preferring DuckDB over DataFusion? Any experiences to share?", "author_fullname": "t2_20n43h6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should I prefer DuckDB over DataFusion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm27px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am checking out DuckDB but it seems like DataFusion can do everything DuckDB can do except some built in extensions provided by DuckDB like postgres.&lt;/p&gt;\n\n&lt;p&gt;What are some cases for preferring DuckDB over DataFusion? Any experiences to share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm27px", "is_robot_indexable": true, "report_reasons": null, "author": "gibriyagi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm27px/when_should_i_prefer_duckdb_over_datafusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm27px/when_should_i_prefer_duckdb_over_datafusion/", "subreddit_subscribers": 171241, "created_utc": 1711226135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Data flow](https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc)\n\nHi,\n\n&amp;#x200B;\n\nI am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:\n\n1) how do I notify the next container(s) that the images have been processed and ready for transfer? \n\n2) how do I transfer the images for further processing between the containers? \n\nI am open to any and all suggestions but the tools/tech need to be free to use.", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on how to efficiently create a pipeline for images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"85qi28f2n4qc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc6bf22cdd9ee210f26981146b90037c6a8f312f"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05da27ad865391a874ce7e66a439af7db06c1fe8"}, {"y": 198, "x": 320, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac853bedb09e7b6de92f353cba5479ae88bd713e"}, {"y": 397, "x": 640, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1f10e5a1791c9891025c20e3740b1651addacc5"}], "s": {"y": 471, "x": 759, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc"}, "id": "85qi28f2n4qc1"}}, "name": "t3_1blzcx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a31C2UUcyPPK-DQYONOvSz6oNMlzbV00yDZL1QZENWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711219085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc\"&gt;Data flow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:&lt;/p&gt;\n\n&lt;p&gt;1) how do I notify the next container(s) that the images have been processed and ready for transfer? &lt;/p&gt;\n\n&lt;p&gt;2) how do I transfer the images for further processing between the containers? &lt;/p&gt;\n\n&lt;p&gt;I am open to any and all suggestions but the tools/tech need to be free to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blzcx2", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "subreddit_subscribers": 171241, "created_utc": 1711219085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!", "author_fullname": "t2_8phjzgjz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blyr09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711217558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blyr09", "is_robot_indexable": true, "report_reasons": null, "author": "spoonorfork1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blyr09/learning_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blyr09/learning_databricks/", "subreddit_subscribers": 171241, "created_utc": 1711217558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.", "author_fullname": "t2_ryxoz6of4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there good scope in data engineering in a non profit healthcare company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2lq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bly2lq", "is_robot_indexable": true, "report_reasons": null, "author": "UnfairDiscount8331", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "subreddit_subscribers": 171241, "created_utc": 1711215842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There's this local (Southeast Asia) cohort-based 15-week data science bootcamp that I've been considering joining, but I'm wondering if I'd be better off investing that money and time elsewhere. If you wanna check it out, it's at [https://www.eskwelabs.com/data-science-fellowship.](https://www.eskwelabs.com/data-science-fellowship)\n\nThe main advantage with this option are the connections/network opportunities as this is an EdTech startup trusted by the local industry. Many former students go on to be successful data professionals. I know it's not for data engineering, but my hope is that it would at least get my foot in the door because where data analysts and data scientists are, data engineers should be too. I could just study on my own, but I would be forgoing the benefits I just mentioned.\n\nI've been struggling to consistently self-learn because I'm so indecisive about exactly what I want to learn. I'm kind of set on data engineering now because it seems to be the better fit vs. data analysis or data science. I also really need a structured learning environment to motivate me, which is why I'm seriously considering taking up a bootcamp.\n\nAny advice is welcome.\n\nP.S.\n\nFor more context, I'm currently an independent contractor for a small company, working with Machine Learning engineers to create datasets for training their computer vision models. Before this, I graduated with a geology degree but it burnt me the hell out. The one thing I held on to was my skill in GIS. I love GIS, the part I like most about GIS is the technical side, using a myriad of tools and data sources to come up with maps. But I'm not happy about the job market. To move up the ladder, you'd need SWE skills to become a GIS developer. I was going to study full stack development, but the number of available GIS developer roles here is scant. At least with how things are looking, there will always be a need for data engineers.", "author_fullname": "t2_6k8yfl9c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I join this $1000 bootcamp or invest in cloud provider certifications and MOOCs instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blvxfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711210419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s this local (Southeast Asia) cohort-based 15-week data science bootcamp that I&amp;#39;ve been considering joining, but I&amp;#39;m wondering if I&amp;#39;d be better off investing that money and time elsewhere. If you wanna check it out, it&amp;#39;s at &lt;a href=\"https://www.eskwelabs.com/data-science-fellowship\"&gt;https://www.eskwelabs.com/data-science-fellowship.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The main advantage with this option are the connections/network opportunities as this is an EdTech startup trusted by the local industry. Many former students go on to be successful data professionals. I know it&amp;#39;s not for data engineering, but my hope is that it would at least get my foot in the door because where data analysts and data scientists are, data engineers should be too. I could just study on my own, but I would be forgoing the benefits I just mentioned.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been struggling to consistently self-learn because I&amp;#39;m so indecisive about exactly what I want to learn. I&amp;#39;m kind of set on data engineering now because it seems to be the better fit vs. data analysis or data science. I also really need a structured learning environment to motivate me, which is why I&amp;#39;m seriously considering taking up a bootcamp.&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome.&lt;/p&gt;\n\n&lt;p&gt;P.S.&lt;/p&gt;\n\n&lt;p&gt;For more context, I&amp;#39;m currently an independent contractor for a small company, working with Machine Learning engineers to create datasets for training their computer vision models. Before this, I graduated with a geology degree but it burnt me the hell out. The one thing I held on to was my skill in GIS. I love GIS, the part I like most about GIS is the technical side, using a myriad of tools and data sources to come up with maps. But I&amp;#39;m not happy about the job market. To move up the ladder, you&amp;#39;d need SWE skills to become a GIS developer. I was going to study full stack development, but the number of available GIS developer roles here is scant. At least with how things are looking, there will always be a need for data engineers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?auto=webp&amp;s=96aff65dba75c56f1bed0f8f99b250dfcde2ba4c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49efc40b1d79a0c094b86ce16c84c72235512a95", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7fab185ecc225430bc48b0acda3de550f4e9a41b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05d8cca46de10ff43ab761403d110861e5d1d5f8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8b5dcb9aa5509fd95552f64dd0148ea7f33b34b6", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=516628c5208d3a1fd0d86d5c343f7fceac1f2e14", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2dd964e97e162e92278d4de258bf4aa595da83ec", "width": 1080, "height": 567}], "variants": {}, "id": "TsI3dGx42LkLb5P7V4Nov50XsoHJ_KsQetLC-BDcRSE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1blvxfn", "is_robot_indexable": true, "report_reasons": null, "author": "justlikeutoo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blvxfn/should_i_join_this_1000_bootcamp_or_invest_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blvxfn/should_i_join_this_1000_bootcamp_or_invest_in/", "subreddit_subscribers": 171241, "created_utc": 1711210419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an use case where I have to create STM document(Source to Target Mapping). \n\nI want to get the business logic which is being applied on a column, along with the column lineage.\n\nUsing databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you", "author_fullname": "t2_4njp7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column level Business rule along with Lineage in Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bls2gy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711200191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an use case where I have to create STM document(Source to Target Mapping). &lt;/p&gt;\n\n&lt;p&gt;I want to get the business logic which is being applied on a column, along with the column lineage.&lt;/p&gt;\n\n&lt;p&gt;Using databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bls2gy", "is_robot_indexable": true, "report_reasons": null, "author": "ravitejasurla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "subreddit_subscribers": 171241, "created_utc": 1711200191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included *courses, seminars, workcenters, associations, conferences, certifications, \u2026* and the like, without any particular budget, where would you start looking?\n\nI\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? \n\nI have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.\n\nFor context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026\n\nMore recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.\n\n\nWhat do you think? Thanks for any input. ", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you allocate an (positively) ambiguously capped professional development budget?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blhvrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711163283.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711162450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included &lt;em&gt;courses, seminars, workcenters, associations, conferences, certifications, \u2026&lt;/em&gt; and the like, without any particular budget, where would you start looking?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? &lt;/p&gt;\n\n&lt;p&gt;I have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.&lt;/p&gt;\n\n&lt;p&gt;For context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026&lt;/p&gt;\n\n&lt;p&gt;More recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Thanks for any input. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blhvrx", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "subreddit_subscribers": 171241, "created_utc": 1711162450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm inheriting a system that is all buckets and functions with an SQL flavor for running queries. There are a few VMs for some persistent jobs. Are there any tools that would help this system with observability, maintenance, extension, and reliability? It's more data heavy then it is compute heavy.  \nThanks for your thoughts.", "author_fullname": "t2_3lqaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "buckets of blobs and cloudy functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blbtxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711145801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m inheriting a system that is all buckets and functions with an SQL flavor for running queries. There are a few VMs for some persistent jobs. Are there any tools that would help this system with observability, maintenance, extension, and reliability? It&amp;#39;s more data heavy then it is compute heavy.&lt;br/&gt;\nThanks for your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blbtxo", "is_robot_indexable": true, "report_reasons": null, "author": "Someoneoldbutnew", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blbtxo/buckets_of_blobs_and_cloudy_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blbtxo/buckets_of_blobs_and_cloudy_functions/", "subreddit_subscribers": 171241, "created_utc": 1711145801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello fellow data engineers! \n\nI recently switched companies and I'm diving into cloud services more extensively than ever before. Previously, I've worked with AWS but approach was waaay different, also I worked in a company that used Snowflake and BigQuery + GCS at another. This new role introduces me to a range of AWS services like Lambda, EC2, Kinesis Data Stream, Kinesis Firehose, Glue, Redshift, DMS, EMR, and more.\n\nIn my previous experiences, we always had code versioning and CI/CD processes using tools like Jenkins or GitLab. Usually, I would create a feature branch from the development branch, commit changes, and push them. After a review, the CI/CD system would handle the deployment to the development environment, and later to production. Production was managed solely through CI/CD pipelines.\n\nHowever, in my current role, the approach is different. Instead of uusing CI/CD for deployments, my team directly writes and tests code on AWS, starting with development tables (code testing), then moving to a staging tables (data validation I guess?!) before deploying to production. This methodology seems to bypass the traditional CI/CD pipeline approach (hands OFF the PROD).\n\nI'm grappling with the concept of having only one AWS environment (production) and testing everything there directly. It raises questions about the necessity of CI/CD. If the Lambda function works in the development environment, does that mean it will work in production without any additional checks or safeguards?\n\nIn my previous experience with Airflow, we maintained separate development and production environments. Changes were tested in the development environment, and upon approval, they were merged into the production branch triggering builds, tests, and deployments automatically and DAGs would be present on Prod without me ever laying a hand on it.\n\nI'm curious to hear about your experiences with implementing code versioning and CI/CD on AWS using GitLab or GitHub. How does your company handle these processes? Thank you for sharing your insights!", "author_fullname": "t2_2jtk54zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD and Code Versioning on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bm3wsz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711230429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers! &lt;/p&gt;\n\n&lt;p&gt;I recently switched companies and I&amp;#39;m diving into cloud services more extensively than ever before. Previously, I&amp;#39;ve worked with AWS but approach was waaay different, also I worked in a company that used Snowflake and BigQuery + GCS at another. This new role introduces me to a range of AWS services like Lambda, EC2, Kinesis Data Stream, Kinesis Firehose, Glue, Redshift, DMS, EMR, and more.&lt;/p&gt;\n\n&lt;p&gt;In my previous experiences, we always had code versioning and CI/CD processes using tools like Jenkins or GitLab. Usually, I would create a feature branch from the development branch, commit changes, and push them. After a review, the CI/CD system would handle the deployment to the development environment, and later to production. Production was managed solely through CI/CD pipelines.&lt;/p&gt;\n\n&lt;p&gt;However, in my current role, the approach is different. Instead of uusing CI/CD for deployments, my team directly writes and tests code on AWS, starting with development tables (code testing), then moving to a staging tables (data validation I guess?!) before deploying to production. This methodology seems to bypass the traditional CI/CD pipeline approach (hands OFF the PROD).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m grappling with the concept of having only one AWS environment (production) and testing everything there directly. It raises questions about the necessity of CI/CD. If the Lambda function works in the development environment, does that mean it will work in production without any additional checks or safeguards?&lt;/p&gt;\n\n&lt;p&gt;In my previous experience with Airflow, we maintained separate development and production environments. Changes were tested in the development environment, and upon approval, they were merged into the production branch triggering builds, tests, and deployments automatically and DAGs would be present on Prod without me ever laying a hand on it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear about your experiences with implementing code versioning and CI/CD on AWS using GitLab or GitHub. How does your company handle these processes? Thank you for sharing your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm3wsz", "is_robot_indexable": true, "report_reasons": null, "author": "d_underdog", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bm3wsz/cicd_and_code_versioning_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm3wsz/cicd_and_code_versioning_on_aws/", "subreddit_subscribers": 171241, "created_utc": 1711230429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nWe are working on a project where the architecture will be like:\n\nADF --&gt; Dabtabricks(ETL) --&gt; Synapse(BI layer)\n\nAnd everything is stored in ADLS gen2.\n\nThe reason we chose Synapse was because our BI team wanted something similar to SQL as they have reports datasets written in SQL and wanted a platform to access databases same way they do now.\n\n&amp;#x200B;\n\nAnd now we have dedicated SQL pools for them and they would access data stored in silver and gold layer. \n\n&amp;#x200B;\n\nSo either we copy the data every day and do duplication of data. ( more development effort to upsert the data and since we copying data, more time taken to finish the whole process.)\n\nOR\n\nwrite external tables for each table. ( less development effort but network latency and not as optimized as internal tables)\n\nWe process close to 4-5 million records in a day to give you estimate on the volume.\n\n&amp;#x200B;\n\nOr if there is another solution I am overlooking?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_kz99f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copy data into dedicated SQL pool from Databricks or create External tables in Synapse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bm2imt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;We are working on a project where the architecture will be like:&lt;/p&gt;\n\n&lt;p&gt;ADF --&amp;gt; Dabtabricks(ETL) --&amp;gt; Synapse(BI layer)&lt;/p&gt;\n\n&lt;p&gt;And everything is stored in ADLS gen2.&lt;/p&gt;\n\n&lt;p&gt;The reason we chose Synapse was because our BI team wanted something similar to SQL as they have reports datasets written in SQL and wanted a platform to access databases same way they do now.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And now we have dedicated SQL pools for them and they would access data stored in silver and gold layer. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So either we copy the data every day and do duplication of data. ( more development effort to upsert the data and since we copying data, more time taken to finish the whole process.)&lt;/p&gt;\n\n&lt;p&gt;OR&lt;/p&gt;\n\n&lt;p&gt;write external tables for each table. ( less development effort but network latency and not as optimized as internal tables)&lt;/p&gt;\n\n&lt;p&gt;We process close to 4-5 million records in a day to give you estimate on the volume.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or if there is another solution I am overlooking?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm2imt", "is_robot_indexable": true, "report_reasons": null, "author": "jerrie86", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm2imt/copy_data_into_dedicated_sql_pool_from_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm2imt/copy_data_into_dedicated_sql_pool_from_databricks/", "subreddit_subscribers": 171241, "created_utc": 1711226908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I'm an American DE working in France. I regularly find good freelance gigs here (notably through a platform called malt). As I'm moving back to the states soon I'd like to test the freelance market there.\n\nI'm wondering if anyone does that full-time, and what platforms work best? Would Upwork still be the go-to or are there more specialized data or IT-focused platforms?", "author_fullname": "t2_gcq3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best platforms for finding freelance US-based DE gigs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm1kyn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711224580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m an American DE working in France. I regularly find good freelance gigs here (notably through a platform called malt). As I&amp;#39;m moving back to the states soon I&amp;#39;d like to test the freelance market there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if anyone does that full-time, and what platforms work best? Would Upwork still be the go-to or are there more specialized data or IT-focused platforms?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm1kyn", "is_robot_indexable": true, "report_reasons": null, "author": "johnsonfrusciante", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm1kyn/best_platforms_for_finding_freelance_usbased_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm1kyn/best_platforms_for_finding_freelance_usbased_de/", "subreddit_subscribers": 171241, "created_utc": 1711224580.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}