{"kind": "Listing", "data": {"after": null, "dist": 6, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "And if yes, where does one find the commonly accepted approaches?\n\nFor context, say you are asked to solve a churn problem. How do you get started on this? Do you read published literature? Medium articles? Ask your senior? Just know off the top of your head? \n\nAs someone early in their career I would like to know how to find the generally accepted approach of trying to solve a problem that has been solved before.", "author_fullname": "t2_wsaymmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there accepted approaches/starting points to solving common problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b310nm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709215328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And if yes, where does one find the commonly accepted approaches?&lt;/p&gt;\n\n&lt;p&gt;For context, say you are asked to solve a churn problem. How do you get started on this? Do you read published literature? Medium articles? Ask your senior? Just know off the top of your head? &lt;/p&gt;\n\n&lt;p&gt;As someone early in their career I would like to know how to find the generally accepted approach of trying to solve a problem that has been solved before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b310nm", "is_robot_indexable": true, "report_reasons": null, "author": "jstr36", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b310nm/are_there_accepted_approachesstarting_points_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b310nm/are_there_accepted_approachesstarting_points_to/", "subreddit_subscribers": 1383022, "created_utc": 1709215328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am the only analyst working at my job which is the center of a consortium, with a lot of different audiences demanding information. In the last few months, my job was pushed to launch a new program without having everything fully ready to go yet. Now, we are in a situation where our main database is going through weekly changes while people are collecting data, with little documentation on what actually means what. It's being built as we're using it, to the frustration of everyone, but especially me because it turns a 10 minute pull into a 2 hour one while I have to go hunt down what things actually mean what.\n\nThere are last minute data requests from people who don't even fully know what data they're asking for, people who want involved analyses within two days, etc, all while our database is changing constantly. Someone from our board recently asked for numbers of \"top 10 states\" but gave no specification. Top 10 what? When asked, all he replied with was \"I'd be interested in absolute numbers and per capita numbers\" and still no specification. And he wanted it almost immediately so he'd have a talking point for a speech.\n\nA lot of them are either ignoring the dashboards that can give them the info they look for, or aren't allowed to have direct access in the first place because my org is strict with who can access what. I can't leave this job until June, but what methods can I use to get control of these requests, or what data policies can I advocate for with my higher-ups, because they don't know anything about tech or data. At this point, I'm going to either ignore silly requests, tell them to go look at the dashboards, or tell people they'll have to wait to receive it.", "author_fullname": "t2_3u65v6ol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get control of last minute data requests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b32h79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709219167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the only analyst working at my job which is the center of a consortium, with a lot of different audiences demanding information. In the last few months, my job was pushed to launch a new program without having everything fully ready to go yet. Now, we are in a situation where our main database is going through weekly changes while people are collecting data, with little documentation on what actually means what. It&amp;#39;s being built as we&amp;#39;re using it, to the frustration of everyone, but especially me because it turns a 10 minute pull into a 2 hour one while I have to go hunt down what things actually mean what.&lt;/p&gt;\n\n&lt;p&gt;There are last minute data requests from people who don&amp;#39;t even fully know what data they&amp;#39;re asking for, people who want involved analyses within two days, etc, all while our database is changing constantly. Someone from our board recently asked for numbers of &amp;quot;top 10 states&amp;quot; but gave no specification. Top 10 what? When asked, all he replied with was &amp;quot;I&amp;#39;d be interested in absolute numbers and per capita numbers&amp;quot; and still no specification. And he wanted it almost immediately so he&amp;#39;d have a talking point for a speech.&lt;/p&gt;\n\n&lt;p&gt;A lot of them are either ignoring the dashboards that can give them the info they look for, or aren&amp;#39;t allowed to have direct access in the first place because my org is strict with who can access what. I can&amp;#39;t leave this job until June, but what methods can I use to get control of these requests, or what data policies can I advocate for with my higher-ups, because they don&amp;#39;t know anything about tech or data. At this point, I&amp;#39;m going to either ignore silly requests, tell them to go look at the dashboards, or tell people they&amp;#39;ll have to wait to receive it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b32h79", "is_robot_indexable": true, "report_reasons": null, "author": "lemonbottles_89", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b32h79/how_to_get_control_of_last_minute_data_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b32h79/how_to_get_control_of_last_minute_data_requests/", "subreddit_subscribers": 1383022, "created_utc": 1709219167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a project aimed at predicting pet insurance claims based on historical data. Our dataset includes 5 million rows, capturing both instances where claims were made (with a specific condition noted) and years without claims (indicated by a NULL condition). These conditions are grouped into 20 higher-level categories by domain experts. Along with that each breed is grouped into a higher-level grouping.\n\nI am approaching this as a supervised learning problem in the same way found in this [paper](https://www.nature.com/articles/s41598-023-36023-5), treating each pet's year as a separate sample. This means a pet with 7 years of data contributes 7 samples(regardless of if it made a claim or not), with features derived from the preceding years' data and the target (claim or no claim) for that year. My goal is to create a binary classifier for each of the 20 disease groupings, incorporating features like recency (e.g., skin\\_condition\\_last\\_year, skin\\_condition\\_claim\\_avg and so on for each disease grouping), disease characteristics (e.g., pain\\_score), and breed groupings. So, one example would be a model for skin conditions for example that would predict given the preceding years info if the pet would have a skin\\_condition claim in the next year.\n\n\u00a0The big challenges I am facing are:\n\n* Imbalanced Data: For each disease grouping, positive samples (i.e., a claim was made) constitute only 1-2% of the data.\n* Feature Selection: Identifying the most relevant features for predicting claims is challenging, along with finding relevant features to create.\n\nCurrent Strategies Under Consideration:\n\n* \u00a0Logistic Regression: Adjusting class weights,employing Repeated Stratified Cross-Validation, and threshold tuning for optimisation.\n* Gradient Boosting Models: Experimenting with CatBoost and XGBoost, adjusting for the imbalanced dataset.\n* Nested Classification: Initially determining whether a claim was made before classifying the specific disease group.\n\n\u00a0I'm seeking advice from those who have tackled similar modelling challenges, especially in the context of imbalanced datasets and feature selection. Any insights on the methodologies outlined above, or recommendations on alternative approaches, would be greatly appreciated. Additionally, if you\u2019ve come across relevant papers or resources that could aid in refining my approach, that would be amazing.\n\nThanks in advance for your help and guidance!", "author_fullname": "t2_u7io3tm4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classification model on pet health insurance claims data with strong imbalance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3pki9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709282497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project aimed at predicting pet insurance claims based on historical data. Our dataset includes 5 million rows, capturing both instances where claims were made (with a specific condition noted) and years without claims (indicated by a NULL condition). These conditions are grouped into 20 higher-level categories by domain experts. Along with that each breed is grouped into a higher-level grouping.&lt;/p&gt;\n\n&lt;p&gt;I am approaching this as a supervised learning problem in the same way found in this &lt;a href=\"https://www.nature.com/articles/s41598-023-36023-5\"&gt;paper&lt;/a&gt;, treating each pet&amp;#39;s year as a separate sample. This means a pet with 7 years of data contributes 7 samples(regardless of if it made a claim or not), with features derived from the preceding years&amp;#39; data and the target (claim or no claim) for that year. My goal is to create a binary classifier for each of the 20 disease groupings, incorporating features like recency (e.g., skin_condition_last_year, skin_condition_claim_avg and so on for each disease grouping), disease characteristics (e.g., pain_score), and breed groupings. So, one example would be a model for skin conditions for example that would predict given the preceding years info if the pet would have a skin_condition claim in the next year.&lt;/p&gt;\n\n&lt;p&gt;\u00a0The big challenges I am facing are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Imbalanced Data: For each disease grouping, positive samples (i.e., a claim was made) constitute only 1-2% of the data.&lt;/li&gt;\n&lt;li&gt;Feature Selection: Identifying the most relevant features for predicting claims is challenging, along with finding relevant features to create.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Current Strategies Under Consideration:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\u00a0Logistic Regression: Adjusting class weights,employing Repeated Stratified Cross-Validation, and threshold tuning for optimisation.&lt;/li&gt;\n&lt;li&gt;Gradient Boosting Models: Experimenting with CatBoost and XGBoost, adjusting for the imbalanced dataset.&lt;/li&gt;\n&lt;li&gt;Nested Classification: Initially determining whether a claim was made before classifying the specific disease group.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;\u00a0I&amp;#39;m seeking advice from those who have tackled similar modelling challenges, especially in the context of imbalanced datasets and feature selection. Any insights on the methodologies outlined above, or recommendations on alternative approaches, would be greatly appreciated. Additionally, if you\u2019ve come across relevant papers or resources that could aid in refining my approach, that would be amazing.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help and guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?auto=webp&amp;s=2c3666a855cbc443251f40377ff230adc1d3e1e7", "width": 685, "height": 503}, "resolutions": [{"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b94f6a9554200ddd141a8478847de36f1005b67", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b970b987aafa51fa3e91a9dae502ae477a1d7f5", "width": 216, "height": 158}, {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e247a6b3b5142866e7082af868aed3c5f9d3550", "width": 320, "height": 234}, {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35548fa0b89995cfda807b0ecbaa30f227806716", "width": 640, "height": 469}], "variants": {}, "id": "hnpMLf_nVtPXYhMs615i_AhD6a-UIdkAS7Milta7GBY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1b3pki9", "is_robot_indexable": true, "report_reasons": null, "author": "LebrawnJames416", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b3pki9/classification_model_on_pet_health_insurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b3pki9/classification_model_on_pet_health_insurance/", "subreddit_subscribers": 1383022, "created_utc": 1709282497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a pretty new data scientist in big tech I churn out a lot of experiment launches but haven't had a stakeholder ask for this before. \n\nIf we have 3 experiments that each improved a metric by 10% during the experiment, we launch all 3 a month later, and the metric improves by 15%, how do we know the contribution from each launch?", "author_fullname": "t2_2ocktbno", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Measuring the actual impact of experiment launches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b36w4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709229981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a pretty new data scientist in big tech I churn out a lot of experiment launches but haven&amp;#39;t had a stakeholder ask for this before. &lt;/p&gt;\n\n&lt;p&gt;If we have 3 experiments that each improved a metric by 10% during the experiment, we launch all 3 a month later, and the metric improves by 15%, how do we know the contribution from each launch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b36w4f", "is_robot_indexable": true, "report_reasons": null, "author": "bukakke-n-chill", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b36w4f/measuring_the_actual_impact_of_experiment_launches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b36w4f/measuring_the_actual_impact_of_experiment_launches/", "subreddit_subscribers": 1383022, "created_utc": 1709229981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve blocked most of the names that post every day unless I find their content engaging. But it left me wondering, what are the motivations for people who spend what I assume is several hours every week posting non-stop. \n\nThe posts themselves are not monetized. Do hourly consulting opportunities usually come this way? Some of these people are corporate employees so it\u2019s not just consultants unless they are all trying for side money. Is it a long term play to secure more job opportunities in the future? Both? Other things they\u2019re building and trying to sell? Just to create a massive but impersonal network? What are the various reasons people do this?\n\nIt takes me mental energy to make even 1 post every couple weeks, so I am always dumbfounded when some people pour so much energy into this when they\u2019re already in a high paying career.", "author_fullname": "t2_a3c282tw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the motivations of LinkedIn influencers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3spfx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709294716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve blocked most of the names that post every day unless I find their content engaging. But it left me wondering, what are the motivations for people who spend what I assume is several hours every week posting non-stop. &lt;/p&gt;\n\n&lt;p&gt;The posts themselves are not monetized. Do hourly consulting opportunities usually come this way? Some of these people are corporate employees so it\u2019s not just consultants unless they are all trying for side money. Is it a long term play to secure more job opportunities in the future? Both? Other things they\u2019re building and trying to sell? Just to create a massive but impersonal network? What are the various reasons people do this?&lt;/p&gt;\n\n&lt;p&gt;It takes me mental energy to make even 1 post every couple weeks, so I am always dumbfounded when some people pour so much energy into this when they\u2019re already in a high paying career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b3spfx", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Detective3852", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b3spfx/what_are_the_motivations_of_linkedin_influencers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b3spfx/what_are_the_motivations_of_linkedin_influencers/", "subreddit_subscribers": 1383022, "created_utc": 1709294716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anybody know of tools that can take spreadsheet data like 5k rows 10 columns and manipulate it with ai language prompts, cleaning data, removing dupes, moving data with certain criteria like a missing website in a contact list to a new sheet, create pivot tables to analyse further unless it can so it in another way so you end up with a new final sheet of exactly the data you want after multiple steps of cleaning and manipulation? Thanks", "author_fullname": "t2_3onpl36q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI spreadsheet/data manipulation, generation, cleaning etc tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3nqxj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709275218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody know of tools that can take spreadsheet data like 5k rows 10 columns and manipulate it with ai language prompts, cleaning data, removing dupes, moving data with certain criteria like a missing website in a contact list to a new sheet, create pivot tables to analyse further unless it can so it in another way so you end up with a new final sheet of exactly the data you want after multiple steps of cleaning and manipulation? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b3nqxj", "is_robot_indexable": true, "report_reasons": null, "author": "jayn35", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b3nqxj/ai_spreadsheetdata_manipulation_generation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b3nqxj/ai_spreadsheetdata_manipulation_generation/", "subreddit_subscribers": 1383022, "created_utc": 1709275218.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}