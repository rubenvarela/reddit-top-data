{"kind": "Listing", "data": {"after": "t3_1b3pi32", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, asking for guidance as my company wanted to migrate to cloud. Currently our process is:\n1. Collect multiple excel files from sharepoint\n2. Transform it thru python code\n3. Store it as a parquet in sharepoint\n4. Feed the parquets to Power BI and more transformation is done in Power Query.\n\nNow, they want to use Talend as ETL solution then use SQL to connect it to PBI but I\u2019m not sure how well it will handle the job we do thru python. The process is done around once a week and it would be helpful if we can have those process automated. They have looked into procuring Azure but they said that Talend is more budget friendly. Are we doing the right thing? I thought what we would need the most is a data warehouse. ", "author_fullname": "t2_57luzhesi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company wants to migrate to cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3mntn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709271381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, asking for guidance as my company wanted to migrate to cloud. Currently our process is:\n1. Collect multiple excel files from sharepoint\n2. Transform it thru python code\n3. Store it as a parquet in sharepoint\n4. Feed the parquets to Power BI and more transformation is done in Power Query.&lt;/p&gt;\n\n&lt;p&gt;Now, they want to use Talend as ETL solution then use SQL to connect it to PBI but I\u2019m not sure how well it will handle the job we do thru python. The process is done around once a week and it would be helpful if we can have those process automated. They have looked into procuring Azure but they said that Talend is more budget friendly. Are we doing the right thing? I thought what we would need the most is a data warehouse. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3mntn", "is_robot_indexable": true, "report_reasons": null, "author": "akanensan", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3mntn/company_wants_to_migrate_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3mntn/company_wants_to_migrate_to_cloud/", "subreddit_subscribers": 164951, "created_utc": 1709271381.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The data is in a table in redshift. On loading this data we plan to run few ML functions on the data (random forest etc), so doing it in python/pandas is essential. Any ideas/suggestions on how this can be performed ?\nEdit: Tech stack currently does not have spark. We are a small team that operates on pandas and sql", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I load a 70 million row table in a dataframe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3cb1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709243537.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709242979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The data is in a table in redshift. On loading this data we plan to run few ML functions on the data (random forest etc), so doing it in python/pandas is essential. Any ideas/suggestions on how this can be performed ?\nEdit: Tech stack currently does not have spark. We are a small team that operates on pandas and sql&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3cb1t", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3cb1t/how_do_i_load_a_70_million_row_table_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3cb1t/how_do_i_load_a_70_million_row_table_in_a/", "subreddit_subscribers": 164951, "created_utc": 1709242979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do companies in healthcare or climate tech hire data or distributed systems engineers?\n\nAre these jobs fulfilling careers? Are the people well renumerated.", "author_fullname": "t2_vqjalmbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer jobs in healthcare or climate tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b374j2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709230558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do companies in healthcare or climate tech hire data or distributed systems engineers?&lt;/p&gt;\n\n&lt;p&gt;Are these jobs fulfilling careers? Are the people well renumerated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b374j2", "is_robot_indexable": true, "report_reasons": null, "author": "diego-the-tortoise", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b374j2/data_engineer_jobs_in_healthcare_or_climate_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b374j2/data_engineer_jobs_in_healthcare_or_climate_tech/", "subreddit_subscribers": 164951, "created_utc": 1709230558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! I got some great help when asking about a similar topic on Reddit before so wanted to see some perspectives on this.   \n\n\nI am working in a databricks environment where my team feels like it's hard to get a good setup for the projects structure and good code quality in our notebooks. For some reason, even though the notebooks are basically run top-down when running processing jobs with them, it's harder to get good code in notebooks. Does anyone have the same experience?   \n\n\nAre there any given best practices when coding notebooks for spark jobs or similar processing? And how would we create a structure (like grouping folders with code by level of refinement in medallion for example, so one folder for the code used for creating bronze, one for silver and so on) to make the code make more sense? It's not a very large scale project either.\n\n&amp;#x200B;\n\nAny thoughts appreciated! ", "author_fullname": "t2_7fu4vx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices on notebook-based project structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3p36n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709280526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! I got some great help when asking about a similar topic on Reddit before so wanted to see some perspectives on this.   &lt;/p&gt;\n\n&lt;p&gt;I am working in a databricks environment where my team feels like it&amp;#39;s hard to get a good setup for the projects structure and good code quality in our notebooks. For some reason, even though the notebooks are basically run top-down when running processing jobs with them, it&amp;#39;s harder to get good code in notebooks. Does anyone have the same experience?   &lt;/p&gt;\n\n&lt;p&gt;Are there any given best practices when coding notebooks for spark jobs or similar processing? And how would we create a structure (like grouping folders with code by level of refinement in medallion for example, so one folder for the code used for creating bronze, one for silver and so on) to make the code make more sense? It&amp;#39;s not a very large scale project either.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts appreciated! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3p36n", "is_robot_indexable": true, "report_reasons": null, "author": "Maxxlax", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3p36n/best_practices_on_notebookbased_project_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3p36n/best_practices_on_notebookbased_project_structure/", "subreddit_subscribers": 164951, "created_utc": 1709280526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\n\nThis is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.\n\n# [Submit your salary here](https://tally.so/r/nraYkN)\n\nYou can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).\n\n&amp;#x200B;\n\nIf you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:\n\n1. Current title\n2. Years of experience (YOE)\n3. Location\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n5. Bonuses/Equity (optional)\n6. Industry (optional)\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion - Mar 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo", "t3_13xldpd", "t3_167b3ep", "t3_188grde", "t3_1b3zatv"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1709312446.881, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"ia7kdykk8dlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=814f58d3eef18e16ebfd881a24dc42c6278c74a5"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=220aef8c88d2d3542556dbc0ceda11308fae54cd"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc0f5873d0a5e748e4664a4925eb409775331c20"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd"}, "id": "ia7kdykk8dlb1"}}, "name": "t3_1b3zatv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 12, "domain": "self.dataengineering", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/WxbPZZDAlp5ZrmC7zINz_BAGO251Q2TbQDAOSYvGspE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709312446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\"&gt;https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://tally.so/r/nraYkN\"&gt;Submit your salary here&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can view and analyze all of the data on our &lt;a href=\"https://dataengineering.wiki/Community/Salaries\"&gt;DE salary page&lt;/a&gt; and get involved with this open-source project &lt;a href=\"https://github.com/data-engineering-community/data-engineering-salaries\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Current title&lt;/li&gt;\n&lt;li&gt;Years of experience (YOE)&lt;/li&gt;\n&lt;li&gt;Location&lt;/li&gt;\n&lt;li&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/li&gt;\n&lt;li&gt;Bonuses/Equity (optional)&lt;/li&gt;\n&lt;li&gt;Industry (optional)&lt;/li&gt;\n&lt;li&gt;Tech stack (optional)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?auto=webp&amp;s=c116639b0e48888e352e060ba2c5f56c07ab43d9", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab73c993eac3ccefd58966d64ec6e5a5dd05f808", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1955a17c66a64ef42bfc6aa52227a3b0a183660b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfad0ea778337cf0589b3428603d1e71cff228fb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a6b65e67a3bcf61b738f8852810c86c1b01298f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b95d64dc6f3995876325c594dbe2dd77c627d406", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=079bd9b9cebe8cd705d7824f7f2a75c5213c3cf7", "width": 1080, "height": 567}], "variants": {}, "id": "vXOF8G9GBUU_-_vM38jf2S1-5UiTZqBcFWecpk4eHS4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b3zatv", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3zatv/quarterly_salary_discussion_mar_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/1b3zatv/quarterly_salary_discussion_mar_2024/", "subreddit_subscribers": 164951, "created_utc": 1709312446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am investigating current ELT/ETL tools like airbyte, cloudquery, fivetran etc. and all of them seems to be very complicated to setup and maintain locally due to their architecture with different types of containers and moving parts.\n\nIs this complexity really worth it? As a user do you think a simpler alternative like a single executable be better? What are your thoughts about the usage experience and maintainability?", "author_fullname": "t2_20n43h6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about current ELT/ETL tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3vdae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709302750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am investigating current ELT/ETL tools like airbyte, cloudquery, fivetran etc. and all of them seems to be very complicated to setup and maintain locally due to their architecture with different types of containers and moving parts.&lt;/p&gt;\n\n&lt;p&gt;Is this complexity really worth it? As a user do you think a simpler alternative like a single executable be better? What are your thoughts about the usage experience and maintainability?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3vdae", "is_robot_indexable": true, "report_reasons": null, "author": "gibriyagi", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3vdae/thoughts_about_current_eltetl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3vdae/thoughts_about_current_eltetl_tools/", "subreddit_subscribers": 164951, "created_utc": 1709302750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm talking about something more in-depth than ERD diagrams. Possibly includes some graph theory analysis like the centrality of a table etc. Something that shows the flow of data linked by stored procedures, connections based on keys, list of triggers/keys/constraints. I've been working with SSMS/Azure Data Factory and I don't see anything on the market that currently fits my needs.   \n\n\n&amp;#x200B;", "author_fullname": "t2_xzn0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools do you guys use for schema analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3m3lh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709269528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m talking about something more in-depth than ERD diagrams. Possibly includes some graph theory analysis like the centrality of a table etc. Something that shows the flow of data linked by stored procedures, connections based on keys, list of triggers/keys/constraints. I&amp;#39;ve been working with SSMS/Azure Data Factory and I don&amp;#39;t see anything on the market that currently fits my needs.   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3m3lh", "is_robot_indexable": true, "report_reasons": null, "author": "richhoods", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3m3lh/what_tools_do_you_guys_use_for_schema_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3m3lh/what_tools_do_you_guys_use_for_schema_analysis/", "subreddit_subscribers": 164951, "created_utc": 1709269528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been doing this for my own enjoyment for a while now, something very close to what the guy(s) at [the pop foot](https://www.google.com/search?sca_esv=59998079312419c0&amp;q=thepopfoot&amp;tbm=isch&amp;source=lnms&amp;sa=X&amp;ved=2ahUKEwikqqyZ_9GEAxW9ANAFHd4nAioQ0pQJegQIDRAB&amp;biw=1920&amp;bih=953) have been doing (just to give you an example). I normally gather data of various teams/players of a certain sport, make some averages here and there and then just compare them out. Nothing too fancy but definitely not simply gathering data and organizing it. I don't think I'd be very good at making graphs/visuals so I just stick to good ol basic excel tables.\n\nYesterday I was having a conversation with some friends on some recent \"data comparison\" I made between teams (not sure if I should call it analysis nor \"insight\") and we all agreed that it made TOO MUCH sense in the end. Kind of made me realize I could be doing this sort of thing as a job; made some google searches and found out about data engineering.\n\nAm I in the right place? Or is analysis the thing I should be aiming for?", "author_fullname": "t2_drxgr3df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I gather, organize and make \"insights\" out of sport data for myself as a hobby. Is this the correct career path for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3jcm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709261145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been doing this for my own enjoyment for a while now, something very close to what the guy(s) at &lt;a href=\"https://www.google.com/search?sca_esv=59998079312419c0&amp;amp;q=thepopfoot&amp;amp;tbm=isch&amp;amp;source=lnms&amp;amp;sa=X&amp;amp;ved=2ahUKEwikqqyZ_9GEAxW9ANAFHd4nAioQ0pQJegQIDRAB&amp;amp;biw=1920&amp;amp;bih=953\"&gt;the pop foot&lt;/a&gt; have been doing (just to give you an example). I normally gather data of various teams/players of a certain sport, make some averages here and there and then just compare them out. Nothing too fancy but definitely not simply gathering data and organizing it. I don&amp;#39;t think I&amp;#39;d be very good at making graphs/visuals so I just stick to good ol basic excel tables.&lt;/p&gt;\n\n&lt;p&gt;Yesterday I was having a conversation with some friends on some recent &amp;quot;data comparison&amp;quot; I made between teams (not sure if I should call it analysis nor &amp;quot;insight&amp;quot;) and we all agreed that it made TOO MUCH sense in the end. Kind of made me realize I could be doing this sort of thing as a job; made some google searches and found out about data engineering.&lt;/p&gt;\n\n&lt;p&gt;Am I in the right place? Or is analysis the thing I should be aiming for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3jcm4", "is_robot_indexable": true, "report_reasons": null, "author": "CarlosHnnz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3jcm4/i_gather_organize_and_make_insights_out_of_sport/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3jcm4/i_gather_organize_and_make_insights_out_of_sport/", "subreddit_subscribers": 164951, "created_utc": 1709261145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, havent seen any info on this, so perhaps its very dumb idea... would it make sense to run Polars on Databricks, using single node clusters.?\n\nReasoning being,... trying to get the advantages/features of databricks while at the same time using a small single node cluster with Polars instead of Spark/Pyspark to process data.   any opinions?\n\n", "author_fullname": "t2_3laxwg3l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b37ca1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709231087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, havent seen any info on this, so perhaps its very dumb idea... would it make sense to run Polars on Databricks, using single node clusters.?&lt;/p&gt;\n\n&lt;p&gt;Reasoning being,... trying to get the advantages/features of databricks while at the same time using a small single node cluster with Polars instead of Spark/Pyspark to process data.   any opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b37ca1", "is_robot_indexable": true, "report_reasons": null, "author": "acelisalas", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b37ca1/polars_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b37ca1/polars_on_databricks/", "subreddit_subscribers": 164951, "created_utc": 1709231087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\ni'm currently responsible for building a database out of research data, this is my first data engineering task.   \nThe data in general is a bunch (magnitude 100) of 1GB CSV-Files, with groups of files (\\~10) being the result of a different analysis &amp; aggregation of 10 different base corpoa with extremly similar structure. The task is to parse these into a DB (including some more custom aggregations and restructuring) in order to build a visualization on top of it - and i don't know what my tooling should be.   \n\n\nSo far i've been working in pandas, but it's no fun. I've been developing on a subset of files, one for each group, and a subslice of each of these files (around 10MB), but scaling it up to the full files breaks, because:  it's very messy data with unexpected missing values, different column names, encodings. One run for one group takes \"forever\" (\\~1h) on the large files until i get the result \"breaking in step X\", then i'd debug this, write another edge-case-treatment and re-run (sometimes looping this for a whole day), so i'm making extreme slow process.   \n\n\nAny tips / literature on how to build such a system more efficiently / less painfully? Does it just take that long and i should tune down my expectations? ", "author_fullname": "t2_295e63iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficiently developing a pipeline for large, messy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3xuan", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709308972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m currently responsible for building a database out of research data, this is my first data engineering task.&lt;br/&gt;\nThe data in general is a bunch (magnitude 100) of 1GB CSV-Files, with groups of files (~10) being the result of a different analysis &amp;amp; aggregation of 10 different base corpoa with extremly similar structure. The task is to parse these into a DB (including some more custom aggregations and restructuring) in order to build a visualization on top of it - and i don&amp;#39;t know what my tooling should be.   &lt;/p&gt;\n\n&lt;p&gt;So far i&amp;#39;ve been working in pandas, but it&amp;#39;s no fun. I&amp;#39;ve been developing on a subset of files, one for each group, and a subslice of each of these files (around 10MB), but scaling it up to the full files breaks, because:  it&amp;#39;s very messy data with unexpected missing values, different column names, encodings. One run for one group takes &amp;quot;forever&amp;quot; (~1h) on the large files until i get the result &amp;quot;breaking in step X&amp;quot;, then i&amp;#39;d debug this, write another edge-case-treatment and re-run (sometimes looping this for a whole day), so i&amp;#39;m making extreme slow process.   &lt;/p&gt;\n\n&lt;p&gt;Any tips / literature on how to build such a system more efficiently / less painfully? Does it just take that long and i should tune down my expectations? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3xuan", "is_robot_indexable": true, "report_reasons": null, "author": "leehawk787", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3xuan/efficiently_developing_a_pipeline_for_large_messy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3xuan/efficiently_developing_a_pipeline_for_large_messy/", "subreddit_subscribers": 164951, "created_utc": 1709308972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nI've got to make a report from our DW on customers and their transactions (for example). I am divided between having a single Spark job handle all the customers+transactions and give it lots of breathing room (in terms of cluster size), or whether I should have the Spark job handle a single customer+(all transactions) and rely on Airflow to get everything done.\n\nAdvice? Please and thank you.\n\nUpdate: The report is like a statement. One report per customer, including all transactions for the given time period.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Many \"customers\" in single Spark job, or many Spark jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3dkm3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709247485.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709245958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got to make a report from our DW on customers and their transactions (for example). I am divided between having a single Spark job handle all the customers+transactions and give it lots of breathing room (in terms of cluster size), or whether I should have the Spark job handle a single customer+(all transactions) and rely on Airflow to get everything done.&lt;/p&gt;\n\n&lt;p&gt;Advice? Please and thank you.&lt;/p&gt;\n\n&lt;p&gt;Update: The report is like a statement. One report per customer, including all transactions for the given time period.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3dkm3", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3dkm3/many_customers_in_single_spark_job_or_many_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3dkm3/many_customers_in_single_spark_job_or_many_spark/", "subreddit_subscribers": 164951, "created_utc": 1709245958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Deep Dive into the Concept and World of Apache Iceberg Catalogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3x4gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l5R7hYeS0BgR22x8GabW0H58QTRPpMjpvJ7jFfesShY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709307251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.datalakehouse.help", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.datalakehouse.help/a-deep-dive-into-the-concept-and-world-of-apache-iceberg-catalogs-c948a2cc25ea", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?auto=webp&amp;s=a98cd9729792a2e9da9ea7f49f8712980209a990", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5ae4f44f81b57fca6b6ef8a47f1af98463cc77", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d1233462d388b3390922ddc523a16b9074dccfb", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=867b8fb3b00177c591d4cd984ef8905fb8d1b107", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce04bf58cef436b78021e3513df38859675055fd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4cd0b16862184899a6ad57b7140c3b12741dfd31", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5195cbcb70a112d6069d20e7706afe21a168455d", "width": 1080, "height": 607}], "variants": {}, "id": "ls8ypxuJ6z3tA7HbOD4Z3GTMQhWB7rVZyH3BwXIunEU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3x4gx", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3x4gx/a_deep_dive_into_the_concept_and_world_of_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.datalakehouse.help/a-deep-dive-into-the-concept-and-world-of-apache-iceberg-catalogs-c948a2cc25ea", "subreddit_subscribers": 164951, "created_utc": 1709307251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.  I am looking to find demo data that I can use to practice some data modeling techniques.  Ideally, this data would be very normalized, such as how it would look when sourced from an application system.  I also hope to find data that includes snapshots of dimensional data to support constructed SCD.  Any suggestions on where I can find such a data set?", "author_fullname": "t2_l04by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demo data for data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3u70d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709299513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.  I am looking to find demo data that I can use to practice some data modeling techniques.  Ideally, this data would be very normalized, such as how it would look when sourced from an application system.  I also hope to find data that includes snapshots of dimensional data to support constructed SCD.  Any suggestions on where I can find such a data set?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3u70d", "is_robot_indexable": true, "report_reasons": null, "author": "kentmaxwell", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3u70d/demo_data_for_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3u70d/demo_data_for_data_modeling/", "subreddit_subscribers": 164951, "created_utc": 1709299513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,  \nI'm currently being offered a role as the data migration lead for a healthcare organisation changing electronic patient record systems. I've been unofficially doing this for a while, but they're talking about making this more official for the next 8 months or so. My background is really in business intelligence, data analysis, etc, so this is somewhat new to me. Is there any resources I should read about best practice for this kind of thing?   \n\n\nBoth of the systems have a SQL Server back end in case that's relevant, although technically the process basically involves creating a bunch of CSVs and loading them into a tool provided by the software supplier.  \nThanks", "author_fullname": "t2_bfginlr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Migration best practice, book/resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3qzi7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709288388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;br/&gt;\nI&amp;#39;m currently being offered a role as the data migration lead for a healthcare organisation changing electronic patient record systems. I&amp;#39;ve been unofficially doing this for a while, but they&amp;#39;re talking about making this more official for the next 8 months or so. My background is really in business intelligence, data analysis, etc, so this is somewhat new to me. Is there any resources I should read about best practice for this kind of thing?   &lt;/p&gt;\n\n&lt;p&gt;Both of the systems have a SQL Server back end in case that&amp;#39;s relevant, although technically the process basically involves creating a bunch of CSVs and loading them into a tool provided by the software supplier.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3qzi7", "is_robot_indexable": true, "report_reasons": null, "author": "MakingNumbersBehave", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3qzi7/data_migration_best_practice_bookresources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3qzi7/data_migration_best_practice_bookresources/", "subreddit_subscribers": 164951, "created_utc": 1709288388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have set up scrapers to extract real estate data with the goal of storing this into a relational database to perform analysis on. I have more focus in data science so I am new to the field of data engineering. Assuming I parse 500 different houses, should i store my data directly into the relational database, or should I save the raw json files and then insert them manually. Also, these json files for each property can get relatively large, while scraping is it unwise to store all of the property json files into one larger json file?\n\nThanks for the help!", "author_fullname": "t2_i1oi9p4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Need advice on intermediate storage of webscraped data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3jjt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709261734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have set up scrapers to extract real estate data with the goal of storing this into a relational database to perform analysis on. I have more focus in data science so I am new to the field of data engineering. Assuming I parse 500 different houses, should i store my data directly into the relational database, or should I save the raw json files and then insert them manually. Also, these json files for each property can get relatively large, while scraping is it unwise to store all of the property json files into one larger json file?&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3jjt1", "is_robot_indexable": true, "report_reasons": null, "author": "No_Map3272", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3jjt1/beginner_need_advice_on_intermediate_storage_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3jjt1/beginner_need_advice_on_intermediate_storage_of/", "subreddit_subscribers": 164951, "created_utc": 1709261734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say you are dealing with multiple csv files, each with over 10 million rows. What kind of validation tests do you perform on the data itself and what type of tests do you write for dealing with database part? Which libraries do you use for it? \n\nAny reference material to read up on would be very helpful! ", "author_fullname": "t2_61uvorko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of validation do you perform on the data and what tests do you write for correct data handling in to a dB? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3ip2a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709259266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say you are dealing with multiple csv files, each with over 10 million rows. What kind of validation tests do you perform on the data itself and what type of tests do you write for dealing with database part? Which libraries do you use for it? &lt;/p&gt;\n\n&lt;p&gt;Any reference material to read up on would be very helpful! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3ip2a", "is_robot_indexable": true, "report_reasons": null, "author": "jadedsprint", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3ip2a/what_kind_of_validation_do_you_perform_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3ip2a/what_kind_of_validation_do_you_perform_on_the/", "subreddit_subscribers": 164951, "created_utc": 1709259266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I own a small business and I have about two years of sales records, our data stack looks like this:  \n\n\nNotion database where we keep the sales records +\n\nPull daily sales into Excel via Power Query through Notion API+\n\nGenerate Excel Pivot Tables and Pivot charts for analysis. The Year/Quarter/Month grouping feature has worked very well so far.\n\nAs you can see these are mostly free and basic tools (I use the single-user, free version of Notion). \n\n  \nNow I would love to migrate this to something where I can do SQL, generate some graphs and perhaps s3 storage. Would like to keep it free as well. \n\nI was thinking of setting up a MySQL and MinIO server in my computer and work from there but I don't know what kind of limitations MinIO has as of today.\n\nDoes anyone have any advice?\n\n&amp;#x200B;", "author_fullname": "t2_5xd8fkm8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for small business data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3fthq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709251466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I own a small business and I have about two years of sales records, our data stack looks like this:  &lt;/p&gt;\n\n&lt;p&gt;Notion database where we keep the sales records +&lt;/p&gt;\n\n&lt;p&gt;Pull daily sales into Excel via Power Query through Notion API+&lt;/p&gt;\n\n&lt;p&gt;Generate Excel Pivot Tables and Pivot charts for analysis. The Year/Quarter/Month grouping feature has worked very well so far.&lt;/p&gt;\n\n&lt;p&gt;As you can see these are mostly free and basic tools (I use the single-user, free version of Notion). &lt;/p&gt;\n\n&lt;p&gt;Now I would love to migrate this to something where I can do SQL, generate some graphs and perhaps s3 storage. Would like to keep it free as well. &lt;/p&gt;\n\n&lt;p&gt;I was thinking of setting up a MySQL and MinIO server in my computer and work from there but I don&amp;#39;t know what kind of limitations MinIO has as of today.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any advice?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3fthq", "is_robot_indexable": true, "report_reasons": null, "author": "carlsLobato", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3fthq/advice_for_small_business_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3fthq/advice_for_small_business_data_stack/", "subreddit_subscribers": 164951, "created_utc": 1709251466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Question for all you that had entry level positions or started off with easier projects. What was the project? What tools did you use? And what was your day to day like?", "author_fullname": "t2_6cmmqb4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Entry Level\" or \"Junior\" if still exist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3afn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709238584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question for all you that had entry level positions or started off with easier projects. What was the project? What tools did you use? And what was your day to day like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3afn7", "is_robot_indexable": true, "report_reasons": null, "author": "chainz3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3afn7/entry_level_or_junior_if_still_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3afn7/entry_level_or_junior_if_still_exist/", "subreddit_subscribers": 164951, "created_utc": 1709238584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data Engineers!\n\nWe're launching, the IOMETE Community Edition on AWS, and looking for insightful testers like you. This is your golden ticket to experience our scalable data lakehouse platform, designed to transform terabytes to petabytes of data, absolutely free.\u00a0You'll be amazed by what you can achieve with our platform.\n\nWe're excited to see how users experiment with the platform by Leveraging Apache Iceberg and Spark for a managed data lakehouse that grows with your data\u2014from terabytes to petabytes\u2014without any vendor lock-in. Enjoy complete control over your data stored in S3 in parquet format, and pay only for the AWS resources you use. Whether you're using Spot or Reserved Instances, IOMETE ensures an affordable path compared to other vendors. Ready to transform your data management strategy?\n\nIOMETE offers several Apache Spark features including:\n\n1. A user-friendly interface and integrated notebook service for data processing and analysis.\n2. Comprehensive monitoring and debugging capabilities for Spark jobs.\n3. Automatic scaling of Spark clusters based on demand.\n4. Capabilities to process real-time data streams from various sources.\n5. A platform for training and deploying machine learning models for tasks like predictive analytics, fraud detection, and customer segmentation.\n\nThese features are designed to help you focus on your data analytics workloads by taking care of the infrastructure and management tasks associated with running Spark - [https://2ly.link/1wFi0](https://2ly.link/1wFi0)\n\nIntrigued? A short video awaits you to guide you through the details and the wonders that IOMETE Community Edition promises - [https://2ly.link/1wFi3](https://2ly.link/1wFi3)\n\nIf you have any questions regarding installation and usage, join our dedicated Discord community, and let's shape the future of data management together - [https://2ly.link/1wFi1](https://2ly.link/1wFi1)\n\nAs of now, the IOMETE Free Community Version can only be deployed on AWS. Please let us know where you would like to deploy the platform so we can prioritize it - [https://2ly.link/1wFi2](https://2ly.link/1wFi2) . We will let you know when your preferred deployment option becomes available", "author_fullname": "t2_9ftsfde7l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IOMETE released the most generous free Data Lakehouse platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3xfzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709308027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Engineers!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re launching, the IOMETE Community Edition on AWS, and looking for insightful testers like you. This is your golden ticket to experience our scalable data lakehouse platform, designed to transform terabytes to petabytes of data, absolutely free.\u00a0You&amp;#39;ll be amazed by what you can achieve with our platform.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re excited to see how users experiment with the platform by Leveraging Apache Iceberg and Spark for a managed data lakehouse that grows with your data\u2014from terabytes to petabytes\u2014without any vendor lock-in. Enjoy complete control over your data stored in S3 in parquet format, and pay only for the AWS resources you use. Whether you&amp;#39;re using Spot or Reserved Instances, IOMETE ensures an affordable path compared to other vendors. Ready to transform your data management strategy?&lt;/p&gt;\n\n&lt;p&gt;IOMETE offers several Apache Spark features including:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A user-friendly interface and integrated notebook service for data processing and analysis.&lt;/li&gt;\n&lt;li&gt;Comprehensive monitoring and debugging capabilities for Spark jobs.&lt;/li&gt;\n&lt;li&gt;Automatic scaling of Spark clusters based on demand.&lt;/li&gt;\n&lt;li&gt;Capabilities to process real-time data streams from various sources.&lt;/li&gt;\n&lt;li&gt;A platform for training and deploying machine learning models for tasks like predictive analytics, fraud detection, and customer segmentation.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These features are designed to help you focus on your data analytics workloads by taking care of the infrastructure and management tasks associated with running Spark - &lt;a href=\"https://2ly.link/1wFi0\"&gt;https://2ly.link/1wFi0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Intrigued? A short video awaits you to guide you through the details and the wonders that IOMETE Community Edition promises - &lt;a href=\"https://2ly.link/1wFi3\"&gt;https://2ly.link/1wFi3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you have any questions regarding installation and usage, join our dedicated Discord community, and let&amp;#39;s shape the future of data management together - &lt;a href=\"https://2ly.link/1wFi1\"&gt;https://2ly.link/1wFi1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As of now, the IOMETE Free Community Version can only be deployed on AWS. Please let us know where you would like to deploy the platform so we can prioritize it - &lt;a href=\"https://2ly.link/1wFi2\"&gt;https://2ly.link/1wFi2&lt;/a&gt; . We will let you know when your preferred deployment option becomes available&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b3xfzr", "is_robot_indexable": true, "report_reasons": null, "author": "IOMETE-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3xfzr/iomete_released_the_most_generous_free_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3xfzr/iomete_released_the_most_generous_free_data/", "subreddit_subscribers": 164951, "created_utc": 1709308027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello r/dataengineering!\n\n&amp;#x200B;\n\nI'm part of the [Jargon.sh](https://Jargon.sh) team, a platform on a mission to bring the principles and tools of open-source software development to Domain Driven Design (DDD) and API design. Our scope is broad, but we've traditionally focused on providing just enough data modelling to meet our users' needs. However, we're seeing a growing demand from clients who are interested in leveraging our platform for general-purpose data modelling, marking a new and exciting direction for us.\n\n&amp;#x200B;\n\nOur clients have shared how much they value the DDD approach for breaking down large models into smaller, more manageable domain models, and how our method of calculating Semantic Version (SemVer) release numbers has been a game-changer for them. These strategies have proven effective for their API design and integration architecture. Additionally, they appreciate Jargon as a platform of reusable models that can be easily searched, discovered, and imported into other domains, all based on immutable SemVer versioned releases. This capability not only enhances the efficiency of their work by promoting reusability and consistency across different projects but also significantly reduces the time and effort required in developing new domain models from scratch. This feedback underscores why our clients are encouraging us to extend our support to include more comprehensive data modelling capabilities.\n\n&amp;#x200B;\n\nOur goal extends beyond offering generic tools; we aim to understand the unique challenges our users face and to develop innovative solutions. By engaging closely with the community, we believe we can customise our solutions to meet specific needs and challenges. This collaborative approach has served us well in the realms of DDD and API, and we're eager to apply it to data modelling for data engineering, hoping to add significant value.\n\n&amp;#x200B;\n\nAs a member of the Jargon team, I'm here to collect your feedback and insights on how an open-source software-inspired approach to data modelling might benefit you. Your input is incredibly important to us as we strive to evolve Jargon into not just a tool, but a community-driven solution that empowers practitioners to achieve what they're trying to do more efficiently.\n\n&amp;#x200B;\n\nI'm quite new to Reddit, having been stalking around for a little while before finding this great community. Our research indicated that this is the most active and engaged data engineering community around, so I decided to reach out. It's clear there's a wealth of knowledge and experience here, and I'm excited to learn from you all and maybe convert some of your knowledge into features of our freely available data modelling platform in return.\n\n&amp;#x200B;\n\nIf you're not familiar with Jargon yet, I invite you to explore our platform. We offer a free-forever tier packed with features that could be of interest to you.\n\n&amp;#x200B;\n\nThank you for your time and insights. I'm looking forward to your feedback, and happy to answer any questions you might have!\n\n&amp;#x200B;", "author_fullname": "t2_36d03l80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pivoting our product from API design to Data Modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3ppn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709283093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m part of the &lt;a href=\"https://Jargon.sh\"&gt;Jargon.sh&lt;/a&gt; team, a platform on a mission to bring the principles and tools of open-source software development to Domain Driven Design (DDD) and API design. Our scope is broad, but we&amp;#39;ve traditionally focused on providing just enough data modelling to meet our users&amp;#39; needs. However, we&amp;#39;re seeing a growing demand from clients who are interested in leveraging our platform for general-purpose data modelling, marking a new and exciting direction for us.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Our clients have shared how much they value the DDD approach for breaking down large models into smaller, more manageable domain models, and how our method of calculating Semantic Version (SemVer) release numbers has been a game-changer for them. These strategies have proven effective for their API design and integration architecture. Additionally, they appreciate Jargon as a platform of reusable models that can be easily searched, discovered, and imported into other domains, all based on immutable SemVer versioned releases. This capability not only enhances the efficiency of their work by promoting reusability and consistency across different projects but also significantly reduces the time and effort required in developing new domain models from scratch. This feedback underscores why our clients are encouraging us to extend our support to include more comprehensive data modelling capabilities.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Our goal extends beyond offering generic tools; we aim to understand the unique challenges our users face and to develop innovative solutions. By engaging closely with the community, we believe we can customise our solutions to meet specific needs and challenges. This collaborative approach has served us well in the realms of DDD and API, and we&amp;#39;re eager to apply it to data modelling for data engineering, hoping to add significant value.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a member of the Jargon team, I&amp;#39;m here to collect your feedback and insights on how an open-source software-inspired approach to data modelling might benefit you. Your input is incredibly important to us as we strive to evolve Jargon into not just a tool, but a community-driven solution that empowers practitioners to achieve what they&amp;#39;re trying to do more efficiently.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m quite new to Reddit, having been stalking around for a little while before finding this great community. Our research indicated that this is the most active and engaged data engineering community around, so I decided to reach out. It&amp;#39;s clear there&amp;#39;s a wealth of knowledge and experience here, and I&amp;#39;m excited to learn from you all and maybe convert some of your knowledge into features of our freely available data modelling platform in return.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re not familiar with Jargon yet, I invite you to explore our platform. We offer a free-forever tier packed with features that could be of interest to you.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and insights. I&amp;#39;m looking forward to your feedback, and happy to answer any questions you might have!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3ppn0", "is_robot_indexable": true, "report_reasons": null, "author": "Jargon-sh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3ppn0/pivoting_our_product_from_api_design_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3ppn0/pivoting_our_product_from_api_design_to_data/", "subreddit_subscribers": 164951, "created_utc": 1709283093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In SQL I need to count occurrences of the date when a deal was passed to a salesperson, the meeting date, and the contract signing date, along with the sum of contracts. \n\nAll this data is in a single table with a unique ID as the primary key (PK).\n\nThe challenge is that I need to obtain the count of each of these dates by month without using any of the dates directly for grouping. This is because grouping by any of these dates directly would result in counting by that specific date. For example, if someone had a meeting in January and we group by the meeting date, we wouldn't capture their contract in February, etc.\n\nHow should I approach this?\"", "author_fullname": "t2_803gugjh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Count of different dates occurencies from one table ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3lump", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709268765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In SQL I need to count occurrences of the date when a deal was passed to a salesperson, the meeting date, and the contract signing date, along with the sum of contracts. &lt;/p&gt;\n\n&lt;p&gt;All this data is in a single table with a unique ID as the primary key (PK).&lt;/p&gt;\n\n&lt;p&gt;The challenge is that I need to obtain the count of each of these dates by month without using any of the dates directly for grouping. This is because grouping by any of these dates directly would result in counting by that specific date. For example, if someone had a meeting in January and we group by the meeting date, we wouldn&amp;#39;t capture their contract in February, etc.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3lump", "is_robot_indexable": true, "report_reasons": null, "author": "Novel_Pattern8035", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3lump/count_of_different_dates_occurencies_from_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3lump/count_of_different_dates_occurencies_from_one/", "subreddit_subscribers": 164951, "created_utc": 1709268765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Mar 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu", "t3_188grkl", "t3_18w0y5n", "t3_1agfqy9", "t3_1b3zb2c"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1709312460.253, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3zb2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709312460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?auto=webp&amp;s=f4aed4accb9b09c9fa81e95e6c52cf3c300fc962", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=255dedc032e49c49b0c4e8f8bb181adc3f7d5295", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f605bcb5e19d3a5c71a81ce00990e7b65f81e52d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac789c54fffcb874c262f4c470d6c034806f8960", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=89ecd9f44728ccd7762c0517d3f0cb495c78c6be", "width": 640, "height": 333}], "variants": {}, "id": "ImrjwYWlQQdcm31jLkEiQbVgLMUnfCK0dT44FpXjpjI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3zb2c", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3zb2c/monthly_general_discussion_mar_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/1b3zb2c/monthly_general_discussion_mar_2024/", "subreddit_subscribers": 164951, "created_utc": 1709312460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v5q74o4dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Video Podcast] No longer a pipe dream \u2014 Gen AI and Data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3ytu1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "No longer a pipe dream \u2014 GenAI and Data pipelines [Cloud Masters #110]", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "DoiT International", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W4HrEz10J9M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@doitintl"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1b3ytu1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hFn5qCv6XLo-WE18ph_n37gprtc0G_j7rtnUzg4Bfew.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709311342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=W4HrEz10J9M&amp;list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss&amp;index=2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?auto=webp&amp;s=5e53e9190808d23549ae9d2875bac69ddb86791d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf266c414a5bf05efabe55f297ef7b5a6eba2a66", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ed7fdca7bcf7297fef2d10774f949a0a3628f6", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4cac4a382fe34529a6d1ea1f88639b0e9c35bcd", "width": 320, "height": 240}], "variants": {}, "id": "xduYiEOi5zVPnZXHY3v5vVr6W8i4vt-CxnOMopjjnUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3ytu1", "is_robot_indexable": true, "report_reasons": null, "author": "LLMaooooooo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3ytu1/video_podcast_no_longer_a_pipe_dream_gen_ai_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=W4HrEz10J9M&amp;list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss&amp;index=2", "subreddit_subscribers": 164951, "created_utc": 1709311342.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "No longer a pipe dream \u2014 GenAI and Data pipelines [Cloud Masters #110]", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "DoiT International", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W4HrEz10J9M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@doitintl"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone implemented such a pattern? Any resources to share?\n\nI'd be really interested in hearing your stories.", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Property-based testing in ETL/ELT flows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3r9wi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709289532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone implemented such a pattern? Any resources to share?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be really interested in hearing your stories.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3r9wi", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3r9wi/propertybased_testing_in_etlelt_flows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3r9wi/propertybased_testing_in_etlelt_flows/", "subreddit_subscribers": 164951, "created_utc": 1709289532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I am reading a hive view into a pyspark data frame and later joining it with the fact table read into another data frame. These views have equivalent hive tables partitioned by snapshot_date as well. The view only stores the latest data by taking a max(snapshot_dt). Will directly reading from the table with max(snapshot_dt) increase the performance rather than reading from the view ?\n\nTyia ", "author_fullname": "t2_qm56uvb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performance or read from a view and table ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3pi32", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709282226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I am reading a hive view into a pyspark data frame and later joining it with the fact table read into another data frame. These views have equivalent hive tables partitioned by snapshot_date as well. The view only stores the latest data by taking a max(snapshot_dt). Will directly reading from the table with max(snapshot_dt) increase the performance rather than reading from the view ?&lt;/p&gt;\n\n&lt;p&gt;Tyia &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3pi32", "is_robot_indexable": true, "report_reasons": null, "author": "Chillardon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3pi32/performance_or_read_from_a_view_and_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3pi32/performance_or_read_from_a_view_and_table/", "subreddit_subscribers": 164951, "created_utc": 1709282226.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}