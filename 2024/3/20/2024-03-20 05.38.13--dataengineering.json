{"kind": "Listing", "data": {"after": "t3_1bipbf7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope this post is ok, as I don't work for either O'Reilly or Humble Bundle. Given the number of questions on this thread for getting books on the topic, thought maybe some of you might be interested in this too! Personally, I'd been wanting to get, \"Data Algorithms with Spark,\" but had been hesitating due to the price. I was super thrilled seeing this included in the book bundle.\n\nThis is an organization that partners with others to offer books (and games) at a super low price. Part of the proceeds goes to charity. I've been a huge fan of them since discovering them a while ago.\n\n[https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books](https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books)", "author_fullname": "t2_97dp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "O\u2019Reilly data engineering reference books on sale! (Includes reference books on pyspark and scaling up pipelines)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bifhj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 120, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 120, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710837462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope this post is ok, as I don&amp;#39;t work for either O&amp;#39;Reilly or Humble Bundle. Given the number of questions on this thread for getting books on the topic, thought maybe some of you might be interested in this too! Personally, I&amp;#39;d been wanting to get, &amp;quot;Data Algorithms with Spark,&amp;quot; but had been hesitating due to the price. I was super thrilled seeing this included in the book bundle.&lt;/p&gt;\n\n&lt;p&gt;This is an organization that partners with others to offer books (and games) at a super low price. Part of the proceeds goes to charity. I&amp;#39;ve been a huge fan of them since discovering them a while ago.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books\"&gt;https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?auto=webp&amp;s=b50f3a7282d32dcfa0e059b0b506a19daa6b7df9", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8df569a17eb586e2b0feb844c8ddd80e2c53523e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc1d0f218d319d03ff9fb045ea5a017098e1c402", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4db0e3979f4fd989e036859dfa1257d15a01f34", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0c5aa5216466749f2ffd89e4f6dda46502974b1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=92b050a7f148a6395bed48099df1cca2307178a1", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=abb37e101932d1c5791c9ad599433a01b56b311e", "width": 1080, "height": 607}], "variants": {}, "id": "FbykrjGMgm2863qufl2xVlkGdUUd4rQbUPblShEhFV4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bifhj9", "is_robot_indexable": true, "report_reasons": null, "author": "truckbot101", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bifhj9/oreilly_data_engineering_reference_books_on_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bifhj9/oreilly_data_engineering_reference_books_on_sale/", "subreddit_subscribers": 170277, "created_utc": 1710837462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever stretched the truth about them being a DE? I was reading a post on Reddit where someone was a Data Analyst, and just did cloud work and projects on his own. He said he put his job title down as \"Data Engineer\" and ended up getting a DE job.  \n\n\nDoes that sound like something common in the job field? I have heard horror stories of people being hired in and not showing competencies. ", "author_fullname": "t2_tpf6owzl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stretching the truth about being a \"Data Engineer\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bit81p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710877335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever stretched the truth about them being a DE? I was reading a post on Reddit where someone was a Data Analyst, and just did cloud work and projects on his own. He said he put his job title down as &amp;quot;Data Engineer&amp;quot; and ended up getting a DE job.  &lt;/p&gt;\n\n&lt;p&gt;Does that sound like something common in the job field? I have heard horror stories of people being hired in and not showing competencies. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bit81p", "is_robot_indexable": true, "report_reasons": null, "author": "DarkPaladin67", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bit81p/stretching_the_truth_about_being_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bit81p/stretching_the_truth_about_being_a_data_engineer/", "subreddit_subscribers": 170277, "created_utc": 1710877335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_t535h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "F1 team Williams used Excel as their database to track the car components (hundreds of thousands of different components)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1bix81r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i4e37SD8XA3IyggLwyo8sH5a_emcTeUSb61sqGyodkY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710886869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "the-race.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.the-race.com/formula-1/shocking-details-behind-painful-williams-f1-revolution/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?auto=webp&amp;s=2b7e70ac6d3f2a40f7b7cf33acd46b67bb09f4b2", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=012270937cdbb17ee5a046bb7a36a26942be0100", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bc41a73feb1ad9af8989ff0aa9414f1085d8c733", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26556524a81cea8c034b5a3f2a3a65a61ec5c279", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=59ab3f3334809d3ece23a9a6dfb8b843c6d9c6f0", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fca2911fa0919e151955a92241189464a5042fba", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/SlVO78FlnZpFCIGKGJLgOpdIdiKS3jI3KxxsD4yChOE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4552d28a32ae4b0577c392562b5e19a73b0c2011", "width": 1080, "height": 720}], "variants": {}, "id": "sYpbiPOv1gfX8p4U2iMf8N5oMWagShFRnkY2-_F9LBQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1bix81r", "is_robot_indexable": true, "report_reasons": null, "author": "Tape56", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bix81r/f1_team_williams_used_excel_as_their_database_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.the-race.com/formula-1/shocking-details-behind-painful-williams-f1-revolution/", "subreddit_subscribers": 170277, "created_utc": 1710886869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I thought developing an API using Python/FastAPI to create a sql session and execute bunch of queries does not sound complex.\n\nWhat am I missing here ?\n\nIf you are someone that develops API, design databases, can you drop a resource that I could see/read about the complexity of developing an API?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Developing API\u2019s as part of being a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1biyz7f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710891221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I thought developing an API using Python/FastAPI to create a sql session and execute bunch of queries does not sound complex.&lt;/p&gt;\n\n&lt;p&gt;What am I missing here ?&lt;/p&gt;\n\n&lt;p&gt;If you are someone that develops API, design databases, can you drop a resource that I could see/read about the complexity of developing an API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1biyz7f", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biyz7f/developing_apis_as_part_of_being_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biyz7f/developing_apis_as_part_of_being_a_de/", "subreddit_subscribers": 170277, "created_utc": 1710891221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently working as a mix of DA/DE, and I believe my skills with SQL are not upto the mark to make a move to DE.\nI understand there is just \"normal\" sql that data analysts, BI analysts use which is typically:\n\n&gt; Select xyz from abc where ysd = '123'\n\nYes this can get more complex with joins, ctes, window functions etc.\n\nWhat is the difference between complex SQL that a DE would write, compared to the SQL a data analyst writes?", "author_fullname": "t2_mvubfxcg0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level of SQL for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bil95m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710857622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working as a mix of DA/DE, and I believe my skills with SQL are not upto the mark to make a move to DE.\nI understand there is just &amp;quot;normal&amp;quot; sql that data analysts, BI analysts use which is typically:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Select xyz from abc where ysd = &amp;#39;123&amp;#39;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes this can get more complex with joins, ctes, window functions etc.&lt;/p&gt;\n\n&lt;p&gt;What is the difference between complex SQL that a DE would write, compared to the SQL a data analyst writes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bil95m", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous-Kale9545", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bil95m/level_of_sql_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bil95m/level_of_sql_for_de/", "subreddit_subscribers": 170277, "created_utc": 1710857622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to work an enterprise workflow and am trying to think of what the right stack looks like.\n\nCloud at the moment is not a possibility - but the organization will go there one day. It\u2019s just a money thing.\n\nWe have contracts with Microsoft and so my front end is forced to be power apps and power BI. We do have licenses for power automate etc. \n\nWe have a very small allocation of dataverse and a decent sized share point. \n\nMy organization has 0 APIs, but are going to build them.\n\nWe have a few large databases and a gateway.\n\nMy original plan was to do data collection through power apps, power automate into a json, build a rest API with fast API to receive post, route traffic to mongo, store into a Postgres staging area to run Python transforms and into another Postgres as long term structured data, put an API in front of that into an MDM, an API off the MDM into an analytical database, and then an API off of that into the various BI customers and generally run data services.\n\nI\u2019ve recently heard about Apache Cassandra and thought it was interesting. I\u2019ve also heard of people building lakehouses and warehouses with duck DB.\n\nUltimately I\u2019m trying to figure out what the best scalable databases are and the easiest to interact with. Also.. am I doing my flow right?", "author_fullname": "t2_4dovkjca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database choices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bij7z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710851881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to work an enterprise workflow and am trying to think of what the right stack looks like.&lt;/p&gt;\n\n&lt;p&gt;Cloud at the moment is not a possibility - but the organization will go there one day. It\u2019s just a money thing.&lt;/p&gt;\n\n&lt;p&gt;We have contracts with Microsoft and so my front end is forced to be power apps and power BI. We do have licenses for power automate etc. &lt;/p&gt;\n\n&lt;p&gt;We have a very small allocation of dataverse and a decent sized share point. &lt;/p&gt;\n\n&lt;p&gt;My organization has 0 APIs, but are going to build them.&lt;/p&gt;\n\n&lt;p&gt;We have a few large databases and a gateway.&lt;/p&gt;\n\n&lt;p&gt;My original plan was to do data collection through power apps, power automate into a json, build a rest API with fast API to receive post, route traffic to mongo, store into a Postgres staging area to run Python transforms and into another Postgres as long term structured data, put an API in front of that into an MDM, an API off the MDM into an analytical database, and then an API off of that into the various BI customers and generally run data services.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve recently heard about Apache Cassandra and thought it was interesting. I\u2019ve also heard of people building lakehouses and warehouses with duck DB.&lt;/p&gt;\n\n&lt;p&gt;Ultimately I\u2019m trying to figure out what the best scalable databases are and the easiest to interact with. Also.. am I doing my flow right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bij7z5", "is_robot_indexable": true, "report_reasons": null, "author": "necrohobo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bij7z5/database_choices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bij7z5/database_choices/", "subreddit_subscribers": 170277, "created_utc": 1710851881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Considering a career pivot and discovered analytics engineering\u2014which to my knowledge is pretty similar to DE but with more business context/less technical skills needed?). Was wondering to all analytics engineers out there what your job looks like and what problems you deal with on a day-to-day?", "author_fullname": "t2_edit41t1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the biggest problems/painpoints in Analytics Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bixoc5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710887963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Considering a career pivot and discovered analytics engineering\u2014which to my knowledge is pretty similar to DE but with more business context/less technical skills needed?). Was wondering to all analytics engineers out there what your job looks like and what problems you deal with on a day-to-day?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bixoc5", "is_robot_indexable": true, "report_reasons": null, "author": "Admirable-Roll-7108", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bixoc5/what_are_the_biggest_problemspainpoints_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bixoc5/what_are_the_biggest_problemspainpoints_in/", "subreddit_subscribers": 170277, "created_utc": 1710887963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning Airflow for the first time. Have been using Prefect.\n\nLearned about xcoms today. The syntax for passing things seems very verbose and somewhat cumbersome, but I get it. However, the 48kb limit means xcoms have some limited application.\n\nIn researching posts, I saw on multiple occasions people stating (paraphrasing here) \"*back when Airflow was still using xcoms*\".\n\nWhat does this mean?\n\n* In airflow, can a task be a function that calls other functions that are not tasks themselves?\n* Could your task push data to something like S3 where the next task can pick it up?\n* Are xcoms still an integral part of Airflow?", "author_fullname": "t2_qhsi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do people say xcoms are no longer the default in airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bimv59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710861874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning Airflow for the first time. Have been using Prefect.&lt;/p&gt;\n\n&lt;p&gt;Learned about xcoms today. The syntax for passing things seems very verbose and somewhat cumbersome, but I get it. However, the 48kb limit means xcoms have some limited application.&lt;/p&gt;\n\n&lt;p&gt;In researching posts, I saw on multiple occasions people stating (paraphrasing here) &amp;quot;&lt;em&gt;back when Airflow was still using xcoms&lt;/em&gt;&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;What does this mean?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In airflow, can a task be a function that calls other functions that are not tasks themselves?&lt;/li&gt;\n&lt;li&gt;Could your task push data to something like S3 where the next task can pick it up?&lt;/li&gt;\n&lt;li&gt;Are xcoms still an integral part of Airflow?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bimv59", "is_robot_indexable": true, "report_reasons": null, "author": "NoUsernames1eft", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bimv59/why_do_people_say_xcoms_are_no_longer_the_default/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bimv59/why_do_people_say_xcoms_are_no_longer_the_default/", "subreddit_subscribers": 170277, "created_utc": 1710861874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, dlt (the data ingestion library) cofounder here,   \n\n\nI want to showcase our event ingestion setup. We put this behind cloudflare, to lower latency in different geographies.\n\nMany of our users use dlt for event ingestion. We were using Segment ourselves as we had free credits, but on credit expiration the bill is not pretty. So we moved to dlt on serverless gcp cloud functions with pub sub.\n\nWe like Segment, but we like 18x cost saving more :)\n\nHere's our setup  \n[https://dlthub.com/docs/blog/dlt-segment-migration](https://dlthub.com/docs/blog/dlt-segment-migration)\n\nMore streaming setups done by our users here: [https://dlthub.com/docs/blog/tags/streaming](https://dlthub.com/docs/blog/tags/streaming)  \n\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event ingestion on GCP terraform template + blog (18x cost saving over Segment)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bigwrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710843634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, dlt (the data ingestion library) cofounder here,   &lt;/p&gt;\n\n&lt;p&gt;I want to showcase our event ingestion setup. We put this behind cloudflare, to lower latency in different geographies.&lt;/p&gt;\n\n&lt;p&gt;Many of our users use dlt for event ingestion. We were using Segment ourselves as we had free credits, but on credit expiration the bill is not pretty. So we moved to dlt on serverless gcp cloud functions with pub sub.&lt;/p&gt;\n\n&lt;p&gt;We like Segment, but we like 18x cost saving more :)&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s our setup&lt;br/&gt;\n&lt;a href=\"https://dlthub.com/docs/blog/dlt-segment-migration\"&gt;https://dlthub.com/docs/blog/dlt-segment-migration&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;More streaming setups done by our users here: &lt;a href=\"https://dlthub.com/docs/blog/tags/streaming\"&gt;https://dlthub.com/docs/blog/tags/streaming&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?auto=webp&amp;s=7f542da7e01be864731a87a5966f1da32fb1c0c6", "width": 3483, "height": 1148}, "resolutions": [{"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e43620cee4872bff896e6e91e21a8b05be75fb6c", "width": 108, "height": 35}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e7bf904f616dabb756e6dfc370782f91bb6e0c7", "width": 216, "height": 71}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eeac09672bbbc25f987aaa496dc5565036f1da3b", "width": 320, "height": 105}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea4b58ab320d7d12631b04de23f15a300aecdd7b", "width": 640, "height": 210}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a6fc2854f5627b9b2ff29e9e4745b940c2d8ac7", "width": 960, "height": 316}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeb7f45ca1bd06a2122e72974c60807e1bedf33a", "width": 1080, "height": 355}], "variants": {}, "id": "_iRCnnKFUj1iGmaRU1XQdxy12fe92yHsgkY8JGxjpyM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bigwrv", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bigwrv/event_ingestion_on_gcp_terraform_template_blog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bigwrv/event_ingestion_on_gcp_terraform_template_blog/", "subreddit_subscribers": 170277, "created_utc": 1710843634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company currently has separate dev/test/prod environments for our data warehouse. Using one data source as an example:\n\nWe have scripts on a test VM that extract data from the data source's test server and loads the data to our test environment. We have the same scripts on a prod VM that extracts data from the data source's prod server and loads to our prod environment.\n\nProblem: \n\n1. The test server on the data source isn't routinely updated, and is thus out of sync with prod and makes a 1 to 1 validation of data for new dev work difficult when users look at the prod data on the data source application. \n2. It seems redundant to have scripts extract data from both test and prod servers, when we could alternatively extract just from prod data source server into our prod data warehouse and then push straight from our prod environment to our test environment so that minimal resources are used for ETL and test data aligns perfectly with prod data.\n\nQuestion:\n\nHow do you guys typically manage ETL for your test environment? Am I right that it would be better to only load data into the prod data warehouse and push from there into the test data warehouse?", "author_fullname": "t2_j3ecksk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Load Test Environment Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bisp92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710876069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company currently has separate dev/test/prod environments for our data warehouse. Using one data source as an example:&lt;/p&gt;\n\n&lt;p&gt;We have scripts on a test VM that extract data from the data source&amp;#39;s test server and loads the data to our test environment. We have the same scripts on a prod VM that extracts data from the data source&amp;#39;s prod server and loads to our prod environment.&lt;/p&gt;\n\n&lt;p&gt;Problem: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The test server on the data source isn&amp;#39;t routinely updated, and is thus out of sync with prod and makes a 1 to 1 validation of data for new dev work difficult when users look at the prod data on the data source application. &lt;/li&gt;\n&lt;li&gt;It seems redundant to have scripts extract data from both test and prod servers, when we could alternatively extract just from prod data source server into our prod data warehouse and then push straight from our prod environment to our test environment so that minimal resources are used for ETL and test data aligns perfectly with prod data.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;How do you guys typically manage ETL for your test environment? Am I right that it would be better to only load data into the prod data warehouse and push from there into the test data warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bisp92", "is_robot_indexable": true, "report_reasons": null, "author": "SellGameRent", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bisp92/how_to_load_test_environment_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bisp92/how_to_load_test_environment_data/", "subreddit_subscribers": 170277, "created_utc": 1710876069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll be working on a migration project and I have a ton of etl pipelines with 2k+ lines of sql and I was wondering if anyone knows a tool that can gate the sql script and turn it into a sort of flow diagram to understand all the tables that are being created and their relation ", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turning sql pipeline into flowchart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1big8k5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710840826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be working on a migration project and I have a ton of etl pipelines with 2k+ lines of sql and I was wondering if anyone knows a tool that can gate the sql script and turn it into a sort of flow diagram to understand all the tables that are being created and their relation &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1big8k5", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1big8k5/turning_sql_pipeline_into_flowchart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1big8k5/turning_sql_pipeline_into_flowchart/", "subreddit_subscribers": 170277, "created_utc": 1710840826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, in a bit of a very stressful choice to make here, hoping I can get some advice on how what would lead me into a data engineering or analytics engineering role the best\n\nI\u2019ve been a data analyst intern(mainly SQL and PowerBI) at my current company for 1.5 years, and they offered me a full time position for 67k. But I got a job offer for a more business enablement focused data analytics position for 75k.\n\n The issue is, the business enablement company doesn\u2019t necessarily have any plans to get me involved in any ETL processes of the data  (they legit told me the position is far from any engineering in the interviews as there is 0 transformation of the data done). It\u2019s strictly SQL and PowerBI and whatever sources PowerBI dataflows could use.\n\nMy current company knows my career goals, but couldn\u2019t get me an actual engineering position said there will be projects in the future where I will be closer to the data source, and mentioned Python. Is this grooming? I\u2019m honestly not sure, I\u2019ve never done those projects before at this company, but going to full time typically gets our team members involved in a variety of projects, and if they know my goals maybe it would be worth staying?\n\nTLDR: Company I interned at offers 67K and more POSSIBLE potential to expand skillset and transition into an engineering role down the line(there\u2019s a chance it\u2019s a smokescreen). Other offer, 75k, much more business enablement focused, doesn\u2019t really want me going into the engineering path, would likely be much harder to leverage position in the future. Turn down 8k for a chance to get into engineering(and significantly higher pay) in the future?\n\n", "author_fullname": "t2_55fytx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take less pay but more potential for a future in engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bj2psw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710902977.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710901397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, in a bit of a very stressful choice to make here, hoping I can get some advice on how what would lead me into a data engineering or analytics engineering role the best&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been a data analyst intern(mainly SQL and PowerBI) at my current company for 1.5 years, and they offered me a full time position for 67k. But I got a job offer for a more business enablement focused data analytics position for 75k.&lt;/p&gt;\n\n&lt;p&gt;The issue is, the business enablement company doesn\u2019t necessarily have any plans to get me involved in any ETL processes of the data  (they legit told me the position is far from any engineering in the interviews as there is 0 transformation of the data done). It\u2019s strictly SQL and PowerBI and whatever sources PowerBI dataflows could use.&lt;/p&gt;\n\n&lt;p&gt;My current company knows my career goals, but couldn\u2019t get me an actual engineering position said there will be projects in the future where I will be closer to the data source, and mentioned Python. Is this grooming? I\u2019m honestly not sure, I\u2019ve never done those projects before at this company, but going to full time typically gets our team members involved in a variety of projects, and if they know my goals maybe it would be worth staying?&lt;/p&gt;\n\n&lt;p&gt;TLDR: Company I interned at offers 67K and more POSSIBLE potential to expand skillset and transition into an engineering role down the line(there\u2019s a chance it\u2019s a smokescreen). Other offer, 75k, much more business enablement focused, doesn\u2019t really want me going into the engineering path, would likely be much harder to leverage position in the future. Turn down 8k for a chance to get into engineering(and significantly higher pay) in the future?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bj2psw", "is_robot_indexable": true, "report_reasons": null, "author": "ToothPickLegs", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bj2psw/take_less_pay_but_more_potential_for_a_future_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bj2psw/take_less_pay_but_more_potential_for_a_future_in/", "subreddit_subscribers": 170277, "created_utc": 1710901397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cbh6ollo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Kafka connector to send kafka topics data to 200+ destinations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1biqsae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Dcu6VBDsnTInxOse8U-R-5-yKyByVMnBqCVSKZnCVVI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710871426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/rudderlabs/rudder-kafka-sink-connector", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?auto=webp&amp;s=2236b72c38c1ffdb3ef00bc2c4dae5fbd4a116cb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab3990f924bd9bf0da88fb79a89075e6cad33a01", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4df0cc65b132eb2a2f60895b37c4f59f705b5cd7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8847d43ea3f647be0e9a2cb39a1ebc6a8277a728", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e6253a85bf7e130c92e6bf21615e7bf385246f8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c854fd5dd1329ce2cb94a4e60d5d3324969aeb54", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97c03bdc700f1d9114a39bb80c449226c6882b10", "width": 1080, "height": 540}], "variants": {}, "id": "HHCapiHt6RX89jBT8ceKmiW73oQ_kfiILwHJ-WwYTqg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1biqsae", "is_robot_indexable": true, "report_reasons": null, "author": "ephemeral404", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biqsae/open_source_kafka_connector_to_send_kafka_topics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/rudderlabs/rudder-kafka-sink-connector", "subreddit_subscribers": 170277, "created_utc": 1710871426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, i\u00b4m trying to model my data from a scraper that i made. I\u00b4m able to retrieve around 26 columns from an api and put togheter in my dwh in bigquery, obviusly the first table that i have is one OBT table but i realize that along the time the prices maybe change and if the owner make renovations some characteristics around the property also can change, the status if it\u00b4s sell can change.\n\nhttps://preview.redd.it/2rvqo23o1dpc1.jpg?width=701&amp;format=pjpg&amp;auto=webp&amp;s=16d470f03ebffc901b4beeeeefe526318242598c\n\nIn the obt is hard to mantain these logic and i want to use scd type 2 to track this changes in the dimensions. So the first thing that i need to do is model my data as you can see in the image.\n\nBut i\u00b4m a few undecided if my schema it\u00b4s OK or something can change.\n\n* In the location table, i see that if is a condo maybe have the same adress and geographical data, but i\u00b4m not sure if i can put the adress and geo data into the fact table\n* for the attributes dimension also i only think that is 1 to 1 relation because there is no chance that 2 property listings have the same property\\_id and url. So i don\u00b4t know how to aproach this dimension\n* the other dimensions i think are ok\n\nWhat do you think about my schema and if i need to do some improvements?\n\nthanks for your support folks.", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Property listings data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 138, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2rvqo23o1dpc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 106, "x": 108, "u": "https://preview.redd.it/2rvqo23o1dpc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9aa33ebf1ba7ea53fc3e6ca5d2fcad3d8b5281b"}, {"y": 212, "x": 216, "u": "https://preview.redd.it/2rvqo23o1dpc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e607712836c29ff93fedb5c5b235a8211902d317"}, {"y": 315, "x": 320, "u": "https://preview.redd.it/2rvqo23o1dpc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a808fa8875141a9c7ae010b7a753752d6d11bde"}, {"y": 630, "x": 640, "u": "https://preview.redd.it/2rvqo23o1dpc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=443d78d3ce77994725d7400bd3e7c0232520ba76"}], "s": {"y": 691, "x": 701, "u": "https://preview.redd.it/2rvqo23o1dpc1.jpg?width=701&amp;format=pjpg&amp;auto=webp&amp;s=16d470f03ebffc901b4beeeeefe526318242598c"}, "id": "2rvqo23o1dpc1"}}, "name": "t3_1biw65l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/g9ud-Jg0GADZsQDDRlLOEqGQWeEfs-EATU5KqiaRtpk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710884401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, i\u00b4m trying to model my data from a scraper that i made. I\u00b4m able to retrieve around 26 columns from an api and put togheter in my dwh in bigquery, obviusly the first table that i have is one OBT table but i realize that along the time the prices maybe change and if the owner make renovations some characteristics around the property also can change, the status if it\u00b4s sell can change.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2rvqo23o1dpc1.jpg?width=701&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=16d470f03ebffc901b4beeeeefe526318242598c\"&gt;https://preview.redd.it/2rvqo23o1dpc1.jpg?width=701&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=16d470f03ebffc901b4beeeeefe526318242598c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In the obt is hard to mantain these logic and i want to use scd type 2 to track this changes in the dimensions. So the first thing that i need to do is model my data as you can see in the image.&lt;/p&gt;\n\n&lt;p&gt;But i\u00b4m a few undecided if my schema it\u00b4s OK or something can change.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In the location table, i see that if is a condo maybe have the same adress and geographical data, but i\u00b4m not sure if i can put the adress and geo data into the fact table&lt;/li&gt;\n&lt;li&gt;for the attributes dimension also i only think that is 1 to 1 relation because there is no chance that 2 property listings have the same property_id and url. So i don\u00b4t know how to aproach this dimension&lt;/li&gt;\n&lt;li&gt;the other dimensions i think are ok&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think about my schema and if i need to do some improvements?&lt;/p&gt;\n\n&lt;p&gt;thanks for your support folks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1biw65l", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biw65l/property_listings_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biw65l/property_listings_data_modeling/", "subreddit_subscribers": 170277, "created_utc": 1710884401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello data engineers,\n\nI'm seeking advice on migrating our on-premises Oracle data warehouse to the azure cloud. Our on-premises oracle db is 80tb with thousands of etl information jobs . \n\n * What was your approach (business-driven vs. replicating on-premises processes)?\n\n * Any recommended migration strategies or tools?\nOur current approach feels scattered. \n\nAny tips or lessons learned would be greatly appreciated!\n", "author_fullname": "t2_7f74h3uy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Legacy Oracle Data Warehouse to Azure Cloud Migration Strategies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bistcf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710876341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data engineers,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeking advice on migrating our on-premises Oracle data warehouse to the azure cloud. Our on-premises oracle db is 80tb with thousands of etl information jobs . &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;What was your approach (business-driven vs. replicating on-premises processes)?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any recommended migration strategies or tools?\nOur current approach feels scattered. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any tips or lessons learned would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bistcf", "is_robot_indexable": true, "report_reasons": null, "author": "CountNo9037", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bistcf/legacy_oracle_data_warehouse_to_azure_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bistcf/legacy_oracle_data_warehouse_to_azure_cloud/", "subreddit_subscribers": 170277, "created_utc": 1710876341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Guys! I need help\n\nIn my business, we typically don't rely on concrete facts, but rather on daily snapshots. We operate within the educational system, focusing on aspects like \"Students enrolled in courses on date X\". These student records may remain constant (I lack a specific date column for updates, only a cancellation date). Therefore, every day we capture a snapshot at 11:59 PM, which results in a significant amount of duplicate data, given the minimal changes from day to day. Perhaps one or two cancellations and two or three new enrollments might occur.\n\nIts something like 50K rows per day, it is not so much but we are on prem \n\nHow can i handle this type of fact?  Usually directors request to me like \"How many enrolled students we have on day X\"", "author_fullname": "t2_8jc0mwfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Problem to design a fact table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1biua2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710879883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Guys! I need help&lt;/p&gt;\n\n&lt;p&gt;In my business, we typically don&amp;#39;t rely on concrete facts, but rather on daily snapshots. We operate within the educational system, focusing on aspects like &amp;quot;Students enrolled in courses on date X&amp;quot;. These student records may remain constant (I lack a specific date column for updates, only a cancellation date). Therefore, every day we capture a snapshot at 11:59 PM, which results in a significant amount of duplicate data, given the minimal changes from day to day. Perhaps one or two cancellations and two or three new enrollments might occur.&lt;/p&gt;\n\n&lt;p&gt;Its something like 50K rows per day, it is not so much but we are on prem &lt;/p&gt;\n\n&lt;p&gt;How can i handle this type of fact?  Usually directors request to me like &amp;quot;How many enrolled students we have on day X&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1biua2g", "is_robot_indexable": true, "report_reasons": null, "author": "Andremallmann", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biua2g/problem_to_design_a_fact_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biua2g/problem_to_design_a_fact_table/", "subreddit_subscribers": 170277, "created_utc": 1710879883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm currently tasked with setting up an open-source ingestion tool for two main use cases within my organization:\n1. Self-service capabilities: for our non-technical users to easily ingest data.\n2. ELT data pipeline: construction to streamline our data processing workflows.\n\nWe were initially considering **Airbyte** as the primary tool due to its versatility and broad connector support. However, we've encountered a significant compatibility issue with our current architecture, which heavily relies on **Delta Lake tables** and **Spark** for data processing. Specifically, we're facing challenges with Airbyte's integration with this setup, as discussed in this GitHub issue: https://github.com/airbytehq/airbyte/issues/16322\n\nGiven this context, I'm reaching out to the community for advice:\n- Has anyone successfully found a workaround for integrating Airbyte with Delta Lake and Spark, as per the mentioned issue?\n- Alternatively, are there any other open-source tools you would recommend that could meet our needs and seamlessly fit into our Delta Lake and Spark-centric architecture?\n\nAny insights, experiences, or suggestions you could share would be immensely appreciated. Our goal is to find a reliable, open-source solution that can accommodate our specific requirements without compromising on functionality or ease of use.\n\nThank you in advance for your help and looking forward to your recommendations!\n", "author_fullname": "t2_hffs9quu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Open Source Ingestion Tool Compatible with Delta Lake and Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1biu10m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710879253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently tasked with setting up an open-source ingestion tool for two main use cases within my organization:\n1. Self-service capabilities: for our non-technical users to easily ingest data.\n2. ELT data pipeline: construction to streamline our data processing workflows.&lt;/p&gt;\n\n&lt;p&gt;We were initially considering &lt;strong&gt;Airbyte&lt;/strong&gt; as the primary tool due to its versatility and broad connector support. However, we&amp;#39;ve encountered a significant compatibility issue with our current architecture, which heavily relies on &lt;strong&gt;Delta Lake tables&lt;/strong&gt; and &lt;strong&gt;Spark&lt;/strong&gt; for data processing. Specifically, we&amp;#39;re facing challenges with Airbyte&amp;#39;s integration with this setup, as discussed in this GitHub issue: &lt;a href=\"https://github.com/airbytehq/airbyte/issues/16322\"&gt;https://github.com/airbytehq/airbyte/issues/16322&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Given this context, I&amp;#39;m reaching out to the community for advice:\n- Has anyone successfully found a workaround for integrating Airbyte with Delta Lake and Spark, as per the mentioned issue?\n- Alternatively, are there any other open-source tools you would recommend that could meet our needs and seamlessly fit into our Delta Lake and Spark-centric architecture?&lt;/p&gt;\n\n&lt;p&gt;Any insights, experiences, or suggestions you could share would be immensely appreciated. Our goal is to find a reliable, open-source solution that can accommodate our specific requirements without compromising on functionality or ease of use.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help and looking forward to your recommendations!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?auto=webp&amp;s=40569cb9bca9b656aab79a7caaf2aa15cecb1528", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=316467b66d8db1e6a7898aacaca13779a4ea3b08", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=25f37ba73d36d0d9037a0fcd4924c33469d1d770", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da0f588fcc80b504fc9396d7b2ab057b97a3e4de", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d1e94e73dedf8b3380a50400e5aef29a6266815", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=970f88a9bdd47a0ef61e9ea80d52ce826e0d3a86", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/pLGN3TzxDTAb7r7K0KCgXSZ27cnQJRwzFzkjuhcm668.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ef746c904e388dc56ef058a6d4e645f17e9caacf", "width": 1080, "height": 540}], "variants": {}, "id": "tVtrXdHx-ZiNTu5lwWtBhHdKSdGFT2DM2lQxn6Ffg38"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1biu10m", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic-Zucchini-53", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biu10m/seeking_advice_on_open_source_ingestion_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biu10m/seeking_advice_on_open_source_ingestion_tool/", "subreddit_subscribers": 170277, "created_utc": 1710879253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI have $500 to use as part of L&amp;D from my company.\n\nJust wondering what are the best resources to invest in.\n\nI read most of my books on Kindle and my computer, so not really a big of physical books.\n\nThinking of educative.io membership?\n\nAny suggestions?\n\nThanks!", "author_fullname": "t2_hnhd87tx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use learning budget?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bisyjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710876684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have $500 to use as part of L&amp;amp;D from my company.&lt;/p&gt;\n\n&lt;p&gt;Just wondering what are the best resources to invest in.&lt;/p&gt;\n\n&lt;p&gt;I read most of my books on Kindle and my computer, so not really a big of physical books.&lt;/p&gt;\n\n&lt;p&gt;Thinking of educative.io membership?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bisyjw", "is_robot_indexable": true, "report_reasons": null, "author": "StoicResearcher", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bisyjw/how_to_use_learning_budget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bisyjw/how_to_use_learning_budget/", "subreddit_subscribers": 170277, "created_utc": 1710876684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Engineers, I am kinda starting to learn and use dbt and have used delta live tables from databricks(dlt) in the past. I am trying to understand the point of using dbt when I am already in databricks environment.\n\nCould someone who has the experience point out some of the scenarios where you found dbt more useful than using dlt. I assume dlt will be bit costlier but would love to hear your thoughts.", "author_fullname": "t2_szxdhbt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs databricks dot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bige78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710841541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Engineers, I am kinda starting to learn and use dbt and have used delta live tables from databricks(dlt) in the past. I am trying to understand the point of using dbt when I am already in databricks environment.&lt;/p&gt;\n\n&lt;p&gt;Could someone who has the experience point out some of the scenarios where you found dbt more useful than using dlt. I assume dlt will be bit costlier but would love to hear your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bige78", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum__Gold", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bige78/dbt_vs_databricks_dot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bige78/dbt_vs_databricks_dot/", "subreddit_subscribers": 170277, "created_utc": 1710841541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI\u2019ve been running some jobs on AWS Lambda, and more than 75% of the time, the job timesout during runtime initialization. Ive switched some of my jobs to use Batch/Fargate tasks instead but I would prefer if some jobs could have those HTTP endpoints to trigger with.\n\nI\u2019m using python 3.11-slim-bullseye as my base image and can figure out how to fix this issue? I\u2019ve tried provisioned concurrency and the like.", "author_fullname": "t2_tbzhecci2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Lambda Runtime.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bix6kx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710886778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been running some jobs on AWS Lambda, and more than 75% of the time, the job timesout during runtime initialization. Ive switched some of my jobs to use Batch/Fargate tasks instead but I would prefer if some jobs could have those HTTP endpoints to trigger with.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m using python 3.11-slim-bullseye as my base image and can figure out how to fix this issue? I\u2019ve tried provisioned concurrency and the like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bix6kx", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Expert2790", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bix6kx/aws_lambda_runtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bix6kx/aws_lambda_runtime/", "subreddit_subscribers": 170277, "created_utc": 1710886778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now I have a new grad offer as a data platform engineer for a big pharma, where in short we are building tools/environments for the data engineers/scientists to use internally.  Here is the job posting for reference: [https://app.otta.com/dashboard/jobs/NcwgNghA](https://app.otta.com/dashboard/jobs/NcwgNghA)  \n\n\nThe thing I am afraid about is whether this type of data-centric SWE/DE heavy position will not give me the experience/skillset needed to get SWE interviews in the future.  I am a CS/DS emphasis, but am wondering whether this would lower my chances of breaking into FAANG positions or big tech companies for more general SWE jobs (Yes, I could've asked my hiring manager/team this but at the time I was focusing on getting the job and not expressing negative energy).  Would be nice to get some opinions on this. ", "author_fullname": "t2_33bgrbrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platform Engineer New Grad - Are these skills transferable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1biwup1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710885999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now I have a new grad offer as a data platform engineer for a big pharma, where in short we are building tools/environments for the data engineers/scientists to use internally.  Here is the job posting for reference: &lt;a href=\"https://app.otta.com/dashboard/jobs/NcwgNghA\"&gt;https://app.otta.com/dashboard/jobs/NcwgNghA&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;The thing I am afraid about is whether this type of data-centric SWE/DE heavy position will not give me the experience/skillset needed to get SWE interviews in the future.  I am a CS/DS emphasis, but am wondering whether this would lower my chances of breaking into FAANG positions or big tech companies for more general SWE jobs (Yes, I could&amp;#39;ve asked my hiring manager/team this but at the time I was focusing on getting the job and not expressing negative energy).  Would be nice to get some opinions on this. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?auto=webp&amp;s=851caaf77714e47e6f0145f042e17cd073fd7461", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3035050507b7f9050c15b4b307222611854a0d12", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=059b76196d60ffd00d6227a82bcd870e62446348", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc72ed166e1ed191960dc27bb4acbe365511a897", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=de54ee5a9c025932ba2ef37de26def846835ad5b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=889df6cad8babe81694cbf8263de32abc5882c31", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/SejLsKAGhExaNj1jyxBtQlM4rzyq-a4OAIt9dM__hpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d2fb43d62781d60cc95e8b0292748a3c6e112f11", "width": 1080, "height": 567}], "variants": {}, "id": "xod25RBDQZClYLUh2yeFVT4J2d97G_jdqQBWP1qjmjk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1biwup1", "is_robot_indexable": true, "report_reasons": null, "author": "c9zellsis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biwup1/data_platform_engineer_new_grad_are_these_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biwup1/data_platform_engineer_new_grad_are_these_skills/", "subreddit_subscribers": 170277, "created_utc": 1710885999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, i\u00b4m trying to model my data from a scraper that i made. I\u00b4m able to retrieve around 26 columns from an api and put togheter in my dwh in bigquery, obviusly the first table that i have is one OBT table but i realize that along the time the prices maybe change and if the owner make renovations some characteristics around the property also can change, the status if it\u00b4s sell can change.\n\nIn the obt is hard to mantain these logic and i want to use scd type 2 to track this changes in the dimensions. So the first thing that i need to do is model my data as you can see in the image.\n\nBut i\u00b4m a few undecided if my schema it\u00b4s OK or something can change.\n\n* In the location table, i see that if is a condo maybe have the same adress and geographical data, but i\u00b4m not sure if i can put the adress and geo data into the fact table\n* for the attributes dimension also i only think that is 1 to 1 relation because there is no chance that 2 property listings have the same property\\_id and url. So i don\u00b4t know how to aproach this dimension\n* the other dimensions i think are ok \n\nWhat do you think about my schema and if i need to do some improvements?\n\n&amp;#x200B;\n\nthanks for your support folks.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_wgg22vwi4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Property listings data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1biv2uw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710881798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, i\u00b4m trying to model my data from a scraper that i made. I\u00b4m able to retrieve around 26 columns from an api and put togheter in my dwh in bigquery, obviusly the first table that i have is one OBT table but i realize that along the time the prices maybe change and if the owner make renovations some characteristics around the property also can change, the status if it\u00b4s sell can change.&lt;/p&gt;\n\n&lt;p&gt;In the obt is hard to mantain these logic and i want to use scd type 2 to track this changes in the dimensions. So the first thing that i need to do is model my data as you can see in the image.&lt;/p&gt;\n\n&lt;p&gt;But i\u00b4m a few undecided if my schema it\u00b4s OK or something can change.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In the location table, i see that if is a condo maybe have the same adress and geographical data, but i\u00b4m not sure if i can put the adress and geo data into the fact table&lt;/li&gt;\n&lt;li&gt;for the attributes dimension also i only think that is 1 to 1 relation because there is no chance that 2 property listings have the same property_id and url. So i don\u00b4t know how to aproach this dimension&lt;/li&gt;\n&lt;li&gt;the other dimensions i think are ok &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think about my schema and if i need to do some improvements?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks for your support folks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1biv2uw", "is_robot_indexable": true, "report_reasons": null, "author": "fr-profile1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biv2uw/property_listings_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biv2uw/property_listings_data_modeling/", "subreddit_subscribers": 170277, "created_utc": 1710881798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been asked to make a plan/road map to migrate my job\u2019s pipelines off airflow + Spark + Redshift to airflow + dbt core + Redshift\n\nCurrently our keep raw data  in S3 to use DBT I would need to load that raw data into using the COPY command in Redshift.\n\nSo I\u2019ve been tinkering with DBT but it doesn\u2019t let me run CREATE, COPY, and UNLOAD anywhere except the pre-hook and post-hook of models, it expects everything to be a SELECT statement.\n\nThis seems like a terrible practice because the SQL \u201chooks\u201d in these needs to be a quoted string meaning you get no sql linting,no syntax highlighting or checking etc.\n\nIs there any way to schedule arbitrary SQL that isn\u2019t models with dbt?\n\n I can roll my own but it just seems like a tool like this that\u2019s literally for running SQL should have something more than these pre and post hooks to run DDL SQL commands.\n\n**tl,dr:** We have over 200+ raw data tables in S3. Making empty models with only pre and post hook to use the CREAT, COPY, and UNLOAD commands to load the data into Redshift seems like a bad idea. Is there a way to run DDL from DBT that\u2019s not pre and post hooks.\n", "author_fullname": "t2_160eq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DDL for COPY and UNLOAD commands in DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1biukdk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710880824.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710880575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been asked to make a plan/road map to migrate my job\u2019s pipelines off airflow + Spark + Redshift to airflow + dbt core + Redshift&lt;/p&gt;\n\n&lt;p&gt;Currently our keep raw data  in S3 to use DBT I would need to load that raw data into using the COPY command in Redshift.&lt;/p&gt;\n\n&lt;p&gt;So I\u2019ve been tinkering with DBT but it doesn\u2019t let me run CREATE, COPY, and UNLOAD anywhere except the pre-hook and post-hook of models, it expects everything to be a SELECT statement.&lt;/p&gt;\n\n&lt;p&gt;This seems like a terrible practice because the SQL \u201chooks\u201d in these needs to be a quoted string meaning you get no sql linting,no syntax highlighting or checking etc.&lt;/p&gt;\n\n&lt;p&gt;Is there any way to schedule arbitrary SQL that isn\u2019t models with dbt?&lt;/p&gt;\n\n&lt;p&gt;I can roll my own but it just seems like a tool like this that\u2019s literally for running SQL should have something more than these pre and post hooks to run DDL SQL commands.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tl,dr:&lt;/strong&gt; We have over 200+ raw data tables in S3. Making empty models with only pre and post hook to use the CREAT, COPY, and UNLOAD commands to load the data into Redshift seems like a bad idea. Is there a way to run DDL from DBT that\u2019s not pre and post hooks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1biukdk", "is_robot_indexable": true, "report_reasons": null, "author": "SirAutismx7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biukdk/ddl_for_copy_and_unload_commands_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1biukdk/ddl_for_copy_and_unload_commands_in_dbt/", "subreddit_subscribers": 170277, "created_utc": 1710880575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Datadogs, \n\nYour expert opinion would be appreciated if you could provide me with book recommendations on Streaming systems, NRT (near-time pipelines ) and related literature.\n\n&amp;#x200B;", "author_fullname": "t2_snzbmfolo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Recommendations on Streaming Systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1birk8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710873313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Datadogs, &lt;/p&gt;\n\n&lt;p&gt;Your expert opinion would be appreciated if you could provide me with book recommendations on Streaming systems, NRT (near-time pipelines ) and related literature.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1birk8h", "is_robot_indexable": true, "report_reasons": null, "author": "loomingdale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1birk8h/book_recommendations_on_streaming_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1birk8h/book_recommendations_on_streaming_systems/", "subreddit_subscribers": 170277, "created_utc": 1710873313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Do you normally build APIs?\n\nI have good gasp of reading and parsing data from APIs but I have never build any. Not sure if building APIs is common for hedge fund DEs? Thank you!\n\nWhat are the common data sources where DE pull data from?  Besides files, APIs, ftps, sql servers, what else? Thank you.  I posted this yesterday but not sure why the content is no longer available. I am kind of new here. Not sure If I am breaking any rules? ", "author_fullname": "t2_9od6j04g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers working at a hedge fund? I got a couple job interviews coming and would like some insights.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bipbf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710867845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you normally build APIs?&lt;/p&gt;\n\n&lt;p&gt;I have good gasp of reading and parsing data from APIs but I have never build any. Not sure if building APIs is common for hedge fund DEs? Thank you!&lt;/p&gt;\n\n&lt;p&gt;What are the common data sources where DE pull data from?  Besides files, APIs, ftps, sql servers, what else? Thank you.  I posted this yesterday but not sure why the content is no longer available. I am kind of new here. Not sure If I am breaking any rules? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bipbf7", "is_robot_indexable": true, "report_reasons": null, "author": "Tall-Skin5800", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bipbf7/any_data_engineers_working_at_a_hedge_fund_i_got/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bipbf7/any_data_engineers_working_at_a_hedge_fund_i_got/", "subreddit_subscribers": 170277, "created_utc": 1710867845.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}