{"kind": "Listing", "data": {"after": "t3_1bdql0m", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, Microsoft is offering a free exam voucher for those who complete any of the Microsoft Learn AI Skills Challenges below:\n\n[Build next generation apps with Azure OpenAI](https://learn.microsoft.com/training/challenges?id=da09d3ca-a2bb-47dc-ba42-bea77b386a3d&amp;WT.mc_id=cloudskillschallenge_da09d3ca-a2bb-47dc-ba42-bea77b386a3d) \n\n[Azure AI Fundamentals](https://learn.microsoft.com/training/challenges?id=3ef5d197-cdef-49bc-a8bc-954bcd9e88cc&amp;WT.mc_id=cloudskillschallenge_3ef5d197-cdef-49bc-a8bc-954bcd9e88cc)\n\n[Fabric Analytics Engineer](https://learn.microsoft.com/training/challenges?id=b696c18d-7201-4aff-9c7d-d33014d93b25&amp;WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25)\n\n[Azure Machine Learning](https://learn.microsoft.com/training/challenges?id=764de7ca-8b6d-4b3a-a491-1942af389d8c&amp;WT.mc_id=cloudskillschallenge_764de7ca-8b6d-4b3a-a491-1942af389d8c)\n\nOnce you complete the challenge, you'll be given a free exam voucher which can be used for any of the exams listed below:\n\n[AI-102 Designing and Implementing a Microsoft Azure AI Solution](https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/#certification-exams?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[AI-900 Microsoft Azure AI Fundamentals](https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-900/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[DP-600 Implementing Analytics Solutions Using Microsoft Fabric](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-600/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[DP-100 Designing and Implementing a Data Science Soluition on Azure](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-100/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n&amp;#x200B;\n\nYou can read the links for all other details, you got a month to complete any of the challenges and you will get a voucher for any from the 4 exams listed. It would make more sense if you do the challenge that relates to the exam you plan on sitting for but it is not mandatory. You have to complete the challenge between March 19th and April 19th.\n\nWhich one are you choosing? I am thinking between AI-900 and DP-600.\n\nCheers!", "author_fullname": "t2_7gvgv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Microsoft Exam Vouchers By Completing a Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdhw74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710301781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, Microsoft is offering a free exam voucher for those who complete any of the Microsoft Learn AI Skills Challenges below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=da09d3ca-a2bb-47dc-ba42-bea77b386a3d&amp;amp;WT.mc_id=cloudskillschallenge_da09d3ca-a2bb-47dc-ba42-bea77b386a3d\"&gt;Build next generation apps with Azure OpenAI&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=3ef5d197-cdef-49bc-a8bc-954bcd9e88cc&amp;amp;WT.mc_id=cloudskillschallenge_3ef5d197-cdef-49bc-a8bc-954bcd9e88cc\"&gt;Azure AI Fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=b696c18d-7201-4aff-9c7d-d33014d93b25&amp;amp;WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25\"&gt;Fabric Analytics Engineer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=764de7ca-8b6d-4b3a-a491-1942af389d8c&amp;amp;WT.mc_id=cloudskillschallenge_764de7ca-8b6d-4b3a-a491-1942af389d8c\"&gt;Azure Machine Learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Once you complete the challenge, you&amp;#39;ll be given a free exam voucher which can be used for any of the exams listed below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/#certification-exams?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;AI-102 Designing and Implementing a Microsoft Azure AI Solution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-900/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;AI-900 Microsoft Azure AI Fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-600/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;DP-600 Implementing Analytics Solutions Using Microsoft Fabric&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-100/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;DP-100 Designing and Implementing a Data Science Soluition on Azure&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;You can read the links for all other details, you got a month to complete any of the challenges and you will get a voucher for any from the 4 exams listed. It would make more sense if you do the challenge that relates to the exam you plan on sitting for but it is not mandatory. You have to complete the challenge between March 19th and April 19th.&lt;/p&gt;\n\n&lt;p&gt;Which one are you choosing? I am thinking between AI-900 and DP-600.&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bdhw74", "is_robot_indexable": true, "report_reasons": null, "author": "salihveseli", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdhw74/free_microsoft_exam_vouchers_by_completing_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdhw74/free_microsoft_exam_vouchers_by_completing_a/", "subreddit_subscribers": 168521, "created_utc": 1710301781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which profession would earn you most money in the long run? I think data analyst salaries usually don\u2019t surpass $200k while DE can make $300k and more. What has been your experience or what have you seen salary wise for DE and DA?", "author_fullname": "t2_kjeptd4cq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs Data Analyst Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdzrkh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710356680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which profession would earn you most money in the long run? I think data analyst salaries usually don\u2019t surpass $200k while DE can make $300k and more. What has been your experience or what have you seen salary wise for DE and DA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bdzrkh", "is_robot_indexable": true, "report_reasons": null, "author": "Mergirl610", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdzrkh/data_engineer_vs_data_analyst_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdzrkh/data_engineer_vs_data_analyst_salary/", "subreddit_subscribers": 168521, "created_utc": 1710356680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm a data engineering consultant specializing in working with startups to develop robust data platforms. Currently, I'm collaborating with a Swedish company whose entire infrastructure is based on Postgres and Django. They've tasked me with either building upon or improving their existing platform to make it more manageable and scalable.\n\nHowever, I've noticed that they heavily rely on Django objects for the ETL process rather than utilizing SQL. As a data engineer, I firmly believe in the effectiveness of SQL/Python Dataframes methodology over Django models for such tasks.\n\nHow do you suggest I approach convincing them of this? Or do you think I might be mistaken in my approach? Open to your insights and suggestions!", "author_fullname": "t2_80ixgpf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Seeking Advice: Convincing a Startup to Embrace SQL/Python Dataframes over Django Models\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdjkaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710307126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineering consultant specializing in working with startups to develop robust data platforms. Currently, I&amp;#39;m collaborating with a Swedish company whose entire infrastructure is based on Postgres and Django. They&amp;#39;ve tasked me with either building upon or improving their existing platform to make it more manageable and scalable.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve noticed that they heavily rely on Django objects for the ETL process rather than utilizing SQL. As a data engineer, I firmly believe in the effectiveness of SQL/Python Dataframes methodology over Django models for such tasks.&lt;/p&gt;\n\n&lt;p&gt;How do you suggest I approach convincing them of this? Or do you think I might be mistaken in my approach? Open to your insights and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdjkaj", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic-Emergency75", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdjkaj/seeking_advice_convincing_a_startup_to_embrace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdjkaj/seeking_advice_convincing_a_startup_to_embrace/", "subreddit_subscribers": 168521, "created_utc": 1710307126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started to learn Python as a data engineering tool a few months ago. Since I come from a SQL background, I have gained good grasp of Pandas and Airflow pretty fast. Recently I heard about other ETL tools such as bonobo, PygramEtL and Petl. Are they still relevant? I tried to find youtube videos to learn more but most videos are quite old (more than 3 years old). I am not sure if I need to spend my energy learning these tools if they are not used often any more. If you are a data engineer, would you please tell me what python tools are you using? If you are still using bonobo, PygramEtL and Petl, would you please share some use cases? Thanks a lot!", "author_fullname": "t2_9od6j04g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Python for data engineering for finance. Is bonobo, PygramEtL and Petl still relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bddw39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710290645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started to learn Python as a data engineering tool a few months ago. Since I come from a SQL background, I have gained good grasp of Pandas and Airflow pretty fast. Recently I heard about other ETL tools such as bonobo, PygramEtL and Petl. Are they still relevant? I tried to find youtube videos to learn more but most videos are quite old (more than 3 years old). I am not sure if I need to spend my energy learning these tools if they are not used often any more. If you are a data engineer, would you please tell me what python tools are you using? If you are still using bonobo, PygramEtL and Petl, would you please share some use cases? Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bddw39", "is_robot_indexable": true, "report_reasons": null, "author": "Tall-Skin5800", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bddw39/learning_python_for_data_engineering_for_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bddw39/learning_python_for_data_engineering_for_finance/", "subreddit_subscribers": 168521, "created_utc": 1710290645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a non technical employee at a small business with mostly non tech employees. So any heavy lifting would be done by a consultant. We have an old Excel file that performs a critical function. The Excel file pulls data in from 5 CSV files (about 30mb total size) exported from one piece of software using Power Query, combines that with data pulled from 2 Salesforce Queries, and references other Excel files with Vlookups or Index equations. The query process used to be reliable and take about 5-10 seconds but has grown to about 30 seconds and fails frequently especially when there are lots of concurrent users(up to 12). I have a budget of $30,000 for a 50% chance at fixing the problem. I figure that having a database as the backend for the Excel file would make it run better. If the project is successful the follow up, with additional budget, would be:\n\nAdd additional data sources\n\nAutomate the data collection\n\nAdditional BI reporting\n\nI am looking for software that can grow with our needs, attainable data connections to other cloud software or data sources, and enough outside consultants that I am not tied to one firm. It seems that whatever consultant I choose would be inclined toward the software they are familiar with. So when screening consultants I should have an idea of what would work best. \n\nIs my budget reasonable? What software should I consider?", "author_fullname": "t2_9sx5w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What database should I use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdr3q3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710335512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a non technical employee at a small business with mostly non tech employees. So any heavy lifting would be done by a consultant. We have an old Excel file that performs a critical function. The Excel file pulls data in from 5 CSV files (about 30mb total size) exported from one piece of software using Power Query, combines that with data pulled from 2 Salesforce Queries, and references other Excel files with Vlookups or Index equations. The query process used to be reliable and take about 5-10 seconds but has grown to about 30 seconds and fails frequently especially when there are lots of concurrent users(up to 12). I have a budget of $30,000 for a 50% chance at fixing the problem. I figure that having a database as the backend for the Excel file would make it run better. If the project is successful the follow up, with additional budget, would be:&lt;/p&gt;\n\n&lt;p&gt;Add additional data sources&lt;/p&gt;\n\n&lt;p&gt;Automate the data collection&lt;/p&gt;\n\n&lt;p&gt;Additional BI reporting&lt;/p&gt;\n\n&lt;p&gt;I am looking for software that can grow with our needs, attainable data connections to other cloud software or data sources, and enough outside consultants that I am not tied to one firm. It seems that whatever consultant I choose would be inclined toward the software they are familiar with. So when screening consultants I should have an idea of what would work best. &lt;/p&gt;\n\n&lt;p&gt;Is my budget reasonable? What software should I consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdr3q3", "is_robot_indexable": true, "report_reasons": null, "author": "calky", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdr3q3/what_database_should_i_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdr3q3/what_database_should_i_use/", "subreddit_subscribers": 168521, "created_utc": 1710335512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just for all the people out there that are applying for jobs and having difficulty landing anything, keep pushing! \n\nWhen the market picks back up you will be happy that you kept upskilling yourself and you didn\u2019t give up ", "author_fullname": "t2_5q1b2lj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Positive Job Market Outlook", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be05tn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710357640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just for all the people out there that are applying for jobs and having difficulty landing anything, keep pushing! &lt;/p&gt;\n\n&lt;p&gt;When the market picks back up you will be happy that you kept upskilling yourself and you didn\u2019t give up &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be05tn", "is_robot_indexable": true, "report_reasons": null, "author": "Guilty-Commission435", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be05tn/positive_job_market_outlook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be05tn/positive_job_market_outlook/", "subreddit_subscribers": 168521, "created_utc": 1710357640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm fairly new so I'm trying to gather a consensus on how often your pipelines break and why?\n\nIs it expected that they will eventually break and there's nothing you can do about it? I've heard people say be as defensive in your pipelines as possible?\n\nHow do you get alerted about the breakages?", "author_fullname": "t2_tnf3rfrjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do your pipelines break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be165f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710360042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new so I&amp;#39;m trying to gather a consensus on how often your pipelines break and why?&lt;/p&gt;\n\n&lt;p&gt;Is it expected that they will eventually break and there&amp;#39;s nothing you can do about it? I&amp;#39;ve heard people say be as defensive in your pipelines as possible?&lt;/p&gt;\n\n&lt;p&gt;How do you get alerted about the breakages?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be165f", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Coat5856", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1be165f/how_often_do_your_pipelines_break/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be165f/how_often_do_your_pipelines_break/", "subreddit_subscribers": 168521, "created_utc": 1710360042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, dlt co-founder here!\n\nWe're on a mission to shake things up in data engineering by moving away from the repetitive and into the innovative, especially with source generation. Wondering about the future of connectors and traditional ETL tools? We see pipeline generation not just as a possibility but as our current reality, supported by the case study in the article.\n\nThe real question now isn't if we're generating sources, but how extensively we're doing it. Building a single data pipeline involves numerous decisions, and we're harnessing automation, LLMs, and the OpenAPI spec to streamline this process. While relying solely on automation tends to lead to compounded errors, a collaborative approach with human oversight is proving effective.\n\nWhat's the future of ETL libraries in this evolving landscape? Our experience and user feedback suggest a significant shift. With 500 private sources created last month alone by the dlt community without any code generation, we hope that empowering the community with better tooling and growing the community will 100x this process within the year.\n\nWant to dive deeper? Check out our [latest blog post](https://dlthub.com/docs/blog/code-vs-buy) and the related case study. \n\nYou can try the code generator we created last year (in the post), but you should probably hold off for our update towards the end of the month.  \n\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The future of Data Engineering: Beyond traditional ETL \"Connectors\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdp3jf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710329128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, dlt co-founder here!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on a mission to shake things up in data engineering by moving away from the repetitive and into the innovative, especially with source generation. Wondering about the future of connectors and traditional ETL tools? We see pipeline generation not just as a possibility but as our current reality, supported by the case study in the article.&lt;/p&gt;\n\n&lt;p&gt;The real question now isn&amp;#39;t if we&amp;#39;re generating sources, but how extensively we&amp;#39;re doing it. Building a single data pipeline involves numerous decisions, and we&amp;#39;re harnessing automation, LLMs, and the OpenAPI spec to streamline this process. While relying solely on automation tends to lead to compounded errors, a collaborative approach with human oversight is proving effective.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the future of ETL libraries in this evolving landscape? Our experience and user feedback suggest a significant shift. With 500 private sources created last month alone by the dlt community without any code generation, we hope that empowering the community with better tooling and growing the community will 100x this process within the year.&lt;/p&gt;\n\n&lt;p&gt;Want to dive deeper? Check out our &lt;a href=\"https://dlthub.com/docs/blog/code-vs-buy\"&gt;latest blog post&lt;/a&gt; and the related case study. &lt;/p&gt;\n\n&lt;p&gt;You can try the code generator we created last year (in the post), but you should probably hold off for our update towards the end of the month.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?auto=webp&amp;s=89baf6cd5beccc2ef436f6c5fd2bf1b1d206cb32", "width": 1780, "height": 994}, "resolutions": [{"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f7670b7c98fe4b83ea3de40d3e2e9046a886096", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0532458503ce22d0b009efd3ed3b0b7bb6b029ba", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=68e0562d5f34ce8a12ad3c477cb49a50cccef51a", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b99612b4585f2153ce648471fbef74ec45cb6ce", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a21ae84c23b97582b017045fe6241cafa3e455ba", "width": 960, "height": 536}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8179bfc0a98adacdd1fbe84e92dab79336661918", "width": 1080, "height": 603}], "variants": {}, "id": "dNitETZjWStuGD_7fRr5BIR4unHLIjEoCTLF_W7F4wA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bdp3jf", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdp3jf/the_future_of_data_engineering_beyond_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdp3jf/the_future_of_data_engineering_beyond_traditional/", "subreddit_subscribers": 168521, "created_utc": 1710329128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been data engineer (mostly working on ETLs in cloud environments) for 5 years. I started a new position yesterday in an industry that requires to work on premises. Nothing exists yet, the project starts with me, which is very enthusiastic. \n\nHowever I am a bit lost after 2 days struggling on the stack. Right now I am trying to identify which tools I should use. The load of data isn't that big yet but it's required to make something a bit scalable; that could welcome new sources of data (structured and unstructured)\n\nMy idea is the following : \n\nAirflow as an orchestrator (already have an experience on it), HDFS for a datalake, PySpark scripts for ETL (comfortable on it) , Hive or Presto for datawarehousing, Metabase for viz \n\nTherefore right now I have created docker containers running Spark, HDFS and Airflow. However the more I go further, the more I am doubting. There are so many tools existing for everything and I feel like this stack is a bit oldish ... I've also checked open source versions of Dremio, Cloudera, Iceberg/minIO but I am not sure how suitable it is for a production environment where all the data weighs probably less than 100GB. Also, I'll stay at my position for approx 6 months, I need to make something that would be easily maintained by people who don't work in data engineering field, I feel like Iceberg would be overkill. I sometimes also think about doing easier stuff with pandas/postgres but this is limiting for unstructured data. \n\nI would be glad to receive your opinions about it !\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6d257z60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On premise stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdzyr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710357167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been data engineer (mostly working on ETLs in cloud environments) for 5 years. I started a new position yesterday in an industry that requires to work on premises. Nothing exists yet, the project starts with me, which is very enthusiastic. &lt;/p&gt;\n\n&lt;p&gt;However I am a bit lost after 2 days struggling on the stack. Right now I am trying to identify which tools I should use. The load of data isn&amp;#39;t that big yet but it&amp;#39;s required to make something a bit scalable; that could welcome new sources of data (structured and unstructured)&lt;/p&gt;\n\n&lt;p&gt;My idea is the following : &lt;/p&gt;\n\n&lt;p&gt;Airflow as an orchestrator (already have an experience on it), HDFS for a datalake, PySpark scripts for ETL (comfortable on it) , Hive or Presto for datawarehousing, Metabase for viz &lt;/p&gt;\n\n&lt;p&gt;Therefore right now I have created docker containers running Spark, HDFS and Airflow. However the more I go further, the more I am doubting. There are so many tools existing for everything and I feel like this stack is a bit oldish ... I&amp;#39;ve also checked open source versions of Dremio, Cloudera, Iceberg/minIO but I am not sure how suitable it is for a production environment where all the data weighs probably less than 100GB. Also, I&amp;#39;ll stay at my position for approx 6 months, I need to make something that would be easily maintained by people who don&amp;#39;t work in data engineering field, I feel like Iceberg would be overkill. I sometimes also think about doing easier stuff with pandas/postgres but this is limiting for unstructured data. &lt;/p&gt;\n\n&lt;p&gt;I would be glad to receive your opinions about it !&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdzyr0", "is_robot_indexable": true, "report_reasons": null, "author": "Ruyia31", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdzyr0/on_premise_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdzyr0/on_premise_stack/", "subreddit_subscribers": 168521, "created_utc": 1710357167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short, we are trying to keep company tools in sync. today it is a mess that comes to bite on the data end as it creates low trust in data quality. \n\nNow some tools have native integrations, which makes things easy, but for some reason, the toolset that our company settled on does not have this (outside of a few mainstream apps)\n\nThe way I see it we have three options \n\n1. Build our integrations between tools and/or integrations between our warehouse and the tools (reverse ETL), seems like lots of work to build and then maintain \n2. Use an IPaaS solution, here I would have to have someone learn the tool as each one of these tools usually uses some proprietary way of doing things. \n3. Reverse ETL tool, this is new to me, haven't really worked with one in the past but I had a call [Hightouch](https://hightouch.com)Reverse ETL tool this is new to me, I haven't really worked with one in the past, but I had a call with Hightouch, and it seems promising. It seems to fit the data team a bit better than the other 2 options as most of the work will be done within warehouse dbt transformations, which anyone in the team can do   \n\n\nAny recommendations on how to tackle this? Have you guys worked with a Reverse ETL tool? If yes which one and what's your feedback   ", "author_fullname": "t2_et5t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping org tools in sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdtjwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710345886.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710341933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, we are trying to keep company tools in sync. today it is a mess that comes to bite on the data end as it creates low trust in data quality. &lt;/p&gt;\n\n&lt;p&gt;Now some tools have native integrations, which makes things easy, but for some reason, the toolset that our company settled on does not have this (outside of a few mainstream apps)&lt;/p&gt;\n\n&lt;p&gt;The way I see it we have three options &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Build our integrations between tools and/or integrations between our warehouse and the tools (reverse ETL), seems like lots of work to build and then maintain &lt;/li&gt;\n&lt;li&gt;Use an IPaaS solution, here I would have to have someone learn the tool as each one of these tools usually uses some proprietary way of doing things. &lt;/li&gt;\n&lt;li&gt;Reverse ETL tool, this is new to me, haven&amp;#39;t really worked with one in the past but I had a call &lt;a href=\"https://hightouch.com\"&gt;Hightouch&lt;/a&gt;Reverse ETL tool this is new to me, I haven&amp;#39;t really worked with one in the past, but I had a call with Hightouch, and it seems promising. It seems to fit the data team a bit better than the other 2 options as most of the work will be done within warehouse dbt transformations, which anyone in the team can do&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any recommendations on how to tackle this? Have you guys worked with a Reverse ETL tool? If yes which one and what&amp;#39;s your feedback   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?auto=webp&amp;s=9536c052f365bbf3762edff656ecbf9ff1c87a20", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e45b525dae7b055f04a99a6162ace736c384fa2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2e6bd7eefa3c34e35b0df80988a8a58b5b1d59b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa1a6445448c2ef5897ecf6c2d3fd479726852de", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6b29ff2c57ada4dd2f2173db2c1e92121437df1", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=45d6c4070a6154d439799678966846f8386890d0", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=311daa8b857a8795d13fd2269b9cb5eff88c4ab6", "width": 1080, "height": 565}], "variants": {}, "id": "7X-6dPLJU2TmqoD0kEsCB8XE26QEVlx0zliDnH3JJLc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdtjwb", "is_robot_indexable": true, "report_reasons": null, "author": "MrGreenPL", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdtjwb/keeping_org_tools_in_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdtjwb/keeping_org_tools_in_sync/", "subreddit_subscribers": 168521, "created_utc": 1710341933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nPlease feel free to stop me in my tracks if I\u2019m going down a bad path. I want to develop my data input forms as webapps with Streamlit. They won\u2019t be dashboards as is typical, but data collection tools. I love the minimal look of Streamlit and it\u2019s quite easy to put out a working product quickly with it. However, that ease makes me concerned a bit- is it safe for deployment?\n\nSome background:\n\nI\u2019ll probably want to deploy several replicas of the application and distribute load among them for high-availability. Perhaps only 2-3 instances is fine though, as this isn\u2019t for high load.\n\nUsers will access the app from remote locations, potentially up to 10-15 at a time. Their internet connection may be poor at best, but if their internet goes out it\u2019s not technically my problem anymore. I\u2019ll just want to make sure (for now) that I can perform well under medium latency.\n\nI\u2019ll launch it was k3s to automate a lot of the infrastructure management. FastAPI will sit between Streamlit and the database.\n\nI guess if nobody knows, I\u2019ll give it a shot and let you guys know how it goes. Can anyone offer some insight ahead of time though?\n\nThanks!", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone deployed Streamlit for some intense workload?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdcdex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710286700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Please feel free to stop me in my tracks if I\u2019m going down a bad path. I want to develop my data input forms as webapps with Streamlit. They won\u2019t be dashboards as is typical, but data collection tools. I love the minimal look of Streamlit and it\u2019s quite easy to put out a working product quickly with it. However, that ease makes me concerned a bit- is it safe for deployment?&lt;/p&gt;\n\n&lt;p&gt;Some background:&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll probably want to deploy several replicas of the application and distribute load among them for high-availability. Perhaps only 2-3 instances is fine though, as this isn\u2019t for high load.&lt;/p&gt;\n\n&lt;p&gt;Users will access the app from remote locations, potentially up to 10-15 at a time. Their internet connection may be poor at best, but if their internet goes out it\u2019s not technically my problem anymore. I\u2019ll just want to make sure (for now) that I can perform well under medium latency.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll launch it was k3s to automate a lot of the infrastructure management. FastAPI will sit between Streamlit and the database.&lt;/p&gt;\n\n&lt;p&gt;I guess if nobody knows, I\u2019ll give it a shot and let you guys know how it goes. Can anyone offer some insight ahead of time though?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdcdex", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdcdex/has_anyone_deployed_streamlit_for_some_intense/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdcdex/has_anyone_deployed_streamlit_for_some_intense/", "subreddit_subscribers": 168521, "created_utc": 1710286700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Link](https://www.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/) to the initial post. Posting this again after debugging. Since this is my first project, I appreciate your feedback on anything; be it Github readme, dashboard, etc.\n\n&amp;#x200B;\n\nLeveraging Schipol Dev API, I've built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard [here](https://aeroatlas.streamlit.app/). I'd love your feedback, suggestions, and opinions to enhance this data-driven journey! Also find the Github repo [here](https://github.com/suleman1412/schipol_flights_pipeline).\n\n&amp;#x200B;", "author_fullname": "t2_rw01dudv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updated: Just launched my first data engineering project!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdv1xv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710345609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/\"&gt;Link&lt;/a&gt; to the initial post. Posting this again after debugging. Since this is my first project, I appreciate your feedback on anything; be it Github readme, dashboard, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Leveraging Schipol Dev API, I&amp;#39;ve built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard &lt;a href=\"https://aeroatlas.streamlit.app/\"&gt;here&lt;/a&gt;. I&amp;#39;d love your feedback, suggestions, and opinions to enhance this data-driven journey! Also find the Github repo &lt;a href=\"https://github.com/suleman1412/schipol_flights_pipeline\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?auto=webp&amp;s=ede95ca400f22e057dffa04ff31de469ef538d82", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d897456f2eb1ccf0e4332fe0dc9bbf31d8785cf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ca7b49d3f21a52a175276cb6e52c44193295a8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e17c7da02f04519c29ac1a7849ad490919346c10", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d3f6fc21cae9cd51c7d0c363e2684ea79774a5f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54ecbc0a8baed2ce0f49d6dab5807c120ec0cdd5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=465c26e0a14bb5641bcce7b228b1b687029074bc", "width": 1080, "height": 567}], "variants": {}, "id": "QDBuNMj6jujXmJHrzKao8hw5SfNdcufBYQsaXgPrC7Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bdv1xv", "is_robot_indexable": true, "report_reasons": null, "author": "botuleman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdv1xv/updated_just_launched_my_first_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdv1xv/updated_just_launched_my_first_data_engineering/", "subreddit_subscribers": 168521, "created_utc": 1710345609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I tested the code that Daniel Palma created for Running Doom inside Snowflake Container Services. In this video I'll show case the same in video format and explore a little bit what Container Services are and what are their use cases.\n\n[https://www.youtube.com/watch?v=Zd81nydtgX4](https://www.youtube.com/watch?v=Zd81nydtgX4)", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Doom in Snowflake Container Services (again)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdovx9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710328577.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710328378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tested the code that Daniel Palma created for Running Doom inside Snowflake Container Services. In this video I&amp;#39;ll show case the same in video format and explore a little bit what Container Services are and what are their use cases.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=Zd81nydtgX4\"&gt;https://www.youtube.com/watch?v=Zd81nydtgX4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?auto=webp&amp;s=afbcfde278fdf6f2f100bacfcfb80da367dc5d4c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=525eda73b654ebd15290c6b9d187c977c2a133ec", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc219c0229e4e211fed5eb54c89866c06157f0fa", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19112e2acdafd3c6ff33454a4582f1f98477777a", "width": 320, "height": 240}], "variants": {}, "id": "ChKNgWkPA8nGKkFnTBiHTPOdr_9M-xnMaoB34UiAtTg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bdovx9", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdovx9/running_doom_in_snowflake_container_services_again/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdovx9/running_doom_in_snowflake_container_services_again/", "subreddit_subscribers": 168521, "created_utc": 1710328378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI've been thinking a lot about how we, as data professionals, are tackling data adoption hurdles, especially in areas like drug development and personalized medicine (Life Sciences); so I wrote this article. \n\n[https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare](https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare)\n\nAre you facing similar challenges? How are you managing them, and what strategies or tools have made a difference in your work?\n\nReally curious to hear if your experiences align with mine and how you're navigating this complex landscape.", "author_fullname": "t2_fosm1pwyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data in Life Sciences: Are We on the Same Page?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be1kpo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710361010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking a lot about how we, as data professionals, are tackling data adoption hurdles, especially in areas like drug development and personalized medicine (Life Sciences); so I wrote this article. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare\"&gt;https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Are you facing similar challenges? How are you managing them, and what strategies or tools have made a difference in your work?&lt;/p&gt;\n\n&lt;p&gt;Really curious to hear if your experiences align with mine and how you&amp;#39;re navigating this complex landscape.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?auto=webp&amp;s=91c90fdf2875134891d193f444905b830d0864da", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e5046c0a3229b2e9e21ed3054b87f1903055596", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86c79bee66d97e1e8dcb050394863d568359d343", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b69b996d84839071da5ae484eb249679d4b969d", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b2237495e1c0a2c721481a18987c1e1e4940a2a4", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ce5da23d057f738322d8874cda1f5d036e44aef", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd322b26a9ac0c1761783fa0722662cb6b7dd90e", "width": 1080, "height": 564}], "variants": {}, "id": "9AKl43XPJbE9__vNApnXsZxefA6nyXZTbapru4_2mhE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1be1kpo", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Queen-Mayra", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be1kpo/data_in_life_sciences_are_we_on_the_same_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be1kpo/data_in_life_sciences_are_we_on_the_same_page/", "subreddit_subscribers": 168521, "created_utc": 1710361010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was working for some time with airflow. However, now some companies migrate to dagster. Why though? Migration always has its prize.", "author_fullname": "t2_uuylu9emi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster vs Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1be578w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710369640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was working for some time with airflow. However, now some companies migrate to dagster. Why though? Migration always has its prize.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be578w", "is_robot_indexable": true, "report_reasons": null, "author": "LinasData", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be578w/dagster_vs_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be578w/dagster_vs_airflow/", "subreddit_subscribers": 168521, "created_utc": 1710369640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nPlease give me any suggestions what will be the best way to redesign this data pipeline, to ingest data from the BI tool back to the source table in Snowflake.  \nCurrent setup:\n\nhttps://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267\n\n I have a Google spreadsheet that is transformed daily with DBT and stored in Snowflake DB as a mart-ready table for analysis. This table undergoes a full refresh daily. Later, this table is connected to the BI tool where Data Analysts analyze the data. However, they now want to manually input data in Power BI so that this data will be saved in the initial source table in Snowflake.\n\nHow should I approach this, considering that the initial table is refreshed daily? I'm thinking of changing DBT materialization to incremental or creating a new extra table in Snowflake that will be a combination of raw source data and input from BI. Maybe there is a better way yo do it?  \n", "author_fullname": "t2_2odyjk2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redesign ETL process, DBT table materialization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": false, "media_metadata": {"94pdir9f16oc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 31, "x": 108, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cfbf74ade92410d88497db8af9b8ca27c372c2d"}, {"y": 62, "x": 216, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=193da8daaf9a56362353b507bc96cbfb62728b22"}, {"y": 92, "x": 320, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0755624e597482769b696c4eca8f753b2b873a4f"}, {"y": 184, "x": 640, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=acf0061a8c4917dd169a02a9982c1ba70cf35117"}, {"y": 276, "x": 960, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee2b256c89aa02600584f6bec6d9bda5d9b096aa"}, {"y": 311, "x": 1080, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c4ad491af8a3239eb5ef8e96e103cfaa068ff6ea"}], "s": {"y": 316, "x": 1096, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267"}, "id": "94pdir9f16oc1"}}, "name": "t3_1be395d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/63jK-_OvQUavcQrCcrDL58R0CJs6FkXm08oDXfbz9Ac.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710364982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Please give me any suggestions what will be the best way to redesign this data pipeline, to ingest data from the BI tool back to the source table in Snowflake.&lt;br/&gt;\nCurrent setup:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267\"&gt;https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a Google spreadsheet that is transformed daily with DBT and stored in Snowflake DB as a mart-ready table for analysis. This table undergoes a full refresh daily. Later, this table is connected to the BI tool where Data Analysts analyze the data. However, they now want to manually input data in Power BI so that this data will be saved in the initial source table in Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this, considering that the initial table is refreshed daily? I&amp;#39;m thinking of changing DBT materialization to incremental or creating a new extra table in Snowflake that will be a combination of raw source data and input from BI. Maybe there is a better way yo do it?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1be395d", "is_robot_indexable": true, "report_reasons": null, "author": "Krukach", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be395d/redesign_etl_process_dbt_table_materialization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be395d/redesign_etl_process_dbt_table_materialization/", "subreddit_subscribers": 168521, "created_utc": 1710364982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm organizing a workshop next Tuesday, March 19, 2024, at 4 PM Pacific Time. During this workshop, instructors will build a real-time dashboard for analyzing pizza shop orders using OSS products: Bytewax, Pinot, and Streamlit.\nFor more details and to RSVP (attendance is free), please visit:\nhttps://bytewax.io/events/real-time-pizza-analytics\n\nI believe this workshop is especially noteworthy for those interested, as I've personally enjoyed migrating the previous solution from Kafka Streams to Bytewax. The solution is now more Python-friendly and the complexity of the codebase is significantly reduced. For me, it felt truly refreshing to rewrite it \ud83d\ude04 I believe many data engineers would prefer Python solutions over JVM based.\n\nI am still in the process of updating the repository and will share it later, but here is the previous version:\nhttps://dev.startree.ai/docs/pinot/demo-apps/pizza-shop", "author_fullname": "t2_zus64vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Workshop: Real time data streaming + Analytics + Visualization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2xai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710364229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m organizing a workshop next Tuesday, March 19, 2024, at 4 PM Pacific Time. During this workshop, instructors will build a real-time dashboard for analyzing pizza shop orders using OSS products: Bytewax, Pinot, and Streamlit.\nFor more details and to RSVP (attendance is free), please visit:\n&lt;a href=\"https://bytewax.io/events/real-time-pizza-analytics\"&gt;https://bytewax.io/events/real-time-pizza-analytics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I believe this workshop is especially noteworthy for those interested, as I&amp;#39;ve personally enjoyed migrating the previous solution from Kafka Streams to Bytewax. The solution is now more Python-friendly and the complexity of the codebase is significantly reduced. For me, it felt truly refreshing to rewrite it \ud83d\ude04 I believe many data engineers would prefer Python solutions over JVM based.&lt;/p&gt;\n\n&lt;p&gt;I am still in the process of updating the repository and will share it later, but here is the previous version:\n&lt;a href=\"https://dev.startree.ai/docs/pinot/demo-apps/pizza-shop\"&gt;https://dev.startree.ai/docs/pinot/demo-apps/pizza-shop&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?auto=webp&amp;s=9710ac602cc3d55cdc3483c30610f0d6cec287c7", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=be1e5d4935c553e543ed40f9063b0890186f9b65", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc522633caa9ca91f4222971361ed6867641bdfa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a14311bc251f6667bef9851c488608dafcfda35f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa1a7d640b445b93da6892292643b670a9e21ecd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=55556a2666f8268a495d077ff92ee5135aa6ee4b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c3598d6efc61818791e553aabc53f37918820c8", "width": 1080, "height": 607}], "variants": {}, "id": "kpggDHbug4GLpb_LymyREbDxwQCTGOuosNWiRAKAgVg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1be2xai", "is_robot_indexable": true, "report_reasons": null, "author": "oli_k", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2xai/virtual_workshop_real_time_data_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2xai/virtual_workshop_real_time_data_streaming/", "subreddit_subscribers": 168521, "created_utc": 1710364229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n&amp;#x200B;\n\n# How to integrate Great Expecation Data Quality tests in Airflow?\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1) Orchestrate Modern Data Stack\n\nVlog on how to how to integrate Great Expectation Data Quality tests in the Apache Airflow.  We use the Great Expectation (GE) provider for Airlow and run the Great Expectations suite. The target data asset is a PostgreSQL table.  We use Airflow as the orchestrator for the ETL (ELT) Data piepline and GE as the testing framework\n\n[https://www.youtube.com/watch?v=WAgbFrHUk50](https://www.youtube.com/watch?v=WAgbFrHUk50)\n\nTopics covered:\n\n* Data Orchestartion\n* Airflow &amp; DAG\n* Airflow GE Provider\n* Run Modern Data Stack with Airflow\n\nTech Stack: **Airflow, Great Expecations, Data Quality, Python**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate Great Expecation Data Quality tests in Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2kwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710363424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;How to integrate Great Expecation Data Quality tests in Airflow?&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; Orchestrate Modern Data Stack&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to how to integrate Great Expectation Data Quality tests in the Apache Airflow.  We use the Great Expectation (GE) provider for Airlow and run the Great Expectations suite. The target data asset is a PostgreSQL table.  We use Airflow as the orchestrator for the ETL (ELT) Data piepline and GE as the testing framework&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=WAgbFrHUk50\"&gt;https://www.youtube.com/watch?v=WAgbFrHUk50&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Orchestartion&lt;/li&gt;\n&lt;li&gt;Airflow &amp;amp; DAG&lt;/li&gt;\n&lt;li&gt;Airflow GE Provider&lt;/li&gt;\n&lt;li&gt;Run Modern Data Stack with Airflow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, Great Expecations, Data Quality, Python&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?auto=webp&amp;s=1f9fac17204c854b5b4d082002059c44d5ae03ed", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8be4ceb1eb56baade4c73afe89f795ba729582c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a24799e256cfd2e1a27df43a0bac89db7a456ad0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb45dfe184a212d81531e5227e21e5f5f95a26b2", "width": 320, "height": 240}], "variants": {}, "id": "TSidoV9hmIfyC3VVXAqXTE2OWfjCP7yrcSm4ForS6lE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1be2kwd", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2kwd/how_to_integrate_great_expecation_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2kwd/how_to_integrate_great_expecation_data_quality/", "subreddit_subscribers": 168521, "created_utc": 1710363424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "guys i recently registered in a data engineering course but i have been going back and forth with backend node.js  so which is better in terms of freelancing jobs and career overall ?", "author_fullname": "t2_b2gb54ug0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2d9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710362909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;guys i recently registered in a data engineering course but i have been going back and forth with backend node.js  so which is better in terms of freelancing jobs and career overall ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be2d9k", "is_robot_indexable": true, "report_reasons": null, "author": "AggressiveReport4655", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2d9k/data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2d9k/data/", "subreddit_subscribers": 168521, "created_utc": 1710362909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are folk seeing a general trend in the particular pairings of open-source compute platforms and open table formats (OTF)? \n\nSpecifically: \n\n1. My _assumption_ is that #ApacheSpark [Databricks] is most often used with #DeltaLake [Databricks], and less so than with Hudi and Iceberg. Is that true?\n\n2. Does #ApacheFlink get used with #ApacheIceberg / #ApacheHudi / #DeltaLake equally when an OTF is involved, or weighted towards one or the other?\n\nI know that folk at the various respective vendors in this space are going to have a bunch of data points to share illustrating the pairings in permutations of favourable light ;) But I would love to hear from folk in the field too who have anecdotal evidence to share too :D\n\nTIA.", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink&amp;Spark - which OTF most commonly used with each?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdyu6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710354558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are folk seeing a general trend in the particular pairings of open-source compute platforms and open table formats (OTF)? &lt;/p&gt;\n\n&lt;p&gt;Specifically: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;My &lt;em&gt;assumption&lt;/em&gt; is that #ApacheSpark [Databricks] is most often used with #DeltaLake [Databricks], and less so than with Hudi and Iceberg. Is that true?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Does #ApacheFlink get used with #ApacheIceberg / #ApacheHudi / #DeltaLake equally when an OTF is involved, or weighted towards one or the other?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I know that folk at the various respective vendors in this space are going to have a bunch of data points to share illustrating the pairings in permutations of favourable light ;) But I would love to hear from folk in the field too who have anecdotal evidence to share too :D&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdyu6v", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdyu6v/flinkspark_which_otf_most_commonly_used_with_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdyu6v/flinkspark_which_otf_most_commonly_used_with_each/", "subreddit_subscribers": 168521, "created_utc": 1710354558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have question like that How do all you guys check if your data consistent. Let me be more detailed. Think about that you have two tables one in A server another in B and based on A table, B table is being updated. I want to check if all the values in B table matches values of A table. Is there best practice to check it ? Currently I have developed my logic, checking both tables with python code. But wonder what if tomorrow the size of tables growths to 2 billion rows. I would like to get your recommendations", "author_fullname": "t2_hf6pnxd8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data consistency checking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdy4lv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710352916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have question like that How do all you guys check if your data consistent. Let me be more detailed. Think about that you have two tables one in A server another in B and based on A table, B table is being updated. I want to check if all the values in B table matches values of A table. Is there best practice to check it ? Currently I have developed my logic, checking both tables with python code. But wonder what if tomorrow the size of tables growths to 2 billion rows. I would like to get your recommendations&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdy4lv", "is_robot_indexable": true, "report_reasons": null, "author": "Fair_Palpitation8548", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdy4lv/data_consistency_checking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdy4lv/data_consistency_checking/", "subreddit_subscribers": 168521, "created_utc": 1710352916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Guys,\n\nNeed some help on writestream with foreachbatch, so my code runs perfectly fine on a single user cluster but when i test it out on a shared multinode cluster it break with an error\n\n&amp;#x200B;\n\n`def process_batch(df, batch_id):`  \n`AT_original.alias(\"t\").merge(`  \n`df_batch.alias(\"s\"),`  \n `\"s.key = t.key\"`  \n`).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()`  \n`query = df.writeStream \\`  \n`.format('delta') \\`  \n`.outputMode(\"update\") \\`  \n`.foreachBatch(process_batch) \\`  \n`.option('checkpointLocation',)\\`  \n`.trigger(once=True) \\`  \n`.start()`\n\nCannot serialize the function \\`foreachBatch\\`  \n\n\nwhat am i missing here?", "author_fullname": "t2_2ssprs7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark Structured Streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdxy8e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710352500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys,&lt;/p&gt;\n\n&lt;p&gt;Need some help on writestream with foreachbatch, so my code runs perfectly fine on a single user cluster but when i test it out on a shared multinode cluster it break with an error&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;def process_batch(df, batch_id):&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;AT_original.alias(&amp;quot;t&amp;quot;).merge(&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;df_batch.alias(&amp;quot;s&amp;quot;),&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;&amp;quot;s.key = t.key&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;query = df.writeStream \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.format(&amp;#39;delta&amp;#39;) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.outputMode(&amp;quot;update&amp;quot;) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.foreachBatch(process_batch) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.option(&amp;#39;checkpointLocation&amp;#39;,)\\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.trigger(once=True) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.start()&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Cannot serialize the function `foreachBatch`  &lt;/p&gt;\n\n&lt;p&gt;what am i missing here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdxy8e", "is_robot_indexable": true, "report_reasons": null, "author": "anurag_bhoga", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdxy8e/pyspark_structured_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdxy8e/pyspark_structured_streaming/", "subreddit_subscribers": 168521, "created_utc": 1710352500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(I have no affiliation with the tool)\n\nIf you are tired of drag-and-drop or heavy client-server applications for data ingestion, worth checking this alternative open-source framework written in Go. Simple, fast and stateless.\n\n[https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery](https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery) ", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to ELT with CloudQuery \u2014 a declarative data integration framework for developers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdvhzv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710346685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(I have no affiliation with the tool)&lt;/p&gt;\n\n&lt;p&gt;If you are tired of drag-and-drop or heavy client-server applications for data ingestion, worth checking this alternative open-source framework written in Go. Simple, fast and stateless.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery\"&gt;https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bdvhzv", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdvhzv/introduction_to_elt_with_cloudquery_a_declarative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdvhzv/introduction_to_elt_with_cloudquery_a_declarative/", "subreddit_subscribers": 168521, "created_utc": 1710346685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data fellas, with version 2.1.0 available, we take this opportunity to re-introduce Apache Doris as an open-source data warehouse that provides:\n\n* **Higher out-of-the-box query performance**: 100% faster speed proven by TPC-DS 1TB benchmark tests.\n* **Improved data lake analytics capabilities**: 4\\~6 times faster than Trino and Spark, compatibility with various SQL dialects for smooth migration, read/write interface based on Arrow Flight for 100 times faster data transfer.\n* **Solid support for semi-structured data analysis**: a newly-added Variant data type, support for more IP types, and a more comprehensive suite of analytic functions.\n* **Materialized view with multiple tables**: a new feature to accelerate multi-table joins, allowing transparent rewriting, auto refresh, materialized views of external tables, and direct query.\n* **Enhanced real-time writing efficiency**: faster data writing at scale powered by AUTO\\_INCREMENT column, AUTO PARTITION, forward placement of MemTable, and Group Commit.\n* **Better workload management**: optimizations of the Workload Group mechanism for higher performance stability and the display of SQL resource consumption in the runtime.\n\nThis very informative release note provides details of the performance tests and the implementation of the new features and mechanisms that make the difference. Take a look and tell us what you think!  \n[https://doris.apache.org/blog/release-note-2.1.0](https://doris.apache.org/blog/release-note-2.1.0)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.1.0 is released, with doubled out-of-the-box performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdvhll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710346656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data fellas, with version 2.1.0 available, we take this opportunity to re-introduce Apache Doris as an open-source data warehouse that provides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Higher out-of-the-box query performance&lt;/strong&gt;: 100% faster speed proven by TPC-DS 1TB benchmark tests.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Improved data lake analytics capabilities&lt;/strong&gt;: 4~6 times faster than Trino and Spark, compatibility with various SQL dialects for smooth migration, read/write interface based on Arrow Flight for 100 times faster data transfer.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Solid support for semi-structured data analysis&lt;/strong&gt;: a newly-added Variant data type, support for more IP types, and a more comprehensive suite of analytic functions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Materialized view with multiple tables&lt;/strong&gt;: a new feature to accelerate multi-table joins, allowing transparent rewriting, auto refresh, materialized views of external tables, and direct query.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enhanced real-time writing efficiency&lt;/strong&gt;: faster data writing at scale powered by AUTO_INCREMENT column, AUTO PARTITION, forward placement of MemTable, and Group Commit.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Better workload management&lt;/strong&gt;: optimizations of the Workload Group mechanism for higher performance stability and the display of SQL resource consumption in the runtime.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This very informative release note provides details of the performance tests and the implementation of the new features and mechanisms that make the difference. Take a look and tell us what you think!&lt;br/&gt;\n&lt;a href=\"https://doris.apache.org/blog/release-note-2.1.0\"&gt;https://doris.apache.org/blog/release-note-2.1.0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?auto=webp&amp;s=11ea49814dea9685e2e1f544cfcee4bdcdc37feb", "width": 1800, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5658ef6d8410cc1d396be16a9ecca937def2281", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbbb6f0c25a70f68275b84b06eab33ddd1a92980", "width": 216, "height": 92}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4dd9d38c646f94128d78a2f56086d51d43d0d88", "width": 320, "height": 136}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b1594732efa7e36dc0d8386e059464c620558dbe", "width": 640, "height": 273}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04d781acd91cbcd252e32b196156d5f4276ea2ca", "width": 960, "height": 409}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ac9e97f87dbb83201c28edcdab037a4859ef9f5", "width": 1080, "height": 460}], "variants": {}, "id": "lO_-l9zrS9XOVWUk5oc40xL8UJr9pZxafcbBIwujrOc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bdvhll", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdvhll/apache_doris_210_is_released_with_doubled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdvhll/apache_doris_210_is_released_with_doubled/", "subreddit_subscribers": 168521, "created_utc": 1710346656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " For those of you who use PySpark consistently, \n\ndo you have code coverage for PySpark UDF/RDD? \n\nWhich tools do you use?", "author_fullname": "t2_a7j25p8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyspark coverage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdql0m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710333976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those of you who use PySpark consistently, &lt;/p&gt;\n\n&lt;p&gt;do you have code coverage for PySpark UDF/RDD? &lt;/p&gt;\n\n&lt;p&gt;Which tools do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdql0m", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoubts9729", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdql0m/pyspark_coverage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdql0m/pyspark_coverage/", "subreddit_subscribers": 168521, "created_utc": 1710333976.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}