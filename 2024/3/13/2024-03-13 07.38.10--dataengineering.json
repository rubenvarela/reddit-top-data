{"kind": "Listing", "data": {"after": "t3_1bd2389", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It\u2019s happening guys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd5wv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 308, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 308, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a74WmaMoBJWdXjOc5lN_oAw6cl-ZpX12mnDZTZx8nDg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710271207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/x2u0nprdeync1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?auto=webp&amp;s=7951e286519849d36881db89b9f736171e631a3d", "width": 1170, "height": 2532}, "resolutions": [{"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e544c49f7f0b9018a52397ce2691791d9f50a79", "width": 108, "height": 216}, {"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dcaf31155b0240163bd0a934a6a4360b92c792e0", "width": 216, "height": 432}, {"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d1f498dead47a709422a080d2dce5f9c539b8b8", "width": 320, "height": 640}, {"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39cfe0c1bc03ac5f92031532267ae741609d63f1", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f9c0cbf05a30219f48a8381a2efcf54f4b714fb8", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/x2u0nprdeync1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e29cb1e3855ca64e8184c10a52a612cf734d9230", "width": 1080, "height": 2160}], "variants": {}, "id": "jADU1Bmpqn51dvqLJa9gq3LlR2IVPhPc3jXKMELUDM0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd5wv8", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 113, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd5wv8/its_happening_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/x2u0nprdeync1.jpeg", "subreddit_subscribers": 168213, "created_utc": 1710271207.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. I have worked my way up in my organization from Service Desk Analyst to the title of a Data Engineernand have been with this company for almost 7 years. My primary tasks are maintening an AWS Glue pipeline into our data lake and bringing new tables from various sources into it. I know python somewhat well (I can pass some medium leetcode problems as a reference), my SQL skills are very basic, I feel like my organization is so far behind things techwise I am getting away with it and I can use chatgpt well enough to figure out anything I don't know. \n\nTyping this out I feel like I'm describing myself more competent than I feel. I have no formal education besides highschool and a boatload of AWS certifications I always have to study my butt off for. \n\nI'm not sure what the point of this post is, I just kinda needed to rant and get it off my chest to someone and maybe get some outside perspective.\n\nHow do you guys deal with thoughts like these? Do my skills line up with what's expected of a DE? ", "author_fullname": "t2_kaic0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like such a fraud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd500u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710269114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. I have worked my way up in my organization from Service Desk Analyst to the title of a Data Engineernand have been with this company for almost 7 years. My primary tasks are maintening an AWS Glue pipeline into our data lake and bringing new tables from various sources into it. I know python somewhat well (I can pass some medium leetcode problems as a reference), my SQL skills are very basic, I feel like my organization is so far behind things techwise I am getting away with it and I can use chatgpt well enough to figure out anything I don&amp;#39;t know. &lt;/p&gt;\n\n&lt;p&gt;Typing this out I feel like I&amp;#39;m describing myself more competent than I feel. I have no formal education besides highschool and a boatload of AWS certifications I always have to study my butt off for. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure what the point of this post is, I just kinda needed to rant and get it off my chest to someone and maybe get some outside perspective.&lt;/p&gt;\n\n&lt;p&gt;How do you guys deal with thoughts like these? Do my skills line up with what&amp;#39;s expected of a DE? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd500u", "is_robot_indexable": true, "report_reasons": null, "author": "Jaggedfel2142", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd500u/i_feel_like_such_a_fraud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd500u/i_feel_like_such_a_fraud/", "subreddit_subscribers": 168213, "created_utc": 1710269114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nOne of my colleagues mentioned she knew a data visualization tool that can edit data. By that, she didn\u2019t mean editing calculated field but fields from the source, impacting the source.\nLike you would plug a DB to Tableau and could modify data in Tableau and the data in the DB data would get updated.\nA two way street between the source and the viz.\n\nSounds crazy to me but we live in a crazy world. ", "author_fullname": "t2_8imxqj2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever heard about a data visualization tool that can edit data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcsjmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710233507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;One of my colleagues mentioned she knew a data visualization tool that can edit data. By that, she didn\u2019t mean editing calculated field but fields from the source, impacting the source.\nLike you would plug a DB to Tableau and could modify data in Tableau and the data in the DB data would get updated.\nA two way street between the source and the viz.&lt;/p&gt;\n\n&lt;p&gt;Sounds crazy to me but we live in a crazy world. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcsjmf", "is_robot_indexable": true, "report_reasons": null, "author": "vitodeltoro", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcsjmf/have_you_ever_heard_about_a_data_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcsjmf/have_you_ever_heard_about_a_data_visualization/", "subreddit_subscribers": 168213, "created_utc": 1710233507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen some pretty crazy SQL queries during my time working on data platforms. I've recently been dealing with SQL queries that consists of hundreds of thousands of union statements. \n\nI've also seen the abuse of dbt's ephemeral models which result in megabytes of massive SQL statements that are impossible to debug.\n\nRecently, I've had to create automated functions to translate spark explode -&gt; bigquery, it produces some pretty ugly code.\n\n```SELECT POSEXPLODE(ARRAY(2, 3)), EXPLODE(ARRAY(4, 5, 6)) FROM tbl```\n\nSELECT\n\n  IF(_u.pos = _u_2.pos_2, _u_2.col) AS col,\n\n  IF(_u.pos = _u_2.pos_2, _u_2.pos_2) AS pos_2,\n\n  IF(_u.pos = _u_3.pos_3, _u_3.col_2) AS col_2\n\nFROM tbl\n\nCROSS JOIN UNNEST(SEQUENCE(1, GREATEST(CARDINALITY(ARRAY[2, 3]), CARDINALITY(ARRAY[4, 5, 6])))) AS _u(pos)\n\nCROSS JOIN UNNEST(ARRAY[2, 3]) WITH ORDINALITY AS _u_2(col, pos_2)\n\nCROSS JOIN UNNEST(ARRAY[4, 5, 6]) WITH ORDINALITY AS _u_3(col_2, pos_3)\n\nWHERE\n\n  (\n\n    _u.pos = _u_2.pos_2\n\n    OR (\n\n      _u.pos &gt; CARDINALITY(ARRAY[2, 3]) AND _u_2.pos_2 = CARDINALITY(ARRAY[2, 3])\n\n    )\n\n  )\n\n  AND (\n\n    _u.pos = _u_3.pos_3\n\n    OR (\n\n      _u.pos &gt; CARDINALITY(ARRAY[4, 5, 6]) AND _u_3.pos_3 = CARDINALITY(ARRAY[4, 5, 6])\n\n    )\n\n  )\n\n\nWhat are some of the worst SQL queries you've encountered?", "author_fullname": "t2_56xhg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gnarliest SQL queries you've ever seen?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd32bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710264607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen some pretty crazy SQL queries during my time working on data platforms. I&amp;#39;ve recently been dealing with SQL queries that consists of hundreds of thousands of union statements. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also seen the abuse of dbt&amp;#39;s ephemeral models which result in megabytes of massive SQL statements that are impossible to debug.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve had to create automated functions to translate spark explode -&amp;gt; bigquery, it produces some pretty ugly code.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT POSEXPLODE(ARRAY(2, 3)), EXPLODE(ARRAY(4, 5, 6)) FROM tbl&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;SELECT&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_2.pos_2, _u_2.col) AS col,&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_2.pos_2, _u_2.pos_2) AS pos_2,&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_3.pos_3, _u_3.col_2) AS col_2&lt;/p&gt;\n\n&lt;p&gt;FROM tbl&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(SEQUENCE(1, GREATEST(CARDINALITY(ARRAY[2, 3]), CARDINALITY(ARRAY[4, 5, 6])))) AS _u(pos)&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(ARRAY[2, 3]) WITH ORDINALITY AS _u_2(col, pos_2)&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(ARRAY[4, 5, 6]) WITH ORDINALITY AS _u_3(col_2, pos_3)&lt;/p&gt;\n\n&lt;p&gt;WHERE&lt;/p&gt;\n\n&lt;p&gt;(&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;_u.pos = _u_2.pos_2\n\nOR (\n\n  _u.pos &amp;gt; CARDINALITY(ARRAY[2, 3]) AND _u_2.pos_2 = CARDINALITY(ARRAY[2, 3])\n\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;AND (&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;_u.pos = _u_3.pos_3\n\nOR (\n\n  _u.pos &amp;gt; CARDINALITY(ARRAY[4, 5, 6]) AND _u_3.pos_3 = CARDINALITY(ARRAY[4, 5, 6])\n\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;What are some of the worst SQL queries you&amp;#39;ve encountered?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd32bx", "is_robot_indexable": true, "report_reasons": null, "author": "captaintobs", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd32bx/gnarliest_sql_queries_youve_ever_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd32bx/gnarliest_sql_queries_youve_ever_seen/", "subreddit_subscribers": 168213, "created_utc": 1710264607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I've been into data engineering ever since I graduate from my bachelors in CS in June 2023. So I've gained skills in SQL and experience with Azure. But since I graduated from CS, I was wondering... what would make me stand out from other data engineers having studied CS? Like I did projects related to web development and would say have a decent coding skills. So what would make me a stronger candidate than others? Having a strong knowledge in frontend dev. or backend dev?", "author_fullname": "t2_chpvvtuts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strong Data Engineering Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1geu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710260835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;ve been into data engineering ever since I graduate from my bachelors in CS in June 2023. So I&amp;#39;ve gained skills in SQL and experience with Azure. But since I graduated from CS, I was wondering... what would make me stand out from other data engineers having studied CS? Like I did projects related to web development and would say have a decent coding skills. So what would make me a stronger candidate than others? Having a strong knowledge in frontend dev. or backend dev?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bd1geu", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Pen_1356", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1geu/strong_data_engineering_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd1geu/strong_data_engineering_profile/", "subreddit_subscribers": 168213, "created_utc": 1710260835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since Data Engineers are rare nowadays - relative to more common SE roles. I wonder if there exists a role of a Software QA Engineer for a DE team. If so, what do they do in your company? How do they define the needed test suites for a specific requirement?\n\n", "author_fullname": "t2_85ty6e1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software QA in a Data Engineering Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcv2qo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710243315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since Data Engineers are rare nowadays - relative to more common SE roles. I wonder if there exists a role of a Software QA Engineer for a DE team. If so, what do they do in your company? How do they define the needed test suites for a specific requirement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bcv2qo", "is_robot_indexable": true, "report_reasons": null, "author": "BestBlackberry1314", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcv2qo/software_qa_in_a_data_engineering_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcv2qo/software_qa_in_a_data_engineering_team/", "subreddit_subscribers": 168213, "created_utc": 1710243315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say I\u2019m developing a web app that will get shown on user devices. So the system would look something like this:\n\nUser Device &lt;-&gt; Streamlit Frontend -&gt; FastAPI Logic -&gt; SQLAlchemy Data Access &lt;-&gt; Postgres Data Store\n\nWould this result in:\n\n* Application Layer: Streamlit\n* Business Logic Layer: FastAPI\n* Data Access Layer: SQLAlchemy\n* Data Layer: Postgres\n\nOr am I misunderstanding anything?\n", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making sure I understand the 3 tier architecture\u2026 Is this it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcyqug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710254137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I\u2019m developing a web app that will get shown on user devices. So the system would look something like this:&lt;/p&gt;\n\n&lt;p&gt;User Device &amp;lt;-&amp;gt; Streamlit Frontend -&amp;gt; FastAPI Logic -&amp;gt; SQLAlchemy Data Access &amp;lt;-&amp;gt; Postgres Data Store&lt;/p&gt;\n\n&lt;p&gt;Would this result in:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Application Layer: Streamlit&lt;/li&gt;\n&lt;li&gt;Business Logic Layer: FastAPI&lt;/li&gt;\n&lt;li&gt;Data Access Layer: SQLAlchemy&lt;/li&gt;\n&lt;li&gt;Data Layer: Postgres&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or am I misunderstanding anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcyqug", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcyqug/making_sure_i_understand_the_3_tier_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcyqug/making_sure_i_understand_the_3_tier_architecture/", "subreddit_subscribers": 168213, "created_utc": 1710254137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started to learn Python as a data engineering tool a few months ago. Since I come from a SQL background, I have gained good grasp of Pandas and Airflow pretty fast. Recently I heard about other ETL tools such as bonobo, PygramEtL and Petl. Are they still relevant? I tried to find youtube videos to learn more but most videos are quite old (more than 3 years old). I am not sure if I need to spend my energy learning these tools if they are not used often any more. If you are a data engineer, would you please tell me what python tools are you using? If you are still using bonobo, PygramEtL and Petl, would you please share some use cases? Thanks a lot!", "author_fullname": "t2_9od6j04g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Python for data engineering for finance. Is bonobo, PygramEtL and Petl still relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bddw39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710290645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started to learn Python as a data engineering tool a few months ago. Since I come from a SQL background, I have gained good grasp of Pandas and Airflow pretty fast. Recently I heard about other ETL tools such as bonobo, PygramEtL and Petl. Are they still relevant? I tried to find youtube videos to learn more but most videos are quite old (more than 3 years old). I am not sure if I need to spend my energy learning these tools if they are not used often any more. If you are a data engineer, would you please tell me what python tools are you using? If you are still using bonobo, PygramEtL and Petl, would you please share some use cases? Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bddw39", "is_robot_indexable": true, "report_reasons": null, "author": "Tall-Skin5800", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bddw39/learning_python_for_data_engineering_for_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bddw39/learning_python_for_data_engineering_for_finance/", "subreddit_subscribers": 168213, "created_utc": 1710290645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dagster.io/blog/dagster-openai](https://dagster.io/blog/dagster-openai)\n\nThe new dagster-openai integration lets you tap into the power of LLMs in a cost-efficient way.\n\nhttps://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0", "author_fullname": "t2_c45yywox7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster's Open AI integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ovkzr6rjoxnc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b2b5fa07a548a4241016e5574ec40dd1be9b42fc"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f756c46d79281ac646f745a834f3a2c150d8076"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7db258eb2a117848a241620ec0f31178f8c2ddc3"}, {"y": 336, "x": 640, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5640258c75bab8e6d7e14c3e1199cfefcfa8248f"}, {"y": 504, "x": 960, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09be2968a5be5d97ee06f679bacc7dc22590866d"}, {"y": 567, "x": 1080, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7bf29066b69a4a3ddd9ae43e82b0d4e36b4d3247"}], "s": {"y": 630, "x": 1200, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0"}, "id": "ovkzr6rjoxnc1"}}, "name": "t3_1bd25o2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CwcvahbzbTHlIv2YnRP4yV4EnweUcOGhl7TvGAVfqG0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710262472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dagster.io/blog/dagster-openai\"&gt;https://dagster.io/blog/dagster-openai&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The new dagster-openai integration lets you tap into the power of LLMs in a cost-efficient way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0\"&gt;https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bd25o2", "is_robot_indexable": true, "report_reasons": null, "author": "dagster-io", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd25o2/dagsters_open_ai_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd25o2/dagsters_open_ai_integration/", "subreddit_subscribers": 168213, "created_utc": 1710262472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, Microsoft is offering a free exam voucher for those who complete any of the Microsoft Learn AI Skills Challenges below:\n\n[Build next generation apps with Azure OpenAI](https://learn.microsoft.com/training/challenges?id=da09d3ca-a2bb-47dc-ba42-bea77b386a3d&amp;WT.mc_id=cloudskillschallenge_da09d3ca-a2bb-47dc-ba42-bea77b386a3d) \n\n[Azure AI Fundamentals](https://learn.microsoft.com/training/challenges?id=3ef5d197-cdef-49bc-a8bc-954bcd9e88cc&amp;WT.mc_id=cloudskillschallenge_3ef5d197-cdef-49bc-a8bc-954bcd9e88cc)\n\n[Fabric Analytics Engineer](https://learn.microsoft.com/training/challenges?id=b696c18d-7201-4aff-9c7d-d33014d93b25&amp;WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25)\n\n[Azure Machine Learning](https://learn.microsoft.com/training/challenges?id=764de7ca-8b6d-4b3a-a491-1942af389d8c&amp;WT.mc_id=cloudskillschallenge_764de7ca-8b6d-4b3a-a491-1942af389d8c)\n\nOnce you complete the challenge, you'll be given a free exam voucher which can be used for any of the exams listed below:\n\n[AI-102 Designing and Implementing a Microsoft Azure AI Solution](https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/#certification-exams?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[AI-900 Microsoft Azure AI Fundamentals](https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-900/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[DP-600 Implementing Analytics Solutions Using Microsoft Fabric](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-600/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[DP-100 Designing and Implementing a Data Science Soluition on Azure](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-100/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n&amp;#x200B;\n\nYou can read the links for all other details, you got a month to complete any of the challenges and you will get a voucher for any from the 4 exams listed. It would make more sense if you do the challenge that relates to the exam you plan on sitting for but it is not mandatory. You have to complete the challenge between March 19th and April 19th.\n\nWhich one are you choosing? I am thinking between AI-900 and DP-600.\n\nCheers!", "author_fullname": "t2_7gvgv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Microsoft Exam Vouchers By Completing a Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdhw74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710301781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, Microsoft is offering a free exam voucher for those who complete any of the Microsoft Learn AI Skills Challenges below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=da09d3ca-a2bb-47dc-ba42-bea77b386a3d&amp;amp;WT.mc_id=cloudskillschallenge_da09d3ca-a2bb-47dc-ba42-bea77b386a3d\"&gt;Build next generation apps with Azure OpenAI&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=3ef5d197-cdef-49bc-a8bc-954bcd9e88cc&amp;amp;WT.mc_id=cloudskillschallenge_3ef5d197-cdef-49bc-a8bc-954bcd9e88cc\"&gt;Azure AI Fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=b696c18d-7201-4aff-9c7d-d33014d93b25&amp;amp;WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25\"&gt;Fabric Analytics Engineer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=764de7ca-8b6d-4b3a-a491-1942af389d8c&amp;amp;WT.mc_id=cloudskillschallenge_764de7ca-8b6d-4b3a-a491-1942af389d8c\"&gt;Azure Machine Learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Once you complete the challenge, you&amp;#39;ll be given a free exam voucher which can be used for any of the exams listed below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/#certification-exams?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;AI-102 Designing and Implementing a Microsoft Azure AI Solution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-900/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;AI-900 Microsoft Azure AI Fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-600/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;DP-600 Implementing Analytics Solutions Using Microsoft Fabric&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-100/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;DP-100 Designing and Implementing a Data Science Soluition on Azure&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;You can read the links for all other details, you got a month to complete any of the challenges and you will get a voucher for any from the 4 exams listed. It would make more sense if you do the challenge that relates to the exam you plan on sitting for but it is not mandatory. You have to complete the challenge between March 19th and April 19th.&lt;/p&gt;\n\n&lt;p&gt;Which one are you choosing? I am thinking between AI-900 and DP-600.&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bdhw74", "is_robot_indexable": true, "report_reasons": null, "author": "salihveseli", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdhw74/free_microsoft_exam_vouchers_by_completing_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdhw74/free_microsoft_exam_vouchers_by_completing_a/", "subreddit_subscribers": 168213, "created_utc": 1710301781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2cbhndmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why we rebuilt our streaming SQL engine on Arrow and DataFusion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1ldx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SP7NuGNJCrGyOCFEDJ-ShUTComq-Wx19oDx4gknWiYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710261151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arroyo.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arroyo.dev/blog/why-arrow-and-datafusion", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?auto=webp&amp;s=e7959007dda0dbb9cf030c20ddac353c861c09fa", "width": 2688, "height": 1792}, "resolutions": [{"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7d7d58332e0cbb07dea5da384e001c7d7176f27", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5966c776f1ca2cdcf06a241d07578197870315b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46d58404c44429d0727987e7a25048654edf70e4", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f1ded20f4d4bafc79d841c95bf9467f0c70e1ba", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b9c33cdda23e774d862952924083bd6044c55f42", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73070affd9bbc91c9314dcd1e8f6ed879045e9c8", "width": 1080, "height": 720}], "variants": {}, "id": "UNxPUV_rhw7H5oI0SODFEM6Izqt3u_t6LNuihNml6Jc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bd1ldx", "is_robot_indexable": true, "report_reasons": null, "author": "mwylde_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1ldx/why_we_rebuilt_our_streaming_sql_engine_on_arrow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arroyo.dev/blog/why-arrow-and-datafusion", "subreddit_subscribers": 168213, "created_utc": 1710261151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI've got a master's degree in data and done several internships in data engineering. I'd like to start my career in the same field but I haven't had the opportunity to learn much about certain technologies. Are there any good exercises or projects on Kaggle to learn how to use certain combined technologies like Python, SQL,  ELK, Kafka, Airflow, Spark, terraform, with docker, Bash for example. If there aren't any Kaggle projects or that sort of thing, would there be appropriate datasets for the data sources? Maybe projects using GNS3 for the configuration part or some kind of github repository as a guided project? I don't know. Above all, I'm looking for a project that will enable me to learn or discover all these technologies. I know that a lot of these technologies can work together in a company, so I suppose it's not impossible to get a lot of them involved in this project.\n\nAs I'm considered to have little experience, I'd like to work on all these skills in my own time to see how everything fits together and to know what I'm talking about. I'm prepared to devote a lot of time to it so that I can be deployed more quickly in companies. If you can help me or even give me advice on the technology, for example, that would be really nice. Any feedback is also very welcome.", "author_fullname": "t2_q95335vn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn data engineering in a non-professional context?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1bsf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710260528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a master&amp;#39;s degree in data and done several internships in data engineering. I&amp;#39;d like to start my career in the same field but I haven&amp;#39;t had the opportunity to learn much about certain technologies. Are there any good exercises or projects on Kaggle to learn how to use certain combined technologies like Python, SQL,  ELK, Kafka, Airflow, Spark, terraform, with docker, Bash for example. If there aren&amp;#39;t any Kaggle projects or that sort of thing, would there be appropriate datasets for the data sources? Maybe projects using GNS3 for the configuration part or some kind of github repository as a guided project? I don&amp;#39;t know. Above all, I&amp;#39;m looking for a project that will enable me to learn or discover all these technologies. I know that a lot of these technologies can work together in a company, so I suppose it&amp;#39;s not impossible to get a lot of them involved in this project.&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;m considered to have little experience, I&amp;#39;d like to work on all these skills in my own time to see how everything fits together and to know what I&amp;#39;m talking about. I&amp;#39;m prepared to devote a lot of time to it so that I can be deployed more quickly in companies. If you can help me or even give me advice on the technology, for example, that would be really nice. Any feedback is also very welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd1bsf", "is_robot_indexable": true, "report_reasons": null, "author": "Aquilae2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1bsf/how_to_learn_data_engineering_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd1bsf/how_to_learn_data_engineering_in_a/", "subreddit_subscribers": 168213, "created_utc": 1710260528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm a data engineering consultant specializing in working with startups to develop robust data platforms. Currently, I'm collaborating with a Swedish company whose entire infrastructure is based on Postgres and Django. They've tasked me with either building upon or improving their existing platform to make it more manageable and scalable.\n\nHowever, I've noticed that they heavily rely on Django objects for the ETL process rather than utilizing SQL. As a data engineer, I firmly believe in the effectiveness of SQL/Python Dataframes methodology over Django models for such tasks.\n\nHow do you suggest I approach convincing them of this? Or do you think I might be mistaken in my approach? Open to your insights and suggestions!", "author_fullname": "t2_80ixgpf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Seeking Advice: Convincing a Startup to Embrace SQL/Python Dataframes over Django Models\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdjkaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710307126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineering consultant specializing in working with startups to develop robust data platforms. Currently, I&amp;#39;m collaborating with a Swedish company whose entire infrastructure is based on Postgres and Django. They&amp;#39;ve tasked me with either building upon or improving their existing platform to make it more manageable and scalable.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve noticed that they heavily rely on Django objects for the ETL process rather than utilizing SQL. As a data engineer, I firmly believe in the effectiveness of SQL/Python Dataframes methodology over Django models for such tasks.&lt;/p&gt;\n\n&lt;p&gt;How do you suggest I approach convincing them of this? Or do you think I might be mistaken in my approach? Open to your insights and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdjkaj", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic-Emergency75", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdjkaj/seeking_advice_convincing_a_startup_to_embrace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdjkaj/seeking_advice_convincing_a_startup_to_embrace/", "subreddit_subscribers": 168213, "created_utc": 1710307126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nPlease feel free to stop me in my tracks if I\u2019m going down a bad path. I want to develop my data input forms as webapps with Streamlit. They won\u2019t be dashboards as is typical, but data collection tools. I love the minimal look of Streamlit and it\u2019s quite easy to put out a working product quickly with it. However, that ease makes me concerned a bit- is it safe for deployment?\n\nSome background:\n\nI\u2019ll probably want to deploy several replicas of the application and distribute load among them for high-availability. Perhaps only 2-3 instances is fine though, as this isn\u2019t for high load.\n\nUsers will access the app from remote locations, potentially up to 10-15 at a time. Their internet connection may be poor at best, but if their internet goes out it\u2019s not technically my problem anymore. I\u2019ll just want to make sure (for now) that I can perform well under medium latency.\n\nI\u2019ll launch it was k3s to automate a lot of the infrastructure management. FastAPI will sit between Streamlit and the database.\n\nI guess if nobody knows, I\u2019ll give it a shot and let you guys know how it goes. Can anyone offer some insight ahead of time though?\n\nThanks!", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone deployed Streamlit for some intense workload?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdcdex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710286700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Please feel free to stop me in my tracks if I\u2019m going down a bad path. I want to develop my data input forms as webapps with Streamlit. They won\u2019t be dashboards as is typical, but data collection tools. I love the minimal look of Streamlit and it\u2019s quite easy to put out a working product quickly with it. However, that ease makes me concerned a bit- is it safe for deployment?&lt;/p&gt;\n\n&lt;p&gt;Some background:&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll probably want to deploy several replicas of the application and distribute load among them for high-availability. Perhaps only 2-3 instances is fine though, as this isn\u2019t for high load.&lt;/p&gt;\n\n&lt;p&gt;Users will access the app from remote locations, potentially up to 10-15 at a time. Their internet connection may be poor at best, but if their internet goes out it\u2019s not technically my problem anymore. I\u2019ll just want to make sure (for now) that I can perform well under medium latency.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll launch it was k3s to automate a lot of the infrastructure management. FastAPI will sit between Streamlit and the database.&lt;/p&gt;\n\n&lt;p&gt;I guess if nobody knows, I\u2019ll give it a shot and let you guys know how it goes. Can anyone offer some insight ahead of time though?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdcdex", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdcdex/has_anyone_deployed_streamlit_for_some_intense/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdcdex/has_anyone_deployed_streamlit_for_some_intense/", "subreddit_subscribers": 168213, "created_utc": 1710286700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to stream data from SNS into an iceberg table on S3. However I am a beginner and I feel quite overwhelmed with the amount of possible ways of how to do that.\n\nSNS has around 100 thousand messaged per day (ca. 1/s) which I would like to stream to an Iceberg table. I was thinking Data Firehose however, I think it can not push directly to an iceberg table on S3.   \nDoes it make sense to first put data onto a landingzone in s3 and then run a streaming glue job in spark to stream into the table?   \nFurthermore the problem is that the table should be somewhat up to date (lets say 1 to 5 minutes delay) because customers use it for querys in Athena. However, as the streaming throughput is that small and the table is partitioned for every customer, it leaves me with the small file problem in the table. (the messages about every second can be from different customers)   \nI think running a compaction job every hour could be overkill if you have to do that for hundreds of customers with always just some little files.   \n\n\nI'm thankful for every pointer in the right direction and I can answer more details if I forgot anything as I am still a beginner. ", "author_fullname": "t2_kv5ze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to stream from SNS to Iceberg table on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd7bfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710274558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to stream data from SNS into an iceberg table on S3. However I am a beginner and I feel quite overwhelmed with the amount of possible ways of how to do that.&lt;/p&gt;\n\n&lt;p&gt;SNS has around 100 thousand messaged per day (ca. 1/s) which I would like to stream to an Iceberg table. I was thinking Data Firehose however, I think it can not push directly to an iceberg table on S3.&lt;br/&gt;\nDoes it make sense to first put data onto a landingzone in s3 and then run a streaming glue job in spark to stream into the table?&lt;br/&gt;\nFurthermore the problem is that the table should be somewhat up to date (lets say 1 to 5 minutes delay) because customers use it for querys in Athena. However, as the streaming throughput is that small and the table is partitioned for every customer, it leaves me with the small file problem in the table. (the messages about every second can be from different customers)&lt;br/&gt;\nI think running a compaction job every hour could be overkill if you have to do that for hundreds of customers with always just some little files.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thankful for every pointer in the right direction and I can answer more details if I forgot anything as I am still a beginner. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd7bfo", "is_robot_indexable": true, "report_reasons": null, "author": "Larsimoto", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd7bfo/how_to_stream_from_sns_to_iceberg_table_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd7bfo/how_to_stream_from_sns_to_iceberg_table_on_aws/", "subreddit_subscribers": 168213, "created_utc": 1710274558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have data assets on multiple clouds (sql ds in aws, databricks and adls gen2 in azure), and I want to build data lineages on top of them, is Apache Atlas good tool of choice. \nIf yes please share some resources, that might be helpful. Thanks in advance\ud83d\ude4c\n\nPs. I don\u2019t want to use ms purview ", "author_fullname": "t2_i9p6l5fsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Atlas Review ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcvbdr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710244117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have data assets on multiple clouds (sql ds in aws, databricks and adls gen2 in azure), and I want to build data lineages on top of them, is Apache Atlas good tool of choice. \nIf yes please share some resources, that might be helpful. Thanks in advance\ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;Ps. I don\u2019t want to use ms purview &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcvbdr", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Job9989", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcvbdr/apache_atlas_review/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcvbdr/apache_atlas_review/", "subreddit_subscribers": 168213, "created_utc": 1710244117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I am writing a report comparing the best data modeling tools to propose for the entire company's use. My company has deployed several projects to build Data Lakes and Data Warehouses for large enterprises. \n\nFor previous projects, my data modeling tools were not consistently used. Yesterday, my boss proposed 2 tools he has used: IDERA's E/RStudio and Visual Paradigm. My boss wants me to research and provide a comparison of the pros and cons of these 2 tools, then propose to everyone in the company to agree on one tool to use for upcoming projects. \n\nI would like to ask everyone which tool would be more suitable for which user groups based on your experiences, or where I could research this information further. \n\nAdditionally, I would want  you to suggest me a tool that you frequently use and feel is the best for your own usage needs for me to consider further.\n\nThank you very much!", "author_fullname": "t2_5zdpc9jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best data modeling tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bctnhy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710238032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I am writing a report comparing the best data modeling tools to propose for the entire company&amp;#39;s use. My company has deployed several projects to build Data Lakes and Data Warehouses for large enterprises. &lt;/p&gt;\n\n&lt;p&gt;For previous projects, my data modeling tools were not consistently used. Yesterday, my boss proposed 2 tools he has used: IDERA&amp;#39;s E/RStudio and Visual Paradigm. My boss wants me to research and provide a comparison of the pros and cons of these 2 tools, then propose to everyone in the company to agree on one tool to use for upcoming projects. &lt;/p&gt;\n\n&lt;p&gt;I would like to ask everyone which tool would be more suitable for which user groups based on your experiences, or where I could research this information further. &lt;/p&gt;\n\n&lt;p&gt;Additionally, I would want  you to suggest me a tool that you frequently use and feel is the best for your own usage needs for me to consider further.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bctnhy", "is_robot_indexable": true, "report_reasons": null, "author": "Public_Depth_532", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bctnhy/best_data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bctnhy/best_data_modeling_tool/", "subreddit_subscribers": 168213, "created_utc": 1710238032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone know of a service that cleans up addresses not only of USA but also other countries. ", "author_fullname": "t2_b7d1hftq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data cleanup for USA addresses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdcmb1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710287334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone know of a service that cleans up addresses not only of USA but also other countries. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdcmb1", "is_robot_indexable": true, "report_reasons": null, "author": "LesTabBlue", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdcmb1/data_cleanup_for_usa_addresses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdcmb1/data_cleanup_for_usa_addresses/", "subreddit_subscribers": 168213, "created_utc": 1710287334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nThe company I work at is currently in a system transition. We are transferring to a low code solution (CMiC) that seemingly offers little to no API support.\n\nAfter transitioning systems, the company plans on integrating data visualization software to help supplement the short-comings of the system selected. CMiC offers some data visualization capabilities, but it does not come close to full fledged data viz softwares available. It does have the capability to output tabular data, so I\u2019m thinking it will be a limited ETL process if I design the standard reports appropriately. \n\nCompany would include 20+ business users that would need access to these reports. \n\nNumber of rows can be expected to be 10,000+. \n\nMy question is: Would Power BI or Tableau be a better solution for this situation? With the limited capabilities to export data, I\u2019m thinking it would be a better solution to use Power BI since it seems like we\u2019ll have to manually export the reports anyway. \n\nPlease let me know if this is the wrong sub and I\u2019ll happily report to another. Thanks!", "author_fullname": "t2_h3u82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ERP System to Data Visualization Tool ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdbeqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710284320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;The company I work at is currently in a system transition. We are transferring to a low code solution (CMiC) that seemingly offers little to no API support.&lt;/p&gt;\n\n&lt;p&gt;After transitioning systems, the company plans on integrating data visualization software to help supplement the short-comings of the system selected. CMiC offers some data visualization capabilities, but it does not come close to full fledged data viz softwares available. It does have the capability to output tabular data, so I\u2019m thinking it will be a limited ETL process if I design the standard reports appropriately. &lt;/p&gt;\n\n&lt;p&gt;Company would include 20+ business users that would need access to these reports. &lt;/p&gt;\n\n&lt;p&gt;Number of rows can be expected to be 10,000+. &lt;/p&gt;\n\n&lt;p&gt;My question is: Would Power BI or Tableau be a better solution for this situation? With the limited capabilities to export data, I\u2019m thinking it would be a better solution to use Power BI since it seems like we\u2019ll have to manually export the reports anyway. &lt;/p&gt;\n\n&lt;p&gt;Please let me know if this is the wrong sub and I\u2019ll happily report to another. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdbeqc", "is_robot_indexable": true, "report_reasons": null, "author": "oimgoingin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdbeqc/erp_system_to_data_visualization_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdbeqc/erp_system_to_data_visualization_tool/", "subreddit_subscribers": 168213, "created_utc": 1710284320.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on building a stitched-together ERP system, where I want actions taken and data created/received in one piece of software be reflected in the other ones. (Ex: make a purchase order in one piece of software =&gt; can see same purchase order in another). Most data pipeline and integration services I've seen have syncs on a daily basis or some other time-frame, they aren't event driven. Anyone have recommendations for something like this?", "author_fullname": "t2_9cov0jfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for Multidirectional Real-Time Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdaodb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710282499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on building a stitched-together ERP system, where I want actions taken and data created/received in one piece of software be reflected in the other ones. (Ex: make a purchase order in one piece of software =&amp;gt; can see same purchase order in another). Most data pipeline and integration services I&amp;#39;ve seen have syncs on a daily basis or some other time-frame, they aren&amp;#39;t event driven. Anyone have recommendations for something like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdaodb", "is_robot_indexable": true, "report_reasons": null, "author": "LongjumpingDebate959", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdaodb/recommendations_for_multidirectional_realtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdaodb/recommendations_for_multidirectional_realtime/", "subreddit_subscribers": 168213, "created_utc": 1710282499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which one is better? \n\nConsider below points:\n-more read operation vs write operation \n-due to late arriving data, we may have to update some of the transactions or table partitions. \n-schema evolution; e.g. int to bigint, new columns being added in the table. \n-rollback to previous states when something goes wrong during data processing \n-storage optimisation \n\nI would love to know how you guys are using it in production? Highlight some major disadvantages in both of cases. ", "author_fullname": "t2_amg2wh1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg vs Delta table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdah3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710282012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one is better? &lt;/p&gt;\n\n&lt;p&gt;Consider below points:\n-more read operation vs write operation \n-due to late arriving data, we may have to update some of the transactions or table partitions. \n-schema evolution; e.g. int to bigint, new columns being added in the table. \n-rollback to previous states when something goes wrong during data processing \n-storage optimisation &lt;/p&gt;\n\n&lt;p&gt;I would love to know how you guys are using it in production? Highlight some major disadvantages in both of cases. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdah3x", "is_robot_indexable": true, "report_reasons": null, "author": "andalibansari", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdah3x/iceberg_vs_delta_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdah3x/iceberg_vs_delta_table/", "subreddit_subscribers": 168213, "created_utc": 1710282012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We run different batch jobs via Qubole/Airflow setup which run at different cadences for different sources. We also have a datadog integration available for observability.   \nFor eg, there will be a pipeline which is running every 3 hours and then there will be one which is running once every 24 hours.   \n\n\nI need to map the data delay that the upstream is having. For eg, if I am expecting the upstream to update their data by 11am PST, but the data is delayed and arrives at 11:30am PST. I will run my ETL/batch process after 11:30am. Need to track this 30 minute delay on datadog.   \n\n\nWhat is the best way of doing it?", "author_fullname": "t2_bjtd8b2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help mapping freshness as a metric for upstream data sources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd8k71", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710277518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We run different batch jobs via Qubole/Airflow setup which run at different cadences for different sources. We also have a datadog integration available for observability.&lt;br/&gt;\nFor eg, there will be a pipeline which is running every 3 hours and then there will be one which is running once every 24 hours.   &lt;/p&gt;\n\n&lt;p&gt;I need to map the data delay that the upstream is having. For eg, if I am expecting the upstream to update their data by 11am PST, but the data is delayed and arrives at 11:30am PST. I will run my ETL/batch process after 11:30am. Need to track this 30 minute delay on datadog.   &lt;/p&gt;\n\n&lt;p&gt;What is the best way of doing it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd8k71", "is_robot_indexable": true, "report_reasons": null, "author": "whiteclay9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd8k71/need_help_mapping_freshness_as_a_metric_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd8k71/need_help_mapping_freshness_as_a_metric_for/", "subreddit_subscribers": 168213, "created_utc": 1710277518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Folks,\n\nI currently need a solution for a particular scenario. I Have three jobs to run the pipeline(assume they are set up using Data bricks workflow). Now I want the first job (1) to produce a unique key and pass that one to the next job(2) which will pass to the next job(3). When this workflow runs again the key generated should be different compared to the previous one.  \n\n\nThis is for databricks\n\nAny Ideas!!\n\nThanks.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help need to with passing a unique key in a workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd6tif", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710273387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,&lt;/p&gt;\n\n&lt;p&gt;I currently need a solution for a particular scenario. I Have three jobs to run the pipeline(assume they are set up using Data bricks workflow). Now I want the first job (1) to produce a unique key and pass that one to the next job(2) which will pass to the next job(3). When this workflow runs again the key generated should be different compared to the previous one.  &lt;/p&gt;\n\n&lt;p&gt;This is for databricks&lt;/p&gt;\n\n&lt;p&gt;Any Ideas!!&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd6tif", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd6tif/help_need_to_with_passing_a_unique_key_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd6tif/help_need_to_with_passing_a_unique_key_in_a/", "subreddit_subscribers": 168213, "created_utc": 1710273387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've recently purchased Mozart, which includes Fivetran for data connectors, then brings everything into a Snowflake DB. From there, we connect Tableau to Snowflake for dashboards. \n\nBy no means am I a data engineering expert, so there's likely a miss on my side (and hopefully an easy solution), but I'm currently unable to find a single way to bring in GA4 data that contains dimensions for date, source, medium, campaign and page title, then the metric of sessions. Ideally, we'd have a bit more than that (events, conversions, views, engaged sessions, etc.), but I'd be happy with that as a starting point. \n\nFrom what I've seen, there's no page title available at all within any of the tables from Fivetran's connector, and I can't get any of the data to align with what we see in GA4. \n\n&amp;#x200B;\n\nIs this a known issue? Are there areas to explore that I may be overlooking?", "author_fullname": "t2_5c8pfg87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran and GA4 Data... useless?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd5pwp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710270742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve recently purchased Mozart, which includes Fivetran for data connectors, then brings everything into a Snowflake DB. From there, we connect Tableau to Snowflake for dashboards. &lt;/p&gt;\n\n&lt;p&gt;By no means am I a data engineering expert, so there&amp;#39;s likely a miss on my side (and hopefully an easy solution), but I&amp;#39;m currently unable to find a single way to bring in GA4 data that contains dimensions for date, source, medium, campaign and page title, then the metric of sessions. Ideally, we&amp;#39;d have a bit more than that (events, conversions, views, engaged sessions, etc.), but I&amp;#39;d be happy with that as a starting point. &lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve seen, there&amp;#39;s no page title available at all within any of the tables from Fivetran&amp;#39;s connector, and I can&amp;#39;t get any of the data to align with what we see in GA4. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this a known issue? Are there areas to explore that I may be overlooking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd5pwp", "is_robot_indexable": true, "report_reasons": null, "author": "MJCowpa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd5pwp/fivetran_and_ga4_data_useless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd5pwp/fivetran_and_ga4_data_useless/", "subreddit_subscribers": 168213, "created_utc": 1710270742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just want to learn more about how to monitor pipelines in a more efficient way and what tools I can use to set alerts.\n\n", "author_fullname": "t2_61uvorko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any resources for monitoring and alerting? What tools do you use? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd2389", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710262318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just want to learn more about how to monitor pipelines in a more efficient way and what tools I can use to set alerts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd2389", "is_robot_indexable": true, "report_reasons": null, "author": "jadedsprint", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd2389/any_resources_for_monitoring_and_alerting_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd2389/any_resources_for_monitoring_and_alerting_what/", "subreddit_subscribers": 168213, "created_utc": 1710262318.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}