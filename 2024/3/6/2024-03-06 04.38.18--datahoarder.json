{"kind": "Listing", "data": {"after": "t3_1b70eij", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nLong time lurker, first time posted in this subreddit. I currently have a bunch of DVDs and Blurays. I was watching a video ([https://youtu.be/xA9Xq7hb6Q0](https://youtu.be/xA9Xq7hb6Q0)) where he talks about life expectancy for storage. This made me worry a bit about the DVDs and Blurays I have. I would like to preserve the content as long as I can, as streaming services keep getting pricier. Is converting these into MKV with MakeMKV and keep moving them from drive to drive the way to go? My goal for the future is to essentially have a NAS that can hold all of it.\n\nTangential question: If I wanted it in a disk form for longer term, is exporting the full disk items, converting it to an ISO, and then \"flashing it\" to a M-DISC the best way for this?", "author_fullname": "t2_qfy2y98e1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to preserve DVD/Bly-Ray media as long as possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7ecai", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709667500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Long time lurker, first time posted in this subreddit. I currently have a bunch of DVDs and Blurays. I was watching a video (&lt;a href=\"https://youtu.be/xA9Xq7hb6Q0\"&gt;https://youtu.be/xA9Xq7hb6Q0&lt;/a&gt;) where he talks about life expectancy for storage. This made me worry a bit about the DVDs and Blurays I have. I would like to preserve the content as long as I can, as streaming services keep getting pricier. Is converting these into MKV with MakeMKV and keep moving them from drive to drive the way to go? My goal for the future is to essentially have a NAS that can hold all of it.&lt;/p&gt;\n\n&lt;p&gt;Tangential question: If I wanted it in a disk form for longer term, is exporting the full disk items, converting it to an ISO, and then &amp;quot;flashing it&amp;quot; to a M-DISC the best way for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/388RYXejWZq3ec4w7sEojJ1jec-383rmFwT553Esu5o.jpg?auto=webp&amp;s=2d51b297d3948118df0d37297ccde5e4538bf20c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/388RYXejWZq3ec4w7sEojJ1jec-383rmFwT553Esu5o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3aea2c56a5853ebb03a9c8b593ca53eba163295e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/388RYXejWZq3ec4w7sEojJ1jec-383rmFwT553Esu5o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9075a334005a91cf6cf247ff7d9c14080d76ce3a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/388RYXejWZq3ec4w7sEojJ1jec-383rmFwT553Esu5o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=75c2e1d31bc3adaccd9ab1f3bfd8c8d6f904f904", "width": 320, "height": 240}], "variants": {}, "id": "__mzULFT7h1UTg5sKKQExNpAqGNYf0AJNsLFpk_Jzhw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7ecai", "is_robot_indexable": true, "report_reasons": null, "author": "Delegator0765", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7ecai/how_to_preserve_dvdblyray_media_as_long_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7ecai/how_to_preserve_dvdblyray_media_as_long_as/", "subreddit_subscribers": 736448, "created_utc": 1709667500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm a photo/video shooter with 25 years of images and videos building up.  Despite all the incredible advances in storage, it's still a costly and complicated proposition just to keep everything safe, and there's a lot of hidden cost (like replacing drives every few years) that can really bite you.  And once you get to 30TB, it seems like you're in between consumer and enterprise solutions (especially for cloud storage) - sort of a storage no-mans-land.   I currently use a Pegasus2 5 drive raid as my primary storage, with various external HDDs for backup, and a backblaze account in the cloud.  The problem is that I'm outgrowing that storage (5x8TB at raid 6=24TB storage).  One possibility is to get 2 Glyph 40TB raid 0 (one primary, one backup) - another would be to go to raid 5 on my Pegasus and do a single glyph as a backup.  I know there is a  higher failure rate with raid 0, so I'm not sure if the glyph makes sense as a backup drive?  Would buying two 16TB drives and backing 1/2 of my raid to each make more sense?  I'm also going to run into higher rates with backblaze, but I don't see a way around that.  One other thing - I have some data that's on 2 drives that aren't spun up - how often do I transfer that data to new drives?   Thanks for any and all advice!", "author_fullname": "t2_w7is6oa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting past 30TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7by3y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709661905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a photo/video shooter with 25 years of images and videos building up.  Despite all the incredible advances in storage, it&amp;#39;s still a costly and complicated proposition just to keep everything safe, and there&amp;#39;s a lot of hidden cost (like replacing drives every few years) that can really bite you.  And once you get to 30TB, it seems like you&amp;#39;re in between consumer and enterprise solutions (especially for cloud storage) - sort of a storage no-mans-land.   I currently use a Pegasus2 5 drive raid as my primary storage, with various external HDDs for backup, and a backblaze account in the cloud.  The problem is that I&amp;#39;m outgrowing that storage (5x8TB at raid 6=24TB storage).  One possibility is to get 2 Glyph 40TB raid 0 (one primary, one backup) - another would be to go to raid 5 on my Pegasus and do a single glyph as a backup.  I know there is a  higher failure rate with raid 0, so I&amp;#39;m not sure if the glyph makes sense as a backup drive?  Would buying two 16TB drives and backing 1/2 of my raid to each make more sense?  I&amp;#39;m also going to run into higher rates with backblaze, but I don&amp;#39;t see a way around that.  One other thing - I have some data that&amp;#39;s on 2 drives that aren&amp;#39;t spun up - how often do I transfer that data to new drives?   Thanks for any and all advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7by3y", "is_robot_indexable": true, "report_reasons": null, "author": "lyrebird2", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7by3y/getting_past_30tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7by3y/getting_past_30tb/", "subreddit_subscribers": 736448, "created_utc": 1709661905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to correctly archive Yuzu and Citra repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6zezr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_tm28o939", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Kh5Kr_1kcKpym7Cvqt_CVhCKfiMJaN3kgcNVoasl9p8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "yuzu", "selftext": "The #citra and #yuzu repositories have been deleted by #Nintendo. Those who have a repository of them follow these steps to be able to share it:\n\nTo archive a repository correctly, it can be done in several ways.\n\n\n\n1. Zip the whole repo and upload it to [archive.org](https://archive.org)\n\n\n2. Add a new remote\n\ncd yuzu-folder \ngit remote add (RemoteName [can be anything]) git@{NewRepoURL} \ngit push --all {RemoteName}\n\n\n3. Making a .bundle and upload it to [archive.org](https://archive.org)\n\n\n\nWith any way all the branches and commits of the repository that you are archiving will be saved.\n\nLong life to emulators and open source!", "author_fullname": "t2_tm28o939", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to correctly archive Yuzu and Citra repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/yuzu", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6q3d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Kh5Kr_1kcKpym7Cvqt_CVhCKfiMJaN3kgcNVoasl9p8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1709595700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The #citra and #yuzu repositories have been deleted by #Nintendo. Those who have a repository of them follow these steps to be able to share it:&lt;/p&gt;\n\n&lt;p&gt;To archive a repository correctly, it can be done in several ways.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Zip the whole repo and upload it to &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Add a new remote&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;cd yuzu-folder \ngit remote add (RemoteName [can be anything]) git@{NewRepoURL} \ngit push --all {RemoteName}&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Making a .bundle and upload it to &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;With any way all the branches and commits of the repository that you are archiving will be saved.&lt;/p&gt;\n\n&lt;p&gt;Long life to emulators and open source!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wn5axz0rlemc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?auto=webp&amp;s=5cd9e21349cf2b0651620498def83fc02e70cc44", "width": 753, "height": 471}, "resolutions": [{"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=71e8dbd0d0d1393ce73d3746e89ec83f556a3fbd", "width": 108, "height": 67}, {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=870aab91e3e3f23b7126fe05232da2e1997e35fc", "width": 216, "height": 135}, {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89bba54b934bcde5786fbe9e1c7f6bbb3abfcc96", "width": 320, "height": 200}, {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b1c51ce4e6b9294372fb4d6e1b5f05bdcdfbdd4", "width": 640, "height": 400}], "variants": {}, "id": "Q8NF3mFw3RljBEoGiQGte_xlsPSKmal9A1vhIFNM1Qs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_39i9t", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1b6q3d6", "is_robot_indexable": true, "report_reasons": null, "author": "PGSCOM", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/yuzu/comments/1b6q3d6/how_to_correctly_archive_yuzu_and_citra/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wn5axz0rlemc1.jpeg", "subreddit_subscribers": 87754, "created_utc": 1709595700.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1709623265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wn5axz0rlemc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?auto=webp&amp;s=5cd9e21349cf2b0651620498def83fc02e70cc44", "width": 753, "height": 471}, "resolutions": [{"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=71e8dbd0d0d1393ce73d3746e89ec83f556a3fbd", "width": 108, "height": 67}, {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=870aab91e3e3f23b7126fe05232da2e1997e35fc", "width": 216, "height": 135}, {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89bba54b934bcde5786fbe9e1c7f6bbb3abfcc96", "width": 320, "height": 200}, {"url": "https://preview.redd.it/wn5axz0rlemc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b1c51ce4e6b9294372fb4d6e1b5f05bdcdfbdd4", "width": 640, "height": 400}], "variants": {}, "id": "Q8NF3mFw3RljBEoGiQGte_xlsPSKmal9A1vhIFNM1Qs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6zezr", "is_robot_indexable": true, "report_reasons": null, "author": "PGSCOM", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1b6q3d6", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6zezr/how_to_correctly_archive_yuzu_and_citra/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wn5axz0rlemc1.jpeg", "subreddit_subscribers": 736448, "created_utc": 1709623265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am converting my DVD collection to several hard drives. I had three DVD burners hooked up to my computer then they all fried. Still not sure why. So I set out looking for a better solution. I bought a used DiscMakers Reflex for $150. It has 7 drives but I am not going to use the control board. My plan was to just use the case as housing and connect all the DVD drives to a port multiplier and connect that to my PC. Problem is I failed to check what kind of interface the drives were. I stupidly assumed from the pictures that this machine was relatively newer. I opened up the case and lo and behold they are all Pata IDE interfaces. I know I can buy Pata to Sata adapters but I don't want to miss a step and nothing works with my PC because of some incompatibility. \n\nIn your professional opinions what, if any, is the best way to connect 7 PATA/IDE drives to my PC? Or did I just buy a $150 brick?\n\nPlease let me know what information you need. Thanks", "author_fullname": "t2_rx4i3ka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bought a duplicator to turn into a burner tower.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7gez1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709672388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am converting my DVD collection to several hard drives. I had three DVD burners hooked up to my computer then they all fried. Still not sure why. So I set out looking for a better solution. I bought a used DiscMakers Reflex for $150. It has 7 drives but I am not going to use the control board. My plan was to just use the case as housing and connect all the DVD drives to a port multiplier and connect that to my PC. Problem is I failed to check what kind of interface the drives were. I stupidly assumed from the pictures that this machine was relatively newer. I opened up the case and lo and behold they are all Pata IDE interfaces. I know I can buy Pata to Sata adapters but I don&amp;#39;t want to miss a step and nothing works with my PC because of some incompatibility. &lt;/p&gt;\n\n&lt;p&gt;In your professional opinions what, if any, is the best way to connect 7 PATA/IDE drives to my PC? Or did I just buy a $150 brick?&lt;/p&gt;\n\n&lt;p&gt;Please let me know what information you need. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7gez1", "is_robot_indexable": true, "report_reasons": null, "author": "Phedis", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7gez1/bought_a_duplicator_to_turn_into_a_burner_tower/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7gez1/bought_a_duplicator_to_turn_into_a_burner_tower/", "subreddit_subscribers": 736448, "created_utc": 1709672388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do I do a cold storage effectively? Trying the 321(?) I think that\u2019s what it\u2019s called for backup purposes \n\n", "author_fullname": "t2_25gmsdyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do cold storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b73dmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709639416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do I do a cold storage effectively? Trying the 321(?) I think that\u2019s what it\u2019s called for backup purposes &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b73dmi", "is_robot_indexable": true, "report_reasons": null, "author": "Feeya_b", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b73dmi/how_to_do_cold_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b73dmi/how_to_do_cold_storage/", "subreddit_subscribers": 736448, "created_utc": 1709639416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI have list of let's say 100 links that I want to download form google drive, size up to 4GB per one link.\n\nI tried using JDownloader and even hacking at it with python, but I can't download them en-masse.\n\nAny way of going around this?", "author_fullname": "t2_44sdgiue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mass downloading from Google Drive links?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7dum3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709666337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have list of let&amp;#39;s say 100 links that I want to download form google drive, size up to 4GB per one link.&lt;/p&gt;\n\n&lt;p&gt;I tried using JDownloader and even hacking at it with python, but I can&amp;#39;t download them en-masse.&lt;/p&gt;\n\n&lt;p&gt;Any way of going around this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b7dum3", "is_robot_indexable": true, "report_reasons": null, "author": "ASatyros", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b7dum3/mass_downloading_from_google_drive_links/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7dum3/mass_downloading_from_google_drive_links/", "subreddit_subscribers": 736448, "created_utc": 1709666337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If I have the nas with the drives inside, inside the nas original packaging and I'm the one transporting them via car ride, will they be safe to do so? Or should I use the drives original antistatic bags and black caps and boxes to transport them?\n\nI will be the only one handling them and the worst thing that I worry about is the car rides vibration getting to the car seat where the drives will be. It will be a 3 day trip.", "author_fullname": "t2_57pge7h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transporting NAS bay woth drives inside via car trip", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7ne7m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709689867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I have the nas with the drives inside, inside the nas original packaging and I&amp;#39;m the one transporting them via car ride, will they be safe to do so? Or should I use the drives original antistatic bags and black caps and boxes to transport them?&lt;/p&gt;\n\n&lt;p&gt;I will be the only one handling them and the worst thing that I worry about is the car rides vibration getting to the car seat where the drives will be. It will be a 3 day trip.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7ne7m", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic_Bookkeeper", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7ne7m/transporting_nas_bay_woth_drives_inside_via_car/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7ne7m/transporting_nas_bay_woth_drives_inside_via_car/", "subreddit_subscribers": 736448, "created_utc": 1709689867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't mean how it finds and moves the tape to the drive, but how does it know where the files are on which tape?\n\nDoes it store an index on its own internal storage? Does it keep track of where the tape stopped?\n\nOr doesn't it do any of that and when you have one you just send a command to \"read tape 4 until file G is found\"?\n\nTape has been an interest to me and a while back I read heavily into it, but I don't ever recall reading about this. Perhaps I'm not searching the correct words either.", "author_fullname": "t2_16u0wi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do tape autoloaders work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b71hke", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709632012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t mean how it finds and moves the tape to the drive, but how does it know where the files are on which tape?&lt;/p&gt;\n\n&lt;p&gt;Does it store an index on its own internal storage? Does it keep track of where the tape stopped?&lt;/p&gt;\n\n&lt;p&gt;Or doesn&amp;#39;t it do any of that and when you have one you just send a command to &amp;quot;read tape 4 until file G is found&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Tape has been an interest to me and a while back I read heavily into it, but I don&amp;#39;t ever recall reading about this. Perhaps I&amp;#39;m not searching the correct words either.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "140 TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b71hke", "is_robot_indexable": true, "report_reasons": null, "author": "TheGleanerBaldwin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b71hke/how_do_tape_autoloaders_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b71hke/how_do_tape_autoloaders_work/", "subreddit_subscribers": 736448, "created_utc": 1709632012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can a JBOD be shared across 2 hosts? It has a dual port 8644 expander and the two servers I have both have a 9300-8e. I was thinking maybe slicing the disks up across hosts? \n\nIf that is possible then coudl I add an expander to a server that has 15 internal disks. Use the 9300-16i to bridge to the internal expander miniSAS internally, on the card, then use the expander to attach the 15 internal drives. Then I could also use the other servers 9300-8e card to plug into the expander on this host, and get access to those internal drives as well if needed.   \n\n\nNot sure I want to do any of this, but curious though. ", "author_fullname": "t2_vsbo9omx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Couple HBA Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b7otgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709693830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can a JBOD be shared across 2 hosts? It has a dual port 8644 expander and the two servers I have both have a 9300-8e. I was thinking maybe slicing the disks up across hosts? &lt;/p&gt;\n\n&lt;p&gt;If that is possible then coudl I add an expander to a server that has 15 internal disks. Use the 9300-16i to bridge to the internal expander miniSAS internally, on the card, then use the expander to attach the 15 internal drives. Then I could also use the other servers 9300-8e card to plug into the expander on this host, and get access to those internal drives as well if needed.   &lt;/p&gt;\n\n&lt;p&gt;Not sure I want to do any of this, but curious though. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7otgn", "is_robot_indexable": true, "report_reasons": null, "author": "Kltpzyxmm", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7otgn/couple_hba_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7otgn/couple_hba_questions/", "subreddit_subscribers": 736448, "created_utc": 1709693830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Last year I bought two 18T Seagate Exos X20 drives to be used as backups, to be used with one of those small toaster-like external drive docks. I used them successfully in the device multiple times over several months. Today, after they had been sitting idle in the device for about a month, I fired them back up and Windows could not read the directory and said they both needed to be formatted. I can hear the computer spinning the drives up, but it cannot read them.\n\nI put them both in another external dock and got the same indication. I put in another backup drive (a 3 TB WD from 2016) and it read successfully.\n\nHow could both drives become unreadable SIMULTANEOUSLY while sitting idle? Is there a remedy or some other way to try to access the drives?\n\nI am beginning to get completely bummed out with simple external storage.\n\nEDIT: Not sure if it matters, but the docks are USB.", "author_fullname": "t2_sfdbj79i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can two drives suddenly and simultaneously become unreadable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7n0xc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709688839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last year I bought two 18T Seagate Exos X20 drives to be used as backups, to be used with one of those small toaster-like external drive docks. I used them successfully in the device multiple times over several months. Today, after they had been sitting idle in the device for about a month, I fired them back up and Windows could not read the directory and said they both needed to be formatted. I can hear the computer spinning the drives up, but it cannot read them.&lt;/p&gt;\n\n&lt;p&gt;I put them both in another external dock and got the same indication. I put in another backup drive (a 3 TB WD from 2016) and it read successfully.&lt;/p&gt;\n\n&lt;p&gt;How could both drives become unreadable SIMULTANEOUSLY while sitting idle? Is there a remedy or some other way to try to access the drives?&lt;/p&gt;\n\n&lt;p&gt;I am beginning to get completely bummed out with simple external storage.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Not sure if it matters, but the docks are USB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7n0xc", "is_robot_indexable": true, "report_reasons": null, "author": "thumperRal", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7n0xc/can_two_drives_suddenly_and_simultaneously_become/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7n0xc/can_two_drives_suddenly_and_simultaneously_become/", "subreddit_subscribers": 736448, "created_utc": 1709688839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Right now I face the problem, that my current PC (2x1TB M2 SSD, Ubuntu 22.04 LTS) is running out of space. I do not have a real backup solution right now besides encrypting and uploading important files to the cloud. \n\nAnyway, I am planing to build an Unraid system later this year, but I need more space now and to invest in components and HDDs is just a little too much for me right now. To solve the storage problem my plan is to buy an HDD now and transfer the drive into the Unraid system later on.\n\nI was thinking about buying the Seagate IronWolf NAS 8TB ST8000VN004.\n\nShould I buy 2 of these drives, install them into my PC and mirror them,  or is there a good software solution for a decent backup with just one 8TB Drive?\n\nAlso can I just transfer the HDD into the Unraid later on or can this be problematic?", "author_fullname": "t2_bp3qppz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buying HDD now, building NAS later", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b78ir4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709653926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now I face the problem, that my current PC (2x1TB M2 SSD, Ubuntu 22.04 LTS) is running out of space. I do not have a real backup solution right now besides encrypting and uploading important files to the cloud. &lt;/p&gt;\n\n&lt;p&gt;Anyway, I am planing to build an Unraid system later this year, but I need more space now and to invest in components and HDDs is just a little too much for me right now. To solve the storage problem my plan is to buy an HDD now and transfer the drive into the Unraid system later on.&lt;/p&gt;\n\n&lt;p&gt;I was thinking about buying the Seagate IronWolf NAS 8TB ST8000VN004.&lt;/p&gt;\n\n&lt;p&gt;Should I buy 2 of these drives, install them into my PC and mirror them,  or is there a good software solution for a decent backup with just one 8TB Drive?&lt;/p&gt;\n\n&lt;p&gt;Also can I just transfer the HDD into the Unraid later on or can this be problematic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b78ir4", "is_robot_indexable": true, "report_reasons": null, "author": "Zswole", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b78ir4/buying_hdd_now_building_nas_later/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b78ir4/buying_hdd_now_building_nas_later/", "subreddit_subscribers": 736448, "created_utc": 1709653926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a photo storage option that meets these requirements:\n\n\\- Has a functional app for iOS (phone and iPad) and an app for Windows or web interface to upload/ organize\n\n\\- Allows for keyword tagging of photos to aid in searching\n\n\\- Decent face recognition/ AI and ability to tag people even if the AI doesn't pick up a face\n\n\\- Nice to have, not required - \"stacking\" or grouping of the same photo in JPEG and RAW so every photo isn't duplicated in the app/view.\n\nI was going to use Amazon Photos as it's unlimited and free with Prime which I already have, but I can't seem to figure out any way to tag photos with key words and the auto-tagging so far is awful (e.g., searching \"dog\" returns pictures of cats). The face recognition so far isn't great either and I can't figure out how to manually tag someone if a face isn't detected. Any experience using Amazon Photos and if the above is possible but I'm not seeing it?\n\nI can't really use iCloud for photo storage as my mobile is through work and they disable photo sync with iCloud, so that option is probably out.\n\nIs Google Photos materially better than Amazon Photos and does it have the capability I'm looking for? Are there any other options? What about an app with these features that works with storage providers? I saw this Photos+ app but not sure if the features match what I'm looking for.\n\n&amp;#x200B;", "author_fullname": "t2_jks02", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for photo storage with certain requirements?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b76qsu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709660053.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709649562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a photo storage option that meets these requirements:&lt;/p&gt;\n\n&lt;p&gt;- Has a functional app for iOS (phone and iPad) and an app for Windows or web interface to upload/ organize&lt;/p&gt;\n\n&lt;p&gt;- Allows for keyword tagging of photos to aid in searching&lt;/p&gt;\n\n&lt;p&gt;- Decent face recognition/ AI and ability to tag people even if the AI doesn&amp;#39;t pick up a face&lt;/p&gt;\n\n&lt;p&gt;- Nice to have, not required - &amp;quot;stacking&amp;quot; or grouping of the same photo in JPEG and RAW so every photo isn&amp;#39;t duplicated in the app/view.&lt;/p&gt;\n\n&lt;p&gt;I was going to use Amazon Photos as it&amp;#39;s unlimited and free with Prime which I already have, but I can&amp;#39;t seem to figure out any way to tag photos with key words and the auto-tagging so far is awful (e.g., searching &amp;quot;dog&amp;quot; returns pictures of cats). The face recognition so far isn&amp;#39;t great either and I can&amp;#39;t figure out how to manually tag someone if a face isn&amp;#39;t detected. Any experience using Amazon Photos and if the above is possible but I&amp;#39;m not seeing it?&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t really use iCloud for photo storage as my mobile is through work and they disable photo sync with iCloud, so that option is probably out.&lt;/p&gt;\n\n&lt;p&gt;Is Google Photos materially better than Amazon Photos and does it have the capability I&amp;#39;m looking for? Are there any other options? What about an app with these features that works with storage providers? I saw this Photos+ app but not sure if the features match what I&amp;#39;m looking for.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b76qsu", "is_robot_indexable": true, "report_reasons": null, "author": "j-rad4", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b76qsu/recommendations_for_photo_storage_with_certain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b76qsu/recommendations_for_photo_storage_with_certain/", "subreddit_subscribers": 736448, "created_utc": 1709649562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I hope this is the right place to ask this question. If not, my apologies. Also, I'm currently at work and can provide more specific information later in the day.\n\nI have a 90TB Plex server running off of 5 HDDs; 4 are Seagate Exos and the other is a WD shucked drive. Everything ran incredibly smooth before moving over to the DrivePool, having them all as individual drives. I was able to DirectPlay and Transcode 4K Remuxes without issue. I was tired of having 5 different drives and read about DrivePool and thought it met my needs. I set it up without issue and moved everything to the new drive....but now EVERYTHING struggles to be read/written to the drive.\n\nI've ran CrystalDiskMark on all the individual drives, and only one (the WD) has a slower speed (relative to the Exos). While attempting to stream, watching the StreamBit program, the read speed jumps all over and isn't a consistent speed AT ALL. It will start at 125MB/s, and then drop to something insanely low like 75KB/s. Reading isn't the only problem either, as I have SABnzbd set to download to the drive and it states the download speed is limited by writing to the Hard drive.\n\nAs I said, I'm at work and can certainly send screenshots of the benchmarks from CrystalDiskMark when I get home, or any other information to help shed some more light on this issue. But if there's any suggestions out there, I'd greatly appreciate it! ", "author_fullname": "t2_nj62oupr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DrivePool seems to be struggling to read movies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b76nf5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709649312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this is the right place to ask this question. If not, my apologies. Also, I&amp;#39;m currently at work and can provide more specific information later in the day.&lt;/p&gt;\n\n&lt;p&gt;I have a 90TB Plex server running off of 5 HDDs; 4 are Seagate Exos and the other is a WD shucked drive. Everything ran incredibly smooth before moving over to the DrivePool, having them all as individual drives. I was able to DirectPlay and Transcode 4K Remuxes without issue. I was tired of having 5 different drives and read about DrivePool and thought it met my needs. I set it up without issue and moved everything to the new drive....but now EVERYTHING struggles to be read/written to the drive.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve ran CrystalDiskMark on all the individual drives, and only one (the WD) has a slower speed (relative to the Exos). While attempting to stream, watching the StreamBit program, the read speed jumps all over and isn&amp;#39;t a consistent speed AT ALL. It will start at 125MB/s, and then drop to something insanely low like 75KB/s. Reading isn&amp;#39;t the only problem either, as I have SABnzbd set to download to the drive and it states the download speed is limited by writing to the Hard drive.&lt;/p&gt;\n\n&lt;p&gt;As I said, I&amp;#39;m at work and can certainly send screenshots of the benchmarks from CrystalDiskMark when I get home, or any other information to help shed some more light on this issue. But if there&amp;#39;s any suggestions out there, I&amp;#39;d greatly appreciate it! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b76nf5", "is_robot_indexable": true, "report_reasons": null, "author": "DiscussionNo226", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b76nf5/drivepool_seems_to_be_struggling_to_read_movies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b76nf5/drivepool_seems_to_be_struggling_to_read_movies/", "subreddit_subscribers": 736448, "created_utc": 1709649312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an ancient Seagate Business NASS (n090401), which has faithfully served me. I've replaced one of the 4TB drives and the firmware is up to date. But I was wondering if I can upgrade the drives to something larger but given the age I don't know what the largest drive it would support. Any suggestions?", "author_fullname": "t2_tkgut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading legacy SeaGate Business NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b70lw2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709628205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an ancient Seagate Business NASS (n090401), which has faithfully served me. I&amp;#39;ve replaced one of the 4TB drives and the firmware is up to date. But I was wondering if I can upgrade the drives to something larger but given the age I don&amp;#39;t know what the largest drive it would support. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b70lw2", "is_robot_indexable": true, "report_reasons": null, "author": "seanhvw", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b70lw2/upgrading_legacy_seagate_business_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b70lw2/upgrading_legacy_seagate_business_nas/", "subreddit_subscribers": 736448, "created_utc": 1709628205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have few Tera of data but spread across external hard drives, remote clouds etc.\n\nI'm looking for some solution that allows me create an index of such resources that can be searched when devices are not connected or remote clouds are not reachable.\n\nEdit: I'm using mac/linux and it would be awesome if the solution would be web-based so that I can self-hosting it.\n\nIn other words I'd like to have a sofware where I can search for a specific filename or metadata and it shows where that file is stored.", "author_fullname": "t2_4mkbv07v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep track of content of remote archives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b703oo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709626766.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709626088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have few Tera of data but spread across external hard drives, remote clouds etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some solution that allows me create an index of such resources that can be searched when devices are not connected or remote clouds are not reachable.&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m using mac/linux and it would be awesome if the solution would be web-based so that I can self-hosting it.&lt;/p&gt;\n\n&lt;p&gt;In other words I&amp;#39;d like to have a sofware where I can search for a specific filename or metadata and it shows where that file is stored.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b703oo", "is_robot_indexable": true, "report_reasons": null, "author": "not-the-real-chopin", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b703oo/keep_track_of_content_of_remote_archives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b703oo/keep_track_of_content_of_remote_archives/", "subreddit_subscribers": 736448, "created_utc": 1709626088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI'm looking to purchase a Broadcom HBA 9500-8i Tri-Mode Storage Controller and came across a listing on eBay from seller \"hbr2015\" ([link to listing](https://www.ebay.com/itm/134734908059)).\n\nI'm interested in the controller but wanted to check with the community before making a purchase. Does anyone have any experience using this specific model (Broadcom HBA 9500-8i)?\n\nAdditionally, if anyone has purchased from seller \"hbr2015\" in the past, I'd appreciate any feedback you can share about your experience.\n\nThanks in advance for any insights!\n\n  \nEDIT:\n\nBroadcom GreyMarket: [https://www.broadcom.com/support/counterfeit-statement](https://www.broadcom.com/support/counterfeit-statement)", "author_fullname": "t2_9u74iu2x7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone had experience with the Broadcom HBA 9500-8i Tri-Mode Controller (Seller: hbr2015)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6znfj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709647330.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709624230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to purchase a Broadcom HBA 9500-8i Tri-Mode Storage Controller and came across a listing on eBay from seller &amp;quot;hbr2015&amp;quot; (&lt;a href=\"https://www.ebay.com/itm/134734908059\"&gt;link to listing&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in the controller but wanted to check with the community before making a purchase. Does anyone have any experience using this specific model (Broadcom HBA 9500-8i)?&lt;/p&gt;\n\n&lt;p&gt;Additionally, if anyone has purchased from seller &amp;quot;hbr2015&amp;quot; in the past, I&amp;#39;d appreciate any feedback you can share about your experience.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any insights!&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Broadcom GreyMarket: &lt;a href=\"https://www.broadcom.com/support/counterfeit-statement\"&gt;https://www.broadcom.com/support/counterfeit-statement&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uwXx2h_-cZPpDIzH7QGe0aC_lZryD6KRJqiO79ECHUY.jpg?auto=webp&amp;s=dee58aaacbeda15effcfd8c776d48481194bb1b4", "width": 400, "height": 318}, "resolutions": [{"url": "https://external-preview.redd.it/uwXx2h_-cZPpDIzH7QGe0aC_lZryD6KRJqiO79ECHUY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dece771ec241c18eaec3226a57a3eb9274be7710", "width": 108, "height": 85}, {"url": "https://external-preview.redd.it/uwXx2h_-cZPpDIzH7QGe0aC_lZryD6KRJqiO79ECHUY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7b8326dd57b767e3a17502f2ca1dd01cc4636443", "width": 216, "height": 171}, {"url": "https://external-preview.redd.it/uwXx2h_-cZPpDIzH7QGe0aC_lZryD6KRJqiO79ECHUY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df51d643566c744835b0811202e840cccb2a6f6e", "width": 320, "height": 254}], "variants": {}, "id": "7ZhnX6MIBswCCj-bSDAGDsPD0HJd10Pi25BwdJxnfTA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6znfj", "is_robot_indexable": true, "report_reasons": null, "author": "vkartk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6znfj/has_anyone_had_experience_with_the_broadcom_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6znfj/has_anyone_had_experience_with_the_broadcom_hba/", "subreddit_subscribers": 736448, "created_utc": 1709624230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Tried FreeFileSync and Rsync but this doesn't require any external programs.\n\nLast letter in the bat-file is the destination dir! F2 in Windows is rename, just in case.\n\nAny ideas for tweaks?\n\n\"Run as Administrator\" changes directory to c:\\\\windows\\\\system32\\\\ so can't use %cd% (CurrentDirectory) so %\\~dp0 has to be used and it works!\n\nDoesn't work without chopping of the last backslash hence the \\~0,-1%.\n\nSuper fast in windows just right-click and press \"e\" and \"unrem\" the /MIR **sober** for clearing out Cubase back-ups etc.\n\n\"robocopy 2 H.bat\":\n\n    @echo off\n    set filename=%~n0\n    set driveletter=%filename:~-1,1%\n    set batfiledir=%~dp0\n    set batfiledir=%batfiledir:~0,-1%\n    set destdir=%driveletter%%batfiledir:~1%\n    @echo on\n    \n    robocopy /E \"%batfiledir%\" \"%destdir%\" /ETA\n    rem robocopy /MIR \"%batfiledir%\" \"%destdir%\" /ETA\n    \n    pause", "author_fullname": "t2_a4cdqy3hc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "bat file for Robocopy syncing in windows.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6x9xg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709616151.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709615708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tried FreeFileSync and Rsync but this doesn&amp;#39;t require any external programs.&lt;/p&gt;\n\n&lt;p&gt;Last letter in the bat-file is the destination dir! F2 in Windows is rename, just in case.&lt;/p&gt;\n\n&lt;p&gt;Any ideas for tweaks?&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Run as Administrator&amp;quot; changes directory to c:\\windows\\system32\\ so can&amp;#39;t use %cd% (CurrentDirectory) so %~dp0 has to be used and it works!&lt;/p&gt;\n\n&lt;p&gt;Doesn&amp;#39;t work without chopping of the last backslash hence the ~0,-1%.&lt;/p&gt;\n\n&lt;p&gt;Super fast in windows just right-click and press &amp;quot;e&amp;quot; and &amp;quot;unrem&amp;quot; the /MIR &lt;strong&gt;sober&lt;/strong&gt; for clearing out Cubase back-ups etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;robocopy 2 H.bat&amp;quot;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@echo off\nset filename=%~n0\nset driveletter=%filename:~-1,1%\nset batfiledir=%~dp0\nset batfiledir=%batfiledir:~0,-1%\nset destdir=%driveletter%%batfiledir:~1%\n@echo on\n\nrobocopy /E &amp;quot;%batfiledir%&amp;quot; &amp;quot;%destdir%&amp;quot; /ETA\nrem robocopy /MIR &amp;quot;%batfiledir%&amp;quot; &amp;quot;%destdir%&amp;quot; /ETA\n\npause\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b6x9xg", "is_robot_indexable": true, "report_reasons": null, "author": "scatkang", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6x9xg/bat_file_for_robocopy_syncing_in_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6x9xg/bat_file_for_robocopy_syncing_in_windows/", "subreddit_subscribers": 736448, "created_utc": 1709615708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I added new data and I would like to transfer the data from my external drive into my server. I plugged it in, but it won't let me reboot the disk. I have transferred from this drive in the past with no issue, but I am relatively new to Unraid. I've got the Unassigned Device plugin. What do I need to fix? \n\nhttps://preview.redd.it/806lvyfp8gmc1.png?width=513&amp;format=png&amp;auto=webp&amp;s=245f32d4b52dac48f007f4f19c3f6c1d9d2fa3be", "author_fullname": "t2_bhj5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Unraid) Can anyone help me figure out my my external hard drive won't reattach?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 23, "top_awarded_type": null, "hide_score": false, "media_metadata": {"806lvyfp8gmc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 18, "x": 108, "u": "https://preview.redd.it/806lvyfp8gmc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=47fd26f537f87de27c15c51b6b735ec48881e17a"}, {"y": 36, "x": 216, "u": "https://preview.redd.it/806lvyfp8gmc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=89d53b0251465fc07e3fc6b2be0c5d10d5dd9da1"}, {"y": 54, "x": 320, "u": "https://preview.redd.it/806lvyfp8gmc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=260ff6deed4431474e19eb99189d78aa45034bb7"}], "s": {"y": 87, "x": 513, "u": "https://preview.redd.it/806lvyfp8gmc1.png?width=513&amp;format=png&amp;auto=webp&amp;s=245f32d4b52dac48f007f4f19c3f6c1d9d2fa3be"}, "id": "806lvyfp8gmc1"}}, "name": "t3_1b6x936", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fFvXdvcYBtOHzRY_sBqqC_vVOXYne0BJ35N7PVHXyEA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709615628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I added new data and I would like to transfer the data from my external drive into my server. I plugged it in, but it won&amp;#39;t let me reboot the disk. I have transferred from this drive in the past with no issue, but I am relatively new to Unraid. I&amp;#39;ve got the Unassigned Device plugin. What do I need to fix? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/806lvyfp8gmc1.png?width=513&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=245f32d4b52dac48f007f4f19c3f6c1d9d2fa3be\"&gt;https://preview.redd.it/806lvyfp8gmc1.png?width=513&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=245f32d4b52dac48f007f4f19c3f6c1d9d2fa3be&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b6x936", "is_robot_indexable": true, "report_reasons": null, "author": "Mattymike", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b6x936/unraid_can_anyone_help_me_figure_out_my_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b6x936/unraid_can_anyone_help_me_figure_out_my_my/", "subreddit_subscribers": 736448, "created_utc": 1709615628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am wondering if it's worth paying extra for externals when I could just by a dock for internals and swap out as needed.", "author_fullname": "t2_fk8e08x1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to handle multiple disk drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b7p0vt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709694393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering if it&amp;#39;s worth paying extra for externals when I could just by a dock for internals and swap out as needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7p0vt", "is_robot_indexable": true, "report_reasons": null, "author": "KWalthersArt", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7p0vt/best_way_to_handle_multiple_disk_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7p0vt/best_way_to_handle_multiple_disk_drives/", "subreddit_subscribers": 736448, "created_utc": 1709694393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking through a deleted Twitter, but there are thousands of posts.  I'm looking for a specific image they posted a while back.  Is there a way to filter for only tweets that have images?", "author_fullname": "t2_13x2zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Search Wayback for Tweets with images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7i0na", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709676122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking through a deleted Twitter, but there are thousands of posts.  I&amp;#39;m looking for a specific image they posted a while back.  Is there a way to filter for only tweets that have images?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7i0na", "is_robot_indexable": true, "report_reasons": null, "author": "getridofme12345", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7i0na/search_wayback_for_tweets_with_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7i0na/search_wayback_for_tweets_with_images/", "subreddit_subscribers": 736448, "created_utc": 1709676122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, my boyfriend and I have been poking the data storage gods in the eye for a lonnnnng time with a woefully inadequate backup solution, so we've decided to get two identical Dell PowerEdge R710 servers and put 6 Hitachi Ultrastar He12 12Tb drives in each of them. They'll be running Arch Linux.\n\nWhat we plan to do is copy everything we store to both of them, meaning, as one of our friendly worker bots acquires a file, it is copied to both the main server and the mirror/backup server. Ideally the two servers will be identical mirrors at all times.\n\nAny thoughts on how to do this? Thanks!", "author_fullname": "t2_jxrwr82a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some real-time file mirroring advice, please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7f77w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709669508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, my boyfriend and I have been poking the data storage gods in the eye for a lonnnnng time with a woefully inadequate backup solution, so we&amp;#39;ve decided to get two identical Dell PowerEdge R710 servers and put 6 Hitachi Ultrastar He12 12Tb drives in each of them. They&amp;#39;ll be running Arch Linux.&lt;/p&gt;\n\n&lt;p&gt;What we plan to do is copy everything we store to both of them, meaning, as one of our friendly worker bots acquires a file, it is copied to both the main server and the mirror/backup server. Ideally the two servers will be identical mirrors at all times.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on how to do this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7f77w", "is_robot_indexable": true, "report_reasons": null, "author": "renarde33", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7f77w/need_some_realtime_file_mirroring_advice_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7f77w/need_some_realtime_file_mirroring_advice_please/", "subreddit_subscribers": 736448, "created_utc": 1709669508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought two Samsung 2TB T7 Sheilds brand new sold and fulfilled by Newegg. I do photography and just need a bit more storage for now (I know I should have a RAID or NAS system in the future) but for now this is more than enough. I don't know what to do with them before I start using them. One is a backup and one is a main drive so I have 2TBs worth of storage. Should I be doing any tests or just trust in them and that the likelihood of getting two faulty T7 Shields is low.", "author_fullname": "t2_11kdbe89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2 New T7 Shields from Newegg. Do I Need to Test Them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7egrc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709667784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought two Samsung 2TB T7 Sheilds brand new sold and fulfilled by Newegg. I do photography and just need a bit more storage for now (I know I should have a RAID or NAS system in the future) but for now this is more than enough. I don&amp;#39;t know what to do with them before I start using them. One is a backup and one is a main drive so I have 2TBs worth of storage. Should I be doing any tests or just trust in them and that the likelihood of getting two faulty T7 Shields is low.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7egrc", "is_robot_indexable": true, "report_reasons": null, "author": "Pinkhead12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7egrc/2_new_t7_shields_from_newegg_do_i_need_to_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7egrc/2_new_t7_shields_from_newegg_do_i_need_to_test/", "subreddit_subscribers": 736448, "created_utc": 1709667784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI saw a post on here around 12 months regarding [Roberts Electronics](https://robertelectronics.co.uk/), and the cheap prices for drives, the cheapest I've found for the UK market.\n\nI was wondering if anyone had any experience with them, as the price almost seems too cheap.\n\nAnd one other thing does anyone have any other recommendations for cheap HDD's for a NAS in the UK, as annoyingly serverpartsdeals has really expensive UK shipping.\n\nThanks", "author_fullname": "t2_7n3fap45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap Drives - UK - Roberts Electronics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7da3f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709665009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I saw a post on here around 12 months regarding &lt;a href=\"https://robertelectronics.co.uk/\"&gt;Roberts Electronics&lt;/a&gt;, and the cheap prices for drives, the cheapest I&amp;#39;ve found for the UK market.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone had any experience with them, as the price almost seems too cheap.&lt;/p&gt;\n\n&lt;p&gt;And one other thing does anyone have any other recommendations for cheap HDD&amp;#39;s for a NAS in the UK, as annoyingly serverpartsdeals has really expensive UK shipping.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?auto=webp&amp;s=37854a66352bd889bdeb494671c725fc490f8469", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0b37794d7b21621b3c76b858ecaee46706cd5fe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e3dee3ab5378684525a043c71d67d66194f11b7a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1eaddf9429977018601d10b64b15150656d5631", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cdd36a705aca5b12d4eb2a1cb373509b988e7bbd", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0a8ef62b20d9bcd03f62046197b8c627bfef1df8", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/5u8etjVPUwkmCC4dzuBv_pZciVmt5N52UfzHhWqRh4I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19ef8e19eccd91febd10a64564c8c374b943eff7", "width": 1080, "height": 565}], "variants": {}, "id": "fRXUiS_f3WlETeAXLSWxly78LtaQpTxyxHFqHr02QhQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b7da3f", "is_robot_indexable": true, "report_reasons": null, "author": "Camspoon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b7da3f/cheap_drives_uk_roberts_electronics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b7da3f/cheap_drives_uk_roberts_electronics/", "subreddit_subscribers": 736448, "created_utc": 1709665009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Datablocks.dev](https://Datablocks.dev) is selling a few 20TB Ironwolf Pro White label drives for 230 euro, making them quite cheap:\n\n[https://datablocks.dev/products/seagate-ironwolf-pro-20-tb-sata-white-label-hard-drive](https://datablocks.dev/products/seagate-ironwolf-pro-20-tb-sata-white-label-hard-drive)", "author_fullname": "t2_uo3ft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "20TB Ironwolf Pro White label 230 euro (11,5 euro pr TB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b72lf7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709636456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://Datablocks.dev\"&gt;Datablocks.dev&lt;/a&gt; is selling a few 20TB Ironwolf Pro White label drives for 230 euro, making them quite cheap:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datablocks.dev/products/seagate-ironwolf-pro-20-tb-sata-white-label-hard-drive\"&gt;https://datablocks.dev/products/seagate-ironwolf-pro-20-tb-sata-white-label-hard-drive&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1b72lf7", "is_robot_indexable": true, "report_reasons": null, "author": "djandDK", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b72lf7/20tb_ironwolf_pro_white_label_230_euro_115_euro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b72lf7/20tb_ironwolf_pro_white_label_230_euro_115_euro/", "subreddit_subscribers": 736448, "created_utc": 1709636456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone tried using a personal Dropbox/Gdrive solution? I'm not entirely sure how to set it up but I'm planning to learn and I'm not sure which to go with.\n\nMy colleague mentioned that he rents his own private vps for $5/month just for the sole purpose of hosting Seafile, but it seems that this sub seems to have a preference for NextCloud. Am curious as to why NextCloud is more popular here, what are some advantages/disadvantages to weigh?", "author_fullname": "t2_e1qv9dge", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NextCloud vs Seafile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b70eij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709627370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried using a personal Dropbox/Gdrive solution? I&amp;#39;m not entirely sure how to set it up but I&amp;#39;m planning to learn and I&amp;#39;m not sure which to go with.&lt;/p&gt;\n\n&lt;p&gt;My colleague mentioned that he rents his own private vps for $5/month just for the sole purpose of hosting Seafile, but it seems that this sub seems to have a preference for NextCloud. Am curious as to why NextCloud is more popular here, what are some advantages/disadvantages to weigh?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b70eij", "is_robot_indexable": true, "report_reasons": null, "author": "Alarmed_Allele", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b70eij/nextcloud_vs_seafile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b70eij/nextcloud_vs_seafile/", "subreddit_subscribers": 736448, "created_utc": 1709627370.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}