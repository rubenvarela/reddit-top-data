{"kind": "Listing", "data": {"after": "t3_1b85aca", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mentally preparing myself for the eventual request to untangle this mess ", "author_fullname": "t2_ajstu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An actual post in my company Slack today ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7ojk4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 256, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 256, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/45hzb4JKb6XUlfc87joYwCKNrz1bIFjatQAXDtaSKKk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709693068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mentally preparing myself for the eventual request to untangle this mess &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nepsf40anmmc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nepsf40anmmc1.png?auto=webp&amp;s=740ca8fffc4c773df10b30bd58760f98ddb5cf5f", "width": 1008, "height": 1021}, "resolutions": [{"url": "https://preview.redd.it/nepsf40anmmc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=306cde57d791a7f7ac2d3fdaf21ee1ccfb7cb1a0", "width": 108, "height": 109}, {"url": "https://preview.redd.it/nepsf40anmmc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=11ce1790efe05b5753efed3324f0e089fac759bf", "width": 216, "height": 218}, {"url": "https://preview.redd.it/nepsf40anmmc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b02882706943fd5dbf19f353937e3330a0c68260", "width": 320, "height": 324}, {"url": "https://preview.redd.it/nepsf40anmmc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=763a74e15788e9fc58f4b055684cf198bb988f8a", "width": 640, "height": 648}, {"url": "https://preview.redd.it/nepsf40anmmc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8133f337b034435917344ca0ac8027caf8f395e", "width": 960, "height": 972}], "variants": {}, "id": "mSITuxfL21sELbVbAM8NXZhwUgSwLzyIhIe3SLKgD9E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1b7ojk4", "is_robot_indexable": true, "report_reasons": null, "author": "OneSixteenthRobot", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7ojk4/an_actual_post_in_my_company_slack_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nepsf40anmmc1.png", "subreddit_subscribers": 166373, "created_utc": 1709693068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently going through a massive reorg and conversion. The existing ETL is built with Ab Initio and the DB is Teradata. We are now moving everything to Databricks / azure. Any advice on learning databricks? I have never utilized python, and now apparently pyspark is what will be used to build the ETL in Databricks. How different is pyspark to python and any advices on learning this as well? I was new to DE when I got here and inherited the legacy systems, so this is going to be the first tools / coding I do from the ground up. Thanks for any advice! ", "author_fullname": "t2_73cw9sv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company is converting to Databricks!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7fz0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709671347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently going through a massive reorg and conversion. The existing ETL is built with Ab Initio and the DB is Teradata. We are now moving everything to Databricks / azure. Any advice on learning databricks? I have never utilized python, and now apparently pyspark is what will be used to build the ETL in Databricks. How different is pyspark to python and any advices on learning this as well? I was new to DE when I got here and inherited the legacy systems, so this is going to be the first tools / coding I do from the ground up. Thanks for any advice! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b7fz0q", "is_robot_indexable": true, "report_reasons": null, "author": "ApatheticRart", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7fz0q/company_is_converting_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7fz0q/company_is_converting_to_databricks/", "subreddit_subscribers": 166373, "created_utc": 1709671347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "   \nI'm currently working in the data aspect of engineering. The path I've embarked upon involves SQL, on-premises ETL tools, and reporting. However, I'm eager to transition into Cloud Data Engineering. I've begun analyzing the requirements companies post for such roles and the number of applicants for each position. It's overwhelming to observe that almost everyone is now identifying as a data engineer, regardless of their experience. I know individuals who transitioned from roles such as Database Administration or C/C++ programming to data engineering. Each job application I've seen attracts anywhere from 500 to 1200 applicants. Additionally, companies are requesting a minimum of 10 skills for data engineering roles, spanning from database management to developing streaming applications. With over 10 years of experience, I wonder if I can secure a job within a year, considering the multitude of skills I need to acquire and the intense competition. Is the effort truly worth it, especially given that I need to start from learning Python to mastering various cloud platforms?\n\n   \nTo be honest, I'm more inclined to master a select few skills rather than trying to be a jack of all trades. I'm aiming to specialize in those areas and work towards achieving a decent pay, perhaps around $100k to $120k, instead of chasing after the salaries of data engineers who are earning approximately $250- 500k with over 10 years of experience. \n\n I'd appreciate your thoughts on this matter. ", "author_fullname": "t2_q2p51ehcb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is everyone becoming a data engineer? And is it still worth embarking on this career journey?\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7fcgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709669860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working in the data aspect of engineering. The path I&amp;#39;ve embarked upon involves SQL, on-premises ETL tools, and reporting. However, I&amp;#39;m eager to transition into Cloud Data Engineering. I&amp;#39;ve begun analyzing the requirements companies post for such roles and the number of applicants for each position. It&amp;#39;s overwhelming to observe that almost everyone is now identifying as a data engineer, regardless of their experience. I know individuals who transitioned from roles such as Database Administration or C/C++ programming to data engineering. Each job application I&amp;#39;ve seen attracts anywhere from 500 to 1200 applicants. Additionally, companies are requesting a minimum of 10 skills for data engineering roles, spanning from database management to developing streaming applications. With over 10 years of experience, I wonder if I can secure a job within a year, considering the multitude of skills I need to acquire and the intense competition. Is the effort truly worth it, especially given that I need to start from learning Python to mastering various cloud platforms?&lt;/p&gt;\n\n&lt;p&gt;To be honest, I&amp;#39;m more inclined to master a select few skills rather than trying to be a jack of all trades. I&amp;#39;m aiming to specialize in those areas and work towards achieving a decent pay, perhaps around $100k to $120k, instead of chasing after the salaries of data engineers who are earning approximately $250- 500k with over 10 years of experience. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate your thoughts on this matter. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b7fcgo", "is_robot_indexable": true, "report_reasons": null, "author": "AccomplishedHat9906", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7fcgo/is_everyone_becoming_a_data_engineer_and_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7fcgo/is_everyone_becoming_a_data_engineer_and_is_it/", "subreddit_subscribers": 166373, "created_utc": 1709669860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you have an un-versioned source which unexpectedly changes its schema, how do you deal with that situation? \n\nDo you maintain a manually entered schema and trigger alert on reads if schema validation fails?\n\nIs it assumed the pipeline will eventually break, so you write your pipeline in a more 'defensive' way?\n\nIs there a Sentry-like tool for ETL pipelines, meaning it can alert when things break?\n\nPlease excuse my lack of knowledge on this topic, I'm very new to DE.", "author_fullname": "t2_tnf3rfrjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you detect source schema changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7f9f6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709669655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you have an un-versioned source which unexpectedly changes its schema, how do you deal with that situation? &lt;/p&gt;\n\n&lt;p&gt;Do you maintain a manually entered schema and trigger alert on reads if schema validation fails?&lt;/p&gt;\n\n&lt;p&gt;Is it assumed the pipeline will eventually break, so you write your pipeline in a more &amp;#39;defensive&amp;#39; way?&lt;/p&gt;\n\n&lt;p&gt;Is there a Sentry-like tool for ETL pipelines, meaning it can alert when things break?&lt;/p&gt;\n\n&lt;p&gt;Please excuse my lack of knowledge on this topic, I&amp;#39;m very new to DE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b7f9f6", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Coat5856", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b7f9f6/how_do_you_detect_source_schema_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7f9f6/how_do_you_detect_source_schema_changes/", "subreddit_subscribers": 166373, "created_utc": 1709669655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, recently I completed another personal project. Any suggestions are welcome.\n\n[Github Repo](https://github.com/Zzdragon66/stock-streaming-project)\n\n## Project Description\n\n* This project leverages Python, Kafka, and Spark to process real-time streaming data from both stock markets and Reddit. It employs a Long Short-Term Memory (LSTM) deep learning model to conduct real-time predictions on SPY (S&amp;P 500 ETF) stock data. Additionally, the project utilizes Grafana for the real-time visualization of stock data, predictive analytics, and reddit data, providing a comprehensive and dynamic overview of market trends and sentiments.\n\n## Demo\n\n&amp;#x200B;\n\nhttps://i.redd.it/t85j4210dpmc1.gif\n\n## Project Structure\n\n&amp;#x200B;\n\nhttps://preview.redd.it/n292wc61dpmc1.png?width=4164&amp;format=png&amp;auto=webp&amp;s=76dcc8279e38327babe8c954c05b17906ba8453c\n\n## Tools\n\n1. Apache Airflow: Data pipeline orchestration\n2. Apache Kafka: Stream data handling\n3. Apache Spark: batch data processing\n4. Apache Cassandra: NoSQL database to store time series data\n5. Docker + Kubernets: Containerization and Docker Orchestration\n6. Pytorch: Deep learning model\n7. Grafna: Stream Data visualization\n8. Python: produce streaming data with multithreading\n\n## Project Design Choice\n\n## Kafka\n\n* Why Kafka?\n   * Kafak serves a stream data handler to feed data into spark and deep learning model\n* Design of kafka\n   * I utilize Python's multi-threading capabilities to simultaneously produce stock data, enhancing the throughput by exploiting parallelism. Consequently, I partition the topic according to the number of stocks, allowing each thread to direct its data into a distinct partition, thereby optimizing the data flow and maximizing efficiency\n\n## Cassandra Database Design\n\n* Stock data contains the data of `stock` symbol and `utc_timestamp`, which can be used to uniquely identify the single data point. Therefore I use those two features as the primary key\n* Use `utc_timestamp` as the clustering key to store the time series data in ascending order for efficient read(sequantial read for a time series data) and high throughput write(real-time data only appends to the end of parition)\n\n## Deep learning model Discussion\n\n* Data\n   * Train Data Dimension (N, T, D)\n      * N is number of data in a batch\n      * T=200 look back two hundred seconds data\n      * D=5 the features in the data (price, number of transactions, high price, low price, volumes)\n   * Prediction Data Dimension (1, 200, 5)\n* Data Preprocessing:\n   * Use MinMaxScaler to make sure each feature has similar scale\n* Model Structure:\n   * X-&gt;\\[LSTM \\* 5\\]-&gt;Linear-&gt;Price-Prediction\n* How the Model works:\n   * At current timestamp t, get latest 200 time sereis data before $t$ in ascending `utc_timestamp` order. Feed the data into deep learning model which will predict the current SPY stock prie at time t.\n* Due to the limited computational resources on my local machine, the \"real-time\" prediction lags behind actual time because of the long computation duration required.\n\n## Future Directions\n\n1. Deploy the local kubernets to AWS EKS and Use GPU accelerator on cloud\n2. Train a better deep learning model to make prediction more accurate and faster", "author_fullname": "t2_5igde9z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End-End Stock Streaming Project(K8S, Airflow, Kafka, Spark, Pytorch, Docker, Cassandra, Grafna)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"t85j4210dpmc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/t85j4210dpmc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=31a407bb797466af045aaacbc93e581ff4f9c604"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/t85j4210dpmc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=3f984dbc901edba448538f4312ee5c65378d0457"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/t85j4210dpmc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=b9d568e98b52007048fd496e3e88d056677ca222"}, {"y": 336, "x": 640, "u": "https://preview.redd.it/t85j4210dpmc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=1f055006987c65e7d8a44ab5e684b7968448b785"}, {"y": 505, "x": 960, "u": "https://preview.redd.it/t85j4210dpmc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=973819231667912f2bd709258a716265b1aae6b9"}, {"y": 568, "x": 1080, "u": "https://preview.redd.it/t85j4210dpmc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=8729eaaf8bd74765e4bc387a1e38d29f3135397f"}], "s": {"y": 720, "gif": "https://i.redd.it/t85j4210dpmc1.gif", "mp4": "https://preview.redd.it/t85j4210dpmc1.gif?format=mp4&amp;s=86060fce964241e914ea0f962b15505fa701cb45", "x": 1368}, "id": "t85j4210dpmc1"}, "n292wc61dpmc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=06952bd781e59b01b59e1ea9f70e28a414a59b10"}, {"y": 107, "x": 216, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0054f645ce39a1e55d9387184a0bdfe10d5a4c45"}, {"y": 158, "x": 320, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8690d6dd977fa313da788fea8dedc619474cb31"}, {"y": 317, "x": 640, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=af2fb8e45950c24c2eb0119ccd66a20b1707a97d"}, {"y": 475, "x": 960, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=64755b34f27cae4ccca0d0cbb161851aa388f5a2"}, {"y": 535, "x": 1080, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d2acf223149cbe17a5e306798d5248d776ee3897"}], "s": {"y": 2064, "x": 4164, "u": "https://preview.redd.it/n292wc61dpmc1.png?width=4164&amp;format=png&amp;auto=webp&amp;s=76dcc8279e38327babe8c954c05b17906ba8453c"}, "id": "n292wc61dpmc1"}}, "name": "t3_1b7xuw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NnTWeD7Jq6sjwYJ_3JRMAz7fH0IDgK0LKZoP69eodVA.jpg", "edited": 1709726718.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709726056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, recently I completed another personal project. Any suggestions are welcome.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Zzdragon66/stock-streaming-project\"&gt;Github Repo&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Project Description&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;This project leverages Python, Kafka, and Spark to process real-time streaming data from both stock markets and Reddit. It employs a Long Short-Term Memory (LSTM) deep learning model to conduct real-time predictions on SPY (S&amp;amp;P 500 ETF) stock data. Additionally, the project utilizes Grafana for the real-time visualization of stock data, predictive analytics, and reddit data, providing a comprehensive and dynamic overview of market trends and sentiments.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Demo&lt;/h2&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/t85j4210dpmc1.gif\"&gt;https://i.redd.it/t85j4210dpmc1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Project Structure&lt;/h2&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n292wc61dpmc1.png?width=4164&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=76dcc8279e38327babe8c954c05b17906ba8453c\"&gt;https://preview.redd.it/n292wc61dpmc1.png?width=4164&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=76dcc8279e38327babe8c954c05b17906ba8453c&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Tools&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Apache Airflow: Data pipeline orchestration&lt;/li&gt;\n&lt;li&gt;Apache Kafka: Stream data handling&lt;/li&gt;\n&lt;li&gt;Apache Spark: batch data processing&lt;/li&gt;\n&lt;li&gt;Apache Cassandra: NoSQL database to store time series data&lt;/li&gt;\n&lt;li&gt;Docker + Kubernets: Containerization and Docker Orchestration&lt;/li&gt;\n&lt;li&gt;Pytorch: Deep learning model&lt;/li&gt;\n&lt;li&gt;Grafna: Stream Data visualization&lt;/li&gt;\n&lt;li&gt;Python: produce streaming data with multithreading&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;Project Design Choice&lt;/h2&gt;\n\n&lt;h2&gt;Kafka&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Why Kafka?\n\n&lt;ul&gt;\n&lt;li&gt;Kafak serves a stream data handler to feed data into spark and deep learning model&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Design of kafka\n\n&lt;ul&gt;\n&lt;li&gt;I utilize Python&amp;#39;s multi-threading capabilities to simultaneously produce stock data, enhancing the throughput by exploiting parallelism. Consequently, I partition the topic according to the number of stocks, allowing each thread to direct its data into a distinct partition, thereby optimizing the data flow and maximizing efficiency&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Cassandra Database Design&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Stock data contains the data of &lt;code&gt;stock&lt;/code&gt; symbol and &lt;code&gt;utc_timestamp&lt;/code&gt;, which can be used to uniquely identify the single data point. Therefore I use those two features as the primary key&lt;/li&gt;\n&lt;li&gt;Use &lt;code&gt;utc_timestamp&lt;/code&gt; as the clustering key to store the time series data in ascending order for efficient read(sequantial read for a time series data) and high throughput write(real-time data only appends to the end of parition)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Deep learning model Discussion&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data\n\n&lt;ul&gt;\n&lt;li&gt;Train Data Dimension (N, T, D)\n\n&lt;ul&gt;\n&lt;li&gt;N is number of data in a batch&lt;/li&gt;\n&lt;li&gt;T=200 look back two hundred seconds data&lt;/li&gt;\n&lt;li&gt;D=5 the features in the data (price, number of transactions, high price, low price, volumes)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Prediction Data Dimension (1, 200, 5)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Data Preprocessing:\n\n&lt;ul&gt;\n&lt;li&gt;Use MinMaxScaler to make sure each feature has similar scale&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Model Structure:\n\n&lt;ul&gt;\n&lt;li&gt;X-&amp;gt;[LSTM * 5]-&amp;gt;Linear-&amp;gt;Price-Prediction&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;How the Model works:\n\n&lt;ul&gt;\n&lt;li&gt;At current timestamp t, get latest 200 time sereis data before $t$ in ascending &lt;code&gt;utc_timestamp&lt;/code&gt; order. Feed the data into deep learning model which will predict the current SPY stock prie at time t.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Due to the limited computational resources on my local machine, the &amp;quot;real-time&amp;quot; prediction lags behind actual time because of the long computation duration required.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Future Directions&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Deploy the local kubernets to AWS EKS and Use GPU accelerator on cloud&lt;/li&gt;\n&lt;li&gt;Train a better deep learning model to make prediction more accurate and faster&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?auto=webp&amp;s=0dffb8e257a9c56177690da3b4d7eb28b035313f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=986b81c3c895b8bdc7d8fbc7b157598533d0708a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=76e711b7b52c25ae632cdb1d13e2c0afc9088b95", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1fc993ea8ea657a4f0b6218d1ab80f8f785ffec3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=179bcba689e824ef31d56f95e4d24c55a352bbd2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04d04a27c7a25944add1502cbacc5123cc428847", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/R7FEafIHAyD-tonTPsdPH3AAjgxXtjnudb3jzwo2vms.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d7327f06c591c2a76917f274a05850fbc8f4e182", "width": 1080, "height": 540}], "variants": {}, "id": "Rj7Hkx8aj--pA4V1ZFv7Ec4bNEzMf6LrYPbsGILQTk8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b7xuw3", "is_robot_indexable": true, "report_reasons": null, "author": "AffectionateEmu8146", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7xuw3/endend_stock_streaming_projectk8s_airflow_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7xuw3/endend_stock_streaming_projectk8s_airflow_kafka/", "subreddit_subscribers": 166373, "created_utc": 1709726056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious to hear about how much the industry sector of your company has affected your career and your job satisfaction. I'm working for a property management company in my first DE job and I'm learning a ton, but I'm not sure if real estate is really my jam so to speak. What are good industries to work for in DE right now?", "author_fullname": "t2_653as", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior DE and above: what happened when you changed industries? Did it have a big affect on your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7mo16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709687856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to hear about how much the industry sector of your company has affected your career and your job satisfaction. I&amp;#39;m working for a property management company in my first DE job and I&amp;#39;m learning a ton, but I&amp;#39;m not sure if real estate is really my jam so to speak. What are good industries to work for in DE right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b7mo16", "is_robot_indexable": true, "report_reasons": null, "author": "tedward27", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7mo16/senior_de_and_above_what_happened_when_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7mo16/senior_de_and_above_what_happened_when_you/", "subreddit_subscribers": 166373, "created_utc": 1709687856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nComing from someone outside the data engineer field, I am just trying to understand what Hadoop is for?\n\nI know, I've googled and read posts, articles and all and it doesn't really stick on me.\n\nIs it really considered a file system or is it just an algorithm to distribute data across nodes in a cluster?\n\nDocs says it's good to process datasets. What are datasets? Are these files, databases? CSVs?\\\\\n\nHow does Hadoop relates to these concepts, datasets, HDFS and ORC (Optimized Row Columnar)\n\nI really think a simple example that I couldnt really find in internet could be the key for me to understand that once and for all.\n\nAnd finally, how Spark and BigData relates to it?", "author_fullname": "t2_7al5p0w0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Hadoop and it's relation with Spark and BigData?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7mhka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709687753.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709687367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Coming from someone outside the data engineer field, I am just trying to understand what Hadoop is for?&lt;/p&gt;\n\n&lt;p&gt;I know, I&amp;#39;ve googled and read posts, articles and all and it doesn&amp;#39;t really stick on me.&lt;/p&gt;\n\n&lt;p&gt;Is it really considered a file system or is it just an algorithm to distribute data across nodes in a cluster?&lt;/p&gt;\n\n&lt;p&gt;Docs says it&amp;#39;s good to process datasets. What are datasets? Are these files, databases? CSVs?\\&lt;/p&gt;\n\n&lt;p&gt;How does Hadoop relates to these concepts, datasets, HDFS and ORC (Optimized Row Columnar)&lt;/p&gt;\n\n&lt;p&gt;I really think a simple example that I couldnt really find in internet could be the key for me to understand that once and for all.&lt;/p&gt;\n\n&lt;p&gt;And finally, how Spark and BigData relates to it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b7mhka", "is_robot_indexable": true, "report_reasons": null, "author": "erudes91", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7mhka/what_is_hadoop_and_its_relation_with_spark_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7mhka/what_is_hadoop_and_its_relation_with_spark_and/", "subreddit_subscribers": 166373, "created_utc": 1709687367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analytics professional of 6 years who started becoming interested in DE after finding software engineering more interesting than my statistics/data analysis work. I first started out by taking python OOP, computer science fundamental and full stack courses. I enjoyed that stuff and had some full stack knowledge beforehand, but the issue was from a career perspective that I had so much experience in data that full stack dev seemed like a disconnect from my past work and I started to look at something that would blend my data skills with software engineering interests. \n\nI started looking into DE, but I didn't quite understand where to even start. I have automated data workflows in the past, but I was using SQL, R and Cron-literally leveraging whatever tools I had because the work previous analysts were doing was very manual and tedious. I don't have formal experience with cloud technologies, airflow, kafka, databricks, etc. I used Docker and AWS on personal projects and kind of understand it, but I'm not an expert by any means. \n\nI just got my first DE job after hundreds of applications for data engineer, software engineer and data science roles. I'm excited but I also don't know what I should prioritize in my learning journey. I bought the joe reis data engineering book months ago and am doing the data engineering zoomcamp, but am so behind on that due to other life things. The DE zoomcamp seems like a great resource so far and it's amazing it's free-but I'm sort of feeling like I'm going through the motions without really understanding what exactly I'm doing. I also saw that AWS has certifications and the job I'm going to be doing uses Redshift so I thought I'd look into that. \n\nAny suggestions on what to start with? ", "author_fullname": "t2_2prckadt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I prioritize learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7nrzd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709690933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analytics professional of 6 years who started becoming interested in DE after finding software engineering more interesting than my statistics/data analysis work. I first started out by taking python OOP, computer science fundamental and full stack courses. I enjoyed that stuff and had some full stack knowledge beforehand, but the issue was from a career perspective that I had so much experience in data that full stack dev seemed like a disconnect from my past work and I started to look at something that would blend my data skills with software engineering interests. &lt;/p&gt;\n\n&lt;p&gt;I started looking into DE, but I didn&amp;#39;t quite understand where to even start. I have automated data workflows in the past, but I was using SQL, R and Cron-literally leveraging whatever tools I had because the work previous analysts were doing was very manual and tedious. I don&amp;#39;t have formal experience with cloud technologies, airflow, kafka, databricks, etc. I used Docker and AWS on personal projects and kind of understand it, but I&amp;#39;m not an expert by any means. &lt;/p&gt;\n\n&lt;p&gt;I just got my first DE job after hundreds of applications for data engineer, software engineer and data science roles. I&amp;#39;m excited but I also don&amp;#39;t know what I should prioritize in my learning journey. I bought the joe reis data engineering book months ago and am doing the data engineering zoomcamp, but am so behind on that due to other life things. The DE zoomcamp seems like a great resource so far and it&amp;#39;s amazing it&amp;#39;s free-but I&amp;#39;m sort of feeling like I&amp;#39;m going through the motions without really understanding what exactly I&amp;#39;m doing. I also saw that AWS has certifications and the job I&amp;#39;m going to be doing uses Redshift so I thought I&amp;#39;d look into that. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions on what to start with? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b7nrzd", "is_robot_indexable": true, "report_reasons": null, "author": "thro0away12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7nrzd/what_should_i_prioritize_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7nrzd/what_should_i_prioritize_learning/", "subreddit_subscribers": 166373, "created_utc": 1709690933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m just shocked\u2026 flabbergasted, actually, that my entire degree had no mention of this word.\n\nConnascence is a concept similar to dependencies and coupling. If a change in one part of something requires changes in other parts of something, that\u2019s connascence. Apparently there\u2019s a decent amount of academic work done on this subject, fresh for the study. \n\nMy first impressions is that you can probably explain very well why Docker is so successful, with only a solid understanding of connascence and how servers / applications work. It minimizes connascence between the machine and the app.\n\nThere are categories: static connascence and dynamic connascence. Both have subcategories, such as value connascence, identity connascence, name connascence, \u2026\n\nI\u2019m finding this neat because it makes talking about an abstract and difficult topic, easier. I\u2019m suddenly making realizations about many of my systems and their connascence, how I could change their connascence measures\u2026\n\nThis is cool stuff, guys.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Let\u2019s have a talk about connascence, shall we?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7meq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709687142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m just shocked\u2026 flabbergasted, actually, that my entire degree had no mention of this word.&lt;/p&gt;\n\n&lt;p&gt;Connascence is a concept similar to dependencies and coupling. If a change in one part of something requires changes in other parts of something, that\u2019s connascence. Apparently there\u2019s a decent amount of academic work done on this subject, fresh for the study. &lt;/p&gt;\n\n&lt;p&gt;My first impressions is that you can probably explain very well why Docker is so successful, with only a solid understanding of connascence and how servers / applications work. It minimizes connascence between the machine and the app.&lt;/p&gt;\n\n&lt;p&gt;There are categories: static connascence and dynamic connascence. Both have subcategories, such as value connascence, identity connascence, name connascence, \u2026&lt;/p&gt;\n\n&lt;p&gt;I\u2019m finding this neat because it makes talking about an abstract and difficult topic, easier. I\u2019m suddenly making realizations about many of my systems and their connascence, how I could change their connascence measures\u2026&lt;/p&gt;\n\n&lt;p&gt;This is cool stuff, guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b7meq0", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7meq0/lets_have_a_talk_about_connascence_shall_we/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7meq0/lets_have_a_talk_about_connascence_shall_we/", "subreddit_subscribers": 166373, "created_utc": 1709687142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s1sqpvie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A tool to quickly extract data from websites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7zezu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/94pkdfw2rpmc1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/94pkdfw2rpmc1/DASH_96.mp4", "dash_url": "https://v.redd.it/94pkdfw2rpmc1/DASHPlaylist.mpd?a=1712342292%2CMzZlZGNiYzg0ZDdlY2ZmYWQxNTNlMGIyYjBiZTg1ZDhlYzBhOTRmMGZjODRkOTQ0MTM0YjkzYjM0YWNjMWI3ZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 53, "hls_url": "https://v.redd.it/94pkdfw2rpmc1/HLSPlaylist.m3u8?a=1712342292%2CZjkwODBlMmU4MDg5YWNhMmQzZWMwM2Q0Yjc2NTcyNjUyZTljODRhNGZjMjM2YjUyMjA2NWJiMWI3MWRkNzY2Yg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=fd3f9a9e3fa773dbf7d1f607766b00cdb0eb9644", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709730925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/94pkdfw2rpmc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?format=pjpg&amp;auto=webp&amp;s=0430c356c59c7aa0f15f767d9fead38ac1e60ae9", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1ce8ea7ec58f56de5a5aaac23f675c954344c7f1", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b76caff515a156b91183bda6484e43c6bba0d59b", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1cfbc805b2bfd0b7078fe23ee907fc05dff6adb2", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0c11fd20ec6c937c2f5bb29322c58e282eeef471", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=65e00eb3dd620fd51fb9237e8c128ac8de834ea4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1382a8ecc535e238086087b11a6f25c2dc0d01f7", "width": 1080, "height": 607}], "variants": {}, "id": "MGEzMzI2Z3VycG1jMbgquC2yV37Gtqn3u1WBKlQegqusV3jYrF88fs9iNH6Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b7zezu", "is_robot_indexable": true, "report_reasons": null, "author": "GeekLifer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7zezu/a_tool_to_quickly_extract_data_from_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/94pkdfw2rpmc1", "subreddit_subscribers": 166373, "created_utc": 1709730925.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/94pkdfw2rpmc1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/94pkdfw2rpmc1/DASH_96.mp4", "dash_url": "https://v.redd.it/94pkdfw2rpmc1/DASHPlaylist.mpd?a=1712342292%2CMzZlZGNiYzg0ZDdlY2ZmYWQxNTNlMGIyYjBiZTg1ZDhlYzBhOTRmMGZjODRkOTQ0MTM0YjkzYjM0YWNjMWI3ZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 53, "hls_url": "https://v.redd.it/94pkdfw2rpmc1/HLSPlaylist.m3u8?a=1712342292%2CZjkwODBlMmU4MDg5YWNhMmQzZWMwM2Q0Yjc2NTcyNjUyZTljODRhNGZjMjM2YjUyMjA2NWJiMWI3MWRkNzY2Yg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I graduated June 2021 from a good UC with a BS in Data Science, but took an opportunity as a contractor at MAANG to get some industry experience in Data Engineering.\n\nI\u2019ve been working as a contractor here for about 2 years, yet I feel like my imposter syndrome is still something I\u2019m struggling with. The title as a contractor also creates this negative perception of myself as well. At this point, I think it\u2019s hindering my progress.\n\nMany of the FTE I\u2019ve worked with have told me I have the skills to transfer to a full time position. I recently failed the full loop for transferring to a FTE. Consequently, this rejection adds to my imposter syndrome of not being enough.\n\nHow did you guys get over your imposter syndrome? How did you guys stop giving a fuck about what others thought and just do what you do to excel? Thanks!\n", "author_fullname": "t2_2r6kthl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with Imposter Syndrome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b82sdv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709739613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I graduated June 2021 from a good UC with a BS in Data Science, but took an opportunity as a contractor at MAANG to get some industry experience in Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working as a contractor here for about 2 years, yet I feel like my imposter syndrome is still something I\u2019m struggling with. The title as a contractor also creates this negative perception of myself as well. At this point, I think it\u2019s hindering my progress.&lt;/p&gt;\n\n&lt;p&gt;Many of the FTE I\u2019ve worked with have told me I have the skills to transfer to a full time position. I recently failed the full loop for transferring to a FTE. Consequently, this rejection adds to my imposter syndrome of not being enough.&lt;/p&gt;\n\n&lt;p&gt;How did you guys get over your imposter syndrome? How did you guys stop giving a fuck about what others thought and just do what you do to excel? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b82sdv", "is_robot_indexable": true, "report_reasons": null, "author": "kabzthegang", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b82sdv/help_with_imposter_syndrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b82sdv/help_with_imposter_syndrome/", "subreddit_subscribers": 166373, "created_utc": 1709739613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working for a small market research company and I'm trying to do some machine learning on survey data. Most of the data we get from clients is in bad shape and I need to be able to format it into a particular shape for this. I'm looking for a general metadata, machine readable format for survey questionnaires. There doesn't seem to be an industrial standard or even any attempts at one?\n\nThe closest thing I've found is what [google forms exports](https://github.com/stevenschmatz/export-google-form), but this is very Google. I thought there would be an RDF schema but there is none (that I have found). Can't see anything from the W3C?\n\nSurely this is a \"good idea\" as it will allow the same survey to be taken on different platforms or reproduced at different times/places/ languages or even act as a description of the resulting data?\n\nHoping that there is something I've missed...\n\nUpdate: Given the lackluster response I take it there is no such standard. Sooooo, do you want to join me in making one?", "author_fullname": "t2_372kgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey questionnaire metadata industry format?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7k1yc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709696014.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709680951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working for a small market research company and I&amp;#39;m trying to do some machine learning on survey data. Most of the data we get from clients is in bad shape and I need to be able to format it into a particular shape for this. I&amp;#39;m looking for a general metadata, machine readable format for survey questionnaires. There doesn&amp;#39;t seem to be an industrial standard or even any attempts at one?&lt;/p&gt;\n\n&lt;p&gt;The closest thing I&amp;#39;ve found is what &lt;a href=\"https://github.com/stevenschmatz/export-google-form\"&gt;google forms exports&lt;/a&gt;, but this is very Google. I thought there would be an RDF schema but there is none (that I have found). Can&amp;#39;t see anything from the W3C?&lt;/p&gt;\n\n&lt;p&gt;Surely this is a &amp;quot;good idea&amp;quot; as it will allow the same survey to be taken on different platforms or reproduced at different times/places/ languages or even act as a description of the resulting data?&lt;/p&gt;\n\n&lt;p&gt;Hoping that there is something I&amp;#39;ve missed...&lt;/p&gt;\n\n&lt;p&gt;Update: Given the lackluster response I take it there is no such standard. Sooooo, do you want to join me in making one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?auto=webp&amp;s=521d2c08c06aa839648c62860b9875f49707731e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2e742ac0b522646c28559017e503893a84d30af6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cdf3873d55e8e2597e69502f25492d8156c8e4e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=57f81186553242346008567ad4065231a0672fe4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f154d7bfc7d76a6824cfcd4dccb379c6b3625564", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e4e15023816850591c3bb16359fc5f8a4da93d4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0rx3D6F4Pw_uzq81Wg-QDGd21-hGKqshQjkKENmXHBw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc2ee66c82baa786c59ab46a78d1732235a869ed", "width": 1080, "height": 540}], "variants": {}, "id": "HivzooITJkQS0duDn7tteq8fvzzueQT2V9g0N74DIA4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b7k1yc", "is_robot_indexable": true, "report_reasons": null, "author": "FMWizard", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7k1yc/survey_questionnaire_metadata_industry_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7k1yc/survey_questionnaire_metadata_industry_format/", "subreddit_subscribers": 166373, "created_utc": 1709680951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nwe have data stored in an S3 bucket in the form of raw CSV files. Adobe is currently accessing this data directly from the S3 bucket. However, these files contain sensitive information. I\u2019m exploring options to ensure that we maintain ownership of the data while allowing Adobe to access it securely.\n\nAny suggestions or use cases or right way to get this done propely . We are having mulitple third parties using the data not only adobe. Just asking what are my options here please help.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expose data from S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b81nx5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709736863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;we have data stored in an S3 bucket in the form of raw CSV files. Adobe is currently accessing this data directly from the S3 bucket. However, these files contain sensitive information. I\u2019m exploring options to ensure that we maintain ownership of the data while allowing Adobe to access it securely.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or use cases or right way to get this done propely . We are having mulitple third parties using the data not only adobe. Just asking what are my options here please help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b81nx5", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b81nx5/expose_data_from_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b81nx5/expose_data_from_s3/", "subreddit_subscribers": 166373, "created_utc": 1709736863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Disclaimer:** I'm NOT a StreamNative employee, but recently became an Apache Pulsar committer.\n\nOxia is a new metadata store and coordination system similar to Zookeeper or Etcd. But in comparison with the others, it can store 100s of GBs of data and can handle millions of reads and writes per second.\n\nOxia GitHub repository: [https://github.com/streamnative/oxia](https://github.com/streamnative/oxia)\n\nIt's licensed under Apache License 2.0.\n\nThe Java client has been just open-sourced. Here is a blog post: [https://streamnative.io/blog/the-oxia-java-client-library-is-now-open-source](https://streamnative.io/blog/the-oxia-java-client-library-is-now-open-source)\n\nOxia is already integrated with Pulsar but isn't a default option yet. Folks from StreamNative claim that they used it in the cloud for a few months without any problems.\n\nI didn't see any independent benchmarks yet, therefore I can't validate the performance and stability claims. Probably this post may change it and attract engineers who are interested in trying Oxia for their projects and publicly share the results.\n\nI understand that it may be not a very interesting topic for many data engineers, but it may be interesting for engineers who build distributed systems FOR data engineers.  \nI would highly value hearing your thoughts on the project.", "author_fullname": "t2_15hg9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think about Oxia: a new high-performant metadata store?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b81nob", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709736847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; I&amp;#39;m NOT a StreamNative employee, but recently became an Apache Pulsar committer.&lt;/p&gt;\n\n&lt;p&gt;Oxia is a new metadata store and coordination system similar to Zookeeper or Etcd. But in comparison with the others, it can store 100s of GBs of data and can handle millions of reads and writes per second.&lt;/p&gt;\n\n&lt;p&gt;Oxia GitHub repository: &lt;a href=\"https://github.com/streamnative/oxia\"&gt;https://github.com/streamnative/oxia&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s licensed under Apache License 2.0.&lt;/p&gt;\n\n&lt;p&gt;The Java client has been just open-sourced. Here is a blog post: &lt;a href=\"https://streamnative.io/blog/the-oxia-java-client-library-is-now-open-source\"&gt;https://streamnative.io/blog/the-oxia-java-client-library-is-now-open-source&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Oxia is already integrated with Pulsar but isn&amp;#39;t a default option yet. Folks from StreamNative claim that they used it in the cloud for a few months without any problems.&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t see any independent benchmarks yet, therefore I can&amp;#39;t validate the performance and stability claims. Probably this post may change it and attract engineers who are interested in trying Oxia for their projects and publicly share the results.&lt;/p&gt;\n\n&lt;p&gt;I understand that it may be not a very interesting topic for many data engineers, but it may be interesting for engineers who build distributed systems FOR data engineers.&lt;br/&gt;\nI would highly value hearing your thoughts on the project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mzjpLNWi54W1gfKLejILwwxOWZvINXC4ViqeZjuRcds.jpg?auto=webp&amp;s=75dde46b1ba4cc2af23609aa9e76196bd173bac5", "width": 512, "height": 513}, "resolutions": [{"url": "https://external-preview.redd.it/mzjpLNWi54W1gfKLejILwwxOWZvINXC4ViqeZjuRcds.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=684a3475bb119dded60790249428235b273d55bc", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/mzjpLNWi54W1gfKLejILwwxOWZvINXC4ViqeZjuRcds.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ecfd2125da458bf74f933f9323c15c227aebec34", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/mzjpLNWi54W1gfKLejILwwxOWZvINXC4ViqeZjuRcds.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43c7c5815dc486d61d74b2b089a4e098a9076311", "width": 320, "height": 320}], "variants": {}, "id": "gtJeIP7C-oK_pJrnq_xIjJoSKvc043IABr5lsGVE56E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b81nob", "is_robot_indexable": true, "report_reasons": null, "author": "visortelle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b81nob/what_do_you_think_about_oxia_a_new_highperformant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b81nob/what_do_you_think_about_oxia_a_new_highperformant/", "subreddit_subscribers": 166373, "created_utc": 1709736847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI have parquet files arriving at S3 regularly. So I created folder structure as root/yyyy/mm/dd/ and in the day I have multiple small parquet files.\nThe parquet file contain time series data.\nI want to generate a histogram in grafana for one of the columns.  How can efficiently achieve this. I cannot use grafana histogram plot because it requires all the rows. \nFor couple of days it's fine. But when I want to calculate over multiple months I get timeout error. And even in Athena it takes more than a minute to calculate the buckets and counts. What I was thinking is to use ctas command to create a table with  statistics for each column and insert or update the fields every day with stats from new data. Is this the correct approach?", "author_fullname": "t2_40nv3bcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions on using Athena ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7vmpd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709717500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI have parquet files arriving at S3 regularly. So I created folder structure as root/yyyy/mm/dd/ and in the day I have multiple small parquet files.\nThe parquet file contain time series data.\nI want to generate a histogram in grafana for one of the columns.  How can efficiently achieve this. I cannot use grafana histogram plot because it requires all the rows. \nFor couple of days it&amp;#39;s fine. But when I want to calculate over multiple months I get timeout error. And even in Athena it takes more than a minute to calculate the buckets and counts. What I was thinking is to use ctas command to create a table with  statistics for each column and insert or update the fields every day with stats from new data. Is this the correct approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b7vmpd", "is_robot_indexable": true, "report_reasons": null, "author": "nanosuituser", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7vmpd/need_suggestions_on_using_athena/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7vmpd/need_suggestions_on_using_athena/", "subreddit_subscribers": 166373, "created_utc": 1709717500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On your data team, if you were to implement a weekly meeting to demo new tools or techniques, what are some of the things you would want to see?", "author_fullname": "t2_h2e0l0gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Team meeting demo topics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7oap5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709692378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On your data team, if you were to implement a weekly meeting to demo new tools or techniques, what are some of the things you would want to see?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b7oap5", "is_robot_indexable": true, "report_reasons": null, "author": "curiosickly", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7oap5/team_meeting_demo_topics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7oap5/team_meeting_demo_topics/", "subreddit_subscribers": 166373, "created_utc": 1709692378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious what people use for translating various data formats. My team has been using gdal (python bindings) converting spatial (shapefile, geodabase) and non-spatial data (csv, json, excel). we are currently exploring other tools that could perform a similar function and that:\n\n1) has more readable code\n2) work with wide variety of data formats\n3) performant \n\n", "author_fullname": "t2_72w13hsg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data format translation tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7juwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709680473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious what people use for translating various data formats. My team has been using gdal (python bindings) converting spatial (shapefile, geodabase) and non-spatial data (csv, json, excel). we are currently exploring other tools that could perform a similar function and that:&lt;/p&gt;\n\n&lt;p&gt;1) has more readable code\n2) work with wide variety of data formats\n3) performant &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b7juwd", "is_robot_indexable": true, "report_reasons": null, "author": "sashathecrimean", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7juwd/data_format_translation_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7juwd/data_format_translation_tools/", "subreddit_subscribers": 166373, "created_utc": 1709680473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a new BA (have always been more IT-adjacent and hobbyist programmer) in a company with a very immature IT department and no data warehousing. \n\nWhat are some ways in which I can build applications for the team/department level that can utilize the stability of databases and move us away from running operations via Excel. Are there best practices or standard toolkits that I should look towards when building solutions?\n\nFrom a cursory search I saw that Docker + Python + Postgres may be an approach to consider, but as this is my first foray I wasn't sure if that is overengineering or even a standard approach, and didn't know whether there is a simpler tech stack that might be more business friendly / stable / easy to maintain.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_vkdfjfmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on architecting data solutions for newbie", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7i2u5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709676263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new BA (have always been more IT-adjacent and hobbyist programmer) in a company with a very immature IT department and no data warehousing. &lt;/p&gt;\n\n&lt;p&gt;What are some ways in which I can build applications for the team/department level that can utilize the stability of databases and move us away from running operations via Excel. Are there best practices or standard toolkits that I should look towards when building solutions?&lt;/p&gt;\n\n&lt;p&gt;From a cursory search I saw that Docker + Python + Postgres may be an approach to consider, but as this is my first foray I wasn&amp;#39;t sure if that is overengineering or even a standard approach, and didn&amp;#39;t know whether there is a simpler tech stack that might be more business friendly / stable / easy to maintain.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b7i2u5", "is_robot_indexable": true, "report_reasons": null, "author": "YoghurtDangerous893", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7i2u5/question_on_architecting_data_solutions_for_newbie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7i2u5/question_on_architecting_data_solutions_for_newbie/", "subreddit_subscribers": 166373, "created_utc": 1709676263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a pyspark dataframe that has a column with values in this format (read.json on json files):\n\n{50:{\"A\":3, \"B\":2}, 60:{\"A\":6, \"B\":5}} (This field is a StructField with StructTypes)\n\nI have been trying to figure out how to get the data into this format:\n\nColumns: |value|A|B|\n\n|\\[50,60\\]|\\[3,2\\]|\\[2,5\\]|\n\nThis is my immediate issue, but to those who are interested in even more of a challenge I actually have two columns with nested dictionaries:\n\ncolumn1| column2\n\n{50: {\"A\":3, \"B\":2}, 60:{\"A\":6, \"B\":5}} | {\"value\": 16:{certain\\_info1: 16}, \"value\": 60 : {certain\\_info1: 42}}\n\nmy ultimate goal is to have the data in this format\n\nColumns: |value|A|B|certain\\_info1|\n\n|60|6|5|42|\n\nTo be clear, the \"value\" info is not in the same order in the two columns, and the \"value\" info is not a key but the value TO a key in the second column.\n\nI have been banging my head on this all day. Would love some advice or help. Thanks!", "author_fullname": "t2_615382bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Grab Keys of a Nested Dictionary in a Pyspark Column? Put Them as Values in New Column?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7d4qw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709669891.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709664656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a pyspark dataframe that has a column with values in this format (read.json on json files):&lt;/p&gt;\n\n&lt;p&gt;{50:{&amp;quot;A&amp;quot;:3, &amp;quot;B&amp;quot;:2}, 60:{&amp;quot;A&amp;quot;:6, &amp;quot;B&amp;quot;:5}} (This field is a StructField with StructTypes)&lt;/p&gt;\n\n&lt;p&gt;I have been trying to figure out how to get the data into this format:&lt;/p&gt;\n\n&lt;p&gt;Columns: |value|A|B|&lt;/p&gt;\n\n&lt;p&gt;|[50,60]|[3,2]|[2,5]|&lt;/p&gt;\n\n&lt;p&gt;This is my immediate issue, but to those who are interested in even more of a challenge I actually have two columns with nested dictionaries:&lt;/p&gt;\n\n&lt;p&gt;column1| column2&lt;/p&gt;\n\n&lt;p&gt;{50: {&amp;quot;A&amp;quot;:3, &amp;quot;B&amp;quot;:2}, 60:{&amp;quot;A&amp;quot;:6, &amp;quot;B&amp;quot;:5}} | {&amp;quot;value&amp;quot;: 16:{certain_info1: 16}, &amp;quot;value&amp;quot;: 60 : {certain_info1: 42}}&lt;/p&gt;\n\n&lt;p&gt;my ultimate goal is to have the data in this format&lt;/p&gt;\n\n&lt;p&gt;Columns: |value|A|B|certain_info1|&lt;/p&gt;\n\n&lt;p&gt;|60|6|5|42|&lt;/p&gt;\n\n&lt;p&gt;To be clear, the &amp;quot;value&amp;quot; info is not in the same order in the two columns, and the &amp;quot;value&amp;quot; info is not a key but the value TO a key in the second column.&lt;/p&gt;\n\n&lt;p&gt;I have been banging my head on this all day. Would love some advice or help. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b7d4qw", "is_robot_indexable": true, "report_reasons": null, "author": "datatastic08200", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b7d4qw/how_to_grab_keys_of_a_nested_dictionary_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b7d4qw/how_to_grab_keys_of_a_nested_dictionary_in_a/", "subreddit_subscribers": 166373, "created_utc": 1709664656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi everyone! I hope you're all doing well.\n\nI'm working on a pipeline to scrape data from SofaScore. On average, I'll need to scrape 36 matches daily, requiring 72 total requests (two per match \u2013 one for statistics and one for highlights). To optimize this process, I'd like to parallelize the DAG execution.\n\nCould you advise on the best practices for this? Should I define a task for each match, or create two separate DAGs (one for statistics and one for highlights) and trigger them both for each match?", "author_fullname": "t2_b95a7eew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parallelize Tasks execution in Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b86dyj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709747926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I hope you&amp;#39;re all doing well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a pipeline to scrape data from SofaScore. On average, I&amp;#39;ll need to scrape 36 matches daily, requiring 72 total requests (two per match \u2013 one for statistics and one for highlights). To optimize this process, I&amp;#39;d like to parallelize the DAG execution.&lt;/p&gt;\n\n&lt;p&gt;Could you advise on the best practices for this? Should I define a task for each match, or create two separate DAGs (one for statistics and one for highlights) and trigger them both for each match?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b86dyj", "is_robot_indexable": true, "report_reasons": null, "author": "Ordinary_Run_2513", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b86dyj/parallelize_tasks_execution_in_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b86dyj/parallelize_tasks_execution_in_airflow/", "subreddit_subscribers": 166373, "created_utc": 1709747926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Over the past year or two I've set up a postgres product database for a small-medium sized business that I work for from scratch (and with no previous experience). On top of this, I've streamlined several very manual and time consuming jobs, originally in VBA but now more in Python. As I've progressed I've become increasingly anxious about the fact that I'm the only one who knows how our systems work, and given that I plan to leave the company within the next 5 years, that I'm carving out job requirements that will render my replacement too expensive for the company. How common are roles within the industry that require skills like SQL and Python (plus a bit of PL/pgSQL and VBA) that pay something like \u00a330000-40000 a year? And what are some best practices or considerations that I can put in place to future-proof my job role for after I've left?\n\nTo provide a bit more detail for my responsibilities, I have set up and I maintain a database full of our product data. This database is mostly queried for different formats of product data and pricing to share with customers. I'm also currently working on a Python project to maintain product-file associations and aid in managing product files (keeping directories clean, making sure naming conventions are followed, etc.). I would like to implement some further systems to maintain data quality across different platforms (eCommerce, finance systems, stock control systems, etc.). I would also like to make editing our product data easy for non-technical staff, as currently all updates are done through me using pgadmin. Lastly I would like to document how all of our systems interact as a whole, as currently everything is divided between our IT supplier, an in-house IT guy, external contractors who code systems for us, and me. Everything is currently glued together in a very ad-hoc fashion.\n\nI've taught myself all the skills I've used above as I've gone, but I'm still very inexperienced and so would really appreciate any guidance as to what kinds of technologies, practices and skills are appropriate for small-medium sized businesses, as well as if there is any standard procedure I should follow to identify business needs and communicate these to future employees, as I really don't want to leave an expensive mess behind that only I know how to operate.", "author_fullname": "t2_1b1qrwg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Concerns About the Future of My Position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b8657k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709747351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the past year or two I&amp;#39;ve set up a postgres product database for a small-medium sized business that I work for from scratch (and with no previous experience). On top of this, I&amp;#39;ve streamlined several very manual and time consuming jobs, originally in VBA but now more in Python. As I&amp;#39;ve progressed I&amp;#39;ve become increasingly anxious about the fact that I&amp;#39;m the only one who knows how our systems work, and given that I plan to leave the company within the next 5 years, that I&amp;#39;m carving out job requirements that will render my replacement too expensive for the company. How common are roles within the industry that require skills like SQL and Python (plus a bit of PL/pgSQL and VBA) that pay something like \u00a330000-40000 a year? And what are some best practices or considerations that I can put in place to future-proof my job role for after I&amp;#39;ve left?&lt;/p&gt;\n\n&lt;p&gt;To provide a bit more detail for my responsibilities, I have set up and I maintain a database full of our product data. This database is mostly queried for different formats of product data and pricing to share with customers. I&amp;#39;m also currently working on a Python project to maintain product-file associations and aid in managing product files (keeping directories clean, making sure naming conventions are followed, etc.). I would like to implement some further systems to maintain data quality across different platforms (eCommerce, finance systems, stock control systems, etc.). I would also like to make editing our product data easy for non-technical staff, as currently all updates are done through me using pgadmin. Lastly I would like to document how all of our systems interact as a whole, as currently everything is divided between our IT supplier, an in-house IT guy, external contractors who code systems for us, and me. Everything is currently glued together in a very ad-hoc fashion.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve taught myself all the skills I&amp;#39;ve used above as I&amp;#39;ve gone, but I&amp;#39;m still very inexperienced and so would really appreciate any guidance as to what kinds of technologies, practices and skills are appropriate for small-medium sized businesses, as well as if there is any standard procedure I should follow to identify business needs and communicate these to future employees, as I really don&amp;#39;t want to leave an expensive mess behind that only I know how to operate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8657k", "is_robot_indexable": true, "report_reasons": null, "author": "Patrick_Gently", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8657k/concerns_about_the_future_of_my_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8657k/concerns_about_the_future_of_my_position/", "subreddit_subscribers": 166373, "created_utc": 1709747351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do we have any resources to prepare for DE system design where a list covers most design, architectural patterns ?\n\nIf not, is anyone interested in building one ?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blind75 for DE system design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b864dd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709747297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do we have any resources to prepare for DE system design where a list covers most design, architectural patterns ?&lt;/p&gt;\n\n&lt;p&gt;If not, is anyone interested in building one ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b864dd", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b864dd/blind75_for_de_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b864dd/blind75_for_de_system_design/", "subreddit_subscribers": 166373, "created_utc": 1709747297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the work at my job is focused around a web scrapping | ETL | ML pipeline, where almost everything is implemented in PySpark, using DataFrames. I've recently started learning Scala for my masters. My feeling is that I should be able to significantly improve the performance of some kind of processes by migrating to Scala, but I don't know what to look for. \n\nMy guess is that any code that makes a significant use of udfs could use a migration. Does anyone have any specific benchmark numbers on this? Do you know of any other use cases, apart from this?", "author_fullname": "t2_2q8p8adc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any use cases for Scala over Python, using Spark with the DataFrame API?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b85yc5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709746912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the work at my job is focused around a web scrapping | ETL | ML pipeline, where almost everything is implemented in PySpark, using DataFrames. I&amp;#39;ve recently started learning Scala for my masters. My feeling is that I should be able to significantly improve the performance of some kind of processes by migrating to Scala, but I don&amp;#39;t know what to look for. &lt;/p&gt;\n\n&lt;p&gt;My guess is that any code that makes a significant use of udfs could use a migration. Does anyone have any specific benchmark numbers on this? Do you know of any other use cases, apart from this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b85yc5", "is_robot_indexable": true, "report_reasons": null, "author": "sepes_15", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b85yc5/are_there_any_use_cases_for_scala_over_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b85yc5/are_there_any_use_cases_for_scala_over_python/", "subreddit_subscribers": 166373, "created_utc": 1709746912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there anyone out there who was working in completely different domain such as some support project with 2.5+years of experience and with no skills similar to Data Engineering and who still managed to transition to Data Engineering. \n\nLooking for some guidance. Thanks in advance", "author_fullname": "t2_ib9mu62z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning to Data Engineering ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b85ecm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709745648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there anyone out there who was working in completely different domain such as some support project with 2.5+years of experience and with no skills similar to Data Engineering and who still managed to transition to Data Engineering. &lt;/p&gt;\n\n&lt;p&gt;Looking for some guidance. Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b85ecm", "is_robot_indexable": true, "report_reasons": null, "author": "iamDjsahu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b85ecm/transitioning_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b85ecm/transitioning_to_data_engineering/", "subreddit_subscribers": 166373, "created_utc": 1709745648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manage ELT pipelines with code using Terraform\u2019s Airbyte provider", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_1b85aca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/6VGrG8IGWWsP8Z02UcD_6_Q0t0NaEo-K4SE6yaOKQH4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709745411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/manage-elt-pipelines-with-code-using-terraforms-airbyte-provider-e79378fdf127", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?auto=webp&amp;s=cf86655bd61d6a3a06088068f437e3ca3e50a3a0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=71696f4e57702b28a45217fe20d3e51e5885c769", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a87930f8692bf7c62912703f33d5ed49a26e84b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c494717238f2162249a6bbec245cbc9f474a0e7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02dc5b2b48815da7a772c545ee455ec648d41547", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1b689f651293d226079fad1006b8c4d75b8cf293", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/xbWox5ita423JRSZvkvncSelwn5V-T7YYHS0l8PJRpo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9dfdef7d7f1b8b9a01380e61c64981409e9896a4", "width": 1080, "height": 540}], "variants": {}, "id": "tkLHq902eaapLbIpmEUFHv-tAT0X3T1xCPuPp4llr9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b85aca", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b85aca/manage_elt_pipelines_with_code_using_terraforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/manage-elt-pipelines-with-code-using-terraforms-airbyte-provider-e79378fdf127", "subreddit_subscribers": 166373, "created_utc": 1709745411.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}