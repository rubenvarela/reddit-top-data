{"kind": "Listing", "data": {"after": "t3_1b6jflr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI've been a data engineer for a few years now and I just dont think I have what it takes anymore.\n\nThe discipline requires immense concentration, and the amount that needs to be learned constantly has left me burned out. There's no end to it.\n\nI understand that every job has an element of constant learning, but I think it's the combination of the lack of acknowledgement of my work (a classic occurrence in data engineering I know), and the fact that despite the amount I've worked and learned, I still only earn slightly more than average (London wages/life are a scam). I have a lot of friends who work classic jobs (think estate agent, operations assistant, administration manager who earn just as much as I do, but the work and the skill involved is much less)\n\nTo cut a long story short, I'm looking for some encouragement or reasons to stay in the field if you could offer some. I was thinking of transitioning into a business analyst role or to become some kind of project manager, because my mental health is taking a big hit.\n\nThank you for reading.", "author_fullname": "t2_lovh9cgne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Giving up data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b67xnz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 133, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 133, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709548923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a data engineer for a few years now and I just dont think I have what it takes anymore.&lt;/p&gt;\n\n&lt;p&gt;The discipline requires immense concentration, and the amount that needs to be learned constantly has left me burned out. There&amp;#39;s no end to it.&lt;/p&gt;\n\n&lt;p&gt;I understand that every job has an element of constant learning, but I think it&amp;#39;s the combination of the lack of acknowledgement of my work (a classic occurrence in data engineering I know), and the fact that despite the amount I&amp;#39;ve worked and learned, I still only earn slightly more than average (London wages/life are a scam). I have a lot of friends who work classic jobs (think estate agent, operations assistant, administration manager who earn just as much as I do, but the work and the skill involved is much less)&lt;/p&gt;\n\n&lt;p&gt;To cut a long story short, I&amp;#39;m looking for some encouragement or reasons to stay in the field if you could offer some. I was thinking of transitioning into a business analyst role or to become some kind of project manager, because my mental health is taking a big hit.&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b67xnz", "is_robot_indexable": true, "report_reasons": null, "author": "Two_5536", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/", "subreddit_subscribers": 165886, "created_utc": 1709548923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I accepted an offer with a decent comp at a bank. Role is remote I started and got my work laptop mailed and have been going through on boarding. \n\nNow I've just gotten an offer from another company which I thought ghosted me and I'm in a bit of a dilemma. The offer is 60% more than my current comp. I'm not even questioning it tbh I am definitely going to accept, I know my current company can't match and of course they won't I literally just started. \n\nWhats my best course of action? Just tell them about the job? Bullshit something else (like medical issue) and say I can't work anymore?\n\nEdit: while the job is remote they did fly me out for my first week so I can meet the core team so that does add another insult when I leave. ", "author_fullname": "t2_cyr5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accepted an offer, 2 weeks later got dream offer from another company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ghh6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 124, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 124, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709573525.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709572757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I accepted an offer with a decent comp at a bank. Role is remote I started and got my work laptop mailed and have been going through on boarding. &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;ve just gotten an offer from another company which I thought ghosted me and I&amp;#39;m in a bit of a dilemma. The offer is 60% more than my current comp. I&amp;#39;m not even questioning it tbh I am definitely going to accept, I know my current company can&amp;#39;t match and of course they won&amp;#39;t I literally just started. &lt;/p&gt;\n\n&lt;p&gt;Whats my best course of action? Just tell them about the job? Bullshit something else (like medical issue) and say I can&amp;#39;t work anymore?&lt;/p&gt;\n\n&lt;p&gt;Edit: while the job is remote they did fly me out for my first week so I can meet the core team so that does add another insult when I leave. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6ghh6", "is_robot_indexable": true, "report_reasons": null, "author": "bigYman", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ghh6/accepted_an_offer_2_weeks_later_got_dream_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ghh6/accepted_an_offer_2_weeks_later_got_dream_offer/", "subreddit_subscribers": 165886, "created_utc": 1709572757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I help companies build and scale machine learning and analytics applications, with Spark being a core part of our data processing toolkit. While Python is generally the go-to language for data processing, libraries like Pandas &amp; NumPy come with a LOT of sharp edges. This is especially true if you're trying to read someone else's code. \n\nIMO Spark (&amp; PySpark) has an edge over other data processing tools for a few reasons: it reads more like SQL (making it a easier to understand without digging through obscure documentation), it's well-supported across cloud platforms, and it's dead simple to scale to handle any size data you need to throw at it.\n\nI wanted to create a resource that anyone with basic Python and SQL knowledge can use to get up and running quickly with Spark (you can probably learn 80% of what you need in a day or two). I also wanted to include some suggestions around code conventions to help with readability and avoiding gotchas that trip a lot of folks up (e.g. duplicating columns when doing joins).\n\nYou can get started with either a web notebook or locally with a batteries-included Docker container. \n\nYou can access it at [SparkMadeEasy.com](https://sparkmadeeasy.com/).\n\nThis is still a work-in-progress, with more topics to come (e.g. Spark-ML). Happy to hear any feedback!", "author_fullname": "t2_uyd9mc1b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an open-source microsite to help analysts and SQL-heavy devs get started with Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6dgsp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709571490.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709565598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I help companies build and scale machine learning and analytics applications, with Spark being a core part of our data processing toolkit. While Python is generally the go-to language for data processing, libraries like Pandas &amp;amp; NumPy come with a LOT of sharp edges. This is especially true if you&amp;#39;re trying to read someone else&amp;#39;s code. &lt;/p&gt;\n\n&lt;p&gt;IMO Spark (&amp;amp; PySpark) has an edge over other data processing tools for a few reasons: it reads more like SQL (making it a easier to understand without digging through obscure documentation), it&amp;#39;s well-supported across cloud platforms, and it&amp;#39;s dead simple to scale to handle any size data you need to throw at it.&lt;/p&gt;\n\n&lt;p&gt;I wanted to create a resource that anyone with basic Python and SQL knowledge can use to get up and running quickly with Spark (you can probably learn 80% of what you need in a day or two). I also wanted to include some suggestions around code conventions to help with readability and avoiding gotchas that trip a lot of folks up (e.g. duplicating columns when doing joins).&lt;/p&gt;\n\n&lt;p&gt;You can get started with either a web notebook or locally with a batteries-included Docker container. &lt;/p&gt;\n\n&lt;p&gt;You can access it at &lt;a href=\"https://sparkmadeeasy.com/\"&gt;SparkMadeEasy.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;This is still a work-in-progress, with more topics to come (e.g. Spark-ML). Happy to hear any feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6dgsp", "is_robot_indexable": true, "report_reasons": null, "author": "zchtsk", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6dgsp/i_created_an_opensource_microsite_to_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6dgsp/i_created_an_opensource_microsite_to_help/", "subreddit_subscribers": 165886, "created_utc": 1709565598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why do data warehouses usually use tools like snowflake, BigQuery, etc? Couldn't they just use regular SQL databases like PostgreSQL or MySQL?", "author_fullname": "t2_tfmsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could regular databases be used in data warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b68gbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709550891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why do data warehouses usually use tools like snowflake, BigQuery, etc? Couldn&amp;#39;t they just use regular SQL databases like PostgreSQL or MySQL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b68gbb", "is_robot_indexable": true, "report_reasons": null, "author": "DanteIsBack", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b68gbb/could_regular_databases_be_used_in_data_warehouses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b68gbb/could_regular_databases_be_used_in_data_warehouses/", "subreddit_subscribers": 165886, "created_utc": 1709550891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB vs Polars - Thunderdome. 16GB on 4GB machine Challenge.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6cit9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Svhr6NvgsWl6waTwFmf_nAjL2WUOo8md6NzezDK14Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709563296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/duckdb-vs-polars-thunderdome", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?auto=webp&amp;s=b4a8e242d446aae1036387391700f0aabd59d711", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9e41e77a1a626e46ede2193743a478491b672f9", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=05d57e59619c7f14c81472cbb98bc9b9d294ae4e", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63e67f98f88582af1ef591d1ad1a17b1b9416872", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e385565c14dd165c96841dd34329ddf8125f54c", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/XnHpEJY2OwTBvJvdUhPeGfJG1DZ1qgy7QTlyTu1OCBM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36ac2596b5f88b7cf188f2f8c71b8f88ce6ad291", "width": 960, "height": 562}], "variants": {}, "id": "AGIJ8LXJRs-Gx1gN_z0Bvyhy42cce5TV-f-S_Opo_f8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6cit9", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6cit9/duckdb_vs_polars_thunderdome_16gb_on_4gb_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/duckdb-vs-polars-thunderdome", "subreddit_subscribers": 165886, "created_utc": 1709563296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have implemented a large scale project for a hospital and the entire infrastructure was built on Azure. I set up the ELT pipelines using ADF and pyspark(for data manipulation and enrichment) and the company created API endpoints around their data sources. And so I used to extract data from the API and load it into a data lake. I then use this weekly generated data to create a dashboard which then auto refreshes weekly. I've never had to use SQL and even if I did have to use it, OpenAI's GPT-4-Turbo-preview model via the API has been absolutely great. \n\nNot to mention that I do know basics of SQL, doing transformations, Window functions, etc. But since OpenAI was able to write the queries exactly how I needed it, I wanted to know if it is worth investing significant amount of time to master SQL.  Yes, OpenAI may get expensive and I need to kno0w when to step in to get the correct O/P, but whenever I put in the schema, what I want, and an example of input and output, it gets the query right 95% of the time in the first go. So is it worth going into advanced SQL or to learn more about the different technologies involved in DE? Any advice would be great, thank you!", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Important is SQL for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6iw84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709578443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have implemented a large scale project for a hospital and the entire infrastructure was built on Azure. I set up the ELT pipelines using ADF and pyspark(for data manipulation and enrichment) and the company created API endpoints around their data sources. And so I used to extract data from the API and load it into a data lake. I then use this weekly generated data to create a dashboard which then auto refreshes weekly. I&amp;#39;ve never had to use SQL and even if I did have to use it, OpenAI&amp;#39;s GPT-4-Turbo-preview model via the API has been absolutely great. &lt;/p&gt;\n\n&lt;p&gt;Not to mention that I do know basics of SQL, doing transformations, Window functions, etc. But since OpenAI was able to write the queries exactly how I needed it, I wanted to know if it is worth investing significant amount of time to master SQL.  Yes, OpenAI may get expensive and I need to kno0w when to step in to get the correct O/P, but whenever I put in the schema, what I want, and an example of input and output, it gets the query right 95% of the time in the first go. So is it worth going into advanced SQL or to learn more about the different technologies involved in DE? Any advice would be great, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6iw84", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6iw84/how_important_is_sql_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6iw84/how_important_is_sql_for_data_engineers/", "subreddit_subscribers": 165886, "created_utc": 1709578443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI have 2 offers and don't know what to do?!\n\n1. the first offer : lower salary , they are mostly using SAS DI for ETL (which is my concern as It's legacy and would limit where I could grow as a data engineer-at least this my understanding-), but the team is more organized and have good structure with team lead with experience more than 10 years and DE seniors where i can learn from.\n2. the second offer has better salary and benefits, stack is spark and python and on-prem Hadoop cluster, using Nifi and python code for ETL pipelines, the team will only be one other than me with the same experience, the team is big but mostly focused on data analysis and data science.\n\nmy concern with the second offer is that there won't be someone with a lot more experience to learn from, is that critical or can I work on that myself even if it requires more effort.\n\n&amp;#x200B;\n\ncurrent experience 2 years in DE/data analysis using python, snowflake and Azure data factory.\n\nIt would be desirable to land a remote job in Europe or to be hired there in the future so which is better to pursue in terms of career and skills?  \n\n\nsorry for the wordy post, I appreciate any advice on this.\n\nthank you", "author_fullname": "t2_1kvyym2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice with next move", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6b2sa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709559465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I have 2 offers and don&amp;#39;t know what to do?!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;the first offer : lower salary , they are mostly using SAS DI for ETL (which is my concern as It&amp;#39;s legacy and would limit where I could grow as a data engineer-at least this my understanding-), but the team is more organized and have good structure with team lead with experience more than 10 years and DE seniors where i can learn from.&lt;/li&gt;\n&lt;li&gt;the second offer has better salary and benefits, stack is spark and python and on-prem Hadoop cluster, using Nifi and python code for ETL pipelines, the team will only be one other than me with the same experience, the team is big but mostly focused on data analysis and data science.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;my concern with the second offer is that there won&amp;#39;t be someone with a lot more experience to learn from, is that critical or can I work on that myself even if it requires more effort.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;current experience 2 years in DE/data analysis using python, snowflake and Azure data factory.&lt;/p&gt;\n\n&lt;p&gt;It would be desirable to land a remote job in Europe or to be hired there in the future so which is better to pursue in terms of career and skills?  &lt;/p&gt;\n\n&lt;p&gt;sorry for the wordy post, I appreciate any advice on this.&lt;/p&gt;\n\n&lt;p&gt;thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6b2sa", "is_robot_indexable": true, "report_reasons": null, "author": "ossama59", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6b2sa/career_advice_with_next_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6b2sa/career_advice_with_next_move/", "subreddit_subscribers": 165886, "created_utc": 1709559465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading some older posts in this sub about working with legacy systems for your first role, and one thread was all in on the idea that your first job is the most important job for setting the stage of your career, and to switch if your work if all Excel files and legacy database management.\n\nI thought, of course every role is important, but are you doomed to fail if your first job isn't exactly what you wanted? Especially in the current market where everyone would take whatever they can get?\n\nIt's a little discouraging for me because I turned down an offer to work with an AWS stack for my first job, to instead work for a huge corporate with amazing benefits but Access/Excel/SQL server stack. At the very least, the company is very well known and respected in my area, and one of my primary responsibilities is using Python and SQL to replace our ancient VBA and Access macros, so I think I'm getting relevant experience for marketable skills. \n\nIs your first job really all that important, especially if you plan on job hopping? Is there hope for data analysts/engineers working with legacy systems to make the jump into a modern cloud stack 1-2 yrs later?", "author_fullname": "t2_tt7gml0lp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is your first role for the trajectory of your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6vwta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709611409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading some older posts in this sub about working with legacy systems for your first role, and one thread was all in on the idea that your first job is the most important job for setting the stage of your career, and to switch if your work if all Excel files and legacy database management.&lt;/p&gt;\n\n&lt;p&gt;I thought, of course every role is important, but are you doomed to fail if your first job isn&amp;#39;t exactly what you wanted? Especially in the current market where everyone would take whatever they can get?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a little discouraging for me because I turned down an offer to work with an AWS stack for my first job, to instead work for a huge corporate with amazing benefits but Access/Excel/SQL server stack. At the very least, the company is very well known and respected in my area, and one of my primary responsibilities is using Python and SQL to replace our ancient VBA and Access macros, so I think I&amp;#39;m getting relevant experience for marketable skills. &lt;/p&gt;\n\n&lt;p&gt;Is your first job really all that important, especially if you plan on job hopping? Is there hope for data analysts/engineers working with legacy systems to make the jump into a modern cloud stack 1-2 yrs later?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6vwta", "is_robot_indexable": true, "report_reasons": null, "author": "date_uh", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6vwta/how_important_is_your_first_role_for_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6vwta/how_important_is_your_first_role_for_the/", "subreddit_subscribers": 165886, "created_utc": 1709611409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to run some basic checks on our data in a fairly generic way. Basically, passing a table (or view) and a list of fields for dims and list of fields for measures \n\nAnd have it slice by each dimension for each measure to see if there is anything that is greater than X number of standard deviations compared to same day last week or compared to rolling week average, for example. \n\nWe randomly encounter data quality issues for metrics within a certain dimension which isn't caught by more high level checks. \n\nExample, for our Transactions fact table, we stopped received Refunds for a specific product type. At the high level, it was almost impossible to see any deviation when charted. but when split by different dimensions, the anomaly immediately pops up. \n\nexample trendline for Refund count for Product XYZ\n\n3/1  : 200\n\n3/2 : 250\n\n3/3: 190\n\n3/4: 0   -- or tiny number like 7\n\nWe're on SQL Server/AWS Redshift. I might do something in dynamic sql to handle this but is there a \\*free\\* solution out there? Don't actually need anything really sophisticated, we're a small company.\n\nWe're not on dbt, but can dbt generic tests help with this? \n\nThere's a few python related solutions that I've looked at, as well but would prefer to do the analysis on the DB engine for larger datasets. \n\n* [https://github.com/ydataai/ydata-profiling](https://github.com/ydataai/ydata-profiling)", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick and easy anomaly detection in SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6rkhb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709599448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to run some basic checks on our data in a fairly generic way. Basically, passing a table (or view) and a list of fields for dims and list of fields for measures &lt;/p&gt;\n\n&lt;p&gt;And have it slice by each dimension for each measure to see if there is anything that is greater than X number of standard deviations compared to same day last week or compared to rolling week average, for example. &lt;/p&gt;\n\n&lt;p&gt;We randomly encounter data quality issues for metrics within a certain dimension which isn&amp;#39;t caught by more high level checks. &lt;/p&gt;\n\n&lt;p&gt;Example, for our Transactions fact table, we stopped received Refunds for a specific product type. At the high level, it was almost impossible to see any deviation when charted. but when split by different dimensions, the anomaly immediately pops up. &lt;/p&gt;\n\n&lt;p&gt;example trendline for Refund count for Product XYZ&lt;/p&gt;\n\n&lt;p&gt;3/1  : 200&lt;/p&gt;\n\n&lt;p&gt;3/2 : 250&lt;/p&gt;\n\n&lt;p&gt;3/3: 190&lt;/p&gt;\n\n&lt;p&gt;3/4: 0   -- or tiny number like 7&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on SQL Server/AWS Redshift. I might do something in dynamic sql to handle this but is there a *free* solution out there? Don&amp;#39;t actually need anything really sophisticated, we&amp;#39;re a small company.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re not on dbt, but can dbt generic tests help with this? &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a few python related solutions that I&amp;#39;ve looked at, as well but would prefer to do the analysis on the DB engine for larger datasets. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/ydataai/ydata-profiling\"&gt;https://github.com/ydataai/ydata-profiling&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?auto=webp&amp;s=d9b5b8ff273ef55984d2b84516414d5c742b7d54", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddc17a5b476dc4bc9bc7850d45241b871daafed4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ab3f9f5002a95c0088b661d27161fad11eb6b24", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a13390688cd5bfa2f8fdf3a5d5b79712c981468", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9a9b4164cc9a9f7e673f4a12dee7455c6ea6581", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=008a7d36e1ad1d7b587e8485d7a644e1915132ab", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6868bfb85e1dfc49222eeb75205ccc128034336", "width": 1080, "height": 540}], "variants": {}, "id": "twBVkMc_k1BYnGPSPsroeGloYvtLSGEcNAiOHgXdwEQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6rkhb", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6rkhb/quick_and_easy_anomaly_detection_in_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6rkhb/quick_and_easy_anomaly_detection_in_sql/", "subreddit_subscribers": 165886, "created_utc": 1709599448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I'm a software developer that want to try data engineering.  \nI'm attending Data Engineering Zoomcamp by [Datatalks.club](https://Datatalks.club). I just complete the week 5 about batch data processing. I just want to elaborate my knowledge from orchestration ([mage.ai](http://mage.ai/)) and spark (or pyspark whatever).  \nI want to know, is it possible to dockerize [mage.ai](http://mage.ai/) and spark? because in the material spark only running on local machine.", "author_fullname": "t2_2lvigk1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to dockerize spark and mage.ai", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b69w5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709555825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m a software developer that want to try data engineering.&lt;br/&gt;\nI&amp;#39;m attending Data Engineering Zoomcamp by &lt;a href=\"https://Datatalks.club\"&gt;Datatalks.club&lt;/a&gt;. I just complete the week 5 about batch data processing. I just want to elaborate my knowledge from orchestration (&lt;a href=\"http://mage.ai/\"&gt;mage.ai&lt;/a&gt;) and spark (or pyspark whatever).&lt;br/&gt;\nI want to know, is it possible to dockerize &lt;a href=\"http://mage.ai/\"&gt;mage.ai&lt;/a&gt; and spark? because in the material spark only running on local machine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?auto=webp&amp;s=55508cb4a6b874b5e37fb7a170c14ef80487d34a", "width": 1032, "height": 525}, "resolutions": [{"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e0506d70e4b9f19621088472046f607e0ba8a98", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e15327ab0f10ac05a6fbe11716943248cd455b8", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0209ccd362987edc89a8e99578c1678c0ed89bd5", "width": 320, "height": 162}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d7c5620225f62e43b180c1b88c3f0278dc5b01ec", "width": 640, "height": 325}, {"url": "https://external-preview.redd.it/RX7NPI1LRCmKmku-uH9PE-BpcXUt5F-py9R0Dp5dhME.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=225bf591f1c42dc8b05b34b3d75b6662896814c1", "width": 960, "height": 488}], "variants": {}, "id": "YfWijtKzkVKJWYfcR7I0BVyJCG-El7IkWyz6doaqagU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b69w5a", "is_robot_indexable": true, "report_reasons": null, "author": "muh_ilhamfajar", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b69w5a/how_to_dockerize_spark_and_mageai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b69w5a/how_to_dockerize_spark_and_mageai/", "subreddit_subscribers": 165886, "created_utc": 1709555825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have data coming from an API for the buses running daily within the country. The data for a particular bus looks like this:\n\n    [{'busNumber': 1,\n    'departureDate': '2024-01-01',\n    'operatorCode': 1,\n    'busType': 'ev',\n    'busCategory': 'Long-distance',\n    'timeTableRows': [{'stationCode': 'B01',\n                       'type': 'DEPARTURE',     \n                       'busStopping': True,     \n                       'confirmedStop': True,   \n                       'scheduledTime': '2024-01-01T12:24:00.000Z',     \n                       'actualTime': '2024-01-01T12:24:58.000Z'},\n                      {'stationCode': 'B02',     \n                       'type': 'ARRIVAL',     \n                       'busStopping': True,     \n                       'confirmedStop': True,  \n                       'scheduledTime': '2024-01-01T12:29:00.000Z',     \n                       'actualTime': '2024-01-01T12:30:53.000Z'}\n                     ]\n\nI understand that because of the already present structure, relational db like postgres, mySQL would be the best databases. But, can this data be considered like a timeseries and be stored in NoSQL databases like Cassandra/HBase?", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can data fetched on a per day basis be treated like timeseries data and stored in Cassandra/HBase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b67asb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709546487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have data coming from an API for the buses running daily within the country. The data for a particular bus looks like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[{&amp;#39;busNumber&amp;#39;: 1,\n&amp;#39;departureDate&amp;#39;: &amp;#39;2024-01-01&amp;#39;,\n&amp;#39;operatorCode&amp;#39;: 1,\n&amp;#39;busType&amp;#39;: &amp;#39;ev&amp;#39;,\n&amp;#39;busCategory&amp;#39;: &amp;#39;Long-distance&amp;#39;,\n&amp;#39;timeTableRows&amp;#39;: [{&amp;#39;stationCode&amp;#39;: &amp;#39;B01&amp;#39;,\n                   &amp;#39;type&amp;#39;: &amp;#39;DEPARTURE&amp;#39;,     \n                   &amp;#39;busStopping&amp;#39;: True,     \n                   &amp;#39;confirmedStop&amp;#39;: True,   \n                   &amp;#39;scheduledTime&amp;#39;: &amp;#39;2024-01-01T12:24:00.000Z&amp;#39;,     \n                   &amp;#39;actualTime&amp;#39;: &amp;#39;2024-01-01T12:24:58.000Z&amp;#39;},\n                  {&amp;#39;stationCode&amp;#39;: &amp;#39;B02&amp;#39;,     \n                   &amp;#39;type&amp;#39;: &amp;#39;ARRIVAL&amp;#39;,     \n                   &amp;#39;busStopping&amp;#39;: True,     \n                   &amp;#39;confirmedStop&amp;#39;: True,  \n                   &amp;#39;scheduledTime&amp;#39;: &amp;#39;2024-01-01T12:29:00.000Z&amp;#39;,     \n                   &amp;#39;actualTime&amp;#39;: &amp;#39;2024-01-01T12:30:53.000Z&amp;#39;}\n                 ]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I understand that because of the already present structure, relational db like postgres, mySQL would be the best databases. But, can this data be considered like a timeseries and be stored in NoSQL databases like Cassandra/HBase?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b67asb", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b67asb/can_data_fetched_on_a_per_day_basis_be_treated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b67asb/can_data_fetched_on_a_per_day_basis_be_treated/", "subreddit_subscribers": 165886, "created_utc": 1709546487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nTrying to give guidance to a company in mid market 600 FTE. They have heard about Mage AI and are interested in it. Any experiences with it? Does it solve certain problems that Airflow/Prefect/Astronomer doesn\u2019t? ", "author_fullname": "t2_putygiix7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mage AI experiences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6k06l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709581113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Trying to give guidance to a company in mid market 600 FTE. They have heard about Mage AI and are interested in it. Any experiences with it? Does it solve certain problems that Airflow/Prefect/Astronomer doesn\u2019t? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6k06l", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantParty6489", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6k06l/mage_ai_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6k06l/mage_ai_experiences/", "subreddit_subscribers": 165886, "created_utc": 1709581113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nUp until recently, I was a Sr DE at FAANG (7YOE). However, I was part of the recent layoffs and found myself contemplating my next steps sooner than expected. To add a twist to the plot, I just tore my achilles tendon playing basketball, which means I'll be spending quite a bit of time on my butt at home recovering. Not exactly the kind of break I had in mind, but here we are.\n\nPost layoff, I was already planning to take a significant break to reset and figure out what I want to do next. The injury just extended this timeline a bit. I'm pretty comfortable with the Leetcode grind, system design, and all that jazz. But for this break, I want to focus on learning and exploring - diving into new tech, maybe picking up some skills that are just for fun, and generally getting reinvigorated about the field.\n\nI've spent a good part of my career leading projects, primarily working with AWS, Python, SQL, mainly with ETL platforms. While I'm pondering whether to return to FAANG or venture into something smaller where I can have a bigger impact (perhaps lead a larger team), I'm not quite sure where to direct my learning energy.\n\nSo, I'm reaching out for suggestions on how to make the most of this time. Are there any books, courses, or personal projects you would recommend? Any emerging tech or tools I should get my hands on? Or perhaps some advice on making a transition that could allow me to be more impactful and fulfill my desire to work closely with a team?\n\nI'm all ears and really appreciate any thoughts or guidance you can share. Thank you!", "author_fullname": "t2_1swxdf76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice for a Sr DE's Learning Journey Post-FAANG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6fxq9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709571506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;Up until recently, I was a Sr DE at FAANG (7YOE). However, I was part of the recent layoffs and found myself contemplating my next steps sooner than expected. To add a twist to the plot, I just tore my achilles tendon playing basketball, which means I&amp;#39;ll be spending quite a bit of time on my butt at home recovering. Not exactly the kind of break I had in mind, but here we are.&lt;/p&gt;\n\n&lt;p&gt;Post layoff, I was already planning to take a significant break to reset and figure out what I want to do next. The injury just extended this timeline a bit. I&amp;#39;m pretty comfortable with the Leetcode grind, system design, and all that jazz. But for this break, I want to focus on learning and exploring - diving into new tech, maybe picking up some skills that are just for fun, and generally getting reinvigorated about the field.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve spent a good part of my career leading projects, primarily working with AWS, Python, SQL, mainly with ETL platforms. While I&amp;#39;m pondering whether to return to FAANG or venture into something smaller where I can have a bigger impact (perhaps lead a larger team), I&amp;#39;m not quite sure where to direct my learning energy.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m reaching out for suggestions on how to make the most of this time. Are there any books, courses, or personal projects you would recommend? Any emerging tech or tools I should get my hands on? Or perhaps some advice on making a transition that could allow me to be more impactful and fulfill my desire to work closely with a team?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m all ears and really appreciate any thoughts or guidance you can share. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6fxq9", "is_robot_indexable": true, "report_reasons": null, "author": "hairbear1234", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6fxq9/seeking_advice_for_a_sr_des_learning_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6fxq9/seeking_advice_for_a_sr_des_learning_journey/", "subreddit_subscribers": 165886, "created_utc": 1709571506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's \"Modern\" in the Modern Data Stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1b69inb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/q1egZ4ZVa1gwL3t7A4aLCoGrcZaxl44lTpI-gSfCqY4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709554605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/whats-modern-in-the-modern-data-stack", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?auto=webp&amp;s=99929a7c3b23b09f4937a54adca9f06e69f0a8f4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6379b2d37eb79f77b5c016a93186f471855a4734", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46f7430807195c599b95cee1927fd6eae8e9f15f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=74c303178f071c6c6c8a5d9a543da50dd5b727c1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aac42f5f61e174f72a4bb47815326b1c59a97914", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=73d224331b54e3000ce208078154f8f55c6bf154", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/TfzPl-X8Mywwxe4PwYPpogSdXKtIZPrS6JzsdD-Ckug.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=51d6ee39e2a410d4af83c04a9f8600e1674e6778", "width": 1080, "height": 540}], "variants": {}, "id": "2OHr9EogUDUSkv0pbBvY1Y2IP6gjwsgfB-3Jot5YbVc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b69inb", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b69inb/whats_modern_in_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/whats-modern-in-the-modern-data-stack", "subreddit_subscribers": 165886, "created_utc": 1709554605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Erwin can reverse engineer a view but it doesn't seem to handle CASE statements and errors out. This is for Hive. Does anyone know if reverse engineering of views can handle CASE statements?", "author_fullname": "t2_kkmygn8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse engineering using Erwin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ndyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709589281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Erwin can reverse engineer a view but it doesn&amp;#39;t seem to handle CASE statements and errors out. This is for Hive. Does anyone know if reverse engineering of views can handle CASE statements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6ndyb", "is_robot_indexable": true, "report_reasons": null, "author": "KarmicDharmic", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ndyb/reverse_engineering_using_erwin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ndyb/reverse_engineering_using_erwin/", "subreddit_subscribers": 165886, "created_utc": 1709589281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI'm looking for some advice and I'm hoping this is the right spot. \n\n&amp;#x200B;\n\nI've recently started a new role as a Machine Learning Engineer for a R&amp;D team focusing on computer vision applications. It has become clear that the biggest weakness in our operation stems from our approach to data. We have \\~terabytes of proprietary image and video data in various formats and no system to efficiently process and label it.  I have been assigned the task of developing a data pipeline to curate custom datasets for our CV models but I don't have any real expertise in data engineering other than some experience with SQL/NoSQL databases. \n\n&amp;#x200B;\n\nI'm aware that a team of dedicated Data Engineers is really what's required for such a task but unfortunately I am the only one available to work on this problem. With that in mind, I'd very much appreciate any guidance on the following: \n\n1. What resources are available for learning Data Engineering for CV? I have spent a lot of time researching this area now but most resources that I've come across really only focus on structured tabular data. I haven't come across any resource that discusses best practices when dealing with video or image data. \n2. How do I decide on what tools to use? I am overwhelmed by the choice of tools relating to the 'modern data stack'. I have come across Activeloop's DeepLake which seems promising but then Delta Lake seems to be more popular. Do I even need a Lakehouse architecture? \n3. I have set up CVAT for image annotation with semi-automatic labelling to improve efficiency. Are there better tools out there for labelling? I have seen LabelBox mentioned as a viable alternative. \n\n&amp;#x200B;\n\nOf course I have many other questions but I'll keep this short as the main thing I'm looking for is advice on how to improve and learn. Any information would be much appreciated! ", "author_fullname": "t2_a1k94kfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering for Computer Vision - Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6kgk6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709582238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some advice and I&amp;#39;m hoping this is the right spot. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started a new role as a Machine Learning Engineer for a R&amp;amp;D team focusing on computer vision applications. It has become clear that the biggest weakness in our operation stems from our approach to data. We have ~terabytes of proprietary image and video data in various formats and no system to efficiently process and label it.  I have been assigned the task of developing a data pipeline to curate custom datasets for our CV models but I don&amp;#39;t have any real expertise in data engineering other than some experience with SQL/NoSQL databases. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that a team of dedicated Data Engineers is really what&amp;#39;s required for such a task but unfortunately I am the only one available to work on this problem. With that in mind, I&amp;#39;d very much appreciate any guidance on the following: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What resources are available for learning Data Engineering for CV? I have spent a lot of time researching this area now but most resources that I&amp;#39;ve come across really only focus on structured tabular data. I haven&amp;#39;t come across any resource that discusses best practices when dealing with video or image data. &lt;/li&gt;\n&lt;li&gt;How do I decide on what tools to use? I am overwhelmed by the choice of tools relating to the &amp;#39;modern data stack&amp;#39;. I have come across Activeloop&amp;#39;s DeepLake which seems promising but then Delta Lake seems to be more popular. Do I even need a Lakehouse architecture? &lt;/li&gt;\n&lt;li&gt;I have set up CVAT for image annotation with semi-automatic labelling to improve efficiency. Are there better tools out there for labelling? I have seen LabelBox mentioned as a viable alternative. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Of course I have many other questions but I&amp;#39;ll keep this short as the main thing I&amp;#39;m looking for is advice on how to improve and learn. Any information would be much appreciated! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6kgk6", "is_robot_indexable": true, "report_reasons": null, "author": "distracted-ferret", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6kgk6/data_engineering_for_computer_vision_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6kgk6/data_engineering_for_computer_vision_advice/", "subreddit_subscribers": 165886, "created_utc": 1709582238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nWe made a tool for BigQuery users. You can generate a view from a JSON object if you are storing your data as us in a JSON field, it's very useful!\n\nAny feedback is welcome! :)\n\nThe tool is here: [https://vg.persio.io](https://vg.persio.io)", "author_fullname": "t2_1mwhn72z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free RAW Json to View tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6i9st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709580170.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709576950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;We made a tool for BigQuery users. You can generate a view from a JSON object if you are storing your data as us in a JSON field, it&amp;#39;s very useful!&lt;/p&gt;\n\n&lt;p&gt;Any feedback is welcome! :)&lt;/p&gt;\n\n&lt;p&gt;The tool is here: &lt;a href=\"https://vg.persio.io\"&gt;https://vg.persio.io&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?auto=webp&amp;s=5e69c52008196472a67548003a28f8f20d609d3b", "width": 878, "height": 460}, "resolutions": [{"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f75eb1a72319934c5328dd4c88160047a46ebfc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61e2acfe92daa0f3277fe698099d56f6738b5c23", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47742f25f6f66e00357e66fb8567f3b30e58c0fa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=19fa8ef1b854a514192bdd51e9b6981d77bc8bc6", "width": 640, "height": 335}], "variants": {}, "id": "5z7wVcO2sxef0OZxRjwC5Wp8rwhxWzWvcKNb8uUTPeI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6i9st", "is_robot_indexable": true, "report_reasons": null, "author": "pigri", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6i9st/free_raw_json_to_view_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6i9st/free_raw_json_to_view_tool/", "subreddit_subscribers": 165886, "created_utc": 1709576950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this is common but wanted to hear any success stories from anyone who applied to role that were under qualified for but got the job and killed it.\n\nBeen looking at [Sr.Data](https://Sr.Data) Eng roles and I just get so intimated with the list of technologies they expect you to manage. All I really do is write up stored procs in BQ to create a dimensional model then throw it in a DAG for orchestration.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intimidated and discouraged by Job Description", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b6ydx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709619391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is common but wanted to hear any success stories from anyone who applied to role that were under qualified for but got the job and killed it.&lt;/p&gt;\n\n&lt;p&gt;Been looking at &lt;a href=\"https://Sr.Data\"&gt;Sr.Data&lt;/a&gt; Eng roles and I just get so intimated with the list of technologies they expect you to manage. All I really do is write up stored procs in BQ to create a dimensional model then throw it in a DAG for orchestration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6ydx2", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ydx2/intimidated_and_discouraged_by_job_description/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ydx2/intimidated_and_discouraged_by_job_description/", "subreddit_subscribers": 165886, "created_utc": 1709619391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I am just starting my DE journey. I currently have Ubuntu on Docker on my PC, with python, related libraries, and dbt core setup. I want to move this to a dedicated always-on machine.\n\nWill an HP Elitedesk 800 G4 or G5 Mini with 32 GB RAM be enough for this? I was reading online that many users were having issues installing Linux on the Prodesks and Elitedesks. Does anybody here have any experience with these machines?", "author_fullname": "t2_gahqegkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HP Elitedesk/Prodesk Mini as Dev Machine for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6x6du", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709615382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am just starting my DE journey. I currently have Ubuntu on Docker on my PC, with python, related libraries, and dbt core setup. I want to move this to a dedicated always-on machine.&lt;/p&gt;\n\n&lt;p&gt;Will an HP Elitedesk 800 G4 or G5 Mini with 32 GB RAM be enough for this? I was reading online that many users were having issues installing Linux on the Prodesks and Elitedesks. Does anybody here have any experience with these machines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6x6du", "is_robot_indexable": true, "report_reasons": null, "author": "wandering-and_lost", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6x6du/hp_elitedeskprodesk_mini_as_dev_machine_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6x6du/hp_elitedeskprodesk_mini_as_dev_machine_for_de/", "subreddit_subscribers": 165886, "created_utc": 1709615382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have configured a local environment that consists of the following containers:\n\n* Trino\n* Hive\n* Minio\n\nI have successfully set up these three containers to create and query external tables using Trino, which are stored in the Hive Metastore and on Minio as Parquet.   This all works great for me.\n\nHowever, when I try to drop the table in Trino that I created, I get this error:\n\n&gt;Access Denied: Cannot drop table schema.tablename io.trino.spi.security.AccessDeniedException: Access Denied: Cannot drop table schema.tablename\n\nThis doesn't make any sense because there is no user setup in Hive Metastore, nor security setup.  If I connect to the Hive metastore using Beeline, I can drop the table with no problem.\n\nDo you have any clue why Trino is unable to drop the table?", "author_fullname": "t2_l04by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cannot drop table in Trino using Hive connector for no good reason", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6woqe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709613842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have configured a local environment that consists of the following containers:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Trino&lt;/li&gt;\n&lt;li&gt;Hive&lt;/li&gt;\n&lt;li&gt;Minio&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have successfully set up these three containers to create and query external tables using Trino, which are stored in the Hive Metastore and on Minio as Parquet.   This all works great for me.&lt;/p&gt;\n\n&lt;p&gt;However, when I try to drop the table in Trino that I created, I get this error:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Access Denied: Cannot drop table schema.tablename io.trino.spi.security.AccessDeniedException: Access Denied: Cannot drop table schema.tablename&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This doesn&amp;#39;t make any sense because there is no user setup in Hive Metastore, nor security setup.  If I connect to the Hive metastore using Beeline, I can drop the table with no problem.&lt;/p&gt;\n\n&lt;p&gt;Do you have any clue why Trino is unable to drop the table?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6woqe", "is_robot_indexable": true, "report_reasons": null, "author": "kentmaxwell", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6woqe/cannot_drop_table_in_trino_using_hive_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6woqe/cannot_drop_table_in_trino_using_hive_connector/", "subreddit_subscribers": 165886, "created_utc": 1709613842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The business I work for needs to replicate a database server (MySQL) (in our AWS infrastructure) to another DB server (MySQL) in a customer's AWS infrastructure over the internet. Originally they wanted log shipping however that's not feasible given that the machines are not locally connected.\n\n&amp;#x200B;\n\nThe business has decided to look into purchasing a solution as Microsoft makes this extremely difficult given the gap between infrastructures. \n\n&amp;#x200B;\n\nWas looking into fivetran/airbyte however I am looking for other solutions/recommendations as I am new to this myself.", "author_fullname": "t2_qdd0yns5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Needing advice for replication software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6smez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709602279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The business I work for needs to replicate a database server (MySQL) (in our AWS infrastructure) to another DB server (MySQL) in a customer&amp;#39;s AWS infrastructure over the internet. Originally they wanted log shipping however that&amp;#39;s not feasible given that the machines are not locally connected.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The business has decided to look into purchasing a solution as Microsoft makes this extremely difficult given the gap between infrastructures. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Was looking into fivetran/airbyte however I am looking for other solutions/recommendations as I am new to this myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6smez", "is_robot_indexable": true, "report_reasons": null, "author": "Capital-Bedroom-2420", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6smez/needing_advice_for_replication_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6smez/needing_advice_for_replication_software/", "subreddit_subscribers": 165886, "created_utc": 1709602279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Glad to have found this subreddit. Was poking around to find a good DBA sub and found this sub.  I've been in the field for 30 years now (started in 1994).  I spent the first 5-6 as a software engineer developing apps with OMNIS, then moved to .NET dev for another 5, and the last 20 years as a DBA for Oracle and Microsoft RDMS.  In between all that, I ran our BI software (Pentaho for ETL, OBIEE, PowerBI, and Tableau), set up Databricks, Exasol, and Snowflake, wrote tons of SQL Code, and created Python notebook scripts to clean and move data around.    \n\nThe reason for asking is I've seen the salaries of some of the DEs on this site and was like \"holy Shartt am I getting underpaid @ roughly 100k yr (its a university)\"\n\nFor those of you who have been in this field for a while,  does my background suffice to be called a DE?\n\nThanks and hello to everyone here\n\n  \n\n\n&amp;#x200B;", "author_fullname": "t2_r0yx5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just came across this subreddit - Am I a Data Engineer or an overly qualified DBA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6numw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709590376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Glad to have found this subreddit. Was poking around to find a good DBA sub and found this sub.  I&amp;#39;ve been in the field for 30 years now (started in 1994).  I spent the first 5-6 as a software engineer developing apps with OMNIS, then moved to .NET dev for another 5, and the last 20 years as a DBA for Oracle and Microsoft RDMS.  In between all that, I ran our BI software (Pentaho for ETL, OBIEE, PowerBI, and Tableau), set up Databricks, Exasol, and Snowflake, wrote tons of SQL Code, and created Python notebook scripts to clean and move data around.    &lt;/p&gt;\n\n&lt;p&gt;The reason for asking is I&amp;#39;ve seen the salaries of some of the DEs on this site and was like &amp;quot;holy Shartt am I getting underpaid @ roughly 100k yr (its a university)&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;For those of you who have been in this field for a while,  does my background suffice to be called a DE?&lt;/p&gt;\n\n&lt;p&gt;Thanks and hello to everyone here&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6numw", "is_robot_indexable": true, "report_reasons": null, "author": "dbogs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6numw/just_came_across_this_subreddit_am_i_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6numw/just_came_across_this_subreddit_am_i_a_data/", "subreddit_subscribers": 165886, "created_utc": 1709590376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Greetings all. Experienced data engineer, but AWS Novice and looking for best practices (if any)\n\nI have a MySQL RDS db, which I want to create a real- or near realtime CDC into a new Aurora PostgreSQL db. This is a database replatform, and both databases will be in use for some time. (The old MySQL db will still be having data written to it, but over time, we'll be migrating code over to the Postgres db.) In addition, the Postgres db is not even close to the same schema as the MySQL db, and significant ETL will be needed.\n\nIt doesn't look like anything in AWS really accomplishes both a realtime data migration *and* complex ETL. What are tried and tested third-party tools that can accomplish this?\n\nMany thanks in advance.", "author_fullname": "t2_9h42b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complex CDC ETL from RDS MySQL to Aurora Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6niyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709589619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings all. Experienced data engineer, but AWS Novice and looking for best practices (if any)&lt;/p&gt;\n\n&lt;p&gt;I have a MySQL RDS db, which I want to create a real- or near realtime CDC into a new Aurora PostgreSQL db. This is a database replatform, and both databases will be in use for some time. (The old MySQL db will still be having data written to it, but over time, we&amp;#39;ll be migrating code over to the Postgres db.) In addition, the Postgres db is not even close to the same schema as the MySQL db, and significant ETL will be needed.&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t look like anything in AWS really accomplishes both a realtime data migration &lt;em&gt;and&lt;/em&gt; complex ETL. What are tried and tested third-party tools that can accomplish this?&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6niyw", "is_robot_indexable": true, "report_reasons": null, "author": "Lightsider", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6niyw/complex_cdc_etl_from_rds_mysql_to_aurora_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6niyw/complex_cdc_etl_from_rds_mysql_to_aurora_postgres/", "subreddit_subscribers": 165886, "created_utc": 1709589619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've been building a new tool called Chicory to help data engineers. Right now, Chicory can speed up SparkSQL by 50% and reduce resource utilization by 25% on average. We use GPT4 under the hood to analyze, rewrite, and optimize code while checking for errors and hallucinations.  \n\nCheck us out at chicory.ai", "author_fullname": "t2_5cyf07yvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple way to optimize queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6k7nw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709581625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been building a new tool called Chicory to help data engineers. Right now, Chicory can speed up SparkSQL by 50% and reduce resource utilization by 25% on average. We use GPT4 under the hood to analyze, rewrite, and optimize code while checking for errors and hallucinations.  &lt;/p&gt;\n\n&lt;p&gt;Check us out at chicory.ai&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6k7nw", "is_robot_indexable": true, "report_reasons": null, "author": "SeniorWorldliness317", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6k7nw/a_simple_way_to_optimize_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6k7nw/a_simple_way_to_optimize_queries/", "subreddit_subscribers": 165886, "created_utc": 1709581625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to prep for some upcoming interviews.\n\nAll I know is confluence, Jira, Jenkins, airflow and data bricks are what are being used.\n\nAny advice is appreciated. ", "author_fullname": "t2_p7krf9ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to prep for upcoming connect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6jflr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709579735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to prep for some upcoming interviews.&lt;/p&gt;\n\n&lt;p&gt;All I know is confluence, Jira, Jenkins, airflow and data bricks are what are being used.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6jflr", "is_robot_indexable": true, "report_reasons": null, "author": "Poyal_Rines", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6jflr/trying_to_prep_for_upcoming_connect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6jflr/trying_to_prep_for_upcoming_connect/", "subreddit_subscribers": 165886, "created_utc": 1709579735.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}