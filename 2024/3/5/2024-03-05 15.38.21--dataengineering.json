{"kind": "Listing", "data": {"after": "t3_1b6gq4k", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I accepted an offer with a decent comp at a bank. Role is remote I started and got my work laptop mailed and have been going through on boarding. \n\nNow I've just gotten an offer from another company which I thought ghosted me and I'm in a bit of a dilemma. The offer is 60% more than my current comp. I'm not even questioning it tbh I am definitely going to accept, I know my current company can't match and of course they won't I literally just started. \n\nWhats my best course of action? Just tell them about the job? Bullshit something else (like medical issue) and say I can't work anymore?\n\nEdit: while the job is remote they did fly me out for my first week so I can meet the core team so that does add another insult when I leave. ", "author_fullname": "t2_cyr5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accepted an offer, 2 weeks later got dream offer from another company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ghh6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 163, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 163, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709573525.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709572757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I accepted an offer with a decent comp at a bank. Role is remote I started and got my work laptop mailed and have been going through on boarding. &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;ve just gotten an offer from another company which I thought ghosted me and I&amp;#39;m in a bit of a dilemma. The offer is 60% more than my current comp. I&amp;#39;m not even questioning it tbh I am definitely going to accept, I know my current company can&amp;#39;t match and of course they won&amp;#39;t I literally just started. &lt;/p&gt;\n\n&lt;p&gt;Whats my best course of action? Just tell them about the job? Bullshit something else (like medical issue) and say I can&amp;#39;t work anymore?&lt;/p&gt;\n\n&lt;p&gt;Edit: while the job is remote they did fly me out for my first week so I can meet the core team so that does add another insult when I leave. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6ghh6", "is_robot_indexable": true, "report_reasons": null, "author": "bigYman", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ghh6/accepted_an_offer_2_weeks_later_got_dream_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ghh6/accepted_an_offer_2_weeks_later_got_dream_offer/", "subreddit_subscribers": 165962, "created_utc": 1709572757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I help companies build and scale machine learning and analytics applications, with Spark being a core part of our data processing toolkit. While Python is generally the go-to language for data processing, libraries like Pandas &amp; NumPy come with a LOT of sharp edges. This is especially true if you're trying to read someone else's code. \n\nIMO Spark (&amp; PySpark) has an edge over other data processing tools for a few reasons: it reads more like SQL (making it a easier to understand without digging through obscure documentation), it's well-supported across cloud platforms, and it's dead simple to scale to handle any size data you need to throw at it.\n\nI wanted to create a resource that anyone with basic Python and SQL knowledge can use to get up and running quickly with Spark (you can probably learn 80% of what you need in a day or two). I also wanted to include some suggestions around code conventions to help with readability and avoiding gotchas that trip a lot of folks up (e.g. duplicating columns when doing joins).\n\nYou can get started with either a web notebook or locally with a batteries-included Docker container. \n\nYou can access it at [SparkMadeEasy.com](https://sparkmadeeasy.com/).\n\nThis is still a work-in-progress, with more topics to come (e.g. Spark-ML). Happy to hear any feedback!", "author_fullname": "t2_uyd9mc1b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an open-source microsite to help analysts and SQL-heavy devs get started with Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6dgsp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709571490.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709565598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I help companies build and scale machine learning and analytics applications, with Spark being a core part of our data processing toolkit. While Python is generally the go-to language for data processing, libraries like Pandas &amp;amp; NumPy come with a LOT of sharp edges. This is especially true if you&amp;#39;re trying to read someone else&amp;#39;s code. &lt;/p&gt;\n\n&lt;p&gt;IMO Spark (&amp;amp; PySpark) has an edge over other data processing tools for a few reasons: it reads more like SQL (making it a easier to understand without digging through obscure documentation), it&amp;#39;s well-supported across cloud platforms, and it&amp;#39;s dead simple to scale to handle any size data you need to throw at it.&lt;/p&gt;\n\n&lt;p&gt;I wanted to create a resource that anyone with basic Python and SQL knowledge can use to get up and running quickly with Spark (you can probably learn 80% of what you need in a day or two). I also wanted to include some suggestions around code conventions to help with readability and avoiding gotchas that trip a lot of folks up (e.g. duplicating columns when doing joins).&lt;/p&gt;\n\n&lt;p&gt;You can get started with either a web notebook or locally with a batteries-included Docker container. &lt;/p&gt;\n\n&lt;p&gt;You can access it at &lt;a href=\"https://sparkmadeeasy.com/\"&gt;SparkMadeEasy.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;This is still a work-in-progress, with more topics to come (e.g. Spark-ML). Happy to hear any feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6dgsp", "is_robot_indexable": true, "report_reasons": null, "author": "zchtsk", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6dgsp/i_created_an_opensource_microsite_to_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6dgsp/i_created_an_opensource_microsite_to_help/", "subreddit_subscribers": 165962, "created_utc": 1709565598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading some older posts in this sub about working with legacy systems for your first role, and one thread was all in on the idea that your first job is the most important job for setting the stage of your career, and to switch if your work if all Excel files and legacy database management.\n\nI thought, of course every role is important, but are you doomed to fail if your first job isn't exactly what you wanted? Especially in the current market where everyone would take whatever they can get?\n\nIt's a little discouraging for me because I turned down an offer to work with an AWS stack for my first job, to instead work for a huge corporate with amazing benefits but Access/Excel/SQL server stack. At the very least, the company is very well known and respected in my area, and one of my primary responsibilities is using Python and SQL to replace our ancient VBA and Access macros, so I think I'm getting relevant experience for marketable skills. \n\nIs your first job really all that important, especially if you plan on job hopping? Is there hope for data analysts/engineers working with legacy systems to make the jump into a modern cloud stack 1-2 yrs later?", "author_fullname": "t2_tt7gml0lp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is your first role for the trajectory of your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6vwta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709611409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading some older posts in this sub about working with legacy systems for your first role, and one thread was all in on the idea that your first job is the most important job for setting the stage of your career, and to switch if your work if all Excel files and legacy database management.&lt;/p&gt;\n\n&lt;p&gt;I thought, of course every role is important, but are you doomed to fail if your first job isn&amp;#39;t exactly what you wanted? Especially in the current market where everyone would take whatever they can get?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a little discouraging for me because I turned down an offer to work with an AWS stack for my first job, to instead work for a huge corporate with amazing benefits but Access/Excel/SQL server stack. At the very least, the company is very well known and respected in my area, and one of my primary responsibilities is using Python and SQL to replace our ancient VBA and Access macros, so I think I&amp;#39;m getting relevant experience for marketable skills. &lt;/p&gt;\n\n&lt;p&gt;Is your first job really all that important, especially if you plan on job hopping? Is there hope for data analysts/engineers working with legacy systems to make the jump into a modern cloud stack 1-2 yrs later?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6vwta", "is_robot_indexable": true, "report_reasons": null, "author": "date_uh", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6vwta/how_important_is_your_first_role_for_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6vwta/how_important_is_your_first_role_for_the/", "subreddit_subscribers": 165962, "created_utc": 1709611409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have implemented a large scale project for a hospital and the entire infrastructure was built on Azure. I set up the ELT pipelines using ADF and pyspark(for data manipulation and enrichment) and the company created API endpoints around their data sources. And so I used to extract data from the API and load it into a data lake. I then use this weekly generated data to create a dashboard which then auto refreshes weekly. I've never had to use SQL and even if I did have to use it, OpenAI's GPT-4-Turbo-preview model via the API has been absolutely great. \n\nNot to mention that I do know basics of SQL, doing transformations, Window functions, etc. But since OpenAI was able to write the queries exactly how I needed it, I wanted to know if it is worth investing significant amount of time to master SQL.  Yes, OpenAI may get expensive and I need to kno0w when to step in to get the correct O/P, but whenever I put in the schema, what I want, and an example of input and output, it gets the query right 95% of the time in the first go. So is it worth going into advanced SQL or to learn more about the different technologies involved in DE? Any advice would be great, thank you!", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Important is SQL for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6iw84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709578443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have implemented a large scale project for a hospital and the entire infrastructure was built on Azure. I set up the ELT pipelines using ADF and pyspark(for data manipulation and enrichment) and the company created API endpoints around their data sources. And so I used to extract data from the API and load it into a data lake. I then use this weekly generated data to create a dashboard which then auto refreshes weekly. I&amp;#39;ve never had to use SQL and even if I did have to use it, OpenAI&amp;#39;s GPT-4-Turbo-preview model via the API has been absolutely great. &lt;/p&gt;\n\n&lt;p&gt;Not to mention that I do know basics of SQL, doing transformations, Window functions, etc. But since OpenAI was able to write the queries exactly how I needed it, I wanted to know if it is worth investing significant amount of time to master SQL.  Yes, OpenAI may get expensive and I need to kno0w when to step in to get the correct O/P, but whenever I put in the schema, what I want, and an example of input and output, it gets the query right 95% of the time in the first go. So is it worth going into advanced SQL or to learn more about the different technologies involved in DE? Any advice would be great, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6iw84", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6iw84/how_important_is_sql_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6iw84/how_important_is_sql_for_data_engineers/", "subreddit_subscribers": 165962, "created_utc": 1709578443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a data scientist for years and hate the analytical part of creating reports/dashboards/KPIs/analysis giving presentations for end users (mostly sales people) that will never use it, give me urgent adhoc requests that will again never use, since they dont know what they want. \n\nI love the technical backend part of creating the dashboards using Power BI, using Python to automate reports, create models, forecast, graphs, use SQL to acquire data etc. \n\nWhat jobs can I look for that are less about having to analyze/provide insights to end users and more on the backend, like creating all the technical processes/automation/etc for maybe other analysts?  dont want to be a software developer. Could it be data engineering? ", "author_fullname": "t2_j0ebc61y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Jobs that are less analytical more technical ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b72khy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709636380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a data scientist for years and hate the analytical part of creating reports/dashboards/KPIs/analysis giving presentations for end users (mostly sales people) that will never use it, give me urgent adhoc requests that will again never use, since they dont know what they want. &lt;/p&gt;\n\n&lt;p&gt;I love the technical backend part of creating the dashboards using Power BI, using Python to automate reports, create models, forecast, graphs, use SQL to acquire data etc. &lt;/p&gt;\n\n&lt;p&gt;What jobs can I look for that are less about having to analyze/provide insights to end users and more on the backend, like creating all the technical processes/automation/etc for maybe other analysts?  dont want to be a software developer. Could it be data engineering? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b72khy", "is_robot_indexable": true, "report_reasons": null, "author": "chicric", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b72khy/data_jobs_that_are_less_analytical_more_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b72khy/data_jobs_that_are_less_analytical_more_technical/", "subreddit_subscribers": 165962, "created_utc": 1709636380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this is common but wanted to hear any success stories from anyone who applied to role that were under qualified for but got the job and killed it.\n\nBeen looking at [Sr.Data](https://Sr.Data) Eng roles and I just get so intimated with the list of technologies they expect you to manage. All I really do is write up stored procs in BQ to create a dimensional model then throw it in a DAG for orchestration.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intimidated and discouraged by Job Description", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ydx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709619391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is common but wanted to hear any success stories from anyone who applied to role that were under qualified for but got the job and killed it.&lt;/p&gt;\n\n&lt;p&gt;Been looking at &lt;a href=\"https://Sr.Data\"&gt;Sr.Data&lt;/a&gt; Eng roles and I just get so intimated with the list of technologies they expect you to manage. All I really do is write up stored procs in BQ to create a dimensional model then throw it in a DAG for orchestration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6ydx2", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ydx2/intimidated_and_discouraged_by_job_description/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ydx2/intimidated_and_discouraged_by_job_description/", "subreddit_subscribers": 165962, "created_utc": 1709619391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to run some basic checks on our data in a fairly generic way. Basically, passing a table (or view) and a list of fields for dims and list of fields for measures\n\nAnd have it slice by each dimension for each measure to see if there is anything that is greater than X number of standard deviations compared to same day last week or compared to rolling week average, for example.\n\nWe randomly encounter data quality issues for metrics within a certain dimension which isn't caught by more high level checks.\n\nExample, for our Transactions fact table, we stopped received transactions for a *specific* product type. At the high level, it was almost impossible to see any deviation when charted. but when split by different dimensions, the anomaly immediately pops up.\n\nexample trendline for transaction count for Product XYZ\n\n3/1  : 200\n\n3/2 : 250\n\n3/3: 190\n\n3/4: 0   -- or tiny number like 7\n\nWe're on SQL Server/AWS Redshift. I might do something in dynamic sql to handle this but is there a \\*free\\* solution out there? Don't actually need anything really sophisticated, we're a small company.\n\nWe're not on dbt, but can dbt generic tests help with this?\n\nThere's a few python related solutions that I've looked at, as well but would prefer to do the analysis on the DB engine for larger datasets.\n\n* [https://github.com/ydataai/ydata-profiling](https://github.com/ydataai/ydata-profiling)", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick and easy anomaly detection in SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6rkhb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709646680.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709599448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to run some basic checks on our data in a fairly generic way. Basically, passing a table (or view) and a list of fields for dims and list of fields for measures&lt;/p&gt;\n\n&lt;p&gt;And have it slice by each dimension for each measure to see if there is anything that is greater than X number of standard deviations compared to same day last week or compared to rolling week average, for example.&lt;/p&gt;\n\n&lt;p&gt;We randomly encounter data quality issues for metrics within a certain dimension which isn&amp;#39;t caught by more high level checks.&lt;/p&gt;\n\n&lt;p&gt;Example, for our Transactions fact table, we stopped received transactions for a &lt;em&gt;specific&lt;/em&gt; product type. At the high level, it was almost impossible to see any deviation when charted. but when split by different dimensions, the anomaly immediately pops up.&lt;/p&gt;\n\n&lt;p&gt;example trendline for transaction count for Product XYZ&lt;/p&gt;\n\n&lt;p&gt;3/1  : 200&lt;/p&gt;\n\n&lt;p&gt;3/2 : 250&lt;/p&gt;\n\n&lt;p&gt;3/3: 190&lt;/p&gt;\n\n&lt;p&gt;3/4: 0   -- or tiny number like 7&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on SQL Server/AWS Redshift. I might do something in dynamic sql to handle this but is there a *free* solution out there? Don&amp;#39;t actually need anything really sophisticated, we&amp;#39;re a small company.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re not on dbt, but can dbt generic tests help with this?&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a few python related solutions that I&amp;#39;ve looked at, as well but would prefer to do the analysis on the DB engine for larger datasets.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/ydataai/ydata-profiling\"&gt;https://github.com/ydataai/ydata-profiling&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?auto=webp&amp;s=d9b5b8ff273ef55984d2b84516414d5c742b7d54", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddc17a5b476dc4bc9bc7850d45241b871daafed4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ab3f9f5002a95c0088b661d27161fad11eb6b24", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a13390688cd5bfa2f8fdf3a5d5b79712c981468", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9a9b4164cc9a9f7e673f4a12dee7455c6ea6581", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=008a7d36e1ad1d7b587e8485d7a644e1915132ab", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Tm6jpBA63jAb04C6xa_3wDaO-JmQI753gcAlT9J3wro.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a6868bfb85e1dfc49222eeb75205ccc128034336", "width": 1080, "height": 540}], "variants": {}, "id": "twBVkMc_k1BYnGPSPsroeGloYvtLSGEcNAiOHgXdwEQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6rkhb", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6rkhb/quick_and_easy_anomaly_detection_in_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6rkhb/quick_and_easy_anomaly_detection_in_sql/", "subreddit_subscribers": 165962, "created_utc": 1709599448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nI am a recent graduate and I got a job offer for a data engineer position where I would have to work on a project with palantir. At the moment I am not familiar with this framework at all (the company would enroll me into a training program) so I wonder how useful is this going to be for my long term career of becoming a data scientist. Could someone shed some light on how niche exactly is the Palantir system and is it worth it to except this job offer if I don't yet know if I want to be working with it in the future. ", "author_fullname": "t2_917g34y9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is palantir framework experience transferable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b71k0x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709632301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a recent graduate and I got a job offer for a data engineer position where I would have to work on a project with palantir. At the moment I am not familiar with this framework at all (the company would enroll me into a training program) so I wonder how useful is this going to be for my long term career of becoming a data scientist. Could someone shed some light on how niche exactly is the Palantir system and is it worth it to except this job offer if I don&amp;#39;t yet know if I want to be working with it in the future. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b71k0x", "is_robot_indexable": true, "report_reasons": null, "author": "Sand-Frosty", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b71k0x/is_palantir_framework_experience_transferable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b71k0x/is_palantir_framework_experience_transferable/", "subreddit_subscribers": 165962, "created_utc": 1709632301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, we've just created a new medium publication on content for running &amp; scaling data consultancies. The link is this one: [Data Consulting Club](https://medium.com/data-consulting-club).\n\n&amp;#x200B;\n\nThe first article is on selling data services to non-data-savvy businesses; I hope you enjoy it.\n\n&amp;#x200B;\n\nI know it sounds like an arcane topic, but really I looked almost everywhere, there is no single source of content out there that helps with scaling data consultancies, and yet there are thousands of them just inside the US. \n\n*Enjoy, feel free to comment, share ideas, questions for content!*\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Consulting Club \u2013 Medium", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b74adw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709642546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, we&amp;#39;ve just created a new medium publication on content for running &amp;amp; scaling data consultancies. The link is this one: &lt;a href=\"https://medium.com/data-consulting-club\"&gt;Data Consulting Club&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The first article is on selling data services to non-data-savvy businesses; I hope you enjoy it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know it sounds like an arcane topic, but really I looked almost everywhere, there is no single source of content out there that helps with scaling data consultancies, and yet there are thousands of them just inside the US. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Enjoy, feel free to comment, share ideas, questions for content!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u_2TYordzOTKZdqTNXcKsx2crSd6T_BxxdOCasWoHd0.jpg?auto=webp&amp;s=6f54c774481eaa68275e471f7cd7cf01b6a5f0a5", "width": 800, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/u_2TYordzOTKZdqTNXcKsx2crSd6T_BxxdOCasWoHd0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=08af7a2adaf1e7ac452ee0dd3019130887110d5b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/u_2TYordzOTKZdqTNXcKsx2crSd6T_BxxdOCasWoHd0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4ec2baf40da327ca96fcfb71fb24497b22caed1", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/u_2TYordzOTKZdqTNXcKsx2crSd6T_BxxdOCasWoHd0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4028c546e01c5eab66bd1c793e79906477faf957", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/u_2TYordzOTKZdqTNXcKsx2crSd6T_BxxdOCasWoHd0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=210d02e6c5137b4b4f19669ef5355e9dab9f95f0", "width": 640, "height": 640}], "variants": {}, "id": "L6jeuPDAfgBs4qNFtmcSHiCFWUPIzQfJRaVYELKf47c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b74adw", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b74adw/data_consulting_club_medium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b74adw/data_consulting_club_medium/", "subreddit_subscribers": 165962, "created_utc": 1709642546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nTrying to give guidance to a company in mid market 600 FTE. They have heard about Mage AI and are interested in it. Any experiences with it? Does it solve certain problems that Airflow/Prefect/Astronomer doesn\u2019t? ", "author_fullname": "t2_putygiix7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mage AI experiences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6k06l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709581113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Trying to give guidance to a company in mid market 600 FTE. They have heard about Mage AI and are interested in it. Any experiences with it? Does it solve certain problems that Airflow/Prefect/Astronomer doesn\u2019t? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6k06l", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantParty6489", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6k06l/mage_ai_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6k06l/mage_ai_experiences/", "subreddit_subscribers": 165962, "created_utc": 1709581113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to build a DB that will house years worth of 15 or 30 minute data for a couple hundred facilities. So about \\~15M rows/year with about a dozen columns and some dimension tables. End goal is using the data for visualization and reporting\n\nRather than just ask what tool I should use for this specific project I wanted to know if there are general rules for what tools to use based on expected table size. I feel like for smaller data like my setup something like SQL Server Express would be fine but I figured I'd ask. I also want to use tools that will help me self market for my next role.", "author_fullname": "t2_1ad62ux7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a guide for how to choose tools based on DB size?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6rxl1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709600410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to build a DB that will house years worth of 15 or 30 minute data for a couple hundred facilities. So about ~15M rows/year with about a dozen columns and some dimension tables. End goal is using the data for visualization and reporting&lt;/p&gt;\n\n&lt;p&gt;Rather than just ask what tool I should use for this specific project I wanted to know if there are general rules for what tools to use based on expected table size. I feel like for smaller data like my setup something like SQL Server Express would be fine but I figured I&amp;#39;d ask. I also want to use tools that will help me self market for my next role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6rxl1", "is_robot_indexable": true, "report_reasons": null, "author": "VegaGT-VZ", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6rxl1/is_there_a_guide_for_how_to_choose_tools_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6rxl1/is_there_a_guide_for_how_to_choose_tools_based_on/", "subreddit_subscribers": 165962, "created_utc": 1709600410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nUp until recently, I was a Sr DE at FAANG (7YOE). However, I was part of the recent layoffs and found myself contemplating my next steps sooner than expected. To add a twist to the plot, I just tore my achilles tendon playing basketball, which means I'll be spending quite a bit of time on my butt at home recovering. Not exactly the kind of break I had in mind, but here we are.\n\nPost layoff, I was already planning to take a significant break to reset and figure out what I want to do next. The injury just extended this timeline a bit. I'm pretty comfortable with the Leetcode grind, system design, and all that jazz. But for this break, I want to focus on learning and exploring - diving into new tech, maybe picking up some skills that are just for fun, and generally getting reinvigorated about the field.\n\nI've spent a good part of my career leading projects, primarily working with AWS, Python, SQL, mainly with ETL platforms. While I'm pondering whether to return to FAANG or venture into something smaller where I can have a bigger impact (perhaps lead a larger team), I'm not quite sure where to direct my learning energy.\n\nSo, I'm reaching out for suggestions on how to make the most of this time. Are there any books, courses, or personal projects you would recommend? Any emerging tech or tools I should get my hands on? Or perhaps some advice on making a transition that could allow me to be more impactful and fulfill my desire to work closely with a team?\n\nI'm all ears and really appreciate any thoughts or guidance you can share. Thank you!", "author_fullname": "t2_1swxdf76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice for a Sr DE's Learning Journey Post-FAANG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6fxq9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709571506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;Up until recently, I was a Sr DE at FAANG (7YOE). However, I was part of the recent layoffs and found myself contemplating my next steps sooner than expected. To add a twist to the plot, I just tore my achilles tendon playing basketball, which means I&amp;#39;ll be spending quite a bit of time on my butt at home recovering. Not exactly the kind of break I had in mind, but here we are.&lt;/p&gt;\n\n&lt;p&gt;Post layoff, I was already planning to take a significant break to reset and figure out what I want to do next. The injury just extended this timeline a bit. I&amp;#39;m pretty comfortable with the Leetcode grind, system design, and all that jazz. But for this break, I want to focus on learning and exploring - diving into new tech, maybe picking up some skills that are just for fun, and generally getting reinvigorated about the field.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve spent a good part of my career leading projects, primarily working with AWS, Python, SQL, mainly with ETL platforms. While I&amp;#39;m pondering whether to return to FAANG or venture into something smaller where I can have a bigger impact (perhaps lead a larger team), I&amp;#39;m not quite sure where to direct my learning energy.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m reaching out for suggestions on how to make the most of this time. Are there any books, courses, or personal projects you would recommend? Any emerging tech or tools I should get my hands on? Or perhaps some advice on making a transition that could allow me to be more impactful and fulfill my desire to work closely with a team?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m all ears and really appreciate any thoughts or guidance you can share. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6fxq9", "is_robot_indexable": true, "report_reasons": null, "author": "hairbear1234", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6fxq9/seeking_advice_for_a_sr_des_learning_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6fxq9/seeking_advice_for_a_sr_des_learning_journey/", "subreddit_subscribers": 165962, "created_utc": 1709571506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI'm currently building a data model for a reporting system. While looking for references or best practices, I stumbled upon the Star Schema. So I'm wondering, does my picture, which is a small cutout of our model, still count as one since it has a dimension in the middle?\n\n[https://imgur.com/a/e4CVooX](https://imgur.com/a/e4CVooX)", "author_fullname": "t2_ffhcii5f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to the world of Data, does this count as a Star Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b72js6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709636298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently building a data model for a reporting system. While looking for references or best practices, I stumbled upon the Star Schema. So I&amp;#39;m wondering, does my picture, which is a small cutout of our model, still count as one since it has a dimension in the middle?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/e4CVooX\"&gt;https://imgur.com/a/e4CVooX&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/10MnfSVzgNZQuCRdrXFqUIFU9y3P0Syii9NmhZrF6lw.jpg?auto=webp&amp;s=b77fc0f034a6fd5ba465d264c1212946891c6402", "width": 848, "height": 467}, "resolutions": [{"url": "https://external-preview.redd.it/10MnfSVzgNZQuCRdrXFqUIFU9y3P0Syii9NmhZrF6lw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3fa64b8a4184ee2363e8849be2ab85342898ba7", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/10MnfSVzgNZQuCRdrXFqUIFU9y3P0Syii9NmhZrF6lw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e52b7b843c391eef43fcf9c988a5835e9523600d", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/10MnfSVzgNZQuCRdrXFqUIFU9y3P0Syii9NmhZrF6lw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8db965dac775e8b2b8af73e5a5e9519f64cb5b4", "width": 320, "height": 176}, {"url": "https://external-preview.redd.it/10MnfSVzgNZQuCRdrXFqUIFU9y3P0Syii9NmhZrF6lw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc196d76f90f96cf31e0c50fb0ce882d808a5f95", "width": 640, "height": 352}], "variants": {}, "id": "l0v-_hfICkaa6htcwY_CsokbzOActHoCk9044epftsY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b72js6", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Let251", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b72js6/new_to_the_world_of_data_does_this_count_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b72js6/new_to_the_world_of_data_does_this_count_as_a/", "subreddit_subscribers": 165962, "created_utc": 1709636298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys\nI'm just learning data engineering by joining DE Zoomcamp. I want to create a end-to-end project from processing files until creating a dashboard. I will be using mage.ai as workflow orchestrator and DBT as data modeling tool.\n\nHere is my dataset from kaggle. https://www.kaggle.com/datasets/antonukolga/cyclistic-bike-share-data-12-months\nIn my mind, I need to download all files then upload to google cloud storage after that to bigQuery. Then trigger DBT to build it.\n\nI'm confused what should I do in the process of extracting and loading? Just as simple as download and upload?", "author_fullname": "t2_2lvigk1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ask the advice for (EL) process in ELT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b719yv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709631104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys\nI&amp;#39;m just learning data engineering by joining DE Zoomcamp. I want to create a end-to-end project from processing files until creating a dashboard. I will be using mage.ai as workflow orchestrator and DBT as data modeling tool.&lt;/p&gt;\n\n&lt;p&gt;Here is my dataset from kaggle. &lt;a href=\"https://www.kaggle.com/datasets/antonukolga/cyclistic-bike-share-data-12-months\"&gt;https://www.kaggle.com/datasets/antonukolga/cyclistic-bike-share-data-12-months&lt;/a&gt;\nIn my mind, I need to download all files then upload to google cloud storage after that to bigQuery. Then trigger DBT to build it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m confused what should I do in the process of extracting and loading? Just as simple as download and upload?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?auto=webp&amp;s=86ac445a852630efa82b17be2bd74300d44d1364", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bee3324f41d097e9bb2806164a72c2ba7315d05f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd557d65200c3e91ddffa2786fbcf771e07a79b7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e25be11f3d7768597c95744a9586356b852d689", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6314e93cdfdf1ee9bfa2a34dee89ab7b1e52ddf1", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06a0f4527cc69125f698a9b6d77e377c662d639c", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/56l_IxqVtAo5Te9aVPGb0XosO6Wd979gKxtBeBi3rrU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d1e1767c195f3d756313b37a9a8c5ea39ea28a1c", "width": 1080, "height": 1080}], "variants": {}, "id": "-ruYmDMVtAVEZ2yLCTdRTVKICXf94FCru05mqoUQoPI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b719yv", "is_robot_indexable": true, "report_reasons": null, "author": "muh_ilhamfajar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b719yv/ask_the_advice_for_el_process_in_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b719yv/ask_the_advice_for_el_process_in_elt/", "subreddit_subscribers": 165962, "created_utc": 1709631104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have configured a local environment that consists of the following containers:\n\n* Trino\n* Hive\n* Minio\n\nI have successfully set up these three containers to create and query external tables using Trino, which are stored in the Hive Metastore and on Minio as Parquet.   This all works great for me.\n\nHowever, when I try to drop the table in Trino that I created, I get this error:\n\n&gt;Access Denied: Cannot drop table schema.tablename io.trino.spi.security.AccessDeniedException: Access Denied: Cannot drop table schema.tablename\n\nThis doesn't make any sense because there is no user setup in Hive Metastore, nor security setup.  If I connect to the Hive metastore using Beeline, I can drop the table with no problem.\n\nDo you have any clue why Trino is unable to drop the table?", "author_fullname": "t2_l04by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cannot drop table in Trino using Hive connector for no good reason", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6woqe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709613842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have configured a local environment that consists of the following containers:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Trino&lt;/li&gt;\n&lt;li&gt;Hive&lt;/li&gt;\n&lt;li&gt;Minio&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have successfully set up these three containers to create and query external tables using Trino, which are stored in the Hive Metastore and on Minio as Parquet.   This all works great for me.&lt;/p&gt;\n\n&lt;p&gt;However, when I try to drop the table in Trino that I created, I get this error:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Access Denied: Cannot drop table schema.tablename io.trino.spi.security.AccessDeniedException: Access Denied: Cannot drop table schema.tablename&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This doesn&amp;#39;t make any sense because there is no user setup in Hive Metastore, nor security setup.  If I connect to the Hive metastore using Beeline, I can drop the table with no problem.&lt;/p&gt;\n\n&lt;p&gt;Do you have any clue why Trino is unable to drop the table?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6woqe", "is_robot_indexable": true, "report_reasons": null, "author": "kentmaxwell", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6woqe/cannot_drop_table_in_trino_using_hive_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6woqe/cannot_drop_table_in_trino_using_hive_connector/", "subreddit_subscribers": 165962, "created_utc": 1709613842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI'm looking for some advice and I'm hoping this is the right spot. \n\n&amp;#x200B;\n\nI've recently started a new role as a Machine Learning Engineer for a R&amp;D team focusing on computer vision applications. It has become clear that the biggest weakness in our operation stems from our approach to data. We have \\~terabytes of proprietary image and video data in various formats and no system to efficiently process and label it.  I have been assigned the task of developing a data pipeline to curate custom datasets for our CV models but I don't have any real expertise in data engineering other than some experience with SQL/NoSQL databases. \n\n&amp;#x200B;\n\nI'm aware that a team of dedicated Data Engineers is really what's required for such a task but unfortunately I am the only one available to work on this problem. With that in mind, I'd very much appreciate any guidance on the following: \n\n1. What resources are available for learning Data Engineering for CV? I have spent a lot of time researching this area now but most resources that I've come across really only focus on structured tabular data. I haven't come across any resource that discusses best practices when dealing with video or image data. \n2. How do I decide on what tools to use? I am overwhelmed by the choice of tools relating to the 'modern data stack'. I have come across Activeloop's DeepLake which seems promising but then Delta Lake seems to be more popular. Do I even need a Lakehouse architecture? \n3. I have set up CVAT for image annotation with semi-automatic labelling to improve efficiency. Are there better tools out there for labelling? I have seen LabelBox mentioned as a viable alternative. \n\n&amp;#x200B;\n\nOf course I have many other questions but I'll keep this short as the main thing I'm looking for is advice on how to improve and learn. Any information would be much appreciated! ", "author_fullname": "t2_a1k94kfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering for Computer Vision - Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6kgk6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709582238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some advice and I&amp;#39;m hoping this is the right spot. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started a new role as a Machine Learning Engineer for a R&amp;amp;D team focusing on computer vision applications. It has become clear that the biggest weakness in our operation stems from our approach to data. We have ~terabytes of proprietary image and video data in various formats and no system to efficiently process and label it.  I have been assigned the task of developing a data pipeline to curate custom datasets for our CV models but I don&amp;#39;t have any real expertise in data engineering other than some experience with SQL/NoSQL databases. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that a team of dedicated Data Engineers is really what&amp;#39;s required for such a task but unfortunately I am the only one available to work on this problem. With that in mind, I&amp;#39;d very much appreciate any guidance on the following: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What resources are available for learning Data Engineering for CV? I have spent a lot of time researching this area now but most resources that I&amp;#39;ve come across really only focus on structured tabular data. I haven&amp;#39;t come across any resource that discusses best practices when dealing with video or image data. &lt;/li&gt;\n&lt;li&gt;How do I decide on what tools to use? I am overwhelmed by the choice of tools relating to the &amp;#39;modern data stack&amp;#39;. I have come across Activeloop&amp;#39;s DeepLake which seems promising but then Delta Lake seems to be more popular. Do I even need a Lakehouse architecture? &lt;/li&gt;\n&lt;li&gt;I have set up CVAT for image annotation with semi-automatic labelling to improve efficiency. Are there better tools out there for labelling? I have seen LabelBox mentioned as a viable alternative. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Of course I have many other questions but I&amp;#39;ll keep this short as the main thing I&amp;#39;m looking for is advice on how to improve and learn. Any information would be much appreciated! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6kgk6", "is_robot_indexable": true, "report_reasons": null, "author": "distracted-ferret", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6kgk6/data_engineering_for_computer_vision_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6kgk6/data_engineering_for_computer_vision_advice/", "subreddit_subscribers": 165962, "created_utc": 1709582238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nWe made a tool for BigQuery users. You can generate a view from a JSON object if you are storing your data as us in a JSON field, it's very useful!\n\nAny feedback is welcome! :)\n\nThe tool is here: [https://vg.persio.io](https://vg.persio.io)", "author_fullname": "t2_1mwhn72z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free RAW Json to View tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6i9st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709580170.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709576950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;We made a tool for BigQuery users. You can generate a view from a JSON object if you are storing your data as us in a JSON field, it&amp;#39;s very useful!&lt;/p&gt;\n\n&lt;p&gt;Any feedback is welcome! :)&lt;/p&gt;\n\n&lt;p&gt;The tool is here: &lt;a href=\"https://vg.persio.io\"&gt;https://vg.persio.io&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?auto=webp&amp;s=5e69c52008196472a67548003a28f8f20d609d3b", "width": 878, "height": 460}, "resolutions": [{"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f75eb1a72319934c5328dd4c88160047a46ebfc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61e2acfe92daa0f3277fe698099d56f6738b5c23", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47742f25f6f66e00357e66fb8567f3b30e58c0fa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/5ZO939ydYbQ0_CsYPeCqzD8n-BW7wuzz38r2Ic7FLH8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=19fa8ef1b854a514192bdd51e9b6981d77bc8bc6", "width": 640, "height": 335}], "variants": {}, "id": "5z7wVcO2sxef0OZxRjwC5Wp8rwhxWzWvcKNb8uUTPeI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6i9st", "is_robot_indexable": true, "report_reasons": null, "author": "pigri", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6i9st/free_raw_json_to_view_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6i9st/free_raw_json_to_view_tool/", "subreddit_subscribers": 165962, "created_utc": 1709576950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Your Clients Are Resistant To Data Literacy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1b71mkb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/moEmme4k-DEAQYqrJrABWmduhEanQQX15vtD2cEosKk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709632602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/why-your-clients-are-resistant-to-data-literacy/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BlLYN4xR5fDfidKXMRyhneFLggZfR4F2s4rc7L6ztNo.jpg?auto=webp&amp;s=3c3862c2a079bafdd08f21614afdab07ec564287", "width": 1024, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/BlLYN4xR5fDfidKXMRyhneFLggZfR4F2s4rc7L6ztNo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2fa3623212d281857f2f7324fe31e4dd7447bab6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/BlLYN4xR5fDfidKXMRyhneFLggZfR4F2s4rc7L6ztNo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5dd76a27478cb9892f77895b2fb4ee2924243044", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/BlLYN4xR5fDfidKXMRyhneFLggZfR4F2s4rc7L6ztNo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=178ea1cd19eadf57b26ab8bc9963a7fc99af2a25", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/BlLYN4xR5fDfidKXMRyhneFLggZfR4F2s4rc7L6ztNo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9224a210744fa375913c2b9fc15ff68b2245ab3a", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/BlLYN4xR5fDfidKXMRyhneFLggZfR4F2s4rc7L6ztNo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6b7d7d3b63ef3496224ae18ecc6a9b8d715b5789", "width": 960, "height": 720}], "variants": {}, "id": "WzsUtQy5NIoU5e2m8Qif1MSJV-kIvtdRIHIvcn-ju_Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b71mkb", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b71mkb/why_your_clients_are_resistant_to_data_literacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/why-your-clients-are-resistant-to-data-literacy/", "subreddit_subscribers": 165962, "created_utc": 1709632602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The business I work for needs to replicate a database server (MySQL) (in our AWS infrastructure) to another DB server (MySQL) in a customer's AWS infrastructure over the internet. Originally they wanted log shipping however that's not feasible given that the machines are not locally connected.\n\n&amp;#x200B;\n\nThe business has decided to look into purchasing a solution as Microsoft makes this extremely difficult given the gap between infrastructures. \n\n&amp;#x200B;\n\nWas looking into fivetran/airbyte however I am looking for other solutions/recommendations as I am new to this myself.", "author_fullname": "t2_qdd0yns5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Needing advice for replication software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6smez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709602279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The business I work for needs to replicate a database server (MySQL) (in our AWS infrastructure) to another DB server (MySQL) in a customer&amp;#39;s AWS infrastructure over the internet. Originally they wanted log shipping however that&amp;#39;s not feasible given that the machines are not locally connected.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The business has decided to look into purchasing a solution as Microsoft makes this extremely difficult given the gap between infrastructures. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Was looking into fivetran/airbyte however I am looking for other solutions/recommendations as I am new to this myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6smez", "is_robot_indexable": true, "report_reasons": null, "author": "Capital-Bedroom-2420", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6smez/needing_advice_for_replication_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6smez/needing_advice_for_replication_software/", "subreddit_subscribers": 165962, "created_utc": 1709602279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Greetings all. Experienced data engineer, but AWS Novice and looking for best practices (if any)\n\nI have a MySQL RDS db, which I want to create a real- or near realtime CDC into a new Aurora PostgreSQL db. This is a database replatform, and both databases will be in use for some time. (The old MySQL db will still be having data written to it, but over time, we'll be migrating code over to the Postgres db.) In addition, the Postgres db is not even close to the same schema as the MySQL db, and significant ETL will be needed.\n\nIt doesn't look like anything in AWS really accomplishes both a realtime data migration *and* complex ETL. What are tried and tested third-party tools that can accomplish this?\n\nMany thanks in advance.", "author_fullname": "t2_9h42b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complex CDC ETL from RDS MySQL to Aurora Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6niyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709589619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings all. Experienced data engineer, but AWS Novice and looking for best practices (if any)&lt;/p&gt;\n\n&lt;p&gt;I have a MySQL RDS db, which I want to create a real- or near realtime CDC into a new Aurora PostgreSQL db. This is a database replatform, and both databases will be in use for some time. (The old MySQL db will still be having data written to it, but over time, we&amp;#39;ll be migrating code over to the Postgres db.) In addition, the Postgres db is not even close to the same schema as the MySQL db, and significant ETL will be needed.&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t look like anything in AWS really accomplishes both a realtime data migration &lt;em&gt;and&lt;/em&gt; complex ETL. What are tried and tested third-party tools that can accomplish this?&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6niyw", "is_robot_indexable": true, "report_reasons": null, "author": "Lightsider", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6niyw/complex_cdc_etl_from_rds_mysql_to_aurora_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6niyw/complex_cdc_etl_from_rds_mysql_to_aurora_postgres/", "subreddit_subscribers": 165962, "created_utc": 1709589619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Erwin can reverse engineer a view but it doesn't seem to handle CASE statements and errors out. This is for Hive. Does anyone know if reverse engineering of views can handle CASE statements?", "author_fullname": "t2_kkmygn8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse engineering using Erwin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6ndyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709589281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Erwin can reverse engineer a view but it doesn&amp;#39;t seem to handle CASE statements and errors out. This is for Hive. Does anyone know if reverse engineering of views can handle CASE statements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b6ndyb", "is_robot_indexable": true, "report_reasons": null, "author": "KarmicDharmic", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6ndyb/reverse_engineering_using_erwin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6ndyb/reverse_engineering_using_erwin/", "subreddit_subscribers": 165962, "created_utc": 1709589281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've been building a new tool called Chicory to help data engineers. Right now, Chicory can speed up SparkSQL by 50% and reduce resource utilization by 25% on average. We use GPT4 under the hood to analyze, rewrite, and optimize code while checking for errors and hallucinations.  \n\nCheck us out at chicory.ai", "author_fullname": "t2_5cyf07yvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple way to optimize queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6k7nw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709581625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been building a new tool called Chicory to help data engineers. Right now, Chicory can speed up SparkSQL by 50% and reduce resource utilization by 25% on average. We use GPT4 under the hood to analyze, rewrite, and optimize code while checking for errors and hallucinations.  &lt;/p&gt;\n\n&lt;p&gt;Check us out at chicory.ai&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6k7nw", "is_robot_indexable": true, "report_reasons": null, "author": "SeniorWorldliness317", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6k7nw/a_simple_way_to_optimize_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6k7nw/a_simple_way_to_optimize_queries/", "subreddit_subscribers": 165962, "created_utc": 1709581625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to prep for some upcoming interviews.\n\nAll I know is confluence, Jira, Jenkins, airflow and data bricks are what are being used.\n\nAny advice is appreciated. ", "author_fullname": "t2_p7krf9ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to prep for upcoming connect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6jflr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709579735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to prep for some upcoming interviews.&lt;/p&gt;\n\n&lt;p&gt;All I know is confluence, Jira, Jenkins, airflow and data bricks are what are being used.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b6jflr", "is_robot_indexable": true, "report_reasons": null, "author": "Poyal_Rines", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6jflr/trying_to_prep_for_upcoming_connect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6jflr/trying_to_prep_for_upcoming_connect/", "subreddit_subscribers": 165962, "created_utc": 1709579735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At [PeerDB](https://peerdb.io/), we commonly get asked from customers on the preferred Postgres managed service. In that spirit, we are releasing our first part of Comparing Postgres Managed Services.\n\nThe blog includes 4 popular options\u00a0 - AWS RDS Postgres, Azure Flexible Server Postgres, GCP CloudSQL Postgres and Supabase and compares them against 3 main dimensions of Performance, Costs and Features. [https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase](https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase)\n\nA couple of disclaimers:  \nThe blog serves as an initial checklist for developers considering managed services. It's an overview, not an exhaustive analysis.  \nThe blog doesn't cover other managed services like Tembo, Crunchy, Neon, TimescaleDB, Aiven, etc. We'll include them in future posts.", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Postgres Managed Services: AWS, Azure, GCP and Supabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6h1cm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709574031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At &lt;a href=\"https://peerdb.io/\"&gt;PeerDB&lt;/a&gt;, we commonly get asked from customers on the preferred Postgres managed service. In that spirit, we are releasing our first part of Comparing Postgres Managed Services.&lt;/p&gt;\n\n&lt;p&gt;The blog includes 4 popular options\u00a0 - AWS RDS Postgres, Azure Flexible Server Postgres, GCP CloudSQL Postgres and Supabase and compares them against 3 main dimensions of Performance, Costs and Features. &lt;a href=\"https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase\"&gt;https://blog.peerdb.io/comparing-postgres-managed-services-aws-azure-gcp-and-supabase&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A couple of disclaimers:&lt;br/&gt;\nThe blog serves as an initial checklist for developers considering managed services. It&amp;#39;s an overview, not an exhaustive analysis.&lt;br/&gt;\nThe blog doesn&amp;#39;t cover other managed services like Tembo, Crunchy, Neon, TimescaleDB, Aiven, etc. We&amp;#39;ll include them in future posts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b6h1cm", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6h1cm/comparing_postgres_managed_services_aws_azure_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6h1cm/comparing_postgres_managed_services_aws_azure_gcp/", "subreddit_subscribers": 165962, "created_utc": 1709574031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Guys, I am trying to setup cdc for our warehouse.  \nI have set it up on dev but the challenge on stage is that the stage db i.e source gets refreshed bi monthly that means the db is restored from prod anonimysed db snapshot.  \n\n\nThe challenge that i see is, every time that refresh will happen we will loose those publication and replication slot. We can create both the things at time of restore but the LSN would be different and might cause some problems.   \n\n\nThe subscriber at the other side is a debezium connector on top of kafka.\n\nPlease don't suggest any architecture changes. Can't implement those.", "author_fullname": "t2_ry9gwrc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setup CDC For changing source replication slot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b6gq4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709573321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Guys, I am trying to setup cdc for our warehouse.&lt;br/&gt;\nI have set it up on dev but the challenge on stage is that the stage db i.e source gets refreshed bi monthly that means the db is restored from prod anonimysed db snapshot.  &lt;/p&gt;\n\n&lt;p&gt;The challenge that i see is, every time that refresh will happen we will loose those publication and replication slot. We can create both the things at time of restore but the LSN would be different and might cause some problems.   &lt;/p&gt;\n\n&lt;p&gt;The subscriber at the other side is a debezium connector on top of kafka.&lt;/p&gt;\n\n&lt;p&gt;Please don&amp;#39;t suggest any architecture changes. Can&amp;#39;t implement those.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b6gq4k", "is_robot_indexable": true, "report_reasons": null, "author": "_Gangadhar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b6gq4k/setup_cdc_for_changing_source_replication_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b6gq4k/setup_cdc_for_changing_source_replication_slot/", "subreddit_subscribers": 165962, "created_utc": 1709573321.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}