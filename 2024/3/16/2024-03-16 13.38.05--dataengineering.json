{"kind": "Listing", "data": {"after": "t3_1bfsb8o", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently received an export from a client\u2019s previous vendor which contained 5,463 columns of Un-normalized data\u2026 I was also given a timeframe of less than a week to build tooling for and migrate this data. \n\nDoes anyone have any tools they\u2019ve used in the past to process this kind of thing? I mainly use Python, pandas, SQLite, Google sheets to extract and transform data (we don\u2019t have infrastructure built yet for streamlined migrations). So far, I\u2019ve removed empty columns and split it into two data frames in order to meet the limit of SQLite 2,000 column max. Still, the data is a mess\u2026 each record, it seems ,was flattened from several tables into a single row for each unique case. \n\nSometimes this isn\u2019t fun anymore lol", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flat file with over 5,000 columns\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfevg2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710511921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently received an export from a client\u2019s previous vendor which contained 5,463 columns of Un-normalized data\u2026 I was also given a timeframe of less than a week to build tooling for and migrate this data. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any tools they\u2019ve used in the past to process this kind of thing? I mainly use Python, pandas, SQLite, Google sheets to extract and transform data (we don\u2019t have infrastructure built yet for streamlined migrations). So far, I\u2019ve removed empty columns and split it into two data frames in order to meet the limit of SQLite 2,000 column max. Still, the data is a mess\u2026 each record, it seems ,was flattened from several tables into a single row for each unique case. &lt;/p&gt;\n\n&lt;p&gt;Sometimes this isn\u2019t fun anymore lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfevg2", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfevg2/flat_file_with_over_5000_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfevg2/flat_file_with_over_5000_columns/", "subreddit_subscribers": 169341, "created_utc": 1710511921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI am currently going over streaming chapter in DE zoomcamp. I have an idea for a project, where I would like to do clickstream analitics. I would like to excersise a heavy load where my single Kafka topic would be bombarded with 10 million messages per minute.\n\nAs part of this process, I would to create a single consumer that would ingest that data and throw it to memory database, eg redis where i would run some queries on top of it.\n\nMy question is, is there an open source framework that has a python api, that would me allow to ingest this much data and throw it into memory db?\nThanks!", "author_fullname": "t2_fw1zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting around 10M events per minute from Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bff92l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710512957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am currently going over streaming chapter in DE zoomcamp. I have an idea for a project, where I would like to do clickstream analitics. I would like to excersise a heavy load where my single Kafka topic would be bombarded with 10 million messages per minute.&lt;/p&gt;\n\n&lt;p&gt;As part of this process, I would to create a single consumer that would ingest that data and throw it to memory database, eg redis where i would run some queries on top of it.&lt;/p&gt;\n\n&lt;p&gt;My question is, is there an open source framework that has a python api, that would me allow to ingest this much data and throw it into memory db?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bff92l", "is_robot_indexable": true, "report_reasons": null, "author": "saif3r", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bff92l/ingesting_around_10m_events_per_minute_from_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bff92l/ingesting_around_10m_events_per_minute_from_kafka/", "subreddit_subscribers": 169341, "created_utc": 1710512957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So for some context, I\u2019m about to graduate with my degree in industrial engineering and I\u2019ve known that I wanted to pursue data engineering for about a year and a half now. Since then I\u2019ve been trying to build myself towards that. I have two internships:\n\nShell (not data related was more research engineering)\n\nRMS (a smaller less known company that I worked as a database administrator for)\n\nI\u2019m about to take my associate cloud engineer exam for GCP and after I get the certificate for that I plan on working towards the professional data engineering certificate. \n\nSo my question here is as a fresh graduate, what jobs should I be applying for if my end goal is data engineer and if I can\u2019t find an entry level data engineering position?", "author_fullname": "t2_2dbrp66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the best entry level jobs to apply for if I want to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfh00d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710519364.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710517476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So for some context, I\u2019m about to graduate with my degree in industrial engineering and I\u2019ve known that I wanted to pursue data engineering for about a year and a half now. Since then I\u2019ve been trying to build myself towards that. I have two internships:&lt;/p&gt;\n\n&lt;p&gt;Shell (not data related was more research engineering)&lt;/p&gt;\n\n&lt;p&gt;RMS (a smaller less known company that I worked as a database administrator for)&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to take my associate cloud engineer exam for GCP and after I get the certificate for that I plan on working towards the professional data engineering certificate. &lt;/p&gt;\n\n&lt;p&gt;So my question here is as a fresh graduate, what jobs should I be applying for if my end goal is data engineer and if I can\u2019t find an entry level data engineering position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfh00d", "is_robot_indexable": true, "report_reasons": null, "author": "iBortex", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfh00d/what_are_some_of_the_best_entry_level_jobs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfh00d/what_are_some_of_the_best_entry_level_jobs_to/", "subreddit_subscribers": 169341, "created_utc": 1710517476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any old timers here remember this *ETL* tool called Ab Initio ? \n\nhttps://www.abinitio.com/en/\n\nBack in 00s, it was a holy grail of ETL tool for F50 banks, retail, insurance etc. Heck even Netflix used it for etl !\n\nWhat happened?\n\nToday in Linkedin there is no developers jobs for this tool.\n\nA few of the jobs are mostly outsourced maintenance.\n\nI know old tools/Mpps like Informatica, Teradata adapted to change and offer cloud/spark/hdfs adapters etc.\n\nAnybody has any idea what happened with Ab Initio and how is any DE with this skill doing ?", "author_fullname": "t2_5ifseipu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A lament for Ab Initio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfk3bf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710525407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any old timers here remember this &lt;em&gt;ETL&lt;/em&gt; tool called Ab Initio ? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.abinitio.com/en/\"&gt;https://www.abinitio.com/en/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Back in 00s, it was a holy grail of ETL tool for F50 banks, retail, insurance etc. Heck even Netflix used it for etl !&lt;/p&gt;\n\n&lt;p&gt;What happened?&lt;/p&gt;\n\n&lt;p&gt;Today in Linkedin there is no developers jobs for this tool.&lt;/p&gt;\n\n&lt;p&gt;A few of the jobs are mostly outsourced maintenance.&lt;/p&gt;\n\n&lt;p&gt;I know old tools/Mpps like Informatica, Teradata adapted to change and offer cloud/spark/hdfs adapters etc.&lt;/p&gt;\n\n&lt;p&gt;Anybody has any idea what happened with Ab Initio and how is any DE with this skill doing ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?auto=webp&amp;s=02708e2cfaede6d2327df1e5c33219acd7f54270", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9627f8dc32e46147963d66ac2754a6add9467b56", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c86035c35c10a431bcdf6c3b29aae238955ce422", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e1961bc1aae2eb95aa64e2fb996bd7db7942330", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dbd85495fc1e6206cb601a413631b19d27df5864", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5a99669e366db277031916d639b75107a3d7133", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=254e6be292a4eb897ce4c62833657ddfedf28422", "width": 1080, "height": 567}], "variants": {}, "id": "pwS9vZT6VYVQjA6ilz_wG4J9ycuTInRmfDBQCdP6b0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfk3bf", "is_robot_indexable": true, "report_reasons": null, "author": "Smart-Weird", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfk3bf/a_lament_for_ab_initio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfk3bf/a_lament_for_ab_initio/", "subreddit_subscribers": 169341, "created_utc": 1710525407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At what point do you decide that you need an API Wrapper around your managed database or regular database?\n\nI would love to get insights into the different factors you are considering, like write / read throughput, security, ease of access for non-data people,...  \n\n\nAlso: what are the hacks and tricks you have picked up around efficient writing and reading beyond throttling and buffering and what tools and services are you using for it?  \n\nThanks for any hints.", "author_fullname": "t2_uc7qtmotr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the point, where you add an API Wrapper around a database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfzpjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710570187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At what point do you decide that you need an API Wrapper around your managed database or regular database?&lt;/p&gt;\n\n&lt;p&gt;I would love to get insights into the different factors you are considering, like write / read throughput, security, ease of access for non-data people,...  &lt;/p&gt;\n\n&lt;p&gt;Also: what are the hacks and tricks you have picked up around efficient writing and reading beyond throttling and buffering and what tools and services are you using for it?  &lt;/p&gt;\n\n&lt;p&gt;Thanks for any hints.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfzpjr", "is_robot_indexable": true, "report_reasons": null, "author": "nicolay-ai", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfzpjr/what_is_the_point_where_you_add_an_api_wrapper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfzpjr/what_is_the_point_where_you_add_an_api_wrapper/", "subreddit_subscribers": 169341, "created_utc": 1710570187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I have created a dataset containing family guy dialogues from season 1 to 19. Anyone interested in text analysis can use this data on kaggle. https://www.kaggle.com/datasets/eswarreddy12/family-guy-dialogues-with-various-lexicon-ratings/data", "author_fullname": "t2_ghx7lafc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataset for family guy dialogues ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfy2sq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710564058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I have created a dataset containing family guy dialogues from season 1 to 19. Anyone interested in text analysis can use this data on kaggle. &lt;a href=\"https://www.kaggle.com/datasets/eswarreddy12/family-guy-dialogues-with-various-lexicon-ratings/data\"&gt;https://www.kaggle.com/datasets/eswarreddy12/family-guy-dialogues-with-various-lexicon-ratings/data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?auto=webp&amp;s=b5f8d8e5df5d0d1b43dd54ebc8cf51ab3d8e7c1f", "width": 1200, "height": 1199}, "resolutions": [{"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6cd6acc61c351fcb50e401e5f27181998e93848c", "width": 108, "height": 107}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9043bd9349b0091fed9a057015664c6512dac99", "width": 216, "height": 215}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b4ac94d455dfc9e7611785be574b33dcb64a246", "width": 320, "height": 319}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=acc4d5d1678e2a1ddc0eb921f08e0a470a7fe514", "width": 640, "height": 639}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cf920ab0f5d42a157baaf979564b9d9fe5c5d94f", "width": 960, "height": 959}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=33f7e818cebc5de9d99c765d6a228fc79f450d87", "width": 1080, "height": 1079}], "variants": {}, "id": "ALSTUekT8HhCTeLMSmTgWNV1TKeRby6Ydk166x7GUpA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bfy2sq", "is_robot_indexable": true, "report_reasons": null, "author": "Content_Drawer_2943", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfy2sq/dataset_for_family_guy_dialogues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfy2sq/dataset_for_family_guy_dialogues/", "subreddit_subscribers": 169341, "created_utc": 1710564058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Okay I need some advice for choosing a training program that will get me job ready for data engineering. I prefer actual training over theory. Are there any good programs that have virtual training for real world examples? Such as building pipelines and using Python.\n\n\nBackground:\n\nWorked as a business analyst, systems analyst and a data analyst for 6 years.\n\nBeen using T-SQL for over 6 years. Need to make the jump into data engineering. Have a little experience in Python.\n\n\n\n\n\n\n", "author_fullname": "t2_exo31rtq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers...what's a great learning program?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfppjz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710539879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay I need some advice for choosing a training program that will get me job ready for data engineering. I prefer actual training over theory. Are there any good programs that have virtual training for real world examples? Such as building pipelines and using Python.&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;Worked as a business analyst, systems analyst and a data analyst for 6 years.&lt;/p&gt;\n\n&lt;p&gt;Been using T-SQL for over 6 years. Need to make the jump into data engineering. Have a little experience in Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfppjz", "is_robot_indexable": true, "report_reasons": null, "author": "Dante_leigh", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfppjz/data_engineerswhats_a_great_learning_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfppjz/data_engineerswhats_a_great_learning_program/", "subreddit_subscribers": 169341, "created_utc": 1710539879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've a pipeline run like this:\n\nextract data from data source -&gt; store into raw table in PostgreSQL -&gt; run another SQL transformation script to load into staging table.\n\n&amp;#x200B;\n\nNow for the third step, I would like to create an automation method to execute the SQL transformation script instead running manually. I expect it to be executed whenever an insertion occurs in the raw table.\n\nI know SQL trigger functions can react to insertion, and I'm not sure if DBT can react to the insertion yet.\n\nMy expectation is: can evoke to run transformation SQL script whenever insertion happens in raw table, and I'm able to record the transformation log to trace the action.\n\n&amp;#x200B;\n\nAny suggestion is appreciated! THanks", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is SQL trigger functions or DBT execution more preferred for data transformation in PostgreSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfe06k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710509411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve a pipeline run like this:&lt;/p&gt;\n\n&lt;p&gt;extract data from data source -&amp;gt; store into raw table in PostgreSQL -&amp;gt; run another SQL transformation script to load into staging table.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now for the third step, I would like to create an automation method to execute the SQL transformation script instead running manually. I expect it to be executed whenever an insertion occurs in the raw table.&lt;/p&gt;\n\n&lt;p&gt;I know SQL trigger functions can react to insertion, and I&amp;#39;m not sure if DBT can react to the insertion yet.&lt;/p&gt;\n\n&lt;p&gt;My expectation is: can evoke to run transformation SQL script whenever insertion happens in raw table, and I&amp;#39;m able to record the transformation log to trace the action.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestion is appreciated! THanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfe06k", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfe06k/is_sql_trigger_functions_or_dbt_execution_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfe06k/is_sql_trigger_functions_or_dbt_execution_more/", "subreddit_subscribers": 169341, "created_utc": 1710509411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you please suggest what pathways one could pursue after doing a masters in data science do data engineering?\n\nThanks for all your suggestions.\n\n&amp;#x200B;", "author_fullname": "t2_143jjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfpn8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710539715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you please suggest what pathways one could pursue after doing a masters in data science do data engineering?&lt;/p&gt;\n\n&lt;p&gt;Thanks for all your suggestions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfpn8q", "is_robot_indexable": true, "report_reasons": null, "author": "Jay12a", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfpn8q/data_science_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfpn8q/data_science_to_data_engineering/", "subreddit_subscribers": 169341, "created_utc": 1710539715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI recently hit this scenario -\n\nPipelines expect a certain schema to exist, this schema changes because life (out of DEs control (prod db?)) =&gt; pipeline breaks =&gt; downtime \n\nDoes this happen to you?\n\nWhat can I do about it?", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preventing pipelines from breaking because of upstream changes ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfdjvj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710508064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I recently hit this scenario -&lt;/p&gt;\n\n&lt;p&gt;Pipelines expect a certain schema to exist, this schema changes because life (out of DEs control (prod db?)) =&amp;gt; pipeline breaks =&amp;gt; downtime &lt;/p&gt;\n\n&lt;p&gt;Does this happen to you?&lt;/p&gt;\n\n&lt;p&gt;What can I do about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfdjvj", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfdjvj/preventing_pipelines_from_breaking_because_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfdjvj/preventing_pipelines_from_breaking_because_of/", "subreddit_subscribers": 169341, "created_utc": 1710508064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Writing this to learn from others experience", "author_fullname": "t2_96xfoily", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am experiencing burnout ..after 6+ years as DE...any suggestions how have others coped with this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfzuwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710570805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Writing this to learn from others experience&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfzuwr", "is_robot_indexable": true, "report_reasons": null, "author": "napolean_911", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfzuwr/i_am_experiencing_burnout_after_6_years_as_deany/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfzuwr/i_am_experiencing_burnout_after_6_years_as_deany/", "subreddit_subscribers": 169341, "created_utc": 1710570805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, new Data Engineer here!\n\nI'm tasked to create CICD for ADF and Databricks.\n\nI understand the importance of pipelines from Dev to UAT and then to Prod. But, I'm a bit unsure about whether I need to create CI for ADF and Databricks in the Dev environment since all the pipelines are already there.\n\nThanks in advance!", "author_fullname": "t2_ap5f9vbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it required to create ADF CI in Dev Env?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bg221u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710580542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, new Data Engineer here!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m tasked to create CICD for ADF and Databricks.&lt;/p&gt;\n\n&lt;p&gt;I understand the importance of pipelines from Dev to UAT and then to Prod. But, I&amp;#39;m a bit unsure about whether I need to create CI for ADF and Databricks in the Dev environment since all the pipelines are already there.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bg221u", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Gur9574", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bg221u/is_it_required_to_create_adf_ci_in_dev_env/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bg221u/is_it_required_to_create_adf_ci_in_dev_env/", "subreddit_subscribers": 169341, "created_utc": 1710580542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building Serverless ELT (that can also run locally)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1bftu0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TDSsz_PESmlXX0bweU_jrnQFSS8V1FSxjQY4DEBAc88.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710550933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/building-local-and-serverless-elt-cq-and-md", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?auto=webp&amp;s=7d38c281f494a85bce1e247be96ec937a50ac39d", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37ec84e7ecc8b5f3cc961e2d7e82a9092d066e88", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7dffac85a85a8b8a94f118e2268ae7aa53318a2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99fd842dae83cdfbcd76664ca026b1ea4ff6d594", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51e51888363ec722549445ca7e2cdae5a6aca0ca", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49622278b5c211082e03b02ee45b4f1f4fe78a89", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=36fcfcd5b6be09a89c3a26464c57e4c9330dfab3", "width": 1080, "height": 607}], "variants": {}, "id": "G6unAVSS7euzYghTG2QZmZ-z1joUbd3D81u9h8w-x7g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bftu0k", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bftu0k/building_serverless_elt_that_can_also_run_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/building-local-and-serverless-elt-cq-and-md", "subreddit_subscribers": 169341, "created_utc": 1710550933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I followed the quick start guide and i'm able to subscribe to objects, just waiting on an event to come through. Wondering what things I can do to get this data into a kafka topic preferable using AWS resources. ", "author_fullname": "t2_vnueu7bje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Salesforce Pub/Sub API to get cdc events into a kafka topic on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfkhdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710526398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I followed the quick start guide and i&amp;#39;m able to subscribe to objects, just waiting on an event to come through. Wondering what things I can do to get this data into a kafka topic preferable using AWS resources. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfkhdp", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Doyle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfkhdp/has_anyone_used_salesforce_pubsub_api_to_get_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfkhdp/has_anyone_used_salesforce_pubsub_api_to_get_cdc/", "subreddit_subscribers": 169341, "created_utc": 1710526398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle orchestration in prod, and why?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite orchestration tool for prod?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfjwdt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710524922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle orchestration in prod, and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfjwdt", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfjwdt/favorite_orchestration_tool_for_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfjwdt/favorite_orchestration_tool_for_prod/", "subreddit_subscribers": 169341, "created_utc": 1710524922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa5dw92do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake FinOps Center - Control and monitor costs with this free Streamlit app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfevv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cztW99v4JlBmYy-f1aqD8w5xM3DnxuEgoHCTvi0Ms2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710511953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "app.snowflake.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://app.snowflake.com/marketplace/listing/GZT8Z2123RJ/baselit-finops-center", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?auto=webp&amp;s=b3c8ef12a1fc8834c8f8e5f91b8776e02bd65c7d", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=067b0f0d8b39972752e8df648542a0eb0f44c78e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b35c87c001a900e0d86832e2ae6adf3ae714f7d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84bc30978b9730b3b342290e0244412fcf9765f1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b28126ea2a6858923a2d8a6c0bb0b5a1e2d033bc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c29935bdd59366f9dddeca916478a805c364d832", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ce18c83f97bc129111ff9672366d1f1c14e13524", "width": 1080, "height": 567}], "variants": {}, "id": "6pwGgdLLEhyeygBB9mofhn0ySjQDLUFfIQfzKSexUVU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bfevv2", "is_robot_indexable": true, "report_reasons": null, "author": "sahil_singla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfevv2/snowflake_finops_center_control_and_monitor_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://app.snowflake.com/marketplace/listing/GZT8Z2123RJ/baselit-finops-center", "subreddit_subscribers": 169341, "created_utc": 1710511953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you know of any interesting problems in software that could be tackled using data engineering skills?  I've seen many people doing projects like having lot of AWS services involved and shifting data from once place to another, but that doesn't solve any real use case (they are kind of showing one's skills). Cases like this [https://www.investopedia.com/simulator/](https://www.investopedia.com/simulator/) where data is constantly generated and given out in the world to learn trading skills (even though they are fake) but still...Something like this which will help people to at least think in the direction of building something which can be put in the world for good.\n\nEDIT: One more example of real life use case of DE skills: [pricetracker.app](http://pricetracker.app) which tracks the price of products on amazon, flipkart etc.", "author_fullname": "t2_c4kloony", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real Problems worth solving with Data Engineering skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bg4g62", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710593061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710590367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you know of any interesting problems in software that could be tackled using data engineering skills?  I&amp;#39;ve seen many people doing projects like having lot of AWS services involved and shifting data from once place to another, but that doesn&amp;#39;t solve any real use case (they are kind of showing one&amp;#39;s skills). Cases like this &lt;a href=\"https://www.investopedia.com/simulator/\"&gt;https://www.investopedia.com/simulator/&lt;/a&gt; where data is constantly generated and given out in the world to learn trading skills (even though they are fake) but still...Something like this which will help people to at least think in the direction of building something which can be put in the world for good.&lt;/p&gt;\n\n&lt;p&gt;EDIT: One more example of real life use case of DE skills: &lt;a href=\"http://pricetracker.app\"&gt;pricetracker.app&lt;/a&gt; which tracks the price of products on amazon, flipkart etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bg4g62", "is_robot_indexable": true, "report_reasons": null, "author": "triesegment", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bg4g62/real_problems_worth_solving_with_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bg4g62/real_problems_worth_solving_with_data_engineering/", "subreddit_subscribers": 169341, "created_utc": 1710590367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working on a pub sub api poc and im the end goal is the get salesforce change events into s3. I have the api setup and listening to events but do I then just write the event to s3 or do I put it in a Kafka topic and gain some added benefit to Kafka? ", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the salesforce pub/sub api in replacement of Kafka or just the Kafka connector? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bg44l6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710589149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a pub sub api poc and im the end goal is the get salesforce change events into s3. I have the api setup and listening to events but do I then just write the event to s3 or do I put it in a Kafka topic and gain some added benefit to Kafka? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bg44l6", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bg44l6/is_the_salesforce_pubsub_api_in_replacement_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bg44l6/is_the_salesforce_pubsub_api_in_replacement_of/", "subreddit_subscribers": 169341, "created_utc": 1710589149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! So, I'm currently working as an entry-level Data Engineer with 3 years of experience under my belt, and I'm really eager to take my career to the next level. On top of that, I'm about to become an international student in the US this fall.\n\nNow, here's the thing: I've been researching Master's in Data Engineering programs, and honestly, there aren't too many options out there. The ones that caught my eye are UNT and UW Madison. I've applied to Madison for the MS DE, along with a bunch of other colleges for MSCS, but I've got some burning questions.\n\nWhat's the scoop on the reputation of a Master's in Data Engineering in the US job market? It seems like a bit of a niche compared to CS. Will having this degree put me at a disadvantage when competing with CS grads for Data Engineering positions? Is it even worth it to pursue a Master's in Data Engineering?\n\nI'm feeling pretty good about my chances at Madison, but I want to make sure I understand how the market views this degree. Any insights or experiences you can share would be super helpful!", "author_fullname": "t2_7lo4eaq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a Master's in Data Engineering Worth It for International Students in the US?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfxq8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710562859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! So, I&amp;#39;m currently working as an entry-level Data Engineer with 3 years of experience under my belt, and I&amp;#39;m really eager to take my career to the next level. On top of that, I&amp;#39;m about to become an international student in the US this fall.&lt;/p&gt;\n\n&lt;p&gt;Now, here&amp;#39;s the thing: I&amp;#39;ve been researching Master&amp;#39;s in Data Engineering programs, and honestly, there aren&amp;#39;t too many options out there. The ones that caught my eye are UNT and UW Madison. I&amp;#39;ve applied to Madison for the MS DE, along with a bunch of other colleges for MSCS, but I&amp;#39;ve got some burning questions.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the scoop on the reputation of a Master&amp;#39;s in Data Engineering in the US job market? It seems like a bit of a niche compared to CS. Will having this degree put me at a disadvantage when competing with CS grads for Data Engineering positions? Is it even worth it to pursue a Master&amp;#39;s in Data Engineering?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m feeling pretty good about my chances at Madison, but I want to make sure I understand how the market views this degree. Any insights or experiences you can share would be super helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfxq8p", "is_robot_indexable": true, "report_reasons": null, "author": "The_late_comer18", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfxq8p/is_a_masters_in_data_engineering_worth_it_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfxq8p/is_a_masters_in_data_engineering_worth_it_for/", "subreddit_subscribers": 169341, "created_utc": 1710562859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m playing with streaming data from f1 games. \n\nBasically I get telemetry from the car via udp, and parse the bytes to float.\n\nWhat solution would you use to:\n\n1) Store this data\n2) Create realtime dashboards ?\n3) Create historical analysis?", "author_fullname": "t2_24zoub6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming + Realtime + Dashboard ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bflawu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710528496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m playing with streaming data from f1 games. &lt;/p&gt;\n\n&lt;p&gt;Basically I get telemetry from the car via udp, and parse the bytes to float.&lt;/p&gt;\n\n&lt;p&gt;What solution would you use to:&lt;/p&gt;\n\n&lt;p&gt;1) Store this data\n2) Create realtime dashboards ?\n3) Create historical analysis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bflawu", "is_robot_indexable": true, "report_reasons": null, "author": "theuzz1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bflawu/streaming_realtime_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bflawu/streaming_realtime_dashboard/", "subreddit_subscribers": 169341, "created_utc": 1710528496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been tasked with getting data that is regularly emailed to us in the form of an xml file into a database. I have gotten past the first step - I can get the file automatically put into a folder (OneDrive/SharePoint). But now I am on to the part of how I can get this data into either a SQL database (which we have) or something else. We are Microsoft leaning, and there are so many tools and options and ETL/ELT options that I'm not even sure what the best thing to do is. I would appreciate any advice that can be given. Much appreciation in advance. If this is the wrong sub for this, please let me know.", "author_fullname": "t2_d2an6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Total Novice, need advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfiznn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710522619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tasked with getting data that is regularly emailed to us in the form of an xml file into a database. I have gotten past the first step - I can get the file automatically put into a folder (OneDrive/SharePoint). But now I am on to the part of how I can get this data into either a SQL database (which we have) or something else. We are Microsoft leaning, and there are so many tools and options and ETL/ELT options that I&amp;#39;m not even sure what the best thing to do is. I would appreciate any advice that can be given. Much appreciation in advance. If this is the wrong sub for this, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfiznn", "is_robot_indexable": true, "report_reasons": null, "author": "inspectornumber5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfiznn/total_novice_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfiznn/total_novice_need_advice/", "subreddit_subscribers": 169341, "created_utc": 1710522619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this type of data, but mostly it's Qualitative values and not numbers, and i need to showcase this on Plotly somehow, any approach you guys would think of ?\n\n&amp;#x200B;\n\nContext on the data: Every Bank in the world has a Rating according of how well they did on the year of Rating, the Rating goes in an alphanumeric value, as you see on columns Short and Long Term Rating(F1+,F2+,BBB,A,etc)  \nI've done several stuff on Dash(Plotly) but mostly my data has been with numbers where i can play with.  \n I just would like to show this data to know which Banks have a good,bad or great Rating and not to show just a table(People non related to numbers who just want to see graphics and all those stuff).  \n\n\nhttps://preview.redd.it/utyjjat6kioc1.png?width=958&amp;format=png&amp;auto=webp&amp;s=126d04b0962008c7646058ed4103e1507e7d2891", "author_fullname": "t2_hbw3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What or how can i show or use for this Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 47, "top_awarded_type": null, "hide_score": false, "media_metadata": {"utyjjat6kioc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7bcd6366f287ac2b28e51dfc9fa360e634c4a1bf"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b54f71058c001f9a05b7faf6ed037c5c0bfd8df"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=858a1cfaf104f52f288194c7e4e1ef941f5a29a4"}, {"y": 215, "x": 640, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=511f561384992ca155e67b7a304a1061a6d20c56"}], "s": {"y": 323, "x": 958, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=958&amp;format=png&amp;auto=webp&amp;s=126d04b0962008c7646058ed4103e1507e7d2891"}, "id": "utyjjat6kioc1"}}, "name": "t3_1bfg9u8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nnx5wmUOAVLIH5rHazARdJFrCjy3roJjGWxZXQNmxPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710515575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this type of data, but mostly it&amp;#39;s Qualitative values and not numbers, and i need to showcase this on Plotly somehow, any approach you guys would think of ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Context on the data: Every Bank in the world has a Rating according of how well they did on the year of Rating, the Rating goes in an alphanumeric value, as you see on columns Short and Long Term Rating(F1+,F2+,BBB,A,etc)&lt;br/&gt;\nI&amp;#39;ve done several stuff on Dash(Plotly) but mostly my data has been with numbers where i can play with.&lt;br/&gt;\n I just would like to show this data to know which Banks have a good,bad or great Rating and not to show just a table(People non related to numbers who just want to see graphics and all those stuff).  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/utyjjat6kioc1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=126d04b0962008c7646058ed4103e1507e7d2891\"&gt;https://preview.redd.it/utyjjat6kioc1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=126d04b0962008c7646058ed4103e1507e7d2891&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfg9u8", "is_robot_indexable": true, "report_reasons": null, "author": "Blast06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfg9u8/what_or_how_can_i_show_or_use_for_this_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfg9u8/what_or_how_can_i_show_or_use_for_this_data/", "subreddit_subscribers": 169341, "created_utc": 1710515575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We used to use the python package mrjob but it is now dead. Before raw dawging boto3, I wanted to see if there are high level python packages or high level approaches that you guys suggest. \n\n&amp;#x200B;\n\nThanks! ", "author_fullname": "t2_xm0tg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for EMR cluster management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfeq9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710511517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We used to use the python package mrjob but it is now dead. Before raw dawging boto3, I wanted to see if there are high level python packages or high level approaches that you guys suggest. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfeq9l", "is_robot_indexable": true, "report_reasons": null, "author": "elephantail", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfeq9l/what_do_you_use_for_emr_cluster_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfeq9l/what_do_you_use_for_emr_cluster_management/", "subreddit_subscribers": 169341, "created_utc": 1710511517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are bigdata and data engineering related, is a bigdata developer can be called a Data Engineer ", "author_fullname": "t2_rtrjd5uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfzjix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710569530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are bigdata and data engineering related, is a bigdata developer can be called a Data Engineer &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfzjix", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Draft_4623", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfzjix/question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfzjix/question/", "subreddit_subscribers": 169341, "created_utc": 1710569530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a beginner data engineer and I wanna read Fundamentals of Data Engineering but I'm not sure if it's right for me at the moment? From my research the biggest criticism of the book is that it's bloated with technical details while not being a textbook and doesn't have enough useful use-cases.\n\nI'm reading DDIA at the moment and I'm really enjoying the pace and find it more or less easy to digest. Is FoDE more difficult than DDIA? Would you recommend it to a beginner who's read DDIA?", "author_fullname": "t2_syp7tbbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fundamentals of Data Engineering vs Designing Data Intensive Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfsb8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710546741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a beginner data engineer and I wanna read Fundamentals of Data Engineering but I&amp;#39;m not sure if it&amp;#39;s right for me at the moment? From my research the biggest criticism of the book is that it&amp;#39;s bloated with technical details while not being a textbook and doesn&amp;#39;t have enough useful use-cases.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reading DDIA at the moment and I&amp;#39;m really enjoying the pace and find it more or less easy to digest. Is FoDE more difficult than DDIA? Would you recommend it to a beginner who&amp;#39;s read DDIA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfsb8o", "is_robot_indexable": true, "report_reasons": null, "author": "Low-Associate2521", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfsb8o/fundamentals_of_data_engineering_vs_designing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfsb8o/fundamentals_of_data_engineering_vs_designing/", "subreddit_subscribers": 169341, "created_utc": 1710546741.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}