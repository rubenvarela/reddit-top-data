{"kind": "Listing", "data": {"after": "t3_1bfaffo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently received an export from a client\u2019s previous vendor which contained 5,463 columns of Un-normalized data\u2026 I was also given a timeframe of less than a week to build tooling for and migrate this data. \n\nDoes anyone have any tools they\u2019ve used in the past to process this kind of thing? I mainly use Python, pandas, SQLite, Google sheets to extract and transform data (we don\u2019t have infrastructure built yet for streamlined migrations). So far, I\u2019ve removed empty columns and split it into two data frames in order to meet the limit of SQLite 2,000 column max. Still, the data is a mess\u2026 each record, it seems ,was flattened from several tables into a single row for each unique case. \n\nSometimes this isn\u2019t fun anymore lol", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flat file with over 5,000 columns\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfevg2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710511921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently received an export from a client\u2019s previous vendor which contained 5,463 columns of Un-normalized data\u2026 I was also given a timeframe of less than a week to build tooling for and migrate this data. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any tools they\u2019ve used in the past to process this kind of thing? I mainly use Python, pandas, SQLite, Google sheets to extract and transform data (we don\u2019t have infrastructure built yet for streamlined migrations). So far, I\u2019ve removed empty columns and split it into two data frames in order to meet the limit of SQLite 2,000 column max. Still, the data is a mess\u2026 each record, it seems ,was flattened from several tables into a single row for each unique case. &lt;/p&gt;\n\n&lt;p&gt;Sometimes this isn\u2019t fun anymore lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfevg2", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfevg2/flat_file_with_over_5000_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfevg2/flat_file_with_over_5000_columns/", "subreddit_subscribers": 169286, "created_utc": 1710511921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI've been working as a Data Engineer for almost 5 years. I mean it was my title, but I think that most of this work was kind of just normal Python development work e.g. building api's with fast API, python library for data manipulation, dashboard app with flask/dash. Of course, 2nd part or even more was building pipelines with Airflow, Kafka, Spark, SQL, Python, and many others. But in the end, my title is Data Engineer, and now I am searching for a new role, and I am thinking about what's a better option. On one side there are fewer DE jobs, and I think these have a better salary, but on the other side: in one company DE = clicking AWS Glue, or writing SQL, whereas in other company is a heavy complex project where you join many other components, build your own, what involves a lot of coding.  \nI see, that for me the most fun is where I have a lot of coding and that's why I am thinking maybe it's better to move into SWE in Python, as I already have a solid foundation. I also love data engineering, but it really depends on the project, cause some are kind of drag and drop, and some really challenging.\n\nBut I wonder if it's no step back, and in the end, it will be more boring. Do you think that DE is a better, future-proof career path? Or Python Developer in CV will give more more possibilities :)\n\n", "author_fullname": "t2_2llofc3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is more future-proof and more secure in terms of work. Python Dev vs Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf8d4j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710489569.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710487868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a Data Engineer for almost 5 years. I mean it was my title, but I think that most of this work was kind of just normal Python development work e.g. building api&amp;#39;s with fast API, python library for data manipulation, dashboard app with flask/dash. Of course, 2nd part or even more was building pipelines with Airflow, Kafka, Spark, SQL, Python, and many others. But in the end, my title is Data Engineer, and now I am searching for a new role, and I am thinking about what&amp;#39;s a better option. On one side there are fewer DE jobs, and I think these have a better salary, but on the other side: in one company DE = clicking AWS Glue, or writing SQL, whereas in other company is a heavy complex project where you join many other components, build your own, what involves a lot of coding.&lt;br/&gt;\nI see, that for me the most fun is where I have a lot of coding and that&amp;#39;s why I am thinking maybe it&amp;#39;s better to move into SWE in Python, as I already have a solid foundation. I also love data engineering, but it really depends on the project, cause some are kind of drag and drop, and some really challenging.&lt;/p&gt;\n\n&lt;p&gt;But I wonder if it&amp;#39;s no step back, and in the end, it will be more boring. Do you think that DE is a better, future-proof career path? Or Python Developer in CV will give more more possibilities :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bf8d4j", "is_robot_indexable": true, "report_reasons": null, "author": "masek94", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf8d4j/which_is_more_futureproof_and_more_secure_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf8d4j/which_is_more_futureproof_and_more_secure_in/", "subreddit_subscribers": 169286, "created_utc": 1710487868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI am currently going over streaming chapter in DE zoomcamp. I have an idea for a project, where I would like to do clickstream analitics. I would like to excersise a heavy load where my single Kafka topic would be bombarded with 10 million messages per minute.\n\nAs part of this process, I would to create a single consumer that would ingest that data and throw it to memory database, eg redis where i would run some queries on top of it.\n\nMy question is, is there an open source framework that has a python api, that would me allow to ingest this much data and throw it into memory db?\nThanks!", "author_fullname": "t2_fw1zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting around 10M events per minute from Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bff92l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710512957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am currently going over streaming chapter in DE zoomcamp. I have an idea for a project, where I would like to do clickstream analitics. I would like to excersise a heavy load where my single Kafka topic would be bombarded with 10 million messages per minute.&lt;/p&gt;\n\n&lt;p&gt;As part of this process, I would to create a single consumer that would ingest that data and throw it to memory database, eg redis where i would run some queries on top of it.&lt;/p&gt;\n\n&lt;p&gt;My question is, is there an open source framework that has a python api, that would me allow to ingest this much data and throw it into memory db?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bff92l", "is_robot_indexable": true, "report_reasons": null, "author": "saif3r", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bff92l/ingesting_around_10m_events_per_minute_from_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bff92l/ingesting_around_10m_events_per_minute_from_kafka/", "subreddit_subscribers": 169286, "created_utc": 1710512957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw some reddit posts on this subreddit and read some articles but I have no clue what photon is. I currently use Apache Airflow, Spark3, and Scala. Python works with airflow to schedule DAG tasks which do very heavy dataframe computations and each of the tasks are ran on the Scala Jars.\n\nI'm pretty new to scala and spark so im basically a noob, can someone explain how Photon will help accelerate my pipeline and dag tasks? I understand that somehow things get re-written in C++. From my understanding once a Scala code gets compiled it gets turned into byte code instead of object code which means scala will run slower compared to C/C++. But I also read on Databricks' website that there would be 0 code changes required so how on earth does that work.\n\nI also read somewhere on this subreddit that it was mostly made for SQL and not for data frames. is this true? If so would this render it useless for my application?\n\nAlso are there other alternatives? I want to increase speed while reducing compute costs", "author_fullname": "t2_tz6ii805", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explain like im 5: Databricks Photon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf8k8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710488800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw some reddit posts on this subreddit and read some articles but I have no clue what photon is. I currently use Apache Airflow, Spark3, and Scala. Python works with airflow to schedule DAG tasks which do very heavy dataframe computations and each of the tasks are ran on the Scala Jars.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to scala and spark so im basically a noob, can someone explain how Photon will help accelerate my pipeline and dag tasks? I understand that somehow things get re-written in C++. From my understanding once a Scala code gets compiled it gets turned into byte code instead of object code which means scala will run slower compared to C/C++. But I also read on Databricks&amp;#39; website that there would be 0 code changes required so how on earth does that work.&lt;/p&gt;\n\n&lt;p&gt;I also read somewhere on this subreddit that it was mostly made for SQL and not for data frames. is this true? If so would this render it useless for my application?&lt;/p&gt;\n\n&lt;p&gt;Also are there other alternatives? I want to increase speed while reducing compute costs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bf8k8q", "is_robot_indexable": true, "report_reasons": null, "author": "bleak-terminal", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf8k8q/explain_like_im_5_databricks_photon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf8k8q/explain_like_im_5_databricks_photon/", "subreddit_subscribers": 169286, "created_utc": 1710488800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So for some context, I\u2019m about to graduate with my degree in industrial engineering and I\u2019ve known that I wanted to pursue data engineering for about a year and a half now. Since then I\u2019ve been trying to build myself towards that. I have two internships:\n\nShell (not data related was more research engineering)\n\nRMS (a smaller less known company that I worked as a database administrator for)\n\nI\u2019m about to take my associate cloud engineer exam for GCP and after I get the certificate for that I plan on working towards the professional data engineering certificate. \n\nSo my question here is as a fresh graduate, what jobs should I be applying for if my end goal is data engineer and if I can\u2019t find an entry level data engineering position?", "author_fullname": "t2_2dbrp66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the best entry level jobs to apply for if I want to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfh00d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710519364.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710517476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So for some context, I\u2019m about to graduate with my degree in industrial engineering and I\u2019ve known that I wanted to pursue data engineering for about a year and a half now. Since then I\u2019ve been trying to build myself towards that. I have two internships:&lt;/p&gt;\n\n&lt;p&gt;Shell (not data related was more research engineering)&lt;/p&gt;\n\n&lt;p&gt;RMS (a smaller less known company that I worked as a database administrator for)&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to take my associate cloud engineer exam for GCP and after I get the certificate for that I plan on working towards the professional data engineering certificate. &lt;/p&gt;\n\n&lt;p&gt;So my question here is as a fresh graduate, what jobs should I be applying for if my end goal is data engineer and if I can\u2019t find an entry level data engineering position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfh00d", "is_robot_indexable": true, "report_reasons": null, "author": "iBortex", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfh00d/what_are_some_of_the_best_entry_level_jobs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfh00d/what_are_some_of_the_best_entry_level_jobs_to/", "subreddit_subscribers": 169286, "created_utc": 1710517476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team's tech stack is completely Azure based and we use ADF for orchestration with pipelines in Databricks and the data sitting in a delta lake in a Storage Account. \n\nThis works well for the most part but for the majority of our pipelines, running Spark is overkill and it could be done using Python or Polars. Many other teams in the firm access the data using their own Databricks Workspaces so I want to keep the data in delta lake but move over some of the DE pipelines into something more suitable and cheaper. I also think certain things such as web scraping using Selenium is overly complex in Databricks and would prefer to develop something like that locally and probably execute elsewhere too.\n\nHow would you recommend going about doing something like this? I'm not too sure of the best architecture for this. My initial thoughts are that we can use VMs to execute our code that we don't want to use Databricks for but I have very little experience with this so some learning recommendations would be helpful too.", "author_fullname": "t2_n937n0g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I move pipelines away from Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfbbqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710500593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team&amp;#39;s tech stack is completely Azure based and we use ADF for orchestration with pipelines in Databricks and the data sitting in a delta lake in a Storage Account. &lt;/p&gt;\n\n&lt;p&gt;This works well for the most part but for the majority of our pipelines, running Spark is overkill and it could be done using Python or Polars. Many other teams in the firm access the data using their own Databricks Workspaces so I want to keep the data in delta lake but move over some of the DE pipelines into something more suitable and cheaper. I also think certain things such as web scraping using Selenium is overly complex in Databricks and would prefer to develop something like that locally and probably execute elsewhere too.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend going about doing something like this? I&amp;#39;m not too sure of the best architecture for this. My initial thoughts are that we can use VMs to execute our code that we don&amp;#39;t want to use Databricks for but I have very little experience with this so some learning recommendations would be helpful too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfbbqt", "is_robot_indexable": true, "report_reasons": null, "author": "piri9825", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfbbqt/how_do_i_move_pipelines_away_from_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfbbqt/how_do_i_move_pipelines_away_from_databricks/", "subreddit_subscribers": 169286, "created_utc": 1710500593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any old timers here remember this *ETL* tool called Ab Initio ? \n\nhttps://www.abinitio.com/en/\n\nBack in 00s, it was a holy grail of ETL tool for F50 banks, retail, insurance etc. Heck even Netflix used it for etl !\n\nWhat happened?\n\nToday in Linkedin there is no developers jobs for this tool.\n\nA few of the jobs are mostly outsourced maintenance.\n\nI know old tools/Mpps like Informatica, Teradata adapted to change and offer cloud/spark/hdfs adapters etc.\n\nAnybody has any idea what happened with Ab Initio and how is any DE with this skill doing ?", "author_fullname": "t2_5ifseipu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A lament for Ab Initio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfk3bf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710525407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any old timers here remember this &lt;em&gt;ETL&lt;/em&gt; tool called Ab Initio ? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.abinitio.com/en/\"&gt;https://www.abinitio.com/en/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Back in 00s, it was a holy grail of ETL tool for F50 banks, retail, insurance etc. Heck even Netflix used it for etl !&lt;/p&gt;\n\n&lt;p&gt;What happened?&lt;/p&gt;\n\n&lt;p&gt;Today in Linkedin there is no developers jobs for this tool.&lt;/p&gt;\n\n&lt;p&gt;A few of the jobs are mostly outsourced maintenance.&lt;/p&gt;\n\n&lt;p&gt;I know old tools/Mpps like Informatica, Teradata adapted to change and offer cloud/spark/hdfs adapters etc.&lt;/p&gt;\n\n&lt;p&gt;Anybody has any idea what happened with Ab Initio and how is any DE with this skill doing ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?auto=webp&amp;s=02708e2cfaede6d2327df1e5c33219acd7f54270", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9627f8dc32e46147963d66ac2754a6add9467b56", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c86035c35c10a431bcdf6c3b29aae238955ce422", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e1961bc1aae2eb95aa64e2fb996bd7db7942330", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dbd85495fc1e6206cb601a413631b19d27df5864", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5a99669e366db277031916d639b75107a3d7133", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=254e6be292a4eb897ce4c62833657ddfedf28422", "width": 1080, "height": 567}], "variants": {}, "id": "pwS9vZT6VYVQjA6ilz_wG4J9ycuTInRmfDBQCdP6b0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfk3bf", "is_robot_indexable": true, "report_reasons": null, "author": "Smart-Weird", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfk3bf/a_lament_for_ab_initio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfk3bf/a_lament_for_ab_initio/", "subreddit_subscribers": 169286, "created_utc": 1710525407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, data lakes unlikes data warehouses let you store unstructured data (text, binary) - does it mean that they are mostly used for this type of data? Or are data lakes mostly used for structured and semi-structured data? But then why choose data lake if we can use data warehouse. What is your experence?", "author_fullname": "t2_34tfcgtu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data lakes mostly used for sturctured and semi-structured data or unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfaon5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710498132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, data lakes unlikes data warehouses let you store unstructured data (text, binary) - does it mean that they are mostly used for this type of data? Or are data lakes mostly used for structured and semi-structured data? But then why choose data lake if we can use data warehouse. What is your experence?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfaon5", "is_robot_indexable": true, "report_reasons": null, "author": "rental_car_abuse", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfaon5/are_data_lakes_mostly_used_for_sturctured_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfaon5/are_data_lakes_mostly_used_for_sturctured_and/", "subreddit_subscribers": 169286, "created_utc": 1710498132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've a pipeline run like this:\n\nextract data from data source -&gt; store into raw table in PostgreSQL -&gt; run another SQL transformation script to load into staging table.\n\n&amp;#x200B;\n\nNow for the third step, I would like to create an automation method to execute the SQL transformation script instead running manually. I expect it to be executed whenever an insertion occurs in the raw table.\n\nI know SQL trigger functions can react to insertion, and I'm not sure if DBT can react to the insertion yet.\n\nMy expectation is: can evoke to run transformation SQL script whenever insertion happens in raw table, and I'm able to record the transformation log to trace the action.\n\n&amp;#x200B;\n\nAny suggestion is appreciated! THanks", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is SQL trigger functions or DBT execution more preferred for data transformation in PostgreSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfe06k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710509411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve a pipeline run like this:&lt;/p&gt;\n\n&lt;p&gt;extract data from data source -&amp;gt; store into raw table in PostgreSQL -&amp;gt; run another SQL transformation script to load into staging table.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now for the third step, I would like to create an automation method to execute the SQL transformation script instead running manually. I expect it to be executed whenever an insertion occurs in the raw table.&lt;/p&gt;\n\n&lt;p&gt;I know SQL trigger functions can react to insertion, and I&amp;#39;m not sure if DBT can react to the insertion yet.&lt;/p&gt;\n\n&lt;p&gt;My expectation is: can evoke to run transformation SQL script whenever insertion happens in raw table, and I&amp;#39;m able to record the transformation log to trace the action.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestion is appreciated! THanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfe06k", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfe06k/is_sql_trigger_functions_or_dbt_execution_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfe06k/is_sql_trigger_functions_or_dbt_execution_more/", "subreddit_subscribers": 169286, "created_utc": 1710509411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you please suggest what pathways one could pursue after doing a masters in data science do data engineering?\n\nThanks for all your suggestions.\n\n&amp;#x200B;", "author_fullname": "t2_143jjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfpn8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710539715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you please suggest what pathways one could pursue after doing a masters in data science do data engineering?&lt;/p&gt;\n\n&lt;p&gt;Thanks for all your suggestions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfpn8q", "is_robot_indexable": true, "report_reasons": null, "author": "Jay12a", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfpn8q/data_science_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfpn8q/data_science_to_data_engineering/", "subreddit_subscribers": 169286, "created_utc": 1710539715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI recently hit this scenario -\n\nPipelines expect a certain schema to exist, this schema changes because life (out of DEs control (prod db?)) =&gt; pipeline breaks =&gt; downtime \n\nDoes this happen to you?\n\nWhat can I do about it?", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preventing pipelines from breaking because of upstream changes ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfdjvj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710508064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I recently hit this scenario -&lt;/p&gt;\n\n&lt;p&gt;Pipelines expect a certain schema to exist, this schema changes because life (out of DEs control (prod db?)) =&amp;gt; pipeline breaks =&amp;gt; downtime &lt;/p&gt;\n\n&lt;p&gt;Does this happen to you?&lt;/p&gt;\n\n&lt;p&gt;What can I do about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfdjvj", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfdjvj/preventing_pipelines_from_breaking_because_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfdjvj/preventing_pipelines_from_breaking_because_of/", "subreddit_subscribers": 169286, "created_utc": 1710508064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Okay I need some advice for choosing a training program that will get me job ready for data engineering. I prefer actual training over theory. Are there any good programs that have virtual training for real world examples? Such as building pipelines and using Python.\n\n\nBackground:\n\nWorked as a business analyst, systems analyst and a data analyst for 6 years.\n\nBeen using T-SQL for over 6 years. Need to make the jump into data engineering. Have a little experience in Python.\n\n\n\n\n\n\n", "author_fullname": "t2_exo31rtq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers...what's a great learning program?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfppjz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710539879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay I need some advice for choosing a training program that will get me job ready for data engineering. I prefer actual training over theory. Are there any good programs that have virtual training for real world examples? Such as building pipelines and using Python.&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;Worked as a business analyst, systems analyst and a data analyst for 6 years.&lt;/p&gt;\n\n&lt;p&gt;Been using T-SQL for over 6 years. Need to make the jump into data engineering. Have a little experience in Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfppjz", "is_robot_indexable": true, "report_reasons": null, "author": "Dante_leigh", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfppjz/data_engineerswhats_a_great_learning_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfppjz/data_engineerswhats_a_great_learning_program/", "subreddit_subscribers": 169286, "created_utc": 1710539879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I have created a dataset containing family guy dialogues from season 1 to 19. Anyone interested in text analysis can use this data on kaggle. https://www.kaggle.com/datasets/eswarreddy12/family-guy-dialogues-with-various-lexicon-ratings/data", "author_fullname": "t2_ghx7lafc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataset for family guy dialogues ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bfy2sq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710564058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I have created a dataset containing family guy dialogues from season 1 to 19. Anyone interested in text analysis can use this data on kaggle. &lt;a href=\"https://www.kaggle.com/datasets/eswarreddy12/family-guy-dialogues-with-various-lexicon-ratings/data\"&gt;https://www.kaggle.com/datasets/eswarreddy12/family-guy-dialogues-with-various-lexicon-ratings/data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?auto=webp&amp;s=b5f8d8e5df5d0d1b43dd54ebc8cf51ab3d8e7c1f", "width": 1200, "height": 1199}, "resolutions": [{"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6cd6acc61c351fcb50e401e5f27181998e93848c", "width": 108, "height": 107}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9043bd9349b0091fed9a057015664c6512dac99", "width": 216, "height": 215}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b4ac94d455dfc9e7611785be574b33dcb64a246", "width": 320, "height": 319}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=acc4d5d1678e2a1ddc0eb921f08e0a470a7fe514", "width": 640, "height": 639}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cf920ab0f5d42a157baaf979564b9d9fe5c5d94f", "width": 960, "height": 959}, {"url": "https://external-preview.redd.it/hTWFkr1FlkvonSVe8xRtfyEKjiPuhfk9lthpVGREGH8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=33f7e818cebc5de9d99c765d6a228fc79f450d87", "width": 1080, "height": 1079}], "variants": {}, "id": "ALSTUekT8HhCTeLMSmTgWNV1TKeRby6Ydk166x7GUpA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bfy2sq", "is_robot_indexable": true, "report_reasons": null, "author": "Content_Drawer_2943", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfy2sq/dataset_for_family_guy_dialogues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfy2sq/dataset_for_family_guy_dialogues/", "subreddit_subscribers": 169286, "created_utc": 1710564058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building Serverless ELT (that can also run locally)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1bftu0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TDSsz_PESmlXX0bweU_jrnQFSS8V1FSxjQY4DEBAc88.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710550933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/building-local-and-serverless-elt-cq-and-md", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?auto=webp&amp;s=7d38c281f494a85bce1e247be96ec937a50ac39d", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37ec84e7ecc8b5f3cc961e2d7e82a9092d066e88", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7dffac85a85a8b8a94f118e2268ae7aa53318a2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99fd842dae83cdfbcd76664ca026b1ea4ff6d594", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51e51888363ec722549445ca7e2cdae5a6aca0ca", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49622278b5c211082e03b02ee45b4f1f4fe78a89", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=36fcfcd5b6be09a89c3a26464c57e4c9330dfab3", "width": 1080, "height": 607}], "variants": {}, "id": "G6unAVSS7euzYghTG2QZmZ-z1joUbd3D81u9h8w-x7g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bftu0k", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bftu0k/building_serverless_elt_that_can_also_run_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/building-local-and-serverless-elt-cq-and-md", "subreddit_subscribers": 169286, "created_utc": 1710550933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I followed the quick start guide and i'm able to subscribe to objects, just waiting on an event to come through. Wondering what things I can do to get this data into a kafka topic preferable using AWS resources. ", "author_fullname": "t2_vnueu7bje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Salesforce Pub/Sub API to get cdc events into a kafka topic on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfkhdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710526398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I followed the quick start guide and i&amp;#39;m able to subscribe to objects, just waiting on an event to come through. Wondering what things I can do to get this data into a kafka topic preferable using AWS resources. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfkhdp", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Doyle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfkhdp/has_anyone_used_salesforce_pubsub_api_to_get_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfkhdp/has_anyone_used_salesforce_pubsub_api_to_get_cdc/", "subreddit_subscribers": 169286, "created_utc": 1710526398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle orchestration in prod, and why?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite orchestration tool for prod?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfjwdt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710524922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle orchestration in prod, and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfjwdt", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfjwdt/favorite_orchestration_tool_for_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfjwdt/favorite_orchestration_tool_for_prod/", "subreddit_subscribers": 169286, "created_utc": 1710524922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa5dw92do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake FinOps Center - Control and monitor costs with this free Streamlit app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfevv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cztW99v4JlBmYy-f1aqD8w5xM3DnxuEgoHCTvi0Ms2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710511953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "app.snowflake.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://app.snowflake.com/marketplace/listing/GZT8Z2123RJ/baselit-finops-center", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?auto=webp&amp;s=b3c8ef12a1fc8834c8f8e5f91b8776e02bd65c7d", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=067b0f0d8b39972752e8df648542a0eb0f44c78e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b35c87c001a900e0d86832e2ae6adf3ae714f7d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84bc30978b9730b3b342290e0244412fcf9765f1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b28126ea2a6858923a2d8a6c0bb0b5a1e2d033bc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c29935bdd59366f9dddeca916478a805c364d832", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ce18c83f97bc129111ff9672366d1f1c14e13524", "width": 1080, "height": 567}], "variants": {}, "id": "6pwGgdLLEhyeygBB9mofhn0ySjQDLUFfIQfzKSexUVU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bfevv2", "is_robot_indexable": true, "report_reasons": null, "author": "sahil_singla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfevv2/snowflake_finops_center_control_and_monitor_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://app.snowflake.com/marketplace/listing/GZT8Z2123RJ/baselit-finops-center", "subreddit_subscribers": 169286, "created_utc": 1710511953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. We have a spark cluster on emr to preprocess the data and move from staging to production layer( as part of lakehouse architecture on s3). The data in staging is on s3 partitioned by downloaded date and hour (date at which the data comes to our system) in increments every hour. We need to preprocess the data and write it to production partitioned by report date (date at which the event occurred). \n\nThe challenge is the source system may update the previously sent data. I.e, for the event recognised by event id which happened last week and was ingested last week, may come again with updated values. We need to update it in out production layer. \n\nWe are currently trying to do it in spark. Every hour we get the staging data (one hour incremental data), get all the data from production layer by distinct report dates and upsert in spark and re write back to prod layer\n\n&amp;#x200B;\n\nData volume.\n\naround 100 million records per day in raw layer (10 gb parquet files)\n\naround 30 million records per day in prod layer (2-3 gb parquet files) (after preprocessing)\n\nEveryday we get around 60 dates older dates data (or 40 dates older dates data per day) which we have to upsert\n\nSo we have to read in spark for every hour data in staging layer (30-40 report dates data from production to upsert which amounts to 180-200GB compressed parquet files, on de-serialization will expand to 1000GB-2000GB)\n\n&amp;#x200B;\n\nThe spark job takes lot of time to complete (1:30 hours to 2 hours on a 7 node cluster with 32 gb machines and 8 core per node). Most of the time is on reads and writes. We have done all the possible optimisations from the spark code and config perspective\n\nFor us it's too long and costly and also not scalable\n\nIs there a better solution for this? How does industry approach this problem? Should we do upsert over any datawarehouse instead of spark?", "author_fullname": "t2_suqqio5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "scalable, performant and cost optimised approach needed for data preprocessing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf7wdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710485861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. We have a spark cluster on emr to preprocess the data and move from staging to production layer( as part of lakehouse architecture on s3). The data in staging is on s3 partitioned by downloaded date and hour (date at which the data comes to our system) in increments every hour. We need to preprocess the data and write it to production partitioned by report date (date at which the event occurred). &lt;/p&gt;\n\n&lt;p&gt;The challenge is the source system may update the previously sent data. I.e, for the event recognised by event id which happened last week and was ingested last week, may come again with updated values. We need to update it in out production layer. &lt;/p&gt;\n\n&lt;p&gt;We are currently trying to do it in spark. Every hour we get the staging data (one hour incremental data), get all the data from production layer by distinct report dates and upsert in spark and re write back to prod layer&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Data volume.&lt;/p&gt;\n\n&lt;p&gt;around 100 million records per day in raw layer (10 gb parquet files)&lt;/p&gt;\n\n&lt;p&gt;around 30 million records per day in prod layer (2-3 gb parquet files) (after preprocessing)&lt;/p&gt;\n\n&lt;p&gt;Everyday we get around 60 dates older dates data (or 40 dates older dates data per day) which we have to upsert&lt;/p&gt;\n\n&lt;p&gt;So we have to read in spark for every hour data in staging layer (30-40 report dates data from production to upsert which amounts to 180-200GB compressed parquet files, on de-serialization will expand to 1000GB-2000GB)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The spark job takes lot of time to complete (1:30 hours to 2 hours on a 7 node cluster with 32 gb machines and 8 core per node). Most of the time is on reads and writes. We have done all the possible optimisations from the spark code and config perspective&lt;/p&gt;\n\n&lt;p&gt;For us it&amp;#39;s too long and costly and also not scalable&lt;/p&gt;\n\n&lt;p&gt;Is there a better solution for this? How does industry approach this problem? Should we do upsert over any datawarehouse instead of spark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bf7wdx", "is_robot_indexable": true, "report_reasons": null, "author": "sud004", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf7wdx/scalable_performant_and_cost_optimised_approach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf7wdx/scalable_performant_and_cost_optimised_approach/", "subreddit_subscribers": 169286, "created_utc": 1710485861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! So, I'm currently working as an entry-level Data Engineer with 3 years of experience under my belt, and I'm really eager to take my career to the next level. On top of that, I'm about to become an international student in the US this fall.\n\nNow, here's the thing: I've been researching Master's in Data Engineering programs, and honestly, there aren't too many options out there. The ones that caught my eye are UNT and UW Madison. I've applied to Madison for the MS DE, along with a bunch of other colleges for MSCS, but I've got some burning questions.\n\nWhat's the scoop on the reputation of a Master's in Data Engineering in the US job market? It seems like a bit of a niche compared to CS. Will having this degree put me at a disadvantage when competing with CS grads for Data Engineering positions? Is it even worth it to pursue a Master's in Data Engineering?\n\nI'm feeling pretty good about my chances at Madison, but I want to make sure I understand how the market views this degree. Any insights or experiences you can share would be super helpful!", "author_fullname": "t2_7lo4eaq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a Master's in Data Engineering Worth It for International Students in the US?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfxq8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710562859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! So, I&amp;#39;m currently working as an entry-level Data Engineer with 3 years of experience under my belt, and I&amp;#39;m really eager to take my career to the next level. On top of that, I&amp;#39;m about to become an international student in the US this fall.&lt;/p&gt;\n\n&lt;p&gt;Now, here&amp;#39;s the thing: I&amp;#39;ve been researching Master&amp;#39;s in Data Engineering programs, and honestly, there aren&amp;#39;t too many options out there. The ones that caught my eye are UNT and UW Madison. I&amp;#39;ve applied to Madison for the MS DE, along with a bunch of other colleges for MSCS, but I&amp;#39;ve got some burning questions.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the scoop on the reputation of a Master&amp;#39;s in Data Engineering in the US job market? It seems like a bit of a niche compared to CS. Will having this degree put me at a disadvantage when competing with CS grads for Data Engineering positions? Is it even worth it to pursue a Master&amp;#39;s in Data Engineering?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m feeling pretty good about my chances at Madison, but I want to make sure I understand how the market views this degree. Any insights or experiences you can share would be super helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfxq8p", "is_robot_indexable": true, "report_reasons": null, "author": "The_late_comer18", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfxq8p/is_a_masters_in_data_engineering_worth_it_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfxq8p/is_a_masters_in_data_engineering_worth_it_for/", "subreddit_subscribers": 169286, "created_utc": 1710562859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m playing with streaming data from f1 games. \n\nBasically I get telemetry from the car via udp, and parse the bytes to float.\n\nWhat solution would you use to:\n\n1) Store this data\n2) Create realtime dashboards ?\n3) Create historical analysis?", "author_fullname": "t2_24zoub6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming + Realtime + Dashboard ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bflawu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710528496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m playing with streaming data from f1 games. &lt;/p&gt;\n\n&lt;p&gt;Basically I get telemetry from the car via udp, and parse the bytes to float.&lt;/p&gt;\n\n&lt;p&gt;What solution would you use to:&lt;/p&gt;\n\n&lt;p&gt;1) Store this data\n2) Create realtime dashboards ?\n3) Create historical analysis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bflawu", "is_robot_indexable": true, "report_reasons": null, "author": "theuzz1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bflawu/streaming_realtime_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bflawu/streaming_realtime_dashboard/", "subreddit_subscribers": 169286, "created_utc": 1710528496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been tasked with getting data that is regularly emailed to us in the form of an xml file into a database. I have gotten past the first step - I can get the file automatically put into a folder (OneDrive/SharePoint). But now I am on to the part of how I can get this data into either a SQL database (which we have) or something else. We are Microsoft leaning, and there are so many tools and options and ETL/ELT options that I'm not even sure what the best thing to do is. I would appreciate any advice that can be given. Much appreciation in advance. If this is the wrong sub for this, please let me know.", "author_fullname": "t2_d2an6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Total Novice, need advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfiznn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710522619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tasked with getting data that is regularly emailed to us in the form of an xml file into a database. I have gotten past the first step - I can get the file automatically put into a folder (OneDrive/SharePoint). But now I am on to the part of how I can get this data into either a SQL database (which we have) or something else. We are Microsoft leaning, and there are so many tools and options and ETL/ELT options that I&amp;#39;m not even sure what the best thing to do is. I would appreciate any advice that can be given. Much appreciation in advance. If this is the wrong sub for this, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfiznn", "is_robot_indexable": true, "report_reasons": null, "author": "inspectornumber5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfiznn/total_novice_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfiznn/total_novice_need_advice/", "subreddit_subscribers": 169286, "created_utc": 1710522619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this type of data, but mostly it's Qualitative values and not numbers, and i need to showcase this on Plotly somehow, any approach you guys would think of ?\n\n&amp;#x200B;\n\nContext on the data: Every Bank in the world has a Rating according of how well they did on the year of Rating, the Rating goes in an alphanumeric value, as you see on columns Short and Long Term Rating(F1+,F2+,BBB,A,etc)  \nI've done several stuff on Dash(Plotly) but mostly my data has been with numbers where i can play with.  \n I just would like to show this data to know which Banks have a good,bad or great Rating and not to show just a table(People non related to numbers who just want to see graphics and all those stuff).  \n\n\nhttps://preview.redd.it/utyjjat6kioc1.png?width=958&amp;format=png&amp;auto=webp&amp;s=126d04b0962008c7646058ed4103e1507e7d2891", "author_fullname": "t2_hbw3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What or how can i show or use for this Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 47, "top_awarded_type": null, "hide_score": false, "media_metadata": {"utyjjat6kioc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7bcd6366f287ac2b28e51dfc9fa360e634c4a1bf"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b54f71058c001f9a05b7faf6ed037c5c0bfd8df"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=858a1cfaf104f52f288194c7e4e1ef941f5a29a4"}, {"y": 215, "x": 640, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=511f561384992ca155e67b7a304a1061a6d20c56"}], "s": {"y": 323, "x": 958, "u": "https://preview.redd.it/utyjjat6kioc1.png?width=958&amp;format=png&amp;auto=webp&amp;s=126d04b0962008c7646058ed4103e1507e7d2891"}, "id": "utyjjat6kioc1"}}, "name": "t3_1bfg9u8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nnx5wmUOAVLIH5rHazARdJFrCjy3roJjGWxZXQNmxPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710515575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this type of data, but mostly it&amp;#39;s Qualitative values and not numbers, and i need to showcase this on Plotly somehow, any approach you guys would think of ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Context on the data: Every Bank in the world has a Rating according of how well they did on the year of Rating, the Rating goes in an alphanumeric value, as you see on columns Short and Long Term Rating(F1+,F2+,BBB,A,etc)&lt;br/&gt;\nI&amp;#39;ve done several stuff on Dash(Plotly) but mostly my data has been with numbers where i can play with.&lt;br/&gt;\n I just would like to show this data to know which Banks have a good,bad or great Rating and not to show just a table(People non related to numbers who just want to see graphics and all those stuff).  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/utyjjat6kioc1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=126d04b0962008c7646058ed4103e1507e7d2891\"&gt;https://preview.redd.it/utyjjat6kioc1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=126d04b0962008c7646058ed4103e1507e7d2891&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfg9u8", "is_robot_indexable": true, "report_reasons": null, "author": "Blast06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfg9u8/what_or_how_can_i_show_or_use_for_this_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfg9u8/what_or_how_can_i_show_or_use_for_this_data/", "subreddit_subscribers": 169286, "created_utc": 1710515575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We used to use the python package mrjob but it is now dead. Before raw dawging boto3, I wanted to see if there are high level python packages or high level approaches that you guys suggest. \n\n&amp;#x200B;\n\nThanks! ", "author_fullname": "t2_xm0tg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for EMR cluster management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfeq9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710511517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We used to use the python package mrjob but it is now dead. Before raw dawging boto3, I wanted to see if there are high level python packages or high level approaches that you guys suggest. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfeq9l", "is_robot_indexable": true, "report_reasons": null, "author": "elephantail", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfeq9l/what_do_you_use_for_emr_cluster_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfeq9l/what_do_you_use_for_emr_cluster_management/", "subreddit_subscribers": 169286, "created_utc": 1710511517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used Y42? I've been looking into it, it seems fairly nice. It's a fairly new tool (created in the past 4 years), so I'm wondering if people have had any issues with reliability or anything like that. I'd love to hear anyone's experience with the tool.\n\nAlso, does anyone have any idea of what the pricing looks like for Enterprise? \n\nFurthermore, can the tool only be deployed for cloud or VPC environments? Or is it possible to locally deploy Y42?", "author_fullname": "t2_mc935wf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Y42", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfdc90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710507440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used Y42? I&amp;#39;ve been looking into it, it seems fairly nice. It&amp;#39;s a fairly new tool (created in the past 4 years), so I&amp;#39;m wondering if people have had any issues with reliability or anything like that. I&amp;#39;d love to hear anyone&amp;#39;s experience with the tool.&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone have any idea of what the pricing looks like for Enterprise? &lt;/p&gt;\n\n&lt;p&gt;Furthermore, can the tool only be deployed for cloud or VPC environments? Or is it possible to locally deploy Y42?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfdc90", "is_robot_indexable": true, "report_reasons": null, "author": "ValidInternetCitizen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfdc90/why_y42/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfdc90/why_y42/", "subreddit_subscribers": 169286, "created_utc": 1710507440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi community, I'm working on our distributed time-series database which leverages a shared storage architecture. In its newest version, we support migrating data table partitions (Regions) from one datanode to another.\n\nSince we utilize a shared storage architecture, where data files are stored on object storage and shared across multiple Datanodes. **Region Migration only requires the migration of a small amount of local data from the Datanode Memtable** compared to databases employing a Shared Nothing architecture, resulting in reduced overall migration durations and a more seamless load-balancing experience at the higher layers.\n\nI share our technical specifics here in [this article](https://www.greptime.com/blogs/2024-03-15-region-migration) and welcome open discussion.", "author_fullname": "t2_ueonzal5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High-Efficiency Data Migration Under Shared Storage Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfaffo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710497109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community, I&amp;#39;m working on our distributed time-series database which leverages a shared storage architecture. In its newest version, we support migrating data table partitions (Regions) from one datanode to another.&lt;/p&gt;\n\n&lt;p&gt;Since we utilize a shared storage architecture, where data files are stored on object storage and shared across multiple Datanodes. &lt;strong&gt;Region Migration only requires the migration of a small amount of local data from the Datanode Memtable&lt;/strong&gt; compared to databases employing a Shared Nothing architecture, resulting in reduced overall migration durations and a more seamless load-balancing experience at the higher layers.&lt;/p&gt;\n\n&lt;p&gt;I share our technical specifics here in &lt;a href=\"https://www.greptime.com/blogs/2024-03-15-region-migration\"&gt;this article&lt;/a&gt; and welcome open discussion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?auto=webp&amp;s=be29aa5b8078cb99e745d407a7cbfc442e44e0c4", "width": 1280, "height": 736}, "resolutions": [{"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d4c177d397bee85772cd3e17e64385ea8e603a31", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=39684a2654f2dcb3523ee705d6707e3dbc43a994", "width": 216, "height": 124}, {"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=08999b43eda43189fa33fabb7aaa72399c8bee27", "width": 320, "height": 184}, {"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f5f90d55a3edc02e9217f56d26ccbdba569ecc9", "width": 640, "height": 368}, {"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f23fedfac3b190170d5a47a4294c192fe161ad43", "width": 960, "height": 552}, {"url": "https://external-preview.redd.it/NVZ6Xa7JmZpa8RoBZBz7CMsODmWLD1p5bmxD3WB3Rxs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16a74ebb926d6af03a933e0d5e1d5aee4ebcaab0", "width": 1080, "height": 621}], "variants": {}, "id": "2im7zCCnMsXeFkFIGzA6xvGu_M-se6vXPeE2V0xbPW0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bfaffo", "is_robot_indexable": true, "report_reasons": null, "author": "jeremy_feng", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfaffo/highefficiency_data_migration_under_shared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfaffo/highefficiency_data_migration_under_shared/", "subreddit_subscribers": 169286, "created_utc": 1710497109.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}