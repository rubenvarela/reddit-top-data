{"kind": "Listing", "data": {"after": "t3_1bflawu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "AI at this point is inevitable and it\u2019s become quite clear to me that the roles and responsibilities of a data engineer today will significantly change as AI tools become more common place. At this point it\u2019s  all speculative but my questions are\nA) what does the data engineer of tomorrow look like\nB) how can I adapt to a changing landscape and essentially future proof my career\n\nAny advice will be greatly appreciated!", "author_fullname": "t2_7iiccjhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I future proof my career as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf4aft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710472745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AI at this point is inevitable and it\u2019s become quite clear to me that the roles and responsibilities of a data engineer today will significantly change as AI tools become more common place. At this point it\u2019s  all speculative but my questions are\nA) what does the data engineer of tomorrow look like\nB) how can I adapt to a changing landscape and essentially future proof my career&lt;/p&gt;\n\n&lt;p&gt;Any advice will be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bf4aft", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Advisor-8235", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf4aft/how_do_i_future_proof_my_career_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf4aft/how_do_i_future_proof_my_career_as_a_data_engineer/", "subreddit_subscribers": 169248, "created_utc": 1710472745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently received an export from a client\u2019s previous vendor which contained 5,463 columns of Un-normalized data\u2026 I was also given a timeframe of less than a week to build tooling for and migrate this data. \n\nDoes anyone have any tools they\u2019ve used in the past to process this kind of thing? I mainly use Python, pandas, SQLite, Google sheets to extract and transform data (we don\u2019t have infrastructure built yet for streamlined migrations). So far, I\u2019ve removed empty columns and split it into two data frames in order to meet the limit of SQLite 2,000 column max. Still, the data is a mess\u2026 each record, it seems ,was flattened from several tables into a single row for each unique case. \n\nSometimes this isn\u2019t fun anymore lol", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flat file with over 5,000 columns\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfevg2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710511921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently received an export from a client\u2019s previous vendor which contained 5,463 columns of Un-normalized data\u2026 I was also given a timeframe of less than a week to build tooling for and migrate this data. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any tools they\u2019ve used in the past to process this kind of thing? I mainly use Python, pandas, SQLite, Google sheets to extract and transform data (we don\u2019t have infrastructure built yet for streamlined migrations). So far, I\u2019ve removed empty columns and split it into two data frames in order to meet the limit of SQLite 2,000 column max. Still, the data is a mess\u2026 each record, it seems ,was flattened from several tables into a single row for each unique case. &lt;/p&gt;\n\n&lt;p&gt;Sometimes this isn\u2019t fun anymore lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfevg2", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfevg2/flat_file_with_over_5000_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfevg2/flat_file_with_over_5000_columns/", "subreddit_subscribers": 169248, "created_utc": 1710511921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI've been working as a Data Engineer for almost 5 years. I mean it was my title, but I think that most of this work was kind of just normal Python development work e.g. building api's with fast API, python library for data manipulation, dashboard app with flask/dash. Of course, 2nd part or even more was building pipelines with Airflow, Kafka, Spark, SQL, Python, and many others. But in the end, my title is Data Engineer, and now I am searching for a new role, and I am thinking about what's a better option. On one side there are fewer DE jobs, and I think these have a better salary, but on the other side: in one company DE = clicking AWS Glue, or writing SQL, whereas in other company is a heavy complex project where you join many other components, build your own, what involves a lot of coding.  \nI see, that for me the most fun is where I have a lot of coding and that's why I am thinking maybe it's better to move into SWE in Python, as I already have a solid foundation. I also love data engineering, but it really depends on the project, cause some are kind of drag and drop, and some really challenging.\n\nBut I wonder if it's no step back, and in the end, it will be more boring. Do you think that DE is a better, future-proof career path? Or Python Developer in CV will give more more possibilities :)\n\n", "author_fullname": "t2_2llofc3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is more future-proof and more secure in terms of work. Python Dev vs Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf8d4j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710489569.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710487868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a Data Engineer for almost 5 years. I mean it was my title, but I think that most of this work was kind of just normal Python development work e.g. building api&amp;#39;s with fast API, python library for data manipulation, dashboard app with flask/dash. Of course, 2nd part or even more was building pipelines with Airflow, Kafka, Spark, SQL, Python, and many others. But in the end, my title is Data Engineer, and now I am searching for a new role, and I am thinking about what&amp;#39;s a better option. On one side there are fewer DE jobs, and I think these have a better salary, but on the other side: in one company DE = clicking AWS Glue, or writing SQL, whereas in other company is a heavy complex project where you join many other components, build your own, what involves a lot of coding.&lt;br/&gt;\nI see, that for me the most fun is where I have a lot of coding and that&amp;#39;s why I am thinking maybe it&amp;#39;s better to move into SWE in Python, as I already have a solid foundation. I also love data engineering, but it really depends on the project, cause some are kind of drag and drop, and some really challenging.&lt;/p&gt;\n\n&lt;p&gt;But I wonder if it&amp;#39;s no step back, and in the end, it will be more boring. Do you think that DE is a better, future-proof career path? Or Python Developer in CV will give more more possibilities :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bf8d4j", "is_robot_indexable": true, "report_reasons": null, "author": "masek94", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf8d4j/which_is_more_futureproof_and_more_secure_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf8d4j/which_is_more_futureproof_and_more_secure_in/", "subreddit_subscribers": 169248, "created_utc": 1710487868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw some reddit posts on this subreddit and read some articles but I have no clue what photon is. I currently use Apache Airflow, Spark3, and Scala. Python works with airflow to schedule DAG tasks which do very heavy dataframe computations and each of the tasks are ran on the Scala Jars.\n\nI'm pretty new to scala and spark so im basically a noob, can someone explain how Photon will help accelerate my pipeline and dag tasks? I understand that somehow things get re-written in C++. From my understanding once a Scala code gets compiled it gets turned into byte code instead of object code which means scala will run slower compared to C/C++. But I also read on Databricks' website that there would be 0 code changes required so how on earth does that work.\n\nI also read somewhere on this subreddit that it was mostly made for SQL and not for data frames. is this true? If so would this render it useless for my application?\n\nAlso are there other alternatives? I want to increase speed while reducing compute costs", "author_fullname": "t2_tz6ii805", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explain like im 5: Databricks Photon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf8k8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710488800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw some reddit posts on this subreddit and read some articles but I have no clue what photon is. I currently use Apache Airflow, Spark3, and Scala. Python works with airflow to schedule DAG tasks which do very heavy dataframe computations and each of the tasks are ran on the Scala Jars.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to scala and spark so im basically a noob, can someone explain how Photon will help accelerate my pipeline and dag tasks? I understand that somehow things get re-written in C++. From my understanding once a Scala code gets compiled it gets turned into byte code instead of object code which means scala will run slower compared to C/C++. But I also read on Databricks&amp;#39; website that there would be 0 code changes required so how on earth does that work.&lt;/p&gt;\n\n&lt;p&gt;I also read somewhere on this subreddit that it was mostly made for SQL and not for data frames. is this true? If so would this render it useless for my application?&lt;/p&gt;\n\n&lt;p&gt;Also are there other alternatives? I want to increase speed while reducing compute costs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bf8k8q", "is_robot_indexable": true, "report_reasons": null, "author": "bleak-terminal", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf8k8q/explain_like_im_5_databricks_photon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf8k8q/explain_like_im_5_databricks_photon/", "subreddit_subscribers": 169248, "created_utc": 1710488800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI am currently going over streaming chapter in DE zoomcamp. I have an idea for a project, where I would like to do clickstream analitics. I would like to excersise a heavy load where my single Kafka topic would be bombarded with 10 million messages per minute.\n\nAs part of this process, I would to create a single consumer that would ingest that data and throw it to memory database, eg redis where i would run some queries on top of it.\n\nMy question is, is there an open source framework that has a python api, that would me allow to ingest this much data and throw it into memory db?\nThanks!", "author_fullname": "t2_fw1zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting around 10M events per minute from Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bff92l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710512957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am currently going over streaming chapter in DE zoomcamp. I have an idea for a project, where I would like to do clickstream analitics. I would like to excersise a heavy load where my single Kafka topic would be bombarded with 10 million messages per minute.&lt;/p&gt;\n\n&lt;p&gt;As part of this process, I would to create a single consumer that would ingest that data and throw it to memory database, eg redis where i would run some queries on top of it.&lt;/p&gt;\n\n&lt;p&gt;My question is, is there an open source framework that has a python api, that would me allow to ingest this much data and throw it into memory db?\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bff92l", "is_robot_indexable": true, "report_reasons": null, "author": "saif3r", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bff92l/ingesting_around_10m_events_per_minute_from_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bff92l/ingesting_around_10m_events_per_minute_from_kafka/", "subreddit_subscribers": 169248, "created_utc": 1710512957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious to find out whether you use the BI tool or rely on SQL to get insights from data. In my experience, the BI tools can be complex and also quite limited in their utility for detailed analytics tasks. What do you currently use today for your analytics workflow, and what do you love and hate about it?", "author_fullname": "t2_ez4cm3m01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BI tools!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf5ij4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710476663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to find out whether you use the BI tool or rely on SQL to get insights from data. In my experience, the BI tools can be complex and also quite limited in their utility for detailed analytics tasks. What do you currently use today for your analytics workflow, and what do you love and hate about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bf5ij4", "is_robot_indexable": true, "report_reasons": null, "author": "glinter777", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf5ij4/bi_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf5ij4/bi_tools/", "subreddit_subscribers": 169248, "created_utc": 1710476663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team's tech stack is completely Azure based and we use ADF for orchestration with pipelines in Databricks and the data sitting in a delta lake in a Storage Account. \n\nThis works well for the most part but for the majority of our pipelines, running Spark is overkill and it could be done using Python or Polars. Many other teams in the firm access the data using their own Databricks Workspaces so I want to keep the data in delta lake but move over some of the DE pipelines into something more suitable and cheaper. I also think certain things such as web scraping using Selenium is overly complex in Databricks and would prefer to develop something like that locally and probably execute elsewhere too.\n\nHow would you recommend going about doing something like this? I'm not too sure of the best architecture for this. My initial thoughts are that we can use VMs to execute our code that we don't want to use Databricks for but I have very little experience with this so some learning recommendations would be helpful too.", "author_fullname": "t2_n937n0g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I move pipelines away from Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfbbqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710500593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team&amp;#39;s tech stack is completely Azure based and we use ADF for orchestration with pipelines in Databricks and the data sitting in a delta lake in a Storage Account. &lt;/p&gt;\n\n&lt;p&gt;This works well for the most part but for the majority of our pipelines, running Spark is overkill and it could be done using Python or Polars. Many other teams in the firm access the data using their own Databricks Workspaces so I want to keep the data in delta lake but move over some of the DE pipelines into something more suitable and cheaper. I also think certain things such as web scraping using Selenium is overly complex in Databricks and would prefer to develop something like that locally and probably execute elsewhere too.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend going about doing something like this? I&amp;#39;m not too sure of the best architecture for this. My initial thoughts are that we can use VMs to execute our code that we don&amp;#39;t want to use Databricks for but I have very little experience with this so some learning recommendations would be helpful too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfbbqt", "is_robot_indexable": true, "report_reasons": null, "author": "piri9825", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfbbqt/how_do_i_move_pipelines_away_from_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfbbqt/how_do_i_move_pipelines_away_from_databricks/", "subreddit_subscribers": 169248, "created_utc": 1710500593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tb9gsv8ek", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Figma's Databases Team Lived to Tell the Scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf5csb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8xbuhoCS2I4KUMWrLfS95pUZth0IhtqhuZrGN49f2HA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710476129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "figma.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?auto=webp&amp;s=b02d84f548d7016532bde698df50f6ad2964cdde", "width": 1200, "height": 899}, "resolutions": [{"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb49ef81566c7f3362de32f19bcbb0503eab41d3", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a47aeec8959e0854c7645af187400ef2b2b8d778", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff4a41b271855634f3f31a1a95d0a1923e5663d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf08e010042ff3adc093c447f05b01d35617f4f8", "width": 640, "height": 479}, {"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=64c428fb6bb53fc271e92487969781f20a0cf5c2", "width": 960, "height": 719}, {"url": "https://external-preview.redd.it/cPfhzsD3qR8AKrrpfJwab-Z2MrviATve6DlFGl8GDQc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b089381d255a531b9dfc063c300fc4d51d3ba692", "width": 1080, "height": 809}], "variants": {}, "id": "Sh9ywQbgHtUAXOpENNdmfZpxlwzzyYcC3r9bH8mkHRA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bf5csb", "is_robot_indexable": true, "report_reasons": null, "author": "Rollstack", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf5csb/how_figmas_databases_team_lived_to_tell_the_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/", "subreddit_subscribers": 169248, "created_utc": 1710476129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any old timers here remember this *ETL* tool called Ab Initio ? \n\nhttps://www.abinitio.com/en/\n\nBack in 00s, it was a holy grail of ETL tool for F50 banks, retail, insurance etc. Heck even Netflix used it for etl !\n\nWhat happened?\n\nToday in Linkedin there is no developers jobs for this tool.\n\nA few of the jobs are mostly outsourced maintenance.\n\nI know old tools/Mpps like Informatica, Teradata adapted to change and offer cloud/spark/hdfs adapters etc.\n\nAnybody has any idea what happened with Ab Initio and how is any DE with this skill doing ?", "author_fullname": "t2_5ifseipu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A lament for Ab Initio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfk3bf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710525407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any old timers here remember this &lt;em&gt;ETL&lt;/em&gt; tool called Ab Initio ? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.abinitio.com/en/\"&gt;https://www.abinitio.com/en/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Back in 00s, it was a holy grail of ETL tool for F50 banks, retail, insurance etc. Heck even Netflix used it for etl !&lt;/p&gt;\n\n&lt;p&gt;What happened?&lt;/p&gt;\n\n&lt;p&gt;Today in Linkedin there is no developers jobs for this tool.&lt;/p&gt;\n\n&lt;p&gt;A few of the jobs are mostly outsourced maintenance.&lt;/p&gt;\n\n&lt;p&gt;I know old tools/Mpps like Informatica, Teradata adapted to change and offer cloud/spark/hdfs adapters etc.&lt;/p&gt;\n\n&lt;p&gt;Anybody has any idea what happened with Ab Initio and how is any DE with this skill doing ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?auto=webp&amp;s=02708e2cfaede6d2327df1e5c33219acd7f54270", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9627f8dc32e46147963d66ac2754a6add9467b56", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c86035c35c10a431bcdf6c3b29aae238955ce422", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e1961bc1aae2eb95aa64e2fb996bd7db7942330", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dbd85495fc1e6206cb601a413631b19d27df5864", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5a99669e366db277031916d639b75107a3d7133", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pDI4LVMNOdGs0gmmTtLv8A0QsObIBS-drCTxMCm0bzQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=254e6be292a4eb897ce4c62833657ddfedf28422", "width": 1080, "height": 567}], "variants": {}, "id": "pwS9vZT6VYVQjA6ilz_wG4J9ycuTInRmfDBQCdP6b0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfk3bf", "is_robot_indexable": true, "report_reasons": null, "author": "Smart-Weird", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfk3bf/a_lament_for_ab_initio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfk3bf/a_lament_for_ab_initio/", "subreddit_subscribers": 169248, "created_utc": 1710525407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So for some context, I\u2019m about to graduate with my degree in industrial engineering and I\u2019ve known that I wanted to pursue data engineering for about a year and a half now. Since then I\u2019ve been trying to build myself towards that. I have two internships:\n\nShell (not data related was more research engineering)\n\nRMS (a smaller less known company that I worked as a database administrator for)\n\nI\u2019m about to take my associate cloud engineer exam for GCP and after I get the certificate for that I plan on working towards the professional data engineering certificate. \n\nSo my question here is as a fresh graduate, what jobs should I be applying for if my end goal is data engineer and if I can\u2019t find an entry level data engineering position?", "author_fullname": "t2_2dbrp66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the best entry level jobs to apply for if I want to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfh00d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710519364.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710517476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So for some context, I\u2019m about to graduate with my degree in industrial engineering and I\u2019ve known that I wanted to pursue data engineering for about a year and a half now. Since then I\u2019ve been trying to build myself towards that. I have two internships:&lt;/p&gt;\n\n&lt;p&gt;Shell (not data related was more research engineering)&lt;/p&gt;\n\n&lt;p&gt;RMS (a smaller less known company that I worked as a database administrator for)&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to take my associate cloud engineer exam for GCP and after I get the certificate for that I plan on working towards the professional data engineering certificate. &lt;/p&gt;\n\n&lt;p&gt;So my question here is as a fresh graduate, what jobs should I be applying for if my end goal is data engineer and if I can\u2019t find an entry level data engineering position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfh00d", "is_robot_indexable": true, "report_reasons": null, "author": "iBortex", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfh00d/what_are_some_of_the_best_entry_level_jobs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfh00d/what_are_some_of_the_best_entry_level_jobs_to/", "subreddit_subscribers": 169248, "created_utc": 1710517476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have a job where all I do is enter the $ amount, vendor name, and invoice # from a pdf invoice that is received in an outlook inbox into a Access database, There has to be a way to make it less manual.\n\nFor context I work for a government organization that receives 100s of invoices from many hundreds of different vendors every day.\n\nWhere should I start?", "author_fullname": "t2_g45v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I manually enter invoices in access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf57d2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710475636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a job where all I do is enter the $ amount, vendor name, and invoice # from a pdf invoice that is received in an outlook inbox into a Access database, There has to be a way to make it less manual.&lt;/p&gt;\n\n&lt;p&gt;For context I work for a government organization that receives 100s of invoices from many hundreds of different vendors every day.&lt;/p&gt;\n\n&lt;p&gt;Where should I start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bf57d2", "is_robot_indexable": true, "report_reasons": null, "author": "KingCharlemange", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf57d2/i_manually_enter_invoices_in_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf57d2/i_manually_enter_invoices_in_access/", "subreddit_subscribers": 169248, "created_utc": 1710475636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, data lakes unlikes data warehouses let you store unstructured data (text, binary) - does it mean that they are mostly used for this type of data? Or are data lakes mostly used for structured and semi-structured data? But then why choose data lake if we can use data warehouse. What is your experence?", "author_fullname": "t2_34tfcgtu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data lakes mostly used for sturctured and semi-structured data or unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfaon5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710498132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, data lakes unlikes data warehouses let you store unstructured data (text, binary) - does it mean that they are mostly used for this type of data? Or are data lakes mostly used for structured and semi-structured data? But then why choose data lake if we can use data warehouse. What is your experence?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfaon5", "is_robot_indexable": true, "report_reasons": null, "author": "rental_car_abuse", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfaon5/are_data_lakes_mostly_used_for_sturctured_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfaon5/are_data_lakes_mostly_used_for_sturctured_and/", "subreddit_subscribers": 169248, "created_utc": 1710498132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Okay I need some advice for choosing a training program that will get me job ready for data engineering. I prefer actual training over theory. Are there any good programs that have virtual training for real world examples? Such as building pipelines and using Python.\n\n\nBackground:\n\nWorked as a business analyst, systems analyst and a data analyst for 6 years.\n\nBeen using T-SQL for over 6 years. Need to make the jump into data engineering. Have a little experience in Python.\n\n\n\n\n\n\n", "author_fullname": "t2_exo31rtq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers...what's a great learning program?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfppjz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710539879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay I need some advice for choosing a training program that will get me job ready for data engineering. I prefer actual training over theory. Are there any good programs that have virtual training for real world examples? Such as building pipelines and using Python.&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;Worked as a business analyst, systems analyst and a data analyst for 6 years.&lt;/p&gt;\n\n&lt;p&gt;Been using T-SQL for over 6 years. Need to make the jump into data engineering. Have a little experience in Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfppjz", "is_robot_indexable": true, "report_reasons": null, "author": "Dante_leigh", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfppjz/data_engineerswhats_a_great_learning_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfppjz/data_engineerswhats_a_great_learning_program/", "subreddit_subscribers": 169248, "created_utc": 1710539879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've a pipeline run like this:\n\nextract data from data source -&gt; store into raw table in PostgreSQL -&gt; run another SQL transformation script to load into staging table.\n\n&amp;#x200B;\n\nNow for the third step, I would like to create an automation method to execute the SQL transformation script instead running manually. I expect it to be executed whenever an insertion occurs in the raw table.\n\nI know SQL trigger functions can react to insertion, and I'm not sure if DBT can react to the insertion yet.\n\nMy expectation is: can evoke to run transformation SQL script whenever insertion happens in raw table, and I'm able to record the transformation log to trace the action.\n\n&amp;#x200B;\n\nAny suggestion is appreciated! THanks", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is SQL trigger functions or DBT execution more preferred for data transformation in PostgreSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfe06k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710509411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve a pipeline run like this:&lt;/p&gt;\n\n&lt;p&gt;extract data from data source -&amp;gt; store into raw table in PostgreSQL -&amp;gt; run another SQL transformation script to load into staging table.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now for the third step, I would like to create an automation method to execute the SQL transformation script instead running manually. I expect it to be executed whenever an insertion occurs in the raw table.&lt;/p&gt;\n\n&lt;p&gt;I know SQL trigger functions can react to insertion, and I&amp;#39;m not sure if DBT can react to the insertion yet.&lt;/p&gt;\n\n&lt;p&gt;My expectation is: can evoke to run transformation SQL script whenever insertion happens in raw table, and I&amp;#39;m able to record the transformation log to trace the action.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestion is appreciated! THanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfe06k", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfe06k/is_sql_trigger_functions_or_dbt_execution_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfe06k/is_sql_trigger_functions_or_dbt_execution_more/", "subreddit_subscribers": 169248, "created_utc": 1710509411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI recently hit this scenario -\n\nPipelines expect a certain schema to exist, this schema changes because life (out of DEs control (prod db?)) =&gt; pipeline breaks =&gt; downtime \n\nDoes this happen to you?\n\nWhat can I do about it?", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preventing pipelines from breaking because of upstream changes ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfdjvj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710508064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I recently hit this scenario -&lt;/p&gt;\n\n&lt;p&gt;Pipelines expect a certain schema to exist, this schema changes because life (out of DEs control (prod db?)) =&amp;gt; pipeline breaks =&amp;gt; downtime &lt;/p&gt;\n\n&lt;p&gt;Does this happen to you?&lt;/p&gt;\n\n&lt;p&gt;What can I do about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfdjvj", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfdjvj/preventing_pipelines_from_breaking_because_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfdjvj/preventing_pipelines_from_breaking_because_of/", "subreddit_subscribers": 169248, "created_utc": 1710508064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you please suggest what pathways one could pursue after doing a masters in data science do data engineering?\n\nThanks for all your suggestions.\n\n&amp;#x200B;", "author_fullname": "t2_143jjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfpn8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710539715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you please suggest what pathways one could pursue after doing a masters in data science do data engineering?&lt;/p&gt;\n\n&lt;p&gt;Thanks for all your suggestions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfpn8q", "is_robot_indexable": true, "report_reasons": null, "author": "Jay12a", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfpn8q/data_science_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfpn8q/data_science_to_data_engineering/", "subreddit_subscribers": 169248, "created_utc": 1710539715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building Serverless ELT (that can also run locally)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1bftu0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TDSsz_PESmlXX0bweU_jrnQFSS8V1FSxjQY4DEBAc88.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710550933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/building-local-and-serverless-elt-cq-and-md", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?auto=webp&amp;s=7d38c281f494a85bce1e247be96ec937a50ac39d", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37ec84e7ecc8b5f3cc961e2d7e82a9092d066e88", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7dffac85a85a8b8a94f118e2268ae7aa53318a2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99fd842dae83cdfbcd76664ca026b1ea4ff6d594", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51e51888363ec722549445ca7e2cdae5a6aca0ca", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49622278b5c211082e03b02ee45b4f1f4fe78a89", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/r9zWpzJwBEQyuyBChk7OJZRgL_btkyPbChY4YyWFASk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=36fcfcd5b6be09a89c3a26464c57e4c9330dfab3", "width": 1080, "height": 607}], "variants": {}, "id": "G6unAVSS7euzYghTG2QZmZ-z1joUbd3D81u9h8w-x7g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bftu0k", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bftu0k/building_serverless_elt_that_can_also_run_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/building-local-and-serverless-elt-cq-and-md", "subreddit_subscribers": 169248, "created_utc": 1710550933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I followed the quick start guide and i'm able to subscribe to objects, just waiting on an event to come through. Wondering what things I can do to get this data into a kafka topic preferable using AWS resources. ", "author_fullname": "t2_vnueu7bje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Salesforce Pub/Sub API to get cdc events into a kafka topic on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfkhdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710526398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I followed the quick start guide and i&amp;#39;m able to subscribe to objects, just waiting on an event to come through. Wondering what things I can do to get this data into a kafka topic preferable using AWS resources. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bfkhdp", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Doyle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfkhdp/has_anyone_used_salesforce_pubsub_api_to_get_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfkhdp/has_anyone_used_salesforce_pubsub_api_to_get_cdc/", "subreddit_subscribers": 169248, "created_utc": 1710526398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle orchestration in prod, and why?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite orchestration tool for prod?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfjwdt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710524922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle orchestration in prod, and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfjwdt", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfjwdt/favorite_orchestration_tool_for_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfjwdt/favorite_orchestration_tool_for_prod/", "subreddit_subscribers": 169248, "created_utc": 1710524922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa5dw92do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake FinOps Center - Control and monitor costs with this free Streamlit app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfevv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cztW99v4JlBmYy-f1aqD8w5xM3DnxuEgoHCTvi0Ms2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710511953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "app.snowflake.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://app.snowflake.com/marketplace/listing/GZT8Z2123RJ/baselit-finops-center", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?auto=webp&amp;s=b3c8ef12a1fc8834c8f8e5f91b8776e02bd65c7d", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=067b0f0d8b39972752e8df648542a0eb0f44c78e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b35c87c001a900e0d86832e2ae6adf3ae714f7d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84bc30978b9730b3b342290e0244412fcf9765f1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b28126ea2a6858923a2d8a6c0bb0b5a1e2d033bc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c29935bdd59366f9dddeca916478a805c364d832", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/rOWeAyEuSxiFWnBPRT99X2dPvg2PDvOn9QLrGwPi2jE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ce18c83f97bc129111ff9672366d1f1c14e13524", "width": 1080, "height": 567}], "variants": {}, "id": "6pwGgdLLEhyeygBB9mofhn0ySjQDLUFfIQfzKSexUVU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bfevv2", "is_robot_indexable": true, "report_reasons": null, "author": "sahil_singla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfevv2/snowflake_finops_center_control_and_monitor_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://app.snowflake.com/marketplace/listing/GZT8Z2123RJ/baselit-finops-center", "subreddit_subscribers": 169248, "created_utc": 1710511953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. We have a spark cluster on emr to preprocess the data and move from staging to production layer( as part of lakehouse architecture on s3). The data in staging is on s3 partitioned by downloaded date and hour (date at which the data comes to our system) in increments every hour. We need to preprocess the data and write it to production partitioned by report date (date at which the event occurred). \n\nThe challenge is the source system may update the previously sent data. I.e, for the event recognised by event id which happened last week and was ingested last week, may come again with updated values. We need to update it in out production layer. \n\nWe are currently trying to do it in spark. Every hour we get the staging data (one hour incremental data), get all the data from production layer by distinct report dates and upsert in spark and re write back to prod layer\n\n&amp;#x200B;\n\nData volume.\n\naround 100 million records per day in raw layer (10 gb parquet files)\n\naround 30 million records per day in prod layer (2-3 gb parquet files) (after preprocessing)\n\nEveryday we get around 60 dates older dates data (or 40 dates older dates data per day) which we have to upsert\n\nSo we have to read in spark for every hour data in staging layer (30-40 report dates data from production to upsert which amounts to 180-200GB compressed parquet files, on de-serialization will expand to 1000GB-2000GB)\n\n&amp;#x200B;\n\nThe spark job takes lot of time to complete (1:30 hours to 2 hours on a 7 node cluster with 32 gb machines and 8 core per node). Most of the time is on reads and writes. We have done all the possible optimisations from the spark code and config perspective\n\nFor us it's too long and costly and also not scalable\n\nIs there a better solution for this? How does industry approach this problem? Should we do upsert over any datawarehouse instead of spark?", "author_fullname": "t2_suqqio5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "scalable, performant and cost optimised approach needed for data preprocessing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bf7wdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710485861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. We have a spark cluster on emr to preprocess the data and move from staging to production layer( as part of lakehouse architecture on s3). The data in staging is on s3 partitioned by downloaded date and hour (date at which the data comes to our system) in increments every hour. We need to preprocess the data and write it to production partitioned by report date (date at which the event occurred). &lt;/p&gt;\n\n&lt;p&gt;The challenge is the source system may update the previously sent data. I.e, for the event recognised by event id which happened last week and was ingested last week, may come again with updated values. We need to update it in out production layer. &lt;/p&gt;\n\n&lt;p&gt;We are currently trying to do it in spark. Every hour we get the staging data (one hour incremental data), get all the data from production layer by distinct report dates and upsert in spark and re write back to prod layer&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Data volume.&lt;/p&gt;\n\n&lt;p&gt;around 100 million records per day in raw layer (10 gb parquet files)&lt;/p&gt;\n\n&lt;p&gt;around 30 million records per day in prod layer (2-3 gb parquet files) (after preprocessing)&lt;/p&gt;\n\n&lt;p&gt;Everyday we get around 60 dates older dates data (or 40 dates older dates data per day) which we have to upsert&lt;/p&gt;\n\n&lt;p&gt;So we have to read in spark for every hour data in staging layer (30-40 report dates data from production to upsert which amounts to 180-200GB compressed parquet files, on de-serialization will expand to 1000GB-2000GB)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The spark job takes lot of time to complete (1:30 hours to 2 hours on a 7 node cluster with 32 gb machines and 8 core per node). Most of the time is on reads and writes. We have done all the possible optimisations from the spark code and config perspective&lt;/p&gt;\n\n&lt;p&gt;For us it&amp;#39;s too long and costly and also not scalable&lt;/p&gt;\n\n&lt;p&gt;Is there a better solution for this? How does industry approach this problem? Should we do upsert over any datawarehouse instead of spark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bf7wdx", "is_robot_indexable": true, "report_reasons": null, "author": "sud004", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bf7wdx/scalable_performant_and_cost_optimised_approach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bf7wdx/scalable_performant_and_cost_optimised_approach/", "subreddit_subscribers": 169248, "created_utc": 1710485861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am seeing a lot of job postings requiring experience creating and maintaining data pipelines and architecture. What does that mean specifically? If I am creating and scheduling pipelines with airflow or using AWS Glue ETL and Lambda for pipelines, does that count? Or does it require being more advanced? ", "author_fullname": "t2_grh3q8ab1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Job Posts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bfw2ny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710557658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am seeing a lot of job postings requiring experience creating and maintaining data pipelines and architecture. What does that mean specifically? If I am creating and scheduling pipelines with airflow or using AWS Glue ETL and Lambda for pipelines, does that count? Or does it require being more advanced? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfw2ny", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Track915", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfw2ny/de_job_posts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfw2ny/de_job_posts/", "subreddit_subscribers": 169248, "created_utc": 1710557658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is \"BigData Developer\" a right term to use\n", "author_fullname": "t2_rtrjd5uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Naming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bfw2f4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710557636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is &amp;quot;BigData Developer&amp;quot; a right term to use&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bfw2f4", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Draft_4623", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfw2f4/naming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfw2f4/naming/", "subreddit_subscribers": 169248, "created_utc": 1710557636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a beginner data engineer and I wanna read Fundamentals of Data Engineering but I'm not sure if it's right for me at the moment? From my research the biggest criticism of the book is that it's bloated with technical details while not being a textbook and doesn't have enough useful use-cases.\n\nI'm reading DDIA at the moment and I'm really enjoying the pace and find it more or less easy to digest. Is FoDE more difficult than DDIA? Would you recommend it to a beginner who's read DDIA?", "author_fullname": "t2_syp7tbbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fundamentals of Data Engineering vs Designing Data Intensive Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bfsb8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710546741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a beginner data engineer and I wanna read Fundamentals of Data Engineering but I&amp;#39;m not sure if it&amp;#39;s right for me at the moment? From my research the biggest criticism of the book is that it&amp;#39;s bloated with technical details while not being a textbook and doesn&amp;#39;t have enough useful use-cases.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reading DDIA at the moment and I&amp;#39;m really enjoying the pace and find it more or less easy to digest. Is FoDE more difficult than DDIA? Would you recommend it to a beginner who&amp;#39;s read DDIA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bfsb8o", "is_robot_indexable": true, "report_reasons": null, "author": "Low-Associate2521", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bfsb8o/fundamentals_of_data_engineering_vs_designing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bfsb8o/fundamentals_of_data_engineering_vs_designing/", "subreddit_subscribers": 169248, "created_utc": 1710546741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m playing with streaming data from f1 games. \n\nBasically I get telemetry from the car via udp, and parse the bytes to float.\n\nWhat solution would you use to:\n\n1) Store this data\n2) Create realtime dashboards ?\n3) Create historical analysis?", "author_fullname": "t2_24zoub6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming + Realtime + Dashboard ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bflawu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710528496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m playing with streaming data from f1 games. &lt;/p&gt;\n\n&lt;p&gt;Basically I get telemetry from the car via udp, and parse the bytes to float.&lt;/p&gt;\n\n&lt;p&gt;What solution would you use to:&lt;/p&gt;\n\n&lt;p&gt;1) Store this data\n2) Create realtime dashboards ?\n3) Create historical analysis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bflawu", "is_robot_indexable": true, "report_reasons": null, "author": "theuzz1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bflawu/streaming_realtime_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bflawu/streaming_realtime_dashboard/", "subreddit_subscribers": 169248, "created_utc": 1710528496.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}