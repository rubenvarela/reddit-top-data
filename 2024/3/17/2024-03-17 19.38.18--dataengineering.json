{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any recommendations would be really helpful. Thanks!", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Important is System Design for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgth7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710667274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations would be really helpful. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgth7l", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgth7l/how_important_is_system_design_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgth7l/how_important_is_system_design_for_data_engineers/", "subreddit_subscribers": 169672, "created_utc": 1710667274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI am wanting to write OOP based Python pipelines for ELT. Does anyone know a resource that I can use to learn and practice ?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning OOP for develop Python based Data engineering pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgl42e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710637247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wanting to write OOP based Python pipelines for ELT. Does anyone know a resource that I can use to learn and practice ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgl42e", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgl42e/learning_oop_for_develop_python_based_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgl42e/learning_oop_for_develop_python_based_data/", "subreddit_subscribers": 169672, "created_utc": 1710637247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! I've been using Reddit more frequently lately, but I\u2019m still active in just a few communities:\n\n- this one, of course\n- /r/cscareerquestions\n- /r/apachespark\n- /r/learnprogramming\n\nwhat other tech/programming subreddits do you follow that compliment this community?", "author_fullname": "t2_a0pro6w2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to expand my Reddit horizon: What other tech/programming Subreddits do you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bglg31", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710638251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I&amp;#39;ve been using Reddit more frequently lately, but I\u2019m still active in just a few communities:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;this one, of course&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/cscareerquestions\"&gt;/r/cscareerquestions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/apachespark\"&gt;/r/apachespark&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/learnprogramming\"&gt;/r/learnprogramming&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;what other tech/programming subreddits do you follow that compliment this community?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bglg31", "is_robot_indexable": true, "report_reasons": null, "author": "benanic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bglg31/trying_to_expand_my_reddit_horizon_what_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bglg31/trying_to_expand_my_reddit_horizon_what_other/", "subreddit_subscribers": 169672, "created_utc": 1710638251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, everyone! I've created this reviewer for my Data Engineering Team, and I thought I'd share it here with all of you. Feel free to use it and provide any feedback or suggestions you may have. Happy learning!\n\n**AWS Certified Data Engineer Associate DEA-C01 Practice Test**\n\n[https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST](https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST)\n\n**Databricks Certified Data Engineer Associate Practice Test 2024**\n\n[https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST](https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST)\n\nedit. P.S. It's free, so please forgive the small question bank.", "author_fullname": "t2_tgfwnw6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reviewer for Data Engineering Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgtc9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710666704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone! I&amp;#39;ve created this reviewer for my Data Engineering Team, and I thought I&amp;#39;d share it here with all of you. Feel free to use it and provide any feedback or suggestions you may have. Happy learning!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;AWS Certified Data Engineer Associate DEA-C01 Practice Test&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST\"&gt;https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Databricks Certified Data Engineer Associate Practice Test 2024&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST\"&gt;https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit. P.S. It&amp;#39;s free, so please forgive the small question bank.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgtc9f", "is_robot_indexable": true, "report_reasons": null, "author": "namibellmere", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgtc9f/reviewer_for_data_engineering_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgtc9f/reviewer_for_data_engineering_certification/", "subreddit_subscribers": 169672, "created_utc": 1710666704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.\n\nHow should I go about documenting/understanding what each table means and each field?\n\nAnd when should I start suggesting changes to some tables?\n\nI'm currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it's the right way to go.", "author_fullname": "t2_apdhbvv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tables all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bh0jww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710689960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.&lt;/p&gt;\n\n&lt;p&gt;How should I go about documenting/understanding what each table means and each field?&lt;/p&gt;\n\n&lt;p&gt;And when should I start suggesting changes to some tables?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it&amp;#39;s the right way to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh0jww", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Scene-2465", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh0jww/tables_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh0jww/tables_all_the_way_down/", "subreddit_subscribers": 169672, "created_utc": 1710689960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,  \nI am seeking guidance how can i become good overall engineer ? What i can learn to be better ?\n\n**Experience**: 3 years  \n**Age**: 27  \n**Current role**: I am working on low latency data pipelines using scala, flink, cassandra, redis, s3 and kafka in a product based company.  \nOther tools i am using prometheus, grafana for monitoring and kubernetes, docker for deploying apps.  \n**Leetcode rating**: My Leetcode rating is 1960 and currently practing more on it. solved around 1200 problems. Using cpp.  \n**System Design**: Completed Design data intensive applicaion book and Grokking the system design course.  \n**Low level Design**: working on it this too using cpp.\n\nRecently I read  design data intensive application book, reading it once again to get more out of it.  Next i am thinking of reading one os book (Galvin), microservices by sam richardson book. I also work on understanding how cassandra redis and kafka works internally in the free time.\n\nI didn't try to learn kuberentes and docker in detail because they are vast in terms of concepts. My current job does allow only to used them as platform for deploying apps and there are other engineers for devops work.\n\nI want your guidance on what can i do to become a good successful engineer and  join good company in future. I am not thinking of switching in few months becomes i want grind more in coming months and my current job able me to provide good free time.  **Is anything needs to be changed or added to what i am doing currently ?** Any comment would be much appreciated. Thanks in advance.\n\nSorry for my bad english.", "author_fullname": "t2_aqmxwdoy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to become a good engineer ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bh2wha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710697134.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710695781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;br/&gt;\nI am seeking guidance how can i become good overall engineer ? What i can learn to be better ?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Experience&lt;/strong&gt;: 3 years&lt;br/&gt;\n&lt;strong&gt;Age&lt;/strong&gt;: 27&lt;br/&gt;\n&lt;strong&gt;Current role&lt;/strong&gt;: I am working on low latency data pipelines using scala, flink, cassandra, redis, s3 and kafka in a product based company.&lt;br/&gt;\nOther tools i am using prometheus, grafana for monitoring and kubernetes, docker for deploying apps.&lt;br/&gt;\n&lt;strong&gt;Leetcode rating&lt;/strong&gt;: My Leetcode rating is 1960 and currently practing more on it. solved around 1200 problems. Using cpp.&lt;br/&gt;\n&lt;strong&gt;System Design&lt;/strong&gt;: Completed Design data intensive applicaion book and Grokking the system design course.&lt;br/&gt;\n&lt;strong&gt;Low level Design&lt;/strong&gt;: working on it this too using cpp.&lt;/p&gt;\n\n&lt;p&gt;Recently I read  design data intensive application book, reading it once again to get more out of it.  Next i am thinking of reading one os book (Galvin), microservices by sam richardson book. I also work on understanding how cassandra redis and kafka works internally in the free time.&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t try to learn kuberentes and docker in detail because they are vast in terms of concepts. My current job does allow only to used them as platform for deploying apps and there are other engineers for devops work.&lt;/p&gt;\n\n&lt;p&gt;I want your guidance on what can i do to become a good successful engineer and  join good company in future. I am not thinking of switching in few months becomes i want grind more in coming months and my current job able me to provide good free time.  &lt;strong&gt;Is anything needs to be changed or added to what i am doing currently ?&lt;/strong&gt; Any comment would be much appreciated. Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;Sorry for my bad english.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bh2wha", "is_robot_indexable": true, "report_reasons": null, "author": "AggravatingParsnip89", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh2wha/how_to_become_a_good_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh2wha/how_to_become_a_good_engineer/", "subreddit_subscribers": 169672, "created_utc": 1710695781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Yes I know the overall goal of our work is to reduce excel reports. But everywhere I go there is some amount of \"essential\" reports.\n\nI've seen so much - S3 buckets, onedrive, SharePoint, mounted disks, email, SFTP.\n\nWhat does your company do? \n\n", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company distribute excel reports?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgwc8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710678421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes I know the overall goal of our work is to reduce excel reports. But everywhere I go there is some amount of &amp;quot;essential&amp;quot; reports.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen so much - S3 buckets, onedrive, SharePoint, mounted disks, email, SFTP.&lt;/p&gt;\n\n&lt;p&gt;What does your company do? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgwc8l", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgwc8l/how_does_your_company_distribute_excel_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgwc8l/how_does_your_company_distribute_excel_reports/", "subreddit_subscribers": 169672, "created_utc": 1710678421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI was browsing internet and found some blogs describing a problem, and giving sample propositions on how to solve it. Do you know of any bloggers or technical content creator who does the same thing with Data engineering problems, modeling and/or Architecting solutions ?\n\nThanks for sharing", "author_fullname": "t2_948bsvs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for technical blogs sharing solutions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgy3ct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710683694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I was browsing internet and found some blogs describing a problem, and giving sample propositions on how to solve it. Do you know of any bloggers or technical content creator who does the same thing with Data engineering problems, modeling and/or Architecting solutions ?&lt;/p&gt;\n\n&lt;p&gt;Thanks for sharing&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bgy3ct", "is_robot_indexable": true, "report_reasons": null, "author": "SdJbra", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgy3ct/looking_for_technical_blogs_sharing_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgy3ct/looking_for_technical_blogs_sharing_solutions/", "subreddit_subscribers": 169672, "created_utc": 1710683694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an API wrapper, which accepts a batch of data, which has to be ingested into multiple tables. First the main facts are inserted and the ids are used to fill some additional metadata tables and junction tables for the dimensional tables.   \n\n\nHow would you efficiently handle the ingestion, when a batch of data arrives?   \n\n\nI think the following options are viable, with respective tradeoffs:\n\n1. Sequential inserts wrapper in transactions. Inserting each fact into the content table and then inserting the accompanying data into the surrounding tables. Do it in a loop for all data. Inefficient, but should give the best guarantees. \n2. Bulk insert with temporary tables. Insert the data into temporary tables (staging). Insert into fact table and get content\\_ids. Fill other temporary tables and insert into dimension tables and metadata tables. \n\nI was looking into COPY but it doesn't seem suitable for multiple tables. Am I missing an option? What setup would you go with? ", "author_fullname": "t2_uc7qtmotr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batching Ingestion (PostgreSQL): Sequential Transactions vs Temporary Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgvc2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710674918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an API wrapper, which accepts a batch of data, which has to be ingested into multiple tables. First the main facts are inserted and the ids are used to fill some additional metadata tables and junction tables for the dimensional tables.   &lt;/p&gt;\n\n&lt;p&gt;How would you efficiently handle the ingestion, when a batch of data arrives?   &lt;/p&gt;\n\n&lt;p&gt;I think the following options are viable, with respective tradeoffs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Sequential inserts wrapper in transactions. Inserting each fact into the content table and then inserting the accompanying data into the surrounding tables. Do it in a loop for all data. Inefficient, but should give the best guarantees. &lt;/li&gt;\n&lt;li&gt;Bulk insert with temporary tables. Insert the data into temporary tables (staging). Insert into fact table and get content_ids. Fill other temporary tables and insert into dimension tables and metadata tables. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I was looking into COPY but it doesn&amp;#39;t seem suitable for multiple tables. Am I missing an option? What setup would you go with? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgvc2w", "is_robot_indexable": true, "report_reasons": null, "author": "nicolay-ai", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgvc2w/batching_ingestion_postgresql_sequential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgvc2w/batching_ingestion_postgresql_sequential/", "subreddit_subscribers": 169672, "created_utc": 1710674918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About 6 months ago, my company made the decision to purchase Ab initio. Based on my research, it, along with other licenseing ETL tools, seems to be on the decline. My company has been rolling it out to various teams and mine is up next. We will be expectsd to migrate current pipelines and new ones to Ab Initio. Currently, we use python + SQL scripts ran on Snowflake to transform our raw data ( files in AWS S3) and then just load into Snowflake tables.\n\nI'm not ready to leave this company, but I'm not so excited about developing a skill set in a dying tool. Still, is there anyway to make the most out of this situation? Is there anything to learn diving deep in ab Initio and learning all I can about the tool? Should I use the tool but focus my cv on the challenges I overcame, not the tool used? Or, should I hyper specialize in ab Initio and become an expert who drifts around to different companies to maintain their pipelines, requiring a large salary for this niche and drying skill set.\n\n", "author_fullname": "t2_jlj0h3u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting the most of out an old tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgymae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710685108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About 6 months ago, my company made the decision to purchase Ab initio. Based on my research, it, along with other licenseing ETL tools, seems to be on the decline. My company has been rolling it out to various teams and mine is up next. We will be expectsd to migrate current pipelines and new ones to Ab Initio. Currently, we use python + SQL scripts ran on Snowflake to transform our raw data ( files in AWS S3) and then just load into Snowflake tables.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not ready to leave this company, but I&amp;#39;m not so excited about developing a skill set in a dying tool. Still, is there anyway to make the most out of this situation? Is there anything to learn diving deep in ab Initio and learning all I can about the tool? Should I use the tool but focus my cv on the challenges I overcame, not the tool used? Or, should I hyper specialize in ab Initio and become an expert who drifts around to different companies to maintain their pipelines, requiring a large salary for this niche and drying skill set.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgymae", "is_robot_indexable": true, "report_reasons": null, "author": "CriticalSouth3447", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgymae/getting_the_most_of_out_an_old_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgymae/getting_the_most_of_out_an_old_tool/", "subreddit_subscribers": 169672, "created_utc": 1710685108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear sub,\n\nI have a quite heterogeneous CV, but was always drawn towards coding, in particular data science &amp; data engineering. Following my interest, after my studies, I have started as a Data Engineer at a boutique consulting firm. For the past six months, this is where I program ETL pipelines for varying clients and industries.\n\nNow, as I mentioned, my CV is quite diverse, and just recently I have received an offer from a leading (Tier 2) strategy consulting firm. My job there would be on a much higher abstraction level, talking to clients about digital transformation and AI strategies.\n\nI really enjoy the work I do right now as a Data Engineer, but the consulting firm is offering me twice the pay. On the other hand, right now I am aquiring a lot of \"hard skills\", therefore I am confident in what I talk about and work is fun.\n\nIf I go into consulting, the path would be quite clear: Work there for 2 years, do a (paid) PhD, work for 1 more year (or if it is fun, even longer) and then hopefully exit into a management role at a tech company or a corporate tech division.\n\nAs I do not know much about possible career paths in data engineering, I am interested in the later career options and how you would choose.", "author_fullname": "t2_4ctvu7t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing between Data Engineering and Strategy Consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgptkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710652243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear sub,&lt;/p&gt;\n\n&lt;p&gt;I have a quite heterogeneous CV, but was always drawn towards coding, in particular data science &amp;amp; data engineering. Following my interest, after my studies, I have started as a Data Engineer at a boutique consulting firm. For the past six months, this is where I program ETL pipelines for varying clients and industries.&lt;/p&gt;\n\n&lt;p&gt;Now, as I mentioned, my CV is quite diverse, and just recently I have received an offer from a leading (Tier 2) strategy consulting firm. My job there would be on a much higher abstraction level, talking to clients about digital transformation and AI strategies.&lt;/p&gt;\n\n&lt;p&gt;I really enjoy the work I do right now as a Data Engineer, but the consulting firm is offering me twice the pay. On the other hand, right now I am aquiring a lot of &amp;quot;hard skills&amp;quot;, therefore I am confident in what I talk about and work is fun.&lt;/p&gt;\n\n&lt;p&gt;If I go into consulting, the path would be quite clear: Work there for 2 years, do a (paid) PhD, work for 1 more year (or if it is fun, even longer) and then hopefully exit into a management role at a tech company or a corporate tech division.&lt;/p&gt;\n\n&lt;p&gt;As I do not know much about possible career paths in data engineering, I am interested in the later career options and how you would choose.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgptkk", "is_robot_indexable": true, "report_reasons": null, "author": "murlurd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgptkk/choosing_between_data_engineering_and_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgptkk/choosing_between_data_engineering_and_strategy/", "subreddit_subscribers": 169672, "created_utc": 1710652243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings,\n\nWe're currently in the process of developing a multi-tenant B2B integration platform, and I'm exploring architectural options, particularly regarding the use of Apache NiFi. I'm considering whether to implement separate NiFi clusters for each tenant or to leverage NiFi's capabilities for multi-tenancy within a single cluster.\n\nOur envisioned data flow involves routing data from various sources such as Amazon Marketplace, Shopify Marketplace, ERP systems, and SAP orders to our Order Management System (OMS) via NiFi. We anticipate a data movement pattern from API to staging and then to another API, with NiFi serving as the translator between these APIs.\n\nFor instance, orders from different marketplaces or systems may need to be directed to different OMS instances, and our integration platform would facilitate this process seamlessly.\n\nI welcome any insights or suggestions on optimizing this approach.\n\nLooking forward to your input.", "author_fullname": "t2_urs1iey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Multi-Tenant B2B Integration with Apache NiFi: Seeking Feedback and Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bghnuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710627366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently in the process of developing a multi-tenant B2B integration platform, and I&amp;#39;m exploring architectural options, particularly regarding the use of Apache NiFi. I&amp;#39;m considering whether to implement separate NiFi clusters for each tenant or to leverage NiFi&amp;#39;s capabilities for multi-tenancy within a single cluster.&lt;/p&gt;\n\n&lt;p&gt;Our envisioned data flow involves routing data from various sources such as Amazon Marketplace, Shopify Marketplace, ERP systems, and SAP orders to our Order Management System (OMS) via NiFi. We anticipate a data movement pattern from API to staging and then to another API, with NiFi serving as the translator between these APIs.&lt;/p&gt;\n\n&lt;p&gt;For instance, orders from different marketplaces or systems may need to be directed to different OMS instances, and our integration platform would facilitate this process seamlessly.&lt;/p&gt;\n\n&lt;p&gt;I welcome any insights or suggestions on optimizing this approach.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bghnuc", "is_robot_indexable": true, "report_reasons": null, "author": "mallucharan", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bghnuc/optimizing_multitenant_b2b_integration_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bghnuc/optimizing_multitenant_b2b_integration_with/", "subreddit_subscribers": 169672, "created_utc": 1710627366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI noticed this subreddit has Oracle WMS related posts so wanted to inquire on that same topic.\n\nMy Organization has implemented Oracle SaaS ERP and Oracle WMS solutions. Both are interconnected to each other.\n\nEvery quarter, Oracle deploys SaaS patches on Fridays. Similarly, WMS also quarterly deploys their patches, but on Saturday.\n\n From what we are being told, WMS and SaaS has reliance on each other. With one of the two being offline on both Friday and Saturday, how does one go about ensuring if anyhing not able to being passed to the other system, how to you sync that up? \n\nIs there a provision in SaaS that allows to queue up data intended for WMS, and vice versa.\n\nthanks", "author_fullname": "t2_h41sfw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle WMS and Oracle SaaS - one depends on the other | seeking data sync advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgf8zo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710620737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I noticed this subreddit has Oracle WMS related posts so wanted to inquire on that same topic.&lt;/p&gt;\n\n&lt;p&gt;My Organization has implemented Oracle SaaS ERP and Oracle WMS solutions. Both are interconnected to each other.&lt;/p&gt;\n\n&lt;p&gt;Every quarter, Oracle deploys SaaS patches on Fridays. Similarly, WMS also quarterly deploys their patches, but on Saturday.&lt;/p&gt;\n\n&lt;p&gt;From what we are being told, WMS and SaaS has reliance on each other. With one of the two being offline on both Friday and Saturday, how does one go about ensuring if anyhing not able to being passed to the other system, how to you sync that up? &lt;/p&gt;\n\n&lt;p&gt;Is there a provision in SaaS that allows to queue up data intended for WMS, and vice versa.&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgf8zo", "is_robot_indexable": true, "report_reasons": null, "author": "fm2xm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgf8zo/oracle_wms_and_oracle_saas_one_depends_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgf8zo/oracle_wms_and_oracle_saas_one_depends_on_the/", "subreddit_subscribers": 169672, "created_utc": 1710620737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all. Throwaway account because I\u2019m paranoid.\n\nMy DE team is slowly shifting away from older msft-beholden tech, to more newer cloud based stuff (Azure). At the end of the day, a huge chunk of what my team does is file ingestion (or output) that either goes into SQL Server or Snowflake in some form or fashion. We are also starting to dabble with some APIs for some core business products that have data needs that have to go through us in some way or form. Management says we're trying to \"modernize\" our stack (for me going to C# from SSIS isn't modernization, but that's what they call it here). \n\nThe nature of my team is B2B interactions. I guess my question is, what kind of cloud tools/offerings can I leverage in this type of environment? I want to be ahead of the curve in my team, but sometimes it feels so pointless to overengineer stuff for something that a simple process can do to upload files to a table and call it a day, or to extract data and create a file. We're not doing anything majorly cutting edge, and Snowflake is handled by a separate BI team. We currently don't do any type of streaming either. The business is currently expanding heavily, and I feel like we need to focus on scalability and producing performant solutions, but when my main experience so far at the company is just reading files and inserting and using SQL to get the data I need, I feel a bit lacking, and management isn't exactly great at providing vision and guidance.", "author_fullname": "t2_5hzy2ed6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance in leveraging cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgfhg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710621397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Throwaway account because I\u2019m paranoid.&lt;/p&gt;\n\n&lt;p&gt;My DE team is slowly shifting away from older msft-beholden tech, to more newer cloud based stuff (Azure). At the end of the day, a huge chunk of what my team does is file ingestion (or output) that either goes into SQL Server or Snowflake in some form or fashion. We are also starting to dabble with some APIs for some core business products that have data needs that have to go through us in some way or form. Management says we&amp;#39;re trying to &amp;quot;modernize&amp;quot; our stack (for me going to C# from SSIS isn&amp;#39;t modernization, but that&amp;#39;s what they call it here). &lt;/p&gt;\n\n&lt;p&gt;The nature of my team is B2B interactions. I guess my question is, what kind of cloud tools/offerings can I leverage in this type of environment? I want to be ahead of the curve in my team, but sometimes it feels so pointless to overengineer stuff for something that a simple process can do to upload files to a table and call it a day, or to extract data and create a file. We&amp;#39;re not doing anything majorly cutting edge, and Snowflake is handled by a separate BI team. We currently don&amp;#39;t do any type of streaming either. The business is currently expanding heavily, and I feel like we need to focus on scalability and producing performant solutions, but when my main experience so far at the company is just reading files and inserting and using SQL to get the data I need, I feel a bit lacking, and management isn&amp;#39;t exactly great at providing vision and guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgfhg6", "is_robot_indexable": true, "report_reasons": null, "author": "white_thiccbori", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgfhg6/guidance_in_leveraging_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgfhg6/guidance_in_leveraging_cloud/", "subreddit_subscribers": 169672, "created_utc": 1710621397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a pipeline in GCP that involves extracting data from a PDF, modifying it, and then reconstructing the PDF with the original layout. Process-wise, this isn't terribly complicated, but I'm struggling with a tool to preserve the layout information to help with reconstructing the PDF after all is said and done. Does anyone know any tools, GCP-native or otherwise, I could use to capture/utilize the layout?", "author_fullname": "t2_o1ln6yad", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recreating document layout in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh5cf1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710701725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a pipeline in GCP that involves extracting data from a PDF, modifying it, and then reconstructing the PDF with the original layout. Process-wise, this isn&amp;#39;t terribly complicated, but I&amp;#39;m struggling with a tool to preserve the layout information to help with reconstructing the PDF after all is said and done. Does anyone know any tools, GCP-native or otherwise, I could use to capture/utilize the layout?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bh5cf1", "is_robot_indexable": true, "report_reasons": null, "author": "_tr9800a_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh5cf1/recreating_document_layout_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh5cf1/recreating_document_layout_in_gcp/", "subreddit_subscribers": 169672, "created_utc": 1710701725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are using SQL Synapse Dedicated Pool which is essentially SQL DW with ELT processes\n\nSo current process look like\n\nLoad raw incremental data from files to staging tables in vendor specific schema in DW\n\nPost that we have stored procs which load that data into main table where incremental data get appended to historic data\n\nFinal layer would be another set of stored proc which move data to dwh schema tables\n\nSo currently everything is in same DW but in different schema and dwh supports various reports (reports are import mode so each interaction does nit hit DW) and some external vendors\n\nThis system could run into issue if number of external vendors that it needs to support increases beyond certain point and if this vendors keep hitting DW with their queries throughout the day as that would give less processing power to other processed\n\nWe are thinking of either creating read only copy of just dwh schema or taking dwh schema entirely on different DW\n\nHowever if we move it out entirely we will have develop equivalent of existing stored procs in either databricks or some other ETL tool and if we just copy dwh to either parquet files or different db then copy process will have to built\n\nIdeally copy would be simple to do but daily copy might take time\n\nWhat would you do in this situation?", "author_fullname": "t2_50u0h0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Separate DB vs Separate Schema for Raw, Processed &amp; DWH?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh4lau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710699957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are using SQL Synapse Dedicated Pool which is essentially SQL DW with ELT processes&lt;/p&gt;\n\n&lt;p&gt;So current process look like&lt;/p&gt;\n\n&lt;p&gt;Load raw incremental data from files to staging tables in vendor specific schema in DW&lt;/p&gt;\n\n&lt;p&gt;Post that we have stored procs which load that data into main table where incremental data get appended to historic data&lt;/p&gt;\n\n&lt;p&gt;Final layer would be another set of stored proc which move data to dwh schema tables&lt;/p&gt;\n\n&lt;p&gt;So currently everything is in same DW but in different schema and dwh supports various reports (reports are import mode so each interaction does nit hit DW) and some external vendors&lt;/p&gt;\n\n&lt;p&gt;This system could run into issue if number of external vendors that it needs to support increases beyond certain point and if this vendors keep hitting DW with their queries throughout the day as that would give less processing power to other processed&lt;/p&gt;\n\n&lt;p&gt;We are thinking of either creating read only copy of just dwh schema or taking dwh schema entirely on different DW&lt;/p&gt;\n\n&lt;p&gt;However if we move it out entirely we will have develop equivalent of existing stored procs in either databricks or some other ETL tool and if we just copy dwh to either parquet files or different db then copy process will have to built&lt;/p&gt;\n\n&lt;p&gt;Ideally copy would be simple to do but daily copy might take time&lt;/p&gt;\n\n&lt;p&gt;What would you do in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh4lau", "is_robot_indexable": true, "report_reasons": null, "author": "dilkushpatel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh4lau/separate_db_vs_separate_schema_for_raw_processed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh4lau/separate_db_vs_separate_schema_for_raw_processed/", "subreddit_subscribers": 169672, "created_utc": 1710699957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Similar to the docker operator we have in airflow do we have something similar in mage, prefect or Dagster? ", "author_fullname": "t2_iojbk0c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker operator alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh3fsi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710697135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Similar to the docker operator we have in airflow do we have something similar in mage, prefect or Dagster? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bh3fsi", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalEmploy3558", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh3fsi/docker_operator_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh3fsi/docker_operator_alternative/", "subreddit_subscribers": 169672, "created_utc": 1710697135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.\n\nHow should I go about documenting/understanding what each table means and each field?\n\nAnd when should I start suggesting changes to some tables?\n\nI'm currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it's the right way to go.", "author_fullname": "t2_apdhbvv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tables all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bh0k35", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710689970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.&lt;/p&gt;\n\n&lt;p&gt;How should I go about documenting/understanding what each table means and each field?&lt;/p&gt;\n\n&lt;p&gt;And when should I start suggesting changes to some tables?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it&amp;#39;s the right way to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh0k35", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Scene-2465", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh0k35/tables_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh0k35/tables_all_the_way_down/", "subreddit_subscribers": 169672, "created_utc": 1710689970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.\n\nHow should I go about documenting/understanding what each table means and each field?\n\nAnd when should I start suggesting changes to some tables?\n\nI'm currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it's the right way to go.", "author_fullname": "t2_apdhbvv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tables all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bh0jzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710689965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.&lt;/p&gt;\n\n&lt;p&gt;How should I go about documenting/understanding what each table means and each field?&lt;/p&gt;\n\n&lt;p&gt;And when should I start suggesting changes to some tables?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it&amp;#39;s the right way to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh0jzr", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Scene-2465", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh0jzr/tables_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh0jzr/tables_all_the_way_down/", "subreddit_subscribers": 169672, "created_utc": 1710689965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to DBT. \n\nI  want to run a CI/CD pipeline to perform DBT jobs against a test set in  Databricks. I want to do this in the most inexpensive way possible using  a very small amount of data so it can be triggered for every PR we  raise to the data models. Ideally this workflow would do DRY run tests so we don't need to launch any clustering. \n\n* Has anybody got any experience with this setup, can point me in the right direction, and ran into any issues? \n* Is this all possible in the  latest open source version of dbt-core?\n\nI also want to create a metadata ingest to list files from various blob store sources e.g. Azure Gen2, into a synchronised raw table of metadata of those files (for visibility/querying/and ontology). \n\n* Is this something DBT can help with? Original plan was to do this with isolated Autoloader Spark jobs, not 100% ideal. \n\nIdeally if we can shove as much as possible into DBT to provide managed CI/CD testing and deployment, and overall a structured workflow for our data tasks, that'd be great.\n\nThanks for any help! ", "author_fullname": "t2_duii2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD Databricks DBT and Github Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgwk0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710679130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to DBT. &lt;/p&gt;\n\n&lt;p&gt;I  want to run a CI/CD pipeline to perform DBT jobs against a test set in  Databricks. I want to do this in the most inexpensive way possible using  a very small amount of data so it can be triggered for every PR we  raise to the data models. Ideally this workflow would do DRY run tests so we don&amp;#39;t need to launch any clustering. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Has anybody got any experience with this setup, can point me in the right direction, and ran into any issues? &lt;/li&gt;\n&lt;li&gt;Is this all possible in the  latest open source version of dbt-core?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I also want to create a metadata ingest to list files from various blob store sources e.g. Azure Gen2, into a synchronised raw table of metadata of those files (for visibility/querying/and ontology). &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is this something DBT can help with? Original plan was to do this with isolated Autoloader Spark jobs, not 100% ideal. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Ideally if we can shove as much as possible into DBT to provide managed CI/CD testing and deployment, and overall a structured workflow for our data tasks, that&amp;#39;d be great.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgwk0l", "is_robot_indexable": true, "report_reasons": null, "author": "MMACheerpuppy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgwk0l/cicd_databricks_dbt_and_github_actions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgwk0l/cicd_databricks_dbt_and_github_actions/", "subreddit_subscribers": 169672, "created_utc": 1710679130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My Azure Data Factory DEs were trying to get a vendor to append a GUID for a batch ID when they extract into a shared location that has multiple file drops from different systems.   \n\nThis is just some vendor widget no code so seems to me like ADF should be doing it.  Seems like a common file wrangler kind of use case.\n\nI suggested moving the files to another folder and separating it that way.  Was told that took 'too much logic'.  What are different ways we can separate a batch of files on the ADF end?\n\nAnd can ADF generate a GUID batch id and append or prefix to the filenames?", "author_fullname": "t2_21umeu7n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "different ways to generate a batch id for a pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgoilu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710647865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Azure Data Factory DEs were trying to get a vendor to append a GUID for a batch ID when they extract into a shared location that has multiple file drops from different systems.   &lt;/p&gt;\n\n&lt;p&gt;This is just some vendor widget no code so seems to me like ADF should be doing it.  Seems like a common file wrangler kind of use case.&lt;/p&gt;\n\n&lt;p&gt;I suggested moving the files to another folder and separating it that way.  Was told that took &amp;#39;too much logic&amp;#39;.  What are different ways we can separate a batch of files on the ADF end?&lt;/p&gt;\n\n&lt;p&gt;And can ADF generate a GUID batch id and append or prefix to the filenames?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgoilu", "is_robot_indexable": true, "report_reasons": null, "author": "ComfortAndSpeed", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgoilu/different_ways_to_generate_a_batch_id_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgoilu/different_ways_to_generate_a_batch_id_for_a/", "subreddit_subscribers": 169672, "created_utc": 1710647865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just something...thinking on a free Sunday ..night  ..about life and career...", "author_fullname": "t2_96xfoily", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much money will make you happy ? ..i feel I am running a race ...chasing higher and higher salary ..and the goal post.just keeps on moving ...fellow DEs what point in your career do you think you will feel ..I have had enough..i can just peacefully work ...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh42l1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710698721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just something...thinking on a free Sunday ..night  ..about life and career...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh42l1", "is_robot_indexable": true, "report_reasons": null, "author": "napolean_911", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh42l1/how_much_money_will_make_you_happy_i_feel_i_am/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh42l1/how_much_money_will_make_you_happy_i_feel_i_am/", "subreddit_subscribers": 169672, "created_utc": 1710698721.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}