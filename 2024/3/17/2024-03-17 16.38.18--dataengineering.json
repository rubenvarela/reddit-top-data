{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, just wondering if some of the more experienced DEs have an answer to this. I\u2019ve played around with pyspark before but I think there\u2019s a df size threshold below which pandas is faster and above which pyspark is faster? Just not sure what this threshold is and whether anyone has tried finding out or have any heuristics.", "author_fullname": "t2_c7e03um6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to use Spark vs Pandas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgct3c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710614073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, just wondering if some of the more experienced DEs have an answer to this. I\u2019ve played around with pyspark before but I think there\u2019s a df size threshold below which pandas is faster and above which pyspark is faster? Just not sure what this threshold is and whether anyone has tried finding out or have any heuristics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgct3c", "is_robot_indexable": true, "report_reasons": null, "author": "last_unsername", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgct3c/when_to_use_spark_vs_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgct3c/when_to_use_spark_vs_pandas/", "subreddit_subscribers": 169635, "created_utc": 1710614073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been pressing for more mature data management practices at work (managing analytics). Right now we have a single MS SQL server with a handful of shitty schema databases absorbing data from two transactional layer systems. I\u2019ve tried getting companies like Fivetran to demo ETL systems for us but we\u2019re just too far behind the curve. \n\nCurrent TTD for any new data source added to this \u201cwarehouse\u201d conglomeration is like 1 year: convincing them we need the data stored, getting budget and project approval, getting resources dedicated, waiting to the start of that budget cycle under which it\u2019s approved, pray no one quit that was allocated to manage the project, contract with a vendor to build any ETL with SSIS and whatever else, wait for their client project cycle to give us room, finally get shit hooked up. \n\nNeedless to say, this is simply the wrong way to do things in 2024. \n\nI\u2019ve got my boss convinced on just using cloud stuff (CFO and likes the idea of not having to engineer an entire modern data platform on prem with redundant backups offsite and whatnot - just had to pay the bill to have a second generator installed at main campus because we\u2019re managing our own data center hosting literally everything so his wallet is stinging). \n\nBUT\u2026\n\nOur CTO and IT team are stuck in the 90s. They refuse to support open source, they refuse to use anything but Microsoft. They haven\u2019t directly refused cloud, but have erected so much bureaucracy around getting any cloud vendor and service in use that it\u2019s basically banned. \n\nWe are really at a point of massive inefficiency though. No one can access data with waiting months. There rarely is data to even access. We partner with other companies and it always turns into years long sprint of IT using some niche vendor supplied scripting language to sftp files all over the place. They can\u2019t even consume a REST API over there let alone expose one for vendors. If a vendor needs historic data to assess if they want to, say, spend $50M on buying assets from us (financial industry) we don\u2019t have enough historic data to give them to model. We\u2019re barely able to model ourselves. Our risk department signed on for some ERM tool and the vendor needed 4 years historic data, we didn\u2019t have it so now we\u2019re paying this vendor for nothing while we wait 4 years - and ironically have no plan or system in place to store that data along the way still be the same problem when it\u2019s revisited. \n\nSo, I broke down medallion architecture to my boss to give him some information tools to work with trying to sell this. All good there. But we were taking about data lakes and I realized, apart from rolling our own Hadoop cluster (not something we have the skills to do as an org - nor the desire) if the CTO insists on everything being on prem, I have no clue if anything exists for this. Especially not a packaged deal like we could get with any cloud vendor. \n\nAnyways, help me out for this impending stand off with a laggard CTO keeping us stuck in the late 1900s.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On prem data lake?! Help me prep for a debate with a laggard CTO.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgbhwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710610579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been pressing for more mature data management practices at work (managing analytics). Right now we have a single MS SQL server with a handful of shitty schema databases absorbing data from two transactional layer systems. I\u2019ve tried getting companies like Fivetran to demo ETL systems for us but we\u2019re just too far behind the curve. &lt;/p&gt;\n\n&lt;p&gt;Current TTD for any new data source added to this \u201cwarehouse\u201d conglomeration is like 1 year: convincing them we need the data stored, getting budget and project approval, getting resources dedicated, waiting to the start of that budget cycle under which it\u2019s approved, pray no one quit that was allocated to manage the project, contract with a vendor to build any ETL with SSIS and whatever else, wait for their client project cycle to give us room, finally get shit hooked up. &lt;/p&gt;\n\n&lt;p&gt;Needless to say, this is simply the wrong way to do things in 2024. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got my boss convinced on just using cloud stuff (CFO and likes the idea of not having to engineer an entire modern data platform on prem with redundant backups offsite and whatnot - just had to pay the bill to have a second generator installed at main campus because we\u2019re managing our own data center hosting literally everything so his wallet is stinging). &lt;/p&gt;\n\n&lt;p&gt;BUT\u2026&lt;/p&gt;\n\n&lt;p&gt;Our CTO and IT team are stuck in the 90s. They refuse to support open source, they refuse to use anything but Microsoft. They haven\u2019t directly refused cloud, but have erected so much bureaucracy around getting any cloud vendor and service in use that it\u2019s basically banned. &lt;/p&gt;\n\n&lt;p&gt;We are really at a point of massive inefficiency though. No one can access data with waiting months. There rarely is data to even access. We partner with other companies and it always turns into years long sprint of IT using some niche vendor supplied scripting language to sftp files all over the place. They can\u2019t even consume a REST API over there let alone expose one for vendors. If a vendor needs historic data to assess if they want to, say, spend $50M on buying assets from us (financial industry) we don\u2019t have enough historic data to give them to model. We\u2019re barely able to model ourselves. Our risk department signed on for some ERM tool and the vendor needed 4 years historic data, we didn\u2019t have it so now we\u2019re paying this vendor for nothing while we wait 4 years - and ironically have no plan or system in place to store that data along the way still be the same problem when it\u2019s revisited. &lt;/p&gt;\n\n&lt;p&gt;So, I broke down medallion architecture to my boss to give him some information tools to work with trying to sell this. All good there. But we were taking about data lakes and I realized, apart from rolling our own Hadoop cluster (not something we have the skills to do as an org - nor the desire) if the CTO insists on everything being on prem, I have no clue if anything exists for this. Especially not a packaged deal like we could get with any cloud vendor. &lt;/p&gt;\n\n&lt;p&gt;Anyways, help me out for this impending stand off with a laggard CTO keeping us stuck in the late 1900s.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgbhwd", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgbhwd/on_prem_data_lake_help_me_prep_for_a_debate_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgbhwd/on_prem_data_lake_help_me_prep_for_a_debate_with/", "subreddit_subscribers": 169635, "created_utc": 1710610579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any recommendations would be really helpful. Thanks!", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Important is System Design for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgth7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710667274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations would be really helpful. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgth7l", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgth7l/how_important_is_system_design_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgth7l/how_important_is_system_design_for_data_engineers/", "subreddit_subscribers": 169635, "created_utc": 1710667274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI am wanting to write OOP based Python pipelines for ELT. Does anyone know a resource that I can use to learn and practice ?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning OOP for develop Python based Data engineering pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgl42e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710637247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wanting to write OOP based Python pipelines for ELT. Does anyone know a resource that I can use to learn and practice ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgl42e", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgl42e/learning_oop_for_develop_python_based_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgl42e/learning_oop_for_develop_python_based_data/", "subreddit_subscribers": 169635, "created_utc": 1710637247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! I've been using Reddit more frequently lately, but I\u2019m still active in just a few communities:\n\n- this one, of course\n- /r/cscareerquestions\n- /r/apachespark\n- /r/learnprogramming\n\nwhat other tech/programming subreddits do you follow that compliment this community?", "author_fullname": "t2_a0pro6w2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to expand my Reddit horizon: What other tech/programming Subreddits do you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bglg31", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710638251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I&amp;#39;ve been using Reddit more frequently lately, but I\u2019m still active in just a few communities:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;this one, of course&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/cscareerquestions\"&gt;/r/cscareerquestions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/apachespark\"&gt;/r/apachespark&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/learnprogramming\"&gt;/r/learnprogramming&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;what other tech/programming subreddits do you follow that compliment this community?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bglg31", "is_robot_indexable": true, "report_reasons": null, "author": "benanic", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bglg31/trying_to_expand_my_reddit_horizon_what_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bglg31/trying_to_expand_my_reddit_horizon_what_other/", "subreddit_subscribers": 169635, "created_utc": 1710638251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, everyone! I've created this reviewer for my Data Engineering Team, and I thought I'd share it here with all of you. Feel free to use it and provide any feedback or suggestions you may have. Happy learning!\n\n**AWS Certified Data Engineer Associate DEA-C01 Practice Test**\n\n[https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST](https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST)\n\n**Databricks Certified Data Engineer Associate Practice Test 2024**\n\n[https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST](https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST)\n\nedit. P.S. It's free, so please forgive the small question bank.", "author_fullname": "t2_tgfwnw6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reviewer for Data Engineering Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgtc9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710666704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone! I&amp;#39;ve created this reviewer for my Data Engineering Team, and I thought I&amp;#39;d share it here with all of you. Feel free to use it and provide any feedback or suggestions you may have. Happy learning!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;AWS Certified Data Engineer Associate DEA-C01 Practice Test&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST\"&gt;https://www.udemy.com/course/ultimate-practice-test-aws-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Databricks Certified Data Engineer Associate Practice Test 2024&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST\"&gt;https://www.udemy.com/course/practice-test-databricks-certified-data-engineer-associate/?couponCode=FREEPRACTICETEST&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit. P.S. It&amp;#39;s free, so please forgive the small question bank.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgtc9f", "is_robot_indexable": true, "report_reasons": null, "author": "namibellmere", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgtc9f/reviewer_for_data_engineering_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgtc9f/reviewer_for_data_engineering_certification/", "subreddit_subscribers": 169635, "created_utc": 1710666704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When building a data platform how do you prioritize these three things?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you prioritize performance, price and ease of use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgb5ki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710609686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When building a data platform how do you prioritize these three things?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgb5ki", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgb5ki/how_do_you_prioritize_performance_price_and_ease/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgb5ki/how_do_you_prioritize_performance_price_and_ease/", "subreddit_subscribers": 169635, "created_utc": 1710609686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Yes I know the overall goal of our work is to reduce excel reports. But everywhere I go there is some amount of \"essential\" reports.\n\nI've seen so much - S3 buckets, onedrive, SharePoint, mounted disks, email, SFTP.\n\nWhat does your company do? \n\n", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company distribute excel reports?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgwc8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710678421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes I know the overall goal of our work is to reduce excel reports. But everywhere I go there is some amount of &amp;quot;essential&amp;quot; reports.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen so much - S3 buckets, onedrive, SharePoint, mounted disks, email, SFTP.&lt;/p&gt;\n\n&lt;p&gt;What does your company do? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgwc8l", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgwc8l/how_does_your_company_distribute_excel_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgwc8l/how_does_your_company_distribute_excel_reports/", "subreddit_subscribers": 169635, "created_utc": 1710678421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an API wrapper, which accepts a batch of data, which has to be ingested into multiple tables. First the main facts are inserted and the ids are used to fill some additional metadata tables and junction tables for the dimensional tables.   \n\n\nHow would you efficiently handle the ingestion, when a batch of data arrives?   \n\n\nI think the following options are viable, with respective tradeoffs:\n\n1. Sequential inserts wrapper in transactions. Inserting each fact into the content table and then inserting the accompanying data into the surrounding tables. Do it in a loop for all data. Inefficient, but should give the best guarantees. \n2. Bulk insert with temporary tables. Insert the data into temporary tables (staging). Insert into fact table and get content\\_ids. Fill other temporary tables and insert into dimension tables and metadata tables. \n\nI was looking into COPY but it doesn't seem suitable for multiple tables. Am I missing an option? What setup would you go with? ", "author_fullname": "t2_uc7qtmotr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batching Ingestion (PostgreSQL): Sequential Transactions vs Temporary Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgvc2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710674918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an API wrapper, which accepts a batch of data, which has to be ingested into multiple tables. First the main facts are inserted and the ids are used to fill some additional metadata tables and junction tables for the dimensional tables.   &lt;/p&gt;\n\n&lt;p&gt;How would you efficiently handle the ingestion, when a batch of data arrives?   &lt;/p&gt;\n\n&lt;p&gt;I think the following options are viable, with respective tradeoffs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Sequential inserts wrapper in transactions. Inserting each fact into the content table and then inserting the accompanying data into the surrounding tables. Do it in a loop for all data. Inefficient, but should give the best guarantees. &lt;/li&gt;\n&lt;li&gt;Bulk insert with temporary tables. Insert the data into temporary tables (staging). Insert into fact table and get content_ids. Fill other temporary tables and insert into dimension tables and metadata tables. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I was looking into COPY but it doesn&amp;#39;t seem suitable for multiple tables. Am I missing an option? What setup would you go with? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgvc2w", "is_robot_indexable": true, "report_reasons": null, "author": "nicolay-ai", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgvc2w/batching_ingestion_postgresql_sequential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgvc2w/batching_ingestion_postgresql_sequential/", "subreddit_subscribers": 169635, "created_utc": 1710674918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings,\n\nWe're currently in the process of developing a multi-tenant B2B integration platform, and I'm exploring architectural options, particularly regarding the use of Apache NiFi. I'm considering whether to implement separate NiFi clusters for each tenant or to leverage NiFi's capabilities for multi-tenancy within a single cluster.\n\nOur envisioned data flow involves routing data from various sources such as Amazon Marketplace, Shopify Marketplace, ERP systems, and SAP orders to our Order Management System (OMS) via NiFi. We anticipate a data movement pattern from API to staging and then to another API, with NiFi serving as the translator between these APIs.\n\nFor instance, orders from different marketplaces or systems may need to be directed to different OMS instances, and our integration platform would facilitate this process seamlessly.\n\nI welcome any insights or suggestions on optimizing this approach.\n\nLooking forward to your input.", "author_fullname": "t2_urs1iey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Multi-Tenant B2B Integration with Apache NiFi: Seeking Feedback and Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bghnuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710627366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently in the process of developing a multi-tenant B2B integration platform, and I&amp;#39;m exploring architectural options, particularly regarding the use of Apache NiFi. I&amp;#39;m considering whether to implement separate NiFi clusters for each tenant or to leverage NiFi&amp;#39;s capabilities for multi-tenancy within a single cluster.&lt;/p&gt;\n\n&lt;p&gt;Our envisioned data flow involves routing data from various sources such as Amazon Marketplace, Shopify Marketplace, ERP systems, and SAP orders to our Order Management System (OMS) via NiFi. We anticipate a data movement pattern from API to staging and then to another API, with NiFi serving as the translator between these APIs.&lt;/p&gt;\n\n&lt;p&gt;For instance, orders from different marketplaces or systems may need to be directed to different OMS instances, and our integration platform would facilitate this process seamlessly.&lt;/p&gt;\n\n&lt;p&gt;I welcome any insights or suggestions on optimizing this approach.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bghnuc", "is_robot_indexable": true, "report_reasons": null, "author": "mallucharan", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bghnuc/optimizing_multitenant_b2b_integration_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bghnuc/optimizing_multitenant_b2b_integration_with/", "subreddit_subscribers": 169635, "created_utc": 1710627366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI noticed this subreddit has Oracle WMS related posts so wanted to inquire on that same topic.\n\nMy Organization has implemented Oracle SaaS ERP and Oracle WMS solutions. Both are interconnected to each other.\n\nEvery quarter, Oracle deploys SaaS patches on Fridays. Similarly, WMS also quarterly deploys their patches, but on Saturday.\n\n From what we are being told, WMS and SaaS has reliance on each other. With one of the two being offline on both Friday and Saturday, how does one go about ensuring if anyhing not able to being passed to the other system, how to you sync that up? \n\nIs there a provision in SaaS that allows to queue up data intended for WMS, and vice versa.\n\nthanks", "author_fullname": "t2_h41sfw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle WMS and Oracle SaaS - one depends on the other | seeking data sync advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgf8zo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710620737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I noticed this subreddit has Oracle WMS related posts so wanted to inquire on that same topic.&lt;/p&gt;\n\n&lt;p&gt;My Organization has implemented Oracle SaaS ERP and Oracle WMS solutions. Both are interconnected to each other.&lt;/p&gt;\n\n&lt;p&gt;Every quarter, Oracle deploys SaaS patches on Fridays. Similarly, WMS also quarterly deploys their patches, but on Saturday.&lt;/p&gt;\n\n&lt;p&gt;From what we are being told, WMS and SaaS has reliance on each other. With one of the two being offline on both Friday and Saturday, how does one go about ensuring if anyhing not able to being passed to the other system, how to you sync that up? &lt;/p&gt;\n\n&lt;p&gt;Is there a provision in SaaS that allows to queue up data intended for WMS, and vice versa.&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgf8zo", "is_robot_indexable": true, "report_reasons": null, "author": "fm2xm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgf8zo/oracle_wms_and_oracle_saas_one_depends_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgf8zo/oracle_wms_and_oracle_saas_one_depends_on_the/", "subreddit_subscribers": 169635, "created_utc": 1710620737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About 6 months ago, my company made the decision to purchase Ab initio. Based on my research, it, along with other licenseing ETL tools, seems to be on the decline. My company has been rolling it out to various teams and mine is up next. We will be expectsd to migrate current pipelines and new ones to Ab Initio. Currently, we use python + SQL scripts ran on Snowflake to transform our raw data ( files in AWS S3) and then just load into Snowflake tables.\n\nI'm not ready to leave this company, but I'm not so excited about developing a skill set in a dying tool. Still, is there anyway to make the most out of this situation? Is there anything to learn diving deep in ab Initio and learning all I can about the tool? Should I use the tool but focus my cv on the challenges I overcame, not the tool used? Or, should I hyper specialize in ab Initio and become an expert who drifts around to different companies to maintain their pipelines, requiring a large salary for this niche and drying skill set.\n\n", "author_fullname": "t2_jlj0h3u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting the most of out an old tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgymae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710685108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About 6 months ago, my company made the decision to purchase Ab initio. Based on my research, it, along with other licenseing ETL tools, seems to be on the decline. My company has been rolling it out to various teams and mine is up next. We will be expectsd to migrate current pipelines and new ones to Ab Initio. Currently, we use python + SQL scripts ran on Snowflake to transform our raw data ( files in AWS S3) and then just load into Snowflake tables.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not ready to leave this company, but I&amp;#39;m not so excited about developing a skill set in a dying tool. Still, is there anyway to make the most out of this situation? Is there anything to learn diving deep in ab Initio and learning all I can about the tool? Should I use the tool but focus my cv on the challenges I overcame, not the tool used? Or, should I hyper specialize in ab Initio and become an expert who drifts around to different companies to maintain their pipelines, requiring a large salary for this niche and drying skill set.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgymae", "is_robot_indexable": true, "report_reasons": null, "author": "CriticalSouth3447", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgymae/getting_the_most_of_out_an_old_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgymae/getting_the_most_of_out_an_old_tool/", "subreddit_subscribers": 169635, "created_utc": 1710685108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI was browsing internet and found some blogs describing a problem, and giving sample propositions on how to solve it. Do you know of any bloggers or technical content creator who does the same thing with Data engineering problems, modeling and/or Architecting solutions ?\n\nThanks for sharing", "author_fullname": "t2_948bsvs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for technical blogs sharing solutions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgy3ct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710683694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I was browsing internet and found some blogs describing a problem, and giving sample propositions on how to solve it. Do you know of any bloggers or technical content creator who does the same thing with Data engineering problems, modeling and/or Architecting solutions ?&lt;/p&gt;\n\n&lt;p&gt;Thanks for sharing&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bgy3ct", "is_robot_indexable": true, "report_reasons": null, "author": "SdJbra", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgy3ct/looking_for_technical_blogs_sharing_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgy3ct/looking_for_technical_blogs_sharing_solutions/", "subreddit_subscribers": 169635, "created_utc": 1710683694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear sub,\n\nI have a quite heterogeneous CV, but was always drawn towards coding, in particular data science &amp; data engineering. Following my interest, after my studies, I have started as a Data Engineer at a boutique consulting firm. For the past six months, this is where I program ETL pipelines for varying clients and industries.\n\nNow, as I mentioned, my CV is quite diverse, and just recently I have received an offer from a leading (Tier 2) strategy consulting firm. My job there would be on a much higher abstraction level, talking to clients about digital transformation and AI strategies.\n\nI really enjoy the work I do right now as a Data Engineer, but the consulting firm is offering me twice the pay. On the other hand, right now I am aquiring a lot of \"hard skills\", therefore I am confident in what I talk about and work is fun.\n\nIf I go into consulting, the path would be quite clear: Work there for 2 years, do a (paid) PhD, work for 1 more year (or if it is fun, even longer) and then hopefully exit into a management role at a tech company or a corporate tech division.\n\nAs I do not know much about possible career paths in data engineering, I am interested in the later career options and how you would choose.", "author_fullname": "t2_4ctvu7t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing between Data Engineering and Strategy Consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgptkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710652243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear sub,&lt;/p&gt;\n\n&lt;p&gt;I have a quite heterogeneous CV, but was always drawn towards coding, in particular data science &amp;amp; data engineering. Following my interest, after my studies, I have started as a Data Engineer at a boutique consulting firm. For the past six months, this is where I program ETL pipelines for varying clients and industries.&lt;/p&gt;\n\n&lt;p&gt;Now, as I mentioned, my CV is quite diverse, and just recently I have received an offer from a leading (Tier 2) strategy consulting firm. My job there would be on a much higher abstraction level, talking to clients about digital transformation and AI strategies.&lt;/p&gt;\n\n&lt;p&gt;I really enjoy the work I do right now as a Data Engineer, but the consulting firm is offering me twice the pay. On the other hand, right now I am aquiring a lot of &amp;quot;hard skills&amp;quot;, therefore I am confident in what I talk about and work is fun.&lt;/p&gt;\n\n&lt;p&gt;If I go into consulting, the path would be quite clear: Work there for 2 years, do a (paid) PhD, work for 1 more year (or if it is fun, even longer) and then hopefully exit into a management role at a tech company or a corporate tech division.&lt;/p&gt;\n\n&lt;p&gt;As I do not know much about possible career paths in data engineering, I am interested in the later career options and how you would choose.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgptkk", "is_robot_indexable": true, "report_reasons": null, "author": "murlurd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgptkk/choosing_between_data_engineering_and_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgptkk/choosing_between_data_engineering_and_strategy/", "subreddit_subscribers": 169635, "created_utc": 1710652243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all. Throwaway account because I\u2019m paranoid.\n\nMy DE team is slowly shifting away from older msft-beholden tech, to more newer cloud based stuff (Azure). At the end of the day, a huge chunk of what my team does is file ingestion (or output) that either goes into SQL Server or Snowflake in some form or fashion. We are also starting to dabble with some APIs for some core business products that have data needs that have to go through us in some way or form. Management says we're trying to \"modernize\" our stack (for me going to C# from SSIS isn't modernization, but that's what they call it here). \n\nThe nature of my team is B2B interactions. I guess my question is, what kind of cloud tools/offerings can I leverage in this type of environment? I want to be ahead of the curve in my team, but sometimes it feels so pointless to overengineer stuff for something that a simple process can do to upload files to a table and call it a day, or to extract data and create a file. We're not doing anything majorly cutting edge, and Snowflake is handled by a separate BI team. We currently don't do any type of streaming either. The business is currently expanding heavily, and I feel like we need to focus on scalability and producing performant solutions, but when my main experience so far at the company is just reading files and inserting and using SQL to get the data I need, I feel a bit lacking, and management isn't exactly great at providing vision and guidance.", "author_fullname": "t2_5hzy2ed6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance in leveraging cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgfhg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710621397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Throwaway account because I\u2019m paranoid.&lt;/p&gt;\n\n&lt;p&gt;My DE team is slowly shifting away from older msft-beholden tech, to more newer cloud based stuff (Azure). At the end of the day, a huge chunk of what my team does is file ingestion (or output) that either goes into SQL Server or Snowflake in some form or fashion. We are also starting to dabble with some APIs for some core business products that have data needs that have to go through us in some way or form. Management says we&amp;#39;re trying to &amp;quot;modernize&amp;quot; our stack (for me going to C# from SSIS isn&amp;#39;t modernization, but that&amp;#39;s what they call it here). &lt;/p&gt;\n\n&lt;p&gt;The nature of my team is B2B interactions. I guess my question is, what kind of cloud tools/offerings can I leverage in this type of environment? I want to be ahead of the curve in my team, but sometimes it feels so pointless to overengineer stuff for something that a simple process can do to upload files to a table and call it a day, or to extract data and create a file. We&amp;#39;re not doing anything majorly cutting edge, and Snowflake is handled by a separate BI team. We currently don&amp;#39;t do any type of streaming either. The business is currently expanding heavily, and I feel like we need to focus on scalability and producing performant solutions, but when my main experience so far at the company is just reading files and inserting and using SQL to get the data I need, I feel a bit lacking, and management isn&amp;#39;t exactly great at providing vision and guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bgfhg6", "is_robot_indexable": true, "report_reasons": null, "author": "white_thiccbori", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgfhg6/guidance_in_leveraging_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgfhg6/guidance_in_leveraging_cloud/", "subreddit_subscribers": 169635, "created_utc": 1710621397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pls share your experience on data migration especially structured data from single to multiple different systems. For example eCom kind of solution contains customer records and transactions. \n\nThanks.", "author_fullname": "t2_85la63x7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data migration tips", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgby5z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710611799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pls share your experience on data migration especially structured data from single to multiple different systems. For example eCom kind of solution contains customer records and transactions. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgby5z", "is_robot_indexable": true, "report_reasons": null, "author": "SubstanceBig5459", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgby5z/any_data_migration_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgby5z/any_data_migration_tips/", "subreddit_subscribers": 169635, "created_utc": 1710611799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.\n\nHow should I go about documenting/understanding what each table means and each field?\n\nAnd when should I start suggesting changes to some tables?\n\nI'm currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it's the right way to go.", "author_fullname": "t2_apdhbvv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tables all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh0k35", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710689970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.&lt;/p&gt;\n\n&lt;p&gt;How should I go about documenting/understanding what each table means and each field?&lt;/p&gt;\n\n&lt;p&gt;And when should I start suggesting changes to some tables?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it&amp;#39;s the right way to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh0k35", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Scene-2465", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh0k35/tables_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh0k35/tables_all_the_way_down/", "subreddit_subscribers": 169635, "created_utc": 1710689970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.\n\nHow should I go about documenting/understanding what each table means and each field?\n\nAnd when should I start suggesting changes to some tables?\n\nI'm currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it's the right way to go.", "author_fullname": "t2_apdhbvv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tables all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh0jzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710689965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.&lt;/p&gt;\n\n&lt;p&gt;How should I go about documenting/understanding what each table means and each field?&lt;/p&gt;\n\n&lt;p&gt;And when should I start suggesting changes to some tables?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it&amp;#39;s the right way to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh0jzr", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Scene-2465", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh0jzr/tables_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh0jzr/tables_all_the_way_down/", "subreddit_subscribers": 169635, "created_utc": 1710689965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.\n\nHow should I go about documenting/understanding what each table means and each field?\n\nAnd when should I start suggesting changes to some tables?\n\nI'm currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it's the right way to go.", "author_fullname": "t2_apdhbvv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tables all the way down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bh0jww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710689960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a new company with almost zero up to date documentation, with loads and loads of tables in different schemas.&lt;/p&gt;\n\n&lt;p&gt;How should I go about documenting/understanding what each table means and each field?&lt;/p&gt;\n\n&lt;p&gt;And when should I start suggesting changes to some tables?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently just building an ERD using dbdiagram.io with comments as much as I can but not sure if it&amp;#39;s the right way to go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bh0jww", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Scene-2465", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bh0jww/tables_all_the_way_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bh0jww/tables_all_the_way_down/", "subreddit_subscribers": 169635, "created_utc": 1710689960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to DBT. \n\nI  want to run a CI/CD pipeline to perform DBT jobs against a test set in  Databricks. I want to do this in the most inexpensive way possible using  a very small amount of data so it can be triggered for every PR we  raise to the data models. Ideally this workflow would do DRY run tests so we don't need to launch any clustering. \n\n* Has anybody got any experience with this setup, can point me in the right direction, and ran into any issues? \n* Is this all possible in the  latest open source version of dbt-core?\n\nI also want to create a metadata ingest to list files from various blob store sources e.g. Azure Gen2, into a synchronised raw table of metadata of those files (for visibility/querying/and ontology). \n\n* Is this something DBT can help with? Original plan was to do this with isolated Autoloader Spark jobs, not 100% ideal. \n\nIdeally if we can shove as much as possible into DBT to provide managed CI/CD testing and deployment, and overall a structured workflow for our data tasks, that'd be great.\n\nThanks for any help! ", "author_fullname": "t2_duii2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD Databricks DBT and Github Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgwk0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710679130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to DBT. &lt;/p&gt;\n\n&lt;p&gt;I  want to run a CI/CD pipeline to perform DBT jobs against a test set in  Databricks. I want to do this in the most inexpensive way possible using  a very small amount of data so it can be triggered for every PR we  raise to the data models. Ideally this workflow would do DRY run tests so we don&amp;#39;t need to launch any clustering. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Has anybody got any experience with this setup, can point me in the right direction, and ran into any issues? &lt;/li&gt;\n&lt;li&gt;Is this all possible in the  latest open source version of dbt-core?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I also want to create a metadata ingest to list files from various blob store sources e.g. Azure Gen2, into a synchronised raw table of metadata of those files (for visibility/querying/and ontology). &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is this something DBT can help with? Original plan was to do this with isolated Autoloader Spark jobs, not 100% ideal. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Ideally if we can shove as much as possible into DBT to provide managed CI/CD testing and deployment, and overall a structured workflow for our data tasks, that&amp;#39;d be great.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bgwk0l", "is_robot_indexable": true, "report_reasons": null, "author": "MMACheerpuppy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgwk0l/cicd_databricks_dbt_and_github_actions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgwk0l/cicd_databricks_dbt_and_github_actions/", "subreddit_subscribers": 169635, "created_utc": 1710679130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My Azure Data Factory DEs were trying to get a vendor to append a GUID for a batch ID when they extract into a shared location that has multiple file drops from different systems.   \n\nThis is just some vendor widget no code so seems to me like ADF should be doing it.  Seems like a common file wrangler kind of use case.\n\nI suggested moving the files to another folder and separating it that way.  Was told that took 'too much logic'.  What are different ways we can separate a batch of files on the ADF end?\n\nAnd can ADF generate a GUID batch id and append or prefix to the filenames?", "author_fullname": "t2_21umeu7n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "different ways to generate a batch id for a pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bgoilu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710647865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Azure Data Factory DEs were trying to get a vendor to append a GUID for a batch ID when they extract into a shared location that has multiple file drops from different systems.   &lt;/p&gt;\n\n&lt;p&gt;This is just some vendor widget no code so seems to me like ADF should be doing it.  Seems like a common file wrangler kind of use case.&lt;/p&gt;\n\n&lt;p&gt;I suggested moving the files to another folder and separating it that way.  Was told that took &amp;#39;too much logic&amp;#39;.  What are different ways we can separate a batch of files on the ADF end?&lt;/p&gt;\n\n&lt;p&gt;And can ADF generate a GUID batch id and append or prefix to the filenames?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bgoilu", "is_robot_indexable": true, "report_reasons": null, "author": "ComfortAndSpeed", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bgoilu/different_ways_to_generate_a_batch_id_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bgoilu/different_ways_to_generate_a_batch_id_for_a/", "subreddit_subscribers": 169635, "created_utc": 1710647865.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}