{"kind": "Listing", "data": {"after": null, "dist": 11, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I am currently documenting the data flow of our project and I wanted the documentation to be easily understood by analysts in a visual manner. What is the appropriate way to diagram data flow between views, tables, left joins? ", "author_fullname": "t2_9o6vpzoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to diagram sql queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ba4g7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709944933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am currently documenting the data flow of our project and I wanted the documentation to be easily understood by analysts in a visual manner. What is the appropriate way to diagram data flow between views, tables, left joins? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ba4g7v", "is_robot_indexable": true, "report_reasons": null, "author": "SlingBag", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ba4g7v/how_to_diagram_sql_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ba4g7v/how_to_diagram_sql_queries/", "subreddit_subscribers": 167140, "created_utc": 1709944933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let me give a brief context. So, we are implementing a data lake project for a client and they are into manufacturing. Their IT team and manufacturing teams are two entities by itself and we work closely with their IT team or Digital team. The issue we are facing is that the data that is coming to the system is changing its structure now and then. To give an example, one of the data sources is SAP now when we extract the data based on the T-code for a year say 2021 we see the set of columns, but for the next year i.e.2022, we see some of the columns are missing or additional columns are present!! Needless to say, this is making the life of our team into a nightmare as we need to keep on loading the data again and again, pipelines are breaking, rewriting the logic... the list goes on. People will be thinking why the data at the source is changed, the answer is that some of the data is entered manually by the people in the manufacturing unit and they might not be following proper standards. At the organization level their IT team has very little say as revenue is generated by the manufacturing team hence it's very difficult for the IT/Digital team to force a standard for these manual data, even though they are trying from their end many of the times manufacturing unit people seldom follows it.\nNow what I want to know is has anyone faced a similar kind of challenge in implementing a datalake project. If so how did your team overcome this issue or how did your team handle this situation? Because I feel our team is highly exhausted due to the same repetitive work. Please put your thoughts it will be really helpful.\n\n\nNB: Please don't ask why we committed to this project, as it's not under my control or my decision!!!", "author_fullname": "t2_spo003v40", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with challenges in implementing data lake projects in an organization where the structure of the data at the source itself is changing frequently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bah0v3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709990373.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709988581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let me give a brief context. So, we are implementing a data lake project for a client and they are into manufacturing. Their IT team and manufacturing teams are two entities by itself and we work closely with their IT team or Digital team. The issue we are facing is that the data that is coming to the system is changing its structure now and then. To give an example, one of the data sources is SAP now when we extract the data based on the T-code for a year say 2021 we see the set of columns, but for the next year i.e.2022, we see some of the columns are missing or additional columns are present!! Needless to say, this is making the life of our team into a nightmare as we need to keep on loading the data again and again, pipelines are breaking, rewriting the logic... the list goes on. People will be thinking why the data at the source is changed, the answer is that some of the data is entered manually by the people in the manufacturing unit and they might not be following proper standards. At the organization level their IT team has very little say as revenue is generated by the manufacturing team hence it&amp;#39;s very difficult for the IT/Digital team to force a standard for these manual data, even though they are trying from their end many of the times manufacturing unit people seldom follows it.\nNow what I want to know is has anyone faced a similar kind of challenge in implementing a datalake project. If so how did your team overcome this issue or how did your team handle this situation? Because I feel our team is highly exhausted due to the same repetitive work. Please put your thoughts it will be really helpful.&lt;/p&gt;\n\n&lt;p&gt;NB: Please don&amp;#39;t ask why we committed to this project, as it&amp;#39;s not under my control or my decision!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bah0v3", "is_robot_indexable": true, "report_reasons": null, "author": "MoonWalker212", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bah0v3/how_to_deal_with_challenges_in_implementing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bah0v3/how_to_deal_with_challenges_in_implementing_data/", "subreddit_subscribers": 167140, "created_utc": 1709988581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit fam,\n\n5-year Data Analyst here feeling like I've hit a wall. I'm a CS grad with proficiency in SQL, Tableau, Metabase, dbt, dimensional modeling, and a sprinkle of Python. My experience spans across Fintech, Health, and Telecom.\n\nWhile I appreciate data analysis, I crave a more challenging and technical role. With my programming background, I feel underutilized. Is it too late to switch gears?\n\nI'm torn between Data Engineering and Data Science for upskilling. My goal? Advance to a more technical position within data.\n\nHere's the kicker: I don't just want courses. I crave practical learning that integrates with my current skillset and is job-market relevant.\n\nAny advice on the best path forward? Open to all suggestions! Happy to share more details about my experience\n\nThanks in advance!", "author_fullname": "t2_mpil1bv3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst (SQL &amp; Viz ONLY!) - Feeling Stuck. What's the Next Step?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1baknx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709999226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit fam,&lt;/p&gt;\n\n&lt;p&gt;5-year Data Analyst here feeling like I&amp;#39;ve hit a wall. I&amp;#39;m a CS grad with proficiency in SQL, Tableau, Metabase, dbt, dimensional modeling, and a sprinkle of Python. My experience spans across Fintech, Health, and Telecom.&lt;/p&gt;\n\n&lt;p&gt;While I appreciate data analysis, I crave a more challenging and technical role. With my programming background, I feel underutilized. Is it too late to switch gears?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m torn between Data Engineering and Data Science for upskilling. My goal? Advance to a more technical position within data.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the kicker: I don&amp;#39;t just want courses. I crave practical learning that integrates with my current skillset and is job-market relevant.&lt;/p&gt;\n\n&lt;p&gt;Any advice on the best path forward? Open to all suggestions! Happy to share more details about my experience&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1baknx0", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Avocado-226", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1baknx0/data_analyst_sql_viz_only_feeling_stuck_whats_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1baknx0/data_analyst_sql_viz_only_feeling_stuck_whats_the/", "subreddit_subscribers": 167140, "created_utc": 1709999226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " A very common problem in querying ERP or manufacturing MRP systems is that they use \u201cself-join\u201d tables to store their part information. These tables store \u201cbill of materials\u201d or \u201cBOM\u201d information, where complete assemblies of items can be found.\n\nI have this table with approximately 200k rows, that's similar to a bill of materials. For example: product A1 is made of 2 A2s, A2 is made of 2 A3s and A3 is made of 2 A4s, so on and so forth. We have thousands of products in this table.\n\nBasically I need to transform this in a table that says A1 is made of 8 A4s, and does this for every product. We need to know which and how many items the products have in their final layer. I've tried doing a bunch of joins in SQL but the problem is a don't know how many layers each product can have.\n\nDo any of you have an efficient way to approach this?\n\n&amp;#x200B;\n\n[Simple example](https://preview.redd.it/2h3ygsyul5nc1.png?width=679&amp;format=png&amp;auto=webp&amp;s=1c3bcb0b000f8ad5e05c4342b7bbec474b721e7b)", "author_fullname": "t2_1fcpawj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bill of materials table - SQL help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2h3ygsyul5nc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/2h3ygsyul5nc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=19bac9127cd540bb036aa0bd8939278207626963"}, {"y": 69, "x": 216, "u": "https://preview.redd.it/2h3ygsyul5nc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a671abae8d14edabe1294437a19ae40aa550ddf"}, {"y": 103, "x": 320, "u": "https://preview.redd.it/2h3ygsyul5nc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=287e5cc9b94d20e5c9506b9614c7c75bec6c63ad"}, {"y": 206, "x": 640, "u": "https://preview.redd.it/2h3ygsyul5nc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d204c9264670d4b35f9d55769f8d51bc814d1308"}], "s": {"y": 219, "x": 679, "u": "https://preview.redd.it/2h3ygsyul5nc1.png?width=679&amp;format=png&amp;auto=webp&amp;s=1c3bcb0b000f8ad5e05c4342b7bbec474b721e7b"}, "id": "2h3ygsyul5nc1"}}, "name": "t3_1b9vh4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/aP2NDvmYmw5Xbsh4TrCD8XYdwSuN1qQKGAVeC276YU8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709922874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A very common problem in querying ERP or manufacturing MRP systems is that they use \u201cself-join\u201d tables to store their part information. These tables store \u201cbill of materials\u201d or \u201cBOM\u201d information, where complete assemblies of items can be found.&lt;/p&gt;\n\n&lt;p&gt;I have this table with approximately 200k rows, that&amp;#39;s similar to a bill of materials. For example: product A1 is made of 2 A2s, A2 is made of 2 A3s and A3 is made of 2 A4s, so on and so forth. We have thousands of products in this table.&lt;/p&gt;\n\n&lt;p&gt;Basically I need to transform this in a table that says A1 is made of 8 A4s, and does this for every product. We need to know which and how many items the products have in their final layer. I&amp;#39;ve tried doing a bunch of joins in SQL but the problem is a don&amp;#39;t know how many layers each product can have.&lt;/p&gt;\n\n&lt;p&gt;Do any of you have an efficient way to approach this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2h3ygsyul5nc1.png?width=679&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c3bcb0b000f8ad5e05c4342b7bbec474b721e7b\"&gt;Simple example&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9vh4s", "is_robot_indexable": true, "report_reasons": null, "author": "TulioCM", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9vh4s/bill_of_materials_table_sql_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9vh4s/bill_of_materials_table_sql_help/", "subreddit_subscribers": 167140, "created_utc": 1709922874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a one man data team who is responsible for too much. In an effort to make our reporting tool easier to use the data model needs to be simplified. Our analytics system is a bloated mess in PowerBI and I am planning on rebuilding it, and planning to hire a consultant to help me build a best practice retail data model for reporting using DBT core + metric flow (open source semantic layer). The source data is already being served in BigQuery with an active DBT project so it\u2019s purely a modeling design exercise.\n\nFor serious data professionals where might be a good place to search for consultants in this domain?", "author_fullname": "t2_ronx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to find good data modeling consultants?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bahyli", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "8cf4f390-e787-11ed-81a4-ca7b65282907", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709991590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a one man data team who is responsible for too much. In an effort to make our reporting tool easier to use the data model needs to be simplified. Our analytics system is a bloated mess in PowerBI and I am planning on rebuilding it, and planning to hire a consultant to help me build a best practice retail data model for reporting using DBT core + metric flow (open source semantic layer). The source data is already being served in BigQuery with an active DBT project so it\u2019s purely a modeling design exercise.&lt;/p&gt;\n\n&lt;p&gt;For serious data professionals where might be a good place to search for consultants in this domain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bahyli", "is_robot_indexable": true, "report_reasons": null, "author": "seanpool3", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bahyli/where_to_find_good_data_modeling_consultants/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bahyli/where_to_find_good_data_modeling_consultants/", "subreddit_subscribers": 167140, "created_utc": 1709991590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI read that lsm trees is used by dynamo db, cassandra and scylla db. But nowhere saw link between relational db(sql db) and lsm trees. Is lsm trees only used in nosql databases if that is the case why can't we used them in sql ?  \n", "author_fullname": "t2_aqmxwdoy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Database using LSM Trees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1badyyn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709976826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I read that lsm trees is used by dynamo db, cassandra and scylla db. But nowhere saw link between relational db(sql db) and lsm trees. Is lsm trees only used in nosql databases if that is the case why can&amp;#39;t we used them in sql ?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1badyyn", "is_robot_indexable": true, "report_reasons": null, "author": "AggravatingParsnip89", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1badyyn/sql_database_using_lsm_trees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1badyyn/sql_database_using_lsm_trees/", "subreddit_subscribers": 167140, "created_utc": 1709976826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently we don\u2019t have vaccum of data happening on regular basis and so size of object storage is growing in huge scale. We need actual data\u2019s retention to be 1 year at-least -  in that case do I need to vaccum delta table (object storage bucket) - by setting  vaccum retention period as 1 year? This is so when in-case 1 year old data is needed we can time travel using timestamp.\n\ndeltaTable.vacuum(8766) \n\n# 8766 is 1 year in hours\n\nAs it is delta table though it\u2019s object storage bucket - rather than life cycle policy, vaccum is what should be done? Any thoughts or suggestions? ", "author_fullname": "t2_asn24r2z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on Vaccum data to save storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1badj0t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709974977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we don\u2019t have vaccum of data happening on regular basis and so size of object storage is growing in huge scale. We need actual data\u2019s retention to be 1 year at-least -  in that case do I need to vaccum delta table (object storage bucket) - by setting  vaccum retention period as 1 year? This is so when in-case 1 year old data is needed we can time travel using timestamp.&lt;/p&gt;\n\n&lt;p&gt;deltaTable.vacuum(8766) &lt;/p&gt;\n\n&lt;h1&gt;8766 is 1 year in hours&lt;/h1&gt;\n\n&lt;p&gt;As it is delta table though it\u2019s object storage bucket - rather than life cycle policy, vaccum is what should be done? Any thoughts or suggestions? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1badj0t", "is_robot_indexable": true, "report_reasons": null, "author": "Slow-Woodpecker-3629", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1badj0t/question_on_vaccum_data_to_save_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1badj0t/question_on_vaccum_data_to_save_storage/", "subreddit_subscribers": 167140, "created_utc": 1709974977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIs there a way to edit Azure Synapse Analytics notebooks in VsCode? I can clone the repository, but the code is stored as JSON, eg as follows:\n\n\n\n\t{\n\t\t\"cell_type\": \"code\",\n\t\t\"source\": [\n\t\t\t\"\\r\\n\",\n\t\t\t\"\\r\\n\",\n\t\t\t\"\\r\\n\",\n\t\t\t\"import http\\r\\n\",\n\t\t\t\"import logging\\r\\n\",\n\t\t\t\"import azure.functions as func\\r\\n\",\n\t\t\t\"import requests\\r\\n\",\n\t\t\t\"from azure.storage.blob import ContainerClient\\r\\n\",\n\t\t\t\"import sys\\r\\n\",\n\t\t\t\"import pandas as pd\\r\\n\",\n\t\t\t\"import json\\r\\n\",\n\t\t\t\"from datetime import datetime\\r\\n\",\n\t\t\t\"from tqdm import tqdm\\r\\n\",\n\t\t\t\"from notebookutils import mssparkutils\\r\\n\",\n\t\t\t\"\\r\\n\",\n\t\t\t\"\\r\\n\",\n\t\t\t\"\\r\\n\",\n\t\t\t\"\\r\\n\",\n\t\t\t\"# Grab API key\\r\\n\",\n\t\t\t\"# (ETC - All code is foramtted like this as a list of strings)\\r\\n\",\n\n\t\t],\n\t\t\"execution_count\": 23\n\t}\n\n\nSo, none of my code formatting / linting tools will work out of the box.\n\nI thought about importing a .py file, but this is difficult as the nodebook code is run on an Apache spark cluster.\n\nAny ideas on this would be appreciated.\n\nPS: Azure Synapse Analytics is a trash product.", "author_fullname": "t2_5i2it6n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Analytics - Editing notebooks with VSCode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ba7vl3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709954872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Is there a way to edit Azure Synapse Analytics notebooks in VsCode? I can clone the repository, but the code is stored as JSON, eg as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n    &amp;quot;cell_type&amp;quot;: &amp;quot;code&amp;quot;,\n    &amp;quot;source&amp;quot;: [\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;import http\\r\\n&amp;quot;,\n        &amp;quot;import logging\\r\\n&amp;quot;,\n        &amp;quot;import azure.functions as func\\r\\n&amp;quot;,\n        &amp;quot;import requests\\r\\n&amp;quot;,\n        &amp;quot;from azure.storage.blob import ContainerClient\\r\\n&amp;quot;,\n        &amp;quot;import sys\\r\\n&amp;quot;,\n        &amp;quot;import pandas as pd\\r\\n&amp;quot;,\n        &amp;quot;import json\\r\\n&amp;quot;,\n        &amp;quot;from datetime import datetime\\r\\n&amp;quot;,\n        &amp;quot;from tqdm import tqdm\\r\\n&amp;quot;,\n        &amp;quot;from notebookutils import mssparkutils\\r\\n&amp;quot;,\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;\\r\\n&amp;quot;,\n        &amp;quot;# Grab API key\\r\\n&amp;quot;,\n        &amp;quot;# (ETC - All code is foramtted like this as a list of strings)\\r\\n&amp;quot;,\n\n    ],\n    &amp;quot;execution_count&amp;quot;: 23\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;So, none of my code formatting / linting tools will work out of the box.&lt;/p&gt;\n\n&lt;p&gt;I thought about importing a .py file, but this is difficult as the nodebook code is run on an Apache spark cluster.&lt;/p&gt;\n\n&lt;p&gt;Any ideas on this would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;PS: Azure Synapse Analytics is a trash product.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ba7vl3", "is_robot_indexable": true, "report_reasons": null, "author": "mr-dre", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ba7vl3/azure_synapse_analytics_editing_notebooks_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ba7vl3/azure_synapse_analytics_editing_notebooks_with/", "subreddit_subscribers": 167140, "created_utc": 1709954872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently working on a patent analysis project and I'm seeking insights on how to efficiently scrape data from the United States Patent and Trademark Office (USPTO) website. We aim to stream this data into a data lake for further analysis. I'm particularly interested in methods or tools that can help streamline the process and ensure accuracy in collecting patent information, while also facilitating the integration of the scraped data into our data lake infrastructure. Any advice or recommendations on best practices, relevant libraries, or specific techniques would be greatly appreciated. Thank you in advance for your insights!", "author_fullname": "t2_7eqe0vfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering student in need of help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1banv68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710007357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a patent analysis project and I&amp;#39;m seeking insights on how to efficiently scrape data from the United States Patent and Trademark Office (USPTO) website. We aim to stream this data into a data lake for further analysis. I&amp;#39;m particularly interested in methods or tools that can help streamline the process and ensure accuracy in collecting patent information, while also facilitating the integration of the scraped data into our data lake infrastructure. Any advice or recommendations on best practices, relevant libraries, or specific techniques would be greatly appreciated. Thank you in advance for your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1banv68", "is_robot_indexable": true, "report_reasons": null, "author": "Positive_Temporary77", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1banv68/data_engineering_student_in_need_of_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1banv68/data_engineering_student_in_need_of_help/", "subreddit_subscribers": 167140, "created_utc": 1710007357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to enroll in the DE bootcamp by WeCloudData- the self-paced one and wanted to know if anyone has gone through their bootcamp. Would like to know your experience- how was there course material, TA support, and career support? I'm currently working as SWE and looking to pivot into a de role. I know there are other ways of developing those skills either by watching YouTube videos or through Udemy but I like to have a structured course.\n\nPlease mention If you tried other boot camps and found it helpful.", "author_fullname": "t2_86hjd67r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinion on Data Engineering Bootcamp- WeCloudData", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ba8g6b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709956689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to enroll in the DE bootcamp by WeCloudData- the self-paced one and wanted to know if anyone has gone through their bootcamp. Would like to know your experience- how was there course material, TA support, and career support? I&amp;#39;m currently working as SWE and looking to pivot into a de role. I know there are other ways of developing those skills either by watching YouTube videos or through Udemy but I like to have a structured course.&lt;/p&gt;\n\n&lt;p&gt;Please mention If you tried other boot camps and found it helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ba8g6b", "is_robot_indexable": true, "report_reasons": null, "author": "Reporter-Soggy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ba8g6b/opinion_on_data_engineering_bootcamp_weclouddata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ba8g6b/opinion_on_data_engineering_bootcamp_weclouddata/", "subreddit_subscribers": 167140, "created_utc": 1709956689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "had a few questions pertaining to what problems have you encountered persistently ?  \n\n\nDo you struggle with ensuring data accuracy across different projects?\n\n&amp;#x200B;\n\nHow often do you encounter issues with outdated or inconsistent data?\n\n&amp;#x200B;\n\nHave data quality problems ever impacted your ability to deliver projects successfully?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_4p4v9ov31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "questions regarding problems faced by data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bafeap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709982657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;had a few questions pertaining to what problems have you encountered persistently ?  &lt;/p&gt;\n\n&lt;p&gt;Do you struggle with ensuring data accuracy across different projects?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How often do you encounter issues with outdated or inconsistent data?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Have data quality problems ever impacted your ability to deliver projects successfully?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bafeap", "is_robot_indexable": true, "report_reasons": null, "author": "Decent_Ice1528", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bafeap/questions_regarding_problems_faced_by_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bafeap/questions_regarding_problems_faced_by_data/", "subreddit_subscribers": 167140, "created_utc": 1709982657.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}