{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m currently a sr. Data analyst, love my job and I\u2019ve come to appreciate the power of analytics in a business setting . When I first went to school I spent time as a data scientist which was equally as enjoyable for different reasons. \n\nWhat I\u2019ve seen in the real world is data science has difficulty in generating business value and can be disconnected from business drivers. While I don\u2019t disagree that work done by data science can be critical for some companies, I\u2019ve seen many companies get more value from analytics and experimentation. \n\nThere has been some discussion that the natural progression in the field is to go from data analyst to data scientist, but why? In companies I\u2019ve worked for DS and DA were paid on the same technical level while usually working more hours( this goes for DE as well), so the move can\u2019t be for the $. \n\nFor those in data science, why did you chose that route vs analytics. For those that transitioned from DA to DS, did you feel like you made the right choice? ", "author_fullname": "t2_vq05x97og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why did you get into data science? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bnqytr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 106, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 106, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711405187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently a sr. Data analyst, love my job and I\u2019ve come to appreciate the power of analytics in a business setting . When I first went to school I spent time as a data scientist which was equally as enjoyable for different reasons. &lt;/p&gt;\n\n&lt;p&gt;What I\u2019ve seen in the real world is data science has difficulty in generating business value and can be disconnected from business drivers. While I don\u2019t disagree that work done by data science can be critical for some companies, I\u2019ve seen many companies get more value from analytics and experimentation. &lt;/p&gt;\n\n&lt;p&gt;There has been some discussion that the natural progression in the field is to go from data analyst to data scientist, but why? In companies I\u2019ve worked for DS and DA were paid on the same technical level while usually working more hours( this goes for DE as well), so the move can\u2019t be for the $. &lt;/p&gt;\n\n&lt;p&gt;For those in data science, why did you chose that route vs analytics. For those that transitioned from DA to DS, did you feel like you made the right choice? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bnqytr", "is_robot_indexable": true, "report_reasons": null, "author": "anonymous_da", "discussion_type": null, "num_comments": 82, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bnqytr/why_did_you_get_into_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bnqytr/why_did_you_get_into_data_science/", "subreddit_subscribers": 1465001, "created_utc": 1711405187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_rpjycw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For the first time, I have seen a job post appreciating having Coursera certificates.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 22, "top_awarded_type": null, "hide_score": false, "name": "t3_1bo5fdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_OFMsR2T8bdcOSNiREKZxu12neQ08nELBBbyzGOwW9I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711452068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dy3lgv2mxnqc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?auto=webp&amp;s=a57fdbf0e9516cd7602199938f04cd833306a248", "width": 1178, "height": 190}, "resolutions": [{"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=493f098b329cfd500f12c94b5e38ed1dfc80fd85", "width": 108, "height": 17}, {"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=19932f5dcbae0eaf6a17e9cb8635e8985d4a6af5", "width": 216, "height": 34}, {"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=256e83248e37f8e1c9e9a6fb5db54c501eecb0e5", "width": 320, "height": 51}, {"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=50e73da43f0369bb495809f13ecbf2ce2e23e9c3", "width": 640, "height": 103}, {"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4ed331e33ef3b3632cbf401863f8932631bad276", "width": 960, "height": 154}, {"url": "https://preview.redd.it/dy3lgv2mxnqc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d6f149a5ce6a382abe15f46c4a6bf717a113c93", "width": 1080, "height": 174}], "variants": {}, "id": "seP4yIwvr9zniAd2C4W7ZjW2qgC2l1DMJZz1CNyzFjE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1bo5fdw", "is_robot_indexable": true, "report_reasons": null, "author": "xandie985", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bo5fdw/for_the_first_time_i_have_seen_a_job_post/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dy3lgv2mxnqc1.png", "subreddit_subscribers": 1465001, "created_utc": 1711452068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "UPDATE: Problem has been resolved and I was able to cancel the subscription and get refunded. Thanks for the help everyone.\n\nIf you're prepping for a DS job interview, I strongly advise you to NOT use DataLemur. The website is fraudulent and does not allow you to cancel a monthly subscription. The website founder does not respond to emails about the issue (I've emailed him 4 times over the last month about the problem). I eventually had to dispute upcoming charges on my credit card because I simply cannot cancel the monthly subscription.\n\nI recommend sticking to Leetcode or Interview Query. Preparing for interviews and searching for jobs is stressful---don't waste your stress disputing credit card charges from websites like DataLemur!", "author_fullname": "t2_ewxudg8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do not use DataLemur for DS interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bo7vo6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711478420.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711459621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;UPDATE: Problem has been resolved and I was able to cancel the subscription and get refunded. Thanks for the help everyone.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re prepping for a DS job interview, I strongly advise you to NOT use DataLemur. The website is fraudulent and does not allow you to cancel a monthly subscription. The website founder does not respond to emails about the issue (I&amp;#39;ve emailed him 4 times over the last month about the problem). I eventually had to dispute upcoming charges on my credit card because I simply cannot cancel the monthly subscription.&lt;/p&gt;\n\n&lt;p&gt;I recommend sticking to Leetcode or Interview Query. Preparing for interviews and searching for jobs is stressful---don&amp;#39;t waste your stress disputing credit card charges from websites like DataLemur!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bo7vo6", "is_robot_indexable": true, "report_reasons": null, "author": "Jan_Michael_Vincent8", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bo7vo6/do_not_use_datalemur_for_ds_interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bo7vo6/do_not_use_datalemur_for_ds_interview_prep/", "subreddit_subscribers": 1465001, "created_utc": 1711459621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Naturally, GDP per capita has a strong correlation with the salary of any profession, including Data Scientists. It is interesting to see, however, which countries pay more than expected based on GDP. The United States not only pays the highest, but it seems to pay way more than the GDP would predict. My interpretation is that this is due to the many successful global companies in the US, which means that a single hour of DS work scales across many more users comparatively to average companies in other countries.\n\nThe basis for this chart are the predictions from the data science salary prediction model, performed only once for a given set of job's features (across all possible combinations of the job's features), to avoid the common mistake of just taking the average salary in the dataset for the analysis.\n\nSource: [Data Scientist Salary](https://jobs-in-data.com/salary/data-scientist-salary)\n\nhttps://preview.redd.it/cwrkfh8scmqc1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=0e5b2387e57a52ea31d2a45e32f2d4e031c118f8", "author_fullname": "t2_h7ibth00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Salary vs GDP per Capita", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cwrkfh8scmqc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=30f7462e85dc822023c354a4dbda8a89c2484e44"}, {"y": 67, "x": 216, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3335dce416e4d4a2cf91ac5d2d5791d9eddb0ee6"}, {"y": 100, "x": 320, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5d52676ef2b970db45ea18b0214b54d89f823a2c"}, {"y": 200, "x": 640, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=414c8fd53770ca24fe40c32af55738fa60daf0ee"}, {"y": 300, "x": 960, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=77152dc29be49134a96d942578c7ec4a4535a7f5"}, {"y": 337, "x": 1080, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9a899101d1baee946460b53934f4a5c27eb53859"}], "s": {"y": 500, "x": 1600, "u": "https://preview.redd.it/cwrkfh8scmqc1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=0e5b2387e57a52ea31d2a45e32f2d4e031c118f8"}, "id": "cwrkfh8scmqc1"}}, "name": "t3_1bo0qx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/S60v497RMluLTUof_nMgCOaCYo88uu51Jdv-cdkkLtg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711433380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Naturally, GDP per capita has a strong correlation with the salary of any profession, including Data Scientists. It is interesting to see, however, which countries pay more than expected based on GDP. The United States not only pays the highest, but it seems to pay way more than the GDP would predict. My interpretation is that this is due to the many successful global companies in the US, which means that a single hour of DS work scales across many more users comparatively to average companies in other countries.&lt;/p&gt;\n\n&lt;p&gt;The basis for this chart are the predictions from the data science salary prediction model, performed only once for a given set of job&amp;#39;s features (across all possible combinations of the job&amp;#39;s features), to avoid the common mistake of just taking the average salary in the dataset for the analysis.&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"https://jobs-in-data.com/salary/data-scientist-salary\"&gt;Data Scientist Salary&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cwrkfh8scmqc1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e5b2387e57a52ea31d2a45e32f2d4e031c118f8\"&gt;https://preview.redd.it/cwrkfh8scmqc1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e5b2387e57a52ea31d2a45e32f2d4e031c118f8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bo0qx0", "is_robot_indexable": true, "report_reasons": null, "author": "pg860", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bo0qx0/data_science_salary_vs_gdp_per_capita/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bo0qx0/data_science_salary_vs_gdp_per_capita/", "subreddit_subscribers": 1465001, "created_utc": 1711433380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pp9vll5o0lqc1.png?width=800&amp;format=png&amp;auto=webp&amp;s=e3639b7a1e01e98e854b152f93e32b7c410ca608\n\nOver the last decade, I've participated in a dozen data science projects in industry. When projects hit production, it's critical to have unit and integration tests to prevent pushing faulty features or models. I've [summarized my learnings in a blog post](https://ploomber.io/blog/ci-for-ds/), here's the summary:\n\n&amp;#x200B;\n\n1. Structure your pipeline in several tasks, each one saving intermediate results to disk\n2. Implement your pipeline in such a way that you can parametrize it\n3. The first parameter should sample raw data to allow quick end-to-end runs for testing\n4. A second parameter should change artifacts location to separate testing and production environments\n5. On every push, the CI service runs unit tests that verify logic inside each task\n6. The pipeline is then executed with a data sample and integration tests verify integrity of intermediate results", "author_fullname": "t2_40t1gisl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Continuous Integration for Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pp9vll5o0lqc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/pp9vll5o0lqc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eaf9c877314bf92bafbac8a979800ff4b48e47f4"}, {"y": 167, "x": 216, "u": "https://preview.redd.it/pp9vll5o0lqc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a0baf121fbb7d16da453b354253066e86012749b"}, {"y": 248, "x": 320, "u": "https://preview.redd.it/pp9vll5o0lqc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f46cc75164abe75cf653e0675db83206bdf24380"}, {"y": 497, "x": 640, "u": "https://preview.redd.it/pp9vll5o0lqc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6c6579b400529858981bd02bf96eeddbebc65065"}], "s": {"y": 622, "x": 800, "u": "https://preview.redd.it/pp9vll5o0lqc1.png?width=800&amp;format=png&amp;auto=webp&amp;s=e3639b7a1e01e98e854b152f93e32b7c410ca608"}, "id": "pp9vll5o0lqc1"}}, "name": "t3_1bnvj8w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XjeGkeNhhrUzXteqLBqGm4VmRlIJcpaLk_kfyvIQwXc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1711416798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pp9vll5o0lqc1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e3639b7a1e01e98e854b152f93e32b7c410ca608\"&gt;https://preview.redd.it/pp9vll5o0lqc1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e3639b7a1e01e98e854b152f93e32b7c410ca608&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Over the last decade, I&amp;#39;ve participated in a dozen data science projects in industry. When projects hit production, it&amp;#39;s critical to have unit and integration tests to prevent pushing faulty features or models. I&amp;#39;ve &lt;a href=\"https://ploomber.io/blog/ci-for-ds/\"&gt;summarized my learnings in a blog post&lt;/a&gt;, here&amp;#39;s the summary:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Structure your pipeline in several tasks, each one saving intermediate results to disk&lt;/li&gt;\n&lt;li&gt;Implement your pipeline in such a way that you can parametrize it&lt;/li&gt;\n&lt;li&gt;The first parameter should sample raw data to allow quick end-to-end runs for testing&lt;/li&gt;\n&lt;li&gt;A second parameter should change artifacts location to separate testing and production environments&lt;/li&gt;\n&lt;li&gt;On every push, the CI service runs unit tests that verify logic inside each task&lt;/li&gt;\n&lt;li&gt;The pipeline is then executed with a data sample and integration tests verify integrity of intermediate results&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?auto=webp&amp;s=86d9c12eafd139c4af99bc12275bbd977488f7fd", "width": 1524, "height": 804}, "resolutions": [{"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4a232ecb60f128e5aae8ed9fb0a8b0d2ae442fc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3dbf66ca364c64e51f9252c923ee65d2b53d749f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=38c6bb95c0e0118725e2ac8fd5236734c6268cbe", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b1fc45d48f0ce33792d5d20945a09fdaf9e3c9c", "width": 640, "height": 337}, {"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=64c25fc211d9aee9eec342d7c093adb0d97ae938", "width": 960, "height": 506}, {"url": "https://external-preview.redd.it/iGQXbjM2EWzve_qQ-Ethg1KwB7VLI1TmB1OKfI787HI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8724e3c16fa00abd02192fd754801770c174dd84", "width": 1080, "height": 569}], "variants": {}, "id": "2PWB643okk9pcA2XB0iqe5cnvYvmIRuzjltIeU2MC1s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1bnvj8w", "is_robot_indexable": true, "report_reasons": null, "author": "databot_", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bnvj8w/continuous_integration_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bnvj8w/continuous_integration_for_data_science/", "subreddit_subscribers": 1465001, "created_utc": 1711416798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title suggests I am looking how to improve my overall code quality by taking from our not so close cousins SWE. Any learning resources would also be greatly appreciated.", "author_fullname": "t2_3kdgnq0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the software engineering best practices that we should know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bo9rre", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711464600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests I am looking how to improve my overall code quality by taking from our not so close cousins SWE. Any learning resources would also be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1bo9rre", "is_robot_indexable": true, "report_reasons": null, "author": "Jbor941197", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bo9rre/what_are_the_software_engineering_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bo9rre/what_are_the_software_engineering_best_practices/", "subreddit_subscribers": 1465001, "created_utc": 1711464600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Because man this is my first role with the data scientist title and I have no one to go to for questions and guidance as the only data science tech resource on my team.\n\nIn fact, after pointing out some issues with my manager with the data and him spending time with me to go through data sources, he knocked points off my performance review for needing help signaling to me that I shouldn\u2019t even go to him for advice. \n\nHonestly wouldn\u2019t go to him for anything anyway he doesn\u2019t know much. \n", "author_fullname": "t2_4xhvqofl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did/do you all have great mentors or peers? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bocmkr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711474931.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711471756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Because man this is my first role with the data scientist title and I have no one to go to for questions and guidance as the only data science tech resource on my team.&lt;/p&gt;\n\n&lt;p&gt;In fact, after pointing out some issues with my manager with the data and him spending time with me to go through data sources, he knocked points off my performance review for needing help signaling to me that I shouldn\u2019t even go to him for advice. &lt;/p&gt;\n\n&lt;p&gt;Honestly wouldn\u2019t go to him for anything anyway he doesn\u2019t know much. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bocmkr", "is_robot_indexable": true, "report_reasons": null, "author": "gengarvibes", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bocmkr/diddo_you_all_have_great_mentors_or_peers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bocmkr/diddo_you_all_have_great_mentors_or_peers/", "subreddit_subscribers": 1465001, "created_utc": 1711471756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am running few XGB , RF models to predict the user spend. I have few features and their occurrence is very small in the sample space(95% of times they are null) but the 5 % times when they are populated the user have high propensity to spend. How can I include this information into the model without doing any sort of imputation?", "author_fullname": "t2_773x6aj9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to include rare events in modeling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bnw2ey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711420277.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711418300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running few XGB , RF models to predict the user spend. I have few features and their occurrence is very small in the sample space(95% of times they are null) but the 5 % times when they are populated the user have high propensity to spend. How can I include this information into the model without doing any sort of imputation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1bnw2ey", "is_robot_indexable": true, "report_reasons": null, "author": "Love_Tech", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bnw2ey/how_to_include_rare_events_in_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bnw2ey/how_to_include_rare_events_in_modeling/", "subreddit_subscribers": 1465001, "created_utc": 1711418300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m working on a project at the moment and would like to hear you guys\u2019 thoughts. \n\nI have data on the number of people who stopped watching a tv show episode broken down by minute for the duration of the episode. \nI have data on the genre of the show along with some topics extracted from the script by minute.\n\nI would like to evaluate whether there is a connection between certain topics, perhaps interacting with genre, that cause an incremental amount of people to \u2018drop off\u2019.\n\nI\u2019m wondering how best to model this data? \n\n1) The drop off rate is fastest in the first 2-3 minutes of every episode, regardless of script, and so I\u2019m thinking I should normalise in some way across the episodes timelines or perhaps use the time in minutes as a feature in the model?\n\n2) I\u2019m also considering modelling the second differential as opposed to the drop off at a particular minute as this might tell a better story in terms of the cause of the drop off. \n\n3) Given (1) and (2) what would be your suggestions in terms of models?\n\nWould a CHAID/Random Forest work in this scenario? Hoping it would be able to capture collections of topics that could be associated with an increased or decreased second differential.\n\nThanks in advance! \u263a\ufe0f", "author_fullname": "t2_us2yme5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How best to model drop-off rates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bo8fqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711461154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a project at the moment and would like to hear you guys\u2019 thoughts. &lt;/p&gt;\n\n&lt;p&gt;I have data on the number of people who stopped watching a tv show episode broken down by minute for the duration of the episode. \nI have data on the genre of the show along with some topics extracted from the script by minute.&lt;/p&gt;\n\n&lt;p&gt;I would like to evaluate whether there is a connection between certain topics, perhaps interacting with genre, that cause an incremental amount of people to \u2018drop off\u2019.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering how best to model this data? &lt;/p&gt;\n\n&lt;p&gt;1) The drop off rate is fastest in the first 2-3 minutes of every episode, regardless of script, and so I\u2019m thinking I should normalise in some way across the episodes timelines or perhaps use the time in minutes as a feature in the model?&lt;/p&gt;\n\n&lt;p&gt;2) I\u2019m also considering modelling the second differential as opposed to the drop off at a particular minute as this might tell a better story in terms of the cause of the drop off. &lt;/p&gt;\n\n&lt;p&gt;3) Given (1) and (2) what would be your suggestions in terms of models?&lt;/p&gt;\n\n&lt;p&gt;Would a CHAID/Random Forest work in this scenario? Hoping it would be able to capture collections of topics that could be associated with an increased or decreased second differential.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! \u263a\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1bo8fqe", "is_robot_indexable": true, "report_reasons": null, "author": "whateverthefuckidc", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1bo8fqe/how_best_to_model_dropoff_rates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1bo8fqe/how_best_to_model_dropoff_rates/", "subreddit_subscribers": 1465001, "created_utc": 1711461154.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}