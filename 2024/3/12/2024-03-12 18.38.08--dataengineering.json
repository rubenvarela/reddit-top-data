{"kind": "Listing", "data": {"after": "t3_1bctnhy", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nOne of my colleagues mentioned she knew a data visualization tool that can edit data. By that, she didn\u2019t mean editing calculated field but fields from the source, impacting the source.\nLike you would plug a DB to Tableau and could modify data in Tableau and the data in the DB data would get updated.\nA two way street between the source and the viz.\n\nSounds crazy to me but we live in a crazy world. ", "author_fullname": "t2_8imxqj2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever heard about a data visualization tool that can edit data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcsjmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710233507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;One of my colleagues mentioned she knew a data visualization tool that can edit data. By that, she didn\u2019t mean editing calculated field but fields from the source, impacting the source.\nLike you would plug a DB to Tableau and could modify data in Tableau and the data in the DB data would get updated.\nA two way street between the source and the viz.&lt;/p&gt;\n\n&lt;p&gt;Sounds crazy to me but we live in a crazy world. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcsjmf", "is_robot_indexable": true, "report_reasons": null, "author": "vitodeltoro", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcsjmf/have_you_ever_heard_about_a_data_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcsjmf/have_you_ever_heard_about_a_data_visualization/", "subreddit_subscribers": 167975, "created_utc": 1710233507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Founder of Multiwoven ([https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)) here. \n\nMy co-founders and I have a background in product and engineering for Asia population-scale customer data infrastructure and applications - across Affle (3 Bn+ connected devices for consumer\u00a0intelligence-based marketing), Truecaller (\\~400 Mn. MAU) and Razorpay (India's largest payments platform).\n\nWe built Multiwoven as an open source reverse ETL tool for data activation. After our recent repo launch, Multiwoven started being used by data teams to eliminate the complexity and tediousness of building and maintaining data pipelines to third-party biz/marketing/sales tools.\u00a0\n\nFrom our early users and discovery conversations, we quickly started seeing users who have a data warehouse use us like a CDP on top of their warehouse. Many of them were customers and prospects of Salesforce (CRM and/or marketing cloud).\u00a0\n\nThe simple solution that worked for them -\u00a0\n\n1. Easily works with all their tools (not just Salesforce's ecosystem). We are adding roughly two new Connectors every week, and it's also easy to build or customize for someone's own needs (without going through long and expensive professional services)\n\n2. Not being compelled to invest upwards of half a million dollars a year on Salesforce CDP. The Salesforce CDP Starter Pack is at $110K, and doesn't include Segmentation, Audiences and Ad integrations (imagine a CDP without these!)\n\n3. Being able to easily self-host the software (that essentially has access to all their warehouse data) and not worry about jumping through Compliance/InfoSec's\u00a0hoops.\u00a0\n\nGartner recently naming Salesforce CDP a leader in their first Magic Quadrant for CDPs is certainly\u00a0surprising. We're not sure that users feel the same way. We recently released a connector to Salesforce CRM, and Salesforce Marketing Cloud is on the way. We are continuing to furiously build and working to meet users' needs.\n\nAs a young project, we'd love your feedback and support (pls star us on GitHub! [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven))", "author_fullname": "t2_1g3ospki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "we built an open source Salesforce CDP alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bchyko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710199640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Founder of Multiwoven (&lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;) here. &lt;/p&gt;\n\n&lt;p&gt;My co-founders and I have a background in product and engineering for Asia population-scale customer data infrastructure and applications - across Affle (3 Bn+ connected devices for consumer\u00a0intelligence-based marketing), Truecaller (~400 Mn. MAU) and Razorpay (India&amp;#39;s largest payments platform).&lt;/p&gt;\n\n&lt;p&gt;We built Multiwoven as an open source reverse ETL tool for data activation. After our recent repo launch, Multiwoven started being used by data teams to eliminate the complexity and tediousness of building and maintaining data pipelines to third-party biz/marketing/sales tools.\u00a0&lt;/p&gt;\n\n&lt;p&gt;From our early users and discovery conversations, we quickly started seeing users who have a data warehouse use us like a CDP on top of their warehouse. Many of them were customers and prospects of Salesforce (CRM and/or marketing cloud).\u00a0&lt;/p&gt;\n\n&lt;p&gt;The simple solution that worked for them -\u00a0&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Easily works with all their tools (not just Salesforce&amp;#39;s ecosystem). We are adding roughly two new Connectors every week, and it&amp;#39;s also easy to build or customize for someone&amp;#39;s own needs (without going through long and expensive professional services)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Not being compelled to invest upwards of half a million dollars a year on Salesforce CDP. The Salesforce CDP Starter Pack is at $110K, and doesn&amp;#39;t include Segmentation, Audiences and Ad integrations (imagine a CDP without these!)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Being able to easily self-host the software (that essentially has access to all their warehouse data) and not worry about jumping through Compliance/InfoSec&amp;#39;s\u00a0hoops.\u00a0&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Gartner recently naming Salesforce CDP a leader in their first Magic Quadrant for CDPs is certainly\u00a0surprising. We&amp;#39;re not sure that users feel the same way. We recently released a connector to Salesforce CRM, and Salesforce Marketing Cloud is on the way. We are continuing to furiously build and working to meet users&amp;#39; needs.&lt;/p&gt;\n\n&lt;p&gt;As a young project, we&amp;#39;d love your feedback and support (pls star us on GitHub! &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?auto=webp&amp;s=0bc0e93038ef50951c90227649f7f6ab254a7cf4", "width": 2560, "height": 1204}, "resolutions": [{"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17a45a447d842e52652926f6dc817d7170a88986", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e12cc0a1c0d9fd4fd747ed329f19cd30a8124b3b", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=69066e72c75f3b4020a551ac50062213dbdb397c", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a02272300d0676184dcf058494ffd170c121368", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a2b31da90137f24f3433708d44936c2fb49ece3", "width": 960, "height": 451}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0d7ab5f6e495f29e4f13cc0b5671fcfd8b115e51", "width": 1080, "height": 507}], "variants": {}, "id": "Gn1oZnAX_pLkKE4iHRaNdie9sLvYRt8PUbXOPUT0MUA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bchyko", "is_robot_indexable": true, "report_reasons": null, "author": "wishingchairs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bchyko/we_built_an_open_source_salesforce_cdp_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bchyko/we_built_an_open_source_salesforce_cdp_alternative/", "subreddit_subscribers": 167975, "created_utc": 1710199640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since Data Engineers are rare nowadays - relative to more common SE roles. I wonder if there exists a role of a Software QA Engineer for a DE team. If so, what do they do in your company? How do they define the needed test suites for a specific requirement?\n\n", "author_fullname": "t2_85ty6e1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software QA in a Data Engineering Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcv2qo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710243315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since Data Engineers are rare nowadays - relative to more common SE roles. I wonder if there exists a role of a Software QA Engineer for a DE team. If so, what do they do in your company? How do they define the needed test suites for a specific requirement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bcv2qo", "is_robot_indexable": true, "report_reasons": null, "author": "BestBlackberry1314", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcv2qo/software_qa_in_a_data_engineering_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcv2qo/software_qa_in_a_data_engineering_team/", "subreddit_subscribers": 167975, "created_utc": 1710243315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have a data engineer intrvw coming up next week and the recruiter told me that it one hour will be technical and the next one hour will be behavioural questions. What kind of behavioural questions i should be expecting? I have a few years experience as a backend developer working in sql server and 2 months of internship experience as a data analyst. This is a career change role for me. Thanks in advance. ", "author_fullname": "t2_a260u37s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the common types of behavioural questions you should expect in an entry level data engineer role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcew7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710192385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a data engineer intrvw coming up next week and the recruiter told me that it one hour will be technical and the next one hour will be behavioural questions. What kind of behavioural questions i should be expecting? I have a few years experience as a backend developer working in sql server and 2 months of internship experience as a data analyst. This is a career change role for me. Thanks in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bcew7i", "is_robot_indexable": true, "report_reasons": null, "author": "Outside_Aide_1958", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcew7i/what_are_the_common_types_of_behavioural/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcew7i/what_are_the_common_types_of_behavioural/", "subreddit_subscribers": 167975, "created_utc": 1710192385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say I\u2019m developing a web app that will get shown on user devices. So the system would look something like this:\n\nUser Device &lt;-&gt; Streamlit Frontend -&gt; FastAPI Logic -&gt; SQLAlchemy Data Access &lt;-&gt; Postgres Data Store\n\nWould this result in:\n\n* Application Layer: Streamlit\n* Business Logic Layer: FastAPI\n* Data Access Layer: SQLAlchemy\n* Data Layer: Postgres\n\nOr am I misunderstanding anything?\n", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making sure I understand the 3 tier architecture\u2026 Is this it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcyqug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710254137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I\u2019m developing a web app that will get shown on user devices. So the system would look something like this:&lt;/p&gt;\n\n&lt;p&gt;User Device &amp;lt;-&amp;gt; Streamlit Frontend -&amp;gt; FastAPI Logic -&amp;gt; SQLAlchemy Data Access &amp;lt;-&amp;gt; Postgres Data Store&lt;/p&gt;\n\n&lt;p&gt;Would this result in:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Application Layer: Streamlit&lt;/li&gt;\n&lt;li&gt;Business Logic Layer: FastAPI&lt;/li&gt;\n&lt;li&gt;Data Access Layer: SQLAlchemy&lt;/li&gt;\n&lt;li&gt;Data Layer: Postgres&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or am I misunderstanding anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcyqug", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcyqug/making_sure_i_understand_the_3_tier_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcyqug/making_sure_i_understand_the_3_tier_architecture/", "subreddit_subscribers": 167975, "created_utc": 1710254137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a data engineer writing massive ETL queries to extract huge amount of data from systems that are so overly complex They make my head spin. One of them for example is Salesforce, another service now. A lot of these queries have been written or put together from past employees or developers, and we are handed them and told to own them going forward. So then we have to look through a 3000 line script and ensure it runs smoothly. But rarely, we will discover incorrect data. For example, just this week, we discovered that an ETL query has been pulling the incorrect data for about 2 years now...\n\nWhat do you even do in this situation? Like \"Sorry, the data was wrong for 2 years but we fixed it!\" Or do you just like say you fixed a data error and provide no specifics? ", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You ever discovered that data has been wrong for a very long time? What do you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd35dy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710264802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data engineer writing massive ETL queries to extract huge amount of data from systems that are so overly complex They make my head spin. One of them for example is Salesforce, another service now. A lot of these queries have been written or put together from past employees or developers, and we are handed them and told to own them going forward. So then we have to look through a 3000 line script and ensure it runs smoothly. But rarely, we will discover incorrect data. For example, just this week, we discovered that an ETL query has been pulling the incorrect data for about 2 years now...&lt;/p&gt;\n\n&lt;p&gt;What do you even do in this situation? Like &amp;quot;Sorry, the data was wrong for 2 years but we fixed it!&amp;quot; Or do you just like say you fixed a data error and provide no specifics? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd35dy", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd35dy/you_ever_discovered_that_data_has_been_wrong_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd35dy/you_ever_discovered_that_data_has_been_wrong_for/", "subreddit_subscribers": 167975, "created_utc": 1710264802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I've been into data engineering ever since I graduate from my bachelors in CS in June 2023. So I've gained skills in SQL and experience with Azure. But since I graduated from CS, I was wondering... what would make me stand out from other data engineers having studied CS? Like I did projects related to web development and would say have a decent coding skills. So what would make me a stronger candidate than others? Having a strong knowledge in frontend dev. or backend dev?", "author_fullname": "t2_chpvvtuts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strong Data Engineering Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1geu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710260835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;ve been into data engineering ever since I graduate from my bachelors in CS in June 2023. So I&amp;#39;ve gained skills in SQL and experience with Azure. But since I graduated from CS, I was wondering... what would make me stand out from other data engineers having studied CS? Like I did projects related to web development and would say have a decent coding skills. So what would make me a stronger candidate than others? Having a strong knowledge in frontend dev. or backend dev?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bd1geu", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Pen_1356", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1geu/strong_data_engineering_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd1geu/strong_data_engineering_profile/", "subreddit_subscribers": 167975, "created_utc": 1710260835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gmelb8os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse to Lakehouse Evolution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcihcy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1710200920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "iomete.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://iomete.com/resources/blog/from-data-warehouses-to-data-lakehouses", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcihcy", "is_robot_indexable": true, "report_reasons": null, "author": "Single_Brother_1791", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcihcy/data_warehouse_to_lakehouse_evolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://iomete.com/resources/blog/from-data-warehouses-to-data-lakehouses", "subreddit_subscribers": 167975, "created_utc": 1710200920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI've got a master's degree in data and done several internships in data engineering. I'd like to start my career in the same field but I haven't had the opportunity to learn much about certain technologies. Are there any good exercises or projects on Kaggle to learn how to use certain combined technologies like Python, SQL,  ELK, Kafka, Airflow, Spark, terraform, with docker, Bash for example. If there aren't any Kaggle projects or that sort of thing, would there be appropriate datasets for the data sources? Maybe projects using GNS3 for the configuration part or some kind of github repository as a guided project? I don't know. Above all, I'm looking for a project that will enable me to learn or discover all these technologies. I know that a lot of these technologies can work together in a company, so I suppose it's not impossible to get a lot of them involved in this project.\n\nAs I'm considered to have little experience, I'd like to work on all these skills in my own time to see how everything fits together and to know what I'm talking about. I'm prepared to devote a lot of time to it so that I can be deployed more quickly in companies. If you can help me or even give me advice on the technology, for example, that would be really nice. Any feedback is also very welcome.", "author_fullname": "t2_q95335vn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn data engineering in a non-professional context?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1bsf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710260528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a master&amp;#39;s degree in data and done several internships in data engineering. I&amp;#39;d like to start my career in the same field but I haven&amp;#39;t had the opportunity to learn much about certain technologies. Are there any good exercises or projects on Kaggle to learn how to use certain combined technologies like Python, SQL,  ELK, Kafka, Airflow, Spark, terraform, with docker, Bash for example. If there aren&amp;#39;t any Kaggle projects or that sort of thing, would there be appropriate datasets for the data sources? Maybe projects using GNS3 for the configuration part or some kind of github repository as a guided project? I don&amp;#39;t know. Above all, I&amp;#39;m looking for a project that will enable me to learn or discover all these technologies. I know that a lot of these technologies can work together in a company, so I suppose it&amp;#39;s not impossible to get a lot of them involved in this project.&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;m considered to have little experience, I&amp;#39;d like to work on all these skills in my own time to see how everything fits together and to know what I&amp;#39;m talking about. I&amp;#39;m prepared to devote a lot of time to it so that I can be deployed more quickly in companies. If you can help me or even give me advice on the technology, for example, that would be really nice. Any feedback is also very welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd1bsf", "is_robot_indexable": true, "report_reasons": null, "author": "Aquilae2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1bsf/how_to_learn_data_engineering_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd1bsf/how_to_learn_data_engineering_in_a/", "subreddit_subscribers": 167975, "created_utc": 1710260528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12e8nx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expedock replicates data from Postgres to Snowflake with &lt;1 min latency and 5x cost savings with PeerDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcch7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5NZ7qIq9blMa9skGD-J8yvYEVMH2VSmbHAgAdoJwkms.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710186776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "peerdb.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.peerdb.io/customers/expedock-customer-story", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?auto=webp&amp;s=8806dea13c3b6fedc9156ec74afc5cb2ede87a35", "width": 1600, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c0a13e4a1a8f139569811457f17e2e097504b20", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2db139849ca3d9dc4e9cdbc4c1b1163de238b70d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5813ab59ac5d588ad375b3bf9c412e43964ad6f0", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7800d7c2aac9cc434d1db6295a950cb509fc5251", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49d824cb8d79efef93c8c042b3672d49d1990c43", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3babcac3c57dfc31923ed0e634f2987a28ff515", "width": 1080, "height": 567}], "variants": {}, "id": "T7-sdcyVeQPqKIYovMULxE17ttt1B3SN4kwiQQs4zCU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcch7b", "is_robot_indexable": true, "report_reasons": null, "author": "assaxor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcch7b/expedock_replicates_data_from_postgres_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.peerdb.io/customers/expedock-customer-story", "subreddit_subscribers": 167975, "created_utc": 1710186776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dagster.io/blog/dagster-openai](https://dagster.io/blog/dagster-openai)\n\nThe new dagster-openai integration lets you tap into the power of LLMs in a cost-efficient way.\n\nhttps://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0", "author_fullname": "t2_c45yywox7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster's Open AI integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "media_metadata": {"ovkzr6rjoxnc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b2b5fa07a548a4241016e5574ec40dd1be9b42fc"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f756c46d79281ac646f745a834f3a2c150d8076"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7db258eb2a117848a241620ec0f31178f8c2ddc3"}, {"y": 336, "x": 640, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5640258c75bab8e6d7e14c3e1199cfefcfa8248f"}, {"y": 504, "x": 960, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09be2968a5be5d97ee06f679bacc7dc22590866d"}, {"y": 567, "x": 1080, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7bf29066b69a4a3ddd9ae43e82b0d4e36b4d3247"}], "s": {"y": 630, "x": 1200, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0"}, "id": "ovkzr6rjoxnc1"}}, "name": "t3_1bd25o2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CwcvahbzbTHlIv2YnRP4yV4EnweUcOGhl7TvGAVfqG0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710262472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dagster.io/blog/dagster-openai\"&gt;https://dagster.io/blog/dagster-openai&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The new dagster-openai integration lets you tap into the power of LLMs in a cost-efficient way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0\"&gt;https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bd25o2", "is_robot_indexable": true, "report_reasons": null, "author": "dagster-io", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd25o2/dagsters_open_ai_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd25o2/dagsters_open_ai_integration/", "subreddit_subscribers": 167975, "created_utc": 1710262472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have data assets on multiple clouds (sql ds in aws, databricks and adls gen2 in azure), and I want to build data lineages on top of them, is Apache Atlas good tool of choice. \nIf yes please share some resources, that might be helpful. Thanks in advance\ud83d\ude4c\n\nPs. I don\u2019t want to use ms purview ", "author_fullname": "t2_i9p6l5fsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Atlas Review ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcvbdr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710244117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have data assets on multiple clouds (sql ds in aws, databricks and adls gen2 in azure), and I want to build data lineages on top of them, is Apache Atlas good tool of choice. \nIf yes please share some resources, that might be helpful. Thanks in advance\ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;Ps. I don\u2019t want to use ms purview &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcvbdr", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Job9989", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcvbdr/apache_atlas_review/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcvbdr/apache_atlas_review/", "subreddit_subscribers": 167975, "created_utc": 1710244117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a project wherein we need to fetch data from ALDS Gen 2 to Excel via API.\n\nMy question, is it faster to read 5 out of 5 columns from the source compared to reading 5 columns from a total of 100 columns? \n\nI'm thinking wether to create a separate data model for the application or the silver layer (which contains more columns) would suffice.\n\nThank you in advance.", "author_fullname": "t2_ap5f9vbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API get data which one is faster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcnb0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710214140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a project wherein we need to fetch data from ALDS Gen 2 to Excel via API.&lt;/p&gt;\n\n&lt;p&gt;My question, is it faster to read 5 out of 5 columns from the source compared to reading 5 columns from a total of 100 columns? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking wether to create a separate data model for the application or the silver layer (which contains more columns) would suffice.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bcnb0v", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Gur9574", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcnb0v/api_get_data_which_one_is_faster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcnb0v/api_get_data_which_one_is_faster/", "subreddit_subscribers": 167975, "created_utc": 1710214140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a client who currently categorizes data in a spreadsheet. When new data appears, they need to assign a category.\n\nAs we move them to a warehouse, I'd love to give them a way to notice data that needs to be assigned a category + an easy way to assign. \n\nThey are in the Microsoft ecosystem.\n\nSeems like this should be a common need, what the standard operating procedure here?", "author_fullname": "t2_vfx4v6x3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SOP for enabling end users to enrich data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bclc8c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710208501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a client who currently categorizes data in a spreadsheet. When new data appears, they need to assign a category.&lt;/p&gt;\n\n&lt;p&gt;As we move them to a warehouse, I&amp;#39;d love to give them a way to notice data that needs to be assigned a category + an easy way to assign. &lt;/p&gt;\n\n&lt;p&gt;They are in the Microsoft ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Seems like this should be a common need, what the standard operating procedure here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bclc8c", "is_robot_indexable": true, "report_reasons": null, "author": "KnightoftheDadBod", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bclc8c/sop_for_enabling_end_users_to_enrich_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bclc8c/sop_for_enabling_end_users_to_enrich_data/", "subreddit_subscribers": 167975, "created_utc": 1710208501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need help. I have been working on Abinito . Recently an opportunity came for me to work on azure data bricks. we will be moving some of the on prem jobs . For this purpose i have done certification in Azure and databricks as well.  Have no experience on Python. Does anyone know of any online course where i can get chance to create 1 or 2 projects where data ingestion using ADF and transformations in Databricks using scala or pyspark. ", "author_fullname": "t2_t0zkmfpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data bricks  live project ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcijs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710201085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help. I have been working on Abinito . Recently an opportunity came for me to work on azure data bricks. we will be moving some of the on prem jobs . For this purpose i have done certification in Azure and databricks as well.  Have no experience on Python. Does anyone know of any online course where i can get chance to create 1 or 2 projects where data ingestion using ADF and transformations in Databricks using scala or pyspark. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcijs0", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible_Mud5318", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcijs0/azure_data_bricks_live_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcijs0/azure_data_bricks_live_project/", "subreddit_subscribers": 167975, "created_utc": 1710201085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen some pretty crazy SQL queries during my time working on data platforms. I've recently been dealing with SQL queries that consists of hundreds of thousands of union statements. \n\nI've also seen the abuse of dbt's ephemeral models which result in megabytes of massive SQL statements that are impossible to debug.\n\nRecently, I've had to create automated functions to translate spark explode -&gt; bigquery, it produces some pretty ugly code.\n\n```SELECT POSEXPLODE(ARRAY(2, 3)), EXPLODE(ARRAY(4, 5, 6)) FROM tbl```\n\nSELECT\n\n  IF(_u.pos = _u_2.pos_2, _u_2.col) AS col,\n\n  IF(_u.pos = _u_2.pos_2, _u_2.pos_2) AS pos_2,\n\n  IF(_u.pos = _u_3.pos_3, _u_3.col_2) AS col_2\n\nFROM tbl\n\nCROSS JOIN UNNEST(SEQUENCE(1, GREATEST(CARDINALITY(ARRAY[2, 3]), CARDINALITY(ARRAY[4, 5, 6])))) AS _u(pos)\n\nCROSS JOIN UNNEST(ARRAY[2, 3]) WITH ORDINALITY AS _u_2(col, pos_2)\n\nCROSS JOIN UNNEST(ARRAY[4, 5, 6]) WITH ORDINALITY AS _u_3(col_2, pos_3)\n\nWHERE\n\n  (\n\n    _u.pos = _u_2.pos_2\n\n    OR (\n\n      _u.pos &gt; CARDINALITY(ARRAY[2, 3]) AND _u_2.pos_2 = CARDINALITY(ARRAY[2, 3])\n\n    )\n\n  )\n\n  AND (\n\n    _u.pos = _u_3.pos_3\n\n    OR (\n\n      _u.pos &gt; CARDINALITY(ARRAY[4, 5, 6]) AND _u_3.pos_3 = CARDINALITY(ARRAY[4, 5, 6])\n\n    )\n\n  )\n\n\nWhat are some of the worst SQL queries you've encountered?", "author_fullname": "t2_56xhg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gnarliest SQL queries you've ever seen?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd32bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710264607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen some pretty crazy SQL queries during my time working on data platforms. I&amp;#39;ve recently been dealing with SQL queries that consists of hundreds of thousands of union statements. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also seen the abuse of dbt&amp;#39;s ephemeral models which result in megabytes of massive SQL statements that are impossible to debug.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve had to create automated functions to translate spark explode -&amp;gt; bigquery, it produces some pretty ugly code.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT POSEXPLODE(ARRAY(2, 3)), EXPLODE(ARRAY(4, 5, 6)) FROM tbl&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;SELECT&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_2.pos_2, _u_2.col) AS col,&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_2.pos_2, _u_2.pos_2) AS pos_2,&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_3.pos_3, _u_3.col_2) AS col_2&lt;/p&gt;\n\n&lt;p&gt;FROM tbl&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(SEQUENCE(1, GREATEST(CARDINALITY(ARRAY[2, 3]), CARDINALITY(ARRAY[4, 5, 6])))) AS _u(pos)&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(ARRAY[2, 3]) WITH ORDINALITY AS _u_2(col, pos_2)&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(ARRAY[4, 5, 6]) WITH ORDINALITY AS _u_3(col_2, pos_3)&lt;/p&gt;\n\n&lt;p&gt;WHERE&lt;/p&gt;\n\n&lt;p&gt;(&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;_u.pos = _u_2.pos_2\n\nOR (\n\n  _u.pos &amp;gt; CARDINALITY(ARRAY[2, 3]) AND _u_2.pos_2 = CARDINALITY(ARRAY[2, 3])\n\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;AND (&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;_u.pos = _u_3.pos_3\n\nOR (\n\n  _u.pos &amp;gt; CARDINALITY(ARRAY[4, 5, 6]) AND _u_3.pos_3 = CARDINALITY(ARRAY[4, 5, 6])\n\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;What are some of the worst SQL queries you&amp;#39;ve encountered?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd32bx", "is_robot_indexable": true, "report_reasons": null, "author": "captaintobs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd32bx/gnarliest_sql_queries_youve_ever_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd32bx/gnarliest_sql_queries_youve_ever_seen/", "subreddit_subscribers": 167975, "created_utc": 1710264607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just want to learn more about how to monitor pipelines in a more efficient way and what tools I can use to set alerts.\n\n", "author_fullname": "t2_61uvorko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any resources for monitoring and alerting? What tools do you use? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd2389", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710262318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just want to learn more about how to monitor pipelines in a more efficient way and what tools I can use to set alerts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd2389", "is_robot_indexable": true, "report_reasons": null, "author": "jadedsprint", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd2389/any_resources_for_monitoring_and_alerting_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd2389/any_resources_for_monitoring_and_alerting_what/", "subreddit_subscribers": 167975, "created_utc": 1710262318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, could the community kindly advise on how to address data type inconsistencies after merging a dbt model? Here's a little background:  following the creation of a staging model that explicitly casts each field, I ensure that \"dbt build\" completes successfully and subsequently execute \"dbt sql\" to validate the records. The dbt extension in VSCode defaults to 500 records for this process. If this subset of data looks accurate, a pull request (PR) is created. However, we are currently facing an issue with records that violate the defined data types, aside from the 500 records displayed. This becomes apparent only after executing a \"select \\* from\" query on the table. This approach seems a bit heavy-handed, and I'm confident that there is a more programmatic way to handle this. ", "author_fullname": "t2_4igjulzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validating data types before merging a dbt model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bce00m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710190293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, could the community kindly advise on how to address data type inconsistencies after merging a dbt model? Here&amp;#39;s a little background:  following the creation of a staging model that explicitly casts each field, I ensure that &amp;quot;dbt build&amp;quot; completes successfully and subsequently execute &amp;quot;dbt sql&amp;quot; to validate the records. The dbt extension in VSCode defaults to 500 records for this process. If this subset of data looks accurate, a pull request (PR) is created. However, we are currently facing an issue with records that violate the defined data types, aside from the 500 records displayed. This becomes apparent only after executing a &amp;quot;select * from&amp;quot; query on the table. This approach seems a bit heavy-handed, and I&amp;#39;m confident that there is a more programmatic way to handle this. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bce00m", "is_robot_indexable": true, "report_reasons": null, "author": "South-Ambassador2326", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bce00m/validating_data_types_before_merging_a_dbt_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bce00m/validating_data_types_before_merging_a_dbt_model/", "subreddit_subscribers": 167975, "created_utc": 1710190293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the DE situation in Montreal at the moment, or sentiment for future? I know they\u2019re pretty strict on what an engineer means. How do DE positions advertise to circumvent this? Any experience would be appreciated ", "author_fullname": "t2_abcjorif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job situation in QC, Canada", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcbj0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710184568.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the DE situation in Montreal at the moment, or sentiment for future? I know they\u2019re pretty strict on what an engineer means. How do DE positions advertise to circumvent this? Any experience would be appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bcbj0k", "is_robot_indexable": true, "report_reasons": null, "author": "FreeTrout", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcbj0k/job_situation_in_qc_canada/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcbj0k/job_situation_in_qc_canada/", "subreddit_subscribers": 167975, "created_utc": 1710184568.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Congnition labs just announced Devin, the first AI software engineer. It has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork. Please see to the tweet to know more.\n\nMy question: Is this agent anywhere near taking your DE role? If no, why exactly? Considering the fact that Devin will be updated and it would be more efficient and accurate in near future.\n\nLet me know what you all think!", "author_fullname": "t2_8i81bbqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Congnition: Devin!! Is this AI anywhere near taking your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd3986", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Today we&amp;#39;re excited to introduce Devin, the first AI software engineer.&lt;br&gt;&lt;br&gt;Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.&lt;br&gt;&lt;br&gt;Devin is\u2026 &lt;a href=\"https://t.co/ladBicxEat\"&gt;pic.twitter.com/ladBicxEat&lt;/a&gt;&lt;/p&gt;&amp;mdash; Cognition (@cognition_labs) &lt;a href=\"https://twitter.com/cognition_labs/status/1767548763134964000?ref_src=twsrc%5Etfw\"&gt;March 12, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/cognition_labs/status/1767548763134964000", "author_name": "Cognition", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Today we&amp;#39;re excited to introduce Devin, the first AI software engineer.&lt;br&gt;&lt;br&gt;Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.&lt;br&gt;&lt;br&gt;Devin is\u2026 &lt;a href=\"https://t.co/ladBicxEat\"&gt;pic.twitter.com/ladBicxEat&lt;/a&gt;&lt;/p&gt;&amp;mdash; Cognition (@cognition_labs) &lt;a href=\"https://twitter.com/cognition_labs/status/1767548763134964000?ref_src=twsrc%5Etfw\"&gt;March 12, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "author_url": "https://twitter.com/cognition_labs", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Today we&amp;#39;re excited to introduce Devin, the first AI software engineer.&lt;br&gt;&lt;br&gt;Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.&lt;br&gt;&lt;br&gt;Devin is\u2026 &lt;a href=\"https://t.co/ladBicxEat\"&gt;pic.twitter.com/ladBicxEat&lt;/a&gt;&lt;/p&gt;&amp;mdash; Cognition (@cognition_labs) &lt;a href=\"https://twitter.com/cognition_labs/status/1767548763134964000?ref_src=twsrc%5Etfw\"&gt;March 12, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1bd3986", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eF3VhkmJe8Sw2_5nf5F5G1DRA2Z2d15R8mbvVgM4koE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710265053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Congnition labs just announced Devin, the first AI software engineer. It has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork. Please see to the tweet to know more.&lt;/p&gt;\n\n&lt;p&gt;My question: Is this agent anywhere near taking your DE role? If no, why exactly? Considering the fact that Devin will be updated and it would be more efficient and accurate in near future.&lt;/p&gt;\n\n&lt;p&gt;Let me know what you all think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/cognition_labs/status/1767548763134964000?t=rVUPBFpl6KtI_GLaoR7fVg&amp;s=19", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2aChCdrQIBVvlgkgEkpfRH--E9hBYt1sUS32UFsdyUo.jpg?auto=webp&amp;s=193d1c414d0f664d4c73729584036919599ba21c", "width": 140, "height": 78}, "resolutions": [{"url": "https://external-preview.redd.it/2aChCdrQIBVvlgkgEkpfRH--E9hBYt1sUS32UFsdyUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac7322fa4cf921e9eab9e907b0fdd2246cf75543", "width": 108, "height": 60}], "variants": {}, "id": "K06ekQRSkJaUC4sVkILuq1ndA3QpWEKyLDx20GzD7Wo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd3986", "is_robot_indexable": true, "report_reasons": null, "author": "trafalgar28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd3986/congnition_devin_is_this_ai_anywhere_near_taking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/cognition_labs/status/1767548763134964000?t=rVUPBFpl6KtI_GLaoR7fVg&amp;s=19", "subreddit_subscribers": 167975, "created_utc": 1710265053.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/cognition_labs/status/1767548763134964000", "author_name": "Cognition", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Today we&amp;#39;re excited to introduce Devin, the first AI software engineer.&lt;br&gt;&lt;br&gt;Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.&lt;br&gt;&lt;br&gt;Devin is\u2026 &lt;a href=\"https://t.co/ladBicxEat\"&gt;pic.twitter.com/ladBicxEat&lt;/a&gt;&lt;/p&gt;&amp;mdash; Cognition (@cognition_labs) &lt;a href=\"https://twitter.com/cognition_labs/status/1767548763134964000?ref_src=twsrc%5Etfw\"&gt;March 12, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "author_url": "https://twitter.com/cognition_labs", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got task to analyse stored procedure in adf.the tables were not making in databricks..can someone help", "author_fullname": "t2_93q1fbla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd2yca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710264342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got task to analyse stored procedure in adf.the tables were not making in databricks..can someone help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd2yca", "is_robot_indexable": true, "report_reasons": null, "author": "FriendEarly654", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd2yca/help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd2yca/help/", "subreddit_subscribers": 167975, "created_utc": 1710264342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DLT CDC\n\nHi all,\n\nI have been going around investigating this but so far no luck. I have to ingest a table from on prem sql server and then proceed with databricks DLT cdc.\n\nI am trying to understand how this works. So do I extract data from CDC table using ADF to landing zone and then ingest those files with DLT or I directly connect to cdc table through notebook. \n\nAlso, do i have to create first external table (I need this) with inital load data and then apply cdc? I know we need to create streaming table but I am not sure how inital load data fall into all of this. Also source table currently does not have primary key and it is a huge table. \n\nHow does DLT cdc work? \n\nThanks! \n", "author_fullname": "t2_4c7udteq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DLT CDC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd2ic4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710263288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DLT CDC&lt;/p&gt;\n\n&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have been going around investigating this but so far no luck. I have to ingest a table from on prem sql server and then proceed with databricks DLT cdc.&lt;/p&gt;\n\n&lt;p&gt;I am trying to understand how this works. So do I extract data from CDC table using ADF to landing zone and then ingest those files with DLT or I directly connect to cdc table through notebook. &lt;/p&gt;\n\n&lt;p&gt;Also, do i have to create first external table (I need this) with inital load data and then apply cdc? I know we need to create streaming table but I am not sure how inital load data fall into all of this. Also source table currently does not have primary key and it is a huge table. &lt;/p&gt;\n\n&lt;p&gt;How does DLT cdc work? &lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd2ic4", "is_robot_indexable": true, "report_reasons": null, "author": "MahoYami", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd2ic4/dlt_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd2ic4/dlt_cdc/", "subreddit_subscribers": 167975, "created_utc": 1710263288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2cbhndmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why we rebuilt our streaming SQL engine on Arrow and DataFusion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1ldx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SP7NuGNJCrGyOCFEDJ-ShUTComq-Wx19oDx4gknWiYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710261151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arroyo.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arroyo.dev/blog/why-arrow-and-datafusion", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?auto=webp&amp;s=e7959007dda0dbb9cf030c20ddac353c861c09fa", "width": 2688, "height": 1792}, "resolutions": [{"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7d7d58332e0cbb07dea5da384e001c7d7176f27", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5966c776f1ca2cdcf06a241d07578197870315b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46d58404c44429d0727987e7a25048654edf70e4", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f1ded20f4d4bafc79d841c95bf9467f0c70e1ba", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b9c33cdda23e774d862952924083bd6044c55f42", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73070affd9bbc91c9314dcd1e8f6ed879045e9c8", "width": 1080, "height": 720}], "variants": {}, "id": "UNxPUV_rhw7H5oI0SODFEM6Izqt3u_t6LNuihNml6Jc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bd1ldx", "is_robot_indexable": true, "report_reasons": null, "author": "mwylde_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1ldx/why_we_rebuilt_our_streaming_sql_engine_on_arrow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arroyo.dev/blog/why-arrow-and-datafusion", "subreddit_subscribers": 167975, "created_utc": 1710261151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interesting take on doing schema migrations on very large production OLAP tables with streaming ingestion and lots of concurrent reads.\n\n[https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming](https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming)\n\nDisclaimer: I work for Tinybird, but did not write the post.", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iterating terabyte-sized ClickHouse tables in production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcy126", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710252260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting take on doing schema migrations on very large production OLAP tables with streaming ingestion and lots of concurrent reads.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming\"&gt;https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I work for Tinybird, but did not write the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?auto=webp&amp;s=a816daa8fe28ab20aee923897959a6a72157660e", "width": 2000, "height": 1050}, "resolutions": [{"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da9e05f8ec09d374b9568fc2dbcda7f66d532b55", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=851f637fac474e4702db40e36551338b708efbbe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ba5efbd735f0fbba39aba13bf8bae1d659016e2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65ddd01ee1fd120bdf8bed4a16bdac247dacbeb5", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=323087cb18120c44a71712d4e380cf8287c54305", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=939debe85d25cbbf6ce7fbb2b2f994c7deeb6da4", "width": 1080, "height": 567}], "variants": {}, "id": "39sXxh4PpQndQcK93T-HHqeuH7VzsqkV4qGk4SpfUqo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcy126", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcy126/iterating_terabytesized_clickhouse_tables_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcy126/iterating_terabytesized_clickhouse_tables_in/", "subreddit_subscribers": 167975, "created_utc": 1710252260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I am writing a report comparing the best data modeling tools to propose for the entire company's use. My company has deployed several projects to build Data Lakes and Data Warehouses for large enterprises. \n\nFor previous projects, my data modeling tools were not consistently used. Yesterday, my boss proposed 2 tools he has used: IDERA's E/RStudio and Visual Paradigm. My boss wants me to research and provide a comparison of the pros and cons of these 2 tools, then propose to everyone in the company to agree on one tool to use for upcoming projects. \n\nI would like to ask everyone which tool would be more suitable for which user groups based on your experiences, or where I could research this information further. \n\nAdditionally, I would want  you to suggest me a tool that you frequently use and feel is the best for your own usage needs for me to consider further.\n\nThank you very much!", "author_fullname": "t2_5zdpc9jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best data modeling tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bctnhy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710238032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I am writing a report comparing the best data modeling tools to propose for the entire company&amp;#39;s use. My company has deployed several projects to build Data Lakes and Data Warehouses for large enterprises. &lt;/p&gt;\n\n&lt;p&gt;For previous projects, my data modeling tools were not consistently used. Yesterday, my boss proposed 2 tools he has used: IDERA&amp;#39;s E/RStudio and Visual Paradigm. My boss wants me to research and provide a comparison of the pros and cons of these 2 tools, then propose to everyone in the company to agree on one tool to use for upcoming projects. &lt;/p&gt;\n\n&lt;p&gt;I would like to ask everyone which tool would be more suitable for which user groups based on your experiences, or where I could research this information further. &lt;/p&gt;\n\n&lt;p&gt;Additionally, I would want  you to suggest me a tool that you frequently use and feel is the best for your own usage needs for me to consider further.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bctnhy", "is_robot_indexable": true, "report_reasons": null, "author": "Public_Depth_532", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bctnhy/best_data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bctnhy/best_data_modeling_tool/", "subreddit_subscribers": 167975, "created_utc": 1710238032.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}