{"kind": "Listing", "data": {"after": "t3_1bctnhy", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a data engineer writing massive ETL queries to extract huge amount of data from systems that are so overly complex They make my head spin. One of them for example is Salesforce, another service now. A lot of these queries have been written or put together from past employees or developers, and we are handed them and told to own them going forward. So then we have to look through a 3000 line script and ensure it runs smoothly. But rarely, we will discover incorrect data. For example, just this week, we discovered that an ETL query has been pulling the incorrect data for about 2 years now...\n\nWhat do you even do in this situation? Like \"Sorry, the data was wrong for 2 years but we fixed it!\" Or do you just like say you fixed a data error and provide no specifics? ", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You ever discovered that data has been wrong for a very long time? What do you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd35dy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710264802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data engineer writing massive ETL queries to extract huge amount of data from systems that are so overly complex They make my head spin. One of them for example is Salesforce, another service now. A lot of these queries have been written or put together from past employees or developers, and we are handed them and told to own them going forward. So then we have to look through a 3000 line script and ensure it runs smoothly. But rarely, we will discover incorrect data. For example, just this week, we discovered that an ETL query has been pulling the incorrect data for about 2 years now...&lt;/p&gt;\n\n&lt;p&gt;What do you even do in this situation? Like &amp;quot;Sorry, the data was wrong for 2 years but we fixed it!&amp;quot; Or do you just like say you fixed a data error and provide no specifics? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd35dy", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd35dy/you_ever_discovered_that_data_has_been_wrong_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd35dy/you_ever_discovered_that_data_has_been_wrong_for/", "subreddit_subscribers": 168020, "created_utc": 1710264802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nOne of my colleagues mentioned she knew a data visualization tool that can edit data. By that, she didn\u2019t mean editing calculated field but fields from the source, impacting the source.\nLike you would plug a DB to Tableau and could modify data in Tableau and the data in the DB data would get updated.\nA two way street between the source and the viz.\n\nSounds crazy to me but we live in a crazy world. ", "author_fullname": "t2_8imxqj2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever heard about a data visualization tool that can edit data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcsjmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710233507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;One of my colleagues mentioned she knew a data visualization tool that can edit data. By that, she didn\u2019t mean editing calculated field but fields from the source, impacting the source.\nLike you would plug a DB to Tableau and could modify data in Tableau and the data in the DB data would get updated.\nA two way street between the source and the viz.&lt;/p&gt;\n\n&lt;p&gt;Sounds crazy to me but we live in a crazy world. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcsjmf", "is_robot_indexable": true, "report_reasons": null, "author": "vitodeltoro", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcsjmf/have_you_ever_heard_about_a_data_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcsjmf/have_you_ever_heard_about_a_data_visualization/", "subreddit_subscribers": 168020, "created_utc": 1710233507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. I have worked my way up in my organization from Service Desk Analyst to the title of a Data Engineernand have been with this company for almost 7 years. My primary tasks are maintening an AWS Glue pipeline into our data lake and bringing new tables from various sources into it. I know python somewhat well (I can pass some medium leetcode problems as a reference), my SQL skills are very basic, I feel like my organization is so far behind things techwise I am getting away with it and I can use chatgpt well enough to figure out anything I don't know. \n\nTyping this out I feel like I'm describing myself more competent than I feel. I have no formal education besides highschool and a boatload of AWS certifications I always have to study my butt off for. \n\nI'm not sure what the point of this post is, I just kinda needed to rant and get it off my chest to someone and maybe get some outside perspective.\n\nHow do you guys deal with thoughts like these? Do my skills line up with what's expected of a DE? ", "author_fullname": "t2_kaic0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like such a fraud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd500u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710269114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. I have worked my way up in my organization from Service Desk Analyst to the title of a Data Engineernand have been with this company for almost 7 years. My primary tasks are maintening an AWS Glue pipeline into our data lake and bringing new tables from various sources into it. I know python somewhat well (I can pass some medium leetcode problems as a reference), my SQL skills are very basic, I feel like my organization is so far behind things techwise I am getting away with it and I can use chatgpt well enough to figure out anything I don&amp;#39;t know. &lt;/p&gt;\n\n&lt;p&gt;Typing this out I feel like I&amp;#39;m describing myself more competent than I feel. I have no formal education besides highschool and a boatload of AWS certifications I always have to study my butt off for. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure what the point of this post is, I just kinda needed to rant and get it off my chest to someone and maybe get some outside perspective.&lt;/p&gt;\n\n&lt;p&gt;How do you guys deal with thoughts like these? Do my skills line up with what&amp;#39;s expected of a DE? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd500u", "is_robot_indexable": true, "report_reasons": null, "author": "Jaggedfel2142", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd500u/i_feel_like_such_a_fraud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd500u/i_feel_like_such_a_fraud/", "subreddit_subscribers": 168020, "created_utc": 1710269114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Founder of Multiwoven ([https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)) here. \n\nMy co-founders and I have a background in product and engineering for Asia population-scale customer data infrastructure and applications - across Affle (3 Bn+ connected devices for consumer\u00a0intelligence-based marketing), Truecaller (\\~400 Mn. MAU) and Razorpay (India's largest payments platform).\n\nWe built Multiwoven as an open source reverse ETL tool for data activation. After our recent repo launch, Multiwoven started being used by data teams to eliminate the complexity and tediousness of building and maintaining data pipelines to third-party biz/marketing/sales tools.\u00a0\n\nFrom our early users and discovery conversations, we quickly started seeing users who have a data warehouse use us like a CDP on top of their warehouse. Many of them were customers and prospects of Salesforce (CRM and/or marketing cloud).\u00a0\n\nThe simple solution that worked for them -\u00a0\n\n1. Easily works with all their tools (not just Salesforce's ecosystem). We are adding roughly two new Connectors every week, and it's also easy to build or customize for someone's own needs (without going through long and expensive professional services)\n\n2. Not being compelled to invest upwards of half a million dollars a year on Salesforce CDP. The Salesforce CDP Starter Pack is at $110K, and doesn't include Segmentation, Audiences and Ad integrations (imagine a CDP without these!)\n\n3. Being able to easily self-host the software (that essentially has access to all their warehouse data) and not worry about jumping through Compliance/InfoSec's\u00a0hoops.\u00a0\n\nGartner recently naming Salesforce CDP a leader in their first Magic Quadrant for CDPs is certainly\u00a0surprising. We're not sure that users feel the same way. We recently released a connector to Salesforce CRM, and Salesforce Marketing Cloud is on the way. We are continuing to furiously build and working to meet users' needs.\n\nAs a young project, we'd love your feedback and support (pls star us on GitHub! [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven))", "author_fullname": "t2_1g3ospki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "we built an open source Salesforce CDP alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bchyko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710199640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Founder of Multiwoven (&lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;) here. &lt;/p&gt;\n\n&lt;p&gt;My co-founders and I have a background in product and engineering for Asia population-scale customer data infrastructure and applications - across Affle (3 Bn+ connected devices for consumer\u00a0intelligence-based marketing), Truecaller (~400 Mn. MAU) and Razorpay (India&amp;#39;s largest payments platform).&lt;/p&gt;\n\n&lt;p&gt;We built Multiwoven as an open source reverse ETL tool for data activation. After our recent repo launch, Multiwoven started being used by data teams to eliminate the complexity and tediousness of building and maintaining data pipelines to third-party biz/marketing/sales tools.\u00a0&lt;/p&gt;\n\n&lt;p&gt;From our early users and discovery conversations, we quickly started seeing users who have a data warehouse use us like a CDP on top of their warehouse. Many of them were customers and prospects of Salesforce (CRM and/or marketing cloud).\u00a0&lt;/p&gt;\n\n&lt;p&gt;The simple solution that worked for them -\u00a0&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Easily works with all their tools (not just Salesforce&amp;#39;s ecosystem). We are adding roughly two new Connectors every week, and it&amp;#39;s also easy to build or customize for someone&amp;#39;s own needs (without going through long and expensive professional services)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Not being compelled to invest upwards of half a million dollars a year on Salesforce CDP. The Salesforce CDP Starter Pack is at $110K, and doesn&amp;#39;t include Segmentation, Audiences and Ad integrations (imagine a CDP without these!)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Being able to easily self-host the software (that essentially has access to all their warehouse data) and not worry about jumping through Compliance/InfoSec&amp;#39;s\u00a0hoops.\u00a0&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Gartner recently naming Salesforce CDP a leader in their first Magic Quadrant for CDPs is certainly\u00a0surprising. We&amp;#39;re not sure that users feel the same way. We recently released a connector to Salesforce CRM, and Salesforce Marketing Cloud is on the way. We are continuing to furiously build and working to meet users&amp;#39; needs.&lt;/p&gt;\n\n&lt;p&gt;As a young project, we&amp;#39;d love your feedback and support (pls star us on GitHub! &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?auto=webp&amp;s=0bc0e93038ef50951c90227649f7f6ab254a7cf4", "width": 2560, "height": 1204}, "resolutions": [{"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17a45a447d842e52652926f6dc817d7170a88986", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e12cc0a1c0d9fd4fd747ed329f19cd30a8124b3b", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=69066e72c75f3b4020a551ac50062213dbdb397c", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a02272300d0676184dcf058494ffd170c121368", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a2b31da90137f24f3433708d44936c2fb49ece3", "width": 960, "height": 451}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0d7ab5f6e495f29e4f13cc0b5671fcfd8b115e51", "width": 1080, "height": 507}], "variants": {}, "id": "Gn1oZnAX_pLkKE4iHRaNdie9sLvYRt8PUbXOPUT0MUA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bchyko", "is_robot_indexable": true, "report_reasons": null, "author": "wishingchairs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bchyko/we_built_an_open_source_salesforce_cdp_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bchyko/we_built_an_open_source_salesforce_cdp_alternative/", "subreddit_subscribers": 168020, "created_utc": 1710199640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have a data engineer intrvw coming up next week and the recruiter told me that it one hour will be technical and the next one hour will be behavioural questions. What kind of behavioural questions i should be expecting? I have a few years experience as a backend developer working in sql server and 2 months of internship experience as a data analyst. This is a career change role for me. Thanks in advance. ", "author_fullname": "t2_a260u37s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the common types of behavioural questions you should expect in an entry level data engineer role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcew7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710192385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a data engineer intrvw coming up next week and the recruiter told me that it one hour will be technical and the next one hour will be behavioural questions. What kind of behavioural questions i should be expecting? I have a few years experience as a backend developer working in sql server and 2 months of internship experience as a data analyst. This is a career change role for me. Thanks in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bcew7i", "is_robot_indexable": true, "report_reasons": null, "author": "Outside_Aide_1958", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcew7i/what_are_the_common_types_of_behavioural/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcew7i/what_are_the_common_types_of_behavioural/", "subreddit_subscribers": 168020, "created_utc": 1710192385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since Data Engineers are rare nowadays - relative to more common SE roles. I wonder if there exists a role of a Software QA Engineer for a DE team. If so, what do they do in your company? How do they define the needed test suites for a specific requirement?\n\n", "author_fullname": "t2_85ty6e1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software QA in a Data Engineering Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcv2qo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710243315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since Data Engineers are rare nowadays - relative to more common SE roles. I wonder if there exists a role of a Software QA Engineer for a DE team. If so, what do they do in your company? How do they define the needed test suites for a specific requirement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bcv2qo", "is_robot_indexable": true, "report_reasons": null, "author": "BestBlackberry1314", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcv2qo/software_qa_in_a_data_engineering_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcv2qo/software_qa_in_a_data_engineering_team/", "subreddit_subscribers": 168020, "created_utc": 1710243315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I've been into data engineering ever since I graduate from my bachelors in CS in June 2023. So I've gained skills in SQL and experience with Azure. But since I graduated from CS, I was wondering... what would make me stand out from other data engineers having studied CS? Like I did projects related to web development and would say have a decent coding skills. So what would make me a stronger candidate than others? Having a strong knowledge in frontend dev. or backend dev?", "author_fullname": "t2_chpvvtuts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strong Data Engineering Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1geu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710260835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;ve been into data engineering ever since I graduate from my bachelors in CS in June 2023. So I&amp;#39;ve gained skills in SQL and experience with Azure. But since I graduated from CS, I was wondering... what would make me stand out from other data engineers having studied CS? Like I did projects related to web development and would say have a decent coding skills. So what would make me a stronger candidate than others? Having a strong knowledge in frontend dev. or backend dev?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bd1geu", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Pen_1356", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1geu/strong_data_engineering_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd1geu/strong_data_engineering_profile/", "subreddit_subscribers": 168020, "created_utc": 1710260835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say I\u2019m developing a web app that will get shown on user devices. So the system would look something like this:\n\nUser Device &lt;-&gt; Streamlit Frontend -&gt; FastAPI Logic -&gt; SQLAlchemy Data Access &lt;-&gt; Postgres Data Store\n\nWould this result in:\n\n* Application Layer: Streamlit\n* Business Logic Layer: FastAPI\n* Data Access Layer: SQLAlchemy\n* Data Layer: Postgres\n\nOr am I misunderstanding anything?\n", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making sure I understand the 3 tier architecture\u2026 Is this it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcyqug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710254137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I\u2019m developing a web app that will get shown on user devices. So the system would look something like this:&lt;/p&gt;\n\n&lt;p&gt;User Device &amp;lt;-&amp;gt; Streamlit Frontend -&amp;gt; FastAPI Logic -&amp;gt; SQLAlchemy Data Access &amp;lt;-&amp;gt; Postgres Data Store&lt;/p&gt;\n\n&lt;p&gt;Would this result in:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Application Layer: Streamlit&lt;/li&gt;\n&lt;li&gt;Business Logic Layer: FastAPI&lt;/li&gt;\n&lt;li&gt;Data Access Layer: SQLAlchemy&lt;/li&gt;\n&lt;li&gt;Data Layer: Postgres&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or am I misunderstanding anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcyqug", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcyqug/making_sure_i_understand_the_3_tier_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcyqug/making_sure_i_understand_the_3_tier_architecture/", "subreddit_subscribers": 168020, "created_utc": 1710254137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dagster.io/blog/dagster-openai](https://dagster.io/blog/dagster-openai)\n\nThe new dagster-openai integration lets you tap into the power of LLMs in a cost-efficient way.\n\nhttps://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0", "author_fullname": "t2_c45yywox7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster's Open AI integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ovkzr6rjoxnc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b2b5fa07a548a4241016e5574ec40dd1be9b42fc"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f756c46d79281ac646f745a834f3a2c150d8076"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7db258eb2a117848a241620ec0f31178f8c2ddc3"}, {"y": 336, "x": 640, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5640258c75bab8e6d7e14c3e1199cfefcfa8248f"}, {"y": 504, "x": 960, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09be2968a5be5d97ee06f679bacc7dc22590866d"}, {"y": 567, "x": 1080, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7bf29066b69a4a3ddd9ae43e82b0d4e36b4d3247"}], "s": {"y": 630, "x": 1200, "u": "https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0"}, "id": "ovkzr6rjoxnc1"}}, "name": "t3_1bd25o2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CwcvahbzbTHlIv2YnRP4yV4EnweUcOGhl7TvGAVfqG0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710262472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dagster.io/blog/dagster-openai\"&gt;https://dagster.io/blog/dagster-openai&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The new dagster-openai integration lets you tap into the power of LLMs in a cost-efficient way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0\"&gt;https://preview.redd.it/ovkzr6rjoxnc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a7ecab5ae764f9a3ce77612374c19fa2442aa8b0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bd25o2", "is_robot_indexable": true, "report_reasons": null, "author": "dagster-io", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd25o2/dagsters_open_ai_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd25o2/dagsters_open_ai_integration/", "subreddit_subscribers": 168020, "created_utc": 1710262472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen some pretty crazy SQL queries during my time working on data platforms. I've recently been dealing with SQL queries that consists of hundreds of thousands of union statements. \n\nI've also seen the abuse of dbt's ephemeral models which result in megabytes of massive SQL statements that are impossible to debug.\n\nRecently, I've had to create automated functions to translate spark explode -&gt; bigquery, it produces some pretty ugly code.\n\n```SELECT POSEXPLODE(ARRAY(2, 3)), EXPLODE(ARRAY(4, 5, 6)) FROM tbl```\n\nSELECT\n\n  IF(_u.pos = _u_2.pos_2, _u_2.col) AS col,\n\n  IF(_u.pos = _u_2.pos_2, _u_2.pos_2) AS pos_2,\n\n  IF(_u.pos = _u_3.pos_3, _u_3.col_2) AS col_2\n\nFROM tbl\n\nCROSS JOIN UNNEST(SEQUENCE(1, GREATEST(CARDINALITY(ARRAY[2, 3]), CARDINALITY(ARRAY[4, 5, 6])))) AS _u(pos)\n\nCROSS JOIN UNNEST(ARRAY[2, 3]) WITH ORDINALITY AS _u_2(col, pos_2)\n\nCROSS JOIN UNNEST(ARRAY[4, 5, 6]) WITH ORDINALITY AS _u_3(col_2, pos_3)\n\nWHERE\n\n  (\n\n    _u.pos = _u_2.pos_2\n\n    OR (\n\n      _u.pos &gt; CARDINALITY(ARRAY[2, 3]) AND _u_2.pos_2 = CARDINALITY(ARRAY[2, 3])\n\n    )\n\n  )\n\n  AND (\n\n    _u.pos = _u_3.pos_3\n\n    OR (\n\n      _u.pos &gt; CARDINALITY(ARRAY[4, 5, 6]) AND _u_3.pos_3 = CARDINALITY(ARRAY[4, 5, 6])\n\n    )\n\n  )\n\n\nWhat are some of the worst SQL queries you've encountered?", "author_fullname": "t2_56xhg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gnarliest SQL queries you've ever seen?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd32bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710264607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen some pretty crazy SQL queries during my time working on data platforms. I&amp;#39;ve recently been dealing with SQL queries that consists of hundreds of thousands of union statements. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also seen the abuse of dbt&amp;#39;s ephemeral models which result in megabytes of massive SQL statements that are impossible to debug.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve had to create automated functions to translate spark explode -&amp;gt; bigquery, it produces some pretty ugly code.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT POSEXPLODE(ARRAY(2, 3)), EXPLODE(ARRAY(4, 5, 6)) FROM tbl&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;SELECT&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_2.pos_2, _u_2.col) AS col,&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_2.pos_2, _u_2.pos_2) AS pos_2,&lt;/p&gt;\n\n&lt;p&gt;IF(_u.pos = _u_3.pos_3, _u_3.col_2) AS col_2&lt;/p&gt;\n\n&lt;p&gt;FROM tbl&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(SEQUENCE(1, GREATEST(CARDINALITY(ARRAY[2, 3]), CARDINALITY(ARRAY[4, 5, 6])))) AS _u(pos)&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(ARRAY[2, 3]) WITH ORDINALITY AS _u_2(col, pos_2)&lt;/p&gt;\n\n&lt;p&gt;CROSS JOIN UNNEST(ARRAY[4, 5, 6]) WITH ORDINALITY AS _u_3(col_2, pos_3)&lt;/p&gt;\n\n&lt;p&gt;WHERE&lt;/p&gt;\n\n&lt;p&gt;(&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;_u.pos = _u_2.pos_2\n\nOR (\n\n  _u.pos &amp;gt; CARDINALITY(ARRAY[2, 3]) AND _u_2.pos_2 = CARDINALITY(ARRAY[2, 3])\n\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;AND (&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;_u.pos = _u_3.pos_3\n\nOR (\n\n  _u.pos &amp;gt; CARDINALITY(ARRAY[4, 5, 6]) AND _u_3.pos_3 = CARDINALITY(ARRAY[4, 5, 6])\n\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;What are some of the worst SQL queries you&amp;#39;ve encountered?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd32bx", "is_robot_indexable": true, "report_reasons": null, "author": "captaintobs", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd32bx/gnarliest_sql_queries_youve_ever_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd32bx/gnarliest_sql_queries_youve_ever_seen/", "subreddit_subscribers": 168020, "created_utc": 1710264607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI've got a master's degree in data and done several internships in data engineering. I'd like to start my career in the same field but I haven't had the opportunity to learn much about certain technologies. Are there any good exercises or projects on Kaggle to learn how to use certain combined technologies like Python, SQL,  ELK, Kafka, Airflow, Spark, terraform, with docker, Bash for example. If there aren't any Kaggle projects or that sort of thing, would there be appropriate datasets for the data sources? Maybe projects using GNS3 for the configuration part or some kind of github repository as a guided project? I don't know. Above all, I'm looking for a project that will enable me to learn or discover all these technologies. I know that a lot of these technologies can work together in a company, so I suppose it's not impossible to get a lot of them involved in this project.\n\nAs I'm considered to have little experience, I'd like to work on all these skills in my own time to see how everything fits together and to know what I'm talking about. I'm prepared to devote a lot of time to it so that I can be deployed more quickly in companies. If you can help me or even give me advice on the technology, for example, that would be really nice. Any feedback is also very welcome.", "author_fullname": "t2_q95335vn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn data engineering in a non-professional context?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1bsf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710260528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a master&amp;#39;s degree in data and done several internships in data engineering. I&amp;#39;d like to start my career in the same field but I haven&amp;#39;t had the opportunity to learn much about certain technologies. Are there any good exercises or projects on Kaggle to learn how to use certain combined technologies like Python, SQL,  ELK, Kafka, Airflow, Spark, terraform, with docker, Bash for example. If there aren&amp;#39;t any Kaggle projects or that sort of thing, would there be appropriate datasets for the data sources? Maybe projects using GNS3 for the configuration part or some kind of github repository as a guided project? I don&amp;#39;t know. Above all, I&amp;#39;m looking for a project that will enable me to learn or discover all these technologies. I know that a lot of these technologies can work together in a company, so I suppose it&amp;#39;s not impossible to get a lot of them involved in this project.&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;m considered to have little experience, I&amp;#39;d like to work on all these skills in my own time to see how everything fits together and to know what I&amp;#39;m talking about. I&amp;#39;m prepared to devote a lot of time to it so that I can be deployed more quickly in companies. If you can help me or even give me advice on the technology, for example, that would be really nice. Any feedback is also very welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd1bsf", "is_robot_indexable": true, "report_reasons": null, "author": "Aquilae2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1bsf/how_to_learn_data_engineering_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd1bsf/how_to_learn_data_engineering_in_a/", "subreddit_subscribers": 168020, "created_utc": 1710260528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gmelb8os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse to Lakehouse Evolution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcihcy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1710200920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "iomete.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://iomete.com/resources/blog/from-data-warehouses-to-data-lakehouses", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcihcy", "is_robot_indexable": true, "report_reasons": null, "author": "Single_Brother_1791", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcihcy/data_warehouse_to_lakehouse_evolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://iomete.com/resources/blog/from-data-warehouses-to-data-lakehouses", "subreddit_subscribers": 168020, "created_utc": 1710200920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have data assets on multiple clouds (sql ds in aws, databricks and adls gen2 in azure), and I want to build data lineages on top of them, is Apache Atlas good tool of choice. \nIf yes please share some resources, that might be helpful. Thanks in advance\ud83d\ude4c\n\nPs. I don\u2019t want to use ms purview ", "author_fullname": "t2_i9p6l5fsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Atlas Review ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcvbdr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710244117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have data assets on multiple clouds (sql ds in aws, databricks and adls gen2 in azure), and I want to build data lineages on top of them, is Apache Atlas good tool of choice. \nIf yes please share some resources, that might be helpful. Thanks in advance\ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;Ps. I don\u2019t want to use ms purview &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcvbdr", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Job9989", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcvbdr/apache_atlas_review/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcvbdr/apache_atlas_review/", "subreddit_subscribers": 168020, "created_utc": 1710244117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a project wherein we need to fetch data from ALDS Gen 2 to Excel via API.\n\nMy question, is it faster to read 5 out of 5 columns from the source compared to reading 5 columns from a total of 100 columns? \n\nI'm thinking wether to create a separate data model for the application or the silver layer (which contains more columns) would suffice.\n\nThank you in advance.", "author_fullname": "t2_ap5f9vbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API get data which one is faster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcnb0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710214140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a project wherein we need to fetch data from ALDS Gen 2 to Excel via API.&lt;/p&gt;\n\n&lt;p&gt;My question, is it faster to read 5 out of 5 columns from the source compared to reading 5 columns from a total of 100 columns? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking wether to create a separate data model for the application or the silver layer (which contains more columns) would suffice.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bcnb0v", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Gur9574", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcnb0v/api_get_data_which_one_is_faster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcnb0v/api_get_data_which_one_is_faster/", "subreddit_subscribers": 168020, "created_utc": 1710214140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a client who currently categorizes data in a spreadsheet. When new data appears, they need to assign a category.\n\nAs we move them to a warehouse, I'd love to give them a way to notice data that needs to be assigned a category + an easy way to assign. \n\nThey are in the Microsoft ecosystem.\n\nSeems like this should be a common need, what the standard operating procedure here?", "author_fullname": "t2_vfx4v6x3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SOP for enabling end users to enrich data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bclc8c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710208501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a client who currently categorizes data in a spreadsheet. When new data appears, they need to assign a category.&lt;/p&gt;\n\n&lt;p&gt;As we move them to a warehouse, I&amp;#39;d love to give them a way to notice data that needs to be assigned a category + an easy way to assign. &lt;/p&gt;\n\n&lt;p&gt;They are in the Microsoft ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Seems like this should be a common need, what the standard operating procedure here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bclc8c", "is_robot_indexable": true, "report_reasons": null, "author": "KnightoftheDadBod", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bclc8c/sop_for_enabling_end_users_to_enrich_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bclc8c/sop_for_enabling_end_users_to_enrich_data/", "subreddit_subscribers": 168020, "created_utc": 1710208501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need help. I have been working on Abinito . Recently an opportunity came for me to work on azure data bricks. we will be moving some of the on prem jobs . For this purpose i have done certification in Azure and databricks as well.  Have no experience on Python. Does anyone know of any online course where i can get chance to create 1 or 2 projects where data ingestion using ADF and transformations in Databricks using scala or pyspark. ", "author_fullname": "t2_t0zkmfpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data bricks  live project ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcijs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710201085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help. I have been working on Abinito . Recently an opportunity came for me to work on azure data bricks. we will be moving some of the on prem jobs . For this purpose i have done certification in Azure and databricks as well.  Have no experience on Python. Does anyone know of any online course where i can get chance to create 1 or 2 projects where data ingestion using ADF and transformations in Databricks using scala or pyspark. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcijs0", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible_Mud5318", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcijs0/azure_data_bricks_live_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcijs0/azure_data_bricks_live_project/", "subreddit_subscribers": 168020, "created_utc": 1710201085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to stream data from SNS into an iceberg table on S3. However I am a beginner and I feel quite overwhelmed with the amount of possible ways of how to do that.\n\nSNS has around 100 thousand messaged per day (ca. 1/s) which I would like to stream to an Iceberg table. I was thinking Data Firehose however, I think it can not push directly to an iceberg table on S3.   \nDoes it make sense to first put data onto a landingzone in s3 and then run a streaming glue job in spark to stream into the table?   \nFurthermore the problem is that the table should be somewhat up to date (lets say 1 to 5 minutes delay) because customers use it for querys in Athena. However, as the streaming throughput is that small and the table is partitioned for every customer, it leaves me with the small file problem in the table. (the messages about every second can be from different customers)   \nI think running a compaction job every hour could be overkill if you have to do that for hundreds of customers with always just some little files.   \n\n\nI'm thankful for every pointer in the right direction and I can answer more details if I forgot anything as I am still a beginner. ", "author_fullname": "t2_kv5ze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to stream from SNS to Iceberg table on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd7bfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710274558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to stream data from SNS into an iceberg table on S3. However I am a beginner and I feel quite overwhelmed with the amount of possible ways of how to do that.&lt;/p&gt;\n\n&lt;p&gt;SNS has around 100 thousand messaged per day (ca. 1/s) which I would like to stream to an Iceberg table. I was thinking Data Firehose however, I think it can not push directly to an iceberg table on S3.&lt;br/&gt;\nDoes it make sense to first put data onto a landingzone in s3 and then run a streaming glue job in spark to stream into the table?&lt;br/&gt;\nFurthermore the problem is that the table should be somewhat up to date (lets say 1 to 5 minutes delay) because customers use it for querys in Athena. However, as the streaming throughput is that small and the table is partitioned for every customer, it leaves me with the small file problem in the table. (the messages about every second can be from different customers)&lt;br/&gt;\nI think running a compaction job every hour could be overkill if you have to do that for hundreds of customers with always just some little files.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thankful for every pointer in the right direction and I can answer more details if I forgot anything as I am still a beginner. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd7bfo", "is_robot_indexable": true, "report_reasons": null, "author": "Larsimoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd7bfo/how_to_stream_from_sns_to_iceberg_table_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd7bfo/how_to_stream_from_sns_to_iceberg_table_on_aws/", "subreddit_subscribers": 168020, "created_utc": 1710274558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Folks,\n\nI currently need a solution for a particular scenario. I Have three jobs to run the pipeline(assume they are set up using Data bricks workflow). Now I want the first job (1) to produce a unique key and pass that one to the next job(2) which will pass to the next job(3). When this workflow runs again the key generated should be different compared to the previous one.  \n\n\nThis is for databricks\n\nAny Ideas!!\n\nThanks.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help need to with passing a unique key in a workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bd6tif", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710273387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,&lt;/p&gt;\n\n&lt;p&gt;I currently need a solution for a particular scenario. I Have three jobs to run the pipeline(assume they are set up using Data bricks workflow). Now I want the first job (1) to produce a unique key and pass that one to the next job(2) which will pass to the next job(3). When this workflow runs again the key generated should be different compared to the previous one.  &lt;/p&gt;\n\n&lt;p&gt;This is for databricks&lt;/p&gt;\n\n&lt;p&gt;Any Ideas!!&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd6tif", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd6tif/help_need_to_with_passing_a_unique_key_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd6tif/help_need_to_with_passing_a_unique_key_in_a/", "subreddit_subscribers": 168020, "created_utc": 1710273387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've recently purchased Mozart, which includes Fivetran for data connectors, then brings everything into a Snowflake DB. From there, we connect Tableau to Snowflake for dashboards. \n\nBy no means am I a data engineering expert, so there's likely a miss on my side (and hopefully an easy solution), but I'm currently unable to find a single way to bring in GA4 data that contains dimensions for date, source, medium, campaign and page title, then the metric of sessions. Ideally, we'd have a bit more than that (events, conversions, views, engaged sessions, etc.), but I'd be happy with that as a starting point. \n\nFrom what I've seen, there's no page title available at all within any of the tables from Fivetran's connector, and I can't get any of the data to align with what we see in GA4. \n\n&amp;#x200B;\n\nIs this a known issue? Are there areas to explore that I may be overlooking?", "author_fullname": "t2_5c8pfg87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran and GA4 Data... useless?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd5pwp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710270742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve recently purchased Mozart, which includes Fivetran for data connectors, then brings everything into a Snowflake DB. From there, we connect Tableau to Snowflake for dashboards. &lt;/p&gt;\n\n&lt;p&gt;By no means am I a data engineering expert, so there&amp;#39;s likely a miss on my side (and hopefully an easy solution), but I&amp;#39;m currently unable to find a single way to bring in GA4 data that contains dimensions for date, source, medium, campaign and page title, then the metric of sessions. Ideally, we&amp;#39;d have a bit more than that (events, conversions, views, engaged sessions, etc.), but I&amp;#39;d be happy with that as a starting point. &lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve seen, there&amp;#39;s no page title available at all within any of the tables from Fivetran&amp;#39;s connector, and I can&amp;#39;t get any of the data to align with what we see in GA4. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this a known issue? Are there areas to explore that I may be overlooking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bd5pwp", "is_robot_indexable": true, "report_reasons": null, "author": "MJCowpa", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd5pwp/fivetran_and_ga4_data_useless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd5pwp/fivetran_and_ga4_data_useless/", "subreddit_subscribers": 168020, "created_utc": 1710270742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just want to learn more about how to monitor pipelines in a more efficient way and what tools I can use to set alerts.\n\n", "author_fullname": "t2_61uvorko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any resources for monitoring and alerting? What tools do you use? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd2389", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710262318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just want to learn more about how to monitor pipelines in a more efficient way and what tools I can use to set alerts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bd2389", "is_robot_indexable": true, "report_reasons": null, "author": "jadedsprint", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd2389/any_resources_for_monitoring_and_alerting_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bd2389/any_resources_for_monitoring_and_alerting_what/", "subreddit_subscribers": 168020, "created_utc": 1710262318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Delta Live Tables 101", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1pkb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lsE32ulzTQ1gv2jMs2mvJn3UbxlOKeEpElKcqSYrGUw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710261421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "synccomputing.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://synccomputing.com/databricks-delta-live-tables-101/#cost-of-Delta-Live-Tables", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?auto=webp&amp;s=17a93af4d7a044493c916086a945be836b30bbb8", "width": 2312, "height": 1280}, "resolutions": [{"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81d4d025f4282c6190de1c37e3b7346cc9029bd6", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d11fa9b79a482dc368f098173e9ae19552124e5c", "width": 216, "height": 119}, {"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d489cdd60969830fd4a18a9c7feab0958076b1fa", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18ceeb1190d05e86994d33ab87d6ffa282739306", "width": 640, "height": 354}, {"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d946fae349f81d19c26164256277f479dd5284b6", "width": 960, "height": 531}, {"url": "https://external-preview.redd.it/yDHeGuibjOL8bwnIRv20oc48WZABjr_Mn8v6xJck9aI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c57430bbdfbf12fc0834be4537cd368a23acc66", "width": 1080, "height": 597}], "variants": {}, "id": "CkFBmk0kVv9HQAfbImsxPji3p0QPqLfwKgUitxDNZnk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bd1pkb", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1pkb/databricks_delta_live_tables_101/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://synccomputing.com/databricks-delta-live-tables-101/#cost-of-Delta-Live-Tables", "subreddit_subscribers": 168020, "created_utc": 1710261421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2cbhndmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why we rebuilt our streaming SQL engine on Arrow and DataFusion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1bd1ldx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SP7NuGNJCrGyOCFEDJ-ShUTComq-Wx19oDx4gknWiYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710261151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arroyo.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arroyo.dev/blog/why-arrow-and-datafusion", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?auto=webp&amp;s=e7959007dda0dbb9cf030c20ddac353c861c09fa", "width": 2688, "height": 1792}, "resolutions": [{"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7d7d58332e0cbb07dea5da384e001c7d7176f27", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5966c776f1ca2cdcf06a241d07578197870315b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46d58404c44429d0727987e7a25048654edf70e4", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f1ded20f4d4bafc79d841c95bf9467f0c70e1ba", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b9c33cdda23e774d862952924083bd6044c55f42", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/M1LT7sPAemCZ40f5TyqpqambSAM-0LY1QRUY5vGlA7Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73070affd9bbc91c9314dcd1e8f6ed879045e9c8", "width": 1080, "height": 720}], "variants": {}, "id": "UNxPUV_rhw7H5oI0SODFEM6Izqt3u_t6LNuihNml6Jc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bd1ldx", "is_robot_indexable": true, "report_reasons": null, "author": "mwylde_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bd1ldx/why_we_rebuilt_our_streaming_sql_engine_on_arrow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arroyo.dev/blog/why-arrow-and-datafusion", "subreddit_subscribers": 168020, "created_utc": 1710261151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently applying for government funding for a Software Engineering education. The application requires that I find people in the occupation I'm pursuing (Data Engineering) and ask them some questions about their experience.\n\nMy program starts in a couple weeks, and I just found out that approval has to come through before the program starts! \ud83d\ude43 \n\nIf anyone who works as a DE could shoot me a DM so I could ask a few short questions, it would mean everything! \n\nAlso, I need to find 2 employers who have DE working within their company to do the same with. If that is also you, or someone could point me in that direction, that would also help immensely!\n\nI feel awful for the huge ask, but this community is the best place to find active data engineers.\n\nThank you!!", "author_fullname": "t2_3djr756e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Education funding requires I ask questions to professional DE [Urgent]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcy5ou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710252602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently applying for government funding for a Software Engineering education. The application requires that I find people in the occupation I&amp;#39;m pursuing (Data Engineering) and ask them some questions about their experience.&lt;/p&gt;\n\n&lt;p&gt;My program starts in a couple weeks, and I just found out that approval has to come through before the program starts! \ud83d\ude43 &lt;/p&gt;\n\n&lt;p&gt;If anyone who works as a DE could shoot me a DM so I could ask a few short questions, it would mean everything! &lt;/p&gt;\n\n&lt;p&gt;Also, I need to find 2 employers who have DE working within their company to do the same with. If that is also you, or someone could point me in that direction, that would also help immensely!&lt;/p&gt;\n\n&lt;p&gt;I feel awful for the huge ask, but this community is the best place to find active data engineers.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcy5ou", "is_robot_indexable": true, "report_reasons": null, "author": "Ablueblaze", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcy5ou/education_funding_requires_i_ask_questions_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcy5ou/education_funding_requires_i_ask_questions_to/", "subreddit_subscribers": 168020, "created_utc": 1710252602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interesting take on doing schema migrations on very large production OLAP tables with streaming ingestion and lots of concurrent reads.\n\n[https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming](https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming)\n\nDisclaimer: I work for Tinybird, but did not write the post.", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iterating terabyte-sized ClickHouse tables in production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcy126", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710252260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting take on doing schema migrations on very large production OLAP tables with streaming ingestion and lots of concurrent reads.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming\"&gt;https://www.tinybird.co/blog-posts/clickhouse-schema-migration-while-streaming&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I work for Tinybird, but did not write the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?auto=webp&amp;s=a816daa8fe28ab20aee923897959a6a72157660e", "width": 2000, "height": 1050}, "resolutions": [{"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da9e05f8ec09d374b9568fc2dbcda7f66d532b55", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=851f637fac474e4702db40e36551338b708efbbe", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ba5efbd735f0fbba39aba13bf8bae1d659016e2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65ddd01ee1fd120bdf8bed4a16bdac247dacbeb5", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=323087cb18120c44a71712d4e380cf8287c54305", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9FjyeqnDUEQ83YU8y5C_wGsCPsQ32rvkknq4PvQNIwg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=939debe85d25cbbf6ce7fbb2b2f994c7deeb6da4", "width": 1080, "height": 567}], "variants": {}, "id": "39sXxh4PpQndQcK93T-HHqeuH7VzsqkV4qGk4SpfUqo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcy126", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcy126/iterating_terabytesized_clickhouse_tables_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcy126/iterating_terabytesized_clickhouse_tables_in/", "subreddit_subscribers": 168020, "created_utc": 1710252260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I am writing a report comparing the best data modeling tools to propose for the entire company's use. My company has deployed several projects to build Data Lakes and Data Warehouses for large enterprises. \n\nFor previous projects, my data modeling tools were not consistently used. Yesterday, my boss proposed 2 tools he has used: IDERA's E/RStudio and Visual Paradigm. My boss wants me to research and provide a comparison of the pros and cons of these 2 tools, then propose to everyone in the company to agree on one tool to use for upcoming projects. \n\nI would like to ask everyone which tool would be more suitable for which user groups based on your experiences, or where I could research this information further. \n\nAdditionally, I would want  you to suggest me a tool that you frequently use and feel is the best for your own usage needs for me to consider further.\n\nThank you very much!", "author_fullname": "t2_5zdpc9jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best data modeling tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bctnhy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710238032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I am writing a report comparing the best data modeling tools to propose for the entire company&amp;#39;s use. My company has deployed several projects to build Data Lakes and Data Warehouses for large enterprises. &lt;/p&gt;\n\n&lt;p&gt;For previous projects, my data modeling tools were not consistently used. Yesterday, my boss proposed 2 tools he has used: IDERA&amp;#39;s E/RStudio and Visual Paradigm. My boss wants me to research and provide a comparison of the pros and cons of these 2 tools, then propose to everyone in the company to agree on one tool to use for upcoming projects. &lt;/p&gt;\n\n&lt;p&gt;I would like to ask everyone which tool would be more suitable for which user groups based on your experiences, or where I could research this information further. &lt;/p&gt;\n\n&lt;p&gt;Additionally, I would want  you to suggest me a tool that you frequently use and feel is the best for your own usage needs for me to consider further.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bctnhy", "is_robot_indexable": true, "report_reasons": null, "author": "Public_Depth_532", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bctnhy/best_data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bctnhy/best_data_modeling_tool/", "subreddit_subscribers": 168020, "created_utc": 1710238032.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}