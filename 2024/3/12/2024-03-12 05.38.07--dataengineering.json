{"kind": "Listing", "data": {"after": "t3_1bcatsa", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tipblvmq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "ELI5: what is \"Self-service Analytics\" (comic)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8uzqh00yoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=67dec4aa3f5e933739b6beb18fbebf506561819d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4187ff9656db23a3de90e0fbd330b267afedcec"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5329a9641c53947613f1b9ca7fb004c8ae3a91bb"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=b9e16028f1ecb5c4bbd958a6f445f1f854334516"}, "id": "8uzqh00yoonc1"}, "7ermym9xoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9be1d00c61f975c6bce3a4eebcea838552e5c6f"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b3beaba98ae8a648d6913c0c31d2263746c9320"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=63ad60c5610cf4ee3d3d49239d08d0d90c7701f9"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=0a27b88c3167111fd73e3b5c4e0676342098723b"}, "id": "7ermym9xoonc1"}, "ofadp50zoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=def9f754f54f86d1aa4a2c39c4d0c938b133bd8d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d68e204ee1cb598243b430aa8fd60f678629150a"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d643558e8540facb04b4c329973560a6501734b6"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=718d950cd40cba77d76be022a14d008702bbcfa1"}, "id": "ofadp50zoonc1"}, "t8xzox91ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e6b133e4098eec34e3fecd33a9a51de8753a931"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9259b0bd2ac5d13aaf93bc1e7ef860d373eabfab"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b657ace644bf9c52f9ed528c082a4d555ffdd16d"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=612a487d4174a9afb58f8e853dbfed9254d4c753"}, "id": "t8xzox91ponc1"}, "qoyx42ruoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce13819c999f7c3ff1b5f1fccc4d69ae9b6419ac"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc110e19eb736d70d85e9b67e9c1ecbb25823643"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9740780abffbd88106136bcb31f71f1b0511c456"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=5eb98629f2bedc5b982265512a9772271581597a"}, "id": "qoyx42ruoonc1"}, "uwvwzc5voonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f418b09b792d41d0f52d9d2cfb44dbf5a4442246"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f264d5d6af568fab4ec2cf4988c4742369b9b2b1"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ac848508f30d43f0aacdfd1c287c99843458ced"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=1036677e8d38421a544c79dd2eac06b87637bbf9"}, "id": "uwvwzc5voonc1"}, "dspzxvpxoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a30551ebc1e0cc537ce9a4910c4e6ca70b4d3f8c"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=552630d2b9a567b243ee1e86bf2ba1f130d08a26"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dcc2518c1f26f9b4be3f330bdda469787c3a75dc"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=55a5f387ed96523c35d8c02e53ede5a845fa2b5b"}, "id": "dspzxvpxoonc1"}, "quodorcyoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/quodorcyoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a62681dee2c3a2a0d35429d20ebfdad959d3295"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/quodorcyoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=44650a2555d4d8820fedbc3bfa85ab3f765695db"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/quodorcyoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6f5774f911f9ce3879c844929a77b8f7f045acb"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/quodorcyoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=4d9c5c50baddb2fd50a165061438d5775d10b9fa"}, "id": "quodorcyoonc1"}, "791h7dwzoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f54781aee44bf58640f75cfeb5eea31cb191badb"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cf1fef5b59360b50f6c5e0477df8bafe631beaa"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=90a9600eda974967702139e8dac6e68f5dbd30eb"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=dda14338f8539013c39edc737d9723dfdcd8d8ac"}, "id": "791h7dwzoonc1"}, "w8b7lkcuoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff06d2eeee3f5cce4cc243792f41dd23e62c1a43"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f02e7ce2c78a0bec160450b659820c824923b8ed"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c3e7878accb53114c2b5963cdb88d1d2d6c74d7"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=ff29701dfb0bacac33171da0fec973eee7b9cf39"}, "id": "w8b7lkcuoonc1"}, "wyj984bzoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9d8ec95df91c9a1a11e86ac8c0ec0a795908a73"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=faca4807a5f07af1739e4158f7afed69de7dabf9"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=be31656b37fe1a8f6cfb38f814d99f43deb37dda"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=d53490d8cb82da6bc04b2ffb9ac031c7dfde7e31"}, "id": "wyj984bzoonc1"}, "nj9t6dywoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4667ed03fa3504b45de70fdff0e5d87908b939b6"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ec6cd88ac7496938219246d276b9a5bcef4226e"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d647735a1ab0a6b1cd204f8fed0ae6646aabc39"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=abc782bbc5321d27a9ebb7ae705cea1872dfa6e6"}, "id": "nj9t6dywoonc1"}, "sgzwkknyoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef974a2f10dad3df92a059a1c990a340485b467b"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b133156ebb65cd1d165f358d39689b339b50f26"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e07cbbb35425aea70aeb156632e3176b61b9149"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=65a0cbc0a6112e13bca1d7dc5c6e9486b27a18c7"}, "id": "sgzwkknyoonc1"}, "6yfoxeg0ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=db6d832d203cd21d4dc020a4791ac2ce6ca520ba"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7dc6a93cf0c962b76e9c75bef90902b90f49caff"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e220b758193554aedb476805f7f8df1bcf631c45"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=86ef1d8b99c2960354e9c36580904c8d758c3405"}, "id": "6yfoxeg0ponc1"}, "evrabedsoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/evrabedsoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cce7ce7cb0911b5a4d54ab5fa2038d3f9abf883"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/evrabedsoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6fed175060cf9a49aab1dcee6a845283f448466"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/evrabedsoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=41f15bf67ba496dae4b135b16f0181035bda18f6"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/evrabedsoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=57e6b0022fe8db0a65a8538f9e4a0a589bfcb6e3"}, "id": "evrabedsoonc1"}, "a9fnr6z0ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc5eb0d53a07eccd6922b9aa83220bed9b693386"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7e24627505d8422c5ef957c7ca19d93b5f8941b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=46a511e7faad2e89172255f8b9708d97860b3e52"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=9ac75d1c8483beb2bfad251a781e717b321fb9de"}, "id": "a9fnr6z0ponc1"}, "srfpmcixoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b8d50b3932d9502ea509418083aaad3e53bf2bdd"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8cc65d399ad77b981fa6ac7e82619290cbb14fee"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fea78c788a8f4958c7d363286a7e21eb6c980d1b"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=9d40bf06186302942b571a8a1b2700fcee2a8c73"}, "id": "srfpmcixoonc1"}, "t9bl78p0ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad535c60b11882bda501b0d932fb5f985dd16b32"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=774368db1cc103ae0668493d4cc21afcdad792f8"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba00fe429fdfcaab6252bababaadb4a8a10c2242"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=7d099f5af7d1ca24bfa52856709c43528e72074a"}, "id": "t9bl78p0ponc1"}, "owjktc80ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/owjktc80ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=727b3990cc45eb11ac31ade0c92d7e02f2847b5d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/owjktc80ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f20cb939a11ebc8834f6331011100a52ab3346b6"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/owjktc80ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe490a0b54a309074af99c20d1a8adc1eab47841"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/owjktc80ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=52358f94fa0d109ed54361aef2f65002eea4a5a8"}, "id": "owjktc80ponc1"}, "cwuvw1mzoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9dd46c9bcabfdd681a6f2113c705161a57b2195"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c05e08febc3b6ba8aaa317241c43fed35aa8060"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf8631295d73175982163f6fd4cfd5dbad34b1e8"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=bec6d0151aa831fe0142bfc4a9e17d6ec36f34cc"}, "id": "cwuvw1mzoonc1"}}, "name": "t3_1bc0bkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 442, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "evrabedsoonc1", "id": 418735667}, {"media_id": "w8b7lkcuoonc1", "id": 418735668}, {"media_id": "qoyx42ruoonc1", "id": 418735669}, {"media_id": "uwvwzc5voonc1", "id": 418735670}, {"media_id": "nj9t6dywoonc1", "id": 418735671}, {"media_id": "7ermym9xoonc1", "id": 418735672}, {"media_id": "srfpmcixoonc1", "id": 418735673}, {"media_id": "dspzxvpxoonc1", "id": 418735674}, {"media_id": "8uzqh00yoonc1", "id": 418735675}, {"media_id": "quodorcyoonc1", "id": 418735676}, {"media_id": "sgzwkknyoonc1", "id": 418735677}, {"media_id": "ofadp50zoonc1", "id": 418735678}, {"media_id": "wyj984bzoonc1", "id": 418735679}, {"media_id": "cwuvw1mzoonc1", "id": 418735680}, {"media_id": "791h7dwzoonc1", "id": 418735681}, {"media_id": "owjktc80ponc1", "id": 418735682}, {"media_id": "6yfoxeg0ponc1", "id": 418735683}, {"media_id": "t9bl78p0ponc1", "id": 418735684}, {"media_id": "a9fnr6z0ponc1", "id": 418735685}, {"media_id": "t8xzox91ponc1", "id": 418735686}]}, "link_flair_text": "Blog", "can_mod_post": false, "score": 442, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/etpTFumtTb6di2p6Z33-Pj6RXgkiru0d52Q74rTKL_k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710154042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1bc0bkv", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bc0bkv", "is_robot_indexable": true, "report_reasons": null, "author": "InitiativeOk6728", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc0bkv/eli5_what_is_selfservice_analytics_comic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1bc0bkv", "subreddit_subscribers": 167761, "created_utc": 1710154042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I hope your pipelines are atomic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc85h9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/78o9DgkP_VnJTu4T7u9sT2b3UwNzkqGE4Pj1Wv1LGTk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710176504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/h5udr4npkqnc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/h5udr4npkqnc1.png?auto=webp&amp;s=52b57d204f20e48f3cbba13fded30269878a1099", "width": 719, "height": 232}, "resolutions": [{"url": "https://preview.redd.it/h5udr4npkqnc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=02434419197c76f8d153f221a9d299d03da18918", "width": 108, "height": 34}, {"url": "https://preview.redd.it/h5udr4npkqnc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d977e88d2de0fe3586fd0a141464375195c42b2f", "width": 216, "height": 69}, {"url": "https://preview.redd.it/h5udr4npkqnc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a7d98e721022d63a9edcf861fa42b212987a46c", "width": 320, "height": 103}, {"url": "https://preview.redd.it/h5udr4npkqnc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=409c1f0a8055aa2b01142ccecbd2776a9dd02035", "width": 640, "height": 206}], "variants": {}, "id": "BtNu00u40LE1xjtG2VkI-2tMB7zUKIrTFBM8aJ69k2w"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1bc85h9", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc85h9/i_hope_your_pipelines_are_atomic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/h5udr4npkqnc1.png", "subreddit_subscribers": 167761, "created_utc": 1710176504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a DA right now trying to break into data engineering and I was curious how others got into this position? It\u2019s my dream to work as a DE so I\u2019ve learned the below:\n\n* SQL - intermediate. Built scripts that do data quality checks, modularized tasks in stored procedures, transform data, and create import CSV files for my workflow. Learned how to use cursors to rebuild indexes for tables. I know all the fundamentals of SQL. \n* Python - intermediate. Built all kinds of apps (GUIs and using OOP principles) and scripts to automate ETL tasks like data cleaning. Also web scraping. I made some of my tools reusable/portable for my team when it comes to data cleaning. \n* Git/github - basic. I have repos on my GitHub to demonstrate my skills.\n* API - how to get authenticated and extract data and feed it into a reporting/visualization tool through a free API for practice. \n* Scripting and automation\n* continuously enhancing and automating a pipeline I created from the ground up in my current job\n* Currently building a pipeline from the ground up from DB2 to Oracle Database as a recent project that came up at work which should be fun!\n* Read 4-5 Python books and 1 fundamental SQL book. Currently reading fundamentals of DE and an advanced SQL book. \n\nIs there anything else I could learn to be marketable as an entry level DE? I know cloud computing is a good one to learn and probably an orchestration tool. But at my current job I don\u2019t have the option to work with cloud computing and have yet to touch a tool like Airflow.", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How did you become a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc0n1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710156028.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710155255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a DA right now trying to break into data engineering and I was curious how others got into this position? It\u2019s my dream to work as a DE so I\u2019ve learned the below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL - intermediate. Built scripts that do data quality checks, modularized tasks in stored procedures, transform data, and create import CSV files for my workflow. Learned how to use cursors to rebuild indexes for tables. I know all the fundamentals of SQL. &lt;/li&gt;\n&lt;li&gt;Python - intermediate. Built all kinds of apps (GUIs and using OOP principles) and scripts to automate ETL tasks like data cleaning. Also web scraping. I made some of my tools reusable/portable for my team when it comes to data cleaning. &lt;/li&gt;\n&lt;li&gt;Git/github - basic. I have repos on my GitHub to demonstrate my skills.&lt;/li&gt;\n&lt;li&gt;API - how to get authenticated and extract data and feed it into a reporting/visualization tool through a free API for practice. &lt;/li&gt;\n&lt;li&gt;Scripting and automation&lt;/li&gt;\n&lt;li&gt;continuously enhancing and automating a pipeline I created from the ground up in my current job&lt;/li&gt;\n&lt;li&gt;Currently building a pipeline from the ground up from DB2 to Oracle Database as a recent project that came up at work which should be fun!&lt;/li&gt;\n&lt;li&gt;Read 4-5 Python books and 1 fundamental SQL book. Currently reading fundamentals of DE and an advanced SQL book. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is there anything else I could learn to be marketable as an entry level DE? I know cloud computing is a good one to learn and probably an orchestration tool. But at my current job I don\u2019t have the option to work with cloud computing and have yet to touch a tool like Airflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bc0n1z", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc0n1z/how_did_you_become_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bc0n1z/how_did_you_become_a_de/", "subreddit_subscribers": 167761, "created_utc": 1710155255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am a bioinformatician and I've got a genomics pipeline that is a series of python, R and bash scripts. I'm looking to make this pipeline have more capacity to run at scale/repeatedly with ease, and also ideally have some interactive tracking element to watch the jobs run.\n\nOriginally I looked into airflow for this, but I've read that it's not directly compatible with R. Are there any other tools that would best suit my purpose? I've come across mage which says it works with Python and R as I need, but I'm not sure if there's something else that I'm missing.", "author_fullname": "t2_4lmrgjr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best pipeline tool when using Python and R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc1fyk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710158253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am a bioinformatician and I&amp;#39;ve got a genomics pipeline that is a series of python, R and bash scripts. I&amp;#39;m looking to make this pipeline have more capacity to run at scale/repeatedly with ease, and also ideally have some interactive tracking element to watch the jobs run.&lt;/p&gt;\n\n&lt;p&gt;Originally I looked into airflow for this, but I&amp;#39;ve read that it&amp;#39;s not directly compatible with R. Are there any other tools that would best suit my purpose? I&amp;#39;ve come across mage which says it works with Python and R as I need, but I&amp;#39;m not sure if there&amp;#39;s something else that I&amp;#39;m missing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bc1fyk", "is_robot_indexable": true, "report_reasons": null, "author": "bioinfo_ml", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc1fyk/best_pipeline_tool_when_using_python_and_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bc1fyk/best_pipeline_tool_when_using_python_and_r/", "subreddit_subscribers": 167761, "created_utc": 1710158253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors,\n\nI hope you're all doing well! I wanted to share my experience and seek some advice on transitioning into the evolving world of data engineering, specifically in 2024. Here's a bit about my journey so far:\n\nI've been in the tech industry for around six years, initially starting as a Backend Developer (4 years) and gradually shifting my focus to DevOps and Data Engineering tasks the last two years in the role. Afterwards, I landed a full Data Engineering role for the past 2 years. Unfortunately, my team recently faced a layoff, and since then, I've been on the hunt for a new opportunity.\n\nThe challenge I'm facing is the industry's increasing demand for cloud experience and proficiency with modern tools, something I wasn't heavily exposed to in my previous role with on-premise solutions. I've been diligently searching for the past year, with moments of intense effort, followed by a need to recharge after facing rejection or reaching the final rounds only to lose out to someone with more cloud-centric experience.\n\nI would love to hear your thoughts and experiences on how to successfully land a data engineering job in 2024, especially considering my background. I love learning new technologies and usually I'm fast to pick them up, so I'm a bit baffled nobody is willing to give me the opportunity to prove myself as so far I've heard only praise from my superiors and colleagues about the work I've done. What strategies have worked for you in bridging the gap between on-premise and cloud-based solutions? Are there specific tools or certifications you found particularly valuable in making this transition?\n\nHere are a few specific questions to get the discussion started:\n\n1. How crucial is cloud experience in today's data engineering landscape, and which platforms/tools should I prioritize learning?\n2. Any success stories or tips from those who have transitioned from on-premise to cloud-focused roles?\n3. Recommendations for certifications or online courses that can enhance my cloud skills and boost my marketability?\n\nI'm eager to hear your insights and learn from your experiences. Let's support each other in navigating the challenges of the job market and adapting to the ever-changing tech landscape!\n\nThanks in advance for your valuable input!\n\n  \nEdit: How to approach the job market in the EU right now? Where should I look for jobs apart from Linkedin (lately they've been unresponsive)? ", "author_fullname": "t2_jzrkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Navigating the Transition: Landing a Data Engineering Job in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbzhez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710181005.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710150648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well! I wanted to share my experience and seek some advice on transitioning into the evolving world of data engineering, specifically in 2024. Here&amp;#39;s a bit about my journey so far:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been in the tech industry for around six years, initially starting as a Backend Developer (4 years) and gradually shifting my focus to DevOps and Data Engineering tasks the last two years in the role. Afterwards, I landed a full Data Engineering role for the past 2 years. Unfortunately, my team recently faced a layoff, and since then, I&amp;#39;ve been on the hunt for a new opportunity.&lt;/p&gt;\n\n&lt;p&gt;The challenge I&amp;#39;m facing is the industry&amp;#39;s increasing demand for cloud experience and proficiency with modern tools, something I wasn&amp;#39;t heavily exposed to in my previous role with on-premise solutions. I&amp;#39;ve been diligently searching for the past year, with moments of intense effort, followed by a need to recharge after facing rejection or reaching the final rounds only to lose out to someone with more cloud-centric experience.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts and experiences on how to successfully land a data engineering job in 2024, especially considering my background. I love learning new technologies and usually I&amp;#39;m fast to pick them up, so I&amp;#39;m a bit baffled nobody is willing to give me the opportunity to prove myself as so far I&amp;#39;ve heard only praise from my superiors and colleagues about the work I&amp;#39;ve done. What strategies have worked for you in bridging the gap between on-premise and cloud-based solutions? Are there specific tools or certifications you found particularly valuable in making this transition?&lt;/p&gt;\n\n&lt;p&gt;Here are a few specific questions to get the discussion started:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How crucial is cloud experience in today&amp;#39;s data engineering landscape, and which platforms/tools should I prioritize learning?&lt;/li&gt;\n&lt;li&gt;Any success stories or tips from those who have transitioned from on-premise to cloud-focused roles?&lt;/li&gt;\n&lt;li&gt;Recommendations for certifications or online courses that can enhance my cloud skills and boost my marketability?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m eager to hear your insights and learn from your experiences. Let&amp;#39;s support each other in navigating the challenges of the job market and adapting to the ever-changing tech landscape!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your valuable input!&lt;/p&gt;\n\n&lt;p&gt;Edit: How to approach the job market in the EU right now? Where should I look for jobs apart from Linkedin (lately they&amp;#39;ve been unresponsive)? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bbzhez", "is_robot_indexable": true, "report_reasons": null, "author": "Sargaxon", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbzhez/navigating_the_transition_landing_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbzhez/navigating_the_transition_landing_a_data/", "subreddit_subscribers": 167761, "created_utc": 1710150648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have telecom data with more than 3 trillion events per day for device location. The data scales way beyond 1PB per day.   \nI want to create a platform where people can do geospatial analysis.   \nright now the usecase that i'm having is selecting a area on hte map, and getting the list of current devices in that area, which fulfils the required condition like affluence price sensitifity, age etc.  \nRight now we do all the processing using spark, convert coordinates to geohash, and do majority analysis at 7 precision, ohwever, we store most granular data at precision 9   \nThe setup needs to be open source,  \nRight now we use kafka, spark/flink for processing, presto for query engine.\n\nas per my current understanding, i'll select some area on map, and get geometry polygon. I'll need to get coordinates (or geohash) which lies within the geometry from data (based on time).   \nthe underlying data will be at different aggregation level, the lowest aggregation will be at a petabyte scale.  \nI'm trying apache-sedona, and presto native geospatial query currently, has anyone worked on a similar setup.   \nI want this platform to scale and be able to scater to any kind of reports interactively..", "author_fullname": "t2_aacnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to setup a Petabyte scale geospatial analysis data platform. Need help to connect the dots, and choosing the right tech stack (OSS only)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc1njq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710158955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have telecom data with more than 3 trillion events per day for device location. The data scales way beyond 1PB per day.&lt;br/&gt;\nI want to create a platform where people can do geospatial analysis.&lt;br/&gt;\nright now the usecase that i&amp;#39;m having is selecting a area on hte map, and getting the list of current devices in that area, which fulfils the required condition like affluence price sensitifity, age etc.&lt;br/&gt;\nRight now we do all the processing using spark, convert coordinates to geohash, and do majority analysis at 7 precision, ohwever, we store most granular data at precision 9&lt;br/&gt;\nThe setup needs to be open source,&lt;br/&gt;\nRight now we use kafka, spark/flink for processing, presto for query engine.&lt;/p&gt;\n\n&lt;p&gt;as per my current understanding, i&amp;#39;ll select some area on map, and get geometry polygon. I&amp;#39;ll need to get coordinates (or geohash) which lies within the geometry from data (based on time).&lt;br/&gt;\nthe underlying data will be at different aggregation level, the lowest aggregation will be at a petabyte scale.&lt;br/&gt;\nI&amp;#39;m trying apache-sedona, and presto native geospatial query currently, has anyone worked on a similar setup.&lt;br/&gt;\nI want this platform to scale and be able to scater to any kind of reports interactively..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bc1njq", "is_robot_indexable": true, "report_reasons": null, "author": "vigorousvj", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc1njq/need_to_setup_a_petabyte_scale_geospatial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bc1njq/need_to_setup_a_petabyte_scale_geospatial/", "subreddit_subscribers": 167761, "created_utc": 1710158955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have a data engineer intrvw coming up next week and the recruiter told me that it one hour will be technical and the next one hour will be behavioural questions. What kind of behavioural questions i should be expecting? I have a few years experience as a backend developer working in sql server and 2 months of internship experience as a data analyst. This is a career change role for me. Thanks in advance. ", "author_fullname": "t2_a260u37s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the common types of behavioural questions you should expect in an entry level data engineer role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcew7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710192385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a data engineer intrvw coming up next week and the recruiter told me that it one hour will be technical and the next one hour will be behavioural questions. What kind of behavioural questions i should be expecting? I have a few years experience as a backend developer working in sql server and 2 months of internship experience as a data analyst. This is a career change role for me. Thanks in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bcew7i", "is_robot_indexable": true, "report_reasons": null, "author": "Outside_Aide_1958", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcew7i/what_are_the_common_types_of_behavioural/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcew7i/what_are_the_common_types_of_behavioural/", "subreddit_subscribers": 167761, "created_utc": 1710192385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently experimenting with Iceberg, and there are some aspects I don't think I fully understand yet.\n\nThe scenario I'm testing involves a dataset containing a customer's information about purchases and other preferences. I need to remove (masquerade) some of this data to comply with GDPR or similar regulations. Could Iceberg be the right tool for this?\n\nWhat I've done so far is load a set of pre-existing Parquet files into an Iceberg table. This generates an initial snapshot that cannot be expired. Am I mistaken?\n\nIn the following days or months, the dataset grows until I receive requests to remove a customer's information from my database. At that point, I proceed to delete or anonymize these records. Then I manually expire older snapshots. However, if this customer's information was included in the first import, it will always be present in my dataset, correct?\n\nRegarding the statement in the Iceberg docs: \n\n    Data files are not deleted until they are no longer referenced by a snapshot that may be used for time travel or rollback. \n    Regularly expiring snapshots deletes unused data files. \n\nHow can I predict if a Parquet file is referenced or not? Even if I expire a snapshot and the data is no longer queryable with time travel, there is always the possibility that it is present in some Parquet file because it contains other data that has not yet expired.\n\nWhat am I missing here?", "author_fullname": "t2_hrlbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On Apache Iceberg and snapshots expiration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc9ree", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710180355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently experimenting with Iceberg, and there are some aspects I don&amp;#39;t think I fully understand yet.&lt;/p&gt;\n\n&lt;p&gt;The scenario I&amp;#39;m testing involves a dataset containing a customer&amp;#39;s information about purchases and other preferences. I need to remove (masquerade) some of this data to comply with GDPR or similar regulations. Could Iceberg be the right tool for this?&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;ve done so far is load a set of pre-existing Parquet files into an Iceberg table. This generates an initial snapshot that cannot be expired. Am I mistaken?&lt;/p&gt;\n\n&lt;p&gt;In the following days or months, the dataset grows until I receive requests to remove a customer&amp;#39;s information from my database. At that point, I proceed to delete or anonymize these records. Then I manually expire older snapshots. However, if this customer&amp;#39;s information was included in the first import, it will always be present in my dataset, correct?&lt;/p&gt;\n\n&lt;p&gt;Regarding the statement in the Iceberg docs: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Data files are not deleted until they are no longer referenced by a snapshot that may be used for time travel or rollback. \nRegularly expiring snapshots deletes unused data files. \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How can I predict if a Parquet file is referenced or not? Even if I expire a snapshot and the data is no longer queryable with time travel, there is always the possibility that it is present in some Parquet file because it contains other data that has not yet expired.&lt;/p&gt;\n\n&lt;p&gt;What am I missing here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bc9ree", "is_robot_indexable": true, "report_reasons": null, "author": "paturnio", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc9ree/on_apache_iceberg_and_snapshots_expiration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bc9ree/on_apache_iceberg_and_snapshots_expiration/", "subreddit_subscribers": 167761, "created_utc": 1710180355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing Kafka streams in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc5i2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tVXFyCX_-dJhssVFOf1cf6n2mxHKHl3j1q3l6vGvfQo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710169981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pathway.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pathway.com/developers/showcases/kafka-etl", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?auto=webp&amp;s=d2e591ff6dbb9cb10bc64325233703503eacdb56", "width": 1900, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe75367180ba997909829c457b6406043da01067", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=54a9b1f43986b8b767ff8cc2c44dfaf007fe3e17", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=110d981ab9ac21ab0b1a5a5ad70503d69dd69b68", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3a5a6ae77df6c0f03c31f4265190e49159cc9f8d", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36fb2e5a83ad7419493891897bab515209963bd6", "width": 960, "height": 505}, {"url": "https://external-preview.redd.it/Qya13ZDueci4hEVGx695BXZB0r6LosD7w5fJJvmJ_Ig.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa70083f0b9bb3904e6b7eac41e651cc48cb41e8", "width": 1080, "height": 568}], "variants": {}, "id": "pw-nxJmdWofqBYfmipWQy7lr4uOUQIcsksuH7g-SH9A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bc5i2z", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc5i2z/processing_kafka_streams_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pathway.com/developers/showcases/kafka-etl", "subreddit_subscribers": 167761, "created_utc": 1710169981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Founder of Multiwoven ([https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)) here. \n\nMy co-founders and I have a background in product and engineering for Asia population-scale customer data infrastructure and applications - across Affle (3 Bn+ connected devices for consumer\u00a0intelligence-based marketing), Truecaller (\\~400 Mn. MAU) and Razorpay (India's largest payments platform).\n\nWe built Multiwoven as an open source reverse ETL tool for data activation. After our recent repo launch, Multiwoven started being used by data teams to eliminate the complexity and tediousness of building and maintaining data pipelines to third-party biz/marketing/sales tools.\u00a0\n\nFrom our early users and discovery conversations, we quickly started seeing users who have a data warehouse use us like a CDP on top of their warehouse. Many of them were customers and prospects of Salesforce (CRM and/or marketing cloud).\u00a0\n\nThe simple solution that worked for them -\u00a0\n\n1. Easily works with all their tools (not just Salesforce's ecosystem). We are adding roughly two new Connectors every week, and it's also easy to build or customize for someone's own needs (without going through long and expensive professional services)\n\n2. Not being compelled to invest upwards of half a million dollars a year on Salesforce CDP. The Salesforce CDP Starter Pack is at $110K, and doesn't include Segmentation, Audiences and Ad integrations (imagine a CDP without these!)\n\n3. Being able to easily self-host the software (that essentially has access to all their warehouse data) and not worry about jumping through Compliance/InfoSec's\u00a0hoops.\u00a0\n\nGartner recently naming Salesforce CDP a leader in their first Magic Quadrant for CDPs is certainly\u00a0surprising. We're not sure that users feel the same way. We recently released a connector to Salesforce CRM, and Salesforce Marketing Cloud is on the way. We are continuing to furiously build and working to meet users' needs.\n\nAs a young project, we'd love your feedback and support (pls star us on GitHub! [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven))", "author_fullname": "t2_1g3ospki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "we built an open source Salesforce CDP alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bchyko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710199640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Founder of Multiwoven (&lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;) here. &lt;/p&gt;\n\n&lt;p&gt;My co-founders and I have a background in product and engineering for Asia population-scale customer data infrastructure and applications - across Affle (3 Bn+ connected devices for consumer\u00a0intelligence-based marketing), Truecaller (~400 Mn. MAU) and Razorpay (India&amp;#39;s largest payments platform).&lt;/p&gt;\n\n&lt;p&gt;We built Multiwoven as an open source reverse ETL tool for data activation. After our recent repo launch, Multiwoven started being used by data teams to eliminate the complexity and tediousness of building and maintaining data pipelines to third-party biz/marketing/sales tools.\u00a0&lt;/p&gt;\n\n&lt;p&gt;From our early users and discovery conversations, we quickly started seeing users who have a data warehouse use us like a CDP on top of their warehouse. Many of them were customers and prospects of Salesforce (CRM and/or marketing cloud).\u00a0&lt;/p&gt;\n\n&lt;p&gt;The simple solution that worked for them -\u00a0&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Easily works with all their tools (not just Salesforce&amp;#39;s ecosystem). We are adding roughly two new Connectors every week, and it&amp;#39;s also easy to build or customize for someone&amp;#39;s own needs (without going through long and expensive professional services)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Not being compelled to invest upwards of half a million dollars a year on Salesforce CDP. The Salesforce CDP Starter Pack is at $110K, and doesn&amp;#39;t include Segmentation, Audiences and Ad integrations (imagine a CDP without these!)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Being able to easily self-host the software (that essentially has access to all their warehouse data) and not worry about jumping through Compliance/InfoSec&amp;#39;s\u00a0hoops.\u00a0&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Gartner recently naming Salesforce CDP a leader in their first Magic Quadrant for CDPs is certainly\u00a0surprising. We&amp;#39;re not sure that users feel the same way. We recently released a connector to Salesforce CRM, and Salesforce Marketing Cloud is on the way. We are continuing to furiously build and working to meet users&amp;#39; needs.&lt;/p&gt;\n\n&lt;p&gt;As a young project, we&amp;#39;d love your feedback and support (pls star us on GitHub! &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?auto=webp&amp;s=0bc0e93038ef50951c90227649f7f6ab254a7cf4", "width": 2560, "height": 1204}, "resolutions": [{"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17a45a447d842e52652926f6dc817d7170a88986", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e12cc0a1c0d9fd4fd747ed329f19cd30a8124b3b", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=69066e72c75f3b4020a551ac50062213dbdb397c", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a02272300d0676184dcf058494ffd170c121368", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a2b31da90137f24f3433708d44936c2fb49ece3", "width": 960, "height": 451}, {"url": "https://external-preview.redd.it/zn1aIHN6usYjxYHdI-29K_pvaMNN7XXWjnqumLIWWp8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0d7ab5f6e495f29e4f13cc0b5671fcfd8b115e51", "width": 1080, "height": 507}], "variants": {}, "id": "Gn1oZnAX_pLkKE4iHRaNdie9sLvYRt8PUbXOPUT0MUA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bchyko", "is_robot_indexable": true, "report_reasons": null, "author": "wishingchairs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bchyko/we_built_an_open_source_salesforce_cdp_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bchyko/we_built_an_open_source_salesforce_cdp_alternative/", "subreddit_subscribers": 167761, "created_utc": 1710199640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, over the past couple months I've been delving into creating some ELT workflows using Databricks and dbt, but I've recently ran into a use case which is abit less standard, and I'm pretty conflicted around the best way to handle this (even after researching this extensively).\n\nThis sub has been really helpful in my learning so far, so I thought it might be worthwhile seeing if anyone might have any guidance/suggestions on what I should do here.\n\n&amp;#x200B;\n\nBasically, I have an existing frontend app which allows users to insert/update/delete data for a few different Postgres tables (using backend API endpoints). Now that we've setup Databricks, we're required to include these tables alongside our other Databricks data (so it can be joined together).\n\n&amp;#x200B;\n\nAdditionally, some of these tables contain data that comes from other Databricks tables (where these other tables are part of ELT workflows from various sources). For these tables, any changes that come through need to be displayed in this same frontend app.\n\n&amp;#x200B;\n\nFrom my initial understanding, these are my options to handle this:\n\n1. Directly query and modify the Databricks tables from our API endpoints (although I've read this isn't a great idea, and instead I should separate API endpoints from directly interacting with the data warehouse?).\n2. Continue using postgres to store this data, and then setup a job to sync the data between postgres and databricks:\n   1. This would involve syncing all postgres tables into Databricks (which I'm assuming I'd just do using regular ELT loading patterns?)\n   2. And then when one of these Databricks tables is updated, any changes would need to be synced back from Databricks into postgres (where I'm assuming I'd just use a standard SQL database connector?)\n\n&amp;#x200B;\n\nNote latency isn't really an issue here (it's fine if the data shown in the frontend is only synced/refreshed daily), and these tables are quite small in size (biggest one has \\~20,000 rows).\n\n&amp;#x200B;\n\nI've also read briefly that cache layer or CDC might be relevant, but my understand is too limited to know whether this is appropriate for my use case.\n\n&amp;#x200B;\n\nAny help at all would be greatly appreciated, and sorry in advance if this is difficult to understand (am happy to provide more context if helpful).", "author_fullname": "t2_paubn65a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I Separate API Endpoints from Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbxmhe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710142602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, over the past couple months I&amp;#39;ve been delving into creating some ELT workflows using Databricks and dbt, but I&amp;#39;ve recently ran into a use case which is abit less standard, and I&amp;#39;m pretty conflicted around the best way to handle this (even after researching this extensively).&lt;/p&gt;\n\n&lt;p&gt;This sub has been really helpful in my learning so far, so I thought it might be worthwhile seeing if anyone might have any guidance/suggestions on what I should do here.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically, I have an existing frontend app which allows users to insert/update/delete data for a few different Postgres tables (using backend API endpoints). Now that we&amp;#39;ve setup Databricks, we&amp;#39;re required to include these tables alongside our other Databricks data (so it can be joined together).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additionally, some of these tables contain data that comes from other Databricks tables (where these other tables are part of ELT workflows from various sources). For these tables, any changes that come through need to be displayed in this same frontend app.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;From my initial understanding, these are my options to handle this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Directly query and modify the Databricks tables from our API endpoints (although I&amp;#39;ve read this isn&amp;#39;t a great idea, and instead I should separate API endpoints from directly interacting with the data warehouse?).&lt;/li&gt;\n&lt;li&gt;Continue using postgres to store this data, and then setup a job to sync the data between postgres and databricks:\n\n&lt;ol&gt;\n&lt;li&gt;This would involve syncing all postgres tables into Databricks (which I&amp;#39;m assuming I&amp;#39;d just do using regular ELT loading patterns?)&lt;/li&gt;\n&lt;li&gt;And then when one of these Databricks tables is updated, any changes would need to be synced back from Databricks into postgres (where I&amp;#39;m assuming I&amp;#39;d just use a standard SQL database connector?)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note latency isn&amp;#39;t really an issue here (it&amp;#39;s fine if the data shown in the frontend is only synced/refreshed daily), and these tables are quite small in size (biggest one has ~20,000 rows).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also read briefly that cache layer or CDC might be relevant, but my understand is too limited to know whether this is appropriate for my use case.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help at all would be greatly appreciated, and sorry in advance if this is difficult to understand (am happy to provide more context if helpful).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bbxmhe", "is_robot_indexable": true, "report_reasons": null, "author": "HauntingPlate3639", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbxmhe/should_i_separate_api_endpoints_from_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbxmhe/should_i_separate_api_endpoints_from_databricks/", "subreddit_subscribers": 167761, "created_utc": 1710142602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1- In production, what's the best approach ? To create and delete cluster with each job or use the existing one ! \n\n2- if we go for using existing cuslter and restart and stop approch then if 3 teams accessing same cluster then how to stop cluster only after completion  of 3 different jobs ?\n\nWhat happens in real world production pipelines ?\n\n\n", "author_fullname": "t2_6i4bdifz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP dataproc cluster related question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbwnbq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710138406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;1- In production, what&amp;#39;s the best approach ? To create and delete cluster with each job or use the existing one ! &lt;/p&gt;\n\n&lt;p&gt;2- if we go for using existing cuslter and restart and stop approch then if 3 teams accessing same cluster then how to stop cluster only after completion  of 3 different jobs ?&lt;/p&gt;\n\n&lt;p&gt;What happens in real world production pipelines ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbwnbq", "is_robot_indexable": true, "report_reasons": null, "author": "24aryannayak24", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbwnbq/gcp_dataproc_cluster_related_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbwnbq/gcp_dataproc_cluster_related_question/", "subreddit_subscribers": 167761, "created_utc": 1710138406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don\u2019t get it, I have a pretty good internet connection. I have one DAG in the AirFlow and it is so slow, what could it be??", "author_fullname": "t2_og6pufokg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow is so slow with one only dag!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcmrya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710212592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t get it, I have a pretty good internet connection. I have one DAG in the AirFlow and it is so slow, what could it be??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcmrya", "is_robot_indexable": true, "report_reasons": null, "author": "Taptinnn", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcmrya/airflow_is_so_slow_with_one_only_dag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcmrya/airflow_is_so_slow_with_one_only_dag/", "subreddit_subscribers": 167761, "created_utc": 1710212592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gmelb8os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse to Lakehouse Evolution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcihcy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1710200920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "iomete.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://iomete.com/resources/blog/from-data-warehouses-to-data-lakehouses", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcihcy", "is_robot_indexable": true, "report_reasons": null, "author": "Single_Brother_1791", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcihcy/data_warehouse_to_lakehouse_evolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://iomete.com/resources/blog/from-data-warehouses-to-data-lakehouses", "subreddit_subscribers": 167761, "created_utc": 1710200920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is the exam? I am considering to take it. But there are less resources available online. \n\nHave anyone take it? Mind sharing some inputs?", "author_fullname": "t2_ush6wu0ww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have anyone taken dbt analytics engineering certification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbzmpj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710151285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is the exam? I am considering to take it. But there are less resources available online. &lt;/p&gt;\n\n&lt;p&gt;Have anyone take it? Mind sharing some inputs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bbzmpj", "is_robot_indexable": true, "report_reasons": null, "author": "Data-dude-00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbzmpj/have_anyone_taken_dbt_analytics_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbzmpj/have_anyone_taken_dbt_analytics_engineering/", "subreddit_subscribers": 167761, "created_utc": 1710151285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a client who currently categorizes data in a spreadsheet. When new data appears, they need to assign a category.\n\nAs we move them to a warehouse, I'd love to give them a way to notice data that needs to be assigned a category + an easy way to assign. \n\nThey are in the Microsoft ecosystem.\n\nSeems like this should be a common need, what the standard operating procedure here?", "author_fullname": "t2_vfx4v6x3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SOP for enabling end users to enrich data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bclc8c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710208501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a client who currently categorizes data in a spreadsheet. When new data appears, they need to assign a category.&lt;/p&gt;\n\n&lt;p&gt;As we move them to a warehouse, I&amp;#39;d love to give them a way to notice data that needs to be assigned a category + an easy way to assign. &lt;/p&gt;\n\n&lt;p&gt;They are in the Microsoft ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Seems like this should be a common need, what the standard operating procedure here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bclc8c", "is_robot_indexable": true, "report_reasons": null, "author": "KnightoftheDadBod", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bclc8c/sop_for_enabling_end_users_to_enrich_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bclc8c/sop_for_enabling_end_users_to_enrich_data/", "subreddit_subscribers": 167761, "created_utc": 1710208501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need help. I have been working on Abinito . Recently an opportunity came for me to work on azure data bricks. we will be moving some of the on prem jobs . For this purpose i have done certification in Azure and databricks as well.  Have no experience on Python. Does anyone know of any online course where i can get chance to create 1 or 2 projects where data ingestion using ADF and transformations in Databricks using scala or pyspark. ", "author_fullname": "t2_t0zkmfpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data bricks  live project ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcijs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710201085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help. I have been working on Abinito . Recently an opportunity came for me to work on azure data bricks. we will be moving some of the on prem jobs . For this purpose i have done certification in Azure and databricks as well.  Have no experience on Python. Does anyone know of any online course where i can get chance to create 1 or 2 projects where data ingestion using ADF and transformations in Databricks using scala or pyspark. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bcijs0", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible_Mud5318", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcijs0/azure_data_bricks_live_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcijs0/azure_data_bricks_live_project/", "subreddit_subscribers": 167761, "created_utc": 1710201085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12e8nx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expedock replicates data from Postgres to Snowflake with &lt;1 min latency and 5x cost savings with PeerDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcch7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5NZ7qIq9blMa9skGD-J8yvYEVMH2VSmbHAgAdoJwkms.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710186776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "peerdb.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.peerdb.io/customers/expedock-customer-story", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?auto=webp&amp;s=8806dea13c3b6fedc9156ec74afc5cb2ede87a35", "width": 1600, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c0a13e4a1a8f139569811457f17e2e097504b20", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2db139849ca3d9dc4e9cdbc4c1b1163de238b70d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5813ab59ac5d588ad375b3bf9c412e43964ad6f0", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7800d7c2aac9cc434d1db6295a950cb509fc5251", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49d824cb8d79efef93c8c042b3672d49d1990c43", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Sllcxk_mYC1XENhlZITAWDK4rLO8pvTmZyBgvN5Xz1Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3babcac3c57dfc31923ed0e634f2987a28ff515", "width": 1080, "height": 567}], "variants": {}, "id": "T7-sdcyVeQPqKIYovMULxE17ttt1B3SN4kwiQQs4zCU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bcch7b", "is_robot_indexable": true, "report_reasons": null, "author": "assaxor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcch7b/expedock_replicates_data_from_postgres_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.peerdb.io/customers/expedock-customer-story", "subreddit_subscribers": 167761, "created_utc": 1710186776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you treat data integrations separate of analytics/data warehousing?  Meaning do you have a IPaaS and team managing integrations (i.e. application to application), and another team managing ETL/ELT and Data Warehousing?  Obviously there\u2019s a lot of overlap in functionality, not necessarily in tooling or processes.  I understand the nuances and differences, but often leadership doesn\u2019t.  If you have successfully merged those disciplines, can you talk about how you did that and the tools you used?", "author_fullname": "t2_2zc375tc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integration Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc3u16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710181533.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710165534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you treat data integrations separate of analytics/data warehousing?  Meaning do you have a IPaaS and team managing integrations (i.e. application to application), and another team managing ETL/ELT and Data Warehousing?  Obviously there\u2019s a lot of overlap in functionality, not necessarily in tooling or processes.  I understand the nuances and differences, but often leadership doesn\u2019t.  If you have successfully merged those disciplines, can you talk about how you did that and the tools you used?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bc3u16", "is_robot_indexable": true, "report_reasons": null, "author": "Heyohz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc3u16/integration_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bc3u16/integration_platform/", "subreddit_subscribers": 167761, "created_utc": 1710165534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, could the community kindly advise on how to address data type inconsistencies after merging a dbt model? Here's a little background:  following the creation of a staging model that explicitly casts each field, I ensure that \"dbt build\" completes successfully and subsequently execute \"dbt sql\" to validate the records. The dbt extension in VSCode defaults to 500 records for this process. If this subset of data looks accurate, a pull request (PR) is created. However, we are currently facing an issue with records that violate the defined data types, aside from the 500 records displayed. This becomes apparent only after executing a \"select \\* from\" query on the table. This approach seems a bit heavy-handed, and I'm confident that there is a more programmatic way to handle this. ", "author_fullname": "t2_4igjulzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validating data types before merging a dbt model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bce00m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710190293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, could the community kindly advise on how to address data type inconsistencies after merging a dbt model? Here&amp;#39;s a little background:  following the creation of a staging model that explicitly casts each field, I ensure that &amp;quot;dbt build&amp;quot; completes successfully and subsequently execute &amp;quot;dbt sql&amp;quot; to validate the records. The dbt extension in VSCode defaults to 500 records for this process. If this subset of data looks accurate, a pull request (PR) is created. However, we are currently facing an issue with records that violate the defined data types, aside from the 500 records displayed. This becomes apparent only after executing a &amp;quot;select * from&amp;quot; query on the table. This approach seems a bit heavy-handed, and I&amp;#39;m confident that there is a more programmatic way to handle this. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bce00m", "is_robot_indexable": true, "report_reasons": null, "author": "South-Ambassador2326", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bce00m/validating_data_types_before_merging_a_dbt_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bce00m/validating_data_types_before_merging_a_dbt_model/", "subreddit_subscribers": 167761, "created_utc": 1710190293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the DE situation in Montreal at the moment, or sentiment for future? I know they\u2019re pretty strict on what an engineer means. How do DE positions advertise to circumvent this? Any experience would be appreciated ", "author_fullname": "t2_abcjorif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job situation in QC, Canada", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcbj0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710184568.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the DE situation in Montreal at the moment, or sentiment for future? I know they\u2019re pretty strict on what an engineer means. How do DE positions advertise to circumvent this? Any experience would be appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bcbj0k", "is_robot_indexable": true, "report_reasons": null, "author": "FreeTrout", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcbj0k/job_situation_in_qc_canada/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcbj0k/job_situation_in_qc_canada/", "subreddit_subscribers": 167761, "created_utc": 1710184568.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you guys think about this course?\nI've been doing it, but I would like to know what's your opinion? Have you heard about it?\n\n", "author_fullname": "t2_hbw3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions about this course ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc78mk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A32zKjzntH6J9kVmGQ-pfMVF_PuvEGZVr7oHE_ATU0c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710174320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you guys think about this course?\nI&amp;#39;ve been doing it, but I would like to know what&amp;#39;s your opinion? Have you heard about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/DataTalksClub/data-engineering-zoomcamp", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?auto=webp&amp;s=3437640a3c59bf998cafe7703257b5dde50b8436", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d50bebdf53c1703135dd6047f54c45bb739c5b10", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7db727f811fd50528f444193acaeb5032bbe5e7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b4f2fca270d6cb049666c56ffeca32cde88654a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=64f401f76557f7a74fb7e3f1c36ff76cde471e58", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6722fc9563ae713191053057e8e4518ec239ed99", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aQIE9DkWz8p3AYI8kt2csmLzvj8IfVl74Nfor8wKHUk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6fd299c3de730de8506c7df692eabe9904f90e1b", "width": 1080, "height": 540}], "variants": {}, "id": "UBDq04c88VRezUlKTzb9jASexnZQE6v_UicYTC9qHpQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bc78mk", "is_robot_indexable": true, "report_reasons": null, "author": "Blast06", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc78mk/opinions_about_this_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/DataTalksClub/data-engineering-zoomcamp", "subreddit_subscribers": 167761, "created_utc": 1710174320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a project wherein we need to fetch data from ALDS Gen 2 to Excel via API.\n\nMy question, is it faster to read 5 out of 5 columns from the source compared to reading 5 columns from a total of 100 columns? \n\nI'm thinking wether to create a separate data model for the application or the silver layer (which contains more columns) would suffice.\n\nThank you in advance.", "author_fullname": "t2_ap5f9vbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API get data which one is faster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcnb0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710214140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a project wherein we need to fetch data from ALDS Gen 2 to Excel via API.&lt;/p&gt;\n\n&lt;p&gt;My question, is it faster to read 5 out of 5 columns from the source compared to reading 5 columns from a total of 100 columns? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking wether to create a separate data model for the application or the silver layer (which contains more columns) would suffice.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bcnb0v", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Gur9574", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bcnb0v/api_get_data_which_one_is_faster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcnb0v/api_get_data_which_one_is_faster/", "subreddit_subscribers": 167761, "created_utc": 1710214140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After 2.9 years of experience in data engineering at a firm, I sat for a coding round for senior data engineer.\n\nTo my surprise, I found out that coding rounds mean SQL rounds for data engineer profile. \nI was all prepared for coding questions and it all went under the drain.\n\nI ended the call within 15 minutes as there was no point of continuing. Talked to HR as well about the misunderstanding. I don't have much hope for a rescheduled round though.\n\nIs this a general norm or the company was special enough to test in this manner?\nIdeally technical rounds can have SQL which is a basic requirement of a DE profile but coding rounds should have coding questions only.\n\nI have a call with another firm tomorrow so going through all SQL concepts tonight. Wish me luck.", "author_fullname": "t2_74dgs38c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clarity about interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bc3oqi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710165115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After 2.9 years of experience in data engineering at a firm, I sat for a coding round for senior data engineer.&lt;/p&gt;\n\n&lt;p&gt;To my surprise, I found out that coding rounds mean SQL rounds for data engineer profile. \nI was all prepared for coding questions and it all went under the drain.&lt;/p&gt;\n\n&lt;p&gt;I ended the call within 15 minutes as there was no point of continuing. Talked to HR as well about the misunderstanding. I don&amp;#39;t have much hope for a rescheduled round though.&lt;/p&gt;\n\n&lt;p&gt;Is this a general norm or the company was special enough to test in this manner?\nIdeally technical rounds can have SQL which is a basic requirement of a DE profile but coding rounds should have coding questions only.&lt;/p&gt;\n\n&lt;p&gt;I have a call with another firm tomorrow so going through all SQL concepts tonight. Wish me luck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bc3oqi", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPaintings8455", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc3oqi/clarity_about_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bc3oqi/clarity_about_interviews/", "subreddit_subscribers": 167761, "created_utc": 1710165115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI am planning to move to DE, in order to start learning, I\u2019d like to have some advices. As I am currently working with Microsoft PowerBi, should I follow the Azure DE or go with the on premise stack, like the stacks that are in the Zoombootcamp ?\n\nThanks", "author_fullname": "t2_bnqvpnvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which DE stack ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bcatsa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.2, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710182929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I am planning to move to DE, in order to start learning, I\u2019d like to have some advices. As I am currently working with Microsoft PowerBi, should I follow the Azure DE or go with the on premise stack, like the stacks that are in the Zoombootcamp ?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bcatsa", "is_robot_indexable": true, "report_reasons": null, "author": "Mr-Wedge01", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bcatsa/which_de_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bcatsa/which_de_stack/", "subreddit_subscribers": 167761, "created_utc": 1710182929.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}