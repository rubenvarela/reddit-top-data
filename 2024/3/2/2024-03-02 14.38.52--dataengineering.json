{"kind": "Listing", "data": {"after": "t3_1b3v3ue", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been wondering why there are so many ETL tools out there when we already have Python and SQL. What do these tools offer that Python and SQL don't? Would love to hear your thoughts and experiences on this.\n\nAnd yes, as a junior I\u2019m completely open to the idea I\u2019m wrong about this\ud83d\ude02", "author_fullname": "t2_ukaxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are there so many ETL tools when we have SQL and Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b44v59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 191, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 191, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709336581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709325572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wondering why there are so many ETL tools out there when we already have Python and SQL. What do these tools offer that Python and SQL don&amp;#39;t? Would love to hear your thoughts and experiences on this.&lt;/p&gt;\n\n&lt;p&gt;And yes, as a junior I\u2019m completely open to the idea I\u2019m wrong about this\ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b44v59", "is_robot_indexable": true, "report_reasons": null, "author": "dildan101", "discussion_type": null, "num_comments": 99, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b44v59/why_are_there_so_many_etl_tools_when_we_have_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b44v59/why_are_there_so_many_etl_tools_when_we_have_sql/", "subreddit_subscribers": 165169, "created_utc": 1709325572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Bull case:** AI is taking off. There will be new tools all over the place. Companies will need to port data around to use it in new ways not possible today. Data will become a big differentiator for products driving its value up. The need for data migrations is going to increase and the opportunity to streamline data management tools will increase accordingly.\n\n**To discuss:** Do we agree with this bull case? Are the golden days of data engineering ahead of us? What can we do to capitalize on this opportunity? If we disagree then what am I missing?", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are we entering a boom time for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b43j0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709323408.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709322439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Bull case:&lt;/strong&gt; AI is taking off. There will be new tools all over the place. Companies will need to port data around to use it in new ways not possible today. Data will become a big differentiator for products driving its value up. The need for data migrations is going to increase and the opportunity to streamline data management tools will increase accordingly.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;To discuss:&lt;/strong&gt; Do we agree with this bull case? Are the golden days of data engineering ahead of us? What can we do to capitalize on this opportunity? If we disagree then what am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b43j0z", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b43j0z/are_we_entering_a_boom_time_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b43j0z/are_we_entering_a_boom_time_for_data_engineering/", "subreddit_subscribers": 165169, "created_utc": 1709322439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\n\nThis is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.\n\n# [Submit your salary here](https://tally.so/r/nraYkN)\n\nYou can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).\n\n&amp;#x200B;\n\nIf you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:\n\n1. Current title\n2. Years of experience (YOE)\n3. Location\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n5. Bonuses/Equity (optional)\n6. Industry (optional)\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion - Mar 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo", "t3_13xldpd", "t3_167b3ep", "t3_188grde", "t3_1b3zatv"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1709312446.881, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ia7kdykk8dlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=814f58d3eef18e16ebfd881a24dc42c6278c74a5"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=220aef8c88d2d3542556dbc0ceda11308fae54cd"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc0f5873d0a5e748e4664a4925eb409775331c20"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd"}, "id": "ia7kdykk8dlb1"}}, "name": "t3_1b3zatv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 82, "domain": "self.dataengineering", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/WxbPZZDAlp5ZrmC7zINz_BAGO251Q2TbQDAOSYvGspE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709312446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\"&gt;https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://tally.so/r/nraYkN\"&gt;Submit your salary here&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can view and analyze all of the data on our &lt;a href=\"https://dataengineering.wiki/Community/Salaries\"&gt;DE salary page&lt;/a&gt; and get involved with this open-source project &lt;a href=\"https://github.com/data-engineering-community/data-engineering-salaries\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Current title&lt;/li&gt;\n&lt;li&gt;Years of experience (YOE)&lt;/li&gt;\n&lt;li&gt;Location&lt;/li&gt;\n&lt;li&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/li&gt;\n&lt;li&gt;Bonuses/Equity (optional)&lt;/li&gt;\n&lt;li&gt;Industry (optional)&lt;/li&gt;\n&lt;li&gt;Tech stack (optional)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?auto=webp&amp;s=c116639b0e48888e352e060ba2c5f56c07ab43d9", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab73c993eac3ccefd58966d64ec6e5a5dd05f808", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1955a17c66a64ef42bfc6aa52227a3b0a183660b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfad0ea778337cf0589b3428603d1e71cff228fb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a6b65e67a3bcf61b738f8852810c86c1b01298f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b95d64dc6f3995876325c594dbe2dd77c627d406", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=079bd9b9cebe8cd705d7824f7f2a75c5213c3cf7", "width": 1080, "height": 567}], "variants": {}, "id": "vXOF8G9GBUU_-_vM38jf2S1-5UiTZqBcFWecpk4eHS4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b3zatv", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 84, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3zatv/quarterly_salary_discussion_mar_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/1b3zatv/quarterly_salary_discussion_mar_2024/", "subreddit_subscribers": 165169, "created_utc": 1709312446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys just wanted to share that you can grab 150$ coupon and take the airflow fundamentals certification for free \n\nUse coupon\n\"m-fundamentals-free-cert\" \n\nHappy weekend guys ! ", "author_fullname": "t2_allygchr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "150$ Coupon for Airflow certification ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b427r1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709319265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys just wanted to share that you can grab 150$ coupon and take the airflow fundamentals certification for free &lt;/p&gt;\n\n&lt;p&gt;Use coupon\n&amp;quot;m-fundamentals-free-cert&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Happy weekend guys ! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b427r1", "is_robot_indexable": true, "report_reasons": null, "author": "_T0fuu_", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b427r1/150_coupon_for_airflow_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b427r1/150_coupon_for_airflow_certification/", "subreddit_subscribers": 165169, "created_utc": 1709319265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am investigating current ELT/ETL tools like airbyte, cloudquery, fivetran etc. and all of them seems to be very complicated to setup and maintain locally due to their architecture with different types of containers and moving parts.\n\nIs this complexity really worth it? As a user do you think a simpler alternative like a single executable be better? What are your thoughts about the usage experience and maintainability?", "author_fullname": "t2_20n43h6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about current ELT/ETL tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3vdae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709302750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am investigating current ELT/ETL tools like airbyte, cloudquery, fivetran etc. and all of them seems to be very complicated to setup and maintain locally due to their architecture with different types of containers and moving parts.&lt;/p&gt;\n\n&lt;p&gt;Is this complexity really worth it? As a user do you think a simpler alternative like a single executable be better? What are your thoughts about the usage experience and maintainability?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3vdae", "is_robot_indexable": true, "report_reasons": null, "author": "gibriyagi", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3vdae/thoughts_about_current_eltetl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3vdae/thoughts_about_current_eltetl_tools/", "subreddit_subscribers": 165169, "created_utc": 1709302750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\ni'm currently responsible for building a database out of research data, this is my first data engineering task.  \nThe data in general is a bunch (magnitude 100) of 1GB CSV-Files, with groups of files (\\~10) being the result of a different analysis &amp; aggregation of 10 different base corpoa with extremly similar structure. The task is to parse these into a DB (including some more custom aggregations and restructuring) in order to build a visualization on top of it - and i don't know what my tooling should be.\n\nSo far i've been working in pandas, but it's no fun. I've been developing on a subset of files, one for each group, and a subslice of each of these files (around 10MB), but scaling it up to the full files breaks, because:  it's very messy data with unexpected missing values, different column names, encodings. One run for one group takes \"forever\" (\\~1h) on the large files until i get the result \"breaking in step X\", then i'd debug this, write another edge-case-treatment and re-run (sometimes looping this for a whole day), so i'm making extreme slow process.\n\nAny tips / literature on how to build such a system more efficiently / less painfully? Does it just take that long and i should tune down my expectations?\n\n  \n**Edit for additional information:** It's a one-off task, resources are 16GB RAM &amp; 8 Cores, the concrete operations are as well joins between the files on dirty columns (with e.g. entities that exist only in one file, different string schemas for the same entity, ... ) as also inner-file computations and it's expected to drop faulty data but write them in a clean report for others to investigate. ", "author_fullname": "t2_295e63iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficiently developing a pipeline for large, messy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3xuan", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709329314.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709308972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m currently responsible for building a database out of research data, this is my first data engineering task.&lt;br/&gt;\nThe data in general is a bunch (magnitude 100) of 1GB CSV-Files, with groups of files (~10) being the result of a different analysis &amp;amp; aggregation of 10 different base corpoa with extremly similar structure. The task is to parse these into a DB (including some more custom aggregations and restructuring) in order to build a visualization on top of it - and i don&amp;#39;t know what my tooling should be.&lt;/p&gt;\n\n&lt;p&gt;So far i&amp;#39;ve been working in pandas, but it&amp;#39;s no fun. I&amp;#39;ve been developing on a subset of files, one for each group, and a subslice of each of these files (around 10MB), but scaling it up to the full files breaks, because:  it&amp;#39;s very messy data with unexpected missing values, different column names, encodings. One run for one group takes &amp;quot;forever&amp;quot; (~1h) on the large files until i get the result &amp;quot;breaking in step X&amp;quot;, then i&amp;#39;d debug this, write another edge-case-treatment and re-run (sometimes looping this for a whole day), so i&amp;#39;m making extreme slow process.&lt;/p&gt;\n\n&lt;p&gt;Any tips / literature on how to build such a system more efficiently / less painfully? Does it just take that long and i should tune down my expectations?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit for additional information:&lt;/strong&gt; It&amp;#39;s a one-off task, resources are 16GB RAM &amp;amp; 8 Cores, the concrete operations are as well joins between the files on dirty columns (with e.g. entities that exist only in one file, different string schemas for the same entity, ... ) as also inner-file computations and it&amp;#39;s expected to drop faulty data but write them in a clean report for others to investigate. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3xuan", "is_robot_indexable": true, "report_reasons": null, "author": "leehawk787", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3xuan/efficiently_developing_a_pipeline_for_large_messy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3xuan/efficiently_developing_a_pipeline_for_large_messy/", "subreddit_subscribers": 165169, "created_utc": 1709308972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just as the title says, how much web scraping would someone be able to do on twitter.com before it flags it as some bot/automated process and either ip bans or blocks the connection in the way they do?", "author_fullname": "t2_39utoy9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How aggressive is Twitter against web scrapers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b45r0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709327659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just as the title says, how much web scraping would someone be able to do on twitter.com before it flags it as some bot/automated process and either ip bans or blocks the connection in the way they do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b45r0c", "is_robot_indexable": true, "report_reasons": null, "author": "scuffed12s", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b45r0c/how_aggressive_is_twitter_against_web_scrapers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b45r0c/how_aggressive_is_twitter_against_web_scrapers/", "subreddit_subscribers": 165169, "created_utc": 1709327659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Off-the-shelf data ingestion works great about 80% of the time. The other 20% is where good data engineers make all the difference.\n\nAt Y42, we've released Python ETL connectors to cater to the \"other 20%\", next to our existing Airbyte-, Fivetran-, and proprietary ingestion capabilities. The goal of this new feature is to:\n\n* implement custom ingestion logic,\n* remove boilerplate code to load data into your data warehouse,\n* get standardized metadata, lineage, and documentation out of the box.\n\nCheck out the demo video, very curious about your feedback: [https://www.youtube.com/watch?v=L252iaNylbo](https://www.youtube.com/watch?v=L252iaNylbo).  \n\n\nTo those who want to read more about it, check out the announcement post: [https://www.y42.com/blog/announcing-python-ingest](https://www.y42.com/blog/announcing-python-ingest).  \n\n\nThanks!", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Video] Custom Python ETL connector demo - feedback welcome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b439j6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709321813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Off-the-shelf data ingestion works great about 80% of the time. The other 20% is where good data engineers make all the difference.&lt;/p&gt;\n\n&lt;p&gt;At Y42, we&amp;#39;ve released Python ETL connectors to cater to the &amp;quot;other 20%&amp;quot;, next to our existing Airbyte-, Fivetran-, and proprietary ingestion capabilities. The goal of this new feature is to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;implement custom ingestion logic,&lt;/li&gt;\n&lt;li&gt;remove boilerplate code to load data into your data warehouse,&lt;/li&gt;\n&lt;li&gt;get standardized metadata, lineage, and documentation out of the box.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Check out the demo video, very curious about your feedback: &lt;a href=\"https://www.youtube.com/watch?v=L252iaNylbo\"&gt;https://www.youtube.com/watch?v=L252iaNylbo&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;To those who want to read more about it, check out the announcement post: &lt;a href=\"https://www.y42.com/blog/announcing-python-ingest\"&gt;https://www.y42.com/blog/announcing-python-ingest&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?auto=webp&amp;s=32f39757a24572d005ede61580ab0010f73257f9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d4373ae44796353a1e1e47398abc4cf8cf623dd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ffe4f55585d3e5367d6bb0d761d10f0b5afe1e1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e79b68cac8c8831bc27815b85aa2a82b53fbb45", "width": 320, "height": 240}], "variants": {}, "id": "vliEb2ghOCgafwl3iTha8feyMIA_S18KUF_iT9G1AD8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b439j6", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b439j6/video_custom_python_etl_connector_demo_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b439j6/video_custom_python_etl_connector_demo_feedback/", "subreddit_subscribers": 165169, "created_utc": 1709321813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Deep Dive into the Concept and World of Apache Iceberg Catalogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3x4gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l5R7hYeS0BgR22x8GabW0H58QTRPpMjpvJ7jFfesShY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709307251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.datalakehouse.help", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.datalakehouse.help/a-deep-dive-into-the-concept-and-world-of-apache-iceberg-catalogs-c948a2cc25ea", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?auto=webp&amp;s=a98cd9729792a2e9da9ea7f49f8712980209a990", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5ae4f44f81b57fca6b6ef8a47f1af98463cc77", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d1233462d388b3390922ddc523a16b9074dccfb", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=867b8fb3b00177c591d4cd984ef8905fb8d1b107", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce04bf58cef436b78021e3513df38859675055fd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4cd0b16862184899a6ad57b7140c3b12741dfd31", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5195cbcb70a112d6069d20e7706afe21a168455d", "width": 1080, "height": 607}], "variants": {}, "id": "ls8ypxuJ6z3tA7HbOD4Z3GTMQhWB7rVZyH3BwXIunEU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3x4gx", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3x4gx/a_deep_dive_into_the_concept_and_world_of_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.datalakehouse.help/a-deep-dive-into-the-concept-and-world-of-apache-iceberg-catalogs-c948a2cc25ea", "subreddit_subscribers": 165169, "created_utc": 1709307251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3qpsfp70", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mistral AI, Klarna AI customer support agent, extract and load still unsolved", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4n50k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WEJPt2FzuFZnoXNluIHC-2TMSyaaGkmUB4VJd8cZGvI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709382380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blef.fr", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.blef.fr/data-news-week-24-09/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?auto=webp&amp;s=2c582ffb719685be75072e2ad3165658a96e0e7c", "width": 2500, "height": 1667}, "resolutions": [{"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff3a6beeb29af9738698f43405c5ef7c03630cb3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f48117d3f5966230ea0f1006394aad85b2551e4", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bbdd4e39c0c3ca26d2e72aa2c67fb44231f12b68", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=332c5b5d7e8f6cc6dec5cd676adb963f3aee3efb", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7985ea0e8108b3f58c869fc531dbf572b6cebc69", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=823626cdd2dd3679a122dbc651c511446ea8cd5d", "width": 1080, "height": 720}], "variants": {}, "id": "_8UH2w59fyHSlLr2L65k-Njp35XnnrWQYTWT62hAk2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b4n50k", "is_robot_indexable": true, "report_reasons": null, "author": "mrocral", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4n50k/mistral_ai_klarna_ai_customer_support_agent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.blef.fr/data-news-week-24-09/", "subreddit_subscribers": 165169, "created_utc": 1709382380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been wondering if anyone's using their Lakehouse for stuff beyond the usual the reporting and BI use-cases in the gold layer. It feels like everyone refers to the to the gold layer as being just for facts and dimensions, pretty much just standard Kimball warehouse stuff. But what about other uses?\n\nSpecifically, I'm looking into serving data for analytical web apps. These are not just simple reports but full-blown applications with a UI, an API, and a back-end running in Docker Containers on K8s. They would rely heavily on data in the Lakehouse, mostly from the silver layer, and wouldn't really generate much data on their own. There may be some exceptions where user input is written, but it would be a very little amount of data.\n\nI can't imagine that they best approach for this would keeping all this data in the Lakehouse, like in Delta Format. Wouldn't it make more sense to move this data into something like a Postgres DB, or even MongoDB, especially for serving it up through an API to the front-end?\n\nWould love to hear if anyone is currently supporting these types of use-cases on their platform.\n\nThanks!", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beyond Reporting in a Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b46sye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709330174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wondering if anyone&amp;#39;s using their Lakehouse for stuff beyond the usual the reporting and BI use-cases in the gold layer. It feels like everyone refers to the to the gold layer as being just for facts and dimensions, pretty much just standard Kimball warehouse stuff. But what about other uses?&lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m looking into serving data for analytical web apps. These are not just simple reports but full-blown applications with a UI, an API, and a back-end running in Docker Containers on K8s. They would rely heavily on data in the Lakehouse, mostly from the silver layer, and wouldn&amp;#39;t really generate much data on their own. There may be some exceptions where user input is written, but it would be a very little amount of data.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t imagine that they best approach for this would keeping all this data in the Lakehouse, like in Delta Format. Wouldn&amp;#39;t it make more sense to move this data into something like a Postgres DB, or even MongoDB, especially for serving it up through an API to the front-end?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear if anyone is currently supporting these types of use-cases on their platform.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b46sye", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b46sye/beyond_reporting_in_a_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b46sye/beyond_reporting_in_a_lakehouse/", "subreddit_subscribers": 165169, "created_utc": 1709330174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you all please suggest what are some good sources to understand salary trends for data scientist, engineering or even data analysts? - preferably with over the years data as well.\n\nMany thanks for all your suggestions.", "author_fullname": "t2_143jjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4fngj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709354301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you all please suggest what are some good sources to understand salary trends for data scientist, engineering or even data analysts? - preferably with over the years data as well.&lt;/p&gt;\n\n&lt;p&gt;Many thanks for all your suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b4fngj", "is_robot_indexable": true, "report_reasons": null, "author": "Jay12a", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4fngj/salary_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4fngj/salary_reports/", "subreddit_subscribers": 165169, "created_utc": 1709354301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The podcast touches on so many interesting topics including Postgres, Open Source, Migrations, Replication,\u00a0 Data Movement, Building Fault Tolerant Enterprise-grade systems, PeerDB and so on. Loved the way Scott navigated through each of these topics and create story. Totally worth a watch!\n\n[https://open.spotify.com/episode/3jZu78eH79aat9UozoHWIQ?si=Ow2mF2h9TB2d6EeH4UmfIQ&amp;nd=1&amp;dlsi=317bc349bf314f1f](https://open.spotify.com/episode/3jZu78eH79aat9UozoHWIQ?si=Ow2mF2h9TB2d6EeH4UmfIQ&amp;nd=1&amp;dlsi=317bc349bf314f1f)", "author_fullname": "t2_6emw6kn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scott Hanselman Interviews Sai Srirampur from PeerDB on Postgres Replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b41mly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709317867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The podcast touches on so many interesting topics including Postgres, Open Source, Migrations, Replication,\u00a0 Data Movement, Building Fault Tolerant Enterprise-grade systems, PeerDB and so on. Loved the way Scott navigated through each of these topics and create story. Totally worth a watch!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://open.spotify.com/episode/3jZu78eH79aat9UozoHWIQ?si=Ow2mF2h9TB2d6EeH4UmfIQ&amp;amp;nd=1&amp;amp;dlsi=317bc349bf314f1f\"&gt;https://open.spotify.com/episode/3jZu78eH79aat9UozoHWIQ?si=Ow2mF2h9TB2d6EeH4UmfIQ&amp;amp;nd=1&amp;amp;dlsi=317bc349bf314f1f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BN4RvcWWIERW_-_QNldK12HaVyqc1boOm6tbiNjtz1c.jpg?auto=webp&amp;s=616911337679272b8aee7a16377552b8c731ab98", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/BN4RvcWWIERW_-_QNldK12HaVyqc1boOm6tbiNjtz1c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c12b1b99468e31d5469ccb4b76253c4cc3bbc25e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/BN4RvcWWIERW_-_QNldK12HaVyqc1boOm6tbiNjtz1c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7724da3d375cb177a9162b228aa9b3e16b97396f", "width": 216, "height": 216}], "variants": {}, "id": "JMGjqlB8SRI9T_GdrZRwpSHYN_TecicKNI59bFfp7Es"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b41mly", "is_robot_indexable": true, "report_reasons": null, "author": "Natrium999", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b41mly/scott_hanselman_interviews_sai_srirampur_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b41mly/scott_hanselman_interviews_sai_srirampur_from/", "subreddit_subscribers": 165169, "created_utc": 1709317867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data Engineers!\n\nWe're launching, the IOMETE Community Edition on AWS, and looking for insightful testers like you. This is your golden ticket to experience our scalable data lakehouse platform, designed to transform terabytes to petabytes of data, absolutely free.\u00a0You'll be amazed by what you can achieve with our platform.\n\nWe're excited to see how users experiment with the platform by Leveraging Apache Iceberg and Spark for a managed data lakehouse that grows with your data\u2014from terabytes to petabytes\u2014without any vendor lock-in. Enjoy complete control over your data stored in S3 in parquet format, and pay only for the AWS resources you use. Whether you're using Spot or Reserved Instances, IOMETE ensures an affordable path compared to other vendors. Ready to transform your data management strategy?\n\nIOMETE offers several Apache Spark features including:\n\n1. A user-friendly interface and integrated notebook service for data processing and analysis.\n2. Comprehensive monitoring and debugging capabilities for Spark jobs.\n3. Automatic scaling of Spark clusters based on demand.\n4. Capabilities to process real-time data streams from various sources.\n5. A platform for training and deploying machine learning models for tasks like predictive analytics, fraud detection, and customer segmentation.\n\nThese features are designed to help you focus on your data analytics workloads by taking care of the infrastructure and management tasks associated with running Spark - [https://2ly.link/1wFi0](https://2ly.link/1wFi0)\n\nIntrigued? A short video awaits you to guide you through the details and the wonders that IOMETE Community Edition promises - [https://2ly.link/1wFi3](https://2ly.link/1wFi3)\n\nIf you have any questions regarding installation and usage, join our dedicated Discord community, and let's shape the future of data management together - [https://2ly.link/1wFi1](https://2ly.link/1wFi1)\n\nAs of now, the IOMETE Free Community Version can only be deployed on AWS. Please let us know where you would like to deploy the platform so we can prioritize it - [https://2ly.link/1wFi2](https://2ly.link/1wFi2) . We will let you know when your preferred deployment option becomes available", "author_fullname": "t2_9ftsfde7l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IOMETE released the most generous free Data Lakehouse platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3xfzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709308027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Engineers!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re launching, the IOMETE Community Edition on AWS, and looking for insightful testers like you. This is your golden ticket to experience our scalable data lakehouse platform, designed to transform terabytes to petabytes of data, absolutely free.\u00a0You&amp;#39;ll be amazed by what you can achieve with our platform.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re excited to see how users experiment with the platform by Leveraging Apache Iceberg and Spark for a managed data lakehouse that grows with your data\u2014from terabytes to petabytes\u2014without any vendor lock-in. Enjoy complete control over your data stored in S3 in parquet format, and pay only for the AWS resources you use. Whether you&amp;#39;re using Spot or Reserved Instances, IOMETE ensures an affordable path compared to other vendors. Ready to transform your data management strategy?&lt;/p&gt;\n\n&lt;p&gt;IOMETE offers several Apache Spark features including:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A user-friendly interface and integrated notebook service for data processing and analysis.&lt;/li&gt;\n&lt;li&gt;Comprehensive monitoring and debugging capabilities for Spark jobs.&lt;/li&gt;\n&lt;li&gt;Automatic scaling of Spark clusters based on demand.&lt;/li&gt;\n&lt;li&gt;Capabilities to process real-time data streams from various sources.&lt;/li&gt;\n&lt;li&gt;A platform for training and deploying machine learning models for tasks like predictive analytics, fraud detection, and customer segmentation.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These features are designed to help you focus on your data analytics workloads by taking care of the infrastructure and management tasks associated with running Spark - &lt;a href=\"https://2ly.link/1wFi0\"&gt;https://2ly.link/1wFi0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Intrigued? A short video awaits you to guide you through the details and the wonders that IOMETE Community Edition promises - &lt;a href=\"https://2ly.link/1wFi3\"&gt;https://2ly.link/1wFi3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you have any questions regarding installation and usage, join our dedicated Discord community, and let&amp;#39;s shape the future of data management together - &lt;a href=\"https://2ly.link/1wFi1\"&gt;https://2ly.link/1wFi1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As of now, the IOMETE Free Community Version can only be deployed on AWS. Please let us know where you would like to deploy the platform so we can prioritize it - &lt;a href=\"https://2ly.link/1wFi2\"&gt;https://2ly.link/1wFi2&lt;/a&gt; . We will let you know when your preferred deployment option becomes available&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b3xfzr", "is_robot_indexable": true, "report_reasons": null, "author": "IOMETE-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3xfzr/iomete_released_the_most_generous_free_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3xfzr/iomete_released_the_most_generous_free_data/", "subreddit_subscribers": 165169, "created_utc": 1709308027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which is for beginners and covers all important topics with hands on experience ", "author_fullname": "t2_umxhnmq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I know on this subs wiki there are enough resources are shared but is there any full fledged course on Udemy or Coursera that covers most concepts of DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b4oyzg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709388159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which is for beginners and covers all important topics with hands on experience &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4oyzg", "is_robot_indexable": true, "report_reasons": null, "author": "perfektenschlagggg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4oyzg/i_know_on_this_subs_wiki_there_are_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4oyzg/i_know_on_this_subs_wiki_there_are_enough/", "subreddit_subscribers": 165169, "created_utc": 1709388159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,  \nSoon I will be joining a new project, seen the board and there is an user story of \"Verify and test spark connectivity\", with no further description. It will take place on Synapse. How would you approach this task? I know I can ask but I've just passed client technical review and wont necessarily go with such question day 1 what did he meant or so. I mean I'll probably go but after doing something on my own and then report that I did this and that and what else he except of me in regards of this user story but I have no idea what to do.. The admin most likely will deploy Synapse spark pool and what, should I just create a notebook in development tab and see if I can execute dataframe creation, read and write using pyspark? This user story has at least 2 story points if I remember correctly which is 1 day, so It cannot be that quick, can it? Thank you in advance for your help!\n\n  \nTL;DR: How to you make sure you have good connectivity of spark in Synapse, how do you test and verify that?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verify and test spark connectivity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4mxaf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709384265.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709381640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nSoon I will be joining a new project, seen the board and there is an user story of &amp;quot;Verify and test spark connectivity&amp;quot;, with no further description. It will take place on Synapse. How would you approach this task? I know I can ask but I&amp;#39;ve just passed client technical review and wont necessarily go with such question day 1 what did he meant or so. I mean I&amp;#39;ll probably go but after doing something on my own and then report that I did this and that and what else he except of me in regards of this user story but I have no idea what to do.. The admin most likely will deploy Synapse spark pool and what, should I just create a notebook in development tab and see if I can execute dataframe creation, read and write using pyspark? This user story has at least 2 story points if I remember correctly which is 1 day, so It cannot be that quick, can it? Thank you in advance for your help!&lt;/p&gt;\n\n&lt;p&gt;TL;DR: How to you make sure you have good connectivity of spark in Synapse, how do you test and verify that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4mxaf", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4mxaf/verify_and_test_spark_connectivity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4mxaf/verify_and_test_spark_connectivity/", "subreddit_subscribers": 165169, "created_utc": 1709381640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone share their experience and tech stacks used dealing with these three above. Automation experience will be a plus! Really interested to know what\u2019s the workaround ppl are using to streamline the ETL process to BI reporting / dashboards.", "author_fullname": "t2_vp3nqhfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAP ECC, S/4 HANA and ARIBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4k4hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709370691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone share their experience and tech stacks used dealing with these three above. Automation experience will be a plus! Really interested to know what\u2019s the workaround ppl are using to streamline the ETL process to BI reporting / dashboards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4k4hr", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway-765431", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4k4hr/sap_ecc_s4_hana_and_ariba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4k4hr/sap_ecc_s4_hana_and_ariba/", "subreddit_subscribers": 165169, "created_utc": 1709370691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any recommendations for materials, e.g., blog/textbook, to help with resource planning and design/architecture for cloud migration?", "author_fullname": "t2_6cc9wqbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recs for materials to help with cloud migration resource planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4gdam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709356620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any recommendations for materials, e.g., blog/textbook, to help with resource planning and design/architecture for cloud migration?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4gdam", "is_robot_indexable": true, "report_reasons": null, "author": "Cultured_dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4gdam/recs_for_materials_to_help_with_cloud_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4gdam/recs_for_materials_to_help_with_cloud_migration/", "subreddit_subscribers": 165169, "created_utc": 1709356620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Better yet, what am I actually looking for here?\n\nI\u2019m designing a system that handles schedules in a novel way that, based on our review, isn\u2019t offered elsewhere. Honestly the magic boils down to just a handful of presentation choices and feature integrations.\n\nI\u2019m using a relational database and the data, for the most part, fits the model well. One thing that stands out is tasks though\u2026 The tasks have a serial order to them meaning that one gets started only after the prior finishes.\n\nI need to support a query that, given a task and a location, the response is the number of incomplete upstream tasks. This is done by getting all incomplete tasks with an expected start date of less than the given task, within the given location, and returning the count of records.\n\nHowever, tasks are global\u2026 Every single space has the same tasks. Therefore, the serial order for tasks is also global. It\u2019s wasted effort to slice to tasks within the given location, recalculating which are upstream every time as based on a date column. \n\nI could just artificially maintain a serial order column within a tasks table. Values would just count upward, and I as the user would just insert them this way. This is an implicitly maintained rule that\u2019s critical for the system\u2019s functionality though\u2026 I think not.\n\nThen there are trigger functions which likely can be used very effectively. However, they carry a negative connotation due to undesired side effects. It can be difficult to reason about the synergic behavior of relational and functional capabilities at large scale, and humans bite the bullet here eventually. I\u2019d like to avoid triggers if possible.\n\nAre there data models that support this kind of precedence between entities more naturally? \n\nAre there data models that blur the line between relational and what I\u2019m looking for, potentially solving both needs at the same time?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do relational databases offer a way to require serial order from manually entered data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4e5fn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709349550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Better yet, what am I actually looking for here?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m designing a system that handles schedules in a novel way that, based on our review, isn\u2019t offered elsewhere. Honestly the magic boils down to just a handful of presentation choices and feature integrations.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m using a relational database and the data, for the most part, fits the model well. One thing that stands out is tasks though\u2026 The tasks have a serial order to them meaning that one gets started only after the prior finishes.&lt;/p&gt;\n\n&lt;p&gt;I need to support a query that, given a task and a location, the response is the number of incomplete upstream tasks. This is done by getting all incomplete tasks with an expected start date of less than the given task, within the given location, and returning the count of records.&lt;/p&gt;\n\n&lt;p&gt;However, tasks are global\u2026 Every single space has the same tasks. Therefore, the serial order for tasks is also global. It\u2019s wasted effort to slice to tasks within the given location, recalculating which are upstream every time as based on a date column. &lt;/p&gt;\n\n&lt;p&gt;I could just artificially maintain a serial order column within a tasks table. Values would just count upward, and I as the user would just insert them this way. This is an implicitly maintained rule that\u2019s critical for the system\u2019s functionality though\u2026 I think not.&lt;/p&gt;\n\n&lt;p&gt;Then there are trigger functions which likely can be used very effectively. However, they carry a negative connotation due to undesired side effects. It can be difficult to reason about the synergic behavior of relational and functional capabilities at large scale, and humans bite the bullet here eventually. I\u2019d like to avoid triggers if possible.&lt;/p&gt;\n\n&lt;p&gt;Are there data models that support this kind of precedence between entities more naturally? &lt;/p&gt;\n\n&lt;p&gt;Are there data models that blur the line between relational and what I\u2019m looking for, potentially solving both needs at the same time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4e5fn", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4e5fn/do_relational_databases_offer_a_way_to_require/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4e5fn/do_relational_databases_offer_a_way_to_require/", "subreddit_subscribers": 165169, "created_utc": 1709349550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My client in healthcare uses a hardware device that generates data and saves it into the VM of the hardware manufacturer. The generated data is about 10gb per file. Is there a way to automatically move these files to my own computer? The next step would be to monitor a folder in my computer to upload the file to S3 using multipart upload, but first, the files need to be there in the first place. Any advice would be appreciated. \n", "author_fullname": "t2_tln2vge3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate data extraction from external VM to my computer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4dnze", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709348099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My client in healthcare uses a hardware device that generates data and saves it into the VM of the hardware manufacturer. The generated data is about 10gb per file. Is there a way to automatically move these files to my own computer? The next step would be to monitor a folder in my computer to upload the file to S3 using multipart upload, but first, the files need to be there in the first place. Any advice would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4dnze", "is_robot_indexable": true, "report_reasons": null, "author": "TheQuiteMind", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4dnze/how_to_automate_data_extraction_from_external_vm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4dnze/how_to_automate_data_extraction_from_external_vm/", "subreddit_subscribers": 165169, "created_utc": 1709348099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all - I'll cut right to the chase: I am working on mentoring a mid-level data dev on skills development, and I could use some advice on where to focus. They mentioned gaining skill in the areas of using python (presumably in the context of notebooks and such) as well as sql. They are also pursuing a snowflake certification.\n\nTo give some context on me: I am a very experienced full stack developer and application/cloud architect on large-scale systems. I am conversant in data, and have built some basic ETL/ELTs, Azure Data Pipelines, relational query tuning, and some work with data lakes. That's enough to know what I don't know about data, if that makes sense.\n\nAny tips on where to focus as it relates to the above skills? Any other thoughts welcome as well - TIA!", "author_fullname": "t2_dnexpjr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Training advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b44616", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709323913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all - I&amp;#39;ll cut right to the chase: I am working on mentoring a mid-level data dev on skills development, and I could use some advice on where to focus. They mentioned gaining skill in the areas of using python (presumably in the context of notebooks and such) as well as sql. They are also pursuing a snowflake certification.&lt;/p&gt;\n\n&lt;p&gt;To give some context on me: I am a very experienced full stack developer and application/cloud architect on large-scale systems. I am conversant in data, and have built some basic ETL/ELTs, Azure Data Pipelines, relational query tuning, and some work with data lakes. That&amp;#39;s enough to know what I don&amp;#39;t know about data, if that makes sense.&lt;/p&gt;\n\n&lt;p&gt;Any tips on where to focus as it relates to the above skills? Any other thoughts welcome as well - TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b44616", "is_robot_indexable": true, "report_reasons": null, "author": "leetcde", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b44616/training_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b44616/training_advice_needed/", "subreddit_subscribers": 165169, "created_utc": 1709323913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Mar 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu", "t3_188grkl", "t3_18w0y5n", "t3_1agfqy9", "t3_1b3zb2c"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1709312460.253, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3zb2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709312460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?auto=webp&amp;s=f4aed4accb9b09c9fa81e95e6c52cf3c300fc962", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=255dedc032e49c49b0c4e8f8bb181adc3f7d5295", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f605bcb5e19d3a5c71a81ce00990e7b65f81e52d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac789c54fffcb874c262f4c470d6c034806f8960", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=89ecd9f44728ccd7762c0517d3f0cb495c78c6be", "width": 640, "height": 333}], "variants": {}, "id": "ImrjwYWlQQdcm31jLkEiQbVgLMUnfCK0dT44FpXjpjI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3zb2c", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3zb2c/monthly_general_discussion_mar_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/1b3zb2c/monthly_general_discussion_mar_2024/", "subreddit_subscribers": 165169, "created_utc": 1709312460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v5q74o4dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Video Podcast] No longer a pipe dream \u2014 Gen AI and Data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3ytu1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "No longer a pipe dream \u2014 GenAI and Data pipelines [Cloud Masters #110]", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "DoiT International", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W4HrEz10J9M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@doitintl"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1b3ytu1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hFn5qCv6XLo-WE18ph_n37gprtc0G_j7rtnUzg4Bfew.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709311342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=W4HrEz10J9M&amp;list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss&amp;index=2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?auto=webp&amp;s=5e53e9190808d23549ae9d2875bac69ddb86791d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf266c414a5bf05efabe55f297ef7b5a6eba2a66", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ed7fdca7bcf7297fef2d10774f949a0a3628f6", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4cac4a382fe34529a6d1ea1f88639b0e9c35bcd", "width": 320, "height": 240}], "variants": {}, "id": "xduYiEOi5zVPnZXHY3v5vVr6W8i4vt-CxnOMopjjnUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3ytu1", "is_robot_indexable": true, "report_reasons": null, "author": "LLMaooooooo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3ytu1/video_podcast_no_longer_a_pipe_dream_gen_ai_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=W4HrEz10J9M&amp;list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss&amp;index=2", "subreddit_subscribers": 165169, "created_utc": 1709311342.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "No longer a pipe dream \u2014 GenAI and Data pipelines [Cloud Masters #110]", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "DoiT International", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W4HrEz10J9M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@doitintl"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did someone ever try to do that? Does it look feasible?", "author_fullname": "t2_q4pfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Host airbyte on SiteGround via manual installation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4l8qj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709375206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did someone ever try to do that? Does it look feasible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4l8qj", "is_robot_indexable": true, "report_reasons": null, "author": "F041", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4l8qj/host_airbyte_on_siteground_via_manual_installation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4l8qj/host_airbyte_on_siteground_via_manual_installation/", "subreddit_subscribers": 165169, "created_utc": 1709375206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\udd25 New Article @ Tela Network\n\nPostgreSQL: Protect schemas against accidental deletion\n\n[https://telablog.com/postgresql-protect-schemas-against-accidental-deletion](https://telablog.com/postgresql-protect-schemas-against-accidental-deletion)\n\n\ud83d\udc49 There is a risk of accidentally deleting an important schema whenever we interact with a PostgreSQL server.\n\n\ud83d\udc49 We want to add a protective guardrail that prevents accidental deletion.\n\n\ud83d\udc49 We create an event trigger that fires when the DROP SCHEMA command is entered.", "author_fullname": "t2_46tlcjz3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PostgreSQL: Protect schemas against accidental deletion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3v3ue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709302052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udd25 New Article @ Tela Network&lt;/p&gt;\n\n&lt;p&gt;PostgreSQL: Protect schemas against accidental deletion&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://telablog.com/postgresql-protect-schemas-against-accidental-deletion\"&gt;https://telablog.com/postgresql-protect-schemas-against-accidental-deletion&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc49 There is a risk of accidentally deleting an important schema whenever we interact with a PostgreSQL server.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc49 We want to add a protective guardrail that prevents accidental deletion.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc49 We create an event trigger that fires when the DROP SCHEMA command is entered.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?auto=webp&amp;s=975a6bcde79f529ec129d699f8409a9b286861c3", "width": 630, "height": 453}, "resolutions": [{"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aa32bb93cad95f6e2cfd72151be0bfb909066cb", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35712222711f2186f600b7062158da4ec1fad92a", "width": 216, "height": 155}, {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=448c26ecdb1120d348a7c7857a528381ac0aabf5", "width": 320, "height": 230}], "variants": {}, "id": "1LFo4RaOds-V5iIDcqED1C0usKQRMLUDV_VKhGkZwcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3v3ue", "is_robot_indexable": true, "report_reasons": null, "author": "stjohn_piano", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3v3ue/postgresql_protect_schemas_against_accidental/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3v3ue/postgresql_protect_schemas_against_accidental/", "subreddit_subscribers": 165169, "created_utc": 1709302052.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}