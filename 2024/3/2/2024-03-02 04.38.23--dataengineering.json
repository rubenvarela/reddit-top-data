{"kind": "Listing", "data": {"after": "t3_1b3pi32", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been wondering why there are so many ETL tools out there when we already have Python and SQL. What do these tools offer that Python and SQL don't? Would love to hear your thoughts and experiences on this.\n\nAnd yes, as a junior I\u2019m completely open to the idea I\u2019m wrong about this\ud83d\ude02", "author_fullname": "t2_ukaxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are there so many ETL tools when we have SQL and Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b44v59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 114, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 114, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709336581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709325572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wondering why there are so many ETL tools out there when we already have Python and SQL. What do these tools offer that Python and SQL don&amp;#39;t? Would love to hear your thoughts and experiences on this.&lt;/p&gt;\n\n&lt;p&gt;And yes, as a junior I\u2019m completely open to the idea I\u2019m wrong about this\ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b44v59", "is_robot_indexable": true, "report_reasons": null, "author": "dildan101", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b44v59/why_are_there_so_many_etl_tools_when_we_have_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b44v59/why_are_there_so_many_etl_tools_when_we_have_sql/", "subreddit_subscribers": 165066, "created_utc": 1709325572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\n\nThis is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.\n\n# [Submit your salary here](https://tally.so/r/nraYkN)\n\nYou can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).\n\n&amp;#x200B;\n\nIf you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:\n\n1. Current title\n2. Years of experience (YOE)\n3. Location\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n5. Bonuses/Equity (optional)\n6. Industry (optional)\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion - Mar 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo", "t3_13xldpd", "t3_167b3ep", "t3_188grde", "t3_1b3zatv"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1709312446.881, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ia7kdykk8dlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=814f58d3eef18e16ebfd881a24dc42c6278c74a5"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=220aef8c88d2d3542556dbc0ceda11308fae54cd"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc0f5873d0a5e748e4664a4925eb409775331c20"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;format=png&amp;auto=webp&amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd"}, "id": "ia7kdykk8dlb1"}}, "name": "t3_1b3zatv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 63, "domain": "self.dataengineering", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/WxbPZZDAlp5ZrmC7zINz_BAGO251Q2TbQDAOSYvGspE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709312446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd\"&gt;https://preview.redd.it/ia7kdykk8dlb1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5cbb667f30e089119bae1fcb2922ffac0700aecd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://tally.so/r/nraYkN\"&gt;Submit your salary here&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can view and analyze all of the data on our &lt;a href=\"https://dataengineering.wiki/Community/Salaries\"&gt;DE salary page&lt;/a&gt; and get involved with this open-source project &lt;a href=\"https://github.com/data-engineering-community/data-engineering-salaries\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Current title&lt;/li&gt;\n&lt;li&gt;Years of experience (YOE)&lt;/li&gt;\n&lt;li&gt;Location&lt;/li&gt;\n&lt;li&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/li&gt;\n&lt;li&gt;Bonuses/Equity (optional)&lt;/li&gt;\n&lt;li&gt;Industry (optional)&lt;/li&gt;\n&lt;li&gt;Tech stack (optional)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?auto=webp&amp;s=c116639b0e48888e352e060ba2c5f56c07ab43d9", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab73c993eac3ccefd58966d64ec6e5a5dd05f808", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1955a17c66a64ef42bfc6aa52227a3b0a183660b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfad0ea778337cf0589b3428603d1e71cff228fb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a6b65e67a3bcf61b738f8852810c86c1b01298f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b95d64dc6f3995876325c594dbe2dd77c627d406", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9JrMWnyLH45NI82ZgN6XJSnuyGowISPugiZ5F46YMbE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=079bd9b9cebe8cd705d7824f7f2a75c5213c3cf7", "width": 1080, "height": 567}], "variants": {}, "id": "vXOF8G9GBUU_-_vM38jf2S1-5UiTZqBcFWecpk4eHS4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b3zatv", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 67, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3zatv/quarterly_salary_discussion_mar_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/1b3zatv/quarterly_salary_discussion_mar_2024/", "subreddit_subscribers": 165066, "created_utc": 1709312446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Bull case:** AI is taking off. There will be new tools all over the place. Companies will need to port data around to use it in new ways not possible today. Data will become a big differentiator for products driving its value up. The need for data migrations is going to increase and the opportunity to streamline data management tools will increase accordingly.\n\n**To discuss:** Do we agree with this bull case? Are the golden days of data engineering ahead of us? What can we do to capitalize on this opportunity? If we disagree then what am I missing?", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are we entering a boom time for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b43j0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709323408.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709322439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Bull case:&lt;/strong&gt; AI is taking off. There will be new tools all over the place. Companies will need to port data around to use it in new ways not possible today. Data will become a big differentiator for products driving its value up. The need for data migrations is going to increase and the opportunity to streamline data management tools will increase accordingly.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;To discuss:&lt;/strong&gt; Do we agree with this bull case? Are the golden days of data engineering ahead of us? What can we do to capitalize on this opportunity? If we disagree then what am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b43j0z", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b43j0z/are_we_entering_a_boom_time_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b43j0z/are_we_entering_a_boom_time_for_data_engineering/", "subreddit_subscribers": 165066, "created_utc": 1709322439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, asking for guidance as my company wanted to migrate to cloud. Currently our process is:\n1. Collect multiple excel files from sharepoint\n2. Transform it thru python code\n3. Store it as a parquet in sharepoint\n4. Feed the parquets to Power BI and more transformation is done in Power Query.\n\nNow, they want to use Talend as ETL solution then use SQL to connect it to PBI but I\u2019m not sure how well it will handle the job we do thru python. The process is done around once a week and it would be helpful if we can have those process automated. They have looked into procuring Azure but they said that Talend is more budget friendly. Are we doing the right thing? I thought what we would need the most is a data warehouse. ", "author_fullname": "t2_57luzhesi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company wants to migrate to cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3mntn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709271381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, asking for guidance as my company wanted to migrate to cloud. Currently our process is:\n1. Collect multiple excel files from sharepoint\n2. Transform it thru python code\n3. Store it as a parquet in sharepoint\n4. Feed the parquets to Power BI and more transformation is done in Power Query.&lt;/p&gt;\n\n&lt;p&gt;Now, they want to use Talend as ETL solution then use SQL to connect it to PBI but I\u2019m not sure how well it will handle the job we do thru python. The process is done around once a week and it would be helpful if we can have those process automated. They have looked into procuring Azure but they said that Talend is more budget friendly. Are we doing the right thing? I thought what we would need the most is a data warehouse. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3mntn", "is_robot_indexable": true, "report_reasons": null, "author": "akanensan", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3mntn/company_wants_to_migrate_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3mntn/company_wants_to_migrate_to_cloud/", "subreddit_subscribers": 165066, "created_utc": 1709271381.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys just wanted to share that you can grab 150$ coupon and take the airflow fundamentals certification for free \n\nUse coupon\n\"m-fundamentals-free-cert\" \n\nHappy weekend guys ! ", "author_fullname": "t2_allygchr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "150$ Coupon for Airflow certification ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b427r1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709319265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys just wanted to share that you can grab 150$ coupon and take the airflow fundamentals certification for free &lt;/p&gt;\n\n&lt;p&gt;Use coupon\n&amp;quot;m-fundamentals-free-cert&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Happy weekend guys ! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b427r1", "is_robot_indexable": true, "report_reasons": null, "author": "_T0fuu_", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b427r1/150_coupon_for_airflow_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b427r1/150_coupon_for_airflow_certification/", "subreddit_subscribers": 165066, "created_utc": 1709319265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! I got some great help when asking about a similar topic on Reddit before so wanted to see some perspectives on this.   \n\n\nI am working in a databricks environment where my team feels like it's hard to get a good setup for the projects structure and good code quality in our notebooks. For some reason, even though the notebooks are basically run top-down when running processing jobs with them, it's harder to get good code in notebooks. Does anyone have the same experience?   \n\n\nAre there any given best practices when coding notebooks for spark jobs or similar processing? And how would we create a structure (like grouping folders with code by level of refinement in medallion for example, so one folder for the code used for creating bronze, one for silver and so on) to make the code make more sense? It's not a very large scale project either.\n\n&amp;#x200B;\n\nAny thoughts appreciated! ", "author_fullname": "t2_7fu4vx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices on notebook-based project structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3p36n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709280526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! I got some great help when asking about a similar topic on Reddit before so wanted to see some perspectives on this.   &lt;/p&gt;\n\n&lt;p&gt;I am working in a databricks environment where my team feels like it&amp;#39;s hard to get a good setup for the projects structure and good code quality in our notebooks. For some reason, even though the notebooks are basically run top-down when running processing jobs with them, it&amp;#39;s harder to get good code in notebooks. Does anyone have the same experience?   &lt;/p&gt;\n\n&lt;p&gt;Are there any given best practices when coding notebooks for spark jobs or similar processing? And how would we create a structure (like grouping folders with code by level of refinement in medallion for example, so one folder for the code used for creating bronze, one for silver and so on) to make the code make more sense? It&amp;#39;s not a very large scale project either.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts appreciated! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3p36n", "is_robot_indexable": true, "report_reasons": null, "author": "Maxxlax", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3p36n/best_practices_on_notebookbased_project_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3p36n/best_practices_on_notebookbased_project_structure/", "subreddit_subscribers": 165066, "created_utc": 1709280526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am investigating current ELT/ETL tools like airbyte, cloudquery, fivetran etc. and all of them seems to be very complicated to setup and maintain locally due to their architecture with different types of containers and moving parts.\n\nIs this complexity really worth it? As a user do you think a simpler alternative like a single executable be better? What are your thoughts about the usage experience and maintainability?", "author_fullname": "t2_20n43h6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about current ELT/ETL tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3vdae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709302750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am investigating current ELT/ETL tools like airbyte, cloudquery, fivetran etc. and all of them seems to be very complicated to setup and maintain locally due to their architecture with different types of containers and moving parts.&lt;/p&gt;\n\n&lt;p&gt;Is this complexity really worth it? As a user do you think a simpler alternative like a single executable be better? What are your thoughts about the usage experience and maintainability?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3vdae", "is_robot_indexable": true, "report_reasons": null, "author": "gibriyagi", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3vdae/thoughts_about_current_eltetl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3vdae/thoughts_about_current_eltetl_tools/", "subreddit_subscribers": 165066, "created_utc": 1709302750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm talking about something more in-depth than ERD diagrams. Possibly includes some graph theory analysis like the centrality of a table etc. Something that shows the flow of data linked by stored procedures, connections based on keys, list of triggers/keys/constraints. I've been working with SSMS/Azure Data Factory and I don't see anything on the market that currently fits my needs.   \n\n\n&amp;#x200B;", "author_fullname": "t2_xzn0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools do you guys use for schema analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3m3lh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709269528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m talking about something more in-depth than ERD diagrams. Possibly includes some graph theory analysis like the centrality of a table etc. Something that shows the flow of data linked by stored procedures, connections based on keys, list of triggers/keys/constraints. I&amp;#39;ve been working with SSMS/Azure Data Factory and I don&amp;#39;t see anything on the market that currently fits my needs.   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3m3lh", "is_robot_indexable": true, "report_reasons": null, "author": "richhoods", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3m3lh/what_tools_do_you_guys_use_for_schema_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3m3lh/what_tools_do_you_guys_use_for_schema_analysis/", "subreddit_subscribers": 165066, "created_utc": 1709269528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\ni'm currently responsible for building a database out of research data, this is my first data engineering task.  \nThe data in general is a bunch (magnitude 100) of 1GB CSV-Files, with groups of files (\\~10) being the result of a different analysis &amp; aggregation of 10 different base corpoa with extremly similar structure. The task is to parse these into a DB (including some more custom aggregations and restructuring) in order to build a visualization on top of it - and i don't know what my tooling should be.\n\nSo far i've been working in pandas, but it's no fun. I've been developing on a subset of files, one for each group, and a subslice of each of these files (around 10MB), but scaling it up to the full files breaks, because:  it's very messy data with unexpected missing values, different column names, encodings. One run for one group takes \"forever\" (\\~1h) on the large files until i get the result \"breaking in step X\", then i'd debug this, write another edge-case-treatment and re-run (sometimes looping this for a whole day), so i'm making extreme slow process.\n\nAny tips / literature on how to build such a system more efficiently / less painfully? Does it just take that long and i should tune down my expectations?\n\n  \n**Edit for additional information:** It's a one-off task, resources are 16GB RAM &amp; 8 Cores, the concrete operations are as well joins between the files on dirty columns (with e.g. entities that exist only in one file, different string schemas for the same entity, ... ) as also inner-file computations and it's expected to drop faulty data but write them in a clean report for others to investigate. ", "author_fullname": "t2_295e63iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficiently developing a pipeline for large, messy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3xuan", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709329314.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709308972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m currently responsible for building a database out of research data, this is my first data engineering task.&lt;br/&gt;\nThe data in general is a bunch (magnitude 100) of 1GB CSV-Files, with groups of files (~10) being the result of a different analysis &amp;amp; aggregation of 10 different base corpoa with extremly similar structure. The task is to parse these into a DB (including some more custom aggregations and restructuring) in order to build a visualization on top of it - and i don&amp;#39;t know what my tooling should be.&lt;/p&gt;\n\n&lt;p&gt;So far i&amp;#39;ve been working in pandas, but it&amp;#39;s no fun. I&amp;#39;ve been developing on a subset of files, one for each group, and a subslice of each of these files (around 10MB), but scaling it up to the full files breaks, because:  it&amp;#39;s very messy data with unexpected missing values, different column names, encodings. One run for one group takes &amp;quot;forever&amp;quot; (~1h) on the large files until i get the result &amp;quot;breaking in step X&amp;quot;, then i&amp;#39;d debug this, write another edge-case-treatment and re-run (sometimes looping this for a whole day), so i&amp;#39;m making extreme slow process.&lt;/p&gt;\n\n&lt;p&gt;Any tips / literature on how to build such a system more efficiently / less painfully? Does it just take that long and i should tune down my expectations?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit for additional information:&lt;/strong&gt; It&amp;#39;s a one-off task, resources are 16GB RAM &amp;amp; 8 Cores, the concrete operations are as well joins between the files on dirty columns (with e.g. entities that exist only in one file, different string schemas for the same entity, ... ) as also inner-file computations and it&amp;#39;s expected to drop faulty data but write them in a clean report for others to investigate. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3xuan", "is_robot_indexable": true, "report_reasons": null, "author": "leehawk787", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3xuan/efficiently_developing_a_pipeline_for_large_messy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3xuan/efficiently_developing_a_pipeline_for_large_messy/", "subreddit_subscribers": 165066, "created_utc": 1709308972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Off-the-shelf data ingestion works great about 80% of the time. The other 20% is where good data engineers make all the difference.\n\nAt Y42, we've released Python ETL connectors to cater to the \"other 20%\", next to our existing Airbyte-, Fivetran-, and proprietary ingestion capabilities. The goal of this new feature is to:\n\n* implement custom ingestion logic,\n* remove boilerplate code to load data into your data warehouse,\n* get standardized metadata, lineage, and documentation out of the box.\n\nCheck out the demo video, very curious about your feedback: [https://www.youtube.com/watch?v=L252iaNylbo](https://www.youtube.com/watch?v=L252iaNylbo).  \n\n\nTo those who want to read more about it, check out the announcement post: [https://www.y42.com/blog/announcing-python-ingest](https://www.y42.com/blog/announcing-python-ingest).  \n\n\nThanks!", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Video] Custom Python ETL connector demo - feedback welcome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b439j6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709321813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Off-the-shelf data ingestion works great about 80% of the time. The other 20% is where good data engineers make all the difference.&lt;/p&gt;\n\n&lt;p&gt;At Y42, we&amp;#39;ve released Python ETL connectors to cater to the &amp;quot;other 20%&amp;quot;, next to our existing Airbyte-, Fivetran-, and proprietary ingestion capabilities. The goal of this new feature is to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;implement custom ingestion logic,&lt;/li&gt;\n&lt;li&gt;remove boilerplate code to load data into your data warehouse,&lt;/li&gt;\n&lt;li&gt;get standardized metadata, lineage, and documentation out of the box.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Check out the demo video, very curious about your feedback: &lt;a href=\"https://www.youtube.com/watch?v=L252iaNylbo\"&gt;https://www.youtube.com/watch?v=L252iaNylbo&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;To those who want to read more about it, check out the announcement post: &lt;a href=\"https://www.y42.com/blog/announcing-python-ingest\"&gt;https://www.y42.com/blog/announcing-python-ingest&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?auto=webp&amp;s=32f39757a24572d005ede61580ab0010f73257f9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d4373ae44796353a1e1e47398abc4cf8cf623dd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ffe4f55585d3e5367d6bb0d761d10f0b5afe1e1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/beHi8Nz9lVOMaGu3L8BK-9R5-au8ftvEs5IUkKELogI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e79b68cac8c8831bc27815b85aa2a82b53fbb45", "width": 320, "height": 240}], "variants": {}, "id": "vliEb2ghOCgafwl3iTha8feyMIA_S18KUF_iT9G1AD8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b439j6", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b439j6/video_custom_python_etl_connector_demo_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b439j6/video_custom_python_etl_connector_demo_feedback/", "subreddit_subscribers": 165066, "created_utc": 1709321813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Deep Dive into the Concept and World of Apache Iceberg Catalogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3x4gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l5R7hYeS0BgR22x8GabW0H58QTRPpMjpvJ7jFfesShY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709307251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.datalakehouse.help", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.datalakehouse.help/a-deep-dive-into-the-concept-and-world-of-apache-iceberg-catalogs-c948a2cc25ea", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?auto=webp&amp;s=a98cd9729792a2e9da9ea7f49f8712980209a990", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad5ae4f44f81b57fca6b6ef8a47f1af98463cc77", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d1233462d388b3390922ddc523a16b9074dccfb", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=867b8fb3b00177c591d4cd984ef8905fb8d1b107", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce04bf58cef436b78021e3513df38859675055fd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4cd0b16862184899a6ad57b7140c3b12741dfd31", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/OED3f10uR4NQEkZWmNbDRyuV8VAofNaZfCSfnXwnHyM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5195cbcb70a112d6069d20e7706afe21a168455d", "width": 1080, "height": 607}], "variants": {}, "id": "ls8ypxuJ6z3tA7HbOD4Z3GTMQhWB7rVZyH3BwXIunEU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3x4gx", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3x4gx/a_deep_dive_into_the_concept_and_world_of_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.datalakehouse.help/a-deep-dive-into-the-concept-and-world-of-apache-iceberg-catalogs-c948a2cc25ea", "subreddit_subscribers": 165066, "created_utc": 1709307251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just as the title says, how much web scraping would someone be able to do on twitter.com before it flags it as some bot/automated process and either ip bans or blocks the connection in the way they do?", "author_fullname": "t2_39utoy9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How aggressive is Twitter against web scrapers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b45r0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709327659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just as the title says, how much web scraping would someone be able to do on twitter.com before it flags it as some bot/automated process and either ip bans or blocks the connection in the way they do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b45r0c", "is_robot_indexable": true, "report_reasons": null, "author": "scuffed12s", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b45r0c/how_aggressive_is_twitter_against_web_scrapers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b45r0c/how_aggressive_is_twitter_against_web_scrapers/", "subreddit_subscribers": 165066, "created_utc": 1709327659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data Engineers!\n\nWe're launching, the IOMETE Community Edition on AWS, and looking for insightful testers like you. This is your golden ticket to experience our scalable data lakehouse platform, designed to transform terabytes to petabytes of data, absolutely free.\u00a0You'll be amazed by what you can achieve with our platform.\n\nWe're excited to see how users experiment with the platform by Leveraging Apache Iceberg and Spark for a managed data lakehouse that grows with your data\u2014from terabytes to petabytes\u2014without any vendor lock-in. Enjoy complete control over your data stored in S3 in parquet format, and pay only for the AWS resources you use. Whether you're using Spot or Reserved Instances, IOMETE ensures an affordable path compared to other vendors. Ready to transform your data management strategy?\n\nIOMETE offers several Apache Spark features including:\n\n1. A user-friendly interface and integrated notebook service for data processing and analysis.\n2. Comprehensive monitoring and debugging capabilities for Spark jobs.\n3. Automatic scaling of Spark clusters based on demand.\n4. Capabilities to process real-time data streams from various sources.\n5. A platform for training and deploying machine learning models for tasks like predictive analytics, fraud detection, and customer segmentation.\n\nThese features are designed to help you focus on your data analytics workloads by taking care of the infrastructure and management tasks associated with running Spark - [https://2ly.link/1wFi0](https://2ly.link/1wFi0)\n\nIntrigued? A short video awaits you to guide you through the details and the wonders that IOMETE Community Edition promises - [https://2ly.link/1wFi3](https://2ly.link/1wFi3)\n\nIf you have any questions regarding installation and usage, join our dedicated Discord community, and let's shape the future of data management together - [https://2ly.link/1wFi1](https://2ly.link/1wFi1)\n\nAs of now, the IOMETE Free Community Version can only be deployed on AWS. Please let us know where you would like to deploy the platform so we can prioritize it - [https://2ly.link/1wFi2](https://2ly.link/1wFi2) . We will let you know when your preferred deployment option becomes available", "author_fullname": "t2_9ftsfde7l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IOMETE released the most generous free Data Lakehouse platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3xfzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709308027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Engineers!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re launching, the IOMETE Community Edition on AWS, and looking for insightful testers like you. This is your golden ticket to experience our scalable data lakehouse platform, designed to transform terabytes to petabytes of data, absolutely free.\u00a0You&amp;#39;ll be amazed by what you can achieve with our platform.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re excited to see how users experiment with the platform by Leveraging Apache Iceberg and Spark for a managed data lakehouse that grows with your data\u2014from terabytes to petabytes\u2014without any vendor lock-in. Enjoy complete control over your data stored in S3 in parquet format, and pay only for the AWS resources you use. Whether you&amp;#39;re using Spot or Reserved Instances, IOMETE ensures an affordable path compared to other vendors. Ready to transform your data management strategy?&lt;/p&gt;\n\n&lt;p&gt;IOMETE offers several Apache Spark features including:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A user-friendly interface and integrated notebook service for data processing and analysis.&lt;/li&gt;\n&lt;li&gt;Comprehensive monitoring and debugging capabilities for Spark jobs.&lt;/li&gt;\n&lt;li&gt;Automatic scaling of Spark clusters based on demand.&lt;/li&gt;\n&lt;li&gt;Capabilities to process real-time data streams from various sources.&lt;/li&gt;\n&lt;li&gt;A platform for training and deploying machine learning models for tasks like predictive analytics, fraud detection, and customer segmentation.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These features are designed to help you focus on your data analytics workloads by taking care of the infrastructure and management tasks associated with running Spark - &lt;a href=\"https://2ly.link/1wFi0\"&gt;https://2ly.link/1wFi0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Intrigued? A short video awaits you to guide you through the details and the wonders that IOMETE Community Edition promises - &lt;a href=\"https://2ly.link/1wFi3\"&gt;https://2ly.link/1wFi3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you have any questions regarding installation and usage, join our dedicated Discord community, and let&amp;#39;s shape the future of data management together - &lt;a href=\"https://2ly.link/1wFi1\"&gt;https://2ly.link/1wFi1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As of now, the IOMETE Free Community Version can only be deployed on AWS. Please let us know where you would like to deploy the platform so we can prioritize it - &lt;a href=\"https://2ly.link/1wFi2\"&gt;https://2ly.link/1wFi2&lt;/a&gt; . We will let you know when your preferred deployment option becomes available&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b3xfzr", "is_robot_indexable": true, "report_reasons": null, "author": "IOMETE-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3xfzr/iomete_released_the_most_generous_free_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3xfzr/iomete_released_the_most_generous_free_data/", "subreddit_subscribers": 165066, "created_utc": 1709308027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.  I am looking to find demo data that I can use to practice some data modeling techniques.  Ideally, this data would be very normalized, such as how it would look when sourced from an application system.  I also hope to find data that includes snapshots of dimensional data to support constructed SCD.  Any suggestions on where I can find such a data set?", "author_fullname": "t2_l04by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demo data for data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3u70d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709299513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.  I am looking to find demo data that I can use to practice some data modeling techniques.  Ideally, this data would be very normalized, such as how it would look when sourced from an application system.  I also hope to find data that includes snapshots of dimensional data to support constructed SCD.  Any suggestions on where I can find such a data set?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3u70d", "is_robot_indexable": true, "report_reasons": null, "author": "kentmaxwell", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3u70d/demo_data_for_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3u70d/demo_data_for_data_modeling/", "subreddit_subscribers": 165066, "created_utc": 1709299513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,  \nI'm currently being offered a role as the data migration lead for a healthcare organisation changing electronic patient record systems. I've been unofficially doing this for a while, but they're talking about making this more official for the next 8 months or so. My background is really in business intelligence, data analysis, etc, so this is somewhat new to me. Is there any resources I should read about best practice for this kind of thing?   \n\n\nBoth of the systems have a SQL Server back end in case that's relevant, although technically the process basically involves creating a bunch of CSVs and loading them into a tool provided by the software supplier.  \nThanks", "author_fullname": "t2_bfginlr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Migration best practice, book/resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3qzi7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709288388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;br/&gt;\nI&amp;#39;m currently being offered a role as the data migration lead for a healthcare organisation changing electronic patient record systems. I&amp;#39;ve been unofficially doing this for a while, but they&amp;#39;re talking about making this more official for the next 8 months or so. My background is really in business intelligence, data analysis, etc, so this is somewhat new to me. Is there any resources I should read about best practice for this kind of thing?   &lt;/p&gt;\n\n&lt;p&gt;Both of the systems have a SQL Server back end in case that&amp;#39;s relevant, although technically the process basically involves creating a bunch of CSVs and loading them into a tool provided by the software supplier.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3qzi7", "is_robot_indexable": true, "report_reasons": null, "author": "MakingNumbersBehave", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3qzi7/data_migration_best_practice_bookresources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3qzi7/data_migration_best_practice_bookresources/", "subreddit_subscribers": 165066, "created_utc": 1709288388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello r/dataengineering!\n\n&amp;#x200B;\n\nI'm part of the [Jargon.sh](https://Jargon.sh) team, a platform on a mission to bring the principles and tools of open-source software development to Domain Driven Design (DDD) and API design. Our scope is broad, but we've traditionally focused on providing just enough data modelling to meet our users' needs. However, we're seeing a growing demand from clients who are interested in leveraging our platform for general-purpose data modelling, marking a new and exciting direction for us.\n\n&amp;#x200B;\n\nOur clients have shared how much they value the DDD approach for breaking down large models into smaller, more manageable domain models, and how our method of calculating Semantic Version (SemVer) release numbers has been a game-changer for them. These strategies have proven effective for their API design and integration architecture. Additionally, they appreciate Jargon as a platform of reusable models that can be easily searched, discovered, and imported into other domains, all based on immutable SemVer versioned releases. This capability not only enhances the efficiency of their work by promoting reusability and consistency across different projects but also significantly reduces the time and effort required in developing new domain models from scratch. This feedback underscores why our clients are encouraging us to extend our support to include more comprehensive data modelling capabilities.\n\n&amp;#x200B;\n\nOur goal extends beyond offering generic tools; we aim to understand the unique challenges our users face and to develop innovative solutions. By engaging closely with the community, we believe we can customise our solutions to meet specific needs and challenges. This collaborative approach has served us well in the realms of DDD and API, and we're eager to apply it to data modelling for data engineering, hoping to add significant value.\n\n&amp;#x200B;\n\nAs a member of the Jargon team, I'm here to collect your feedback and insights on how an open-source software-inspired approach to data modelling might benefit you. Your input is incredibly important to us as we strive to evolve Jargon into not just a tool, but a community-driven solution that empowers practitioners to achieve what they're trying to do more efficiently.\n\n&amp;#x200B;\n\nI'm quite new to Reddit, having been stalking around for a little while before finding this great community. Our research indicated that this is the most active and engaged data engineering community around, so I decided to reach out. It's clear there's a wealth of knowledge and experience here, and I'm excited to learn from you all and maybe convert some of your knowledge into features of our freely available data modelling platform in return.\n\n&amp;#x200B;\n\nIf you're not familiar with Jargon yet, I invite you to explore our platform. We offer a free-forever tier packed with features that could be of interest to you.\n\n&amp;#x200B;\n\nThank you for your time and insights. I'm looking forward to your feedback, and happy to answer any questions you might have!\n\n&amp;#x200B;", "author_fullname": "t2_36d03l80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pivoting our product from API design to Data Modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3ppn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709283093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m part of the &lt;a href=\"https://Jargon.sh\"&gt;Jargon.sh&lt;/a&gt; team, a platform on a mission to bring the principles and tools of open-source software development to Domain Driven Design (DDD) and API design. Our scope is broad, but we&amp;#39;ve traditionally focused on providing just enough data modelling to meet our users&amp;#39; needs. However, we&amp;#39;re seeing a growing demand from clients who are interested in leveraging our platform for general-purpose data modelling, marking a new and exciting direction for us.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Our clients have shared how much they value the DDD approach for breaking down large models into smaller, more manageable domain models, and how our method of calculating Semantic Version (SemVer) release numbers has been a game-changer for them. These strategies have proven effective for their API design and integration architecture. Additionally, they appreciate Jargon as a platform of reusable models that can be easily searched, discovered, and imported into other domains, all based on immutable SemVer versioned releases. This capability not only enhances the efficiency of their work by promoting reusability and consistency across different projects but also significantly reduces the time and effort required in developing new domain models from scratch. This feedback underscores why our clients are encouraging us to extend our support to include more comprehensive data modelling capabilities.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Our goal extends beyond offering generic tools; we aim to understand the unique challenges our users face and to develop innovative solutions. By engaging closely with the community, we believe we can customise our solutions to meet specific needs and challenges. This collaborative approach has served us well in the realms of DDD and API, and we&amp;#39;re eager to apply it to data modelling for data engineering, hoping to add significant value.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a member of the Jargon team, I&amp;#39;m here to collect your feedback and insights on how an open-source software-inspired approach to data modelling might benefit you. Your input is incredibly important to us as we strive to evolve Jargon into not just a tool, but a community-driven solution that empowers practitioners to achieve what they&amp;#39;re trying to do more efficiently.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m quite new to Reddit, having been stalking around for a little while before finding this great community. Our research indicated that this is the most active and engaged data engineering community around, so I decided to reach out. It&amp;#39;s clear there&amp;#39;s a wealth of knowledge and experience here, and I&amp;#39;m excited to learn from you all and maybe convert some of your knowledge into features of our freely available data modelling platform in return.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re not familiar with Jargon yet, I invite you to explore our platform. We offer a free-forever tier packed with features that could be of interest to you.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and insights. I&amp;#39;m looking forward to your feedback, and happy to answer any questions you might have!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3ppn0", "is_robot_indexable": true, "report_reasons": null, "author": "Jargon-sh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3ppn0/pivoting_our_product_from_api_design_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3ppn0/pivoting_our_product_from_api_design_to_data/", "subreddit_subscribers": 165066, "created_utc": 1709283093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In SQL I need to count occurrences of the date when a deal was passed to a salesperson, the meeting date, and the contract signing date, along with the sum of contracts. \n\nAll this data is in a single table with a unique ID as the primary key (PK).\n\nThe challenge is that I need to obtain the count of each of these dates by month without using any of the dates directly for grouping. This is because grouping by any of these dates directly would result in counting by that specific date. For example, if someone had a meeting in January and we group by the meeting date, we wouldn't capture their contract in February, etc.\n\nHow should I approach this?\"", "author_fullname": "t2_803gugjh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Count of different dates occurencies from one table ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3lump", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709268765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In SQL I need to count occurrences of the date when a deal was passed to a salesperson, the meeting date, and the contract signing date, along with the sum of contracts. &lt;/p&gt;\n\n&lt;p&gt;All this data is in a single table with a unique ID as the primary key (PK).&lt;/p&gt;\n\n&lt;p&gt;The challenge is that I need to obtain the count of each of these dates by month without using any of the dates directly for grouping. This is because grouping by any of these dates directly would result in counting by that specific date. For example, if someone had a meeting in January and we group by the meeting date, we wouldn&amp;#39;t capture their contract in February, etc.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3lump", "is_robot_indexable": true, "report_reasons": null, "author": "Novel_Pattern8035", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3lump/count_of_different_dates_occurencies_from_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3lump/count_of_different_dates_occurencies_from_one/", "subreddit_subscribers": 165066, "created_utc": 1709268765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Better yet, what am I actually looking for here?\n\nI\u2019m designing a system that handles schedules in a novel way that, based on our review, isn\u2019t offered elsewhere. Honestly the magic boils down to just a handful of presentation choices and feature integrations.\n\nI\u2019m using a relational database and the data, for the most part, fits the model well. One thing that stands out is tasks though\u2026 The tasks have a serial order to them meaning that one gets started only after the prior finishes.\n\nI need to support a query that, given a task and a location, the response is the number of incomplete upstream tasks. This is done by getting all incomplete tasks with an expected start date of less than the given task, within the given location, and returning the count of records.\n\nHowever, tasks are global\u2026 Every single space has the same tasks. Therefore, the serial order for tasks is also global. It\u2019s wasted effort to slice to tasks within the given location, recalculating which are upstream every time as based on a date column. \n\nI could just artificially maintain a serial order column within a tasks table. Values would just count upward, and I as the user would just insert them this way. This is an implicitly maintained rule that\u2019s critical for the system\u2019s functionality though\u2026 I think not.\n\nThen there are trigger functions which likely can be used very effectively. However, they carry a negative connotation due to undesired side effects. It can be difficult to reason about the synergic behavior of relational and functional capabilities at large scale, and humans bite the bullet here eventually. I\u2019d like to avoid triggers if possible.\n\nAre there data models that support this kind of precedence between entities more naturally? \n\nAre there data models that blur the line between relational and what I\u2019m looking for, potentially solving both needs at the same time?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do relational databases offer a way to require serial order from manually entered data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b4e5fn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709349550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Better yet, what am I actually looking for here?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m designing a system that handles schedules in a novel way that, based on our review, isn\u2019t offered elsewhere. Honestly the magic boils down to just a handful of presentation choices and feature integrations.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m using a relational database and the data, for the most part, fits the model well. One thing that stands out is tasks though\u2026 The tasks have a serial order to them meaning that one gets started only after the prior finishes.&lt;/p&gt;\n\n&lt;p&gt;I need to support a query that, given a task and a location, the response is the number of incomplete upstream tasks. This is done by getting all incomplete tasks with an expected start date of less than the given task, within the given location, and returning the count of records.&lt;/p&gt;\n\n&lt;p&gt;However, tasks are global\u2026 Every single space has the same tasks. Therefore, the serial order for tasks is also global. It\u2019s wasted effort to slice to tasks within the given location, recalculating which are upstream every time as based on a date column. &lt;/p&gt;\n\n&lt;p&gt;I could just artificially maintain a serial order column within a tasks table. Values would just count upward, and I as the user would just insert them this way. This is an implicitly maintained rule that\u2019s critical for the system\u2019s functionality though\u2026 I think not.&lt;/p&gt;\n\n&lt;p&gt;Then there are trigger functions which likely can be used very effectively. However, they carry a negative connotation due to undesired side effects. It can be difficult to reason about the synergic behavior of relational and functional capabilities at large scale, and humans bite the bullet here eventually. I\u2019d like to avoid triggers if possible.&lt;/p&gt;\n\n&lt;p&gt;Are there data models that support this kind of precedence between entities more naturally? &lt;/p&gt;\n\n&lt;p&gt;Are there data models that blur the line between relational and what I\u2019m looking for, potentially solving both needs at the same time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4e5fn", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4e5fn/do_relational_databases_offer_a_way_to_require/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4e5fn/do_relational_databases_offer_a_way_to_require/", "subreddit_subscribers": 165066, "created_utc": 1709349550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My client in healthcare uses a hardware device that generates data and saves it into the VM of the hardware manufacturer. The generated data is about 10gb per file. Is there a way to automatically move these files to my own computer? The next step would be to monitor a folder in my computer to upload the file to S3 using multipart upload, but first, the files need to be there in the first place. Any advice would be appreciated. \n", "author_fullname": "t2_tln2vge3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate data extraction from external VM to my computer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b4dnze", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709348099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My client in healthcare uses a hardware device that generates data and saves it into the VM of the hardware manufacturer. The generated data is about 10gb per file. Is there a way to automatically move these files to my own computer? The next step would be to monitor a folder in my computer to upload the file to S3 using multipart upload, but first, the files need to be there in the first place. Any advice would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4dnze", "is_robot_indexable": true, "report_reasons": null, "author": "TheQuiteMind", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4dnze/how_to_automate_data_extraction_from_external_vm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4dnze/how_to_automate_data_extraction_from_external_vm/", "subreddit_subscribers": 165066, "created_utc": 1709348099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been wondering if anyone's using their Lakehouse for stuff beyond the usual the reporting and BI use-cases in the gold layer. It feels like everyone refers to the to the gold layer as being just for facts and dimensions, pretty much just standard Kimball warehouse stuff. But what about other uses?\n\nSpecifically, I'm looking into serving data for analytical web apps. These are not just simple reports but full-blown applications with a UI, an API, and a back-end running in Docker Containers on K8s. They would rely heavily on data in the Lakehouse, mostly from the silver layer, and wouldn't really generate much data on their own. There may be some exceptions where user input is written, but it would be a very little amount of data.\n\nI can't imagine that they best approach for this would keeping all this data in the Lakehouse, like in Delta Format. Wouldn't it make more sense to move this data into something like a Postgres DB, or even MongoDB, especially for serving it up through an API to the front-end?\n\nWould love to hear if anyone is currently supporting these types of use-cases on their platform.\n\nThanks!", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beyond Reporting in a Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b46sye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709330174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wondering if anyone&amp;#39;s using their Lakehouse for stuff beyond the usual the reporting and BI use-cases in the gold layer. It feels like everyone refers to the to the gold layer as being just for facts and dimensions, pretty much just standard Kimball warehouse stuff. But what about other uses?&lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m looking into serving data for analytical web apps. These are not just simple reports but full-blown applications with a UI, an API, and a back-end running in Docker Containers on K8s. They would rely heavily on data in the Lakehouse, mostly from the silver layer, and wouldn&amp;#39;t really generate much data on their own. There may be some exceptions where user input is written, but it would be a very little amount of data.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t imagine that they best approach for this would keeping all this data in the Lakehouse, like in Delta Format. Wouldn&amp;#39;t it make more sense to move this data into something like a Postgres DB, or even MongoDB, especially for serving it up through an API to the front-end?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear if anyone is currently supporting these types of use-cases on their platform.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b46sye", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b46sye/beyond_reporting_in_a_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b46sye/beyond_reporting_in_a_lakehouse/", "subreddit_subscribers": 165066, "created_utc": 1709330174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all - I'll cut right to the chase: I am working on mentoring a mid-level data dev on skills development, and I could use some advice on where to focus. They mentioned gaining skill in the areas of using python (presumably in the context of notebooks and such) as well as sql. They are also pursuing a snowflake certification.\n\nTo give some context on me: I am a very experienced full stack developer and application/cloud architect on large-scale systems. I am conversant in data, and have built some basic ETL/ELTs, Azure Data Pipelines, relational query tuning, and some work with data lakes. That's enough to know what I don't know about data, if that makes sense.\n\nAny tips on where to focus as it relates to the above skills? Any other thoughts welcome as well - TIA!", "author_fullname": "t2_dnexpjr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Training advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b44616", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709323913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all - I&amp;#39;ll cut right to the chase: I am working on mentoring a mid-level data dev on skills development, and I could use some advice on where to focus. They mentioned gaining skill in the areas of using python (presumably in the context of notebooks and such) as well as sql. They are also pursuing a snowflake certification.&lt;/p&gt;\n\n&lt;p&gt;To give some context on me: I am a very experienced full stack developer and application/cloud architect on large-scale systems. I am conversant in data, and have built some basic ETL/ELTs, Azure Data Pipelines, relational query tuning, and some work with data lakes. That&amp;#39;s enough to know what I don&amp;#39;t know about data, if that makes sense.&lt;/p&gt;\n\n&lt;p&gt;Any tips on where to focus as it relates to the above skills? Any other thoughts welcome as well - TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b44616", "is_robot_indexable": true, "report_reasons": null, "author": "leetcde", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b44616/training_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b44616/training_advice_needed/", "subreddit_subscribers": 165066, "created_utc": 1709323913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Mar 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu", "t3_188grkl", "t3_18w0y5n", "t3_1agfqy9", "t3_1b3zb2c"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1709312460.253, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3zb2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709312460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?auto=webp&amp;s=f4aed4accb9b09c9fa81e95e6c52cf3c300fc962", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=255dedc032e49c49b0c4e8f8bb181adc3f7d5295", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f605bcb5e19d3a5c71a81ce00990e7b65f81e52d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac789c54fffcb874c262f4c470d6c034806f8960", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6LuG4ZPxSPtKuv5jZHRLjhdSYVn1k5My9J5dwONa6hE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=89ecd9f44728ccd7762c0517d3f0cb495c78c6be", "width": 640, "height": 333}], "variants": {}, "id": "ImrjwYWlQQdcm31jLkEiQbVgLMUnfCK0dT44FpXjpjI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3zb2c", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3zb2c/monthly_general_discussion_mar_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/1b3zb2c/monthly_general_discussion_mar_2024/", "subreddit_subscribers": 165066, "created_utc": 1709312460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v5q74o4dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Video Podcast] No longer a pipe dream \u2014 Gen AI and Data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3ytu1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "No longer a pipe dream \u2014 GenAI and Data pipelines [Cloud Masters #110]", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "DoiT International", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W4HrEz10J9M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@doitintl"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1b3ytu1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hFn5qCv6XLo-WE18ph_n37gprtc0G_j7rtnUzg4Bfew.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709311342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=W4HrEz10J9M&amp;list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss&amp;index=2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?auto=webp&amp;s=5e53e9190808d23549ae9d2875bac69ddb86791d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf266c414a5bf05efabe55f297ef7b5a6eba2a66", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ed7fdca7bcf7297fef2d10774f949a0a3628f6", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/WpVffAvSIZ8EqzjoJXGFF_zMtnb-SFFIcjW6VKSSprs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4cac4a382fe34529a6d1ea1f88639b0e9c35bcd", "width": 320, "height": 240}], "variants": {}, "id": "xduYiEOi5zVPnZXHY3v5vVr6W8i4vt-CxnOMopjjnUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b3ytu1", "is_robot_indexable": true, "report_reasons": null, "author": "LLMaooooooo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3ytu1/video_podcast_no_longer_a_pipe_dream_gen_ai_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=W4HrEz10J9M&amp;list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss&amp;index=2", "subreddit_subscribers": 165066, "created_utc": 1709311342.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "No longer a pipe dream \u2014 GenAI and Data pipelines [Cloud Masters #110]", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W4HrEz10J9M?list=PLEBxNMZ7Mu39fMIYhr5fdq8S-UrvTpEss\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "DoiT International", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W4HrEz10J9M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@doitintl"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone implemented such a pattern? Any resources to share?\n\nI'd be really interested in hearing your stories.", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Property-based testing in ETL/ELT flows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3r9wi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709289532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone implemented such a pattern? Any resources to share?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be really interested in hearing your stories.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3r9wi", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3r9wi/propertybased_testing_in_etlelt_flows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3r9wi/propertybased_testing_in_etlelt_flows/", "subreddit_subscribers": 165066, "created_utc": 1709289532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I am reading a hive view into a pyspark data frame and later joining it with the fact table read into another data frame. These views have equivalent hive tables partitioned by snapshot_date as well. The view only stores the latest data by taking a max(snapshot_dt). Will directly reading from the table with max(snapshot_dt) increase the performance rather than reading from the view ?\n\nTyia ", "author_fullname": "t2_qm56uvb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performance or read from a view and table ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3pi32", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709282226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I am reading a hive view into a pyspark data frame and later joining it with the fact table read into another data frame. These views have equivalent hive tables partitioned by snapshot_date as well. The view only stores the latest data by taking a max(snapshot_dt). Will directly reading from the table with max(snapshot_dt) increase the performance rather than reading from the view ?&lt;/p&gt;\n\n&lt;p&gt;Tyia &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3pi32", "is_robot_indexable": true, "report_reasons": null, "author": "Chillardon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3pi32/performance_or_read_from_a_view_and_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3pi32/performance_or_read_from_a_view_and_table/", "subreddit_subscribers": 165066, "created_utc": 1709282226.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}