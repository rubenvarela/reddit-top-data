{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've almost always used seaborn in the past 5 years as a data scientist. Looking to upgrade to something new/better to use!  \n  \nedit: looks like it's time to give plotly a shot!", "author_fullname": "t2_9p4skdeg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What python data visualization package are you using in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b40em5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 130, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 130, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709322696.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709315022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve almost always used seaborn in the past 5 years as a data scientist. Looking to upgrade to something new/better to use!  &lt;/p&gt;\n\n&lt;p&gt;edit: looks like it&amp;#39;s time to give plotly a shot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b40em5", "is_robot_indexable": true, "report_reasons": null, "author": "startup_biz_36", "discussion_type": null, "num_comments": 87, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b40em5/what_python_data_visualization_package_are_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b40em5/what_python_data_visualization_package_are_you/", "subreddit_subscribers": 1384672, "created_utc": 1709315022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve blocked most of the names that post every day unless I find their content engaging. But it left me wondering, what are the motivations for people who spend what I assume is several hours every week posting non-stop. \n\nThe posts themselves are not monetized. Do hourly consulting opportunities usually come this way? Some of these people are corporate employees so it\u2019s not just consultants unless they are all trying for side money. Is it a long term play to secure more job opportunities in the future? Both? Other things they\u2019re building and trying to sell? Just to create a massive but impersonal network? What are the various reasons people do this?\n\nIt takes me mental energy to make even 1 post every couple weeks, so I am always dumbfounded when some people pour so much energy into this when they\u2019re already in a high paying career.", "author_fullname": "t2_a3c282tw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the motivations of LinkedIn influencers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3spfx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709294716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve blocked most of the names that post every day unless I find their content engaging. But it left me wondering, what are the motivations for people who spend what I assume is several hours every week posting non-stop. &lt;/p&gt;\n\n&lt;p&gt;The posts themselves are not monetized. Do hourly consulting opportunities usually come this way? Some of these people are corporate employees so it\u2019s not just consultants unless they are all trying for side money. Is it a long term play to secure more job opportunities in the future? Both? Other things they\u2019re building and trying to sell? Just to create a massive but impersonal network? What are the various reasons people do this?&lt;/p&gt;\n\n&lt;p&gt;It takes me mental energy to make even 1 post every couple weeks, so I am always dumbfounded when some people pour so much energy into this when they\u2019re already in a high paying career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b3spfx", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Detective3852", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b3spfx/what_are_the_motivations_of_linkedin_influencers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b3spfx/what_are_the_motivations_of_linkedin_influencers/", "subreddit_subscribers": 1384672, "created_utc": 1709294716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been seeing lots of data scientist jobs for major airlines (delta, united) and I\u2019ve always thought how data science in that specific industry has changed. Specifically, airlines companies traditionally was home to lots of Operations Research practitioners (the problem of scheduling flights is like a textbook OR problem I believe). I wonder how this industry has changed from a setting of problems they are interested in solving and how data scientists in these companies operate. For data scientists who are in these types of companies, are the problems you solve similar to these traditional OR type of problems? Could you guys weigh in on this? \nAlso, do you guys get perks on traveling cause of working for such companies too? I\u2019d imagine if you worked for a place like delta you could get major perks for this when traveling with your family. Any kind of benefits like this?", "author_fullname": "t2_uy28jztl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists at airlines companies, how much is your work similar to traditional OR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b479fk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709331261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been seeing lots of data scientist jobs for major airlines (delta, united) and I\u2019ve always thought how data science in that specific industry has changed. Specifically, airlines companies traditionally was home to lots of Operations Research practitioners (the problem of scheduling flights is like a textbook OR problem I believe). I wonder how this industry has changed from a setting of problems they are interested in solving and how data scientists in these companies operate. For data scientists who are in these types of companies, are the problems you solve similar to these traditional OR type of problems? Could you guys weigh in on this? \nAlso, do you guys get perks on traveling cause of working for such companies too? I\u2019d imagine if you worked for a place like delta you could get major perks for this when traveling with your family. Any kind of benefits like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b479fk", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Touch469", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b479fk/data_scientists_at_airlines_companies_how_much_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b479fk/data_scientists_at_airlines_companies_how_much_is/", "subreddit_subscribers": 1384672, "created_utc": 1709331261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a project aimed at predicting pet insurance claims based on historical data. Our dataset includes 5 million rows, capturing both instances where claims were made (with a specific condition noted) and years without claims (indicated by a NULL condition). These conditions are grouped into 20 higher-level categories by domain experts. Along with that each breed is grouped into a higher-level grouping.\n\nI am approaching this as a supervised learning problem in the same way found in this [paper](https://www.nature.com/articles/s41598-023-36023-5), treating each pet's year as a separate sample. This means a pet with 7 years of data contributes 7 samples(regardless of if it made a claim or not), with features derived from the preceding years' data and the target (claim or no claim) for that year. My goal is to create a binary classifier for each of the 20 disease groupings, incorporating features like recency (e.g., skin\\_condition\\_last\\_year, skin\\_condition\\_claim\\_avg and so on for each disease grouping), disease characteristics (e.g., pain\\_score), and breed groupings. So, one example would be a model for skin conditions for example that would predict given the preceding years info if the pet would have a skin\\_condition claim in the next year.\n\n\u00a0The big challenges I am facing are:\n\n* Imbalanced Data: For each disease grouping, positive samples (i.e., a claim was made) constitute only 1-2% of the data.\n* Feature Selection: Identifying the most relevant features for predicting claims is challenging, along with finding relevant features to create.\n\nCurrent Strategies Under Consideration:\n\n* \u00a0Logistic Regression: Adjusting class weights,employing Repeated Stratified Cross-Validation, and threshold tuning for optimisation.\n* Gradient Boosting Models: Experimenting with CatBoost and XGBoost, adjusting for the imbalanced dataset.\n* Nested Classification: Initially determining whether a claim was made before classifying the specific disease group.\n\n\u00a0I'm seeking advice from those who have tackled similar modelling challenges, especially in the context of imbalanced datasets and feature selection. Any insights on the methodologies outlined above, or recommendations on alternative approaches, would be greatly appreciated. Additionally, if you\u2019ve come across relevant papers or resources that could aid in refining my approach, that would be amazing.\n\nThanks in advance for your help and guidance!", "author_fullname": "t2_u7io3tm4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classification model on pet health insurance claims data with strong imbalance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3pki9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709282497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project aimed at predicting pet insurance claims based on historical data. Our dataset includes 5 million rows, capturing both instances where claims were made (with a specific condition noted) and years without claims (indicated by a NULL condition). These conditions are grouped into 20 higher-level categories by domain experts. Along with that each breed is grouped into a higher-level grouping.&lt;/p&gt;\n\n&lt;p&gt;I am approaching this as a supervised learning problem in the same way found in this &lt;a href=\"https://www.nature.com/articles/s41598-023-36023-5\"&gt;paper&lt;/a&gt;, treating each pet&amp;#39;s year as a separate sample. This means a pet with 7 years of data contributes 7 samples(regardless of if it made a claim or not), with features derived from the preceding years&amp;#39; data and the target (claim or no claim) for that year. My goal is to create a binary classifier for each of the 20 disease groupings, incorporating features like recency (e.g., skin_condition_last_year, skin_condition_claim_avg and so on for each disease grouping), disease characteristics (e.g., pain_score), and breed groupings. So, one example would be a model for skin conditions for example that would predict given the preceding years info if the pet would have a skin_condition claim in the next year.&lt;/p&gt;\n\n&lt;p&gt;\u00a0The big challenges I am facing are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Imbalanced Data: For each disease grouping, positive samples (i.e., a claim was made) constitute only 1-2% of the data.&lt;/li&gt;\n&lt;li&gt;Feature Selection: Identifying the most relevant features for predicting claims is challenging, along with finding relevant features to create.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Current Strategies Under Consideration:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\u00a0Logistic Regression: Adjusting class weights,employing Repeated Stratified Cross-Validation, and threshold tuning for optimisation.&lt;/li&gt;\n&lt;li&gt;Gradient Boosting Models: Experimenting with CatBoost and XGBoost, adjusting for the imbalanced dataset.&lt;/li&gt;\n&lt;li&gt;Nested Classification: Initially determining whether a claim was made before classifying the specific disease group.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;\u00a0I&amp;#39;m seeking advice from those who have tackled similar modelling challenges, especially in the context of imbalanced datasets and feature selection. Any insights on the methodologies outlined above, or recommendations on alternative approaches, would be greatly appreciated. Additionally, if you\u2019ve come across relevant papers or resources that could aid in refining my approach, that would be amazing.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help and guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?auto=webp&amp;s=2c3666a855cbc443251f40377ff230adc1d3e1e7", "width": 685, "height": 503}, "resolutions": [{"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b94f6a9554200ddd141a8478847de36f1005b67", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b970b987aafa51fa3e91a9dae502ae477a1d7f5", "width": 216, "height": 158}, {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e247a6b3b5142866e7082af868aed3c5f9d3550", "width": 320, "height": 234}, {"url": "https://external-preview.redd.it/DrXrXjMaMQHXffHfkAt3r8Xji-Zp2i-vlsdRpCX6kWA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35548fa0b89995cfda807b0ecbaa30f227806716", "width": 640, "height": 469}], "variants": {}, "id": "hnpMLf_nVtPXYhMs615i_AhD6a-UIdkAS7Milta7GBY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1b3pki9", "is_robot_indexable": true, "report_reasons": null, "author": "LebrawnJames416", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b3pki9/classification_model_on_pet_health_insurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b3pki9/classification_model_on_pet_health_insurance/", "subreddit_subscribers": 1384672, "created_utc": 1709282497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Learn about Monte Carlo simulations, understand what it does and how to use it. You bring that bad boy out in an interview and your chances just went through the roof. Trust me. ", "author_fullname": "t2_eih58jo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for aspiring data scientists ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b4b141", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709340655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learn about Monte Carlo simulations, understand what it does and how to use it. You bring that bad boy out in an interview and your chances just went through the roof. Trust me. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b4b141", "is_robot_indexable": true, "report_reasons": null, "author": "lightuponlight99", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b4b141/advice_for_aspiring_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b4b141/advice_for_aspiring_data_scientists/", "subreddit_subscribers": 1384672, "created_utc": 1709340655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a pyspark dataframe that has a column with values in this format (read.json on json files):\n\n{50:{\"A\":3, \"B\":2}, 60:{\"A\":6, \"B\":5}}\n\nI have been trying to figure out how to get the data into this format:\n\nColumns: |value|A|B|\n\n|\\[50,60\\]|\\[3,2\\]|\\[2,5\\]|\n\nThis is my immediate issue, but to those who are interested in even more of a challenge I actually have two columns with nested dictionaries:\n\ncolumn1| column2\n\n{50: {\"A\":3, \"B\":2}, 60:{\"A\":6, \"B\":5}} |  {\"value\": 16:{certain\\_info1: 16}, \"value\": 60 : {certain\\_info1: 42}}\n\n&amp;#x200B;\n\nmy ultimate goal is to have the data in this format\n\nColumns: |value|A|B|certain\\_info1|\n\n|60|6|5|42|\n\n&amp;#x200B;\n\nTo be clear, the \"value\" info is not in the same order in the two columns, and the \"value\" info is not a key but the value TO a key in the second column.\n\nI have been banging my head on this all day. Would love some advice or help. Thanks!", "author_fullname": "t2_615382bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Grab Keys of a Nested Dictionary in a Pyspark Column? Put Them as Values in New Column?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b48juo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Coding", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709334339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a pyspark dataframe that has a column with values in this format (read.json on json files):&lt;/p&gt;\n\n&lt;p&gt;{50:{&amp;quot;A&amp;quot;:3, &amp;quot;B&amp;quot;:2}, 60:{&amp;quot;A&amp;quot;:6, &amp;quot;B&amp;quot;:5}}&lt;/p&gt;\n\n&lt;p&gt;I have been trying to figure out how to get the data into this format:&lt;/p&gt;\n\n&lt;p&gt;Columns: |value|A|B|&lt;/p&gt;\n\n&lt;p&gt;|[50,60]|[3,2]|[2,5]|&lt;/p&gt;\n\n&lt;p&gt;This is my immediate issue, but to those who are interested in even more of a challenge I actually have two columns with nested dictionaries:&lt;/p&gt;\n\n&lt;p&gt;column1| column2&lt;/p&gt;\n\n&lt;p&gt;{50: {&amp;quot;A&amp;quot;:3, &amp;quot;B&amp;quot;:2}, 60:{&amp;quot;A&amp;quot;:6, &amp;quot;B&amp;quot;:5}} |  {&amp;quot;value&amp;quot;: 16:{certain_info1: 16}, &amp;quot;value&amp;quot;: 60 : {certain_info1: 42}}&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;my ultimate goal is to have the data in this format&lt;/p&gt;\n\n&lt;p&gt;Columns: |value|A|B|certain_info1|&lt;/p&gt;\n\n&lt;p&gt;|60|6|5|42|&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To be clear, the &amp;quot;value&amp;quot; info is not in the same order in the two columns, and the &amp;quot;value&amp;quot; info is not a key but the value TO a key in the second column.&lt;/p&gt;\n\n&lt;p&gt;I have been banging my head on this all day. Would love some advice or help. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4ab9c418-70eb-11ee-8a37-4a495429ae82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1b48juo", "is_robot_indexable": true, "report_reasons": null, "author": "datatastic08200", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b48juo/how_to_grab_keys_of_a_nested_dictionary_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b48juo/how_to_grab_keys_of_a_nested_dictionary_in_a/", "subreddit_subscribers": 1384672, "created_utc": 1709334339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "They claim they built kalaido.ai in 6 months, with translation capabilities, etc. is it possible?", "author_fullname": "t2_qog9epqs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone build Foundational model on their own? Just saw an announcement from a service company in India that they built an image generational foundational model on their own (as good as Midjourney, etc).  ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b4cdhw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709344427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They claim they built kalaido.ai in 6 months, with translation capabilities, etc. is it possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b4cdhw", "is_robot_indexable": true, "report_reasons": null, "author": "ramnit05", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b4cdhw/can_anyone_build_foundational_model_on_their_own/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b4cdhw/can_anyone_build_foundational_model_on_their_own/", "subreddit_subscribers": 1384672, "created_utc": 1709344427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Next month, I am going to give a 2-3 hour course in my university about using LLMs. I don't really want to get into all the NLP fundamentals because some modules of my uni already cover those.\n\nSo I rather thought about showing the students how to grab a pre-trained model from huggingface and fine-tune it on a downstream task. First I would show them the theory behind it and then a practical step-by-step guide.\n\nMy problem is that this is by far not enough content to fill these 2-3 hours. So my question is what you think I should include which may be interesting or even essential. An example outline would also be very appreciated", "author_fullname": "t2_ed1zitv0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best outline for short LLM course?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b3y3i6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709309595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Next month, I am going to give a 2-3 hour course in my university about using LLMs. I don&amp;#39;t really want to get into all the NLP fundamentals because some modules of my uni already cover those.&lt;/p&gt;\n\n&lt;p&gt;So I rather thought about showing the students how to grab a pre-trained model from huggingface and fine-tune it on a downstream task. First I would show them the theory behind it and then a practical step-by-step guide.&lt;/p&gt;\n\n&lt;p&gt;My problem is that this is by far not enough content to fill these 2-3 hours. So my question is what you think I should include which may be interesting or even essential. An example outline would also be very appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b3y3i6", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Guava-64", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b3y3i6/best_outline_for_short_llm_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b3y3i6/best_outline_for_short_llm_course/", "subreddit_subscribers": 1384672, "created_utc": 1709309595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, in short, I know nothing in unsupervised learning.\n\n\nAll problems I worked on or saw in courses or read on the internet and the majority of ML threads here are devoted to supervised learning, classification or regression.\n\nAlthough all my job is getting creative with the data collection phase and the TRYING SO FUCKING HARD TO CONVERT IT TO A SUPERVISED LEARNING PROBLEM.\n\nI am genuinely interested in learning more about segmentation but all I see on the internet on this topic is fitting a kmeans with a K from an elbow plot.\n\nWhat do you guys suggest?\n\nGenerally, how to explore the data to make it fit for an unsupervised learning algorithm? How does automated segmentation work? For example if my \"behavior\" has changed as a customer in your company, do you periodically run a script and inspect the features of the group and manually annotate each cluster to a description? \n\nThanks", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsupervised learning sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b4as8w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709340004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, in short, I know nothing in unsupervised learning.&lt;/p&gt;\n\n&lt;p&gt;All problems I worked on or saw in courses or read on the internet and the majority of ML threads here are devoted to supervised learning, classification or regression.&lt;/p&gt;\n\n&lt;p&gt;Although all my job is getting creative with the data collection phase and the TRYING SO FUCKING HARD TO CONVERT IT TO A SUPERVISED LEARNING PROBLEM.&lt;/p&gt;\n\n&lt;p&gt;I am genuinely interested in learning more about segmentation but all I see on the internet on this topic is fitting a kmeans with a K from an elbow plot.&lt;/p&gt;\n\n&lt;p&gt;What do you guys suggest?&lt;/p&gt;\n\n&lt;p&gt;Generally, how to explore the data to make it fit for an unsupervised learning algorithm? How does automated segmentation work? For example if my &amp;quot;behavior&amp;quot; has changed as a customer in your company, do you periodically run a script and inspect the features of the group and manually annotate each cluster to a description? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1b4as8w", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b4as8w/unsupervised_learning_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b4as8w/unsupervised_learning_sources/", "subreddit_subscribers": 1384672, "created_utc": 1709340004.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}