{"kind": "Listing", "data": {"after": null, "dist": 7, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Recently my ML model has been under scrutiny for inaccuracy for one the sales channel predictions.  The model predicts monthly proportional volume.  It works great on channels with consistent volume flows (higher volume channels), not so great when ordering patterns are not consistent.  My boss wants to look at model validation, that\u2019s what was said.  When creating the model initially we did cross validation, looked at MSE, and it was known that low volume channels are not as accurate.  I\u2019m given some articles to read (from medium.com) for my coaching.  I asked what they did in the past for model validation. This is what was said \u201cTrain/Test for most models (Kn means, log reg, regression), k-fold for risk based models.\u201d  That was my coaching. I\u2019m better off consulting Chat at this point. Do your boss\u2019s offer substantial coaching or at least offer to help you out?", "author_fullname": "t2_15wob0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blind leading the blind", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7z9fg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 146, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 146, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709730491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently my ML model has been under scrutiny for inaccuracy for one the sales channel predictions.  The model predicts monthly proportional volume.  It works great on channels with consistent volume flows (higher volume channels), not so great when ordering patterns are not consistent.  My boss wants to look at model validation, that\u2019s what was said.  When creating the model initially we did cross validation, looked at MSE, and it was known that low volume channels are not as accurate.  I\u2019m given some articles to read (from medium.com) for my coaching.  I asked what they did in the past for model validation. This is what was said \u201cTrain/Test for most models (Kn means, log reg, regression), k-fold for risk based models.\u201d  That was my coaching. I\u2019m better off consulting Chat at this point. Do your boss\u2019s offer substantial coaching or at least offer to help you out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1b7z9fg", "is_robot_indexable": true, "report_reasons": null, "author": "myKidsLike2Scream", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b7z9fg/blind_leading_the_blind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b7z9fg/blind_leading_the_blind/", "subreddit_subscribers": 1399902, "created_utc": 1709730491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So this was my first \"data science\" interview where I was asked (what I think) was a business case. Apparently I did soo poorly I got handed a rejection a few hours later, so I wanted to know what you guys think of this problem, how you would solve it, if it's even an appropriate DS question etc...\n\nThe problem goes something like this: You are a data scientist that works at an e-commerce platform that sells experiences at Paris (think bicycle rides, wine tours, etc...). The company doesn't own any products but rather takes a commission from every product sold.\n\nYou have access to a table of 500 such products (for Paris only) that has columns like title, category, review count, review avg, price, duration, when it was posted, etc... (maybe 2-3 more but these seem more like internal IDs that don't really matter). The three questions we went over before she gave up on me were:\n\n1. How would you pick 1-2 metrics from this column to sort these listings? (To build a quick formula for ranking these listings)\n2. What are some disadvantages of this approach?\n3. How would you predict that the rankings will change in 6 months from today (assuming I implemented my strategy)?\n\nMy answers where:\n\n1. I would pick the review avg and count. normalize the count, like minmax so that it is in the same range as the review avg, and weight the review count and review avg by a alpha and (1 - alpha) for example. Should have I picked price instead of review count? I didn't because I would assume that the revenue generated per product would be somewhat similar (I also asked how they take commission and the answer I got was to use price as the proxy for commission which imo makes no sense, the rates wouldn't be the same for all of the prices right?), otherwise they would not have signed that product plus, for longer term growth I would assume UX would be more important that money generated short term, i.e. recommend things that the user would like more... should have I used the inverse of the review count to treat this problem more like a multi armed bandit with the UCB strategy?\n2. I said that this approach wouldn't give a higher ranking to newer products and that it would be more dificult for these new products to rank\n3. I pretty much said the same as 2. because I also gave up around here\n\nThe questions I have are: why ask a question that doesn't allow me to use ML? I understand having a baseline, but still... I briefly mentioned multi armed bandits and she overlooked what I said. If this was a business case why didn't I get more context? I asked what was the bigger context, if this was for a ranking algorithm, and got a not very convincing \"sure\" (tbh using the term \"sort\" here somewhat confused me, I usually see the term \"ranking\" for these problems, it looked like she was avoiding it for some reason). I then asked what was their current approach for sorting these listings and she didn't answer...", "author_fullname": "t2_mbc0bpphd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you approach this interview question?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b853sy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709754597.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709745015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So this was my first &amp;quot;data science&amp;quot; interview where I was asked (what I think) was a business case. Apparently I did soo poorly I got handed a rejection a few hours later, so I wanted to know what you guys think of this problem, how you would solve it, if it&amp;#39;s even an appropriate DS question etc...&lt;/p&gt;\n\n&lt;p&gt;The problem goes something like this: You are a data scientist that works at an e-commerce platform that sells experiences at Paris (think bicycle rides, wine tours, etc...). The company doesn&amp;#39;t own any products but rather takes a commission from every product sold.&lt;/p&gt;\n\n&lt;p&gt;You have access to a table of 500 such products (for Paris only) that has columns like title, category, review count, review avg, price, duration, when it was posted, etc... (maybe 2-3 more but these seem more like internal IDs that don&amp;#39;t really matter). The three questions we went over before she gave up on me were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How would you pick 1-2 metrics from this column to sort these listings? (To build a quick formula for ranking these listings)&lt;/li&gt;\n&lt;li&gt;What are some disadvantages of this approach?&lt;/li&gt;\n&lt;li&gt;How would you predict that the rankings will change in 6 months from today (assuming I implemented my strategy)?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My answers where:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I would pick the review avg and count. normalize the count, like minmax so that it is in the same range as the review avg, and weight the review count and review avg by a alpha and (1 - alpha) for example. Should have I picked price instead of review count? I didn&amp;#39;t because I would assume that the revenue generated per product would be somewhat similar (I also asked how they take commission and the answer I got was to use price as the proxy for commission which imo makes no sense, the rates wouldn&amp;#39;t be the same for all of the prices right?), otherwise they would not have signed that product plus, for longer term growth I would assume UX would be more important that money generated short term, i.e. recommend things that the user would like more... should have I used the inverse of the review count to treat this problem more like a multi armed bandit with the UCB strategy?&lt;/li&gt;\n&lt;li&gt;I said that this approach wouldn&amp;#39;t give a higher ranking to newer products and that it would be more dificult for these new products to rank&lt;/li&gt;\n&lt;li&gt;I pretty much said the same as 2. because I also gave up around here&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The questions I have are: why ask a question that doesn&amp;#39;t allow me to use ML? I understand having a baseline, but still... I briefly mentioned multi armed bandits and she overlooked what I said. If this was a business case why didn&amp;#39;t I get more context? I asked what was the bigger context, if this was for a ranking algorithm, and got a not very convincing &amp;quot;sure&amp;quot; (tbh using the term &amp;quot;sort&amp;quot; here somewhat confused me, I usually see the term &amp;quot;ranking&amp;quot; for these problems, it looked like she was avoiding it for some reason). I then asked what was their current approach for sorting these listings and she didn&amp;#39;t answer...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b853sy", "is_robot_indexable": true, "report_reasons": null, "author": "AromaticCantaloupe19", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b853sy/how_would_you_approach_this_interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b853sy/how_would_you_approach_this_interview_question/", "subreddit_subscribers": 1399902, "created_utc": 1709745015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Be gentle, I'm learning here. I have a fairly simple adaptive lasso regression that I'm trying to test for a minimum sample size. I used cross-validated mean squared error as the \"score\" of model accuracy. Where I am stuck is how to analyze each group of samples to determine at what point the CV-MSE stops being significantly different from the last smaller size. I believe the tactic is good, or maybe not, please tell me. But just stuck on how to decide which sample size to select.\n\n[Just a box plot visualization of cross-validated mean squared error from the simulation. Black dots represent a single test for that sample size. Purple line is the median of CV MSE, and yellow is the mean.](https://preview.redd.it/hu2cpyo26qmc1.png?width=3076&amp;format=png&amp;auto=webp&amp;s=b9933681140e667edbacc74722a6d02de9668a37)", "author_fullname": "t2_okwnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lasso Regression Sample Size", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hu2cpyo26qmc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=af42f047497c07c5a759e5dae2f5ea914815da33"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=659f17c742b03704b4f90ae4b1bdc027dac58b6e"}, {"y": 209, "x": 320, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c86a31691b2942dfc61592ece739cf0e6514d3f"}, {"y": 418, "x": 640, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e7e17daec752d58bcbd3a213061115a3e5f958b"}, {"y": 627, "x": 960, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a8695545dee1e43562d02fad396112b93763530b"}, {"y": 705, "x": 1080, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39a3f9121373363a34a46546b4a9dcb06b1044da"}], "s": {"y": 2010, "x": 3076, "u": "https://preview.redd.it/hu2cpyo26qmc1.png?width=3076&amp;format=png&amp;auto=webp&amp;s=b9933681140e667edbacc74722a6d02de9668a37"}, "id": "hu2cpyo26qmc1"}}, "name": "t3_1b81cq3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/coFDrMx9BN4AAsuCMd9Q5gtH7NWNe8y3yL6CK53w8xg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709736094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Be gentle, I&amp;#39;m learning here. I have a fairly simple adaptive lasso regression that I&amp;#39;m trying to test for a minimum sample size. I used cross-validated mean squared error as the &amp;quot;score&amp;quot; of model accuracy. Where I am stuck is how to analyze each group of samples to determine at what point the CV-MSE stops being significantly different from the last smaller size. I believe the tactic is good, or maybe not, please tell me. But just stuck on how to decide which sample size to select.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hu2cpyo26qmc1.png?width=3076&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b9933681140e667edbacc74722a6d02de9668a37\"&gt;Just a box plot visualization of cross-validated mean squared error from the simulation. Black dots represent a single test for that sample size. Purple line is the median of CV MSE, and yellow is the mean.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b81cq3", "is_robot_indexable": true, "report_reasons": null, "author": "jrdubbleu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b81cq3/lasso_regression_sample_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b81cq3/lasso_regression_sample_size/", "subreddit_subscribers": 1399902, "created_utc": 1709736094.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear hive mind, I'm in the fortunate position to have offers for two positions. They pay both basically the same however\n1. Position 1 is in a large, multinational company which is currently modernizing it's product portfolio and invests heavily in research and development, where I would work on ML models for all sorts of products. I would be required to be at the office about 50% of the time and attendance is tracked using some app. The tech stack is somewhat out of date but modernizing it would be part of my tasks. Here I could learn a lot about several different domains of machine learning and data science. \n2. Position 2 is at a former startup which was recently bought by a larger company. I would have 100% wfh and a very modern tech stack, however my work would focus strongly on a very narrow range of models which are interesting to one single industry. However, this company is basically a software company so that I could learn a lot about software development and ML engineering. \n\nSo what position would you take? I tend towards position 1 because I liked doing research at university (did my PhD in math) but position 2 seems to have better benefits and engineering is interesting as well? Also I think the skills I learn at position 1 are more valuable when switching jobs again, but I'm not sure about that. \n\nWhat would be the key factors you are looking for when considering a new position? \n\nThank you all in advance. \n\nEdit: for reference, I'm living in Europe and have worked as a data scientist for four years, currently being a senior DS. ", "author_fullname": "t2_dhv2p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Research or software development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b84uff", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709746628.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709744430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear hive mind, I&amp;#39;m in the fortunate position to have offers for two positions. They pay both basically the same however\n1. Position 1 is in a large, multinational company which is currently modernizing it&amp;#39;s product portfolio and invests heavily in research and development, where I would work on ML models for all sorts of products. I would be required to be at the office about 50% of the time and attendance is tracked using some app. The tech stack is somewhat out of date but modernizing it would be part of my tasks. Here I could learn a lot about several different domains of machine learning and data science. \n2. Position 2 is at a former startup which was recently bought by a larger company. I would have 100% wfh and a very modern tech stack, however my work would focus strongly on a very narrow range of models which are interesting to one single industry. However, this company is basically a software company so that I could learn a lot about software development and ML engineering. &lt;/p&gt;\n\n&lt;p&gt;So what position would you take? I tend towards position 1 because I liked doing research at university (did my PhD in math) but position 2 seems to have better benefits and engineering is interesting as well? Also I think the skills I learn at position 1 are more valuable when switching jobs again, but I&amp;#39;m not sure about that. &lt;/p&gt;\n\n&lt;p&gt;What would be the key factors you are looking for when considering a new position? &lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance. &lt;/p&gt;\n\n&lt;p&gt;Edit: for reference, I&amp;#39;m living in Europe and have worked as a data scientist for four years, currently being a senior DS. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b84uff", "is_robot_indexable": true, "report_reasons": null, "author": "Hero_without_Powers", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b84uff/research_or_software_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b84uff/research_or_software_development/", "subreddit_subscribers": 1399902, "created_utc": 1709744430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a job interview for a role I really want. They said i have the exact same experience and they reached out to me. \n\nIn the process they said they will cover stuff like\nProbability, machine learning, etc..\nThats all good but they said they have two interviews were you build\nA ml algorithm on the spot\nA optimization model on the spot.\n\nFor those that did those what should i do and prepare. I really want to do well.\n\nEspecially optimization for mip and lp problems. ", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you prepare for optimization interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b84dad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709743329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a job interview for a role I really want. They said i have the exact same experience and they reached out to me. &lt;/p&gt;\n\n&lt;p&gt;In the process they said they will cover stuff like\nProbability, machine learning, etc..\nThats all good but they said they have two interviews were you build\nA ml algorithm on the spot\nA optimization model on the spot.&lt;/p&gt;\n\n&lt;p&gt;For those that did those what should i do and prepare. I really want to do well.&lt;/p&gt;\n\n&lt;p&gt;Especially optimization for mip and lp problems. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b84dad", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b84dad/how_do_you_prepare_for_optimization_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b84dad/how_do_you_prepare_for_optimization_interviews/", "subreddit_subscribers": 1399902, "created_utc": 1709743329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "1. Is it true that during train and test split of data we can observe a data shift? If yes, is it significant?\n2. Is there any other way to split the data so as to terminate/minimize data shift?", "author_fullname": "t2_3wr0pzmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data shift while splitting data into train and test set", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b7sf8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709704918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;Is it true that during train and test split of data we can observe a data shift? If yes, is it significant?&lt;/li&gt;\n&lt;li&gt;Is there any other way to split the data so as to terminate/minimize data shift?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b7sf8d", "is_robot_indexable": true, "report_reasons": null, "author": "sARUcasm", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b7sf8d/data_shift_while_splitting_data_into_train_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b7sf8d/data_shift_while_splitting_data_into_train_and/", "subreddit_subscribers": 1399902, "created_utc": 1709704918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I need to build a regression model at my new job. It\u2019s up to me what type of regression model I build using data from my company. \nI have access to employee data such as hours employees have worked, hours worked on projects, different types of leave (eg annual leave, sickness..)\nCan I build a regression model with this data? ", "author_fullname": "t2_nalcnkfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me build a regression model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b83ur1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709742116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to build a regression model at my new job. It\u2019s up to me what type of regression model I build using data from my company. \nI have access to employee data such as hours employees have worked, hours worked on projects, different types of leave (eg annual leave, sickness..)\nCan I build a regression model with this data? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b83ur1", "is_robot_indexable": true, "report_reasons": null, "author": "Careful-Ingenuity674", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b83ur1/help_me_build_a_regression_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b83ur1/help_me_build_a_regression_model/", "subreddit_subscribers": 1399902, "created_utc": 1709742116.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}