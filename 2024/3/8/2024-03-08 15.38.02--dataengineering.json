{"kind": "Listing", "data": {"after": "t3_1b95rtd", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster University | Dagster &amp; dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1b96lr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 96, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 96, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i7uvXAQehTiTa-GR06ule2ZxoK0CwW6OmbEs5i42OLc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709848417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "courses.dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://courses.dagster.io/courses/dagster-dbt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?auto=webp&amp;s=2b2ad690130139debc526a5f823b5cf404c0dddb", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a07bb99f808bf6061884accddb56896352108f9", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a3d3dc8ebf131273408ef99ce2b2b94175ff40d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f808fdd3dad44f069fcf35c0a8df705f437b3300", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e1a5b7d305c395c05135bd0541f636bdaec6286", "width": 640, "height": 336}], "variants": {}, "id": "Xo4201FG41r9g9jTl6ooInnjJ_aXjb09SNDclCPTp0k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b96lr0", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b96lr0/dagster_university_dagster_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://courses.dagster.io/courses/dagster-dbt", "subreddit_subscribers": 166903, "created_utc": 1709848417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the worst data related decision a company made that left you speechless ", "author_fullname": "t2_sunv53vps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's that one WTF moment you had that made you leave a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b91l3e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709835543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the worst data related decision a company made that left you speechless &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b91l3e", "is_robot_indexable": true, "report_reasons": null, "author": "Eastern-Education-31", "discussion_type": null, "num_comments": 97, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b91l3e/whats_that_one_wtf_moment_you_had_that_made_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b91l3e/whats_that_one_wtf_moment_you_had_that_made_you/", "subreddit_subscribers": 166903, "created_utc": 1709835543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I've found gifs with this style on LinkedIn a couple of times and I wonder which tool was it made on. In some posts they say it's Excalidraw, but I can't find the moving arrows style.\n\nBut let's not make it so specific. Which visual tools do you use to diagram your data architectures/solutions? I almost always use **draw.io**\n\nhttps://i.redd.it/wwy0b4byi0nc1.gif", "author_fullname": "t2_9d3dxxer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture diagram tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wwy0b4byi0nc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 129, "x": 108, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=f6fccae06d86170a03777bd3bcb198fcdaf49de0"}, {"y": 258, "x": 216, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=b1767f3a5e350e5a9c6495c370dad93f0f0fb1a3"}, {"y": 383, "x": 320, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=d8779f649af117c04b557551dac3d92476086e1f"}, {"y": 767, "x": 640, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=bda04f64c43d62dc2b1e442ab699d092a5599527"}, {"y": 1150, "x": 960, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=467ddf6a798a5083023710960b9a99eb719a8f41"}, {"y": 1294, "x": 1080, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=a803dd832179b89545c952d1b515ab76dca8c946"}], "s": {"y": 1496, "gif": "https://i.redd.it/wwy0b4byi0nc1.gif", "mp4": "https://preview.redd.it/wwy0b4byi0nc1.gif?format=mp4&amp;s=0d9dbbe1552c35488d79d1f4fa73ad49e9306506", "x": 1248}, "id": "wwy0b4byi0nc1"}}, "name": "t3_1b9ba5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A7N4PCE0t_kDJIsOZAwZ9FDPvb9k9U79N-xJ_Q1db1E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709861244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;ve found gifs with this style on LinkedIn a couple of times and I wonder which tool was it made on. In some posts they say it&amp;#39;s Excalidraw, but I can&amp;#39;t find the moving arrows style.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s not make it so specific. Which visual tools do you use to diagram your data architectures/solutions? I almost always use &lt;strong&gt;draw.io&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/wwy0b4byi0nc1.gif\"&gt;https://i.redd.it/wwy0b4byi0nc1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9ba5c", "is_robot_indexable": true, "report_reasons": null, "author": "thehelptea", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9ba5c/data_architecture_diagram_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9ba5c/data_architecture_diagram_tools/", "subreddit_subscribers": 166903, "created_utc": 1709861244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm excited to share my latest blog post, \"From dbt to SQLMesh\" \n\nCheck it out here  [https://www.harness.io/blog/from-dbt-to-sqlmesh](https://www.harness.io/blog/from-dbt-to-sqlmesh)\n\nWe have been running sqlmesh in production in some way shape or form for a long time now, since the earliest versions of the tool. This post is focused on high level migration approach (which is the reason we were able to adopt quickly and drive innovation) &amp; touches on the learnings and key takeaways too. Major points include simplification, no jinja (sqlglot macros instead creating valid and structurally correct sql syntax vs string interpolation free-for-all), better state management and simplified CICD+dev experience. Has been a rewarding experience and paid off manyfold in the quality, reliability, and maintainability of our data platform. And we are poised to scale extremely effectively. I hope this is useful for any folks looking for information on the topic or are just curious.", "author_fullname": "t2_bnmvkmcq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From dbt to SQLMesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b912nc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709834347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m excited to share my latest blog post, &amp;quot;From dbt to SQLMesh&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Check it out here  &lt;a href=\"https://www.harness.io/blog/from-dbt-to-sqlmesh\"&gt;https://www.harness.io/blog/from-dbt-to-sqlmesh&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We have been running sqlmesh in production in some way shape or form for a long time now, since the earliest versions of the tool. This post is focused on high level migration approach (which is the reason we were able to adopt quickly and drive innovation) &amp;amp; touches on the learnings and key takeaways too. Major points include simplification, no jinja (sqlglot macros instead creating valid and structurally correct sql syntax vs string interpolation free-for-all), better state management and simplified CICD+dev experience. Has been a rewarding experience and paid off manyfold in the quality, reliability, and maintainability of our data platform. And we are poised to scale extremely effectively. I hope this is useful for any folks looking for information on the topic or are just curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?auto=webp&amp;s=c1fa91492ec85dde2cc551d64a479a15fc202571", "width": 1806, "height": 715}, "resolutions": [{"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=648b4ebdda1e7006e43d2186982a32fb68c70671", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63803909338b1e089837c44c72f384d3ec98a074", "width": 216, "height": 85}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f35c17cd58802bc65fb7cea9175da69e9110c977", "width": 320, "height": 126}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aba361bf8337f9bf8d3cb96af5be4bc6b28fa7d6", "width": 640, "height": 253}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=79ee662e4a48b06a40cc63edd7f3b8dd1049b199", "width": 960, "height": 380}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=170560a91625a85482e2a13307d4f57bb411da9c", "width": 1080, "height": 427}], "variants": {}, "id": "h1cq6A3022auvjfrixpGE5rrKpYSJm_jmuxfWZCRsn8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b912nc", "is_robot_indexable": true, "report_reasons": null, "author": "Academic_Ad_8747", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b912nc/from_dbt_to_sqlmesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b912nc/from_dbt_to_sqlmesh/", "subreddit_subscribers": 166903, "created_utc": 1709834347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am aware the answer will depend on many cases of what is the stack of the company, budget and familiarity but If you are working with one of these daily imagine you are selling/pitching each of these DW solutions here!", "author_fullname": "t2_42yrzhea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks SQL, Amazon Redshift, GBQ or Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8zeek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709830411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am aware the answer will depend on many cases of what is the stack of the company, budget and familiarity but If you are working with one of these daily imagine you are selling/pitching each of these DW solutions here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b8zeek", "is_robot_indexable": true, "report_reasons": null, "author": "josejo9423", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8zeek/databricks_sql_amazon_redshift_gbq_or_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8zeek/databricks_sql_amazon_redshift_gbq_or_snowflake/", "subreddit_subscribers": 166903, "created_utc": 1709830411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys. I'd like to become DE, I'm a bit fed up with BI after many years. I'm not sure where to start, as my current company does not throw such tasks at me. I have mainly reporting background:\n\n\\- OBIEE, Tableau - very well known, licked some PBI\n\n\\- Simple SQL queries - I know how to select &amp; join, some performance principles and that's it\n\n\\- I know how to set up a python env on my local machine, install libraries ;)\n\n\\- I know data modeling fundamentals and principles, did some modeling in Oracle BI \n\nWhere shall I aim next? I was thinking Rasp Pi + Postgresql, do some ETL on that, add some other tools maybe to it? But which? \n\nI'd like to ask you, more experienced DE, for some advice how to get it spinning. \n\nAlso would love some suggestions on where to get some free data sets to work on, I know only Kaggle tbh.\n\nThanks!", "author_fullname": "t2_n0it8b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Become DE with BI background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9mv4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709901268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I&amp;#39;d like to become DE, I&amp;#39;m a bit fed up with BI after many years. I&amp;#39;m not sure where to start, as my current company does not throw such tasks at me. I have mainly reporting background:&lt;/p&gt;\n\n&lt;p&gt;- OBIEE, Tableau - very well known, licked some PBI&lt;/p&gt;\n\n&lt;p&gt;- Simple SQL queries - I know how to select &amp;amp; join, some performance principles and that&amp;#39;s it&lt;/p&gt;\n\n&lt;p&gt;- I know how to set up a python env on my local machine, install libraries ;)&lt;/p&gt;\n\n&lt;p&gt;- I know data modeling fundamentals and principles, did some modeling in Oracle BI &lt;/p&gt;\n\n&lt;p&gt;Where shall I aim next? I was thinking Rasp Pi + Postgresql, do some ETL on that, add some other tools maybe to it? But which? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask you, more experienced DE, for some advice how to get it spinning. &lt;/p&gt;\n\n&lt;p&gt;Also would love some suggestions on where to get some free data sets to work on, I know only Kaggle tbh.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b9mv4d", "is_robot_indexable": true, "report_reasons": null, "author": "maciekszlachta", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9mv4d/become_de_with_bi_background/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9mv4d/become_de_with_bi_background/", "subreddit_subscribers": 166903, "created_utc": 1709901268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Leveraging Schipol Dev API, I've built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard [here](https://aeroatlas.streamlit.app/). I'd love your feedback, suggestions, and opinions to enhance this data-driven journey!", "author_fullname": "t2_rw01dudv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just launched my first data engineering project!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9hnn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709880414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Leveraging Schipol Dev API, I&amp;#39;ve built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard &lt;a href=\"https://aeroatlas.streamlit.app/\"&gt;here&lt;/a&gt;. I&amp;#39;d love your feedback, suggestions, and opinions to enhance this data-driven journey!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?auto=webp&amp;s=9865438c46b36f6ceceae2a4f691e77823f49706", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f2a7fdcf1696abd365a02221e38e0fec9fbccf0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c78b890a0a78713482641dfc23ab4bb06accfbb0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ead203f9bd786ae0ce939c56d4de097a9b7bbb9a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c17981a8c5361bba27539e884ea4406a31af7e9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=987bef2e4dbcf6165f0aafad164259f6f3b31560", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9eb15378a2902c32993c4d17ff71148add906e4", "width": 1080, "height": 567}], "variants": {}, "id": "5noDdCvNFXIpfSURWR11QJ056eivlSF0Fxt4b3n6Wyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b9hnn0", "is_robot_indexable": true, "report_reasons": null, "author": "botuleman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/", "subreddit_subscribers": 166903, "created_utc": 1709880414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I just recently started working as a consultant, I'm being offered to work in a project with databricks. My main question is how valuable can be the experience I could get from that project in the look for developing my career? I've seen there's a a lot of mix reviews on databricks, so I would like to hear your opinions and experiences.\nThanks in advance :)", "author_fullname": "t2_q9k8q4cy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks value ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9b9oa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709861205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I just recently started working as a consultant, I&amp;#39;m being offered to work in a project with databricks. My main question is how valuable can be the experience I could get from that project in the look for developing my career? I&amp;#39;ve seen there&amp;#39;s a a lot of mix reviews on databricks, so I would like to hear your opinions and experiences.\nThanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9b9oa", "is_robot_indexable": true, "report_reasons": null, "author": "Cid-Cthulhu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9b9oa/databricks_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9b9oa/databricks_value/", "subreddit_subscribers": 166903, "created_utc": 1709861205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI just recently joined a big pharma company to do some data engineering tasks (I'm basically more on the data science side, but have some experiences in building data pipelines).\n\nIn my previous company (a typical tech startup), building a data pipeline is relatively straightforward, most data sources either have data connectors or APIs so you can easily access the data and ingest them into the data lake/data warehouse, and you can use a lot of open-source tools for data transformation.\n\nHowever, this time, I work with a lot of data generated from lab instruments, which typically need to be processed with specific software (typically the software made by the instruments' vendors). These software are either desktop app, and/or do not have any programmatic way (API or CLI) to access them. The raw data format is also often non standard text format (i.e. propriatary binary data format and there were no data parser available for most of them). Moreover, data processing is also not straightforward as often times it requires specific expertise in interpreting the meaningful information out of raw data, for example manual labeling and data selection from lab scientists.\n\nHas anyone had any experience in building a data pipeline in this kinda settings? I wonder if I can pick up some successful strategies you guys have implemented previously.\n\nThank you.", "author_fullname": "t2_as9pcaig", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering in a biopharma/biotech company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8z73y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709829933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I just recently joined a big pharma company to do some data engineering tasks (I&amp;#39;m basically more on the data science side, but have some experiences in building data pipelines).&lt;/p&gt;\n\n&lt;p&gt;In my previous company (a typical tech startup), building a data pipeline is relatively straightforward, most data sources either have data connectors or APIs so you can easily access the data and ingest them into the data lake/data warehouse, and you can use a lot of open-source tools for data transformation.&lt;/p&gt;\n\n&lt;p&gt;However, this time, I work with a lot of data generated from lab instruments, which typically need to be processed with specific software (typically the software made by the instruments&amp;#39; vendors). These software are either desktop app, and/or do not have any programmatic way (API or CLI) to access them. The raw data format is also often non standard text format (i.e. propriatary binary data format and there were no data parser available for most of them). Moreover, data processing is also not straightforward as often times it requires specific expertise in interpreting the meaningful information out of raw data, for example manual labeling and data selection from lab scientists.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had any experience in building a data pipeline in this kinda settings? I wonder if I can pick up some successful strategies you guys have implemented previously.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8z73y", "is_robot_indexable": true, "report_reasons": null, "author": "mardian-octopus", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8z73y/data_engineering_in_a_biopharmabiotech_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8z73y/data_engineering_in_a_biopharmabiotech_company/", "subreddit_subscribers": 166903, "created_utc": 1709829933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm working on streamlining our data engineering processes using AWS Glue, and I'd love to learn from others' experiences regarding:\n\n* **Terraform for Glue:** Do you use Terraform to manage and provision your AWS Glue jobs and related infrastructure? If so, would you be willing to share some insights into your setup and any helpful tips?\n* **CI/CD for Glue scripts:** How do you integrate CI/CD (e.g., GitLab CI/CD) to synchronize Python scripts with S3 buckets? Do you employ a monorepo strategy, or do you have a preferred alternative? What triggers your CI/CD pipelines (file changes, scheduled updates, etc.)?\n\nI'd greatly appreciate any details on your best practices and any challenges you've overcome.\n\nThank you in advance for sharing your expertise!", "author_fullname": "t2_d9r3cjd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for Terraform, AWS Glue, and CI/CD in data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8ytdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709828724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on streamlining our data engineering processes using AWS Glue, and I&amp;#39;d love to learn from others&amp;#39; experiences regarding:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Terraform for Glue:&lt;/strong&gt; Do you use Terraform to manage and provision your AWS Glue jobs and related infrastructure? If so, would you be willing to share some insights into your setup and any helpful tips?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CI/CD for Glue scripts:&lt;/strong&gt; How do you integrate CI/CD (e.g., GitLab CI/CD) to synchronize Python scripts with S3 buckets? Do you employ a monorepo strategy, or do you have a preferred alternative? What triggers your CI/CD pipelines (file changes, scheduled updates, etc.)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d greatly appreciate any details on your best practices and any challenges you&amp;#39;ve overcome.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for sharing your expertise!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8ytdj", "is_robot_indexable": true, "report_reasons": null, "author": "Warsoco", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8ytdj/best_practices_for_terraform_aws_glue_and_cicd_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8ytdj/best_practices_for_terraform_aws_glue_and_cicd_in/", "subreddit_subscribers": 166903, "created_utc": 1709828724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nI have a basic question today, so please bear with me. I've been working with Azure Databricks for just a few months.\n\nMy question is about storage options. Initially, I was under the impression that using ADLS and storing files extracted from SAP S/4HANA in the raw layer as Parquet was the optimal approach. I believed that Parquet was the most suitable format for this purpose. However, I've recently learned that aside from ADLS, it's also possible to store data in Cassandra. This discovery has led me to wonder: if Cassandra is capable of storing highly structured data from SAP, might it be a better choice?\n\nAm I oversimplifying the issue by not fully considering factors like the cost differences between saving data in Parquet versus storing it in Cassandra, or potential use cases like analytic reporting versus write preference?\n\nI would greatly appreciate your perspective on how to make this decision.\n\nThanks.", "author_fullname": "t2_5b8k9nl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cassandra or Praquet for structured data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9bnak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709862251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;I have a basic question today, so please bear with me. I&amp;#39;ve been working with Azure Databricks for just a few months.&lt;/p&gt;\n\n&lt;p&gt;My question is about storage options. Initially, I was under the impression that using ADLS and storing files extracted from SAP S/4HANA in the raw layer as Parquet was the optimal approach. I believed that Parquet was the most suitable format for this purpose. However, I&amp;#39;ve recently learned that aside from ADLS, it&amp;#39;s also possible to store data in Cassandra. This discovery has led me to wonder: if Cassandra is capable of storing highly structured data from SAP, might it be a better choice?&lt;/p&gt;\n\n&lt;p&gt;Am I oversimplifying the issue by not fully considering factors like the cost differences between saving data in Parquet versus storing it in Cassandra, or potential use cases like analytic reporting versus write preference?&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your perspective on how to make this decision.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9bnak", "is_robot_indexable": true, "report_reasons": null, "author": "scht1980", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9bnak/cassandra_or_praquet_for_structured_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9bnak/cassandra_or_praquet_for_structured_data/", "subreddit_subscribers": 166903, "created_utc": 1709862251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I won't give much context here as I work with classified data, I'm a software engineer(not a data engineer).\n\nWhat are some viable options for me to move big data from MS SQL SERVER to PostgreSQL for a daily batch process. The data is large enough for LINKED SERVER to be bottleneck while transferring to PostgreSQL.\n\nI thought of Apache SPARK, if so can you give me the drawbacks.  \n\n\nThank You!", "author_fullname": "t2_121fx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on ELT: MS SQL SERVER to PostgreSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9alt0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709859429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I won&amp;#39;t give much context here as I work with classified data, I&amp;#39;m a software engineer(not a data engineer).&lt;/p&gt;\n\n&lt;p&gt;What are some viable options for me to move big data from MS SQL SERVER to PostgreSQL for a daily batch process. The data is large enough for LINKED SERVER to be bottleneck while transferring to PostgreSQL.&lt;/p&gt;\n\n&lt;p&gt;I thought of Apache SPARK, if so can you give me the drawbacks.  &lt;/p&gt;\n\n&lt;p&gt;Thank You!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9alt0", "is_robot_indexable": true, "report_reasons": null, "author": "Vanvil", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9alt0/need_advice_on_elt_ms_sql_server_to_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9alt0/need_advice_on_elt_ms_sql_server_to_postgresql/", "subreddit_subscribers": 166903, "created_utc": 1709859429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa5dw92do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stop Paying Snowflake for Failing Workloads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9oqr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wOM8ib6rTYoiI0FU8X1XFvJdcf2IDdqmc2UArIGxy-w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709906752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "baselit.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://baselit.ai/blog/stop-paying-snowflake-for-failing-workloads", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mFxH8sLMQjxtNCSxcLFOp9GRmZS2bBRwesfpb1vev3I.jpg?auto=webp&amp;s=8ee32ef232f1d9b4ad2813e8f617ec61acdebbf3", "width": 1024, "height": 773}, "resolutions": [{"url": "https://external-preview.redd.it/mFxH8sLMQjxtNCSxcLFOp9GRmZS2bBRwesfpb1vev3I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=543ee50b5969a2641d08e32aaebcbf150d40c49b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/mFxH8sLMQjxtNCSxcLFOp9GRmZS2bBRwesfpb1vev3I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7b7208f26ffcd6ba77f097a8ba46da5e5c680ff7", "width": 216, "height": 163}, {"url": "https://external-preview.redd.it/mFxH8sLMQjxtNCSxcLFOp9GRmZS2bBRwesfpb1vev3I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=827fe7c2852c9add08b2640bd191572a846a4354", "width": 320, "height": 241}, {"url": "https://external-preview.redd.it/mFxH8sLMQjxtNCSxcLFOp9GRmZS2bBRwesfpb1vev3I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36dfead6e99a4bee4a2ddf38c8dcc663472ed621", "width": 640, "height": 483}, {"url": "https://external-preview.redd.it/mFxH8sLMQjxtNCSxcLFOp9GRmZS2bBRwesfpb1vev3I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=846d7d76ba880b788d64436cef4ffe9e1ca0edac", "width": 960, "height": 724}], "variants": {}, "id": "r3CgWc1G_RZzYfh9ko9igTDnHUgYIslIfknt6RfU6cw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b9oqr9", "is_robot_indexable": true, "report_reasons": null, "author": "sahil_singla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9oqr9/stop_paying_snowflake_for_failing_workloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://baselit.ai/blog/stop-paying-snowflake-for-failing-workloads", "subreddit_subscribers": 166903, "created_utc": 1709906752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productizing data services: Removing fears with the LEAP framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9jo2d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4_KghhkXNwF2MIVMXdjqEUFrvMGkB0MN-MCA3SHlJQ4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709888125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/productizing-data-services-removing-fears-with-the-leap-framework/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?auto=webp&amp;s=22d019227459e8dd7ec6d7a1301a5e1950f97720", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=39d71177e71f497f070771f54b052c7461e2750b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=321ddb2bf8d4648c8c5c48707ec103d0a4f55ca5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19a4e2baad28afcd3a08c53ea65e3ffc6a543855", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f05bd0cb86c47d0b4102f59fdf74ce84228b3cb8", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f984af9a0053478168a803638ccff44f27b7bf9c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d76b6c44c877e3ff283b61bf924d27d6d6c4fdfc", "width": 1080, "height": 607}], "variants": {}, "id": "FvmfvAiv20GoQlJeug9X3S4maUuzOWIK6kXMvqVo8GY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b9jo2d", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9jo2d/productizing_data_services_removing_fears_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/productizing-data-services-removing-fears-with-the-leap-framework/", "subreddit_subscribers": 166903, "created_utc": 1709888125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a dataset that consists of thousands of JSONL files (one JSON object per line). About 800GB in total, and 288 files of 15-50MB are added each day. Each file contains JSON objects with different schemas. Example:\n\n&amp;#x200B;\n\n[Each 'LogAnalyticsCategory' has a different schema \\(not visible in the picture, but you get the point\\)](https://preview.redd.it/t6hmtz0i6ymc1.png?width=1332&amp;format=png&amp;auto=webp&amp;s=84105e3453bfaed8019ec8f9dadebbeccc8d8d5c)\n\nEventually each category needs to go into a different destination table (sink = Postgres), but I'm unsure how to do this efficiently. I can do it easily with BigQuery, but given the volume of the data that will become too expensive, especially as the data will be queried for analytical purposes.  \n\nMy toolkit for now is basically limited to Python on a single machine. My source files are stored on GCS. Looping over the rows to figure out the schema of each line will probably be horribly slow. How do I best approach this (in the most simple way)?", "author_fullname": "t2_4p5ynpa6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you ETL JSONL data with different schemas in the same file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": false, "media_metadata": {"t6hmtz0i6ymc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 44, "x": 108, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bfb81a3f40b4871ec6539b5c65df606bf4052cdd"}, {"y": 88, "x": 216, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe10d6782a7f08950470479c306976590172909d"}, {"y": 131, "x": 320, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7cb49d064ac5f7c4ec92e7ec3052b9a80ffddb4"}, {"y": 263, "x": 640, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e714ed9513425640331c17b19b16beff59a751bb"}, {"y": 394, "x": 960, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d034d6302c4c81fccd13961b6130bd8ee405113"}, {"y": 444, "x": 1080, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=674b770c4a6d1ef59a9cd46f0206bbd0e2bc85dd"}], "s": {"y": 548, "x": 1332, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=1332&amp;format=png&amp;auto=webp&amp;s=84105e3453bfaed8019ec8f9dadebbeccc8d8d5c"}, "id": "t6hmtz0i6ymc1"}}, "name": "t3_1b90nap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6s1jmiqjCe2hjpbsHFMJ1_qC9jdrglSQWSlGfaTTCpo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709833339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset that consists of thousands of JSONL files (one JSON object per line). About 800GB in total, and 288 files of 15-50MB are added each day. Each file contains JSON objects with different schemas. Example:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/t6hmtz0i6ymc1.png?width=1332&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84105e3453bfaed8019ec8f9dadebbeccc8d8d5c\"&gt;Each &amp;#39;LogAnalyticsCategory&amp;#39; has a different schema (not visible in the picture, but you get the point)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Eventually each category needs to go into a different destination table (sink = Postgres), but I&amp;#39;m unsure how to do this efficiently. I can do it easily with BigQuery, but given the volume of the data that will become too expensive, especially as the data will be queried for analytical purposes.  &lt;/p&gt;\n\n&lt;p&gt;My toolkit for now is basically limited to Python on a single machine. My source files are stored on GCS. Looping over the rows to figure out the schema of each line will probably be horribly slow. How do I best approach this (in the most simple way)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b90nap", "is_robot_indexable": true, "report_reasons": null, "author": "unplannedmaintenance", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b90nap/how_would_you_etl_jsonl_data_with_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b90nap/how_would_you_etl_jsonl_data_with_different/", "subreddit_subscribers": 166903, "created_utc": 1709833339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can't get concurrent users to increase no matter the server's CPU power.\n\nHello, I'm working on a production web application that has a giant MySQL database at the backend. The database is constantly updated with new information from various sources at different timestamps every single day. The web application is report-generation-based, where the user 'generates reports' of data from a certain time range they specify, which is done by querying against the database. This querying of MySQL takes a lot of time and is CPU intensive (observed from htop). MySQL contains various types of data, especially large-string data. Now, to generate a complex report for a single user, it uses 1 CPU (thread or vCPU), not the whole number of CPUs available. Similarly, for 4 users, 4 CPUs, and the rest of the CPUs are idle. I simulate multiple concurrent users' report generation tests using the PostMan application. **Now, no matter how powerful the CPU I use, it is not being efficient and caps at around 30-40 concurrent users (powerful CPU results in higher caps) and also takes a lot of time.**\n\nWhen multiple users are simultaneously querying the database, all logical cores of the server become preoccupied with handling MySQL queries, which in turn reduces the application's ability to manage concurrent users effectively. For example, a single user might generate a report for one month's worth of data in 5 minutes. However, if 20 to 30 users attempt to generate the same report simultaneously, the completion time can extend to as much as 30 minutes. Also, **when the volume of concurrent requests grows further, some users may experience failures in receiving their report outputs successfully.**\n\nI am thinking of parallel computing and using all available CPUs for each report generation instead of using only 1 CPU, but it has its disadvantages. If a rogue user constantly keeps generating very complex reports, other users will not be able to get fruitful results. So I'm currently not considering this option.\n\nIs there any other way I can improve this from a query perspective or any other perspective? Please can anyone help me find a solution to this problem? What type of architecture should be used to keep the same performance for all concurrent users and also increase the concurrent users cap (our requirement is about 100+ concurrent users)?\n\n# Additional Information:\n\nBackend: Dotnet Core 6 Web API (MVC)\n\n# Database:\n\nMySql Community Server\u00a0(free\u00a0version)  \n**table 48, data length 3,368,960,000, indexes\u00a081,920**  \nBut in my calculation, I mostly only need to query from 2 big tables:\n\n# 1st table information:\n\nEvery 24 hours, 7,153 rows are inserted into our database, each identified by a timestamp range from start (timestamp) to finish (timestamp, which may be Null). When retrieving data from this table over a long date range\u2014using both start and finish times\u2014alongside an integer field representing a list of user IDs.  \nFor example, a user might request data spanning from January 1, 2024, to February 29, 2024. This duration could vary significantly, ranging from 6 months to 1 year. Additionally, the query includes a large list of user IDs (e.g., 112, 23, 45, 78, 45, 56, etc.), with each userID associated with multiple rows in the database.\n\n|Type|\n|:-|\n|bigint(20) unassigned Auto Increment|\n|int(11)|\n|int(11)|\n|timestamp \\[current\\_timestamp()\\]|\n|timestamp NULL|\n|double(10,2) NULL|\n|int(11) \\[1\\]|\n|int(11) \\[1\\]|\n|int(11) NULL|\n\n# 2nd table information:\n\nThe second table in our database experiences an insertion of 2,000 rows every 24 hours. Similar to the first, this table records data within specific time ranges, set by a start and finish timestamp. Additionally, it stores variable character data (VARCHAR) as well.  \nQueries on this table are executed over time ranges, similar to those for table one, with durations typically spanning 3 to 6 months. Along with time-based criteria like Table 1, these queries also filter for five extensive lists of string values, each list containing approximately 100 to 200 string values.\n\n|Type|\n|:-|\n|int(11) Auto Increment|\n|date|\n|int(10)|\n|varchar(200)|\n|varchar(100)|\n|varchar(100)|\n|time|\n|int(10)|\n|timestamp \\[current\\_timestamp()\\]|\n|timestamp \\[current\\_timestamp()\\]|\n|varchar(200)|\n|varchar(100)|\n|varchar(100)|\n|varchar(100)|\n|varchar(100)|\n|varchar(100)|\n|varchar(200)|\n|varchar(100)|\n|int(10)|\n|int(10)|\n|varchar(200) NULL|\n|int(100)|\n|varchar(100) NULL|\n\n# Test Results (Dedicated Bare Metal Servers):\n\nSystemInfo: Intel Xeon E5-2696 v4 | 2 sockets x 22 cores/CPU x 2 thread/core = 88\u00a0threads | 448GB DDR4 RAM  \nSingle User Report Generation time: 3mins (for 1 week's data)  \n20 Concurrent Users Report Generation time: 25 min (for 1 week's data) and 2 users report generation were unsuccessful.  \n**Maximum concurrent users it\u00a0can\u00a0handle:\u00a040**", "author_fullname": "t2_58tp8ktc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help: Optimizing MySQL for 100 Concurrent Users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9mh05", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709900020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t get concurrent users to increase no matter the server&amp;#39;s CPU power.&lt;/p&gt;\n\n&lt;p&gt;Hello, I&amp;#39;m working on a production web application that has a giant MySQL database at the backend. The database is constantly updated with new information from various sources at different timestamps every single day. The web application is report-generation-based, where the user &amp;#39;generates reports&amp;#39; of data from a certain time range they specify, which is done by querying against the database. This querying of MySQL takes a lot of time and is CPU intensive (observed from htop). MySQL contains various types of data, especially large-string data. Now, to generate a complex report for a single user, it uses 1 CPU (thread or vCPU), not the whole number of CPUs available. Similarly, for 4 users, 4 CPUs, and the rest of the CPUs are idle. I simulate multiple concurrent users&amp;#39; report generation tests using the PostMan application. &lt;strong&gt;Now, no matter how powerful the CPU I use, it is not being efficient and caps at around 30-40 concurrent users (powerful CPU results in higher caps) and also takes a lot of time.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;When multiple users are simultaneously querying the database, all logical cores of the server become preoccupied with handling MySQL queries, which in turn reduces the application&amp;#39;s ability to manage concurrent users effectively. For example, a single user might generate a report for one month&amp;#39;s worth of data in 5 minutes. However, if 20 to 30 users attempt to generate the same report simultaneously, the completion time can extend to as much as 30 minutes. Also, &lt;strong&gt;when the volume of concurrent requests grows further, some users may experience failures in receiving their report outputs successfully.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am thinking of parallel computing and using all available CPUs for each report generation instead of using only 1 CPU, but it has its disadvantages. If a rogue user constantly keeps generating very complex reports, other users will not be able to get fruitful results. So I&amp;#39;m currently not considering this option.&lt;/p&gt;\n\n&lt;p&gt;Is there any other way I can improve this from a query perspective or any other perspective? Please can anyone help me find a solution to this problem? What type of architecture should be used to keep the same performance for all concurrent users and also increase the concurrent users cap (our requirement is about 100+ concurrent users)?&lt;/p&gt;\n\n&lt;h1&gt;Additional Information:&lt;/h1&gt;\n\n&lt;p&gt;Backend: Dotnet Core 6 Web API (MVC)&lt;/p&gt;\n\n&lt;h1&gt;Database:&lt;/h1&gt;\n\n&lt;p&gt;MySql Community Server\u00a0(free\u00a0version)&lt;br/&gt;\n&lt;strong&gt;table 48, data length 3,368,960,000, indexes\u00a081,920&lt;/strong&gt;&lt;br/&gt;\nBut in my calculation, I mostly only need to query from 2 big tables:&lt;/p&gt;\n\n&lt;h1&gt;1st table information:&lt;/h1&gt;\n\n&lt;p&gt;Every 24 hours, 7,153 rows are inserted into our database, each identified by a timestamp range from start (timestamp) to finish (timestamp, which may be Null). When retrieving data from this table over a long date range\u2014using both start and finish times\u2014alongside an integer field representing a list of user IDs.&lt;br/&gt;\nFor example, a user might request data spanning from January 1, 2024, to February 29, 2024. This duration could vary significantly, ranging from 6 months to 1 year. Additionally, the query includes a large list of user IDs (e.g., 112, 23, 45, 78, 45, 56, etc.), with each userID associated with multiple rows in the database.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Type&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;bigint(20) unassigned Auto Increment&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(11)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(11)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;timestamp [current_timestamp()]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;timestamp NULL&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;double(10,2) NULL&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(11) [1]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(11) [1]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(11) NULL&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;h1&gt;2nd table information:&lt;/h1&gt;\n\n&lt;p&gt;The second table in our database experiences an insertion of 2,000 rows every 24 hours. Similar to the first, this table records data within specific time ranges, set by a start and finish timestamp. Additionally, it stores variable character data (VARCHAR) as well.&lt;br/&gt;\nQueries on this table are executed over time ranges, similar to those for table one, with durations typically spanning 3 to 6 months. Along with time-based criteria like Table 1, these queries also filter for five extensive lists of string values, each list containing approximately 100 to 200 string values.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Type&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(11) Auto Increment&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;date&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(10)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(200)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;time&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(10)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;timestamp [current_timestamp()]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;timestamp [current_timestamp()]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(200)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(200)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(10)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(10)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(200) NULL&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;int(100)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;varchar(100) NULL&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;h1&gt;Test Results (Dedicated Bare Metal Servers):&lt;/h1&gt;\n\n&lt;p&gt;SystemInfo: Intel Xeon E5-2696 v4 | 2 sockets x 22 cores/CPU x 2 thread/core = 88\u00a0threads | 448GB DDR4 RAM&lt;br/&gt;\nSingle User Report Generation time: 3mins (for 1 week&amp;#39;s data)&lt;br/&gt;\n20 Concurrent Users Report Generation time: 25 min (for 1 week&amp;#39;s data) and 2 users report generation were unsuccessful.&lt;br/&gt;\n&lt;strong&gt;Maximum concurrent users it\u00a0can\u00a0handle:\u00a040&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9mh05", "is_robot_indexable": true, "report_reasons": null, "author": "Dr-Double-A", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9mh05/need_help_optimizing_mysql_for_100_concurrent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9mh05/need_help_optimizing_mysql_for_100_concurrent/", "subreddit_subscribers": 166903, "created_utc": 1709900020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79\n\nI created a multi-armed bandit simulator as a personal project: https://github.com/FlynnOwen/multi-armed-bandits/tree/main  \nI work as a data engineer/scientist but don't often get to play around with new software, and sometimes work on projects outside of work hours to stay fresh and learn more about the space. I thought members of this sub may appreciate this piece of software I worked on.  \nStay cool data devs 8)", "author_fullname": "t2_fwzjyaet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-Armed Bandit Simulator [https://github.com/FlynnOwen/multi-armed-bandits/tree/main]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 108, "top_awarded_type": null, "hide_score": false, "media_metadata": {"b4zv93asb2nc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f49804f658fdf6b17cfe29d64cb3551d73598b71"}, {"y": 167, "x": 216, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5cfbd2dfda59f3f315759a8f9e1749c00bcf4b92"}, {"y": 248, "x": 320, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3aa4d7f0eafe502fb03f3b1b23b2c2a43c660cea"}, {"y": 496, "x": 640, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d968cf106f25faf646db4ac262c8577bcc9547d0"}, {"y": 744, "x": 960, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b80f460d70a8cc360d1e75b4ccee89964f8d6264"}, {"y": 837, "x": 1080, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d49b1ed4d1a370bac5d6647ec1c3a47905d6b2ea"}], "s": {"y": 1248, "x": 1610, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79"}, "id": "b4zv93asb2nc1"}}, "name": "t3_1b9ic2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4rngoA4erfW4rlEKT2OUcHVvsWshK3SYMHOhq5Hmlqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709882935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79\"&gt;https://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I created a multi-armed bandit simulator as a personal project: &lt;a href=\"https://github.com/FlynnOwen/multi-armed-bandits/tree/main\"&gt;https://github.com/FlynnOwen/multi-armed-bandits/tree/main&lt;/a&gt;&lt;br/&gt;\nI work as a data engineer/scientist but don&amp;#39;t often get to play around with new software, and sometimes work on projects outside of work hours to stay fresh and learn more about the space. I thought members of this sub may appreciate this piece of software I worked on.&lt;br/&gt;\nStay cool data devs 8)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b9ic2j", "is_robot_indexable": true, "report_reasons": null, "author": "engineering-scienct", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9ic2j/multiarmed_bandit_simulator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9ic2j/multiarmed_bandit_simulator/", "subreddit_subscribers": 166903, "created_utc": 1709882935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR:\n\nFeels left out of the handover process after team lead resigned. Concerned about career growth &amp; potential reassignment of tasks to less technically skilled coworker. Time to look for a new role or tough it out while trying to get buy-in from management?    \n.  \n.  \n.  \n\n---\nHi all, relatively pretty green &amp; junior here (esp. with regards to navigating the human side of things in a corporate setting). Looking for advice/perspective from the more experienced DE folks here. \n\nMy team lead has decided to resign recently &amp; we're about to start the handover process. I've been fortunate to be working with him as he's been a great manager who can advocate for me to management &amp; thus far I'd like to say that I've sufficiently contributed to the data team. AFAIK I've been doing just fine since nobody has raised any issues regarding my performance.\n\nBut I just caught wind that I was not meant to be involved in the handover meeting. My team lead, bless his heart, does want to involve me so he will invite me in but it's strange to originally leave me out as the rest of data team are required to be in attendance. \n\nSome of the newer, currently in development reporting/dashboard stack that's definitely right up my alley is even to be assigned to a coworker who's not as technical as me. I don't mean that as a demeaning remark as said coworker does an amazing data admin-related job (which is his main role in the data team), but in a more DA/DE capacity, has to frequently ask me for ad-hoc, quite simple queries. Just doesn't make sense to me.\n\nIt seems like for now there's a still a chance to convince management that I have something to offer from a more technical standpoint to the data team through the handover meeting but the whole thing just leaves a sour note on my end. Is it time to start looking for a new role just in case management remains unconvinced?", "author_fullname": "t2_lp3x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with Management's Lack of Awareness (and Potential Underappreciation of Technical Contributions)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9b188", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709863615.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709860561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;Feels left out of the handover process after team lead resigned. Concerned about career growth &amp;amp; potential reassignment of tasks to less technically skilled coworker. Time to look for a new role or tough it out while trying to get buy-in from management?&lt;br/&gt;\n.&lt;br/&gt;\n.&lt;br/&gt;\n.  &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Hi all, relatively pretty green &amp;amp; junior here (esp. with regards to navigating the human side of things in a corporate setting). Looking for advice/perspective from the more experienced DE folks here. &lt;/p&gt;\n\n&lt;p&gt;My team lead has decided to resign recently &amp;amp; we&amp;#39;re about to start the handover process. I&amp;#39;ve been fortunate to be working with him as he&amp;#39;s been a great manager who can advocate for me to management &amp;amp; thus far I&amp;#39;d like to say that I&amp;#39;ve sufficiently contributed to the data team. AFAIK I&amp;#39;ve been doing just fine since nobody has raised any issues regarding my performance.&lt;/p&gt;\n\n&lt;p&gt;But I just caught wind that I was not meant to be involved in the handover meeting. My team lead, bless his heart, does want to involve me so he will invite me in but it&amp;#39;s strange to originally leave me out as the rest of data team are required to be in attendance. &lt;/p&gt;\n\n&lt;p&gt;Some of the newer, currently in development reporting/dashboard stack that&amp;#39;s definitely right up my alley is even to be assigned to a coworker who&amp;#39;s not as technical as me. I don&amp;#39;t mean that as a demeaning remark as said coworker does an amazing data admin-related job (which is his main role in the data team), but in a more DA/DE capacity, has to frequently ask me for ad-hoc, quite simple queries. Just doesn&amp;#39;t make sense to me.&lt;/p&gt;\n\n&lt;p&gt;It seems like for now there&amp;#39;s a still a chance to convince management that I have something to offer from a more technical standpoint to the data team through the handover meeting but the whole thing just leaves a sour note on my end. Is it time to start looking for a new role just in case management remains unconvinced?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9b188", "is_robot_indexable": true, "report_reasons": null, "author": "YsrYsl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9b188/dealing_with_managements_lack_of_awareness_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9b188/dealing_with_managements_lack_of_awareness_and/", "subreddit_subscribers": 166903, "created_utc": 1709860561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've just got the Databricks Data Engineering Associate certification and I'm thinking about keep studying for the Databricks Data Engineering Professional certification.\n\nI've been using Databricks at work and I think it's a powerful tool. What's your advice? \n\nTo go for the professional certification or to learn another stack like snowflake, DBT or another one?", "author_fullname": "t2_ea5033yq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks certifications advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b98jy5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709853304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just got the Databricks Data Engineering Associate certification and I&amp;#39;m thinking about keep studying for the Databricks Data Engineering Professional certification.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using Databricks at work and I think it&amp;#39;s a powerful tool. What&amp;#39;s your advice? &lt;/p&gt;\n\n&lt;p&gt;To go for the professional certification or to learn another stack like snowflake, DBT or another one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b98jy5", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Durian7029", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b98jy5/databricks_certifications_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b98jy5/databricks_certifications_advice/", "subreddit_subscribers": 166903, "created_utc": 1709853304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nSo I recently got more into the Microsoft stack and before that I had a \"best practice outlook\" on  setting up small/medium sized DWHs:\n- onprem/cheap cloud DB\n- EL: custom / Free tools like airbyte, pentaho.. \n- T: dbt\n\nOn my new job we only use azure for everything. Namely azure functions/data flows for ELT and a datalake blobstorage as a DWH.\nThe datalake sources powerbi, which is possible since onelake?  I am pretty new on the onelake/fabric stuff and asking myself if this is \"best practice\" for small/medium sized DWHs?\n\nI actually like nothing about this stack but that might be due to me not knowing/understanding it's capabilities?", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Onelake as DWH replacement ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b91k2e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709835479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;So I recently got more into the Microsoft stack and before that I had a &amp;quot;best practice outlook&amp;quot; on  setting up small/medium sized DWHs:\n- onprem/cheap cloud DB\n- EL: custom / Free tools like airbyte, pentaho.. \n- T: dbt&lt;/p&gt;\n\n&lt;p&gt;On my new job we only use azure for everything. Namely azure functions/data flows for ELT and a datalake blobstorage as a DWH.\nThe datalake sources powerbi, which is possible since onelake?  I am pretty new on the onelake/fabric stuff and asking myself if this is &amp;quot;best practice&amp;quot; for small/medium sized DWHs?&lt;/p&gt;\n\n&lt;p&gt;I actually like nothing about this stack but that might be due to me not knowing/understanding it&amp;#39;s capabilities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b91k2e", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b91k2e/onelake_as_dwh_replacement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b91k2e/onelake_as_dwh_replacement/", "subreddit_subscribers": 166903, "created_utc": 1709835479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tools like dbt are becoming a popular alternative to the legacy and platform tools like IBM DataStage or Azure Data Factory. Here is a quick comparison of five leading contenders to own the transformation stage in your data platform. (I leave off the dbt clones as largely derivative)  \n\n\n||[Coalesce](https://coalesce.io)|[Coginiti](https://www.coginiti.co)|dbt Cloud|[Prophecy](https://www.prophecy.io)|[SQLMesh](https://sqlmesh.com)|\n|:-|:-|:-|:-|:-|:-|\n|Transform|LowCode|AaC|AaC|LowCode|AaC|\n|Versioning|\u2705|\u2705|\u2705|\u2705|\u2705|\n|Scheduling|\u2705|\u2705|\u2705|\u2705|\u2705|\n|SQL|\u2705|\u2705|\u2705|\u2705|\u2705|\n|Python|\u274c|\u274c|\u2705|\u274c|\u2705|\n|DQ Tests|\u2705|\u2705|\u2705|\u274c|\u2705|\n|Obj Store|\u274c|\u2705|\u274c|\u274c|\u274c|\n|AI Assistant|\u274c|\u2705|\u274c|\u2705|\u274c|\n|Orchestration API|\u2705|\u2705|\u2705|\u2705|\u274c|\n|Data API|\u274c|\u2705|\u274c|\u274c|\u274c|\n|Lineage|\u2705|\u2705|\u2705|\u2705|\u2705|\n|Ad-Hoc Query|\u274c|\u2705|\u274c|\u274c|\u274c|\n|Supported Platforms|Snowflake|Netezza, DB2 Warehouse, Databricks, Redshift, Athena, BigQuery, Yellowbrick, Starburst/Trino, Synapse, SQL Server, Postgres, Snowflake, Spark, Hive, Greenplum|Redshift, BigQuery, AlloyDB, Databricks, MSFT Fabric, Starburst/Trino, Postgres, Snowflake, Spark|Databricks|BigQuery, Databricks, DuckDB, MySQL, PostgreSQL, Redshift, Snowflake, Spark|\n\n&amp;#x200B;", "author_fullname": "t2_ez8d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Transformation Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8xm1f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709825736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tools like dbt are becoming a popular alternative to the legacy and platform tools like IBM DataStage or Azure Data Factory. Here is a quick comparison of five leading contenders to own the transformation stage in your data platform. (I leave off the dbt clones as largely derivative)  &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://coalesce.io\"&gt;Coalesce&lt;/a&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://www.coginiti.co\"&gt;Coginiti&lt;/a&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;dbt Cloud&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://www.prophecy.io\"&gt;Prophecy&lt;/a&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://sqlmesh.com\"&gt;SQLMesh&lt;/a&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Transform&lt;/td&gt;\n&lt;td align=\"left\"&gt;LowCode&lt;/td&gt;\n&lt;td align=\"left\"&gt;AaC&lt;/td&gt;\n&lt;td align=\"left\"&gt;AaC&lt;/td&gt;\n&lt;td align=\"left\"&gt;LowCode&lt;/td&gt;\n&lt;td align=\"left\"&gt;AaC&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Versioning&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Scheduling&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;SQL&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Python&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;DQ Tests&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Obj Store&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AI Assistant&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Orchestration API&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Data API&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Lineage&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Ad-Hoc Query&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Supported Platforms&lt;/td&gt;\n&lt;td align=\"left\"&gt;Snowflake&lt;/td&gt;\n&lt;td align=\"left\"&gt;Netezza, DB2 Warehouse, Databricks, Redshift, Athena, BigQuery, Yellowbrick, Starburst/Trino, Synapse, SQL Server, Postgres, Snowflake, Spark, Hive, Greenplum&lt;/td&gt;\n&lt;td align=\"left\"&gt;Redshift, BigQuery, AlloyDB, Databricks, MSFT Fabric, Starburst/Trino, Postgres, Snowflake, Spark&lt;/td&gt;\n&lt;td align=\"left\"&gt;Databricks&lt;/td&gt;\n&lt;td align=\"left\"&gt;BigQuery, Databricks, DuckDB, MySQL, PostgreSQL, Redshift, Snowflake, Spark&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b8xm1f", "is_robot_indexable": true, "report_reasons": null, "author": "Bazencourt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8xm1f/data_transformation_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8xm1f/data_transformation_comparison/", "subreddit_subscribers": 166903, "created_utc": 1709825736.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm a business Intelligence student and Data warehousing isn't my strong suit. I'm working on a project in which I need to evaluate the performance of members in a test. I created a constellation star schema where I have fact tables that mesure the overall performance of that type of test, with mesures such as number of participants, number succeded, number in progresss , etc ...\n\nI also have one fact table that mesures the individual performance of a participant rather than the entire test, with mesures such as score, startdate, finishdate , durationForCompletion, etc ...\n\nEach attempt made by a participant has a timestamp. I want to mesure the performance of the test by using the test fact table, and the time axis of analysis would analyse by quarter, year, month, etc ...\n\nI also want to mesure advancement by individual so the time axis would analyse progress by hour, day , month , etc ...\n\nDue to the granularity being different between both fact tables, do I create two time dimensions or is there a better approach ?", "author_fullname": "t2_kibbksmcq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Constellation schema problem : One or two Time Dimensions ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9pcs2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709908360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m a business Intelligence student and Data warehousing isn&amp;#39;t my strong suit. I&amp;#39;m working on a project in which I need to evaluate the performance of members in a test. I created a constellation star schema where I have fact tables that mesure the overall performance of that type of test, with mesures such as number of participants, number succeded, number in progresss , etc ...&lt;/p&gt;\n\n&lt;p&gt;I also have one fact table that mesures the individual performance of a participant rather than the entire test, with mesures such as score, startdate, finishdate , durationForCompletion, etc ...&lt;/p&gt;\n\n&lt;p&gt;Each attempt made by a participant has a timestamp. I want to mesure the performance of the test by using the test fact table, and the time axis of analysis would analyse by quarter, year, month, etc ...&lt;/p&gt;\n\n&lt;p&gt;I also want to mesure advancement by individual so the time axis would analyse progress by hour, day , month , etc ...&lt;/p&gt;\n\n&lt;p&gt;Due to the granularity being different between both fact tables, do I create two time dimensions or is there a better approach ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9pcs2", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible-Word-137", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9pcs2/constellation_schema_problem_one_or_two_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9pcs2/constellation_schema_problem_one_or_two_time/", "subreddit_subscribers": 166903, "created_utc": 1709908360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://medium.com/gitconnected/turnkey-data-analysis-using-duckdb-and-metabase-for-postgresql-cloudwatch-1255b925b7b4", "author_fullname": "t2_14lsag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turnkey Data Analysis Using DuckDB and Metabase for PostgreSQL &amp; CloudWatch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9p7eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709907986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/gitconnected/turnkey-data-analysis-using-duckdb-and-metabase-for-postgresql-cloudwatch-1255b925b7b4\"&gt;https://medium.com/gitconnected/turnkey-data-analysis-using-duckdb-and-metabase-for-postgresql-cloudwatch-1255b925b7b4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3OVLPtWNIqfKWMkM0ZpyDCj9I-6nBOJRoaAF4MnNwDU.jpg?auto=webp&amp;s=abaa6360bb09d94c3227fe8f18ad59de5848a42b", "width": 686, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/3OVLPtWNIqfKWMkM0ZpyDCj9I-6nBOJRoaAF4MnNwDU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2468b6c6a2be58cf42aa7e20614daa68ea0f79c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/3OVLPtWNIqfKWMkM0ZpyDCj9I-6nBOJRoaAF4MnNwDU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8ddf297cb6021e7f0d92ef24cb4ec81cdf6b736", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/3OVLPtWNIqfKWMkM0ZpyDCj9I-6nBOJRoaAF4MnNwDU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c1c5e93640b894f5dca0ae91121f73a3cf353a6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/3OVLPtWNIqfKWMkM0ZpyDCj9I-6nBOJRoaAF4MnNwDU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fad19306cfa8405de1555516d3364ec20081a882", "width": 640, "height": 640}], "variants": {}, "id": "VGarDclfmkWIQ7EJ1_v3fMXiX3AflWHP_k0JGGKcL4E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b9p7eb", "is_robot_indexable": true, "report_reasons": null, "author": "redgeoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9p7eb/turnkey_data_analysis_using_duckdb_and_metabase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9p7eb/turnkey_data_analysis_using_duckdb_and_metabase/", "subreddit_subscribers": 166903, "created_utc": 1709907986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,  \n(Im personally quite new to data engineering)  \none of our customers has hundreds of distributed databases, each with one important table of sensor records. We have an existing data pipeline to process this kind of data (with Dagster), but never ingested data at this scale.  \nNormally we do ingestion with a simple Python script, but at this scale, we would need to build a set of features that any database-to-database ingestion framework would need (keep a list of databases, connect, check table exists, check what's new, fetch it, allow the user to add a new database table to be synced).\n\nI know about Airbyte and Meltano, both are quite powerful and heavy frameworks with many connectors. I was hoping for something simpler. I just need keep the local table in sync with the remote one via SQL at regular intervals (not realtime). Im tempted to build it myself, please stop me.\n\nWould be happy if you would share your ideas.", "author_fullname": "t2_otqll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion tools to keep databases in sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9niyy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709905565.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709903318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\n(Im personally quite new to data engineering)&lt;br/&gt;\none of our customers has hundreds of distributed databases, each with one important table of sensor records. We have an existing data pipeline to process this kind of data (with Dagster), but never ingested data at this scale.&lt;br/&gt;\nNormally we do ingestion with a simple Python script, but at this scale, we would need to build a set of features that any database-to-database ingestion framework would need (keep a list of databases, connect, check table exists, check what&amp;#39;s new, fetch it, allow the user to add a new database table to be synced).&lt;/p&gt;\n\n&lt;p&gt;I know about Airbyte and Meltano, both are quite powerful and heavy frameworks with many connectors. I was hoping for something simpler. I just need keep the local table in sync with the remote one via SQL at regular intervals (not realtime). Im tempted to build it myself, please stop me.&lt;/p&gt;\n\n&lt;p&gt;Would be happy if you would share your ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9niyy", "is_robot_indexable": true, "report_reasons": null, "author": "Cominous", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9niyy/data_ingestion_tools_to_keep_databases_in_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9niyy/data_ingestion_tools_to_keep_databases_in_sync/", "subreddit_subscribers": 166903, "created_utc": 1709903318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently consolidating monthly sales data across different datasets but some don\u2019t have a UPC.\n\nFor those that don\u2019t have a UPC, I\u2019ve been manually mapping in an excel file every month but know this isn\u2019t scalable or efficient.\n\nProcess is file gets downloaded &gt; added to SharePoint folder &gt; refresh stacked file &gt; update mapping &gt; S3 &gt; Snowflake &gt; PBI.\n\nNewer to this so open to suggestions.  ", "author_fullname": "t2_ffr7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping products across datasets without excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b95rtd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709846463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently consolidating monthly sales data across different datasets but some don\u2019t have a UPC.&lt;/p&gt;\n\n&lt;p&gt;For those that don\u2019t have a UPC, I\u2019ve been manually mapping in an excel file every month but know this isn\u2019t scalable or efficient.&lt;/p&gt;\n\n&lt;p&gt;Process is file gets downloaded &amp;gt; added to SharePoint folder &amp;gt; refresh stacked file &amp;gt; update mapping &amp;gt; S3 &amp;gt; Snowflake &amp;gt; PBI.&lt;/p&gt;\n\n&lt;p&gt;Newer to this so open to suggestions.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b95rtd", "is_robot_indexable": true, "report_reasons": null, "author": "Batmansappendix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b95rtd/mapping_products_across_datasets_without_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b95rtd/mapping_products_across_datasets_without_excel/", "subreddit_subscribers": 166903, "created_utc": 1709846463.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}