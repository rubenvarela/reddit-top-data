{"kind": "Listing", "data": {"after": null, "dist": 6, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Thanks you guys fpr every single book recommendation, for every single career advice.\n\nI took your recommendations seriously, studied the books you told me to study, and studied other videos on my own, learning everything I can learn on my own.\n\nThen I took the advice someone here told is to talk to someone internally in the data science team, turns out, they were impressed by the scope of the projects I worked on for a sales analyst and how I improved everything data-related in the department and the lead told me once I am ready (I still have a probability course to finish and recap hands on ML) and I will be up for a transfer.\n\nI will be a junior DS in 5 or 6 months time after being an analyst for 2 years (I started when I was 20) and it's all you guys, so, thanks. \n\nEdit: here's everything:\n\nI started when I was 18 years old, in something that I never knew it would be my gate to this job: a sales agent. Been so for a whole year. This gave me a lot of business context, how a manager leads people under him, and how his manager looks at his performance and understood something about the hierarchical behavior of companies. \nThen, I left the job after a year, now it's the pandemic, I spent it leqrning Excel and basic statistics, all on YouTube.\n\nMoving forward to when I was 20, I had no idea a data analyst is even a title, and got a job as an accountant at a small workshop, with college going on, and I was studying business administration and statistics.\nThe job was never an accountant or have anything to do with accounting, my manager at the time was a very smart guy, working with pen and paper as his ledger, then I introduced Excel, he was all in for it, I started creating tables for our sales and inventory and customers and places we work in.\n\nHe started asking questions, you said last month we made 40K, how come we make 45 this month? I started digging into our data unknowingly doing analysis.\n\nHis brother was a regular visitor, I learned that he is the head of data at a big startup in our country, saw what I did, kept giving me tasks and I answer with Excel.\n\nThen, he gave me a course that I highly recommend about Excel: power tools in Excel, you can find sources on YouTube for it a lot (power query, power pivot and data modeling). I started applying DAX, and here comes my first book [Dax Guide](https://www.google.com.eg/books/edition/_/dtr8oQEACAAJ?hl=en&amp;sa=X&amp;ved=2ahUKEwiQo4eZ8OKEAxUXgP0HHXfgDTIQ7_IDKAB6BAgPEAM).\n\nThen I started my LinkedIn journey, showing Excel and powerBI dashboards and applying to jobs, in data analysis, really that's all you need, business context, some technical tools to help you dig into the data and answer questions.\n\nThen, I started reading about data science, how statistics is important and how much I liked it in college, here goes the second book, [Naked Statistics](https://www.amazon.com/Naked-Statistics-Stripping-Dread-Data-ebook/dp/B007Q6XLF2).\nHere I learned to think with stats a bit.\n\nThen, I found that I lack implementation to a lot of concepts to statistics, people recommended python for me, here there were two sources for me to learn from, YouTube courses got me up and running into how to write simple code in python and understand the syntax.\n\nLater, DataCamp had tracks, I finished the Data Analyst with python and another one data analyst with SQL. This helped me BIG time in knowing where to go next. \n\nNote: I was doing all of that while working and being in college.\n\nThe DataCamp course had great courses about statistics and probability and simulation. While also practicing SQL, I got really good with it.\n\nNow, got a job as a junior sales ops analyst (my role now). I got lucky, working on real problems and practicing what I learn.\n\nThen started moving back to books, but I lacked problem solving mindset, read these books: [Stop Guessing](https://www.amazon.com/Stop-Guessing-Behaviors-Problem-Solvers/dp/162656986X) and[Lean Analytics](https://leananalyticsbook.com/).\n\nThis helped me big time understand how my work affects the company. \n\nNow it's time to show your work to stakeholders, I read this book: [Storytelling with data](https://leananalyticsbook.com/).\n\nIt's time to go back to the details of my job, It was all querying on metabase, an open source BI tool.\n\nI was responsible for giving agents retailers to visit, so, Every morning, we are supposed to apply filters on our data (last order date, last visit date and some other features ) and tell the agent, visit 20 of those retailers and go home. I was doing all of that in an automated fashion with power query, creating automated pipelines was my passion in Excel. All I had to do was give it an updated file from our database, refresh the pipeline, take the new file, dump it into our system.\n\nThey do visit 20 retailers, but the problem reached the tech team, the data was too much to handle, requiring us to give a smaller set of retailers for the agents, specifically 40 retailers.\n\nBut how do we guarantee they are close to each other? Here come my first interaction with adata scientist.\n\nI did all what I did in Excel but in python using pandas and then reached the point where I don't know how to give clusters.\n\nHe took my jupyter notebook, gave it to us back with the solution to our problem, with something I was not familiar with at the time, Kmeans constrained.\nWhich took only longitude, latitude gave each agent his route of 40 retailers.\n\nI started taking notes from his improvements to my code and asked him, what did you do?\n\nHe told my my code was fine, but you used a lot of custom functions on operations that can be vectorized, I asked for a book recommendation about vectorized operations in pandas here, the guys recommended this [Data Wrangling in python book](https://www.amazon.com/Data-Wrangling-Python-Tools-Easier/dp/1491948817).\n\nAfter that book, I was obsessed with data automation in python using pandas and numpy only.\n\nI got also obsessed with vectorizing any operation in our code base, read something pandas specific now: [Effective Pandas](https://www.amazon.com/Effective-Pandas-Patterns-Manipulation-Treading/dp/B09MYXXSFM).\n\nThen, it was the part where he interacted with our system API.\n\nSince all our company data scientists and swes have access to snowflake and live databases, we, analysts, had access to only metabase.\n\nI saw this as an opportunity to get known!\n\nI wrote two functions used by our entire company, ret_metabase and interact_with_google_sheets\nThe first one connects to the API endpoint and then takes your credintials and the makes a session ID and gets your card ID string response in json and I convert it to a dataframe. The second requires an Api key, thenenables tge user to do anything with a google sheet, remove data set with a dataframe get data asa dataframe append on data filter views really anything in one function.\nHow did I learn to do all of that? A course on youtube , just type API development in python amd a book about data structures, [Grokking Algorithms](https://www.amazon.com/Effective-Pandas-Patterns-Manipulation-Treading/dp/B09MYXXSFM). This helped big time in optimizing my code performance and writing cleaner code.\n\nI got known and these functions are in the companies library now and people use it all the time. And I even left funny comments in the documentation and Everything.\n\nThe kmeans thing got me really interested in machine learning and here's the first book you guys recommended: [ISLR](https://www.statlearning.com/).\n\nIt was really hard for me at first because I had not been introduced properly to those three topics:\n1- linear algebra\n2- calculus\n3- probability and statistics\nI took [Jon Krohn's live lessions](https://github.com/jonkrohn/ML-foundations) it's free on YouTube.\n\nBut those three were later taken (started linear algebra in November 23).\n\nSo I struggled back then and here, another book was suggested: Hands-on ML.\n\nI finished it and was really fucking hyped to apply the stuff I learned directly into my job, even without my manager permissions.\n\nBut that was not enough, I did not know what I should do to impact our compqny, what is data science?\n\nI read this book: [Data science with business, what you need to know about DS](https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323)\n\nFirst thing I dod after understanding what kmeans is, improved our routes clustering function by standerdizing the scales of the long, lat, giving it another column ( retailer rank) that rankstarts at the maximum value the longitude and decays linearly from 31 to 30 (longitude here is from 30 to 31), I used linspace and select in numpy here to give retailers ranks. This rank was business objective (give 31 toretailers with high conversion and then 30.9 to retailers with monotonically decreasing nmv to make them order back and so on...) Any other retailer takes a zero in his face. This helped in giving optimized distance to retailers we really need to visit.\n\nThis gave us a big boost in agents strike rate and overall performance.\n\nSecond, I applied xgboost, predicting who will place an order today if visited. Gave them the biggest rank.\n\nTesting this was a must, so I learned about A/B testing, and some other great bootstrapping ideas here [Practical Statistics](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) Book.\n\nThis pushed our strike rate from 40 to 73%.\n\nThen, I really now see that I lack probability knowledge and maths knowledge to be a data scientist, so I read [Essential maths for DS](https://www.amazon.eg/-/en/Essential-Math-Data-Science-Fundamental/dp/1098102932).\n\nSince my job was about sales operations, it was a necessary thing to automate discovering new sales areas and opportunity, previously, we used to draw polygons in areas we want to open, and then the agents are set there to wander and find retailers on their own.\n\nI got an idea, how about I get all streets know in this area and make blocks in the intersections and then convert the coords to google maps link and give 50 daily sequential links to agents to discover areas in a more naturally sequential way? I used omnix API to get streets data and geopandas to make all other operations, I learned how to work with geopandas from their docs, really straightforward.\n\nThis project was big, applied everything I know about pandas and data structures and business knowledge to do it, and it's up and running now.\n\nI got praised for it and the head of data was impressed with the result and decided to give me access to snowflake directly to limit requests on metabase as the data was big and then I scaled the project to all regions we operate in.\n\nThen it was time to speak with the senior ds lead.\n\nI showed him all I wrote here, he recommended I get a strong foundation in linear algebra and calculus and probability.\n\nI got it, and now working on probability and statistics.\n\nI then told him I am really into causal inference (rwcommended by someone in my previous post here) and regression analysis.\n\nHe said that's exactly what they need from the junior they want to hire, \"anyone can fit and predict nowdays\" he said, \"we need someone who can make an impact in all the stuff we don't have time for and teach him more cloud tools and maybe he gives us new ideas or show us new tools\" he elaborated.\n\nRight now I am studying probability and statistics and then will study [Causal Inference](https://www.oreilly.com/library/view/causal-inference-in/9781098140243/).\n\n\nI guess that's all, the most important thing is that you keep studying and never giving up, please, focus more on business context as it's overlooked.\n\nI hope this was useful to you guys.", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to show how grateful I am to this sub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8ym5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 258, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 258, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709846071.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709828162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks you guys fpr every single book recommendation, for every single career advice.&lt;/p&gt;\n\n&lt;p&gt;I took your recommendations seriously, studied the books you told me to study, and studied other videos on my own, learning everything I can learn on my own.&lt;/p&gt;\n\n&lt;p&gt;Then I took the advice someone here told is to talk to someone internally in the data science team, turns out, they were impressed by the scope of the projects I worked on for a sales analyst and how I improved everything data-related in the department and the lead told me once I am ready (I still have a probability course to finish and recap hands on ML) and I will be up for a transfer.&lt;/p&gt;\n\n&lt;p&gt;I will be a junior DS in 5 or 6 months time after being an analyst for 2 years (I started when I was 20) and it&amp;#39;s all you guys, so, thanks. &lt;/p&gt;\n\n&lt;p&gt;Edit: here&amp;#39;s everything:&lt;/p&gt;\n\n&lt;p&gt;I started when I was 18 years old, in something that I never knew it would be my gate to this job: a sales agent. Been so for a whole year. This gave me a lot of business context, how a manager leads people under him, and how his manager looks at his performance and understood something about the hierarchical behavior of companies. \nThen, I left the job after a year, now it&amp;#39;s the pandemic, I spent it leqrning Excel and basic statistics, all on YouTube.&lt;/p&gt;\n\n&lt;p&gt;Moving forward to when I was 20, I had no idea a data analyst is even a title, and got a job as an accountant at a small workshop, with college going on, and I was studying business administration and statistics.\nThe job was never an accountant or have anything to do with accounting, my manager at the time was a very smart guy, working with pen and paper as his ledger, then I introduced Excel, he was all in for it, I started creating tables for our sales and inventory and customers and places we work in.&lt;/p&gt;\n\n&lt;p&gt;He started asking questions, you said last month we made 40K, how come we make 45 this month? I started digging into our data unknowingly doing analysis.&lt;/p&gt;\n\n&lt;p&gt;His brother was a regular visitor, I learned that he is the head of data at a big startup in our country, saw what I did, kept giving me tasks and I answer with Excel.&lt;/p&gt;\n\n&lt;p&gt;Then, he gave me a course that I highly recommend about Excel: power tools in Excel, you can find sources on YouTube for it a lot (power query, power pivot and data modeling). I started applying DAX, and here comes my first book &lt;a href=\"https://www.google.com.eg/books/edition/_/dtr8oQEACAAJ?hl=en&amp;amp;sa=X&amp;amp;ved=2ahUKEwiQo4eZ8OKEAxUXgP0HHXfgDTIQ7_IDKAB6BAgPEAM\"&gt;Dax Guide&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Then I started my LinkedIn journey, showing Excel and powerBI dashboards and applying to jobs, in data analysis, really that&amp;#39;s all you need, business context, some technical tools to help you dig into the data and answer questions.&lt;/p&gt;\n\n&lt;p&gt;Then, I started reading about data science, how statistics is important and how much I liked it in college, here goes the second book, &lt;a href=\"https://www.amazon.com/Naked-Statistics-Stripping-Dread-Data-ebook/dp/B007Q6XLF2\"&gt;Naked Statistics&lt;/a&gt;.\nHere I learned to think with stats a bit.&lt;/p&gt;\n\n&lt;p&gt;Then, I found that I lack implementation to a lot of concepts to statistics, people recommended python for me, here there were two sources for me to learn from, YouTube courses got me up and running into how to write simple code in python and understand the syntax.&lt;/p&gt;\n\n&lt;p&gt;Later, DataCamp had tracks, I finished the Data Analyst with python and another one data analyst with SQL. This helped me BIG time in knowing where to go next. &lt;/p&gt;\n\n&lt;p&gt;Note: I was doing all of that while working and being in college.&lt;/p&gt;\n\n&lt;p&gt;The DataCamp course had great courses about statistics and probability and simulation. While also practicing SQL, I got really good with it.&lt;/p&gt;\n\n&lt;p&gt;Now, got a job as a junior sales ops analyst (my role now). I got lucky, working on real problems and practicing what I learn.&lt;/p&gt;\n\n&lt;p&gt;Then started moving back to books, but I lacked problem solving mindset, read these books: &lt;a href=\"https://www.amazon.com/Stop-Guessing-Behaviors-Problem-Solvers/dp/162656986X\"&gt;Stop Guessing&lt;/a&gt; and&lt;a href=\"https://leananalyticsbook.com/\"&gt;Lean Analytics&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;This helped me big time understand how my work affects the company. &lt;/p&gt;\n\n&lt;p&gt;Now it&amp;#39;s time to show your work to stakeholders, I read this book: &lt;a href=\"https://leananalyticsbook.com/\"&gt;Storytelling with data&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s time to go back to the details of my job, It was all querying on metabase, an open source BI tool.&lt;/p&gt;\n\n&lt;p&gt;I was responsible for giving agents retailers to visit, so, Every morning, we are supposed to apply filters on our data (last order date, last visit date and some other features ) and tell the agent, visit 20 of those retailers and go home. I was doing all of that in an automated fashion with power query, creating automated pipelines was my passion in Excel. All I had to do was give it an updated file from our database, refresh the pipeline, take the new file, dump it into our system.&lt;/p&gt;\n\n&lt;p&gt;They do visit 20 retailers, but the problem reached the tech team, the data was too much to handle, requiring us to give a smaller set of retailers for the agents, specifically 40 retailers.&lt;/p&gt;\n\n&lt;p&gt;But how do we guarantee they are close to each other? Here come my first interaction with adata scientist.&lt;/p&gt;\n\n&lt;p&gt;I did all what I did in Excel but in python using pandas and then reached the point where I don&amp;#39;t know how to give clusters.&lt;/p&gt;\n\n&lt;p&gt;He took my jupyter notebook, gave it to us back with the solution to our problem, with something I was not familiar with at the time, Kmeans constrained.\nWhich took only longitude, latitude gave each agent his route of 40 retailers.&lt;/p&gt;\n\n&lt;p&gt;I started taking notes from his improvements to my code and asked him, what did you do?&lt;/p&gt;\n\n&lt;p&gt;He told my my code was fine, but you used a lot of custom functions on operations that can be vectorized, I asked for a book recommendation about vectorized operations in pandas here, the guys recommended this &lt;a href=\"https://www.amazon.com/Data-Wrangling-Python-Tools-Easier/dp/1491948817\"&gt;Data Wrangling in python book&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;After that book, I was obsessed with data automation in python using pandas and numpy only.&lt;/p&gt;\n\n&lt;p&gt;I got also obsessed with vectorizing any operation in our code base, read something pandas specific now: &lt;a href=\"https://www.amazon.com/Effective-Pandas-Patterns-Manipulation-Treading/dp/B09MYXXSFM\"&gt;Effective Pandas&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Then, it was the part where he interacted with our system API.&lt;/p&gt;\n\n&lt;p&gt;Since all our company data scientists and swes have access to snowflake and live databases, we, analysts, had access to only metabase.&lt;/p&gt;\n\n&lt;p&gt;I saw this as an opportunity to get known!&lt;/p&gt;\n\n&lt;p&gt;I wrote two functions used by our entire company, ret_metabase and interact_with_google_sheets\nThe first one connects to the API endpoint and then takes your credintials and the makes a session ID and gets your card ID string response in json and I convert it to a dataframe. The second requires an Api key, thenenables tge user to do anything with a google sheet, remove data set with a dataframe get data asa dataframe append on data filter views really anything in one function.\nHow did I learn to do all of that? A course on youtube , just type API development in python amd a book about data structures, &lt;a href=\"https://www.amazon.com/Effective-Pandas-Patterns-Manipulation-Treading/dp/B09MYXXSFM\"&gt;Grokking Algorithms&lt;/a&gt;. This helped big time in optimizing my code performance and writing cleaner code.&lt;/p&gt;\n\n&lt;p&gt;I got known and these functions are in the companies library now and people use it all the time. And I even left funny comments in the documentation and Everything.&lt;/p&gt;\n\n&lt;p&gt;The kmeans thing got me really interested in machine learning and here&amp;#39;s the first book you guys recommended: &lt;a href=\"https://www.statlearning.com/\"&gt;ISLR&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It was really hard for me at first because I had not been introduced properly to those three topics:\n1- linear algebra\n2- calculus\n3- probability and statistics\nI took &lt;a href=\"https://github.com/jonkrohn/ML-foundations\"&gt;Jon Krohn&amp;#39;s live lessions&lt;/a&gt; it&amp;#39;s free on YouTube.&lt;/p&gt;\n\n&lt;p&gt;But those three were later taken (started linear algebra in November 23).&lt;/p&gt;\n\n&lt;p&gt;So I struggled back then and here, another book was suggested: Hands-on ML.&lt;/p&gt;\n\n&lt;p&gt;I finished it and was really fucking hyped to apply the stuff I learned directly into my job, even without my manager permissions.&lt;/p&gt;\n\n&lt;p&gt;But that was not enough, I did not know what I should do to impact our compqny, what is data science?&lt;/p&gt;\n\n&lt;p&gt;I read this book: &lt;a href=\"https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323\"&gt;Data science with business, what you need to know about DS&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;First thing I dod after understanding what kmeans is, improved our routes clustering function by standerdizing the scales of the long, lat, giving it another column ( retailer rank) that rankstarts at the maximum value the longitude and decays linearly from 31 to 30 (longitude here is from 30 to 31), I used linspace and select in numpy here to give retailers ranks. This rank was business objective (give 31 toretailers with high conversion and then 30.9 to retailers with monotonically decreasing nmv to make them order back and so on...) Any other retailer takes a zero in his face. This helped in giving optimized distance to retailers we really need to visit.&lt;/p&gt;\n\n&lt;p&gt;This gave us a big boost in agents strike rate and overall performance.&lt;/p&gt;\n\n&lt;p&gt;Second, I applied xgboost, predicting who will place an order today if visited. Gave them the biggest rank.&lt;/p&gt;\n\n&lt;p&gt;Testing this was a must, so I learned about A/B testing, and some other great bootstrapping ideas here &lt;a href=\"https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/\"&gt;Practical Statistics&lt;/a&gt; Book.&lt;/p&gt;\n\n&lt;p&gt;This pushed our strike rate from 40 to 73%.&lt;/p&gt;\n\n&lt;p&gt;Then, I really now see that I lack probability knowledge and maths knowledge to be a data scientist, so I read &lt;a href=\"https://www.amazon.eg/-/en/Essential-Math-Data-Science-Fundamental/dp/1098102932\"&gt;Essential maths for DS&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Since my job was about sales operations, it was a necessary thing to automate discovering new sales areas and opportunity, previously, we used to draw polygons in areas we want to open, and then the agents are set there to wander and find retailers on their own.&lt;/p&gt;\n\n&lt;p&gt;I got an idea, how about I get all streets know in this area and make blocks in the intersections and then convert the coords to google maps link and give 50 daily sequential links to agents to discover areas in a more naturally sequential way? I used omnix API to get streets data and geopandas to make all other operations, I learned how to work with geopandas from their docs, really straightforward.&lt;/p&gt;\n\n&lt;p&gt;This project was big, applied everything I know about pandas and data structures and business knowledge to do it, and it&amp;#39;s up and running now.&lt;/p&gt;\n\n&lt;p&gt;I got praised for it and the head of data was impressed with the result and decided to give me access to snowflake directly to limit requests on metabase as the data was big and then I scaled the project to all regions we operate in.&lt;/p&gt;\n\n&lt;p&gt;Then it was time to speak with the senior ds lead.&lt;/p&gt;\n\n&lt;p&gt;I showed him all I wrote here, he recommended I get a strong foundation in linear algebra and calculus and probability.&lt;/p&gt;\n\n&lt;p&gt;I got it, and now working on probability and statistics.&lt;/p&gt;\n\n&lt;p&gt;I then told him I am really into causal inference (rwcommended by someone in my previous post here) and regression analysis.&lt;/p&gt;\n\n&lt;p&gt;He said that&amp;#39;s exactly what they need from the junior they want to hire, &amp;quot;anyone can fit and predict nowdays&amp;quot; he said, &amp;quot;we need someone who can make an impact in all the stuff we don&amp;#39;t have time for and teach him more cloud tools and maybe he gives us new ideas or show us new tools&amp;quot; he elaborated.&lt;/p&gt;\n\n&lt;p&gt;Right now I am studying probability and statistics and then will study &lt;a href=\"https://www.oreilly.com/library/view/causal-inference-in/9781098140243/\"&gt;Causal Inference&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I guess that&amp;#39;s all, the most important thing is that you keep studying and never giving up, please, focus more on business context as it&amp;#39;s overlooked.&lt;/p&gt;\n\n&lt;p&gt;I hope this was useful to you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YS92VYxGPPJXX2YV_H71zU48MJ3xmQWqt76iV8mRQLI.jpg?auto=webp&amp;s=77b3453214fe0468523347dd39d2cbe78a1db1a1", "width": 128, "height": 156}, "resolutions": [{"url": "https://external-preview.redd.it/YS92VYxGPPJXX2YV_H71zU48MJ3xmQWqt76iV8mRQLI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc9eb28f10e511136f8344905b03f42a10ea1d1c", "width": 108, "height": 131}], "variants": {}, "id": "8pvtbzzOrqRA_YjlZhw1SyaRP-5NWmLOhceHFpDyumQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b8ym5o", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b8ym5o/i_need_to_show_how_grateful_i_am_to_this_sub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b8ym5o/i_need_to_show_how_grateful_i_am_to_this_sub/", "subreddit_subscribers": 1403346, "created_utc": 1709828162.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nI'm constantly checking for jobs in the sports analytics industry, specially keeping an eye into Zelus which I think is a top notch player and hires remotely around the world.\n\nYesterday they submitted open positions for [ML and Data Engineers.](https://www.sportsjobs.online/job-details/645machine%2520learning%2520engineer%2520%2528close%2520date%253a%2520march%252022nd%2529/r/recjeCiYrqHwdZ8vl)\n\nThey also have an always open job post for Data Science to increase their pool.\n\nOn top of that, since it's not easy to land a job in the industry, I look for intern positions. Recently [the Jets](https://www.sportsjobs.online/job-details/640seasonal%2520intern%2520-%2520football%2520analytics/r/recb7DwE4NVfGTiPJ) posted one opening. Other teams too a few days ago.\n\nI've created also a [reddit community](https://www.reddit.com/r/sports_jobs/) where I post recurrently the openings if that's easier to check for you.\n\nDisclaimer: I run the job board.\n\nI hope this helps someone!", "author_fullname": "t2_24mvheq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zelus Analytics and Tennessee Titans are hiring. NY Jets are looking for interns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8xr3y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709826070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m constantly checking for jobs in the sports analytics industry, specially keeping an eye into Zelus which I think is a top notch player and hires remotely around the world.&lt;/p&gt;\n\n&lt;p&gt;Yesterday they submitted open positions for &lt;a href=\"https://www.sportsjobs.online/job-details/645machine%2520learning%2520engineer%2520%2528close%2520date%253a%2520march%252022nd%2529/r/recjeCiYrqHwdZ8vl\"&gt;ML and Data Engineers.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They also have an always open job post for Data Science to increase their pool.&lt;/p&gt;\n\n&lt;p&gt;On top of that, since it&amp;#39;s not easy to land a job in the industry, I look for intern positions. Recently &lt;a href=\"https://www.sportsjobs.online/job-details/640seasonal%2520intern%2520-%2520football%2520analytics/r/recb7DwE4NVfGTiPJ\"&gt;the Jets&lt;/a&gt; posted one opening. Other teams too a few days ago.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve created also a &lt;a href=\"https://www.reddit.com/r/sports_jobs/\"&gt;reddit community&lt;/a&gt; where I post recurrently the openings if that&amp;#39;s easier to check for you.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I run the job board.&lt;/p&gt;\n\n&lt;p&gt;I hope this helps someone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b8xr3y", "is_robot_indexable": true, "report_reasons": null, "author": "fark13", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b8xr3y/zelus_analytics_and_tennessee_titans_are_hiring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b8xr3y/zelus_analytics_and_tennessee_titans_are_hiring/", "subreddit_subscribers": 1403346, "created_utc": 1709826070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nThis is my first time posting here, so please forgive my naivety.\n\nFor the past few weeks, I've been trying to understand how to extract causal inference information from models that seem to be primarily predictive. Specifically, I've been working with Gaussian Process Regression using some crime data and learning how to better tune it to improve predictions. However, I'm uncertain about how to move from there to making statements about the effects of my X variables on the variance of my Y, or (from a Bayesian perspective) which distribution most credibly explains my Y given my set of Xs.\n\nI'm wondering if I'm missing some fundamental understanding here, or if GPR simply can't be used to make causal statements.\n\nAny critique or information you can provide would be greatly appreciated!", "author_fullname": "t2_kc2v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move from Prediction to Inference: Gaussian Process Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8xjyb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709825606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;This is my first time posting here, so please forgive my naivety.&lt;/p&gt;\n\n&lt;p&gt;For the past few weeks, I&amp;#39;ve been trying to understand how to extract causal inference information from models that seem to be primarily predictive. Specifically, I&amp;#39;ve been working with Gaussian Process Regression using some crime data and learning how to better tune it to improve predictions. However, I&amp;#39;m uncertain about how to move from there to making statements about the effects of my X variables on the variance of my Y, or (from a Bayesian perspective) which distribution most credibly explains my Y given my set of Xs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if I&amp;#39;m missing some fundamental understanding here, or if GPR simply can&amp;#39;t be used to make causal statements.&lt;/p&gt;\n\n&lt;p&gt;Any critique or information you can provide would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b8xjyb", "is_robot_indexable": true, "report_reasons": null, "author": "AmadeusBlackwell", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b8xjyb/how_to_move_from_prediction_to_inference_gaussian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b8xjyb/how_to_move_from_prediction_to_inference_gaussian/", "subreddit_subscribers": 1403346, "created_utc": 1709825606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3iw05ko4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Starburst\u2019s Icehouse Is A Bad Bet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 108, "top_awarded_type": null, "hide_score": false, "name": "t3_1b93awg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "DE", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BUKA7L0DPMazfD20jVo8wsgPSXLaxiQb1KHXc54Akwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709840605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "starrocks.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://starrocks.medium.com/why-starbursts-icehouse-is-a-bad-bet-d7c0985f9c8b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NLqUS4DWFdaYnNA1vo7Oh4JcL0Uus-T-grwHYNsQLTs.jpg?auto=webp&amp;s=170f0a132f67e9cafa281520f6f877c59040e775", "width": 524, "height": 406}, "resolutions": [{"url": "https://external-preview.redd.it/NLqUS4DWFdaYnNA1vo7Oh4JcL0Uus-T-grwHYNsQLTs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6f019685d5008c40d42ff71d1f314cc13e16f28", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/NLqUS4DWFdaYnNA1vo7Oh4JcL0Uus-T-grwHYNsQLTs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98fb5deef36d07cb57079d0f9a317bb69251e1b1", "width": 216, "height": 167}, {"url": "https://external-preview.redd.it/NLqUS4DWFdaYnNA1vo7Oh4JcL0Uus-T-grwHYNsQLTs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddcd641f4cdf37e06ef2696622433b741033194a", "width": 320, "height": 247}], "variants": {}, "id": "kszejspKo7XFqlALHMMQzlYtpW0xRGfMKFHpre7xUv4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "271d2932-70eb-11ee-b552-0a391e3dc147", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0dd3bb", "id": "1b93awg", "is_robot_indexable": true, "report_reasons": null, "author": "Judgment_External", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b93awg/why_starbursts_icehouse_is_a_bad_bet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://starrocks.medium.com/why-starbursts-icehouse-is-a-bad-bet-d7c0985f9c8b", "subreddit_subscribers": 1403346, "created_utc": 1709840605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I created a multi-armed bandit simulator as a personal project: [https://github.com/FlynnOwen/multi-armed-bandits/tree/main](https://github.com/FlynnOwen/multi-armed-bandits/tree/main)\n\nI work as a data scientist but don't often get to play around with new software, and sometimes work on projects outside of work hours to stay fresh and learn more about the space. I thought members of this sub may appreciate this piece of software I worked on.\n\nStay cool data devs 8)\n\nhttps://preview.redd.it/4mgtdzjsa2nc1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=7d1073abec73b959935134d84c18a4b3045e5618", "author_fullname": "t2_fwzjyaet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-Armed Bandit Simulator [https://github.com/FlynnOwen/multi-armed-bandits/tree/main]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 108, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4mgtdzjsa2nc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=38fd5d09fe651c5b2459e4fe5fb1a5c62c3946e0"}, {"y": 167, "x": 216, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9174c0c5826f27351b9218243ecdfd51f0ff4ba"}, {"y": 248, "x": 320, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2539aaa044f3bb9512ea228392c475a8068d3438"}, {"y": 496, "x": 640, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aaa1c3855e21b5b8e56292bc8817e2c8a820e3c9"}, {"y": 744, "x": 960, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=af75ce00de06aa50fcdd1a8dc9dc4218eeabf4f3"}, {"y": 837, "x": 1080, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b1025d9345752c65d4dc3fcc03c404617a8572dd"}], "s": {"y": 1248, "x": 1610, "u": "https://preview.redd.it/4mgtdzjsa2nc1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=7d1073abec73b959935134d84c18a4b3045e5618"}, "id": "4mgtdzjsa2nc1"}}, "name": "t3_1b9iagn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Hd29WQIqKU5Fw3Lb8N_TDbGQa7OFBUhyAPEskERr6U4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709882755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a multi-armed bandit simulator as a personal project: &lt;a href=\"https://github.com/FlynnOwen/multi-armed-bandits/tree/main\"&gt;https://github.com/FlynnOwen/multi-armed-bandits/tree/main&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I work as a data scientist but don&amp;#39;t often get to play around with new software, and sometimes work on projects outside of work hours to stay fresh and learn more about the space. I thought members of this sub may appreciate this piece of software I worked on.&lt;/p&gt;\n\n&lt;p&gt;Stay cool data devs 8)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4mgtdzjsa2nc1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7d1073abec73b959935134d84c18a4b3045e5618\"&gt;https://preview.redd.it/4mgtdzjsa2nc1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7d1073abec73b959935134d84c18a4b3045e5618&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1b9iagn", "is_robot_indexable": true, "report_reasons": null, "author": "engineering-scienct", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b9iagn/multiarmed_bandit_simulator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b9iagn/multiarmed_bandit_simulator/", "subreddit_subscribers": 1403346, "created_utc": 1709882755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wanted to renew my DataSpell license and found that DataSpell is missing from the Developer Tools at jetbrains main page.\n\nI noticed that with the last update or so the UI of DataSpell and PyCharm was unified. Further PyCharm is now described as \"The Python IDE for data science and web development\".\nAnd PyCharms features now list Pandas/Polarssupport + native jupyter notebook support.\n\nThe drawing is in the wall, but I just want to confirm that I should make a switch to PyCharm now.\n\n", "author_fullname": "t2_1uc7fzwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did DataSpell converge into PyCharm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9jdfx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709886913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to renew my DataSpell license and found that DataSpell is missing from the Developer Tools at jetbrains main page.&lt;/p&gt;\n\n&lt;p&gt;I noticed that with the last update or so the UI of DataSpell and PyCharm was unified. Further PyCharm is now described as &amp;quot;The Python IDE for data science and web development&amp;quot;.\nAnd PyCharms features now list Pandas/Polarssupport + native jupyter notebook support.&lt;/p&gt;\n\n&lt;p&gt;The drawing is in the wall, but I just want to confirm that I should make a switch to PyCharm now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b9jdfx", "is_robot_indexable": true, "report_reasons": null, "author": "Phunfactory", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b9jdfx/did_dataspell_converge_into_pycharm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b9jdfx/did_dataspell_converge_into_pycharm/", "subreddit_subscribers": 1403346, "created_utc": 1709886913.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}