{"kind": "Listing", "data": {"after": "t3_1b9mp6u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "An analysis of DOIs suggests that digital preservation is not keeping up with burgeoning scholarly knowledge.", "author_fullname": "t2_8ztqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Millions of research papers at risk of disappearing from the Internet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b97hzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 754, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 754, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/t-GLhfzbts7OaxBsljTaZ98mZClXnwwC7PSqRUkRVas.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709850587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "nature.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;An analysis of DOIs suggests that digital preservation is not keeping up with burgeoning scholarly knowledge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.nature.com/articles/d41586-024-00616-5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Zolv08WE_4M5Gzvysp-THa_cws0Qn74AJ0ZLVw9RgpA.jpg?auto=webp&amp;s=25f1969367754f109a0ebe67ee18cd4c19137292", "width": 1024, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/Zolv08WE_4M5Gzvysp-THa_cws0Qn74AJ0ZLVw9RgpA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e9918ad1ad9123bb023b1fa35eff194fa99f2a5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Zolv08WE_4M5Gzvysp-THa_cws0Qn74AJ0ZLVw9RgpA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7488d4727a0f46e003cab13d90a19f5c5e6c65e2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Zolv08WE_4M5Gzvysp-THa_cws0Qn74AJ0ZLVw9RgpA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2848d1ca7d59eb85c96c6458b3805d33f52a021b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Zolv08WE_4M5Gzvysp-THa_cws0Qn74AJ0ZLVw9RgpA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7102bef0fa982c27c1d084e5ddfd50fe02cf553f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Zolv08WE_4M5Gzvysp-THa_cws0Qn74AJ0ZLVw9RgpA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ef1c943f15c8f896808c0a1703b7e0a2c143513e", "width": 960, "height": 540}], "variants": {}, "id": "9CymYjs6R6CONIR46BpXETBmjrlmCu5Zhwaui5rEl_g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b97hzi", "is_robot_indexable": true, "report_reasons": null, "author": "peliciego", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b97hzi/millions_of_research_papers_at_risk_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.nature.com/articles/d41586-024-00616-5", "subreddit_subscribers": 737272, "created_utc": 1709850587.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys. Thanks in advance for any advice.\n\nI am one of a team of moderators for a large pop music forum. We have tens of thousands of threads going back to October 2011 on our forums.\n\nApproximately 1 month ago, our Admin disappeared completely off the web. We have no way to contact him IRL, and he controlled all of the technical aspects of the website, and all socials,  etc relating to it. \n\nWe are very concerned for his safety as he lived and worked in a country that is currently at war and has recently banned all things related to LGBTQ. \n\n(The website is indirectly related to the LGBTQ community.)\n\nHe was a protester against this country and its dictator and we are very nervous since he has been arrested more than once before , that this time it may have been for good. \n\nMy question is, how can I train myself in a limited amount of time to back up a full Invision Power Boards forum? How big a harddrive should I buy? I know nothing of coding.  (We all have little to no money to spend on this, unless we made a payment plan with a company like Apify for example.)\n\nWe want to make a full copy of every forum, every thread/ topic,  and all the user profiles and all posts. We have several hidden sections only mods can see or only certain community members can see as well, so I can't hand over my log in info to someone, I'd need to run the crawler myself. Especially since there is sensitive data such as user ip addresses,  etc. \n\nBack in 2020, we had a moderator who made perfect backups of this site herself, that she ran on her own server, but her health has declined to the point she can no longer do it. When she did, It took her 2 to 3 months of running the crawler day and night to archive all posts from 2020 to 2011. \n\nWith the disappearance of our Admin, we are very concerned as we have no idea how the payments system for our forum went, or when the plug could be pulled. He handled all glitches or downtime or DDOS / server problems  himself and was always very accessible. We are now vulnerable and worried for his safety and our forums' future. \n\nA full backup of our content, even if only public facing, is valuable to the public fans of this pop musician. \n\nAny help or advice you can offer would be fantastic. \n\nThe website is:\n\nwww.gagadaily.com\n\nOur archives are here (link pending) and to give you an idea of what they once looked like when we did crawl them:\n\nThis is the perfect-ish copy our fellow mod made in 2020. You can get an idea from this as to what we want to achieve as far as a Read Only record of our forum: \n\nhttps://web.archive.org/web/20221012192112/http://gagaverse.com/archives/GagaDaily3_2020_03_07/Forums/\n\n\nAs you can see, the \"tree\" and \"branches\" of the forum went pretty deep, sometimes with hundreds of pages per thread:\n\nhttps://web.archive.org/web/20221011211452/http://gagaverse.com/archives/GagaDaily3_2020_03_07/Forums/Lady_Gaga/Gaga_Thoughts/index.html\n\n\n\n", "author_fullname": "t2_d8mr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Our forum owner may have been imprisoned / drafted /killed in a wartorn country.They have left no backup plans to us. What is the best webcrawler to preserve our massive forum if the payments should lapse? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9h9sd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 109, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 109, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709879701.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709879046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. Thanks in advance for any advice.&lt;/p&gt;\n\n&lt;p&gt;I am one of a team of moderators for a large pop music forum. We have tens of thousands of threads going back to October 2011 on our forums.&lt;/p&gt;\n\n&lt;p&gt;Approximately 1 month ago, our Admin disappeared completely off the web. We have no way to contact him IRL, and he controlled all of the technical aspects of the website, and all socials,  etc relating to it. &lt;/p&gt;\n\n&lt;p&gt;We are very concerned for his safety as he lived and worked in a country that is currently at war and has recently banned all things related to LGBTQ. &lt;/p&gt;\n\n&lt;p&gt;(The website is indirectly related to the LGBTQ community.)&lt;/p&gt;\n\n&lt;p&gt;He was a protester against this country and its dictator and we are very nervous since he has been arrested more than once before , that this time it may have been for good. &lt;/p&gt;\n\n&lt;p&gt;My question is, how can I train myself in a limited amount of time to back up a full Invision Power Boards forum? How big a harddrive should I buy? I know nothing of coding.  (We all have little to no money to spend on this, unless we made a payment plan with a company like Apify for example.)&lt;/p&gt;\n\n&lt;p&gt;We want to make a full copy of every forum, every thread/ topic,  and all the user profiles and all posts. We have several hidden sections only mods can see or only certain community members can see as well, so I can&amp;#39;t hand over my log in info to someone, I&amp;#39;d need to run the crawler myself. Especially since there is sensitive data such as user ip addresses,  etc. &lt;/p&gt;\n\n&lt;p&gt;Back in 2020, we had a moderator who made perfect backups of this site herself, that she ran on her own server, but her health has declined to the point she can no longer do it. When she did, It took her 2 to 3 months of running the crawler day and night to archive all posts from 2020 to 2011. &lt;/p&gt;\n\n&lt;p&gt;With the disappearance of our Admin, we are very concerned as we have no idea how the payments system for our forum went, or when the plug could be pulled. He handled all glitches or downtime or DDOS / server problems  himself and was always very accessible. We are now vulnerable and worried for his safety and our forums&amp;#39; future. &lt;/p&gt;\n\n&lt;p&gt;A full backup of our content, even if only public facing, is valuable to the public fans of this pop musician. &lt;/p&gt;\n\n&lt;p&gt;Any help or advice you can offer would be fantastic. &lt;/p&gt;\n\n&lt;p&gt;The website is:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.gagadaily.com\"&gt;www.gagadaily.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Our archives are here (link pending) and to give you an idea of what they once looked like when we did crawl them:&lt;/p&gt;\n\n&lt;p&gt;This is the perfect-ish copy our fellow mod made in 2020. You can get an idea from this as to what we want to achieve as far as a Read Only record of our forum: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://web.archive.org/web/20221012192112/http://gagaverse.com/archives/GagaDaily3_2020_03_07/Forums/\"&gt;https://web.archive.org/web/20221012192112/http://gagaverse.com/archives/GagaDaily3_2020_03_07/Forums/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As you can see, the &amp;quot;tree&amp;quot; and &amp;quot;branches&amp;quot; of the forum went pretty deep, sometimes with hundreds of pages per thread:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://web.archive.org/web/20221011211452/http://gagaverse.com/archives/GagaDaily3_2020_03_07/Forums/Lady_Gaga/Gaga_Thoughts/index.html\"&gt;https://web.archive.org/web/20221011211452/http://gagaverse.com/archives/GagaDaily3_2020_03_07/Forums/Lady_Gaga/Gaga_Thoughts/index.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9h9sd", "is_robot_indexable": true, "report_reasons": null, "author": "ChicaSkas", "discussion_type": null, "num_comments": 50, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9h9sd/our_forum_owner_may_have_been_imprisoned_drafted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9h9sd/our_forum_owner_may_have_been_imprisoned_drafted/", "subreddit_subscribers": 737272, "created_utc": 1709879046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello. I received this hard drive from a friend who bought it on ebay. The drive states it's a pre-production sample, but googling the model number doesn't provide any results. Does anyone know what model of hard drive this is a pre prod sample too? I've yet to get it to power on, but may be due to the 3.3 volt rail, still troubleshooting", "author_fullname": "t2_5vaqz7s0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD 22TB \"Pre-production sample\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b95zv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pucK1rJJsVfk4jWEpSrd0bP7gCJNr8-0IQCUuiIBbz0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709847002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I received this hard drive from a friend who bought it on ebay. The drive states it&amp;#39;s a pre-production sample, but googling the model number doesn&amp;#39;t provide any results. Does anyone know what model of hard drive this is a pre prod sample too? I&amp;#39;ve yet to get it to power on, but may be due to the 3.3 volt rail, still troubleshooting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sxqkvx00dzmc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?auto=webp&amp;s=78871d0ada3111f7f622711c5c6faa35c90920db", "width": 2252, "height": 3776}, "resolutions": [{"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6fbcee879ef51bf4f8b2f76c7ca7162890eb4566", "width": 108, "height": 181}, {"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=248c073ecf7aa30cd1a6fbaec999a4663bf993c4", "width": 216, "height": 362}, {"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=834e3354b38bb170fd0c77993ed23d84a157c3e7", "width": 320, "height": 536}, {"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5efd78384da521ab375e112103deb8b9496ef9a", "width": 640, "height": 1073}, {"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ceb69cb323788e00244b6374eb6f66c5114ee2c6", "width": 960, "height": 1609}, {"url": "https://preview.redd.it/sxqkvx00dzmc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49fe940f22b766c3fc08aef6f1efc412ca523d15", "width": 1080, "height": 1810}], "variants": {}, "id": "su-VYCZDt-hjhfHiJZ2juCLVAreXI3sNd1RI15mur8I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b95zv5", "is_robot_indexable": true, "report_reasons": null, "author": "saints0963", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b95zv5/wd_22tb_preproduction_sample/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sxqkvx00dzmc1.jpeg", "subreddit_subscribers": 737272, "created_utc": 1709847002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In my university class we are doing a time capsule for our university to be opened 50 years from now. It is my job to figure out how to have data last that long. So far I've determined the best way to go about it would be to print our presentations on paper designed to last a long time. But in the event other presenters would like to have music or videos in their presentation I'd also like to prepare for a digital method that could last 50 years in a time capsule.\n\nFeedback would be greatly appreciated, thank you.", "author_fullname": "t2_2sjzxx2c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ensure digital data lasts 50 years without interaction or additional cost?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b963ig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709847234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my university class we are doing a time capsule for our university to be opened 50 years from now. It is my job to figure out how to have data last that long. So far I&amp;#39;ve determined the best way to go about it would be to print our presentations on paper designed to last a long time. But in the event other presenters would like to have music or videos in their presentation I&amp;#39;d also like to prepare for a digital method that could last 50 years in a time capsule.&lt;/p&gt;\n\n&lt;p&gt;Feedback would be greatly appreciated, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b963ig", "is_robot_indexable": true, "report_reasons": null, "author": "PiggiesGoSqueal", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b963ig/how_to_ensure_digital_data_lasts_50_years_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b963ig/how_to_ensure_digital_data_lasts_50_years_without/", "subreddit_subscribers": 737272, "created_utc": 1709847234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_bdveu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After a week of running checmsum verifications and fixing any errors to migrate to a new server I can finally start..... building another checksum!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 33, "top_awarded_type": null, "hide_score": false, "name": "t3_1b98uyg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/freF4W-Dru1WOVKzKLzjh-eYVh_u330YRBeWelWTXrI.jpg", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709854254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ua2qn1bjyzmc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?auto=webp&amp;s=55506dbcbc69c6a671af9bb7345e83fcc8e5f109", "width": 1917, "height": 461}, "resolutions": [{"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7be9143b0398b9c9f9d344428a3a4b5bb313dad0", "width": 108, "height": 25}, {"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=05dc4177640de76517ff5a67b459fea181cfc6f5", "width": 216, "height": 51}, {"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=00705a436bddbc222b547a2e54e7d8570f13628b", "width": 320, "height": 76}, {"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec844c37fe4d6fe6dbe7432fc9163e1dbcb54a9b", "width": 640, "height": 153}, {"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e8f5a94db611b96ab6aaaea7dd707e8b3b31342", "width": 960, "height": 230}, {"url": "https://preview.redd.it/ua2qn1bjyzmc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f27b438bbc182d535a544d1f3526616f969591ec", "width": 1080, "height": 259}], "variants": {}, "id": "n-eRrMpUyqGRTL2tXaGB_7fCg4VPbvbeqiIi0eKRfgA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "My backups are on floppies.", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b98uyg", "is_robot_indexable": true, "report_reasons": null, "author": "XOIIO", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b98uyg/after_a_week_of_running_checmsum_verifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ua2qn1bjyzmc1.jpeg", "subreddit_subscribers": 737272, "created_utc": 1709854254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_bsklr77o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "StableBid Cloud will stop working with Google on 5/15/2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b98xzl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CjmjH1RgR0J44awrLRlz3knRb-kQrsze6G_Bp33h9oo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709854504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q9wzxxabyzmc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q9wzxxabyzmc1.png?auto=webp&amp;s=95feda381ce100f6f1e17de4005faf2372098e3c", "width": 632, "height": 698}, "resolutions": [{"url": "https://preview.redd.it/q9wzxxabyzmc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=625968463c9c7d41f9c3052da90ea51f08e7858e", "width": 108, "height": 119}, {"url": "https://preview.redd.it/q9wzxxabyzmc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa86d65ac1b20bf51489a6c78a1a785966b631ee", "width": 216, "height": 238}, {"url": "https://preview.redd.it/q9wzxxabyzmc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e3a6c3a6da8e0a8920b97f5eec8e3b493d4df8e", "width": 320, "height": 353}], "variants": {}, "id": "sY3hqrrMf8DdQDDatMtm3eSSQriHOHIzO0tmRqUzjMk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b98xzl", "is_robot_indexable": true, "report_reasons": null, "author": "Fish_Fellatio", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b98xzl/stablebid_cloud_will_stop_working_with_google_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q9wzxxabyzmc1.png", "subreddit_subscribers": 737272, "created_utc": 1709854504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In 2022, I somehow converted my entire collection at the time into a txt file, and I've been wanting to update it for so long but couldn't remember how I did that. I'm not exactly technology illiterate, but I'm not well versed in a lot of computer things. I figured out today that the original copies are in .wpl format, meaning I clearly used Windows Media Player to do the conversion but couldn't get it to stop crashing when trying to do what I did previously. \n\nSo I used CMD prompt, edited the stuff I didn't need in Notepad++, and now despite it being messy as *fuck* due to me having to omit a lot of characters that were also in song names, I'm thankful to finally have the txt files in case I lose my collection for some reason!! \n\nNow my next hurdle- sorting my photo collection from 2009-present *(shudders)*", "author_fullname": "t2_7l2p5s3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just updated my music collection into txt file format- had to use a less clean method, but the txt files of all my music from 2010-present are now fully updated!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9hj3m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Show 'n Tell", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709879953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In 2022, I somehow converted my entire collection at the time into a txt file, and I&amp;#39;ve been wanting to update it for so long but couldn&amp;#39;t remember how I did that. I&amp;#39;m not exactly technology illiterate, but I&amp;#39;m not well versed in a lot of computer things. I figured out today that the original copies are in .wpl format, meaning I clearly used Windows Media Player to do the conversion but couldn&amp;#39;t get it to stop crashing when trying to do what I did previously. &lt;/p&gt;\n\n&lt;p&gt;So I used CMD prompt, edited the stuff I didn&amp;#39;t need in Notepad++, and now despite it being messy as &lt;em&gt;fuck&lt;/em&gt; due to me having to omit a lot of characters that were also in song names, I&amp;#39;m thankful to finally have the txt files in case I lose my collection for some reason!! &lt;/p&gt;\n\n&lt;p&gt;Now my next hurdle- sorting my photo collection from 2009-present &lt;em&gt;(shudders)&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b9hj3m", "is_robot_indexable": true, "report_reasons": null, "author": "shinnith", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9hj3m/just_updated_my_music_collection_into_txt_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9hj3m/just_updated_my_music_collection_into_txt_file/", "subreddit_subscribers": 737272, "created_utc": 1709879953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried posting this elsewhere with little luck. I'm thinking of creating a digital library for works that match the Free Cultural Works definition. It's an idea similar to, but distinct from, Wikimedia Commons, Project Gutenberg and the Free Music Archive before it was bought out. \n\nIt's different from Wikimedia Commons because WC distributes content with all kinds of copyright licenses, so long as it aids the WC projects. This means cultural artifacts like full music albums are missing. It's much more similar to Project Gutenberg, but with a focus on the Canadian public domain as that's where I'm from, a broader scope than just the public domain and it'll contain more than just literature. Lastly, it's also like the Free Music Archive, but only for works that meet the Free Cultural Works definition, and for all media types, not just music. \n\nLike a real library, I need a catalog to organize all these files. I'm going to use a MySQL database table with article metadata inside each table. Something like UUID, Checksum, Title, Author, Publisher, Illustrator, etc. etc. \n\nIt's very important to be that I collect as much metadata as possible while being as objective as possible. The catalog should not contain subjective or primary information. What kind of metadata should I include to make searching through it a breeze? Also, since I'm just starting the collection, I'd like my first few items to be special. What would you suggest? I'd also like to potentially add user descriptions and ratings, if I'm feeling brave. What features would you like to see in a Free Culture Library?", "author_fullname": "t2_5ghi2lkd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Free Culture Library/Collection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9kivz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709891724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried posting this elsewhere with little luck. I&amp;#39;m thinking of creating a digital library for works that match the Free Cultural Works definition. It&amp;#39;s an idea similar to, but distinct from, Wikimedia Commons, Project Gutenberg and the Free Music Archive before it was bought out. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s different from Wikimedia Commons because WC distributes content with all kinds of copyright licenses, so long as it aids the WC projects. This means cultural artifacts like full music albums are missing. It&amp;#39;s much more similar to Project Gutenberg, but with a focus on the Canadian public domain as that&amp;#39;s where I&amp;#39;m from, a broader scope than just the public domain and it&amp;#39;ll contain more than just literature. Lastly, it&amp;#39;s also like the Free Music Archive, but only for works that meet the Free Cultural Works definition, and for all media types, not just music. &lt;/p&gt;\n\n&lt;p&gt;Like a real library, I need a catalog to organize all these files. I&amp;#39;m going to use a MySQL database table with article metadata inside each table. Something like UUID, Checksum, Title, Author, Publisher, Illustrator, etc. etc. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s very important to be that I collect as much metadata as possible while being as objective as possible. The catalog should not contain subjective or primary information. What kind of metadata should I include to make searching through it a breeze? Also, since I&amp;#39;m just starting the collection, I&amp;#39;d like my first few items to be special. What would you suggest? I&amp;#39;d also like to potentially add user descriptions and ratings, if I&amp;#39;m feeling brave. What features would you like to see in a Free Culture Library?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9kivz", "is_robot_indexable": true, "report_reasons": null, "author": "GeeXerox", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9kivz/a_free_culture_librarycollection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9kivz/a_free_culture_librarycollection/", "subreddit_subscribers": 737272, "created_utc": 1709891724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanted to start a thread on this topic because, even though it comes up frequently, there isn't a list of recommended cloud storage providers in the wiki which feels like a bit of a gap currently.\n\nMy use case: I run a Synology NAS at home to backup family photos/videos/files/media and always use an offsite cloud backup of my NAS for just-in-case retrieval. Over the years I've experimented with a ton of different options:\n\n* Google Drive Unlimited (RIP)\n* Amazon S3 (reliable, but expensive)\n* Amazon Glacier (reliable, cheap, but hard to use and extremely expensive if you need to actually retrieve your data)\n* iDrive (looks relatively inexpensive but have heard terrible things)\n* Backblaze B2 (good cost, but recently got more expensive)\n* Storj (decentralized, durable (11 9's), S3-compatible APIs, and extremely inexpensive -- $4/TB/mo)\n\nI've recently switched over to use Storj as my cloud backup provider, simply because they have 11 9's of durability, the lowest cost per TB I've been able to find, and an S3-compatible API so they work with pretty much every tool.\n\nWhat are you using?", "author_fullname": "t2_4g95l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheapest Cloud Storage Providers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9czns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709865971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to start a thread on this topic because, even though it comes up frequently, there isn&amp;#39;t a list of recommended cloud storage providers in the wiki which feels like a bit of a gap currently.&lt;/p&gt;\n\n&lt;p&gt;My use case: I run a Synology NAS at home to backup family photos/videos/files/media and always use an offsite cloud backup of my NAS for just-in-case retrieval. Over the years I&amp;#39;ve experimented with a ton of different options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Google Drive Unlimited (RIP)&lt;/li&gt;\n&lt;li&gt;Amazon S3 (reliable, but expensive)&lt;/li&gt;\n&lt;li&gt;Amazon Glacier (reliable, cheap, but hard to use and extremely expensive if you need to actually retrieve your data)&lt;/li&gt;\n&lt;li&gt;iDrive (looks relatively inexpensive but have heard terrible things)&lt;/li&gt;\n&lt;li&gt;Backblaze B2 (good cost, but recently got more expensive)&lt;/li&gt;\n&lt;li&gt;Storj (decentralized, durable (11 9&amp;#39;s), S3-compatible APIs, and extremely inexpensive -- $4/TB/mo)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve recently switched over to use Storj as my cloud backup provider, simply because they have 11 9&amp;#39;s of durability, the lowest cost per TB I&amp;#39;ve been able to find, and an S3-compatible API so they work with pretty much every tool.&lt;/p&gt;\n\n&lt;p&gt;What are you using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9czns", "is_robot_indexable": true, "report_reasons": null, "author": "rdegges", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9czns/cheapest_cloud_storage_providers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9czns/cheapest_cloud_storage_providers/", "subreddit_subscribers": 737272, "created_utc": 1709865971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've built a CLI tool for file management automation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9txy0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_68xpi7ow", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "opensource", "selftext": "I've been playing around with tools that allow me to automate file sorting workflows. There are some interesting tools out there, but none allowed me to write custom rules in a simple, declarative way.\n\nSo I've built one myself:\n\n[https://github.com/leonmeka/sortql-cli](https://github.com/leonmeka/sortql-cli)\n\nLet me know if you find it useful!", "author_fullname": "t2_68xpi7ow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've built a CLI tool for file management automation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/opensource", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9tq7m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Promotional", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709918803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.opensource", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been playing around with tools that allow me to automate file sorting workflows. There are some interesting tools out there, but none allowed me to write custom rules in a simple, declarative way.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve built one myself:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/leonmeka/sortql-cli\"&gt;https://github.com/leonmeka/sortql-cli&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let me know if you find it useful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?auto=webp&amp;s=25c101ca695cfcb9df10117cf63fe4cdbd44abc7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=02e97ea5a049470a44efce04b51e34f76f10aab1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63f5362f223b047a0e42300ebd2e8789f8da3a40", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=894c53438ffc44828cc83c71026714e8e7851950", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ec4990e31d1038b96d70ce78d38f49e798a0359", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d84ccace5e53f952ef035647b58bbd07ef71fb2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3eba6bc1e173c391f19a83f9bdf0811da2fff65c", "width": 1080, "height": 540}], "variants": {}, "id": "oHHfKzFgQXqdQF-15ERd8e7Pt24wWdWpUFsdpIkT-Ec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f048747a-4094-11ed-afcf-16b5e38a4910", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh4n", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffd635", "id": "1b9tq7m", "is_robot_indexable": true, "report_reasons": null, "author": "SeaEstablishment1367", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/opensource/comments/1b9tq7m/ive_built_a_cli_tool_for_file_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/opensource/comments/1b9tq7m/ive_built_a_cli_tool_for_file_management/", "subreddit_subscribers": 216339, "created_utc": 1709918803.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1709919300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.opensource", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/opensource/comments/1b9tq7m/ive_built_a_cli_tool_for_file_management/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?auto=webp&amp;s=25c101ca695cfcb9df10117cf63fe4cdbd44abc7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=02e97ea5a049470a44efce04b51e34f76f10aab1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63f5362f223b047a0e42300ebd2e8789f8da3a40", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=894c53438ffc44828cc83c71026714e8e7851950", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ec4990e31d1038b96d70ce78d38f49e798a0359", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d84ccace5e53f952ef035647b58bbd07ef71fb2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/stL1_2TJNrfmj7PGiJyF7vcYOUJd6PPZ6K7jf-Hy634.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3eba6bc1e173c391f19a83f9bdf0811da2fff65c", "width": 1080, "height": 540}], "variants": {}, "id": "oHHfKzFgQXqdQF-15ERd8e7Pt24wWdWpUFsdpIkT-Ec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9txy0", "is_robot_indexable": true, "report_reasons": null, "author": "SeaEstablishment1367", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1b9tq7m", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9txy0/ive_built_a_cli_tool_for_file_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/opensource/comments/1b9tq7m/ive_built_a_cli_tool_for_file_management/", "subreddit_subscribers": 737272, "created_utc": 1709919300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i can remember the title, but i cant remember the url. is there a way to search all the videos archived from youtube by title? probably not, but ill stay hopeful", "author_fullname": "t2_kqnled8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "searchable wayback machine youtube archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9qrph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709911817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i can remember the title, but i cant remember the url. is there a way to search all the videos archived from youtube by title? probably not, but ill stay hopeful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9qrph", "is_robot_indexable": true, "report_reasons": null, "author": "dowrgi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9qrph/searchable_wayback_machine_youtube_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9qrph/searchable_wayback_machine_youtube_archive/", "subreddit_subscribers": 737272, "created_utc": 1709911817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, as far as I've understood it, this site was captured on [archive.org](https://archive.org). but I've never been able to access it. The entire screen just whites out, what could be causing this? I've never been able to acccess any of the things archived on this blog,  and when you look there are supposed to be several.\n\n[https://web.archive.org/web/20151201000000\\*/http://foolsforluv.blogspot.com/2013/02/BLUDDYVALENTINE.html](https://web.archive.org/web/20151201000000*/http://foolsforluv.blogspot.com/2013/02/BLUDDYVALENTINE.html)\n\n&amp;#x200B;\n\nwhenever I try to click any of these links, it never works.  \n[https://web.archive.org/web/\\*/http://foolsforluv.blogspot.com/\\*](https://web.archive.org/web/*/http://foolsforluv.blogspot.com/*)", "author_fullname": "t2_j3lajj2up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't access Archive.org archived site.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b96pbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709848656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, as far as I&amp;#39;ve understood it, this site was captured on &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;. but I&amp;#39;ve never been able to access it. The entire screen just whites out, what could be causing this? I&amp;#39;ve never been able to acccess any of the things archived on this blog,  and when you look there are supposed to be several.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://web.archive.org/web/20151201000000*/http://foolsforluv.blogspot.com/2013/02/BLUDDYVALENTINE.html\"&gt;https://web.archive.org/web/20151201000000*/http://foolsforluv.blogspot.com/2013/02/BLUDDYVALENTINE.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;whenever I try to click any of these links, it never works.&lt;br/&gt;\n&lt;a href=\"https://web.archive.org/web/*/http://foolsforluv.blogspot.com/*\"&gt;https://web.archive.org/web/*/http://foolsforluv.blogspot.com/*&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b96pbc", "is_robot_indexable": true, "report_reasons": null, "author": "BedroomDependent8152", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b96pbc/cant_access_archiveorg_archived_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b96pbc/cant_access_archiveorg_archived_site/", "subreddit_subscribers": 737272, "created_utc": 1709848656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Everything I know about DVD ripping I learned in the past 30 days. I\u2019m good at figuring things out quickly, but have no formal computer education. I have a massive collection of TV series on DVD (I just flippin love owning things). I bought MacX DVD Ripper Pro. Had weird issues: it only converted to MP4, not MKV and the ISO Clone function only worked once. It would include subtitles if selected, but the font is clunky and they\u2019re so low on the screen that they get partly cut off when I play the video on my TV. I\u2019m looking for a low-cost (under $50) DVD ripper that will convert directly to lossless MP4, allow episode extraction and burn in subtitles. This is for a 2019 MacBook with M1 chip. I\u2019m running MakeMKV on my old 2009 MacBook but I can\u2019t keep accommodating those file sizes. Attempting to convert the ginormous MKVs to MP4 with Handbrake but the setting options are overwhelming to a newbie. I can\u2019t get a zero loss quality no matter what I tweak and it\u2019s been VERY time consuming. I\u2019m too nervous to attempt installing Libdvdcss. I\u2019m debating between trying DumboFab and Wonderfox next. Any suggestions on either of those or just overall advice? I\u2019ve gotten this far by reading dozens of r/DataHoarder posts. Last thing - anyone know the deal with eneba.com? They sell license codes for next to nothing. Like, $2 for a lifetime Wonderfox DVD Ripper Pro key. Is this a scam? Malware? (I am also a compulsive bargain hunter) \ud83d\ude38", "author_fullname": "t2_9aotl7yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DVD ripping: general software advice &amp; (eneba?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9vd2w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709922615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everything I know about DVD ripping I learned in the past 30 days. I\u2019m good at figuring things out quickly, but have no formal computer education. I have a massive collection of TV series on DVD (I just flippin love owning things). I bought MacX DVD Ripper Pro. Had weird issues: it only converted to MP4, not MKV and the ISO Clone function only worked once. It would include subtitles if selected, but the font is clunky and they\u2019re so low on the screen that they get partly cut off when I play the video on my TV. I\u2019m looking for a low-cost (under $50) DVD ripper that will convert directly to lossless MP4, allow episode extraction and burn in subtitles. This is for a 2019 MacBook with M1 chip. I\u2019m running MakeMKV on my old 2009 MacBook but I can\u2019t keep accommodating those file sizes. Attempting to convert the ginormous MKVs to MP4 with Handbrake but the setting options are overwhelming to a newbie. I can\u2019t get a zero loss quality no matter what I tweak and it\u2019s been VERY time consuming. I\u2019m too nervous to attempt installing Libdvdcss. I\u2019m debating between trying DumboFab and Wonderfox next. Any suggestions on either of those or just overall advice? I\u2019ve gotten this far by reading dozens of &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt; posts. Last thing - anyone know the deal with eneba.com? They sell license codes for next to nothing. Like, $2 for a lifetime Wonderfox DVD Ripper Pro key. Is this a scam? Malware? (I am also a compulsive bargain hunter) \ud83d\ude38&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9vd2w", "is_robot_indexable": true, "report_reasons": null, "author": "DaMewses", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9vd2w/dvd_ripping_general_software_advice_eneba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9vd2w/dvd_ripping_general_software_advice_eneba/", "subreddit_subscribers": 737272, "created_utc": 1709922615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I've tried everything I could think of, disabled indexing, encrypting the data with bitlocker, setting the drive as offline in disk management, power settings. Nothing seems to work.\n\nI want my internal drives to not spin up and make a racket until I want to access them, basically.\n\nIs there a way to do this? Doesn't seem like something hard or that people wouldn't want, I mean, external hard drives exist, is physically unplugging them really the only way with no way of doing it through software?\n\nRight now I'm putting them offline and having them spin down with hddscan, which gives me a bit of peace, but after a while windows spins them back up even if I'm not doing anything", "author_fullname": "t2_5nkyopvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows spins up my internal hdds randomly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9v53g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709922096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried everything I could think of, disabled indexing, encrypting the data with bitlocker, setting the drive as offline in disk management, power settings. Nothing seems to work.&lt;/p&gt;\n\n&lt;p&gt;I want my internal drives to not spin up and make a racket until I want to access them, basically.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this? Doesn&amp;#39;t seem like something hard or that people wouldn&amp;#39;t want, I mean, external hard drives exist, is physically unplugging them really the only way with no way of doing it through software?&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;m putting them offline and having them spin down with hddscan, which gives me a bit of peace, but after a while windows spins them back up even if I&amp;#39;m not doing anything&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9v53g", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping-Bake-557", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9v53g/windows_spins_up_my_internal_hdds_randomly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9v53g/windows_spins_up_my_internal_hdds_randomly/", "subreddit_subscribers": 737272, "created_utc": 1709922096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My Synology NAS is sending me about alerts on just one of my WD NAS Red drives; I bought both drives at the same time as the NAS (Sept 2018).\n\nIn searching for a replacement for WD80EFAX-68KNBN0, I see the WD80EFZZ is considerably less expensive. How compatible are the two drives in a NAS?\n\nCross-posted from /r/WesternDigital", "author_fullname": "t2_mytnu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What other WD drive is compatible with an 8TB NAS WD80EFAX in a 2-drive NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9ttur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709919038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Synology NAS is sending me about alerts on just one of my WD NAS Red drives; I bought both drives at the same time as the NAS (Sept 2018).&lt;/p&gt;\n\n&lt;p&gt;In searching for a replacement for WD80EFAX-68KNBN0, I see the WD80EFZZ is considerably less expensive. How compatible are the two drives in a NAS?&lt;/p&gt;\n\n&lt;p&gt;Cross-posted from &lt;a href=\"/r/WesternDigital\"&gt;/r/WesternDigital&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9ttur", "is_robot_indexable": true, "report_reasons": null, "author": "BWB8771", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9ttur/what_other_wd_drive_is_compatible_with_an_8tb_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9ttur/what_other_wd_drive_is_compatible_with_an_8tb_nas/", "subreddit_subscribers": 737272, "created_utc": 1709919038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TL;DR: with a low end CPU, is RaidZ2 worth it over hardware Raid5?\n\nHi all, I am setting up a NAS for general experimentation and fun.\n\nI am using a lot of old parts.\n\n&amp;#x200B;\n\n|Hardware|Type|\n|:-|:-|\n|CPU|Pentium G3458 (2 cores)|\n|RAM|32 GB DDR-3|\n|OS Drive|Kingston A400 (Trash)|\n|Storage|8x HPE 4TB 7200 RPM|\n|ZFS Cache|Samsung 850 256G|\n|Raid Controler|IBM M5015 crossflashed|\n|Sas Controler|6 GB/s HBA I can get|\n|PSU|650 W|\n\nHere's my question: with this setup, and \"lighterweight\" CPU. Is it better to use hardware raid5 as a drive in my ZFS pool, or would the CPU be robust enough to do raidz2.\n\nSecondary question... any interesting mount points to use for the ZFS pool? The server's hostname is \"Lil-Nas-X\".", "author_fullname": "t2_e10s8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RaidZ2 or Hardware Raid 5 on old computers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9qqj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709911735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: with a low end CPU, is RaidZ2 worth it over hardware Raid5?&lt;/p&gt;\n\n&lt;p&gt;Hi all, I am setting up a NAS for general experimentation and fun.&lt;/p&gt;\n\n&lt;p&gt;I am using a lot of old parts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Hardware&lt;/th&gt;\n&lt;th align=\"left\"&gt;Type&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;CPU&lt;/td&gt;\n&lt;td align=\"left\"&gt;Pentium G3458 (2 cores)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;RAM&lt;/td&gt;\n&lt;td align=\"left\"&gt;32 GB DDR-3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;OS Drive&lt;/td&gt;\n&lt;td align=\"left\"&gt;Kingston A400 (Trash)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Storage&lt;/td&gt;\n&lt;td align=\"left\"&gt;8x HPE 4TB 7200 RPM&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;ZFS Cache&lt;/td&gt;\n&lt;td align=\"left\"&gt;Samsung 850 256G&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Raid Controler&lt;/td&gt;\n&lt;td align=\"left\"&gt;IBM M5015 crossflashed&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Sas Controler&lt;/td&gt;\n&lt;td align=\"left\"&gt;6 GB/s HBA I can get&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;PSU&lt;/td&gt;\n&lt;td align=\"left\"&gt;650 W&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Here&amp;#39;s my question: with this setup, and &amp;quot;lighterweight&amp;quot; CPU. Is it better to use hardware raid5 as a drive in my ZFS pool, or would the CPU be robust enough to do raidz2.&lt;/p&gt;\n\n&lt;p&gt;Secondary question... any interesting mount points to use for the ZFS pool? The server&amp;#39;s hostname is &amp;quot;Lil-Nas-X&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9qqj2", "is_robot_indexable": true, "report_reasons": null, "author": "MacGuyver247", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9qqj2/raidz2_or_hardware_raid_5_on_old_computers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9qqj2/raidz2_or_hardware_raid_5_on_old_computers/", "subreddit_subscribers": 737272, "created_utc": 1709911735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, im doing a large migration from one array to another using rsync. Large transfer, 175TB.\n\nI've essentially spawned a separate instance of rsync for every disk in my unraid array to maximize performance over a 10GB network.\n\nI found a script someone made online as i've never used rsync before.  For every file, this command is run: \n\n        rsync --recursive \\\n              --whole-file \\\n              --inplace \\\n              --sparse \\\n              --no-compress \\\n              --max-alloc=8GiB \\\n              --size-only \\\n              --human-readable \\\n              --info=progress2 \\\n              --log-file=\"$rsync_file_basename.log\" \\\n              --log-file-format=\"%o=%-7'''b | total=%-7'''l [%i] =&gt; %f%L\" \\\n           \"/mnt/disk${disk_id}/$share_name/$share_subdir/\" \\\n           \"$target_path\" \\\n        &gt;&gt; \"$rsync_file_basename.out\"\n\nInitially, everything looked good.  But then I started seeing errors in some of the processes like this - \n&gt; rsync: [receiver] ftruncate failed on \"/mnt/remotes/TS140_stuff/pictures/family_1/IMG345.jpg\": Resource temporarily unavailable (11)\n    \n&gt; rsync: [receiver] write failed on \"/mnt/remotes/TS140_stuff/shows/ep1.mp4\": Resource temporarily unavailable (11) rsync error: error in file IO (code 11) at receiver.c(380) [receiver=3.2.7] rsync: [sender] write error: Broken pipe (32) rsync error: error in file IO (code 11) at io.c(1700) [sender=3.2.7]\n\nLooking at the logs, I can see a file size difference for *some* but not *all* of the failed files - \n\n&gt; 2024/03/05 18:48:42 [15416] send=156.91M | total=156.89M [&gt;f+++++++++] =&gt;mnt/disk1/stuff/movies/mov2_youtube.mp4\n\nHowever, some of the files do have the right size where the error occured.\n\nSo I guess my questions are: \n\n1.  It looks like rsync will automatically stop the process on a failure and so the rest of the disk will not transfer, is this correct?\n2.  If I rerun the command, it will use the default size/modification time comparison and just essentially pick up where it left off.  \n3.  My bigger question is around each particular file it failed at.  So is the best approach for me here is to just delete the file it had a broken pipe at on the destination and let rsync send it over again?  The only other alternative I see is to checksum EVERY file, which will take a very long time.", "author_fullname": "t2_os8s9418t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with rsync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9o4c1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709905091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, im doing a large migration from one array to another using rsync. Large transfer, 175TB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve essentially spawned a separate instance of rsync for every disk in my unraid array to maximize performance over a 10GB network.&lt;/p&gt;\n\n&lt;p&gt;I found a script someone made online as i&amp;#39;ve never used rsync before.  For every file, this command is run: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    rsync --recursive \\\n          --whole-file \\\n          --inplace \\\n          --sparse \\\n          --no-compress \\\n          --max-alloc=8GiB \\\n          --size-only \\\n          --human-readable \\\n          --info=progress2 \\\n          --log-file=&amp;quot;$rsync_file_basename.log&amp;quot; \\\n          --log-file-format=&amp;quot;%o=%-7&amp;#39;&amp;#39;&amp;#39;b | total=%-7&amp;#39;&amp;#39;&amp;#39;l [%i] =&amp;gt; %f%L&amp;quot; \\\n       &amp;quot;/mnt/disk${disk_id}/$share_name/$share_subdir/&amp;quot; \\\n       &amp;quot;$target_path&amp;quot; \\\n    &amp;gt;&amp;gt; &amp;quot;$rsync_file_basename.out&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Initially, everything looked good.  But then I started seeing errors in some of the processes like this - &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;rsync: [receiver] ftruncate failed on &amp;quot;/mnt/remotes/TS140_stuff/pictures/family_1/IMG345.jpg&amp;quot;: Resource temporarily unavailable (11)&lt;/p&gt;\n\n&lt;p&gt;rsync: [receiver] write failed on &amp;quot;/mnt/remotes/TS140_stuff/shows/ep1.mp4&amp;quot;: Resource temporarily unavailable (11) rsync error: error in file IO (code 11) at receiver.c(380) [receiver=3.2.7] rsync: [sender] write error: Broken pipe (32) rsync error: error in file IO (code 11) at io.c(1700) [sender=3.2.7]&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Looking at the logs, I can see a file size difference for &lt;em&gt;some&lt;/em&gt; but not &lt;em&gt;all&lt;/em&gt; of the failed files - &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;2024/03/05 18:48:42 [15416] send=156.91M | total=156.89M [&amp;gt;f+++++++++] =&amp;gt;mnt/disk1/stuff/movies/mov2_youtube.mp4&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;However, some of the files do have the right size where the error occured.&lt;/p&gt;\n\n&lt;p&gt;So I guess my questions are: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; It looks like rsync will automatically stop the process on a failure and so the rest of the disk will not transfer, is this correct?&lt;/li&gt;\n&lt;li&gt; If I rerun the command, it will use the default size/modification time comparison and just essentially pick up where it left off.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt; My bigger question is around each particular file it failed at.  So is the best approach for me here is to just delete the file it had a broken pipe at on the destination and let rsync send it over again?  The only other alternative I see is to checksum EVERY file, which will take a very long time.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9o4c1", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Tone6393", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9o4c1/help_with_rsync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9o4c1/help_with_rsync/", "subreddit_subscribers": 737272, "created_utc": 1709905091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi storage geeks. I currently use Snapraid on my data drives with 2 drives dedicated to parity. I'm thinking about ditching this approach and moving to a RAID setup with btrfs.\n\nI have about 68.4TB usable spread over 7 disks and am using about 20.4TB so plenty of space for parity and snaps.\n\nI do backup my essential data with borg to 6TB of offsite VPS.\n\nThis is what I have to play with:\n\n    \u2502 MOUNTED ON  \u2502    SIZE \u2502   USED \u2502  AVAIL \u2502  USE% \u2502 TYPE \u2502\n    \u2502 /           \u2502  116.0G \u2502  61.9G \u2502  54.1G \u2502 53.3% \u2502 xfs  \u2502\n    \u2502             \u2502         \u2502        \u2502        \u2502       \u2502      \u2502\n    \u2502 /boot       \u2502 1014.0M \u2502 400.7M \u2502 613.3M \u2502 39.5% \u2502 xfs  \u2502\n    \u2502 /boot/efi   \u2502  598.8M \u2502   7.4M \u2502 591.4M \u2502  1.2% \u2502 vfat \u2502\n    \u2502 /mnt/data1  \u2502   10.8T \u2502   7.6T \u2502   2.7T \u2502 69.8% \u2502 ext4 \u2502\n    \u2502 /mnt/data2  \u2502   10.8T \u2502   4.6T \u2502   5.7T \u2502 42.5% \u2502 ext4 \u2502\n    \u2502 /mnt/data3  \u2502   10.8T \u2502   8.0T \u2502   2.3T \u2502 73.9% \u2502 ext4 \u2502\n    \u2502 /mnt/data4  \u2502    3.6T \u2502 176.6M \u2502   3.4T \u2502  0.0% \u2502 ext4 \u2502\n    \u2502 /mnt/diskp1 \u2502   10.8T \u2502   8.2T \u2502   2.0T \u2502 76.2% \u2502 ext4 \u2502\n    \u2502 /mnt/diskp2 \u2502   10.8T \u2502   8.2T \u2502   2.0T \u2502 76.2% \u2502 ext4 \u2502\n    \n    + not yet installed another 10.8T\n\nI was thinking maybe 2 x RAID5 groups with 2D+1P 10.8TB drives or should I RAID 6 the whole lot of large drives in one large group?\n\nAppreciate any opinions on a set up that provides some level of protection from drive failure. I'm going round in circles trying to decide on an optimum layout.", "author_fullname": "t2_mo11s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pls recommend a storage layout", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9exds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709871561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi storage geeks. I currently use Snapraid on my data drives with 2 drives dedicated to parity. I&amp;#39;m thinking about ditching this approach and moving to a RAID setup with btrfs.&lt;/p&gt;\n\n&lt;p&gt;I have about 68.4TB usable spread over 7 disks and am using about 20.4TB so plenty of space for parity and snaps.&lt;/p&gt;\n\n&lt;p&gt;I do backup my essential data with borg to 6TB of offsite VPS.&lt;/p&gt;\n\n&lt;p&gt;This is what I have to play with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2502 MOUNTED ON  \u2502    SIZE \u2502   USED \u2502  AVAIL \u2502  USE% \u2502 TYPE \u2502\n\u2502 /           \u2502  116.0G \u2502  61.9G \u2502  54.1G \u2502 53.3% \u2502 xfs  \u2502\n\u2502             \u2502         \u2502        \u2502        \u2502       \u2502      \u2502\n\u2502 /boot       \u2502 1014.0M \u2502 400.7M \u2502 613.3M \u2502 39.5% \u2502 xfs  \u2502\n\u2502 /boot/efi   \u2502  598.8M \u2502   7.4M \u2502 591.4M \u2502  1.2% \u2502 vfat \u2502\n\u2502 /mnt/data1  \u2502   10.8T \u2502   7.6T \u2502   2.7T \u2502 69.8% \u2502 ext4 \u2502\n\u2502 /mnt/data2  \u2502   10.8T \u2502   4.6T \u2502   5.7T \u2502 42.5% \u2502 ext4 \u2502\n\u2502 /mnt/data3  \u2502   10.8T \u2502   8.0T \u2502   2.3T \u2502 73.9% \u2502 ext4 \u2502\n\u2502 /mnt/data4  \u2502    3.6T \u2502 176.6M \u2502   3.4T \u2502  0.0% \u2502 ext4 \u2502\n\u2502 /mnt/diskp1 \u2502   10.8T \u2502   8.2T \u2502   2.0T \u2502 76.2% \u2502 ext4 \u2502\n\u2502 /mnt/diskp2 \u2502   10.8T \u2502   8.2T \u2502   2.0T \u2502 76.2% \u2502 ext4 \u2502\n\n+ not yet installed another 10.8T\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I was thinking maybe 2 x RAID5 groups with 2D+1P 10.8TB drives or should I RAID 6 the whole lot of large drives in one large group?&lt;/p&gt;\n\n&lt;p&gt;Appreciate any opinions on a set up that provides some level of protection from drive failure. I&amp;#39;m going round in circles trying to decide on an optimum layout.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9exds", "is_robot_indexable": true, "report_reasons": null, "author": "Finno_", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9exds/pls_recommend_a_storage_layout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9exds/pls_recommend_a_storage_layout/", "subreddit_subscribers": 737272, "created_utc": 1709871561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basic question but am I covered in terms of the hardware I need to run a basic media server (either Plex or Jellyfin) ?\n\nBeen planning to start this project for a while, have a bunch of saved resources to get through, but I some what instantaneously decided to start this project *now*.\n\nI live in a country where it's difficult and expensive to buy electronic hardware and I'm currently in the U.S. - want to make sure I have everything I might need before I fly back this weekend.\n\nAny tips or advice would be greatly appreciated.\n\nThanks!", "author_fullname": "t2_1llv04y0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just bought a DS224+ and two WD Red Plus HDD - is there anything else I need to set up my first NAS with the intention of serving media files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9bu7i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709862772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basic question but am I covered in terms of the hardware I need to run a basic media server (either Plex or Jellyfin) ?&lt;/p&gt;\n\n&lt;p&gt;Been planning to start this project for a while, have a bunch of saved resources to get through, but I some what instantaneously decided to start this project &lt;em&gt;now&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;I live in a country where it&amp;#39;s difficult and expensive to buy electronic hardware and I&amp;#39;m currently in the U.S. - want to make sure I have everything I might need before I fly back this weekend.&lt;/p&gt;\n\n&lt;p&gt;Any tips or advice would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9bu7i", "is_robot_indexable": true, "report_reasons": null, "author": "lovely_trequartista", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9bu7i/just_bought_a_ds224_and_two_wd_red_plus_hdd_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9bu7i/just_bought_a_ds224_and_two_wd_red_plus_hdd_is/", "subreddit_subscribers": 737272, "created_utc": 1709862772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have onedrive student account with 5TB space. As onedrive is going to remove the A1 Plus license, my university has to downgrade the plan and limits the storage to 5GB per student starting 1st April. Yes, from 5TB to 5GB. Currently I'm having 2.1TB in the cloud and planning to move all the files to a selfhosted cloud storage. I'm familiar with docker and linux but still a newbie. So, here I am kindly ask for help and advice to setup a selfhosted cloud storage. \n\nUse cases: \n1. Multiplatform - ipad, mac, windows, android\n2. Upload files to cloud \n3. Download on-demand and view file locally \n3. Delete that locally save on-demand went needed\n4. Offline editing &amp; sync to cloud when online\n\nMy questions:\n1. What is the best multiplatform selfhosted cloud storage that suits my use cases? Nextcloud? Seafile?\n2. What is the best filesystem to use? Zfs? Btrfs? \n3. Where should I host the app? NAS? Docker?\n4. What is the best storage disk? HDD 3.5 or 2.5? SMR or CMR?\n5. Other things to consider? NAS? RAID? SMB? Webdav? ", "author_fullname": "t2_8fiv28qr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Onedrive to selfhosted cloud storage migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9abgr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709858680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have onedrive student account with 5TB space. As onedrive is going to remove the A1 Plus license, my university has to downgrade the plan and limits the storage to 5GB per student starting 1st April. Yes, from 5TB to 5GB. Currently I&amp;#39;m having 2.1TB in the cloud and planning to move all the files to a selfhosted cloud storage. I&amp;#39;m familiar with docker and linux but still a newbie. So, here I am kindly ask for help and advice to setup a selfhosted cloud storage. &lt;/p&gt;\n\n&lt;p&gt;Use cases: \n1. Multiplatform - ipad, mac, windows, android\n2. Upload files to cloud \n3. Download on-demand and view file locally \n3. Delete that locally save on-demand went needed\n4. Offline editing &amp;amp; sync to cloud when online&lt;/p&gt;\n\n&lt;p&gt;My questions:\n1. What is the best multiplatform selfhosted cloud storage that suits my use cases? Nextcloud? Seafile?\n2. What is the best filesystem to use? Zfs? Btrfs? \n3. Where should I host the app? NAS? Docker?\n4. What is the best storage disk? HDD 3.5 or 2.5? SMR or CMR?\n5. Other things to consider? NAS? RAID? SMB? Webdav? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9abgr", "is_robot_indexable": true, "report_reasons": null, "author": "Retiary_Lime", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9abgr/onedrive_to_selfhosted_cloud_storage_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9abgr/onedrive_to_selfhosted_cloud_storage_migration/", "subreddit_subscribers": 737272, "created_utc": 1709858680.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a NAS Linux backup server that I have setup smartd to send an email should it find a smart error on a drive.\n\nMy server only runs long enough to execute an incremental backup 3x a week. This backup takes 5-10min on average.\n\nI have not changed the default smart check time period from 30 min, so I was wondering if smartd ran a check at boot or does it only start checking at boot+30min.\n\nIf my server normally runs less than 30min; will smartd never check the drives and send a warning  as it never hits that 30min window for the first check?", "author_fullname": "t2_cskhbtwdp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smartd - When is the first smart check?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b98r7t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709853936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a NAS Linux backup server that I have setup smartd to send an email should it find a smart error on a drive.&lt;/p&gt;\n\n&lt;p&gt;My server only runs long enough to execute an incremental backup 3x a week. This backup takes 5-10min on average.&lt;/p&gt;\n\n&lt;p&gt;I have not changed the default smart check time period from 30 min, so I was wondering if smartd ran a check at boot or does it only start checking at boot+30min.&lt;/p&gt;\n\n&lt;p&gt;If my server normally runs less than 30min; will smartd never check the drives and send a warning  as it never hits that 30min window for the first check?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b98r7t", "is_robot_indexable": true, "report_reasons": null, "author": "Beaver-on-fire", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b98r7t/smartd_when_is_the_first_smart_check/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b98r7t/smartd_when_is_the_first_smart_check/", "subreddit_subscribers": 737272, "created_utc": 1709853936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm in the process of rebuilding a media server. The common Plex, ARR stack with qBittorent. So seeding is also relevant, not just hardlinking. I will be using Docker for the stack. Full disclosure, I am new to pretty much all of it, Linux, mergerfs, etc. I have been reading docs extensively but am still confused on a couple concepts/config settings.\n\nThe point in the setup process I am at now is taking 2 storage HDDs with media and pooling them with mergerfs. Most mergerfs Google results seem to be from this sub so here I am!\n\nFor context, my mergerfs config looks like this:\n\n`/mnt/hdd1:/mnt/hdd2 /merge mergerfs cache.files=partial,dropcacheonclose=true,category.create=mfs`\n\n* /mnt/hdd1 - already has TV and Movies on it\n* /mnt/hdd2 - empty, but have set the same high level directory structure on it:\n   * /torrents\n      * /movies\n      * /tv\n   * /library\n      * /movies\n      * /tv\n\nThe part in the docs that made me start second guessing was reference to \"hardlinks do not work across branches in a pool\". I started thinking about what happens if mergerfs effectively puts the torrent file on one branch, but the Sonarr/Radarr hardlink on another branch (if that's even what it's doing)? *If this is completely irrelevant by just setting Sonarr/Radarr root to /merge then let me know.*\n\nI also want to avoid running into the issue mentioned in docs of \"all my files ending up on 1 filesystem?!\" since I have one drive that already has a bunch of files and directories on it, and one empty drive.\n\nSo, now I'm wondering if I need to modify my mergerfs options from the default to make sure hardlinks and seeding work.\n\n* Do I need to change to create policy to `epmfs`?\n* Do I need to create specific policies for something like tv series' to keep all seasons/episodes related to a show on the same branch?\n* Do I need to enable `moveonenospc`?\n* Would any of the other extensive options be relevant to this topic?\n\nAs far as Docker is concerned, my understanding is I need to mount the containers at the root /merge directory. *It's entirely possible that's all I need to do and I'm overthinking this.*", "author_fullname": "t2_1ajq44ub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make sure hardlinks and seeding work with mergerfs and Radarr/Sonarr?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b96ke4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709848329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of rebuilding a media server. The common Plex, ARR stack with qBittorent. So seeding is also relevant, not just hardlinking. I will be using Docker for the stack. Full disclosure, I am new to pretty much all of it, Linux, mergerfs, etc. I have been reading docs extensively but am still confused on a couple concepts/config settings.&lt;/p&gt;\n\n&lt;p&gt;The point in the setup process I am at now is taking 2 storage HDDs with media and pooling them with mergerfs. Most mergerfs Google results seem to be from this sub so here I am!&lt;/p&gt;\n\n&lt;p&gt;For context, my mergerfs config looks like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;/mnt/hdd1:/mnt/hdd2 /merge mergerfs cache.files=partial,dropcacheonclose=true,category.create=mfs&lt;/code&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;/mnt/hdd1 - already has TV and Movies on it&lt;/li&gt;\n&lt;li&gt;/mnt/hdd2 - empty, but have set the same high level directory structure on it:\n\n&lt;ul&gt;\n&lt;li&gt;/torrents\n\n&lt;ul&gt;\n&lt;li&gt;/movies&lt;/li&gt;\n&lt;li&gt;/tv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;/library\n\n&lt;ul&gt;\n&lt;li&gt;/movies&lt;/li&gt;\n&lt;li&gt;/tv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The part in the docs that made me start second guessing was reference to &amp;quot;hardlinks do not work across branches in a pool&amp;quot;. I started thinking about what happens if mergerfs effectively puts the torrent file on one branch, but the Sonarr/Radarr hardlink on another branch (if that&amp;#39;s even what it&amp;#39;s doing)? &lt;em&gt;If this is completely irrelevant by just setting Sonarr/Radarr root to /merge then let me know.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I also want to avoid running into the issue mentioned in docs of &amp;quot;all my files ending up on 1 filesystem?!&amp;quot; since I have one drive that already has a bunch of files and directories on it, and one empty drive.&lt;/p&gt;\n\n&lt;p&gt;So, now I&amp;#39;m wondering if I need to modify my mergerfs options from the default to make sure hardlinks and seeding work.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do I need to change to create policy to &lt;code&gt;epmfs&lt;/code&gt;?&lt;/li&gt;\n&lt;li&gt;Do I need to create specific policies for something like tv series&amp;#39; to keep all seasons/episodes related to a show on the same branch?&lt;/li&gt;\n&lt;li&gt;Do I need to enable &lt;code&gt;moveonenospc&lt;/code&gt;?&lt;/li&gt;\n&lt;li&gt;Would any of the other extensive options be relevant to this topic?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As far as Docker is concerned, my understanding is I need to mount the containers at the root /merge directory. &lt;em&gt;It&amp;#39;s entirely possible that&amp;#39;s all I need to do and I&amp;#39;m overthinking this.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b96ke4", "is_robot_indexable": true, "report_reasons": null, "author": "GooeyDuck1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b96ke4/how_to_make_sure_hardlinks_and_seeding_work_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b96ke4/how_to_make_sure_hardlinks_and_seeding_work_with/", "subreddit_subscribers": 737272, "created_utc": 1709848329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I need to recover some data from a very old HDD that i don't feel super safe just plugging in my PC.\n\nI thought of live booting Ubuntu of a usb stick, but have also read about kali live with forensic mode and stuff, keep in mind i'm not very familiar with linux, which is why i'm looking for suggestions.\n\nI would transfer that data to a usb stick, how should i tackle scanning it after?", "author_fullname": "t2_b5suwht0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to retrieve data from a potentially infected HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b96hef", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709848142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I need to recover some data from a very old HDD that i don&amp;#39;t feel super safe just plugging in my PC.&lt;/p&gt;\n\n&lt;p&gt;I thought of live booting Ubuntu of a usb stick, but have also read about kali live with forensic mode and stuff, keep in mind i&amp;#39;m not very familiar with linux, which is why i&amp;#39;m looking for suggestions.&lt;/p&gt;\n\n&lt;p&gt;I would transfer that data to a usb stick, how should i tackle scanning it after?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b96hef", "is_robot_indexable": true, "report_reasons": null, "author": "banekal", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b96hef/best_way_to_retrieve_data_from_a_potentially/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b96hef/best_way_to_retrieve_data_from_a_potentially/", "subreddit_subscribers": 737272, "created_utc": 1709848142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I have a big folder in drive C and want to create automatic monthly backups/copies to another drive, it should overwrite when it's full. That's it\n\nThanks", "author_fullname": "t2_d6ciu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free and simple backup software?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9o4fh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709905100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have a big folder in drive C and want to create automatic monthly backups/copies to another drive, it should overwrite when it&amp;#39;s full. That&amp;#39;s it&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9o4fh", "is_robot_indexable": true, "report_reasons": null, "author": "xSniperLol", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9o4fh/free_and_simple_backup_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9o4fh/free_and_simple_backup_software/", "subreddit_subscribers": 737272, "created_utc": 1709905100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This website is near and dear to my heart and the heart of many. If anyone knows how to scrape the whole thing and archive it or can point me towards somewhere where I can find people who can I'd really appreciate it. \n\nhttps://squattheplanet.com/threads/i-need-your-input-on-stps-upcoming-restructuring-plans.44923/\n\nSquat the planet is an important part of internet history and it would be an incredible to shame to just let so many threads detailing good knowledge and legendary stories from the road die like this.", "author_fullname": "t2_gt1sm89m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Squat The Planet is migrating forum software and probably deleting the old forum in the process. Please help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9mp6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709900750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This website is near and dear to my heart and the heart of many. If anyone knows how to scrape the whole thing and archive it or can point me towards somewhere where I can find people who can I&amp;#39;d really appreciate it. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://squattheplanet.com/threads/i-need-your-input-on-stps-upcoming-restructuring-plans.44923/\"&gt;https://squattheplanet.com/threads/i-need-your-input-on-stps-upcoming-restructuring-plans.44923/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Squat the planet is an important part of internet history and it would be an incredible to shame to just let so many threads detailing good knowledge and legendary stories from the road die like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qw73V066TqOv-E76MyWQsO1UwFPqaB2ECUx0gE3A9pc.jpg?auto=webp&amp;s=5379962eb22c6b61516b946ebfa8c62dade7e63c", "width": 856, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/Qw73V066TqOv-E76MyWQsO1UwFPqaB2ECUx0gE3A9pc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b31781c8147207fa9d798a67d26394d1062bd36", "width": 108, "height": 37}, {"url": "https://external-preview.redd.it/Qw73V066TqOv-E76MyWQsO1UwFPqaB2ECUx0gE3A9pc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=add5ef42370ae96e7b3c770548f988f3e458a412", "width": 216, "height": 75}, {"url": "https://external-preview.redd.it/Qw73V066TqOv-E76MyWQsO1UwFPqaB2ECUx0gE3A9pc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f8a96048cc77d0b732d0d9dc614670b160b439", "width": 320, "height": 112}, {"url": "https://external-preview.redd.it/Qw73V066TqOv-E76MyWQsO1UwFPqaB2ECUx0gE3A9pc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17ce6bc0c86948c14e1e89b01dd2ab68409ac877", "width": 640, "height": 224}], "variants": {}, "id": "M8epLW1Otjqp_i3ntxSXKZf37BTvkeGdfzFacKNLBGE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b9mp6u", "is_robot_indexable": true, "report_reasons": null, "author": "goobergal97", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b9mp6u/squat_the_planet_is_migrating_forum_software_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b9mp6u/squat_the_planet_is_migrating_forum_software_and/", "subreddit_subscribers": 737272, "created_utc": 1709900750.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}