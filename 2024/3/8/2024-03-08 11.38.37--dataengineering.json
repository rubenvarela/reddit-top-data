{"kind": "Listing", "data": {"after": "t3_1b9jo2d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster University | Dagster &amp; dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1b96lr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i7uvXAQehTiTa-GR06ule2ZxoK0CwW6OmbEs5i42OLc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709848417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "courses.dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://courses.dagster.io/courses/dagster-dbt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?auto=webp&amp;s=2b2ad690130139debc526a5f823b5cf404c0dddb", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a07bb99f808bf6061884accddb56896352108f9", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a3d3dc8ebf131273408ef99ce2b2b94175ff40d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f808fdd3dad44f069fcf35c0a8df705f437b3300", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LdI8rVMlRX9JNp-rkAanpamCbQnd3axH6pbBsThPS7U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e1a5b7d305c395c05135bd0541f636bdaec6286", "width": 640, "height": 336}], "variants": {}, "id": "Xo4201FG41r9g9jTl6ooInnjJ_aXjb09SNDclCPTp0k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b96lr0", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b96lr0/dagster_university_dagster_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://courses.dagster.io/courses/dagster-dbt", "subreddit_subscribers": 166860, "created_utc": 1709848417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the worst data related decision a company made that left you speechless ", "author_fullname": "t2_sunv53vps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's that one WTF moment you had that made you leave a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b91l3e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709835543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the worst data related decision a company made that left you speechless &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b91l3e", "is_robot_indexable": true, "report_reasons": null, "author": "Eastern-Education-31", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b91l3e/whats_that_one_wtf_moment_you_had_that_made_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b91l3e/whats_that_one_wtf_moment_you_had_that_made_you/", "subreddit_subscribers": 166860, "created_utc": 1709835543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm excited to share my latest blog post, \"From dbt to SQLMesh\" \n\nCheck it out here  [https://www.harness.io/blog/from-dbt-to-sqlmesh](https://www.harness.io/blog/from-dbt-to-sqlmesh)\n\nWe have been running sqlmesh in production in some way shape or form for a long time now, since the earliest versions of the tool. This post is focused on high level migration approach (which is the reason we were able to adopt quickly and drive innovation) &amp; touches on the learnings and key takeaways too. Major points include simplification, no jinja (sqlglot macros instead creating valid and structurally correct sql syntax vs string interpolation free-for-all), better state management and simplified CICD+dev experience. Has been a rewarding experience and paid off manyfold in the quality, reliability, and maintainability of our data platform. And we are poised to scale extremely effectively. I hope this is useful for any folks looking for information on the topic or are just curious.", "author_fullname": "t2_bnmvkmcq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From dbt to SQLMesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b912nc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709834347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m excited to share my latest blog post, &amp;quot;From dbt to SQLMesh&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Check it out here  &lt;a href=\"https://www.harness.io/blog/from-dbt-to-sqlmesh\"&gt;https://www.harness.io/blog/from-dbt-to-sqlmesh&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We have been running sqlmesh in production in some way shape or form for a long time now, since the earliest versions of the tool. This post is focused on high level migration approach (which is the reason we were able to adopt quickly and drive innovation) &amp;amp; touches on the learnings and key takeaways too. Major points include simplification, no jinja (sqlglot macros instead creating valid and structurally correct sql syntax vs string interpolation free-for-all), better state management and simplified CICD+dev experience. Has been a rewarding experience and paid off manyfold in the quality, reliability, and maintainability of our data platform. And we are poised to scale extremely effectively. I hope this is useful for any folks looking for information on the topic or are just curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?auto=webp&amp;s=c1fa91492ec85dde2cc551d64a479a15fc202571", "width": 1806, "height": 715}, "resolutions": [{"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=648b4ebdda1e7006e43d2186982a32fb68c70671", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63803909338b1e089837c44c72f384d3ec98a074", "width": 216, "height": 85}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f35c17cd58802bc65fb7cea9175da69e9110c977", "width": 320, "height": 126}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aba361bf8337f9bf8d3cb96af5be4bc6b28fa7d6", "width": 640, "height": 253}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=79ee662e4a48b06a40cc63edd7f3b8dd1049b199", "width": 960, "height": 380}, {"url": "https://external-preview.redd.it/Zm_esMDPFPmV-EQdBSiffvXmg855-aRXDjFsoBvHQCU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=170560a91625a85482e2a13307d4f57bb411da9c", "width": 1080, "height": 427}], "variants": {}, "id": "h1cq6A3022auvjfrixpGE5rrKpYSJm_jmuxfWZCRsn8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b912nc", "is_robot_indexable": true, "report_reasons": null, "author": "Academic_Ad_8747", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b912nc/from_dbt_to_sqlmesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b912nc/from_dbt_to_sqlmesh/", "subreddit_subscribers": 166860, "created_utc": 1709834347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "During my entire career, I have had the job title of data engineer.\n\n\n\n\n\nDuring my current and previous job, I worked on the software engineering side of data engineering.  Lots of work done in Python, Java, Terraform, and various cloud services.  This has definitely been my favorite part of data engineering.\n\n\n\n\nHowever, another company I worked with involved building data pipelines in Airflow and writing lots of SQL.  I even have a friend in data engineering who mentioned that most data pipelines at his company were written in Python, manually run on his laptop ever day, and basically transformed a source excel file into an excel file that can be delivered to downstream users.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think data engineering is too broad of a job title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8sklo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709811571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;During my entire career, I have had the job title of data engineer.&lt;/p&gt;\n\n&lt;p&gt;During my current and previous job, I worked on the software engineering side of data engineering.  Lots of work done in Python, Java, Terraform, and various cloud services.  This has definitely been my favorite part of data engineering.&lt;/p&gt;\n\n&lt;p&gt;However, another company I worked with involved building data pipelines in Airflow and writing lots of SQL.  I even have a friend in data engineering who mentioned that most data pipelines at his company were written in Python, manually run on his laptop ever day, and basically transformed a source excel file into an excel file that can be delivered to downstream users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b8sklo", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b8sklo/do_you_think_data_engineering_is_too_broad_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8sklo/do_you_think_data_engineering_is_too_broad_of_a/", "subreddit_subscribers": 166860, "created_utc": 1709811571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I've found gifs with this style on LinkedIn a couple of times and I wonder which tool was it made on. In some posts they say it's Excalidraw, but I can't find the moving arrows style.\n\nBut let's not make it so specific. Which visual tools do you use to diagram your data architectures/solutions? I almost always use **draw.io**\n\nhttps://i.redd.it/wwy0b4byi0nc1.gif", "author_fullname": "t2_9d3dxxer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture diagram tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wwy0b4byi0nc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 129, "x": 108, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=f6fccae06d86170a03777bd3bcb198fcdaf49de0"}, {"y": 258, "x": 216, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=b1767f3a5e350e5a9c6495c370dad93f0f0fb1a3"}, {"y": 383, "x": 320, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=d8779f649af117c04b557551dac3d92476086e1f"}, {"y": 767, "x": 640, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=bda04f64c43d62dc2b1e442ab699d092a5599527"}, {"y": 1150, "x": 960, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=467ddf6a798a5083023710960b9a99eb719a8f41"}, {"y": 1294, "x": 1080, "u": "https://preview.redd.it/wwy0b4byi0nc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=a803dd832179b89545c952d1b515ab76dca8c946"}], "s": {"y": 1496, "gif": "https://i.redd.it/wwy0b4byi0nc1.gif", "mp4": "https://preview.redd.it/wwy0b4byi0nc1.gif?format=mp4&amp;s=0d9dbbe1552c35488d79d1f4fa73ad49e9306506", "x": 1248}, "id": "wwy0b4byi0nc1"}}, "name": "t3_1b9ba5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A7N4PCE0t_kDJIsOZAwZ9FDPvb9k9U79N-xJ_Q1db1E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709861244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;ve found gifs with this style on LinkedIn a couple of times and I wonder which tool was it made on. In some posts they say it&amp;#39;s Excalidraw, but I can&amp;#39;t find the moving arrows style.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s not make it so specific. Which visual tools do you use to diagram your data architectures/solutions? I almost always use &lt;strong&gt;draw.io&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/wwy0b4byi0nc1.gif\"&gt;https://i.redd.it/wwy0b4byi0nc1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9ba5c", "is_robot_indexable": true, "report_reasons": null, "author": "thehelptea", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9ba5c/data_architecture_diagram_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9ba5c/data_architecture_diagram_tools/", "subreddit_subscribers": 166860, "created_utc": 1709861244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your favorite Python library and why?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite Python library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8vfdv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709820220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your favorite Python library and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b8vfdv", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8vfdv/favorite_python_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8vfdv/favorite_python_library/", "subreddit_subscribers": 166860, "created_utc": 1709820220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am aware the answer will depend on many cases of what is the stack of the company, budget and familiarity but If you are working with one of these daily imagine you are selling/pitching each of these DW solutions here!", "author_fullname": "t2_42yrzhea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks SQL, Amazon Redshift, GBQ or Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8zeek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709830411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am aware the answer will depend on many cases of what is the stack of the company, budget and familiarity but If you are working with one of these daily imagine you are selling/pitching each of these DW solutions here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b8zeek", "is_robot_indexable": true, "report_reasons": null, "author": "josejo9423", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8zeek/databricks_sql_amazon_redshift_gbq_or_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8zeek/databricks_sql_amazon_redshift_gbq_or_snowflake/", "subreddit_subscribers": 166860, "created_utc": 1709830411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi guys, I am in a bit of a pickle at work. I will tell you my story and I would appreciate  if you could help me with identifying, if their reasons are plausible.\n\nSo I am a data analyst in an retail company (lets call it company J) with low data maturity. \n\nThe company has server on-premise which is handled by our IT, there is also a \"processing\" server which is handled by ERP wannabe, but actually accounting software company (lets call it company A).\n\nThe issue is, before the company hired me, they depended on the company A to build reports in their software, but it takes them forever and/or don't do it because the load will be too big on the servers.\n\nNow, I have to export excel files from company A's software and I am very limited in the amount of data. The software allows me to download sales of 3 months at a time. \n\nSo I talked to company J's head of IT, he said - hey ask company A to give you access to their processing RDB server, let them give you \"read-only\" permission, should be all good.\n\nI called company A they tell me - we will give you the access, but we won't be responsible for ANYTHING that happens to the servers. Even if we give you read-only, there is still a threat of SQL injections (they said something can be done with sql that still could be a threat). Another option is you set up a server for analytics and we will transfer the data you require.\n\nI mentioned this to head of IT at company J, he was pissed, he said - they are full of sh#$t. If we add extra VM to our cluster, the load will be too big and will crash possibly. There are no such issues that company A said in modern day...\n\n&amp;#x200B;\n\nIs the SQL injection threat really a bs? Is the advice of me getting a read-only permission to a processing server a bad advice?", "author_fullname": "t2_98kyulf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8uryg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709818463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi guys, I am in a bit of a pickle at work. I will tell you my story and I would appreciate  if you could help me with identifying, if their reasons are plausible.&lt;/p&gt;\n\n&lt;p&gt;So I am a data analyst in an retail company (lets call it company J) with low data maturity. &lt;/p&gt;\n\n&lt;p&gt;The company has server on-premise which is handled by our IT, there is also a &amp;quot;processing&amp;quot; server which is handled by ERP wannabe, but actually accounting software company (lets call it company A).&lt;/p&gt;\n\n&lt;p&gt;The issue is, before the company hired me, they depended on the company A to build reports in their software, but it takes them forever and/or don&amp;#39;t do it because the load will be too big on the servers.&lt;/p&gt;\n\n&lt;p&gt;Now, I have to export excel files from company A&amp;#39;s software and I am very limited in the amount of data. The software allows me to download sales of 3 months at a time. &lt;/p&gt;\n\n&lt;p&gt;So I talked to company J&amp;#39;s head of IT, he said - hey ask company A to give you access to their processing RDB server, let them give you &amp;quot;read-only&amp;quot; permission, should be all good.&lt;/p&gt;\n\n&lt;p&gt;I called company A they tell me - we will give you the access, but we won&amp;#39;t be responsible for ANYTHING that happens to the servers. Even if we give you read-only, there is still a threat of SQL injections (they said something can be done with sql that still could be a threat). Another option is you set up a server for analytics and we will transfer the data you require.&lt;/p&gt;\n\n&lt;p&gt;I mentioned this to head of IT at company J, he was pissed, he said - they are full of sh#$t. If we add extra VM to our cluster, the load will be too big and will crash possibly. There are no such issues that company A said in modern day...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is the SQL injection threat really a bs? Is the advice of me getting a read-only permission to a processing server a bad advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8uryg", "is_robot_indexable": true, "report_reasons": null, "author": "Corvou", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8uryg/need_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8uryg/need_recommendation/", "subreddit_subscribers": 166860, "created_utc": 1709818463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I just recently started working as a consultant, I'm being offered to work in a project with databricks. My main question is how valuable can be the experience I could get from that project in the look for developing my career? I've seen there's a a lot of mix reviews on databricks, so I would like to hear your opinions and experiences.\nThanks in advance :)", "author_fullname": "t2_q9k8q4cy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks value ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9b9oa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709861205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I just recently started working as a consultant, I&amp;#39;m being offered to work in a project with databricks. My main question is how valuable can be the experience I could get from that project in the look for developing my career? I&amp;#39;ve seen there&amp;#39;s a a lot of mix reviews on databricks, so I would like to hear your opinions and experiences.\nThanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9b9oa", "is_robot_indexable": true, "report_reasons": null, "author": "Cid-Cthulhu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9b9oa/databricks_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9b9oa/databricks_value/", "subreddit_subscribers": 166860, "created_utc": 1709861205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI just recently joined a big pharma company to do some data engineering tasks (I'm basically more on the data science side, but have some experiences in building data pipelines).\n\nIn my previous company (a typical tech startup), building a data pipeline is relatively straightforward, most data sources either have data connectors or APIs so you can easily access the data and ingest them into the data lake/data warehouse, and you can use a lot of open-source tools for data transformation.\n\nHowever, this time, I work with a lot of data generated from lab instruments, which typically need to be processed with specific software (typically the software made by the instruments' vendors). These software are either desktop app, and/or do not have any programmatic way (API or CLI) to access them. The raw data format is also often non standard text format (i.e. propriatary binary data format and there were no data parser available for most of them). Moreover, data processing is also not straightforward as often times it requires specific expertise in interpreting the meaningful information out of raw data, for example manual labeling and data selection from lab scientists.\n\nHas anyone had any experience in building a data pipeline in this kinda settings? I wonder if I can pick up some successful strategies you guys have implemented previously.\n\nThank you.", "author_fullname": "t2_as9pcaig", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering in a biopharma/biotech company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8z73y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709829933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I just recently joined a big pharma company to do some data engineering tasks (I&amp;#39;m basically more on the data science side, but have some experiences in building data pipelines).&lt;/p&gt;\n\n&lt;p&gt;In my previous company (a typical tech startup), building a data pipeline is relatively straightforward, most data sources either have data connectors or APIs so you can easily access the data and ingest them into the data lake/data warehouse, and you can use a lot of open-source tools for data transformation.&lt;/p&gt;\n\n&lt;p&gt;However, this time, I work with a lot of data generated from lab instruments, which typically need to be processed with specific software (typically the software made by the instruments&amp;#39; vendors). These software are either desktop app, and/or do not have any programmatic way (API or CLI) to access them. The raw data format is also often non standard text format (i.e. propriatary binary data format and there were no data parser available for most of them). Moreover, data processing is also not straightforward as often times it requires specific expertise in interpreting the meaningful information out of raw data, for example manual labeling and data selection from lab scientists.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had any experience in building a data pipeline in this kinda settings? I wonder if I can pick up some successful strategies you guys have implemented previously.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8z73y", "is_robot_indexable": true, "report_reasons": null, "author": "mardian-octopus", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8z73y/data_engineering_in_a_biopharmabiotech_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8z73y/data_engineering_in_a_biopharmabiotech_company/", "subreddit_subscribers": 166860, "created_utc": 1709829933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm working on streamlining our data engineering processes using AWS Glue, and I'd love to learn from others' experiences regarding:\n\n* **Terraform for Glue:** Do you use Terraform to manage and provision your AWS Glue jobs and related infrastructure? If so, would you be willing to share some insights into your setup and any helpful tips?\n* **CI/CD for Glue scripts:** How do you integrate CI/CD (e.g., GitLab CI/CD) to synchronize Python scripts with S3 buckets? Do you employ a monorepo strategy, or do you have a preferred alternative? What triggers your CI/CD pipelines (file changes, scheduled updates, etc.)?\n\nI'd greatly appreciate any details on your best practices and any challenges you've overcome.\n\nThank you in advance for sharing your expertise!", "author_fullname": "t2_d9r3cjd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for Terraform, AWS Glue, and CI/CD in data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8ytdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709828724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on streamlining our data engineering processes using AWS Glue, and I&amp;#39;d love to learn from others&amp;#39; experiences regarding:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Terraform for Glue:&lt;/strong&gt; Do you use Terraform to manage and provision your AWS Glue jobs and related infrastructure? If so, would you be willing to share some insights into your setup and any helpful tips?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CI/CD for Glue scripts:&lt;/strong&gt; How do you integrate CI/CD (e.g., GitLab CI/CD) to synchronize Python scripts with S3 buckets? Do you employ a monorepo strategy, or do you have a preferred alternative? What triggers your CI/CD pipelines (file changes, scheduled updates, etc.)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d greatly appreciate any details on your best practices and any challenges you&amp;#39;ve overcome.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for sharing your expertise!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8ytdj", "is_robot_indexable": true, "report_reasons": null, "author": "Warsoco", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8ytdj/best_practices_for_terraform_aws_glue_and_cicd_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8ytdj/best_practices_for_terraform_aws_glue_and_cicd_in/", "subreddit_subscribers": 166860, "created_utc": 1709828724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Leveraging Schipol Dev API, I've built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard [here](https://aeroatlas.streamlit.app/). I'd love your feedback, suggestions, and opinions to enhance this data-driven journey!", "author_fullname": "t2_rw01dudv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just launched my first data engineering project!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9hnn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709880414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Leveraging Schipol Dev API, I&amp;#39;ve built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard &lt;a href=\"https://aeroatlas.streamlit.app/\"&gt;here&lt;/a&gt;. I&amp;#39;d love your feedback, suggestions, and opinions to enhance this data-driven journey!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?auto=webp&amp;s=9865438c46b36f6ceceae2a4f691e77823f49706", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f2a7fdcf1696abd365a02221e38e0fec9fbccf0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c78b890a0a78713482641dfc23ab4bb06accfbb0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ead203f9bd786ae0ce939c56d4de097a9b7bbb9a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c17981a8c5361bba27539e884ea4406a31af7e9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=987bef2e4dbcf6165f0aafad164259f6f3b31560", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Ec4cXXHvPH9sI7OkgKV88CdSKaGINkXxd_IXgo-pT6o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9eb15378a2902c32993c4d17ff71148add906e4", "width": 1080, "height": 567}], "variants": {}, "id": "5noDdCvNFXIpfSURWR11QJ056eivlSF0Fxt4b3n6Wyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b9hnn0", "is_robot_indexable": true, "report_reasons": null, "author": "botuleman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/", "subreddit_subscribers": 166860, "created_utc": 1709880414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nI have a basic question today, so please bear with me. I've been working with Azure Databricks for just a few months.\n\nMy question is about storage options. Initially, I was under the impression that using ADLS and storing files extracted from SAP S/4HANA in the raw layer as Parquet was the optimal approach. I believed that Parquet was the most suitable format for this purpose. However, I've recently learned that aside from ADLS, it's also possible to store data in Cassandra. This discovery has led me to wonder: if Cassandra is capable of storing highly structured data from SAP, might it be a better choice?\n\nAm I oversimplifying the issue by not fully considering factors like the cost differences between saving data in Parquet versus storing it in Cassandra, or potential use cases like analytic reporting versus write preference?\n\nI would greatly appreciate your perspective on how to make this decision.\n\nThanks.", "author_fullname": "t2_5b8k9nl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cassandra or Praquet for structured data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9bnak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709862251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;I have a basic question today, so please bear with me. I&amp;#39;ve been working with Azure Databricks for just a few months.&lt;/p&gt;\n\n&lt;p&gt;My question is about storage options. Initially, I was under the impression that using ADLS and storing files extracted from SAP S/4HANA in the raw layer as Parquet was the optimal approach. I believed that Parquet was the most suitable format for this purpose. However, I&amp;#39;ve recently learned that aside from ADLS, it&amp;#39;s also possible to store data in Cassandra. This discovery has led me to wonder: if Cassandra is capable of storing highly structured data from SAP, might it be a better choice?&lt;/p&gt;\n\n&lt;p&gt;Am I oversimplifying the issue by not fully considering factors like the cost differences between saving data in Parquet versus storing it in Cassandra, or potential use cases like analytic reporting versus write preference?&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your perspective on how to make this decision.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9bnak", "is_robot_indexable": true, "report_reasons": null, "author": "scht1980", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9bnak/cassandra_or_praquet_for_structured_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9bnak/cassandra_or_praquet_for_structured_data/", "subreddit_subscribers": 166860, "created_utc": 1709862251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I won't give much context here as I work with classified data, I'm a software engineer(not a data engineer).\n\nWhat are some viable options for me to move big data from MS SQL SERVER to PostgreSQL for a daily batch process. The data is large enough for LINKED SERVER to be bottleneck while transferring to PostgreSQL.\n\nI thought of Apache SPARK, if so can you give me the drawbacks.  \n\n\nThank You!", "author_fullname": "t2_121fx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on ELT: MS SQL SERVER to PostgreSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9alt0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709859429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I won&amp;#39;t give much context here as I work with classified data, I&amp;#39;m a software engineer(not a data engineer).&lt;/p&gt;\n\n&lt;p&gt;What are some viable options for me to move big data from MS SQL SERVER to PostgreSQL for a daily batch process. The data is large enough for LINKED SERVER to be bottleneck while transferring to PostgreSQL.&lt;/p&gt;\n\n&lt;p&gt;I thought of Apache SPARK, if so can you give me the drawbacks.  &lt;/p&gt;\n\n&lt;p&gt;Thank You!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b9alt0", "is_robot_indexable": true, "report_reasons": null, "author": "Vanvil", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9alt0/need_advice_on_elt_ms_sql_server_to_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9alt0/need_advice_on_elt_ms_sql_server_to_postgresql/", "subreddit_subscribers": 166860, "created_utc": 1709859429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am referring to all those that involve any kind of subscription or pay-per-use formula. \nAny suggestions?\n", "author_fullname": "t2_c0ghewdh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can one practice (alone and for free) with DE tools or frameworks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8vzri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709821711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am referring to all those that involve any kind of subscription or pay-per-use formula. \nAny suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b8vzri", "is_robot_indexable": true, "report_reasons": null, "author": "hasty-beaver", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8vzri/how_can_one_practice_alone_and_for_free_with_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8vzri/how_can_one_practice_alone_and_for_free_with_de/", "subreddit_subscribers": 166860, "created_utc": 1709821711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tic4e2n8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "skyffel - prototype for generating Airbyte connectors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8sa5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/fid5h8vbcwmc1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/fid5h8vbcwmc1/DASH_96.mp4", "dash_url": "https://v.redd.it/fid5h8vbcwmc1/DASHPlaylist.mpd?a=1712489917%2CYjgzM2RhOTdkMGQ1Y2ExYzAwOTRmYzk2YzdmZTRjYjgxYjIwOWM5MzQ3Mzg0N2MzYWYxM2I3OWUyYTM0NmUwOQ%3D%3D&amp;v=1&amp;f=sd", "duration": 68, "hls_url": "https://v.redd.it/fid5h8vbcwmc1/HLSPlaylist.m3u8?a=1712489917%2COThmODRlNzUzMDhlYzM5MDhkMTI0MGE2NWJiY2NiZjFiYmMyMTJhYjhkZmY1Nzg2ZGU2MzQ4NDY3OWQ1ZWVjMA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=69c8ad1e8005278fc478bc96d1c2dd86e1ec4b6b", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709810527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/fid5h8vbcwmc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?format=pjpg&amp;auto=webp&amp;s=bab28949e5b068965d151994a8761d86d66097b9", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c47917f58c93a55a9c4ea12f0a743a635efa32e4", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d85a584722ed6f74929a6414a658560d0b1224b2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=cfe03e1c741241f2cc0add1fcceecd8943952395", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=cdf37a22f884d4e3eda5aad5902d6c49b9d8847a", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3e696d29a55e43a87f058eed825187e85a0cba30", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=295798a8425e5d0a140b6b0cc983d552b380014d", "width": 1080, "height": 607}], "variants": {}, "id": "cmpibjVpOGhjd21jMUu5fCuKDtETGVP5ZNKU-dnwXMdLVPeX8q51aUrQY0ti"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b8sa5g", "is_robot_indexable": true, "report_reasons": null, "author": "phiandersson", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b8sa5g/skyffel_prototype_for_generating_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/fid5h8vbcwmc1", "subreddit_subscribers": 166860, "created_utc": 1709810527.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/fid5h8vbcwmc1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/fid5h8vbcwmc1/DASH_96.mp4", "dash_url": "https://v.redd.it/fid5h8vbcwmc1/DASHPlaylist.mpd?a=1712489917%2CYjgzM2RhOTdkMGQ1Y2ExYzAwOTRmYzk2YzdmZTRjYjgxYjIwOWM5MzQ3Mzg0N2MzYWYxM2I3OWUyYTM0NmUwOQ%3D%3D&amp;v=1&amp;f=sd", "duration": 68, "hls_url": "https://v.redd.it/fid5h8vbcwmc1/HLSPlaylist.m3u8?a=1712489917%2COThmODRlNzUzMDhlYzM5MDhkMTI0MGE2NWJiY2NiZjFiYmMyMTJhYjhkZmY1Nzg2ZGU2MzQ4NDY3OWQ1ZWVjMA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a dataset that consists of thousands of JSONL files (one JSON object per line). About 800GB in total, and 288 files of 15-50MB are added each day. Each file contains JSON objects with different schemas. Example:\n\n&amp;#x200B;\n\n[Each 'LogAnalyticsCategory' has a different schema \\(not visible in the picture, but you get the point\\)](https://preview.redd.it/t6hmtz0i6ymc1.png?width=1332&amp;format=png&amp;auto=webp&amp;s=84105e3453bfaed8019ec8f9dadebbeccc8d8d5c)\n\nEventually each category needs to go into a different destination table (sink = Postgres), but I'm unsure how to do this efficiently. I can do it easily with BigQuery, but given the volume of the data that will become too expensive, especially as the data will be queried for analytical purposes.  \n\nMy toolkit for now is basically limited to Python on a single machine. My source files are stored on GCS. Looping over the rows to figure out the schema of each line will probably be horribly slow. How do I best approach this (in the most simple way)?", "author_fullname": "t2_4p5ynpa6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you ETL JSONL data with different schemas in the same file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": false, "media_metadata": {"t6hmtz0i6ymc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 44, "x": 108, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bfb81a3f40b4871ec6539b5c65df606bf4052cdd"}, {"y": 88, "x": 216, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe10d6782a7f08950470479c306976590172909d"}, {"y": 131, "x": 320, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7cb49d064ac5f7c4ec92e7ec3052b9a80ffddb4"}, {"y": 263, "x": 640, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e714ed9513425640331c17b19b16beff59a751bb"}, {"y": 394, "x": 960, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d034d6302c4c81fccd13961b6130bd8ee405113"}, {"y": 444, "x": 1080, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=674b770c4a6d1ef59a9cd46f0206bbd0e2bc85dd"}], "s": {"y": 548, "x": 1332, "u": "https://preview.redd.it/t6hmtz0i6ymc1.png?width=1332&amp;format=png&amp;auto=webp&amp;s=84105e3453bfaed8019ec8f9dadebbeccc8d8d5c"}, "id": "t6hmtz0i6ymc1"}}, "name": "t3_1b90nap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6s1jmiqjCe2hjpbsHFMJ1_qC9jdrglSQWSlGfaTTCpo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709833339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset that consists of thousands of JSONL files (one JSON object per line). About 800GB in total, and 288 files of 15-50MB are added each day. Each file contains JSON objects with different schemas. Example:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/t6hmtz0i6ymc1.png?width=1332&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84105e3453bfaed8019ec8f9dadebbeccc8d8d5c\"&gt;Each &amp;#39;LogAnalyticsCategory&amp;#39; has a different schema (not visible in the picture, but you get the point)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Eventually each category needs to go into a different destination table (sink = Postgres), but I&amp;#39;m unsure how to do this efficiently. I can do it easily with BigQuery, but given the volume of the data that will become too expensive, especially as the data will be queried for analytical purposes.  &lt;/p&gt;\n\n&lt;p&gt;My toolkit for now is basically limited to Python on a single machine. My source files are stored on GCS. Looping over the rows to figure out the schema of each line will probably be horribly slow. How do I best approach this (in the most simple way)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b90nap", "is_robot_indexable": true, "report_reasons": null, "author": "unplannedmaintenance", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b90nap/how_would_you_etl_jsonl_data_with_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b90nap/how_would_you_etl_jsonl_data_with_different/", "subreddit_subscribers": 166860, "created_utc": 1709833339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnosdzg5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leaving LinkedIn: Choosing Engineering Excellence Over Expediency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9kdvm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u2WIp0qVmte5zZpGDuvaxFPzvWfGHew0tlvX2d2bjJs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709891143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "corecursive.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://corecursive.com/leaving-linkedin-with-chris-krycho/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?auto=webp&amp;s=f2bf0cbe65da496b817ac521d7b445ce3a640c52", "width": 3000, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6ba4534e076b2a552d554914e7f2f1ab47cdbd2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=68168466948db838f259ac962f62e32249f13341", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b60a3029a4e936d726404e90a07e0c3d6c5935f8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=992e33224246ec291bc5c5c9f0abc3bea7bd4dd4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=244679e83e78b02b413ddf087c4210a09b77ff09", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4_h_dBgqIRHPd4nWdokXqnEJUaAEQ4FqlW_qVnNtxGc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b431f38ed2a74205726ec83df7acf37b049b4f47", "width": 1080, "height": 540}], "variants": {}, "id": "rUXfOjVKsNPs5APIrbXZ7tIgl9QCoEGUScE1VM2-GKo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b9kdvm", "is_robot_indexable": true, "report_reasons": null, "author": "ellnorrisjerry", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9kdvm/leaving_linkedin_choosing_engineering_excellence/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://corecursive.com/leaving-linkedin-with-chris-krycho/", "subreddit_subscribers": 166860, "created_utc": 1709891143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79\n\nI created a multi-armed bandit simulator as a personal project: https://github.com/FlynnOwen/multi-armed-bandits/tree/main  \nI work as a data engineer/scientist but don't often get to play around with new software, and sometimes work on projects outside of work hours to stay fresh and learn more about the space. I thought members of this sub may appreciate this piece of software I worked on.  \nStay cool data devs 8)", "author_fullname": "t2_fwzjyaet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-Armed Bandit Simulator [https://github.com/FlynnOwen/multi-armed-bandits/tree/main]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 108, "top_awarded_type": null, "hide_score": false, "media_metadata": {"b4zv93asb2nc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f49804f658fdf6b17cfe29d64cb3551d73598b71"}, {"y": 167, "x": 216, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5cfbd2dfda59f3f315759a8f9e1749c00bcf4b92"}, {"y": 248, "x": 320, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3aa4d7f0eafe502fb03f3b1b23b2c2a43c660cea"}, {"y": 496, "x": 640, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d968cf106f25faf646db4ac262c8577bcc9547d0"}, {"y": 744, "x": 960, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b80f460d70a8cc360d1e75b4ccee89964f8d6264"}, {"y": 837, "x": 1080, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d49b1ed4d1a370bac5d6647ec1c3a47905d6b2ea"}], "s": {"y": 1248, "x": 1610, "u": "https://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79"}, "id": "b4zv93asb2nc1"}}, "name": "t3_1b9ic2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4rngoA4erfW4rlEKT2OUcHVvsWshK3SYMHOhq5Hmlqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709882935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79\"&gt;https://preview.redd.it/b4zv93asb2nc1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=20b4e39ec6d2c9fa3ac4d43b64660ef6fc443d79&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I created a multi-armed bandit simulator as a personal project: &lt;a href=\"https://github.com/FlynnOwen/multi-armed-bandits/tree/main\"&gt;https://github.com/FlynnOwen/multi-armed-bandits/tree/main&lt;/a&gt;&lt;br/&gt;\nI work as a data engineer/scientist but don&amp;#39;t often get to play around with new software, and sometimes work on projects outside of work hours to stay fresh and learn more about the space. I thought members of this sub may appreciate this piece of software I worked on.&lt;br/&gt;\nStay cool data devs 8)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b9ic2j", "is_robot_indexable": true, "report_reasons": null, "author": "engineering-scienct", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9ic2j/multiarmed_bandit_simulator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9ic2j/multiarmed_bandit_simulator/", "subreddit_subscribers": 166860, "created_utc": 1709882935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR:\n\nFeels left out of the handover process after team lead resigned. Concerned about career growth &amp; potential reassignment of tasks to less technically skilled coworker. Time to look for a new role or tough it out while trying to get buy-in from management?    \n.  \n.  \n.  \n\n---\nHi all, relatively pretty green &amp; junior here (esp. with regards to navigating the human side of things in a corporate setting). Looking for advice/perspective from the more experienced DE folks here. \n\nMy team lead has decided to resign recently &amp; we're about to start the handover process. I've been fortunate to be working with him as he's been a great manager who can advocate for me to management &amp; thus far I'd like to say that I've sufficiently contributed to the data team. AFAIK I've been doing just fine since nobody has raised any issues regarding my performance.\n\nBut I just caught wind that I was not meant to be involved in the handover meeting. My team lead, bless his heart, does want to involve me so he will invite me in but it's strange to originally leave me out as the rest of data team are required to be in attendance. \n\nSome of the newer, currently in development reporting/dashboard stack that's definitely right up my alley is even to be assigned to a coworker who's not as technical as me. I don't mean that as a demeaning remark as said coworker does an amazing data admin-related job (which is his main role in the data team), but in a more DA/DE capacity, has to frequently ask me for ad-hoc, quite simple queries. Just doesn't make sense to me.\n\nIt seems like for now there's a still a chance to convince management that I have something to offer from a more technical standpoint to the data team through the handover meeting but the whole thing just leaves a sour note on my end. Is it time to start looking for a new role just in case management remains unconvinced?", "author_fullname": "t2_lp3x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with Management's Lack of Awareness (and Potential Underappreciation of Technical Contributions)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9b188", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709863615.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709860561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR:&lt;/p&gt;\n\n&lt;p&gt;Feels left out of the handover process after team lead resigned. Concerned about career growth &amp;amp; potential reassignment of tasks to less technically skilled coworker. Time to look for a new role or tough it out while trying to get buy-in from management?&lt;br/&gt;\n.&lt;br/&gt;\n.&lt;br/&gt;\n.  &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Hi all, relatively pretty green &amp;amp; junior here (esp. with regards to navigating the human side of things in a corporate setting). Looking for advice/perspective from the more experienced DE folks here. &lt;/p&gt;\n\n&lt;p&gt;My team lead has decided to resign recently &amp;amp; we&amp;#39;re about to start the handover process. I&amp;#39;ve been fortunate to be working with him as he&amp;#39;s been a great manager who can advocate for me to management &amp;amp; thus far I&amp;#39;d like to say that I&amp;#39;ve sufficiently contributed to the data team. AFAIK I&amp;#39;ve been doing just fine since nobody has raised any issues regarding my performance.&lt;/p&gt;\n\n&lt;p&gt;But I just caught wind that I was not meant to be involved in the handover meeting. My team lead, bless his heart, does want to involve me so he will invite me in but it&amp;#39;s strange to originally leave me out as the rest of data team are required to be in attendance. &lt;/p&gt;\n\n&lt;p&gt;Some of the newer, currently in development reporting/dashboard stack that&amp;#39;s definitely right up my alley is even to be assigned to a coworker who&amp;#39;s not as technical as me. I don&amp;#39;t mean that as a demeaning remark as said coworker does an amazing data admin-related job (which is his main role in the data team), but in a more DA/DE capacity, has to frequently ask me for ad-hoc, quite simple queries. Just doesn&amp;#39;t make sense to me.&lt;/p&gt;\n\n&lt;p&gt;It seems like for now there&amp;#39;s a still a chance to convince management that I have something to offer from a more technical standpoint to the data team through the handover meeting but the whole thing just leaves a sour note on my end. Is it time to start looking for a new role just in case management remains unconvinced?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9b188", "is_robot_indexable": true, "report_reasons": null, "author": "YsrYsl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9b188/dealing_with_managements_lack_of_awareness_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b9b188/dealing_with_managements_lack_of_awareness_and/", "subreddit_subscribers": 166860, "created_utc": 1709860561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've just got the Databricks Data Engineering Associate certification and I'm thinking about keep studying for the Databricks Data Engineering Professional certification.\n\nI've been using Databricks at work and I think it's a powerful tool. What's your advice? \n\nTo go for the professional certification or to learn another stack like snowflake, DBT or another one?", "author_fullname": "t2_ea5033yq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks certifications advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b98jy5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709853304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just got the Databricks Data Engineering Associate certification and I&amp;#39;m thinking about keep studying for the Databricks Data Engineering Professional certification.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using Databricks at work and I think it&amp;#39;s a powerful tool. What&amp;#39;s your advice? &lt;/p&gt;\n\n&lt;p&gt;To go for the professional certification or to learn another stack like snowflake, DBT or another one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b98jy5", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Durian7029", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b98jy5/databricks_certifications_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b98jy5/databricks_certifications_advice/", "subreddit_subscribers": 166860, "created_utc": 1709853304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nSo I recently got more into the Microsoft stack and before that I had a \"best practice outlook\" on  setting up small/medium sized DWHs:\n- onprem/cheap cloud DB\n- EL: custom / Free tools like airbyte, pentaho.. \n- T: dbt\n\nOn my new job we only use azure for everything. Namely azure functions/data flows for ELT and a datalake blobstorage as a DWH.\nThe datalake sources powerbi, which is possible since onelake?  I am pretty new on the onelake/fabric stuff and asking myself if this is \"best practice\" for small/medium sized DWHs?\n\nI actually like nothing about this stack but that might be due to me not knowing/understanding it's capabilities?", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Onelake as DWH replacement ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b91k2e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709835479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;So I recently got more into the Microsoft stack and before that I had a &amp;quot;best practice outlook&amp;quot; on  setting up small/medium sized DWHs:\n- onprem/cheap cloud DB\n- EL: custom / Free tools like airbyte, pentaho.. \n- T: dbt&lt;/p&gt;\n\n&lt;p&gt;On my new job we only use azure for everything. Namely azure functions/data flows for ELT and a datalake blobstorage as a DWH.\nThe datalake sources powerbi, which is possible since onelake?  I am pretty new on the onelake/fabric stuff and asking myself if this is &amp;quot;best practice&amp;quot; for small/medium sized DWHs?&lt;/p&gt;\n\n&lt;p&gt;I actually like nothing about this stack but that might be due to me not knowing/understanding it&amp;#39;s capabilities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b91k2e", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b91k2e/onelake_as_dwh_replacement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b91k2e/onelake_as_dwh_replacement/", "subreddit_subscribers": 166860, "created_utc": 1709835479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tools like dbt are becoming a popular alternative to the legacy and platform tools like IBM DataStage or Azure Data Factory. Here is a quick comparison of five leading contenders to own the transformation stage in your data platform. (I leave off the dbt clones as largely derivative)  \n\n\n||[Coalesce](https://coalesce.io)|[Coginiti](https://www.coginiti.co)|dbt Cloud|[Prophecy](https://www.prophecy.io)|[SQLMesh](https://sqlmesh.com)|\n|:-|:-|:-|:-|:-|:-|\n|Transform|LowCode|AaC|AaC|LowCode|AaC|\n|Versioning|\u2705|\u2705|\u2705|\u2705|\u2705|\n|Scheduling|\u2705|\u2705|\u2705|\u2705|\u2705|\n|SQL|\u2705|\u2705|\u2705|\u2705|\u2705|\n|Python|\u274c|\u274c|\u2705|\u274c|\u2705|\n|DQ Tests|\u2705|\u2705|\u2705|\u274c|\u2705|\n|Obj Store|\u274c|\u2705|\u274c|\u274c|\u274c|\n|AI Assistant|\u274c|\u2705|\u274c|\u2705|\u274c|\n|Orchestration API|\u2705|\u2705|\u2705|\u2705|\u274c|\n|Data API|\u274c|\u2705|\u274c|\u274c|\u274c|\n|Lineage|\u2705|\u2705|\u2705|\u2705|\u2705|\n|Ad-Hoc Query|\u274c|\u2705|\u274c|\u274c|\u274c|\n|Supported Platforms|Snowflake|Netezza, DB2 Warehouse, Databricks, Redshift, Athena, BigQuery, Yellowbrick, Starburst/Trino, Synapse, SQL Server, Postgres, Snowflake, Spark, Hive, Greenplum|Redshift, BigQuery, AlloyDB, Databricks, MSFT Fabric, Starburst/Trino, Postgres, Snowflake, Spark|Databricks|BigQuery, Databricks, DuckDB, MySQL, PostgreSQL, Redshift, Snowflake, Spark|\n\n&amp;#x200B;", "author_fullname": "t2_ez8d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Transformation Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b8xm1f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709825736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tools like dbt are becoming a popular alternative to the legacy and platform tools like IBM DataStage or Azure Data Factory. Here is a quick comparison of five leading contenders to own the transformation stage in your data platform. (I leave off the dbt clones as largely derivative)  &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://coalesce.io\"&gt;Coalesce&lt;/a&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://www.coginiti.co\"&gt;Coginiti&lt;/a&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;dbt Cloud&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://www.prophecy.io\"&gt;Prophecy&lt;/a&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;a href=\"https://sqlmesh.com\"&gt;SQLMesh&lt;/a&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Transform&lt;/td&gt;\n&lt;td align=\"left\"&gt;LowCode&lt;/td&gt;\n&lt;td align=\"left\"&gt;AaC&lt;/td&gt;\n&lt;td align=\"left\"&gt;AaC&lt;/td&gt;\n&lt;td align=\"left\"&gt;LowCode&lt;/td&gt;\n&lt;td align=\"left\"&gt;AaC&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Versioning&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Scheduling&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;SQL&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Python&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;DQ Tests&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Obj Store&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AI Assistant&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Orchestration API&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Data API&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Lineage&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Ad-Hoc Query&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2705&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u274c&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Supported Platforms&lt;/td&gt;\n&lt;td align=\"left\"&gt;Snowflake&lt;/td&gt;\n&lt;td align=\"left\"&gt;Netezza, DB2 Warehouse, Databricks, Redshift, Athena, BigQuery, Yellowbrick, Starburst/Trino, Synapse, SQL Server, Postgres, Snowflake, Spark, Hive, Greenplum&lt;/td&gt;\n&lt;td align=\"left\"&gt;Redshift, BigQuery, AlloyDB, Databricks, MSFT Fabric, Starburst/Trino, Postgres, Snowflake, Spark&lt;/td&gt;\n&lt;td align=\"left\"&gt;Databricks&lt;/td&gt;\n&lt;td align=\"left\"&gt;BigQuery, Databricks, DuckDB, MySQL, PostgreSQL, Redshift, Snowflake, Spark&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b8xm1f", "is_robot_indexable": true, "report_reasons": null, "author": "Bazencourt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b8xm1f/data_transformation_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b8xm1f/data_transformation_comparison/", "subreddit_subscribers": 166860, "created_utc": 1709825736.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3mqfnwzt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualizing Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_1b9l12d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BA1RzfkasDVJOr4XjBj44VYAyrG9Nk77D42-oqfLuYM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709893777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "x.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://x.com/Sofiane91310826/status/1766042500597223625?t=lJo0SL_PSmAGwfeG0pFATA&amp;s=34", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H5OQnYVbafrRL3gAAAEngq1GaPkWTEyQz1sRN2In3qM.jpg?auto=webp&amp;s=7fde216d3d3a957e6489917e26922ef849c88ceb", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/H5OQnYVbafrRL3gAAAEngq1GaPkWTEyQz1sRN2In3qM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=733d995aae68da42b224ae1106265775d714ade5", "width": 108, "height": 108}], "variants": {}, "id": "LtYG6K1XHswNuA6Ij8KHwiWODxqIEBaMJenBELCnyzA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b9l12d", "is_robot_indexable": true, "report_reasons": null, "author": "Scommel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9l12d/visualizing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://x.com/Sofiane91310826/status/1766042500597223625?t=lJo0SL_PSmAGwfeG0pFATA&amp;s=34", "subreddit_subscribers": 166860, "created_utc": 1709893777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productizing data services: Removing fears with the LEAP framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1b9jo2d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4_KghhkXNwF2MIVMXdjqEUFrvMGkB0MN-MCA3SHlJQ4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709888125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/productizing-data-services-removing-fears-with-the-leap-framework/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?auto=webp&amp;s=22d019227459e8dd7ec6d7a1301a5e1950f97720", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=39d71177e71f497f070771f54b052c7461e2750b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=321ddb2bf8d4648c8c5c48707ec103d0a4f55ca5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19a4e2baad28afcd3a08c53ea65e3ffc6a543855", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f05bd0cb86c47d0b4102f59fdf74ce84228b3cb8", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f984af9a0053478168a803638ccff44f27b7bf9c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/QjupfQk_2KaMyanQW-ao3y1RNHsw-3F7zdzcr_s7QG4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d76b6c44c877e3ff283b61bf924d27d6d6c4fdfc", "width": 1080, "height": 607}], "variants": {}, "id": "FvmfvAiv20GoQlJeug9X3S4maUuzOWIK6kXMvqVo8GY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b9jo2d", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b9jo2d/productizing_data_services_removing_fears_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/productizing-data-services-removing-fears-with-the-leap-framework/", "subreddit_subscribers": 166860, "created_utc": 1709888125.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}