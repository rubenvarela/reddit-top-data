{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My background ~11 years of expert level ETL/Datawarehousing exp with Informatica Powercenter, Informatica Cloud, Matillion (1Year)\n\nSome basic snowflake, basic AWS, training level exposure to python (I remember defining functions - could not recollect syntax of objects, methods in objects etc. no realtime project exp with python) I have been trying to learn Pandas and Pyspark over the last few days. ", "author_fullname": "t2_6cuqg1k5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I learn to call myself a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbe7ab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710087716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My background ~11 years of expert level ETL/Datawarehousing exp with Informatica Powercenter, Informatica Cloud, Matillion (1Year)&lt;/p&gt;\n\n&lt;p&gt;Some basic snowflake, basic AWS, training level exposure to python (I remember defining functions - could not recollect syntax of objects, methods in objects etc. no realtime project exp with python) I have been trying to learn Pandas and Pyspark over the last few days. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bbe7ab", "is_robot_indexable": true, "report_reasons": null, "author": "sneekeeei", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbe7ab/what_should_i_learn_to_call_myself_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbe7ab/what_should_i_learn_to_call_myself_a_data_engineer/", "subreddit_subscribers": 167535, "created_utc": 1710087716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For exemple, if I want to read and process multiples csv files or writes multiples csv files from coalesce(1) dataframes. Since for the latest, spark will rely on only 1 node ", "author_fullname": "t2_uhw0wx8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a good practice to mix spark with python parellel thread?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbd3oi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710084902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For exemple, if I want to read and process multiples csv files or writes multiples csv files from coalesce(1) dataframes. Since for the latest, spark will rely on only 1 node &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbd3oi", "is_robot_indexable": true, "report_reasons": null, "author": "randomWasabiEnjoyer", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbd3oi/is_it_a_good_practice_to_mix_spark_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbd3oi/is_it_a_good_practice_to_mix_spark_with_python/", "subreddit_subscribers": 167535, "created_utc": 1710084902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys\n\nI am joining a new company as a first data guy. This company doesn't have basically anything set up right now. I'll have to set up a data lake and plan all the data architecture, etc. I've been working with data in data analyst/ scientist / BI roles for 3 years, so I know how to code and how to work with data, mostly from the analyst perspective.\n\nDo you know any courses, documentations and resources that I could study in order to learn how to do stuff related to setting basic infrastructure, designing data architecture, and building the basic stuff so we could start a data team?", "author_fullname": "t2_ua22sufp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joining a new company as a first data engineer with a data analyst/scientist background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbdm13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710086237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys&lt;/p&gt;\n\n&lt;p&gt;I am joining a new company as a first data guy. This company doesn&amp;#39;t have basically anything set up right now. I&amp;#39;ll have to set up a data lake and plan all the data architecture, etc. I&amp;#39;ve been working with data in data analyst/ scientist / BI roles for 3 years, so I know how to code and how to work with data, mostly from the analyst perspective.&lt;/p&gt;\n\n&lt;p&gt;Do you know any courses, documentations and resources that I could study in order to learn how to do stuff related to setting basic infrastructure, designing data architecture, and building the basic stuff so we could start a data team?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bbdm13", "is_robot_indexable": true, "report_reasons": null, "author": "iengmind", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbdm13/joining_a_new_company_as_a_first_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbdm13/joining_a_new_company_as_a_first_data_engineer/", "subreddit_subscribers": 167535, "created_utc": 1710086237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nJust a quick one, I know this isn\u2019t the best way to recruit contributors but I\u2019m really still laying down the mental groundwork.\n\nI want to build a system that helps people manage their own money. Think like Privacy Card, as in you get multiple isolated ways to charge a single bank account. With Privacy, the cards are managed with spend limits or merchant restrictions. It\u2019s a debit account proxy with a debit card interface and customizable access control, basically.\n\nWhat I want to do is build a bucket system. You put money in a bucket and you can charge that bucket until it\u2019s depleted. When the bucket is depleted, charges will fail due to insufficient funds EVEN IF the underlying bank has funds. \n\nEach bucket gets its own virtual card to make digital transactions directly to it.\n\nThen, I want to offer a paid service (because this costs money\u2026) to print an actual card for users and send it to them. They can, via a cellular app, change which bucket the card charges to at any time.\n\nI don\u2019t know about you guys, but I\u2019ve dreamed of software like this for awhile. I want to build it now. Does the idea sound cool enough to anyone that you\u2019d want to help?\n\nSome key features:\n\n* Automated event based and/or scheduled bucket reloading of funds.\n\n* Merchant detection, to auto charge the correct bucket. Put the card in \u201cauto detect\u201d mode via the app, and it\u2019ll reference a set of user defined rules to allocate gas, groceries, etc. to the correct buckets based on merchant name. With a sensical default bucket or something in case the system cannot figure it out.\n\n\nEdit: Thanks for the feedback guys. Least to say, I\u2019m excited now!\n\nI\u2019ve already begun planning. I\u2019ll reach out to everyone who posted here when the time is right.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone interested in helping build an open source banking app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbfh3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710107782.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710090934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Just a quick one, I know this isn\u2019t the best way to recruit contributors but I\u2019m really still laying down the mental groundwork.&lt;/p&gt;\n\n&lt;p&gt;I want to build a system that helps people manage their own money. Think like Privacy Card, as in you get multiple isolated ways to charge a single bank account. With Privacy, the cards are managed with spend limits or merchant restrictions. It\u2019s a debit account proxy with a debit card interface and customizable access control, basically.&lt;/p&gt;\n\n&lt;p&gt;What I want to do is build a bucket system. You put money in a bucket and you can charge that bucket until it\u2019s depleted. When the bucket is depleted, charges will fail due to insufficient funds EVEN IF the underlying bank has funds. &lt;/p&gt;\n\n&lt;p&gt;Each bucket gets its own virtual card to make digital transactions directly to it.&lt;/p&gt;\n\n&lt;p&gt;Then, I want to offer a paid service (because this costs money\u2026) to print an actual card for users and send it to them. They can, via a cellular app, change which bucket the card charges to at any time.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know about you guys, but I\u2019ve dreamed of software like this for awhile. I want to build it now. Does the idea sound cool enough to anyone that you\u2019d want to help?&lt;/p&gt;\n\n&lt;p&gt;Some key features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Automated event based and/or scheduled bucket reloading of funds.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Merchant detection, to auto charge the correct bucket. Put the card in \u201cauto detect\u201d mode via the app, and it\u2019ll reference a set of user defined rules to allocate gas, groceries, etc. to the correct buckets based on merchant name. With a sensical default bucket or something in case the system cannot figure it out.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Edit: Thanks for the feedback guys. Least to say, I\u2019m excited now!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve already begun planning. I\u2019ll reach out to everyone who posted here when the time is right.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbfh3f", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbfh3f/anyone_interested_in_helping_build_an_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbfh3f/anyone_interested_in_helping_build_an_open_source/", "subreddit_subscribers": 167535, "created_utc": 1710090934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tipblvmq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "ELI5: what is \"Self-service Analytics\" (comic)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"8uzqh00yoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=67dec4aa3f5e933739b6beb18fbebf506561819d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4187ff9656db23a3de90e0fbd330b267afedcec"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5329a9641c53947613f1b9ca7fb004c8ae3a91bb"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/8uzqh00yoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=b9e16028f1ecb5c4bbd958a6f445f1f854334516"}, "id": "8uzqh00yoonc1"}, "7ermym9xoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9be1d00c61f975c6bce3a4eebcea838552e5c6f"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b3beaba98ae8a648d6913c0c31d2263746c9320"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=63ad60c5610cf4ee3d3d49239d08d0d90c7701f9"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/7ermym9xoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=0a27b88c3167111fd73e3b5c4e0676342098723b"}, "id": "7ermym9xoonc1"}, "ofadp50zoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=def9f754f54f86d1aa4a2c39c4d0c938b133bd8d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d68e204ee1cb598243b430aa8fd60f678629150a"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d643558e8540facb04b4c329973560a6501734b6"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/ofadp50zoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=718d950cd40cba77d76be022a14d008702bbcfa1"}, "id": "ofadp50zoonc1"}, "t8xzox91ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e6b133e4098eec34e3fecd33a9a51de8753a931"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9259b0bd2ac5d13aaf93bc1e7ef860d373eabfab"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b657ace644bf9c52f9ed528c082a4d555ffdd16d"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/t8xzox91ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=612a487d4174a9afb58f8e853dbfed9254d4c753"}, "id": "t8xzox91ponc1"}, "qoyx42ruoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce13819c999f7c3ff1b5f1fccc4d69ae9b6419ac"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc110e19eb736d70d85e9b67e9c1ecbb25823643"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9740780abffbd88106136bcb31f71f1b0511c456"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/qoyx42ruoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=5eb98629f2bedc5b982265512a9772271581597a"}, "id": "qoyx42ruoonc1"}, "uwvwzc5voonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f418b09b792d41d0f52d9d2cfb44dbf5a4442246"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f264d5d6af568fab4ec2cf4988c4742369b9b2b1"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ac848508f30d43f0aacdfd1c287c99843458ced"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/uwvwzc5voonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=1036677e8d38421a544c79dd2eac06b87637bbf9"}, "id": "uwvwzc5voonc1"}, "dspzxvpxoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a30551ebc1e0cc537ce9a4910c4e6ca70b4d3f8c"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=552630d2b9a567b243ee1e86bf2ba1f130d08a26"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dcc2518c1f26f9b4be3f330bdda469787c3a75dc"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/dspzxvpxoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=55a5f387ed96523c35d8c02e53ede5a845fa2b5b"}, "id": "dspzxvpxoonc1"}, "quodorcyoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/quodorcyoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a62681dee2c3a2a0d35429d20ebfdad959d3295"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/quodorcyoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=44650a2555d4d8820fedbc3bfa85ab3f765695db"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/quodorcyoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6f5774f911f9ce3879c844929a77b8f7f045acb"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/quodorcyoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=4d9c5c50baddb2fd50a165061438d5775d10b9fa"}, "id": "quodorcyoonc1"}, "791h7dwzoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f54781aee44bf58640f75cfeb5eea31cb191badb"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cf1fef5b59360b50f6c5e0477df8bafe631beaa"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=90a9600eda974967702139e8dac6e68f5dbd30eb"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/791h7dwzoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=dda14338f8539013c39edc737d9723dfdcd8d8ac"}, "id": "791h7dwzoonc1"}, "w8b7lkcuoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff06d2eeee3f5cce4cc243792f41dd23e62c1a43"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f02e7ce2c78a0bec160450b659820c824923b8ed"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c3e7878accb53114c2b5963cdb88d1d2d6c74d7"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/w8b7lkcuoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=ff29701dfb0bacac33171da0fec973eee7b9cf39"}, "id": "w8b7lkcuoonc1"}, "wyj984bzoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9d8ec95df91c9a1a11e86ac8c0ec0a795908a73"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=faca4807a5f07af1739e4158f7afed69de7dabf9"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=be31656b37fe1a8f6cfb38f814d99f43deb37dda"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/wyj984bzoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=d53490d8cb82da6bc04b2ffb9ac031c7dfde7e31"}, "id": "wyj984bzoonc1"}, "nj9t6dywoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4667ed03fa3504b45de70fdff0e5d87908b939b6"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ec6cd88ac7496938219246d276b9a5bcef4226e"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d647735a1ab0a6b1cd204f8fed0ae6646aabc39"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/nj9t6dywoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=abc782bbc5321d27a9ebb7ae705cea1872dfa6e6"}, "id": "nj9t6dywoonc1"}, "sgzwkknyoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef974a2f10dad3df92a059a1c990a340485b467b"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b133156ebb65cd1d165f358d39689b339b50f26"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e07cbbb35425aea70aeb156632e3176b61b9149"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/sgzwkknyoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=65a0cbc0a6112e13bca1d7dc5c6e9486b27a18c7"}, "id": "sgzwkknyoonc1"}, "6yfoxeg0ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=db6d832d203cd21d4dc020a4791ac2ce6ca520ba"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7dc6a93cf0c962b76e9c75bef90902b90f49caff"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e220b758193554aedb476805f7f8df1bcf631c45"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/6yfoxeg0ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=86ef1d8b99c2960354e9c36580904c8d758c3405"}, "id": "6yfoxeg0ponc1"}, "evrabedsoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/evrabedsoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cce7ce7cb0911b5a4d54ab5fa2038d3f9abf883"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/evrabedsoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6fed175060cf9a49aab1dcee6a845283f448466"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/evrabedsoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=41f15bf67ba496dae4b135b16f0181035bda18f6"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/evrabedsoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=57e6b0022fe8db0a65a8538f9e4a0a589bfcb6e3"}, "id": "evrabedsoonc1"}, "a9fnr6z0ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc5eb0d53a07eccd6922b9aa83220bed9b693386"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7e24627505d8422c5ef957c7ca19d93b5f8941b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=46a511e7faad2e89172255f8b9708d97860b3e52"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/a9fnr6z0ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=9ac75d1c8483beb2bfad251a781e717b321fb9de"}, "id": "a9fnr6z0ponc1"}, "srfpmcixoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b8d50b3932d9502ea509418083aaad3e53bf2bdd"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8cc65d399ad77b981fa6ac7e82619290cbb14fee"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fea78c788a8f4958c7d363286a7e21eb6c980d1b"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/srfpmcixoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=9d40bf06186302942b571a8a1b2700fcee2a8c73"}, "id": "srfpmcixoonc1"}, "t9bl78p0ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad535c60b11882bda501b0d932fb5f985dd16b32"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=774368db1cc103ae0668493d4cc21afcdad792f8"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba00fe429fdfcaab6252bababaadb4a8a10c2242"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/t9bl78p0ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=7d099f5af7d1ca24bfa52856709c43528e72074a"}, "id": "t9bl78p0ponc1"}, "owjktc80ponc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/owjktc80ponc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=727b3990cc45eb11ac31ade0c92d7e02f2847b5d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/owjktc80ponc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f20cb939a11ebc8834f6331011100a52ab3346b6"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/owjktc80ponc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe490a0b54a309074af99c20d1a8adc1eab47841"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/owjktc80ponc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=52358f94fa0d109ed54361aef2f65002eea4a5a8"}, "id": "owjktc80ponc1"}, "cwuvw1mzoonc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9dd46c9bcabfdd681a6f2113c705161a57b2195"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c05e08febc3b6ba8aaa317241c43fed35aa8060"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf8631295d73175982163f6fd4cfd5dbad34b1e8"}], "s": {"y": 768, "x": 576, "u": "https://preview.redd.it/cwuvw1mzoonc1.png?width=576&amp;format=png&amp;auto=webp&amp;s=bec6d0151aa831fe0142bfc4a9e17d6ec36f34cc"}, "id": "cwuvw1mzoonc1"}}, "name": "t3_1bc0bkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 13, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "evrabedsoonc1", "id": 418735667}, {"media_id": "w8b7lkcuoonc1", "id": 418735668}, {"media_id": "qoyx42ruoonc1", "id": 418735669}, {"media_id": "uwvwzc5voonc1", "id": 418735670}, {"media_id": "nj9t6dywoonc1", "id": 418735671}, {"media_id": "7ermym9xoonc1", "id": 418735672}, {"media_id": "srfpmcixoonc1", "id": 418735673}, {"media_id": "dspzxvpxoonc1", "id": 418735674}, {"media_id": "8uzqh00yoonc1", "id": 418735675}, {"media_id": "quodorcyoonc1", "id": 418735676}, {"media_id": "sgzwkknyoonc1", "id": 418735677}, {"media_id": "ofadp50zoonc1", "id": 418735678}, {"media_id": "wyj984bzoonc1", "id": 418735679}, {"media_id": "cwuvw1mzoonc1", "id": 418735680}, {"media_id": "791h7dwzoonc1", "id": 418735681}, {"media_id": "owjktc80ponc1", "id": 418735682}, {"media_id": "6yfoxeg0ponc1", "id": 418735683}, {"media_id": "t9bl78p0ponc1", "id": 418735684}, {"media_id": "a9fnr6z0ponc1", "id": 418735685}, {"media_id": "t8xzox91ponc1", "id": 418735686}]}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/etpTFumtTb6di2p6Z33-Pj6RXgkiru0d52Q74rTKL_k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710154042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1bc0bkv", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bc0bkv", "is_robot_indexable": true, "report_reasons": null, "author": "InitiativeOk6728", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bc0bkv/eli5_what_is_selfservice_analytics_comic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1bc0bkv", "subreddit_subscribers": 167535, "created_utc": 1710154042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_655tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good bundle for a Junior Data Engineer? I'm looking for good ways to spend the last $100 CAD of PD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbcrrl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hdgrgoo_qTCqduXQSEhSlssOyR4fuyhGZMHVBcUb_AM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710084049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "humblebundle.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.humblebundle.com/software/packt-data-engineering-software?hmb_source=&amp;hmb_medium=product_tile&amp;hmb_campaign=mosaic_section_1_layout_index_2_layout_type_threes_tile_index_2_c_packtdataengineering_softwarebundle", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?auto=webp&amp;s=9173e01a77d46a0a5e412d942fd0cf6883304071", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4635fbc4d6f777bc04c6abcc63ce22624200df0e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d28636d4db2991b3336f96b8960dd780c2f9c50", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d0d891d13010fa0edbd3776a5aa76f061849673", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e6ab8ccb587c2bfacda3088e137d55b0d3d80e16", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5f364728ac62f521797282459358149e201cadb0", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/svNcOxrRvOLCOxk8M9_cS9bzd057ToAoluZ3N5XLkBU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49aef8848ba79674a328c31970838d5251ccee48", "width": 1080, "height": 607}], "variants": {}, "id": "9FP6H7cMVe4FRgTW1gIOCw1HUZHlflM-rJYSbyt157k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bbcrrl", "is_robot_indexable": true, "report_reasons": null, "author": "Fuhrmaaj", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbcrrl/is_this_a_good_bundle_for_a_junior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.humblebundle.com/software/packt-data-engineering-software?hmb_source=&amp;hmb_medium=product_tile&amp;hmb_campaign=mosaic_section_1_layout_index_2_layout_type_threes_tile_index_2_c_packtdataengineering_softwarebundle", "subreddit_subscribers": 167535, "created_utc": 1710084049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, over the past couple months I've been delving into creating some ELT workflows using Databricks and dbt, but I've recently ran into a use case which is abit less standard, and I'm pretty conflicted around the best way to handle this (even after researching this extensively).\n\nThis sub has been really helpful in my learning so far, so I thought it might be worthwhile seeing if anyone might have any guidance/suggestions on what I should do here.\n\n&amp;#x200B;\n\nBasically, I have an existing frontend app which allows users to insert/update/delete data for a few different Postgres tables (using backend API endpoints). Now that we've setup Databricks, we're required to include these tables alongside our other Databricks data (so it can be joined together).\n\n&amp;#x200B;\n\nAdditionally, some of these tables contain data that comes from other Databricks tables (where these other tables are part of ELT workflows from various sources). For these tables, any changes that come through need to be displayed in this same frontend app.\n\n&amp;#x200B;\n\nFrom my initial understanding, these are my options to handle this:\n\n1. Directly query and modify the Databricks tables from our API endpoints (although I've read this isn't a great idea, and instead I should separate API endpoints from directly interacting with the data warehouse?).\n2. Continue using postgres to store this data, and then setup a job to sync the data between postgres and databricks:\n   1. This would involve syncing all postgres tables into Databricks (which I'm assuming I'd just do using regular ELT loading patterns?)\n   2. And then when one of these Databricks tables is updated, any changes would need to be synced back from Databricks into postgres (where I'm assuming I'd just use a standard SQL database connector?)\n\n&amp;#x200B;\n\nNote latency isn't really an issue here (it's fine if the data shown in the frontend is only synced/refreshed daily), and these tables are quite small in size (biggest one has \\~20,000 rows).\n\n&amp;#x200B;\n\nI've also read briefly that cache layer or CDC might be relevant, but my understand is too limited to know whether this is appropriate for my use case.\n\n&amp;#x200B;\n\nAny help at all would be greatly appreciated, and sorry in advance if this is difficult to understand (am happy to provide more context if helpful).", "author_fullname": "t2_paubn65a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I Separate API Endpoints from Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbxmhe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710142602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, over the past couple months I&amp;#39;ve been delving into creating some ELT workflows using Databricks and dbt, but I&amp;#39;ve recently ran into a use case which is abit less standard, and I&amp;#39;m pretty conflicted around the best way to handle this (even after researching this extensively).&lt;/p&gt;\n\n&lt;p&gt;This sub has been really helpful in my learning so far, so I thought it might be worthwhile seeing if anyone might have any guidance/suggestions on what I should do here.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically, I have an existing frontend app which allows users to insert/update/delete data for a few different Postgres tables (using backend API endpoints). Now that we&amp;#39;ve setup Databricks, we&amp;#39;re required to include these tables alongside our other Databricks data (so it can be joined together).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additionally, some of these tables contain data that comes from other Databricks tables (where these other tables are part of ELT workflows from various sources). For these tables, any changes that come through need to be displayed in this same frontend app.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;From my initial understanding, these are my options to handle this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Directly query and modify the Databricks tables from our API endpoints (although I&amp;#39;ve read this isn&amp;#39;t a great idea, and instead I should separate API endpoints from directly interacting with the data warehouse?).&lt;/li&gt;\n&lt;li&gt;Continue using postgres to store this data, and then setup a job to sync the data between postgres and databricks:\n\n&lt;ol&gt;\n&lt;li&gt;This would involve syncing all postgres tables into Databricks (which I&amp;#39;m assuming I&amp;#39;d just do using regular ELT loading patterns?)&lt;/li&gt;\n&lt;li&gt;And then when one of these Databricks tables is updated, any changes would need to be synced back from Databricks into postgres (where I&amp;#39;m assuming I&amp;#39;d just use a standard SQL database connector?)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note latency isn&amp;#39;t really an issue here (it&amp;#39;s fine if the data shown in the frontend is only synced/refreshed daily), and these tables are quite small in size (biggest one has ~20,000 rows).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also read briefly that cache layer or CDC might be relevant, but my understand is too limited to know whether this is appropriate for my use case.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help at all would be greatly appreciated, and sorry in advance if this is difficult to understand (am happy to provide more context if helpful).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bbxmhe", "is_robot_indexable": true, "report_reasons": null, "author": "HauntingPlate3639", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbxmhe/should_i_separate_api_endpoints_from_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbxmhe/should_i_separate_api_endpoints_from_databricks/", "subreddit_subscribers": 167535, "created_utc": 1710142602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors,\n\nI hope you're all doing well! I wanted to share my experience and seek some advice on transitioning into the evolving world of data engineering, specifically in 2024. Here's a bit about my journey so far:\n\nI've been in the tech industry for around six years, initially starting as a Backend Developer (4 years) and gradually shifting my focus to DevOps and Data Engineering tasks the last two years in the role. Afterwards, I landed a full Data Engineering role for the past 2 years. Unfortunately, my team recently faced a layoff, and since then, I've been on the hunt for a new opportunity.\n\nThe challenge I'm facing is the industry's increasing demand for cloud experience and proficiency with modern tools, something I wasn't heavily exposed to in my previous role with on-premise solutions. I've been diligently searching for the past year, with moments of intense effort, followed by a need to recharge after facing rejection or reaching the final rounds only to lose out to someone with more cloud-centric experience.\n\nI would love to hear your thoughts and experiences on how to successfully land a data engineering job in 2024, especially considering my background. I love learning new technologies and usually I'm fast to pick them up, so I'm a bit baffled nobody is willing to give me the opportunity to prove myself as so far I've heard only praise from my superiors and colleagues about the work I've done. What strategies have worked for you in bridging the gap between on-premise and cloud-based solutions? Are there specific tools or certifications you found particularly valuable in making this transition?\n\nHere are a few specific questions to get the discussion started:\n\n1. How crucial is cloud experience in today's data engineering landscape, and which platforms/tools should I prioritize learning?\n2. Any success stories or tips from those who have transitioned from on-premise to cloud-focused roles?\n3. Recommendations for certifications or online courses that can enhance my cloud skills and boost my marketability?\n\nI'm eager to hear your insights and learn from your experiences. Let's support each other in navigating the challenges of the job market and adapting to the ever-changing tech landscape!\n\nThanks in advance for your valuable input!", "author_fullname": "t2_jzrkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Navigating the Transition: Landing a Data Engineering Job in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bbzhez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710150648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well! I wanted to share my experience and seek some advice on transitioning into the evolving world of data engineering, specifically in 2024. Here&amp;#39;s a bit about my journey so far:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been in the tech industry for around six years, initially starting as a Backend Developer (4 years) and gradually shifting my focus to DevOps and Data Engineering tasks the last two years in the role. Afterwards, I landed a full Data Engineering role for the past 2 years. Unfortunately, my team recently faced a layoff, and since then, I&amp;#39;ve been on the hunt for a new opportunity.&lt;/p&gt;\n\n&lt;p&gt;The challenge I&amp;#39;m facing is the industry&amp;#39;s increasing demand for cloud experience and proficiency with modern tools, something I wasn&amp;#39;t heavily exposed to in my previous role with on-premise solutions. I&amp;#39;ve been diligently searching for the past year, with moments of intense effort, followed by a need to recharge after facing rejection or reaching the final rounds only to lose out to someone with more cloud-centric experience.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts and experiences on how to successfully land a data engineering job in 2024, especially considering my background. I love learning new technologies and usually I&amp;#39;m fast to pick them up, so I&amp;#39;m a bit baffled nobody is willing to give me the opportunity to prove myself as so far I&amp;#39;ve heard only praise from my superiors and colleagues about the work I&amp;#39;ve done. What strategies have worked for you in bridging the gap between on-premise and cloud-based solutions? Are there specific tools or certifications you found particularly valuable in making this transition?&lt;/p&gt;\n\n&lt;p&gt;Here are a few specific questions to get the discussion started:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How crucial is cloud experience in today&amp;#39;s data engineering landscape, and which platforms/tools should I prioritize learning?&lt;/li&gt;\n&lt;li&gt;Any success stories or tips from those who have transitioned from on-premise to cloud-focused roles?&lt;/li&gt;\n&lt;li&gt;Recommendations for certifications or online courses that can enhance my cloud skills and boost my marketability?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m eager to hear your insights and learn from your experiences. Let&amp;#39;s support each other in navigating the challenges of the job market and adapting to the ever-changing tech landscape!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your valuable input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bbzhez", "is_robot_indexable": true, "report_reasons": null, "author": "Sargaxon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbzhez/navigating_the_transition_landing_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbzhez/navigating_the_transition_landing_a_data/", "subreddit_subscribers": 167535, "created_utc": 1710150648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for advice on efficiently storing historical market order book data for analysis purposes. Eventually, I'll have to deal with around 400GB of data (10 pairs, 1 year worth of data, with an entry per second, and each entry being roughly 1 kilobyte). I need to collect this data manually since the API I'm using doesn't provide historical data.\n\nAt the moment, I'm storing the data locally in a Parquet file containing a Pandas DataFrame. However, this file is getting too large to fit into memory. I'd like to be able to scale to the cloud in the future.\n\nI've thought about two approaches:\n\n1.Recording into a traditional database and then converting it into a columnar format.\n2.Recording directly into a columnar format.\n\nI'm unsure about which tools to learn for this task and don't want to reinvent the wheel. \n\nCan anyone suggest tools or approaches that would be suitable for this?", "author_fullname": "t2_175zcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Help] Market order book storage for further analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbhvxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710096959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for advice on efficiently storing historical market order book data for analysis purposes. Eventually, I&amp;#39;ll have to deal with around 400GB of data (10 pairs, 1 year worth of data, with an entry per second, and each entry being roughly 1 kilobyte). I need to collect this data manually since the API I&amp;#39;m using doesn&amp;#39;t provide historical data.&lt;/p&gt;\n\n&lt;p&gt;At the moment, I&amp;#39;m storing the data locally in a Parquet file containing a Pandas DataFrame. However, this file is getting too large to fit into memory. I&amp;#39;d like to be able to scale to the cloud in the future.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve thought about two approaches:&lt;/p&gt;\n\n&lt;p&gt;1.Recording into a traditional database and then converting it into a columnar format.\n2.Recording directly into a columnar format.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m unsure about which tools to learn for this task and don&amp;#39;t want to reinvent the wheel. &lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest tools or approaches that would be suitable for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bbhvxs", "is_robot_indexable": true, "report_reasons": null, "author": "f0kes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbhvxs/help_market_order_book_storage_for_further/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbhvxs/help_market_order_book_storage_for_further/", "subreddit_subscribers": 167535, "created_utc": 1710096959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n\n\nI'm in the middle of preparing for the Databricks Data Engineer Associate exam. I've already practiced questions that I could find on examtopics. Are there any other FREE sources that provide practice exams for this certification?\n\nThank you so much in advance!", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I fin dDatabricks Data Engineer Associate Exam material?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bbzri0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710151819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the middle of preparing for the Databricks Data Engineer Associate exam. I&amp;#39;ve already practiced questions that I could find on examtopics. Are there any other FREE sources that provide practice exams for this certification?&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bbzri0", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbzri0/where_can_i_fin_ddatabricks_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbzri0/where_can_i_fin_ddatabricks_data_engineer/", "subreddit_subscribers": 167535, "created_utc": 1710151819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is the exam? I am considering to take it. But there are less resources available online. \n\nHave anyone take it? Mind sharing some inputs?", "author_fullname": "t2_ush6wu0ww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have anyone taken dbt analytics engineering certification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bbzmpj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710151285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is the exam? I am considering to take it. But there are less resources available online. &lt;/p&gt;\n\n&lt;p&gt;Have anyone take it? Mind sharing some inputs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bbzmpj", "is_robot_indexable": true, "report_reasons": null, "author": "Data-dude-00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbzmpj/have_anyone_taken_dbt_analytics_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbzmpj/have_anyone_taken_dbt_analytics_engineering/", "subreddit_subscribers": 167535, "created_utc": 1710151285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1- In production, what's the best approach ? To create and delete cluster with each job or use the existing one ! \n\n2- if we go for using existing cuslter and restart and stop approch then if 3 teams accessing same cluster then how to stop cluster only after completion  of 3 different jobs ?\n\nWhat happens in real world production pipelines ?\n\n\n", "author_fullname": "t2_6i4bdifz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP dataproc cluster related question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbwnbq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710138406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;1- In production, what&amp;#39;s the best approach ? To create and delete cluster with each job or use the existing one ! &lt;/p&gt;\n\n&lt;p&gt;2- if we go for using existing cuslter and restart and stop approch then if 3 teams accessing same cluster then how to stop cluster only after completion  of 3 different jobs ?&lt;/p&gt;\n\n&lt;p&gt;What happens in real world production pipelines ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbwnbq", "is_robot_indexable": true, "report_reasons": null, "author": "24aryannayak24", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbwnbq/gcp_dataproc_cluster_related_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbwnbq/gcp_dataproc_cluster_related_question/", "subreddit_subscribers": 167535, "created_utc": 1710138406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI want to exctract infos from CV such as first name, second name, gender, ... and fill them into an excel table automatically, the scenario is having many CVs inside a folder, and then have an excel table where each row represent a candidate data. the CVs can be either in English or French, pdf or .docx formats\n\nDoes anyone have an idea how to achieve that ? or have previously done that before ? I saw there is an AWS service that can help ? what are your thoughts ?\n\nThanks", "author_fullname": "t2_tz5gveo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extract CV infos automatically with NLP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbiqwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710099101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I want to exctract infos from CV such as first name, second name, gender, ... and fill them into an excel table automatically, the scenario is having many CVs inside a folder, and then have an excel table where each row represent a candidate data. the CVs can be either in English or French, pdf or .docx formats&lt;/p&gt;\n\n&lt;p&gt;Does anyone have an idea how to achieve that ? or have previously done that before ? I saw there is an AWS service that can help ? what are your thoughts ?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bbiqwk", "is_robot_indexable": true, "report_reasons": null, "author": "abdelhakim54", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbiqwk/extract_cv_infos_automatically_with_nlp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbiqwk/extract_cv_infos_automatically_with_nlp/", "subreddit_subscribers": 167535, "created_utc": 1710099101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You had to convince any business they were underutilizing their data in order to keep your job \n\nHow would you do it?\nWhat data is probably being overlooked?\nWhat\u2019s your solution?\nWhat\u2019s the impact?\n\nGo!\n\nP.S a big tech company asks this questions to staff data engineer ", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making Businesses Realize Data potential ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbdii9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710085973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You had to convince any business they were underutilizing their data in order to keep your job &lt;/p&gt;\n\n&lt;p&gt;How would you do it?\nWhat data is probably being overlooked?\nWhat\u2019s your solution?\nWhat\u2019s the impact?&lt;/p&gt;\n\n&lt;p&gt;Go!&lt;/p&gt;\n\n&lt;p&gt;P.S a big tech company asks this questions to staff data engineer &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CEO of Data Engineer Academy", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbdii9", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bbdii9/making_businesses_realize_data_potential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbdii9/making_businesses_realize_data_potential/", "subreddit_subscribers": 167535, "created_utc": 1710085973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\n\nI want to create a parallel copy activity for 5 components to the datalake. Three of them are from legacy database to datalake, two of them from sharepoint to datalake. Out of those three from legacy, two are from same db and schema, one is from different. From sharepoint everything is in the same directory just different folders\n\nSo far we dont use something like metadata pipeline but it will be soon either config from db/databricks or so however for the time being its not there. And I wonder what is the best approach for that?\n\nShould I create one executor pipeline and in the sub pipeline 5 copy activity with directly set db/schema and query for each copy activity and with bearer tokens to get sharepoint access and ingest files from there?  I know most sense makes split by source, atleast by db and sharepoint but then, how it is parallel? I believe what they want is to click debug or trigger will get all 5 copy activities running at the same time, so \"for each\" is not the case? Do I really need this master pipeline?\n\nEDIT:okay I figured out that if I have \"IsSequential\" set to false and I run via Trigger it will be parallel, not sequential, but still, how to create one properly and set the metadata including what query to run\n\nAlso if I were to create a json file with config metadata for each, where should I store it? in the raw directory in datalake, where all the files/tables should go after ingestion?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qpx7gcnj3inc1.png?width=1345&amp;format=png&amp;auto=webp&amp;s=77fa499c16575f1da01c393fc4646c8f9db979a3", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my \"architecture\" ok?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qpx7gcnj3inc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7918510c51e106c80f2c121cc08f1c6c0a5eccbc"}, {"y": 66, "x": 216, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7327008d21956a77d0ff5a5c6bfe0ba79109205"}, {"y": 99, "x": 320, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=93c27d7223b4385ab4a876e3d747cc50ca746a4c"}, {"y": 198, "x": 640, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=84775eaaada206f8ee36594bb8ac27bf77b309fc"}, {"y": 297, "x": 960, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8cfde75ab0f72a8e2b3cc273021bef945bc8f575"}, {"y": 334, "x": 1080, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=032ca72cf2fcc67403e78e8ffc96ebbf3f717c26"}], "s": {"y": 417, "x": 1345, "u": "https://preview.redd.it/qpx7gcnj3inc1.png?width=1345&amp;format=png&amp;auto=webp&amp;s=77fa499c16575f1da01c393fc4646c8f9db979a3"}, "id": "qpx7gcnj3inc1"}}, "name": "t3_1bb9am5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/THUhHFK-q07g153t_SPIWLCXvX2Pkc4BCKTFXvlzaqY.jpg", "edited": 1710074905.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710073955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I want to create a parallel copy activity for 5 components to the datalake. Three of them are from legacy database to datalake, two of them from sharepoint to datalake. Out of those three from legacy, two are from same db and schema, one is from different. From sharepoint everything is in the same directory just different folders&lt;/p&gt;\n\n&lt;p&gt;So far we dont use something like metadata pipeline but it will be soon either config from db/databricks or so however for the time being its not there. And I wonder what is the best approach for that?&lt;/p&gt;\n\n&lt;p&gt;Should I create one executor pipeline and in the sub pipeline 5 copy activity with directly set db/schema and query for each copy activity and with bearer tokens to get sharepoint access and ingest files from there?  I know most sense makes split by source, atleast by db and sharepoint but then, how it is parallel? I believe what they want is to click debug or trigger will get all 5 copy activities running at the same time, so &amp;quot;for each&amp;quot; is not the case? Do I really need this master pipeline?&lt;/p&gt;\n\n&lt;p&gt;EDIT:okay I figured out that if I have &amp;quot;IsSequential&amp;quot; set to false and I run via Trigger it will be parallel, not sequential, but still, how to create one properly and set the metadata including what query to run&lt;/p&gt;\n\n&lt;p&gt;Also if I were to create a json file with config metadata for each, where should I store it? in the raw directory in datalake, where all the files/tables should go after ingestion?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qpx7gcnj3inc1.png?width=1345&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=77fa499c16575f1da01c393fc4646c8f9db979a3\"&gt;https://preview.redd.it/qpx7gcnj3inc1.png?width=1345&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=77fa499c16575f1da01c393fc4646c8f9db979a3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bb9am5", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bb9am5/is_my_architecture_ok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bb9am5/is_my_architecture_ok/", "subreddit_subscribers": 167535, "created_utc": 1710073955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in my first data analytics course, and I have been assigned to present on HADOOP. It's been a challenging task, learning something without actually putting my hands on it. After many many hours of reading and watching videos, I still can't seem to figure out some major pieces: 1) Is there a definitive list of what is considered part of the Hadoop ecosystem? and 2) if not, then what exactly would qualify a piece of software as part of the ecosystem? Just if it can integrate with Hadoop?\n\nI feel like these should be simple questions to answer, but every time I think I find an answer, I find a different list with different software packages.", "author_fullname": "t2_h36q6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop Ecosystem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbhg34", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710095871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in my first data analytics course, and I have been assigned to present on HADOOP. It&amp;#39;s been a challenging task, learning something without actually putting my hands on it. After many many hours of reading and watching videos, I still can&amp;#39;t seem to figure out some major pieces: 1) Is there a definitive list of what is considered part of the Hadoop ecosystem? and 2) if not, then what exactly would qualify a piece of software as part of the ecosystem? Just if it can integrate with Hadoop?&lt;/p&gt;\n\n&lt;p&gt;I feel like these should be simple questions to answer, but every time I think I find an answer, I find a different list with different software packages.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbhg34", "is_robot_indexable": true, "report_reasons": null, "author": "Duckyes", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bbhg34/hadoop_ecosystem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbhg34/hadoop_ecosystem/", "subreddit_subscribers": 167535, "created_utc": 1710095871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious if anyone is in that situation? Or do you have to move to the US? ", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers in Canada working in the US?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bbcqvo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710083988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if anyone is in that situation? Or do you have to move to the US? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CEO of Data Engineer Academy", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bbcqvo", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bbcqvo/any_data_engineers_in_canada_working_in_the_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bbcqvo/any_data_engineers_in_canada_working_in_the_us/", "subreddit_subscribers": 167535, "created_utc": 1710083988.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}