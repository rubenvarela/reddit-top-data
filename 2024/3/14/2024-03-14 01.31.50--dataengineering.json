{"kind": "Listing", "data": {"after": "t3_1bdvhll", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which profession would earn you most money in the long run? I think data analyst salaries usually don\u2019t surpass $200k while DE can make $300k and more. What has been your experience or what have you seen salary wise for DE and DA?", "author_fullname": "t2_kjeptd4cq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs Data Analyst Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdzrkh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710356680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which profession would earn you most money in the long run? I think data analyst salaries usually don\u2019t surpass $200k while DE can make $300k and more. What has been your experience or what have you seen salary wise for DE and DA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bdzrkh", "is_robot_indexable": true, "report_reasons": null, "author": "Mergirl610", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdzrkh/data_engineer_vs_data_analyst_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdzrkh/data_engineer_vs_data_analyst_salary/", "subreddit_subscribers": 168560, "created_utc": 1710356680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, Microsoft is offering a free exam voucher for those who complete any of the Microsoft Learn AI Skills Challenges below:\n\n[Build next generation apps with Azure OpenAI](https://learn.microsoft.com/training/challenges?id=da09d3ca-a2bb-47dc-ba42-bea77b386a3d&amp;WT.mc_id=cloudskillschallenge_da09d3ca-a2bb-47dc-ba42-bea77b386a3d) \n\n[Azure AI Fundamentals](https://learn.microsoft.com/training/challenges?id=3ef5d197-cdef-49bc-a8bc-954bcd9e88cc&amp;WT.mc_id=cloudskillschallenge_3ef5d197-cdef-49bc-a8bc-954bcd9e88cc)\n\n[Fabric Analytics Engineer](https://learn.microsoft.com/training/challenges?id=b696c18d-7201-4aff-9c7d-d33014d93b25&amp;WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25)\n\n[Azure Machine Learning](https://learn.microsoft.com/training/challenges?id=764de7ca-8b6d-4b3a-a491-1942af389d8c&amp;WT.mc_id=cloudskillschallenge_764de7ca-8b6d-4b3a-a491-1942af389d8c)\n\nOnce you complete the challenge, you'll be given a free exam voucher which can be used for any of the exams listed below:\n\n[AI-102 Designing and Implementing a Microsoft Azure AI Solution](https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/#certification-exams?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[AI-900 Microsoft Azure AI Fundamentals](https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-900/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[DP-600 Implementing Analytics Solutions Using Microsoft Fabric](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-600/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n[DP-100 Designing and Implementing a Data Science Soluition on Azure](https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-100/?ocid=aisc24_cloudskillschallenge_webpage_cnl)\n\n&amp;#x200B;\n\nYou can read the links for all other details, you got a month to complete any of the challenges and you will get a voucher for any from the 4 exams listed. It would make more sense if you do the challenge that relates to the exam you plan on sitting for but it is not mandatory. You have to complete the challenge between March 19th and April 19th.\n\nWhich one are you choosing? I am thinking between AI-900 and DP-600.\n\nCheers!", "author_fullname": "t2_7gvgv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Microsoft Exam Vouchers By Completing a Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdhw74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710301781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, Microsoft is offering a free exam voucher for those who complete any of the Microsoft Learn AI Skills Challenges below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=da09d3ca-a2bb-47dc-ba42-bea77b386a3d&amp;amp;WT.mc_id=cloudskillschallenge_da09d3ca-a2bb-47dc-ba42-bea77b386a3d\"&gt;Build next generation apps with Azure OpenAI&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=3ef5d197-cdef-49bc-a8bc-954bcd9e88cc&amp;amp;WT.mc_id=cloudskillschallenge_3ef5d197-cdef-49bc-a8bc-954bcd9e88cc\"&gt;Azure AI Fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=b696c18d-7201-4aff-9c7d-d33014d93b25&amp;amp;WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25\"&gt;Fabric Analytics Engineer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/training/challenges?id=764de7ca-8b6d-4b3a-a491-1942af389d8c&amp;amp;WT.mc_id=cloudskillschallenge_764de7ca-8b6d-4b3a-a491-1942af389d8c\"&gt;Azure Machine Learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Once you complete the challenge, you&amp;#39;ll be given a free exam voucher which can be used for any of the exams listed below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/#certification-exams?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;AI-102 Designing and Implementing a Microsoft Azure AI Solution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-900/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;AI-900 Microsoft Azure AI Fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-600/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;DP-600 Implementing Analytics Solutions Using Microsoft Fabric&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/exams/dp-100/?ocid=aisc24_cloudskillschallenge_webpage_cnl\"&gt;DP-100 Designing and Implementing a Data Science Soluition on Azure&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;You can read the links for all other details, you got a month to complete any of the challenges and you will get a voucher for any from the 4 exams listed. It would make more sense if you do the challenge that relates to the exam you plan on sitting for but it is not mandatory. You have to complete the challenge between March 19th and April 19th.&lt;/p&gt;\n\n&lt;p&gt;Which one are you choosing? I am thinking between AI-900 and DP-600.&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bdhw74", "is_robot_indexable": true, "report_reasons": null, "author": "salihveseli", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdhw74/free_microsoft_exam_vouchers_by_completing_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdhw74/free_microsoft_exam_vouchers_by_completing_a/", "subreddit_subscribers": 168560, "created_utc": 1710301781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm a data engineering consultant specializing in working with startups to develop robust data platforms. Currently, I'm collaborating with a Swedish company whose entire infrastructure is based on Postgres and Django. They've tasked me with either building upon or improving their existing platform to make it more manageable and scalable.\n\nHowever, I've noticed that they heavily rely on Django objects for the ETL process rather than utilizing SQL. As a data engineer, I firmly believe in the effectiveness of SQL/Python Dataframes methodology over Django models for such tasks.\n\nHow do you suggest I approach convincing them of this? Or do you think I might be mistaken in my approach? Open to your insights and suggestions!", "author_fullname": "t2_80ixgpf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Seeking Advice: Convincing a Startup to Embrace SQL/Python Dataframes over Django Models\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdjkaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710307126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineering consultant specializing in working with startups to develop robust data platforms. Currently, I&amp;#39;m collaborating with a Swedish company whose entire infrastructure is based on Postgres and Django. They&amp;#39;ve tasked me with either building upon or improving their existing platform to make it more manageable and scalable.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve noticed that they heavily rely on Django objects for the ETL process rather than utilizing SQL. As a data engineer, I firmly believe in the effectiveness of SQL/Python Dataframes methodology over Django models for such tasks.&lt;/p&gt;\n\n&lt;p&gt;How do you suggest I approach convincing them of this? Or do you think I might be mistaken in my approach? Open to your insights and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdjkaj", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic-Emergency75", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdjkaj/seeking_advice_convincing_a_startup_to_embrace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdjkaj/seeking_advice_convincing_a_startup_to_embrace/", "subreddit_subscribers": 168560, "created_utc": 1710307126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm fairly new so I'm trying to gather a consensus on how often your pipelines break and why?\n\nIs it expected that they will eventually break and there's nothing you can do about it? I've heard people say be as defensive in your pipelines as possible?\n\nHow do you get alerted about the breakages?", "author_fullname": "t2_tnf3rfrjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do your pipelines break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be165f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710360042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new so I&amp;#39;m trying to gather a consensus on how often your pipelines break and why?&lt;/p&gt;\n\n&lt;p&gt;Is it expected that they will eventually break and there&amp;#39;s nothing you can do about it? I&amp;#39;ve heard people say be as defensive in your pipelines as possible?&lt;/p&gt;\n\n&lt;p&gt;How do you get alerted about the breakages?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be165f", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Coat5856", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1be165f/how_often_do_your_pipelines_break/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be165f/how_often_do_your_pipelines_break/", "subreddit_subscribers": 168560, "created_utc": 1710360042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just for all the people out there that are applying for jobs and having difficulty landing anything, keep pushing! \n\nWhen the market picks back up you will be happy that you kept upskilling yourself and you didn\u2019t give up ", "author_fullname": "t2_5q1b2lj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Positive Job Market Outlook", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be05tn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710357640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just for all the people out there that are applying for jobs and having difficulty landing anything, keep pushing! &lt;/p&gt;\n\n&lt;p&gt;When the market picks back up you will be happy that you kept upskilling yourself and you didn\u2019t give up &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be05tn", "is_robot_indexable": true, "report_reasons": null, "author": "Guilty-Commission435", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be05tn/positive_job_market_outlook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be05tn/positive_job_market_outlook/", "subreddit_subscribers": 168560, "created_utc": 1710357640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a non technical employee at a small business with mostly non tech employees. So any heavy lifting would be done by a consultant. We have an old Excel file that performs a critical function. The Excel file pulls data in from 5 CSV files (about 30mb total size) exported from one piece of software using Power Query, combines that with data pulled from 2 Salesforce Queries, and references other Excel files with Vlookups or Index equations. The query process used to be reliable and take about 5-10 seconds but has grown to about 30 seconds and fails frequently especially when there are lots of concurrent users(up to 12). I have a budget of $30,000 for a 50% chance at fixing the problem. I figure that having a database as the backend for the Excel file would make it run better. If the project is successful the follow up, with additional budget, would be:\n\nAdd additional data sources\n\nAutomate the data collection\n\nAdditional BI reporting\n\nI am looking for software that can grow with our needs, attainable data connections to other cloud software or data sources, and enough outside consultants that I am not tied to one firm. It seems that whatever consultant I choose would be inclined toward the software they are familiar with. So when screening consultants I should have an idea of what would work best. \n\nIs my budget reasonable? What software should I consider?", "author_fullname": "t2_9sx5w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What database should I use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdr3q3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710335512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a non technical employee at a small business with mostly non tech employees. So any heavy lifting would be done by a consultant. We have an old Excel file that performs a critical function. The Excel file pulls data in from 5 CSV files (about 30mb total size) exported from one piece of software using Power Query, combines that with data pulled from 2 Salesforce Queries, and references other Excel files with Vlookups or Index equations. The query process used to be reliable and take about 5-10 seconds but has grown to about 30 seconds and fails frequently especially when there are lots of concurrent users(up to 12). I have a budget of $30,000 for a 50% chance at fixing the problem. I figure that having a database as the backend for the Excel file would make it run better. If the project is successful the follow up, with additional budget, would be:&lt;/p&gt;\n\n&lt;p&gt;Add additional data sources&lt;/p&gt;\n\n&lt;p&gt;Automate the data collection&lt;/p&gt;\n\n&lt;p&gt;Additional BI reporting&lt;/p&gt;\n\n&lt;p&gt;I am looking for software that can grow with our needs, attainable data connections to other cloud software or data sources, and enough outside consultants that I am not tied to one firm. It seems that whatever consultant I choose would be inclined toward the software they are familiar with. So when screening consultants I should have an idea of what would work best. &lt;/p&gt;\n\n&lt;p&gt;Is my budget reasonable? What software should I consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdr3q3", "is_robot_indexable": true, "report_reasons": null, "author": "calky", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdr3q3/what_database_should_i_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdr3q3/what_database_should_i_use/", "subreddit_subscribers": 168560, "created_utc": 1710335512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, dlt co-founder here!\n\nWe're on a mission to shake things up in data engineering by moving away from the repetitive and into the innovative, especially with source generation. Wondering about the future of connectors and traditional ETL tools? We see pipeline generation not just as a possibility but as our current reality, supported by the case study in the article.\n\nThe real question now isn't if we're generating sources, but how extensively we're doing it. Building a single data pipeline involves numerous decisions, and we're harnessing automation, LLMs, and the OpenAPI spec to streamline this process. While relying solely on automation tends to lead to compounded errors, a collaborative approach with human oversight is proving effective.\n\nWhat's the future of ETL libraries in this evolving landscape? Our experience and user feedback suggest a significant shift. With 500 private sources created last month alone by the dlt community without any code generation, we hope that empowering the community with better tooling and growing the community will 100x this process within the year.\n\nWant to dive deeper? Check out our [latest blog post](https://dlthub.com/docs/blog/code-vs-buy) and the related case study. \n\nYou can try the code generator we created last year (in the post), but you should probably hold off for our update towards the end of the month.  \n\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The future of Data Engineering: Beyond traditional ETL \"Connectors\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdp3jf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710329128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, dlt co-founder here!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on a mission to shake things up in data engineering by moving away from the repetitive and into the innovative, especially with source generation. Wondering about the future of connectors and traditional ETL tools? We see pipeline generation not just as a possibility but as our current reality, supported by the case study in the article.&lt;/p&gt;\n\n&lt;p&gt;The real question now isn&amp;#39;t if we&amp;#39;re generating sources, but how extensively we&amp;#39;re doing it. Building a single data pipeline involves numerous decisions, and we&amp;#39;re harnessing automation, LLMs, and the OpenAPI spec to streamline this process. While relying solely on automation tends to lead to compounded errors, a collaborative approach with human oversight is proving effective.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the future of ETL libraries in this evolving landscape? Our experience and user feedback suggest a significant shift. With 500 private sources created last month alone by the dlt community without any code generation, we hope that empowering the community with better tooling and growing the community will 100x this process within the year.&lt;/p&gt;\n\n&lt;p&gt;Want to dive deeper? Check out our &lt;a href=\"https://dlthub.com/docs/blog/code-vs-buy\"&gt;latest blog post&lt;/a&gt; and the related case study. &lt;/p&gt;\n\n&lt;p&gt;You can try the code generator we created last year (in the post), but you should probably hold off for our update towards the end of the month.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?auto=webp&amp;s=89baf6cd5beccc2ef436f6c5fd2bf1b1d206cb32", "width": 1780, "height": 994}, "resolutions": [{"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f7670b7c98fe4b83ea3de40d3e2e9046a886096", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0532458503ce22d0b009efd3ed3b0b7bb6b029ba", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=68e0562d5f34ce8a12ad3c477cb49a50cccef51a", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b99612b4585f2153ce648471fbef74ec45cb6ce", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a21ae84c23b97582b017045fe6241cafa3e455ba", "width": 960, "height": 536}, {"url": "https://external-preview.redd.it/c1KXyf8czxazHd26d9uciupuICcfYeQpljzPAn5jZGE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8179bfc0a98adacdd1fbe84e92dab79336661918", "width": 1080, "height": 603}], "variants": {}, "id": "dNitETZjWStuGD_7fRr5BIR4unHLIjEoCTLF_W7F4wA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bdp3jf", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdp3jf/the_future_of_data_engineering_beyond_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdp3jf/the_future_of_data_engineering_beyond_traditional/", "subreddit_subscribers": 168560, "created_utc": 1710329128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been data engineer (mostly working on ETLs in cloud environments) for 5 years. I started a new position yesterday in an industry that requires to work on premises. Nothing exists yet, the project starts with me, which is very enthusiastic. \n\nHowever I am a bit lost after 2 days struggling on the stack. Right now I am trying to identify which tools I should use. The load of data isn't that big yet but it's required to make something a bit scalable; that could welcome new sources of data (structured and unstructured)\n\nMy idea is the following : \n\nAirflow as an orchestrator (already have an experience on it), HDFS for a datalake, PySpark scripts for ETL (comfortable on it) , Hive or Presto for datawarehousing, Metabase for viz \n\nTherefore right now I have created docker containers running Spark, HDFS and Airflow. However the more I go further, the more I am doubting. There are so many tools existing for everything and I feel like this stack is a bit oldish ... I've also checked open source versions of Dremio, Cloudera, Iceberg/minIO but I am not sure how suitable it is for a production environment where all the data weighs probably less than 100GB. Also, I'll stay at my position for approx 6 months, I need to make something that would be easily maintained by people who don't work in data engineering field, I feel like Iceberg would be overkill. I sometimes also think about doing easier stuff with pandas/postgres but this is limiting for unstructured data. \n\nI would be glad to receive your opinions about it !\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6d257z60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On premise stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdzyr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710357167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been data engineer (mostly working on ETLs in cloud environments) for 5 years. I started a new position yesterday in an industry that requires to work on premises. Nothing exists yet, the project starts with me, which is very enthusiastic. &lt;/p&gt;\n\n&lt;p&gt;However I am a bit lost after 2 days struggling on the stack. Right now I am trying to identify which tools I should use. The load of data isn&amp;#39;t that big yet but it&amp;#39;s required to make something a bit scalable; that could welcome new sources of data (structured and unstructured)&lt;/p&gt;\n\n&lt;p&gt;My idea is the following : &lt;/p&gt;\n\n&lt;p&gt;Airflow as an orchestrator (already have an experience on it), HDFS for a datalake, PySpark scripts for ETL (comfortable on it) , Hive or Presto for datawarehousing, Metabase for viz &lt;/p&gt;\n\n&lt;p&gt;Therefore right now I have created docker containers running Spark, HDFS and Airflow. However the more I go further, the more I am doubting. There are so many tools existing for everything and I feel like this stack is a bit oldish ... I&amp;#39;ve also checked open source versions of Dremio, Cloudera, Iceberg/minIO but I am not sure how suitable it is for a production environment where all the data weighs probably less than 100GB. Also, I&amp;#39;ll stay at my position for approx 6 months, I need to make something that would be easily maintained by people who don&amp;#39;t work in data engineering field, I feel like Iceberg would be overkill. I sometimes also think about doing easier stuff with pandas/postgres but this is limiting for unstructured data. &lt;/p&gt;\n\n&lt;p&gt;I would be glad to receive your opinions about it !&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdzyr0", "is_robot_indexable": true, "report_reasons": null, "author": "Ruyia31", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdzyr0/on_premise_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdzyr0/on_premise_stack/", "subreddit_subscribers": 168560, "created_utc": 1710357167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short, we are trying to keep company tools in sync. today it is a mess that comes to bite on the data end as it creates low trust in data quality. \n\nNow some tools have native integrations, which makes things easy, but for some reason, the toolset that our company settled on does not have this (outside of a few mainstream apps)\n\nThe way I see it we have three options \n\n1. Build our integrations between tools and/or integrations between our warehouse and the tools (reverse ETL), seems like lots of work to build and then maintain \n2. Use an IPaaS solution, here I would have to have someone learn the tool as each one of these tools usually uses some proprietary way of doing things. \n3. Reverse ETL tool, this is new to me, haven't really worked with one in the past but I had a call [Hightouch](https://hightouch.com)Reverse ETL tool this is new to me, I haven't really worked with one in the past, but I had a call with Hightouch, and it seems promising. It seems to fit the data team a bit better than the other 2 options as most of the work will be done within warehouse dbt transformations, which anyone in the team can do   \n\n\nAny recommendations on how to tackle this? Have you guys worked with a Reverse ETL tool? If yes which one and what's your feedback   ", "author_fullname": "t2_et5t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping org tools in sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdtjwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710345886.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710341933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, we are trying to keep company tools in sync. today it is a mess that comes to bite on the data end as it creates low trust in data quality. &lt;/p&gt;\n\n&lt;p&gt;Now some tools have native integrations, which makes things easy, but for some reason, the toolset that our company settled on does not have this (outside of a few mainstream apps)&lt;/p&gt;\n\n&lt;p&gt;The way I see it we have three options &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Build our integrations between tools and/or integrations between our warehouse and the tools (reverse ETL), seems like lots of work to build and then maintain &lt;/li&gt;\n&lt;li&gt;Use an IPaaS solution, here I would have to have someone learn the tool as each one of these tools usually uses some proprietary way of doing things. &lt;/li&gt;\n&lt;li&gt;Reverse ETL tool, this is new to me, haven&amp;#39;t really worked with one in the past but I had a call &lt;a href=\"https://hightouch.com\"&gt;Hightouch&lt;/a&gt;Reverse ETL tool this is new to me, I haven&amp;#39;t really worked with one in the past, but I had a call with Hightouch, and it seems promising. It seems to fit the data team a bit better than the other 2 options as most of the work will be done within warehouse dbt transformations, which anyone in the team can do&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any recommendations on how to tackle this? Have you guys worked with a Reverse ETL tool? If yes which one and what&amp;#39;s your feedback   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?auto=webp&amp;s=9536c052f365bbf3762edff656ecbf9ff1c87a20", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e45b525dae7b055f04a99a6162ace736c384fa2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2e6bd7eefa3c34e35b0df80988a8a58b5b1d59b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa1a6445448c2ef5897ecf6c2d3fd479726852de", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6b29ff2c57ada4dd2f2173db2c1e92121437df1", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=45d6c4070a6154d439799678966846f8386890d0", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=311daa8b857a8795d13fd2269b9cb5eff88c4ab6", "width": 1080, "height": 565}], "variants": {}, "id": "7X-6dPLJU2TmqoD0kEsCB8XE26QEVlx0zliDnH3JJLc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdtjwb", "is_robot_indexable": true, "report_reasons": null, "author": "MrGreenPL", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdtjwb/keeping_org_tools_in_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdtjwb/keeping_org_tools_in_sync/", "subreddit_subscribers": 168560, "created_utc": 1710341933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I tested the code that Daniel Palma created for Running Doom inside Snowflake Container Services. In this video I'll show case the same in video format and explore a little bit what Container Services are and what are their use cases.\n\n[https://www.youtube.com/watch?v=Zd81nydtgX4](https://www.youtube.com/watch?v=Zd81nydtgX4)", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Doom in Snowflake Container Services (again)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdovx9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710328577.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710328378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tested the code that Daniel Palma created for Running Doom inside Snowflake Container Services. In this video I&amp;#39;ll show case the same in video format and explore a little bit what Container Services are and what are their use cases.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=Zd81nydtgX4\"&gt;https://www.youtube.com/watch?v=Zd81nydtgX4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?auto=webp&amp;s=afbcfde278fdf6f2f100bacfcfb80da367dc5d4c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=525eda73b654ebd15290c6b9d187c977c2a133ec", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc219c0229e4e211fed5eb54c89866c06157f0fa", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/DURfMc7ju_r56ifCirHdmFWYRefndJFD8A19NBQmA2E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19112e2acdafd3c6ff33454a4582f1f98477777a", "width": 320, "height": 240}], "variants": {}, "id": "ChKNgWkPA8nGKkFnTBiHTPOdr_9M-xnMaoB34UiAtTg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bdovx9", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdovx9/running_doom_in_snowflake_container_services_again/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdovx9/running_doom_in_snowflake_container_services_again/", "subreddit_subscribers": 168560, "created_utc": 1710328378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm organizing a workshop next Tuesday, March 19, 2024, at 4 PM Pacific Time. During this workshop, instructors will build a real-time dashboard for analyzing pizza shop orders using OSS products: Bytewax, Pinot, and Streamlit.\nFor more details and to RSVP (attendance is free), please visit:\nhttps://bytewax.io/events/real-time-pizza-analytics\n\nI believe this workshop is especially noteworthy for those interested, as I've personally enjoyed migrating the previous solution from Kafka Streams to Bytewax. The solution is now more Python-friendly and the complexity of the codebase is significantly reduced. For me, it felt truly refreshing to rewrite it \ud83d\ude04 I believe many data engineers would prefer Python solutions over JVM based.\n\nI am still in the process of updating the repository and will share it later, but here is the previous version:\nhttps://dev.startree.ai/docs/pinot/demo-apps/pizza-shop", "author_fullname": "t2_zus64vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Workshop: Real time data streaming + Analytics + Visualization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2xai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710364229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m organizing a workshop next Tuesday, March 19, 2024, at 4 PM Pacific Time. During this workshop, instructors will build a real-time dashboard for analyzing pizza shop orders using OSS products: Bytewax, Pinot, and Streamlit.\nFor more details and to RSVP (attendance is free), please visit:\n&lt;a href=\"https://bytewax.io/events/real-time-pizza-analytics\"&gt;https://bytewax.io/events/real-time-pizza-analytics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I believe this workshop is especially noteworthy for those interested, as I&amp;#39;ve personally enjoyed migrating the previous solution from Kafka Streams to Bytewax. The solution is now more Python-friendly and the complexity of the codebase is significantly reduced. For me, it felt truly refreshing to rewrite it \ud83d\ude04 I believe many data engineers would prefer Python solutions over JVM based.&lt;/p&gt;\n\n&lt;p&gt;I am still in the process of updating the repository and will share it later, but here is the previous version:\n&lt;a href=\"https://dev.startree.ai/docs/pinot/demo-apps/pizza-shop\"&gt;https://dev.startree.ai/docs/pinot/demo-apps/pizza-shop&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?auto=webp&amp;s=9710ac602cc3d55cdc3483c30610f0d6cec287c7", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=be1e5d4935c553e543ed40f9063b0890186f9b65", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc522633caa9ca91f4222971361ed6867641bdfa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a14311bc251f6667bef9851c488608dafcfda35f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa1a7d640b445b93da6892292643b670a9e21ecd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=55556a2666f8268a495d077ff92ee5135aa6ee4b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c3598d6efc61818791e553aabc53f37918820c8", "width": 1080, "height": 607}], "variants": {}, "id": "kpggDHbug4GLpb_LymyREbDxwQCTGOuosNWiRAKAgVg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be2xai", "is_robot_indexable": true, "report_reasons": null, "author": "oli_k", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2xai/virtual_workshop_real_time_data_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2xai/virtual_workshop_real_time_data_streaming/", "subreddit_subscribers": 168560, "created_utc": 1710364229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Link](https://www.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/) to the initial post. Posting this again after debugging. Since this is my first project, I appreciate your feedback on anything; be it Github readme, dashboard, etc.\n\n&amp;#x200B;\n\nLeveraging Schipol Dev API, I've built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard [here](https://aeroatlas.streamlit.app/). I'd love your feedback, suggestions, and opinions to enhance this data-driven journey! Also find the Github repo [here](https://github.com/suleman1412/schipol_flights_pipeline).\n\n&amp;#x200B;", "author_fullname": "t2_rw01dudv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updated: Just launched my first data engineering project!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdv1xv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710345609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/\"&gt;Link&lt;/a&gt; to the initial post. Posting this again after debugging. Since this is my first project, I appreciate your feedback on anything; be it Github readme, dashboard, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Leveraging Schipol Dev API, I&amp;#39;ve built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard &lt;a href=\"https://aeroatlas.streamlit.app/\"&gt;here&lt;/a&gt;. I&amp;#39;d love your feedback, suggestions, and opinions to enhance this data-driven journey! Also find the Github repo &lt;a href=\"https://github.com/suleman1412/schipol_flights_pipeline\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?auto=webp&amp;s=ede95ca400f22e057dffa04ff31de469ef538d82", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d897456f2eb1ccf0e4332fe0dc9bbf31d8785cf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ca7b49d3f21a52a175276cb6e52c44193295a8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e17c7da02f04519c29ac1a7849ad490919346c10", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d3f6fc21cae9cd51c7d0c363e2684ea79774a5f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54ecbc0a8baed2ce0f49d6dab5807c120ec0cdd5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=465c26e0a14bb5641bcce7b228b1b687029074bc", "width": 1080, "height": 567}], "variants": {}, "id": "QDBuNMj6jujXmJHrzKao8hw5SfNdcufBYQsaXgPrC7Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bdv1xv", "is_robot_indexable": true, "report_reasons": null, "author": "botuleman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdv1xv/updated_just_launched_my_first_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdv1xv/updated_just_launched_my_first_data_engineering/", "subreddit_subscribers": 168560, "created_utc": 1710345609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Early stage startups can't fund a DE team** obviously - not enough data, time, or money! But startups have a ton of data (stripe, customer, app analytics, finance/payments etc..) generally a better understanding of data. \n\n**So... for you guys:** how can early stage startups make the most of their data in your experience? Is there a way to stitch together all the key data without a large engineering effort? What specific examples have you seen work in your experience? Is this even a data engineering problem or is ad-hoc the way to go? ", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should early stage startups approach data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1be7kij", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710375587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Early stage startups can&amp;#39;t fund a DE team&lt;/strong&gt; obviously - not enough data, time, or money! But startups have a ton of data (stripe, customer, app analytics, finance/payments etc..) generally a better understanding of data. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So... for you guys:&lt;/strong&gt; how can early stage startups make the most of their data in your experience? Is there a way to stitch together all the key data without a large engineering effort? What specific examples have you seen work in your experience? Is this even a data engineering problem or is ad-hoc the way to go? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be7kij", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7kij/how_should_early_stage_startups_approach_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7kij/how_should_early_stage_startups_approach_data/", "subreddit_subscribers": 168560, "created_utc": 1710375587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nPlease give me any suggestions what will be the best way to redesign this data pipeline, to ingest data from the BI tool back to the source table in Snowflake.  \nCurrent setup:\n\nhttps://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267\n\n I have a Google spreadsheet that is transformed daily with DBT and stored in Snowflake DB as a mart-ready table for analysis. This table undergoes a full refresh daily. Later, this table is connected to the BI tool where Data Analysts analyze the data. However, they now want to manually input data in Power BI so that this data will be saved in the initial source table in Snowflake.\n\nHow should I approach this, considering that the initial table is refreshed daily? I'm thinking of changing DBT materialization to incremental or creating a new extra table in Snowflake that will be a combination of raw source data and input from BI. Maybe there is a better way yo do it?  \n", "author_fullname": "t2_2odyjk2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redesign ETL process, DBT table materialization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": false, "media_metadata": {"94pdir9f16oc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 31, "x": 108, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cfbf74ade92410d88497db8af9b8ca27c372c2d"}, {"y": 62, "x": 216, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=193da8daaf9a56362353b507bc96cbfb62728b22"}, {"y": 92, "x": 320, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0755624e597482769b696c4eca8f753b2b873a4f"}, {"y": 184, "x": 640, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=acf0061a8c4917dd169a02a9982c1ba70cf35117"}, {"y": 276, "x": 960, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee2b256c89aa02600584f6bec6d9bda5d9b096aa"}, {"y": 311, "x": 1080, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c4ad491af8a3239eb5ef8e96e103cfaa068ff6ea"}], "s": {"y": 316, "x": 1096, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267"}, "id": "94pdir9f16oc1"}}, "name": "t3_1be395d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/63jK-_OvQUavcQrCcrDL58R0CJs6FkXm08oDXfbz9Ac.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710364982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Please give me any suggestions what will be the best way to redesign this data pipeline, to ingest data from the BI tool back to the source table in Snowflake.&lt;br/&gt;\nCurrent setup:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267\"&gt;https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a Google spreadsheet that is transformed daily with DBT and stored in Snowflake DB as a mart-ready table for analysis. This table undergoes a full refresh daily. Later, this table is connected to the BI tool where Data Analysts analyze the data. However, they now want to manually input data in Power BI so that this data will be saved in the initial source table in Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this, considering that the initial table is refreshed daily? I&amp;#39;m thinking of changing DBT materialization to incremental or creating a new extra table in Snowflake that will be a combination of raw source data and input from BI. Maybe there is a better way yo do it?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1be395d", "is_robot_indexable": true, "report_reasons": null, "author": "Krukach", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be395d/redesign_etl_process_dbt_table_materialization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be395d/redesign_etl_process_dbt_table_materialization/", "subreddit_subscribers": 168560, "created_utc": 1710364982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI've been thinking a lot about how we, as data professionals, are tackling data adoption hurdles, especially in areas like drug development and personalized medicine (Life Sciences); so I wrote this article. \n\n[https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare](https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare)\n\nAre you facing similar challenges? How are you managing them, and what strategies or tools have made a difference in your work?\n\nReally curious to hear if your experiences align with mine and how you're navigating this complex landscape.", "author_fullname": "t2_fosm1pwyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data in Life Sciences: Are We on the Same Page?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be1kpo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710361010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking a lot about how we, as data professionals, are tackling data adoption hurdles, especially in areas like drug development and personalized medicine (Life Sciences); so I wrote this article. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare\"&gt;https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Are you facing similar challenges? How are you managing them, and what strategies or tools have made a difference in your work?&lt;/p&gt;\n\n&lt;p&gt;Really curious to hear if your experiences align with mine and how you&amp;#39;re navigating this complex landscape.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?auto=webp&amp;s=91c90fdf2875134891d193f444905b830d0864da", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e5046c0a3229b2e9e21ed3054b87f1903055596", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86c79bee66d97e1e8dcb050394863d568359d343", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b69b996d84839071da5ae484eb249679d4b969d", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b2237495e1c0a2c721481a18987c1e1e4940a2a4", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ce5da23d057f738322d8874cda1f5d036e44aef", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd322b26a9ac0c1761783fa0722662cb6b7dd90e", "width": 1080, "height": 564}], "variants": {}, "id": "9AKl43XPJbE9__vNApnXsZxefA6nyXZTbapru4_2mhE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1be1kpo", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Queen-Mayra", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be1kpo/data_in_life_sciences_are_we_on_the_same_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be1kpo/data_in_life_sciences_are_we_on_the_same_page/", "subreddit_subscribers": 168560, "created_utc": 1710361010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For folks out there looking to build data infrastructure using python: [https://docs.turntable.so/quickstart](https://docs.turntable.so/quickstart)  \n\n\nSupports federated ETL across warehouses and DBs, data contracts, embeddable into other BI tools/API and a metrics/semantic layer  \n\n\n&amp;#x200B;", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt alternative using Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1be7qvk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710376056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For folks out there looking to build data infrastructure using python: &lt;a href=\"https://docs.turntable.so/quickstart\"&gt;https://docs.turntable.so/quickstart&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Supports federated ETL across warehouses and DBs, data contracts, embeddable into other BI tools/API and a metrics/semantic layer  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?auto=webp&amp;s=4a2c1b36f6bae69a83ff387c6f354d106f0c6ccc", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c5d2904bd0af3466fe4583c44bb4af1a360ae9d1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b7eb5b88cb95143a9197e76c22cd11a8876bdcf", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=77beb58961be7eed0a3252e27a1a8c3c69e329e2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=86b12ee450005e9315fff130b87264ca160d20e4", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f1772e88293dda35504fd4902586abdea112e54", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/OpVaBDAPkEJbEP2k-SLR5OluiNuazHC95OLH26nSZbk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b7429f9e2d33f890ce9eb55eccefc9824d8e95c9", "width": 1080, "height": 567}], "variants": {}, "id": "Q8Zzrc1SR0QZlwpb4D9moTOEN5u8xrz9cxuQYYgpcW8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1be7qvk", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7qvk/dbt_alternative_using_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7qvk/dbt_alternative_using_python/", "subreddit_subscribers": 168560, "created_utc": 1710376056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What services do you recommend to make this migration as fast and smooth as possible, just once? First though is glue (used before but different purpose), or DMS service (have not never used it).ed daily, storing only 90 days. This is one of the problems of the migration, that querying from it is impossible my first approach was with a simple lambda, MySQL connector, and python script and chunk it, but would take me about 2 days if I do that. Also, the idea is to have this data somewhere else before thinking of a Lakehouse solution. My questions are:  \n\n\n* What ETL do you propose to make this process daily (1.5M records) comes to glue again if i am succesfull with the first bullet pointe but for different purposes), or DMS service (have not never used it).\n* What ETL do you propose to make this process daily (1.5M records) come to glue again if I am succesfull with the first bullet point\n* Lastly, this data is desired to be used for analytics, initially will be in S3 to make queries using Athena while the team gains an idea about the KPIs they want to track, in the future the idea is to have it somewhere else (I though of a lakehouse) that makes it fast to query and build sql models with it. The whole company env. is in AWS so my first thought is RedShift but I like the efficiency and how GBQ handles this amount of data\n\nThank you so much for reading!", "author_fullname": "t2_42yrzhea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDS to S3 migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1be7oi7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710375876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What services do you recommend to make this migration as fast and smooth as possible, just once? First though is glue (used before but different purpose), or DMS service (have not never used it).ed daily, storing only 90 days. This is one of the problems of the migration, that querying from it is impossible my first approach was with a simple lambda, MySQL connector, and python script and chunk it, but would take me about 2 days if I do that. Also, the idea is to have this data somewhere else before thinking of a Lakehouse solution. My questions are:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What ETL do you propose to make this process daily (1.5M records) comes to glue again if i am succesfull with the first bullet pointe but for different purposes), or DMS service (have not never used it).&lt;/li&gt;\n&lt;li&gt;What ETL do you propose to make this process daily (1.5M records) come to glue again if I am succesfull with the first bullet point&lt;/li&gt;\n&lt;li&gt;Lastly, this data is desired to be used for analytics, initially will be in S3 to make queries using Athena while the team gains an idea about the KPIs they want to track, in the future the idea is to have it somewhere else (I though of a lakehouse) that makes it fast to query and build sql models with it. The whole company env. is in AWS so my first thought is RedShift but I like the efficiency and how GBQ handles this amount of data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you so much for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1be7oi7", "is_robot_indexable": true, "report_reasons": null, "author": "josejo9423", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7oi7/rds_to_s3_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7oi7/rds_to_s3_migration/", "subreddit_subscribers": 168560, "created_utc": 1710375876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a traditional backend engineer with lots of cloud experience and I'm interested in making a transition to the AI/ML world and I think a lot of my experience could be applicable best towards the aforementioned roles.\n\nFrom my limited research so far my understanding is that data engineers don't necessarily work with ML or even data science teams but just data in general whereas MLOps/ML platform/ML infrastructure engineers require a good understanding of ML and work on the entire ML-lifecycle infrastructure which may or may not include ETL pipelines. Did I get it right? What's your perspective?", "author_fullname": "t2_syp7tbbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering vs MLOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1be7ccx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710375000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a traditional backend engineer with lots of cloud experience and I&amp;#39;m interested in making a transition to the AI/ML world and I think a lot of my experience could be applicable best towards the aforementioned roles.&lt;/p&gt;\n\n&lt;p&gt;From my limited research so far my understanding is that data engineers don&amp;#39;t necessarily work with ML or even data science teams but just data in general whereas MLOps/ML platform/ML infrastructure engineers require a good understanding of ML and work on the entire ML-lifecycle infrastructure which may or may not include ETL pipelines. Did I get it right? What&amp;#39;s your perspective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1be7ccx", "is_robot_indexable": true, "report_reasons": null, "author": "Low-Associate2521", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7ccx/data_engineering_vs_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7ccx/data_engineering_vs_mlops/", "subreddit_subscribers": 168560, "created_utc": 1710375000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined this company two years ago with next to no experience in data. I did some self-learning 6 months prior to joining and I already had some experience with Python from college, but that was it.\n\nOver the first year I was essentially a data analyst with &lt;5% data science work. I worked with controls engineers to get data off the equipment and into SQL tables. From there I built out dashboards in Power BI that showed relatively real-time metrics out on the shop floor. I then started to build out tables/queries to aggregate that data and send out daily reports. During this time I was learning a lot and honestly having a blast.\n\nAfter the dashboards I did some dabbling with condition monitoring sensors to try to drive towards predictive maintenance solutions. This totally flopped, we just didn't know enough about predictive maintenance and the sensors/math required to make a viable production ready solution.\n\nThe next year, I had the opportunity to dabble in Azure to better understand how we could bring some of this production/machine data into the cloud. This would help the business bring all our data sources together in the future. I dabbled in ADF, Azure Stream Analytics, and a few other Azure tools.  But my knowledge felt half-baked and disconnected. \n\nSince then I've basically hit a brick wall. Systems were changing, equipment was moving, and I was still a sole employee working alone in manufacturing. We began switching our ERP to Oracle so ERP data has essentially been off limits for me while IT works. It was bad data to begin with. then we wanted to start using a historian for manufacturing data so I again had to wait for IT to make implementations. Now, I'm at a point where I feel trapped. The historian is cool but ultimately does not allow me to learn traditional data engineering techniques/tools, the PLC programmers have limited time so I can't get new data from them, and extracting data from other data sources is something that IT likes to keep for themselves since I fall under the \"operations\" bucket. \n\nI'm alone, feel like I have very little mentorship in this space, and see roadblocks in nearly every direction. However, I can tell my director has a significant amount of trust in me. She always asks for my input to provide feedback to a \"global I4.0 committee\" that is forming. Additionally, she seems open to me getting professional training but data engineering in manufacturing feels super niche. It feels like normal courses don't apply. Networking, the tools used, etc are all different and create a unique set of problems.\n\nHow do I continue to develop? I like DE and may even see myself as a good software engineer in the future (not sure how common that switch happens), but as of right now I'm learning a totally different skillset and I'm unsure how many years it will be before a true \"data team\" exists that I could learn from in the manufacturing space.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I progress my career working in manufacturing? Look for something new or wait it out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1be75eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710374509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined this company two years ago with next to no experience in data. I did some self-learning 6 months prior to joining and I already had some experience with Python from college, but that was it.&lt;/p&gt;\n\n&lt;p&gt;Over the first year I was essentially a data analyst with &amp;lt;5% data science work. I worked with controls engineers to get data off the equipment and into SQL tables. From there I built out dashboards in Power BI that showed relatively real-time metrics out on the shop floor. I then started to build out tables/queries to aggregate that data and send out daily reports. During this time I was learning a lot and honestly having a blast.&lt;/p&gt;\n\n&lt;p&gt;After the dashboards I did some dabbling with condition monitoring sensors to try to drive towards predictive maintenance solutions. This totally flopped, we just didn&amp;#39;t know enough about predictive maintenance and the sensors/math required to make a viable production ready solution.&lt;/p&gt;\n\n&lt;p&gt;The next year, I had the opportunity to dabble in Azure to better understand how we could bring some of this production/machine data into the cloud. This would help the business bring all our data sources together in the future. I dabbled in ADF, Azure Stream Analytics, and a few other Azure tools.  But my knowledge felt half-baked and disconnected. &lt;/p&gt;\n\n&lt;p&gt;Since then I&amp;#39;ve basically hit a brick wall. Systems were changing, equipment was moving, and I was still a sole employee working alone in manufacturing. We began switching our ERP to Oracle so ERP data has essentially been off limits for me while IT works. It was bad data to begin with. then we wanted to start using a historian for manufacturing data so I again had to wait for IT to make implementations. Now, I&amp;#39;m at a point where I feel trapped. The historian is cool but ultimately does not allow me to learn traditional data engineering techniques/tools, the PLC programmers have limited time so I can&amp;#39;t get new data from them, and extracting data from other data sources is something that IT likes to keep for themselves since I fall under the &amp;quot;operations&amp;quot; bucket. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m alone, feel like I have very little mentorship in this space, and see roadblocks in nearly every direction. However, I can tell my director has a significant amount of trust in me. She always asks for my input to provide feedback to a &amp;quot;global I4.0 committee&amp;quot; that is forming. Additionally, she seems open to me getting professional training but data engineering in manufacturing feels super niche. It feels like normal courses don&amp;#39;t apply. Networking, the tools used, etc are all different and create a unique set of problems.&lt;/p&gt;\n\n&lt;p&gt;How do I continue to develop? I like DE and may even see myself as a good software engineer in the future (not sure how common that switch happens), but as of right now I&amp;#39;m learning a totally different skillset and I&amp;#39;m unsure how many years it will be before a true &amp;quot;data team&amp;quot; exists that I could learn from in the manufacturing space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1be75eb", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be75eb/how_do_i_progress_my_career_working_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be75eb/how_do_i_progress_my_career_working_in/", "subreddit_subscribers": 168560, "created_utc": 1710374509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n&amp;#x200B;\n\n# How to integrate Great Expecation Data Quality tests in Airflow?\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1) Orchestrate Modern Data Stack\n\nVlog on how to how to integrate Great Expectation Data Quality tests in the Apache Airflow.  We use the Great Expectation (GE) provider for Airlow and run the Great Expectations suite. The target data asset is a PostgreSQL table.  We use Airflow as the orchestrator for the ETL (ELT) Data piepline and GE as the testing framework\n\n[https://www.youtube.com/watch?v=WAgbFrHUk50](https://www.youtube.com/watch?v=WAgbFrHUk50)\n\nTopics covered:\n\n* Data Orchestartion\n* Airflow &amp; DAG\n* Airflow GE Provider\n* Run Modern Data Stack with Airflow\n\nTech Stack: **Airflow, Great Expecations, Data Quality, Python**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate Great Expecation Data Quality tests in Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2kwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710363424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;How to integrate Great Expecation Data Quality tests in Airflow?&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; Orchestrate Modern Data Stack&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to how to integrate Great Expectation Data Quality tests in the Apache Airflow.  We use the Great Expectation (GE) provider for Airlow and run the Great Expectations suite. The target data asset is a PostgreSQL table.  We use Airflow as the orchestrator for the ETL (ELT) Data piepline and GE as the testing framework&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=WAgbFrHUk50\"&gt;https://www.youtube.com/watch?v=WAgbFrHUk50&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Orchestartion&lt;/li&gt;\n&lt;li&gt;Airflow &amp;amp; DAG&lt;/li&gt;\n&lt;li&gt;Airflow GE Provider&lt;/li&gt;\n&lt;li&gt;Run Modern Data Stack with Airflow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, Great Expecations, Data Quality, Python&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?auto=webp&amp;s=1f9fac17204c854b5b4d082002059c44d5ae03ed", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8be4ceb1eb56baade4c73afe89f795ba729582c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a24799e256cfd2e1a27df43a0bac89db7a456ad0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb45dfe184a212d81531e5227e21e5f5f95a26b2", "width": 320, "height": 240}], "variants": {}, "id": "TSidoV9hmIfyC3VVXAqXTE2OWfjCP7yrcSm4ForS6lE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1be2kwd", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2kwd/how_to_integrate_great_expecation_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2kwd/how_to_integrate_great_expecation_data_quality/", "subreddit_subscribers": 168560, "created_utc": 1710363424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are folk seeing a general trend in the particular pairings of open-source compute platforms and open table formats (OTF)? \n\nSpecifically: \n\n1. My _assumption_ is that #ApacheSpark [Databricks] is most often used with #DeltaLake [Databricks], and less so than with Hudi and Iceberg. Is that true?\n\n2. Does #ApacheFlink get used with #ApacheIceberg / #ApacheHudi / #DeltaLake equally when an OTF is involved, or weighted towards one or the other?\n\nI know that folk at the various respective vendors in this space are going to have a bunch of data points to share illustrating the pairings in permutations of favourable light ;) But I would love to hear from folk in the field too who have anecdotal evidence to share too :D\n\nTIA.", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink&amp;Spark - which OTF most commonly used with each?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdyu6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710354558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are folk seeing a general trend in the particular pairings of open-source compute platforms and open table formats (OTF)? &lt;/p&gt;\n\n&lt;p&gt;Specifically: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;My &lt;em&gt;assumption&lt;/em&gt; is that #ApacheSpark [Databricks] is most often used with #DeltaLake [Databricks], and less so than with Hudi and Iceberg. Is that true?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Does #ApacheFlink get used with #ApacheIceberg / #ApacheHudi / #DeltaLake equally when an OTF is involved, or weighted towards one or the other?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I know that folk at the various respective vendors in this space are going to have a bunch of data points to share illustrating the pairings in permutations of favourable light ;) But I would love to hear from folk in the field too who have anecdotal evidence to share too :D&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdyu6v", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdyu6v/flinkspark_which_otf_most_commonly_used_with_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdyu6v/flinkspark_which_otf_most_commonly_used_with_each/", "subreddit_subscribers": 168560, "created_utc": 1710354558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have question like that How do all you guys check if your data consistent. Let me be more detailed. Think about that you have two tables one in A server another in B and based on A table, B table is being updated. I want to check if all the values in B table matches values of A table. Is there best practice to check it ? Currently I have developed my logic, checking both tables with python code. But wonder what if tomorrow the size of tables growths to 2 billion rows. I would like to get your recommendations", "author_fullname": "t2_hf6pnxd8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data consistency checking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdy4lv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710352916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have question like that How do all you guys check if your data consistent. Let me be more detailed. Think about that you have two tables one in A server another in B and based on A table, B table is being updated. I want to check if all the values in B table matches values of A table. Is there best practice to check it ? Currently I have developed my logic, checking both tables with python code. But wonder what if tomorrow the size of tables growths to 2 billion rows. I would like to get your recommendations&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdy4lv", "is_robot_indexable": true, "report_reasons": null, "author": "Fair_Palpitation8548", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdy4lv/data_consistency_checking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdy4lv/data_consistency_checking/", "subreddit_subscribers": 168560, "created_utc": 1710352916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Guys,\n\nNeed some help on writestream with foreachbatch, so my code runs perfectly fine on a single user cluster but when i test it out on a shared multinode cluster it break with an error\n\n&amp;#x200B;\n\n`def process_batch(df, batch_id):`  \n`AT_original.alias(\"t\").merge(`  \n`df_batch.alias(\"s\"),`  \n `\"s.key = t.key\"`  \n`).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()`  \n`query = df.writeStream \\`  \n`.format('delta') \\`  \n`.outputMode(\"update\") \\`  \n`.foreachBatch(process_batch) \\`  \n`.option('checkpointLocation',)\\`  \n`.trigger(once=True) \\`  \n`.start()`\n\nCannot serialize the function \\`foreachBatch\\`  \n\n\nwhat am i missing here?", "author_fullname": "t2_2ssprs7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark Structured Streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdxy8e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710352500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys,&lt;/p&gt;\n\n&lt;p&gt;Need some help on writestream with foreachbatch, so my code runs perfectly fine on a single user cluster but when i test it out on a shared multinode cluster it break with an error&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;def process_batch(df, batch_id):&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;AT_original.alias(&amp;quot;t&amp;quot;).merge(&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;df_batch.alias(&amp;quot;s&amp;quot;),&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;&amp;quot;s.key = t.key&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;query = df.writeStream \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.format(&amp;#39;delta&amp;#39;) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.outputMode(&amp;quot;update&amp;quot;) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.foreachBatch(process_batch) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.option(&amp;#39;checkpointLocation&amp;#39;,)\\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.trigger(once=True) \\&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;.start()&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Cannot serialize the function `foreachBatch`  &lt;/p&gt;\n\n&lt;p&gt;what am i missing here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdxy8e", "is_robot_indexable": true, "report_reasons": null, "author": "anurag_bhoga", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdxy8e/pyspark_structured_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdxy8e/pyspark_structured_streaming/", "subreddit_subscribers": 168560, "created_utc": 1710352500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(I have no affiliation with the tool)\n\nIf you are tired of drag-and-drop or heavy client-server applications for data ingestion, worth checking this alternative open-source framework written in Go. Simple, fast and stateless.\n\n[https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery](https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery) ", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to ELT with CloudQuery \u2014 a declarative data integration framework for developers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdvhzv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710346685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(I have no affiliation with the tool)&lt;/p&gt;\n\n&lt;p&gt;If you are tired of drag-and-drop or heavy client-server applications for data ingestion, worth checking this alternative open-source framework written in Go. Simple, fast and stateless.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery\"&gt;https://kestra.io/blogs/2024-03-12-introduction-to-cloudquery&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bdvhzv", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdvhzv/introduction_to_elt_with_cloudquery_a_declarative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdvhzv/introduction_to_elt_with_cloudquery_a_declarative/", "subreddit_subscribers": 168560, "created_utc": 1710346685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data fellas, with version 2.1.0 available, we take this opportunity to re-introduce Apache Doris as an open-source data warehouse that provides:\n\n* **Higher out-of-the-box query performance**: 100% faster speed proven by TPC-DS 1TB benchmark tests.\n* **Improved data lake analytics capabilities**: 4\\~6 times faster than Trino and Spark, compatibility with various SQL dialects for smooth migration, read/write interface based on Arrow Flight for 100 times faster data transfer.\n* **Solid support for semi-structured data analysis**: a newly-added Variant data type, support for more IP types, and a more comprehensive suite of analytic functions.\n* **Materialized view with multiple tables**: a new feature to accelerate multi-table joins, allowing transparent rewriting, auto refresh, materialized views of external tables, and direct query.\n* **Enhanced real-time writing efficiency**: faster data writing at scale powered by AUTO\\_INCREMENT column, AUTO PARTITION, forward placement of MemTable, and Group Commit.\n* **Better workload management**: optimizations of the Workload Group mechanism for higher performance stability and the display of SQL resource consumption in the runtime.\n\nThis very informative release note provides details of the performance tests and the implementation of the new features and mechanisms that make the difference. Take a look and tell us what you think!  \n[https://doris.apache.org/blog/release-note-2.1.0](https://doris.apache.org/blog/release-note-2.1.0)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.1.0 is released, with doubled out-of-the-box performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdvhll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710346656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data fellas, with version 2.1.0 available, we take this opportunity to re-introduce Apache Doris as an open-source data warehouse that provides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Higher out-of-the-box query performance&lt;/strong&gt;: 100% faster speed proven by TPC-DS 1TB benchmark tests.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Improved data lake analytics capabilities&lt;/strong&gt;: 4~6 times faster than Trino and Spark, compatibility with various SQL dialects for smooth migration, read/write interface based on Arrow Flight for 100 times faster data transfer.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Solid support for semi-structured data analysis&lt;/strong&gt;: a newly-added Variant data type, support for more IP types, and a more comprehensive suite of analytic functions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Materialized view with multiple tables&lt;/strong&gt;: a new feature to accelerate multi-table joins, allowing transparent rewriting, auto refresh, materialized views of external tables, and direct query.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enhanced real-time writing efficiency&lt;/strong&gt;: faster data writing at scale powered by AUTO_INCREMENT column, AUTO PARTITION, forward placement of MemTable, and Group Commit.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Better workload management&lt;/strong&gt;: optimizations of the Workload Group mechanism for higher performance stability and the display of SQL resource consumption in the runtime.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This very informative release note provides details of the performance tests and the implementation of the new features and mechanisms that make the difference. Take a look and tell us what you think!&lt;br/&gt;\n&lt;a href=\"https://doris.apache.org/blog/release-note-2.1.0\"&gt;https://doris.apache.org/blog/release-note-2.1.0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?auto=webp&amp;s=11ea49814dea9685e2e1f544cfcee4bdcdc37feb", "width": 1800, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5658ef6d8410cc1d396be16a9ecca937def2281", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbbb6f0c25a70f68275b84b06eab33ddd1a92980", "width": 216, "height": 92}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4dd9d38c646f94128d78a2f56086d51d43d0d88", "width": 320, "height": 136}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b1594732efa7e36dc0d8386e059464c620558dbe", "width": 640, "height": 273}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04d781acd91cbcd252e32b196156d5f4276ea2ca", "width": 960, "height": 409}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ac9e97f87dbb83201c28edcdab037a4859ef9f5", "width": 1080, "height": 460}], "variants": {}, "id": "lO_-l9zrS9XOVWUk5oc40xL8UJr9pZxafcbBIwujrOc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bdvhll", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdvhll/apache_doris_210_is_released_with_doubled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdvhll/apache_doris_210_is_released_with_doubled/", "subreddit_subscribers": 168560, "created_utc": 1710346656.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}