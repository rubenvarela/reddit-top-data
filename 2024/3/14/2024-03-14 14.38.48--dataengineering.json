{"kind": "Listing", "data": {"after": "t3_1bdyu6v", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which profession would earn you most money in the long run? I think data analyst salaries usually don\u2019t surpass $200k while DE can make $300k and more. What has been your experience or what have you seen salary wise for DE and DA?", "author_fullname": "t2_kjeptd4cq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs Data Analyst Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdzrkh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710356680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which profession would earn you most money in the long run? I think data analyst salaries usually don\u2019t surpass $200k while DE can make $300k and more. What has been your experience or what have you seen salary wise for DE and DA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bdzrkh", "is_robot_indexable": true, "report_reasons": null, "author": "Mergirl610", "discussion_type": null, "num_comments": 94, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdzrkh/data_engineer_vs_data_analyst_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdzrkh/data_engineer_vs_data_analyst_salary/", "subreddit_subscribers": 168745, "created_utc": 1710356680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm fairly new so I'm trying to gather a consensus on how often your pipelines break and why?\n\nIs it expected that they will eventually break and there's nothing you can do about it? I've heard people say be as defensive in your pipelines as possible?\n\nHow do you get alerted about the breakages?", "author_fullname": "t2_tnf3rfrjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do your pipelines break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be165f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710360042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new so I&amp;#39;m trying to gather a consensus on how often your pipelines break and why?&lt;/p&gt;\n\n&lt;p&gt;Is it expected that they will eventually break and there&amp;#39;s nothing you can do about it? I&amp;#39;ve heard people say be as defensive in your pipelines as possible?&lt;/p&gt;\n\n&lt;p&gt;How do you get alerted about the breakages?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be165f", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Coat5856", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1be165f/how_often_do_your_pipelines_break/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be165f/how_often_do_your_pipelines_break/", "subreddit_subscribers": 168745, "created_utc": 1710360042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Early stage startups can't fund a DE team** obviously - not enough data, time, or money! But startups have a ton of data (stripe, customer, app analytics, finance/payments etc..) generally a better understanding of data. \n\n**So... for you guys:** how can early stage startups make the most of their data in your experience? Is there a way to stitch together all the key data without a large engineering effort? What specific examples have you seen work in your experience? Is this even a data engineering problem or is ad-hoc the way to go? ", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should early stage startups approach data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be7kij", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710375587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Early stage startups can&amp;#39;t fund a DE team&lt;/strong&gt; obviously - not enough data, time, or money! But startups have a ton of data (stripe, customer, app analytics, finance/payments etc..) generally a better understanding of data. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So... for you guys:&lt;/strong&gt; how can early stage startups make the most of their data in your experience? Is there a way to stitch together all the key data without a large engineering effort? What specific examples have you seen work in your experience? Is this even a data engineering problem or is ad-hoc the way to go? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be7kij", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7kij/how_should_early_stage_startups_approach_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7kij/how_should_early_stage_startups_approach_data/", "subreddit_subscribers": 168745, "created_utc": 1710375587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just for all the people out there that are applying for jobs and having difficulty landing anything, keep pushing! \n\nWhen the market picks back up you will be happy that you kept upskilling yourself and you didn\u2019t give up ", "author_fullname": "t2_5q1b2lj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Positive Job Market Outlook", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be05tn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710357640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just for all the people out there that are applying for jobs and having difficulty landing anything, keep pushing! &lt;/p&gt;\n\n&lt;p&gt;When the market picks back up you will be happy that you kept upskilling yourself and you didn\u2019t give up &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be05tn", "is_robot_indexable": true, "report_reasons": null, "author": "Guilty-Commission435", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be05tn/positive_job_market_outlook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be05tn/positive_job_market_outlook/", "subreddit_subscribers": 168745, "created_utc": 1710357640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, founder at Latitude here.\n\nWe spent the last 2 years building software for data teams. After many iterations, we've decided to rebuild everything from scratch and open-source it for the entire community.\n\nLatitude is an open-source framework to create high-quality data apps on top of your database or warehouse using SQL and simple frontend components.\n\nYou can check out the repo here: [https://github.com/latitude-dev/latitude](https://github.com/latitude-dev/latitude)\n\nWe're actively looking for feedback and contributors. Let me know your thoughts!", "author_fullname": "t2_o4qnw2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Latitude: an open-source web framework to build data apps using SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bej704", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710416485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, founder at Latitude here.&lt;/p&gt;\n\n&lt;p&gt;We spent the last 2 years building software for data teams. After many iterations, we&amp;#39;ve decided to rebuild everything from scratch and open-source it for the entire community.&lt;/p&gt;\n\n&lt;p&gt;Latitude is an open-source framework to create high-quality data apps on top of your database or warehouse using SQL and simple frontend components.&lt;/p&gt;\n\n&lt;p&gt;You can check out the repo here: &lt;a href=\"https://github.com/latitude-dev/latitude\"&gt;https://github.com/latitude-dev/latitude&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re actively looking for feedback and contributors. Let me know your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?auto=webp&amp;s=6eebca997ea4d4b55aeb0f760233c0415a0bdf63", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d827756cdde837af4ec07d99725da141bd435f68", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5612dbc3c955b0133b686b2df347ee7160426a8d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d57471adc017d17799740c2e311be154ac893f0c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbdd7b25a13222445010fda16e55f3b9df18a71b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5ff1193415b2a1522056645b8cd2f1bfb564810b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MLNGDePAtO1TbWGm-DIVjUNM2Hh0XLfb52qolN2ITsM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba65964d68ee85a55125b4e94d704ac87a36d2e3", "width": 1080, "height": 540}], "variants": {}, "id": "zRu4yaIX9sS06soWCMlaUqVBLjk_mkvd6UlhzEJIqNY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bej704", "is_robot_indexable": true, "report_reasons": null, "author": "EloquentPickle", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bej704/latitude_an_opensource_web_framework_to_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bej704/latitude_an_opensource_web_framework_to_build/", "subreddit_subscribers": 168745, "created_utc": 1710416485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been data engineer (mostly working on ETLs in cloud environments) for 5 years. I started a new position yesterday in an industry that requires to work on premises. Nothing exists yet, the project starts with me, which is very enthusiastic. \n\nHowever I am a bit lost after 2 days struggling on the stack. Right now I am trying to identify which tools I should use. The load of data isn't that big yet but it's required to make something a bit scalable; that could welcome new sources of data (structured and unstructured)\n\nMy idea is the following : \n\nAirflow as an orchestrator (already have an experience on it), HDFS for a datalake, PySpark scripts for ETL (comfortable on it) , Hive or Presto for datawarehousing, Metabase for viz \n\nTherefore right now I have created docker containers running Spark, HDFS and Airflow. However the more I go further, the more I am doubting. There are so many tools existing for everything and I feel like this stack is a bit oldish ... I've also checked open source versions of Dremio, Cloudera, Iceberg/minIO but I am not sure how suitable it is for a production environment where all the data weighs probably less than 100GB. Also, I'll stay at my position for approx 6 months, I need to make something that would be easily maintained by people who don't work in data engineering field, I feel like Iceberg would be overkill. I sometimes also think about doing easier stuff with pandas/postgres but this is limiting for unstructured data. \n\nI would be glad to receive your opinions about it !\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6d257z60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On premise stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdzyr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710357167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been data engineer (mostly working on ETLs in cloud environments) for 5 years. I started a new position yesterday in an industry that requires to work on premises. Nothing exists yet, the project starts with me, which is very enthusiastic. &lt;/p&gt;\n\n&lt;p&gt;However I am a bit lost after 2 days struggling on the stack. Right now I am trying to identify which tools I should use. The load of data isn&amp;#39;t that big yet but it&amp;#39;s required to make something a bit scalable; that could welcome new sources of data (structured and unstructured)&lt;/p&gt;\n\n&lt;p&gt;My idea is the following : &lt;/p&gt;\n\n&lt;p&gt;Airflow as an orchestrator (already have an experience on it), HDFS for a datalake, PySpark scripts for ETL (comfortable on it) , Hive or Presto for datawarehousing, Metabase for viz &lt;/p&gt;\n\n&lt;p&gt;Therefore right now I have created docker containers running Spark, HDFS and Airflow. However the more I go further, the more I am doubting. There are so many tools existing for everything and I feel like this stack is a bit oldish ... I&amp;#39;ve also checked open source versions of Dremio, Cloudera, Iceberg/minIO but I am not sure how suitable it is for a production environment where all the data weighs probably less than 100GB. Also, I&amp;#39;ll stay at my position for approx 6 months, I need to make something that would be easily maintained by people who don&amp;#39;t work in data engineering field, I feel like Iceberg would be overkill. I sometimes also think about doing easier stuff with pandas/postgres but this is limiting for unstructured data. &lt;/p&gt;\n\n&lt;p&gt;I would be glad to receive your opinions about it !&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdzyr0", "is_robot_indexable": true, "report_reasons": null, "author": "Ruyia31", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdzyr0/on_premise_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdzyr0/on_premise_stack/", "subreddit_subscribers": 168745, "created_utc": 1710357167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4ymkgdql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python requests best practices for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1begg9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ugbrL_EtU52ai4ErXvB2sZD09kEziLG1QVKocyJn93c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710405308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/python-requests-best-practices-for-data-engineers", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?auto=webp&amp;s=fdae695fd5fe2cee64e1fb4a7ec4483c6443e584", "width": 2912, "height": 1632}, "resolutions": [{"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f31260549e9d62ab9efa9beedc3fb6de9b637b1", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=930ed37cb47a4999c9f98a4e2bdb99166c32c43e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0669238db69cae8dcc36a03fc19af9df9df8b54b", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db93ea8d2e717d1b325f1c01272dad51892ecf90", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8b7dcf25cde15dce4e116d09646fd78936820785", "width": 960, "height": 538}, {"url": "https://external-preview.redd.it/FJk0f_J5UBiAK7cHHG5V83ONuOtI-OigwrzjNRbEY1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77bd0feb4c744910ad476681f1a10765dff24509", "width": 1080, "height": 605}], "variants": {}, "id": "dW0cXVdRG0AiMhGU9NGc_dayd_CcrOfYkH0KamIBEUQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1begg9k", "is_robot_indexable": true, "report_reasons": null, "author": "SnooBeans3890", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1begg9k/python_requests_best_practices_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/python-requests-best-practices-for-data-engineers", "subreddit_subscribers": 168745, "created_utc": 1710405308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you guys are using DBT, I would like to know if my approach is good or not.\n\nI am using dbt with bigquery. In same gcp project, I have dataset\\_staging and dataset\\_production. In production target, I use dataset\\_production as source. And for local testing or staging, im using dataset\\_staging. The tables in dataset\\_staging is just the copy of tables from dataset\\_production with limited data from [table sampling](https://cloud.google.com/bigquery/docs/table-sampling).\n\nTo use them as source for a dbt model, this is what I am doing in my source yml:\n\n    sources: \n      - name: some_dataset\n        schema:  \"{{ 'dataset_production' if target.name == \"production\" else 'dataset_staging' }}\"\n        database: gcp_project_id\n        tables:\n         - name: table1\n         - name: table2\n\nI am not sure if this is the standard way. Or am I supposed to use dataset\\_production as source even for local testing and staging purpose? The actual goal is not to scan whole table partition during testing, as each partition is more than 5TB.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_dda8zr28", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT source for production and testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bedblt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710392440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you guys are using DBT, I would like to know if my approach is good or not.&lt;/p&gt;\n\n&lt;p&gt;I am using dbt with bigquery. In same gcp project, I have dataset_staging and dataset_production. In production target, I use dataset_production as source. And for local testing or staging, im using dataset_staging. The tables in dataset_staging is just the copy of tables from dataset_production with limited data from &lt;a href=\"https://cloud.google.com/bigquery/docs/table-sampling\"&gt;table sampling&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;To use them as source for a dbt model, this is what I am doing in my source yml:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sources: \n  - name: some_dataset\n    schema:  &amp;quot;{{ &amp;#39;dataset_production&amp;#39; if target.name == &amp;quot;production&amp;quot; else &amp;#39;dataset_staging&amp;#39; }}&amp;quot;\n    database: gcp_project_id\n    tables:\n     - name: table1\n     - name: table2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I am not sure if this is the standard way. Or am I supposed to use dataset_production as source even for local testing and staging purpose? The actual goal is not to scan whole table partition during testing, as each partition is more than 5TB.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?auto=webp&amp;s=b3c1793ddfb0595cba1bbb23fba79360953beb8d", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0329d4207ada0345185e70a97a0ef1f27aec034", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8722bf8052baa4647e96ebeb0d22f50bf529b6ac", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6562c4a330763746058f2250630ec6d3854b2e3d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fff0deae054d2476ac870508887dbbee06d9387c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6a32be275833b4d47802b79f3345f568bd43a4d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/hHuPbOBuX42Zu5_MT0rir3JO7cgRTfjn0ct4UWuqTu4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97e8d6d94b95697d64482f5fcda32d11814df7b8", "width": 1080, "height": 567}], "variants": {}, "id": "DsiOIzUSicS_9zIKwMDQbNT2LOE1o29sSYs49HAmO_k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bedblt", "is_robot_indexable": true, "report_reasons": null, "author": "seeker114", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bedblt/dbt_source_for_production_and_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bedblt/dbt_source_for_production_and_testing/", "subreddit_subscribers": 168745, "created_utc": 1710392440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019m in analytics and one of the seniors must have been high or something because he ended up deleting the Master dataset from the  project.\n\nThe dataset had over 5000 tables that were used across the board. \n\nMost of the teams are panicking and there is a lot of chaos. Online articles and StackOverFlow don\u2019t help.\n\nIs there a way to restore it because we might lose the client at this rate? \n\nSample id of a table: \u2018project.Master.table1\u2019", "author_fullname": "t2_5hvalgp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to recover a deleted dataset from BigQuery? (Urgent)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bekue2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710421925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019m in analytics and one of the seniors must have been high or something because he ended up deleting the Master dataset from the  project.&lt;/p&gt;\n\n&lt;p&gt;The dataset had over 5000 tables that were used across the board. &lt;/p&gt;\n\n&lt;p&gt;Most of the teams are panicking and there is a lot of chaos. Online articles and StackOverFlow don\u2019t help.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to restore it because we might lose the client at this rate? &lt;/p&gt;\n\n&lt;p&gt;Sample id of a table: \u2018project.Master.table1\u2019&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bekue2", "is_robot_indexable": true, "report_reasons": null, "author": "honpra", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bekue2/how_to_recover_a_deleted_dataset_from_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bekue2/how_to_recover_a_deleted_dataset_from_bigquery/", "subreddit_subscribers": 168745, "created_utc": 1710421925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What services do you recommend to make this migration as fast and smooth as possible, just once? First though is glue (used before but different purpose), or DMS service (have not never used it).ed daily, storing only 90 days. This is one of the problems of the migration, that querying from it is impossible my first approach was with a simple lambda, MySQL connector, and python script and chunk it, but would take me about 2 days if I do that. Also, the idea is to have this data somewhere else before thinking of a Lakehouse solution. My questions are:  \n\n\n* What ETL do you propose to make this process daily (1.5M records) comes to glue again if i am succesfull with the first bullet pointe but for different purposes), or DMS service (have not never used it).\n* What ETL do you propose to make this process daily (1.5M records) come to glue again if I am succesfull with the first bullet point\n* Lastly, this data is desired to be used for analytics, initially will be in S3 to make queries using Athena while the team gains an idea about the KPIs they want to track, in the future the idea is to have it somewhere else (I though of a lakehouse) that makes it fast to query and build sql models with it. The whole company env. is in AWS so my first thought is RedShift but I like the efficiency and how GBQ handles this amount of data\n\nThank you so much for reading!", "author_fullname": "t2_42yrzhea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDS to S3 migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be7oi7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710375876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What services do you recommend to make this migration as fast and smooth as possible, just once? First though is glue (used before but different purpose), or DMS service (have not never used it).ed daily, storing only 90 days. This is one of the problems of the migration, that querying from it is impossible my first approach was with a simple lambda, MySQL connector, and python script and chunk it, but would take me about 2 days if I do that. Also, the idea is to have this data somewhere else before thinking of a Lakehouse solution. My questions are:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What ETL do you propose to make this process daily (1.5M records) comes to glue again if i am succesfull with the first bullet pointe but for different purposes), or DMS service (have not never used it).&lt;/li&gt;\n&lt;li&gt;What ETL do you propose to make this process daily (1.5M records) come to glue again if I am succesfull with the first bullet point&lt;/li&gt;\n&lt;li&gt;Lastly, this data is desired to be used for analytics, initially will be in S3 to make queries using Athena while the team gains an idea about the KPIs they want to track, in the future the idea is to have it somewhere else (I though of a lakehouse) that makes it fast to query and build sql models with it. The whole company env. is in AWS so my first thought is RedShift but I like the efficiency and how GBQ handles this amount of data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you so much for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1be7oi7", "is_robot_indexable": true, "report_reasons": null, "author": "josejo9423", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7oi7/rds_to_s3_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7oi7/rds_to_s3_migration/", "subreddit_subscribers": 168745, "created_utc": 1710375876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data fellas, with version 2.1.0 available, we take this opportunity to re-introduce Apache Doris as an open-source data warehouse that provides:\n\n* **Higher out-of-the-box query performance**: 100% faster speed proven by TPC-DS 1TB benchmark tests.\n* **Improved data lake analytics capabilities**: 4\\~6 times faster than Trino and Spark, compatibility with various SQL dialects for smooth migration, read/write interface based on Arrow Flight for 100 times faster data transfer.\n* **Solid support for semi-structured data analysis**: a newly-added Variant data type, support for more IP types, and a more comprehensive suite of analytic functions.\n* **Materialized view with multiple tables**: a new feature to accelerate multi-table joins, allowing transparent rewriting, auto refresh, materialized views of external tables, and direct query.\n* **Enhanced real-time writing efficiency**: faster data writing at scale powered by AUTO\\_INCREMENT column, AUTO PARTITION, forward placement of MemTable, and Group Commit.\n* **Better workload management**: optimizations of the Workload Group mechanism for higher performance stability and the display of SQL resource consumption in the runtime.\n\nThis very informative release note provides details of the performance tests and the implementation of the new features and mechanisms that make the difference. Take a look and tell us what you think!  \n[https://doris.apache.org/blog/release-note-2.1.0](https://doris.apache.org/blog/release-note-2.1.0)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.1.0 is released, with doubled out-of-the-box performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdvhll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710346656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data fellas, with version 2.1.0 available, we take this opportunity to re-introduce Apache Doris as an open-source data warehouse that provides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Higher out-of-the-box query performance&lt;/strong&gt;: 100% faster speed proven by TPC-DS 1TB benchmark tests.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Improved data lake analytics capabilities&lt;/strong&gt;: 4~6 times faster than Trino and Spark, compatibility with various SQL dialects for smooth migration, read/write interface based on Arrow Flight for 100 times faster data transfer.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Solid support for semi-structured data analysis&lt;/strong&gt;: a newly-added Variant data type, support for more IP types, and a more comprehensive suite of analytic functions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Materialized view with multiple tables&lt;/strong&gt;: a new feature to accelerate multi-table joins, allowing transparent rewriting, auto refresh, materialized views of external tables, and direct query.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enhanced real-time writing efficiency&lt;/strong&gt;: faster data writing at scale powered by AUTO_INCREMENT column, AUTO PARTITION, forward placement of MemTable, and Group Commit.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Better workload management&lt;/strong&gt;: optimizations of the Workload Group mechanism for higher performance stability and the display of SQL resource consumption in the runtime.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This very informative release note provides details of the performance tests and the implementation of the new features and mechanisms that make the difference. Take a look and tell us what you think!&lt;br/&gt;\n&lt;a href=\"https://doris.apache.org/blog/release-note-2.1.0\"&gt;https://doris.apache.org/blog/release-note-2.1.0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?auto=webp&amp;s=11ea49814dea9685e2e1f544cfcee4bdcdc37feb", "width": 1800, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5658ef6d8410cc1d396be16a9ecca937def2281", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbbb6f0c25a70f68275b84b06eab33ddd1a92980", "width": 216, "height": 92}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4dd9d38c646f94128d78a2f56086d51d43d0d88", "width": 320, "height": 136}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b1594732efa7e36dc0d8386e059464c620558dbe", "width": 640, "height": 273}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04d781acd91cbcd252e32b196156d5f4276ea2ca", "width": 960, "height": 409}, {"url": "https://external-preview.redd.it/txa-yKDhLL1PUJDzydQrqFFgkFwOucMpxhL-PhabCZs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ac9e97f87dbb83201c28edcdab037a4859ef9f5", "width": 1080, "height": 460}], "variants": {}, "id": "lO_-l9zrS9XOVWUk5oc40xL8UJr9pZxafcbBIwujrOc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bdvhll", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdvhll/apache_doris_210_is_released_with_doubled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdvhll/apache_doris_210_is_released_with_doubled/", "subreddit_subscribers": 168745, "created_utc": 1710346656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short, we are trying to keep company tools in sync. today it is a mess that comes to bite on the data end as it creates low trust in data quality. \n\nNow some tools have native integrations, which makes things easy, but for some reason, the toolset that our company settled on does not have this (outside of a few mainstream apps)\n\nThe way I see it we have three options \n\n1. Build our integrations between tools and/or integrations between our warehouse and the tools (reverse ETL), seems like lots of work to build and then maintain \n2. Use an IPaaS solution, here I would have to have someone learn the tool as each one of these tools usually uses some proprietary way of doing things. \n3. Reverse ETL tool, this is new to me, haven't really worked with one in the past but I had a call [Hightouch](https://hightouch.com)Reverse ETL tool this is new to me, I haven't really worked with one in the past, but I had a call with Hightouch, and it seems promising. It seems to fit the data team a bit better than the other 2 options as most of the work will be done within warehouse dbt transformations, which anyone in the team can do   \n\n\nAny recommendations on how to tackle this? Have you guys worked with a Reverse ETL tool? If yes which one and what's your feedback   ", "author_fullname": "t2_et5t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping org tools in sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdtjwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710345886.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710341933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, we are trying to keep company tools in sync. today it is a mess that comes to bite on the data end as it creates low trust in data quality. &lt;/p&gt;\n\n&lt;p&gt;Now some tools have native integrations, which makes things easy, but for some reason, the toolset that our company settled on does not have this (outside of a few mainstream apps)&lt;/p&gt;\n\n&lt;p&gt;The way I see it we have three options &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Build our integrations between tools and/or integrations between our warehouse and the tools (reverse ETL), seems like lots of work to build and then maintain &lt;/li&gt;\n&lt;li&gt;Use an IPaaS solution, here I would have to have someone learn the tool as each one of these tools usually uses some proprietary way of doing things. &lt;/li&gt;\n&lt;li&gt;Reverse ETL tool, this is new to me, haven&amp;#39;t really worked with one in the past but I had a call &lt;a href=\"https://hightouch.com\"&gt;Hightouch&lt;/a&gt;Reverse ETL tool this is new to me, I haven&amp;#39;t really worked with one in the past, but I had a call with Hightouch, and it seems promising. It seems to fit the data team a bit better than the other 2 options as most of the work will be done within warehouse dbt transformations, which anyone in the team can do&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any recommendations on how to tackle this? Have you guys worked with a Reverse ETL tool? If yes which one and what&amp;#39;s your feedback   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?auto=webp&amp;s=9536c052f365bbf3762edff656ecbf9ff1c87a20", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e45b525dae7b055f04a99a6162ace736c384fa2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2e6bd7eefa3c34e35b0df80988a8a58b5b1d59b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa1a6445448c2ef5897ecf6c2d3fd479726852de", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6b29ff2c57ada4dd2f2173db2c1e92121437df1", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=45d6c4070a6154d439799678966846f8386890d0", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/e2zr64aeoKu278JwUBIbJMJtWwUamHqB3kdv3BiB0j4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=311daa8b857a8795d13fd2269b9cb5eff88c4ab6", "width": 1080, "height": 565}], "variants": {}, "id": "7X-6dPLJU2TmqoD0kEsCB8XE26QEVlx0zliDnH3JJLc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bdtjwb", "is_robot_indexable": true, "report_reasons": null, "author": "MrGreenPL", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdtjwb/keeping_org_tools_in_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdtjwb/keeping_org_tools_in_sync/", "subreddit_subscribers": 168745, "created_utc": 1710341933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nPlease give me any suggestions what will be the best way to redesign this data pipeline, to ingest data from the BI tool back to the source table in Snowflake.  \nCurrent setup:\n\nhttps://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267\n\n I have a Google spreadsheet that is transformed daily with DBT and stored in Snowflake DB as a mart-ready table for analysis. This table undergoes a full refresh daily. Later, this table is connected to the BI tool where Data Analysts analyze the data. However, they now want to manually input data in Power BI so that this data will be saved in the initial source table in Snowflake.\n\nHow should I approach this, considering that the initial table is refreshed daily? I'm thinking of changing DBT materialization to incremental or creating a new extra table in Snowflake that will be a combination of raw source data and input from BI. Maybe there is a better way yo do it?  \n", "author_fullname": "t2_2odyjk2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redesign ETL process, DBT table materialization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": false, "media_metadata": {"94pdir9f16oc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 31, "x": 108, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cfbf74ade92410d88497db8af9b8ca27c372c2d"}, {"y": 62, "x": 216, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=193da8daaf9a56362353b507bc96cbfb62728b22"}, {"y": 92, "x": 320, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0755624e597482769b696c4eca8f753b2b873a4f"}, {"y": 184, "x": 640, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=acf0061a8c4917dd169a02a9982c1ba70cf35117"}, {"y": 276, "x": 960, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee2b256c89aa02600584f6bec6d9bda5d9b096aa"}, {"y": 311, "x": 1080, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c4ad491af8a3239eb5ef8e96e103cfaa068ff6ea"}], "s": {"y": 316, "x": 1096, "u": "https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267"}, "id": "94pdir9f16oc1"}}, "name": "t3_1be395d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/63jK-_OvQUavcQrCcrDL58R0CJs6FkXm08oDXfbz9Ac.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710364982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Please give me any suggestions what will be the best way to redesign this data pipeline, to ingest data from the BI tool back to the source table in Snowflake.&lt;br/&gt;\nCurrent setup:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267\"&gt;https://preview.redd.it/94pdir9f16oc1.png?width=1096&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f3c45506cf2a3c288d780fead9f33d979e3267&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a Google spreadsheet that is transformed daily with DBT and stored in Snowflake DB as a mart-ready table for analysis. This table undergoes a full refresh daily. Later, this table is connected to the BI tool where Data Analysts analyze the data. However, they now want to manually input data in Power BI so that this data will be saved in the initial source table in Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this, considering that the initial table is refreshed daily? I&amp;#39;m thinking of changing DBT materialization to incremental or creating a new extra table in Snowflake that will be a combination of raw source data and input from BI. Maybe there is a better way yo do it?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1be395d", "is_robot_indexable": true, "report_reasons": null, "author": "Krukach", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be395d/redesign_etl_process_dbt_table_materialization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be395d/redesign_etl_process_dbt_table_materialization/", "subreddit_subscribers": 168745, "created_utc": 1710364982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm organizing a workshop next Tuesday, March 19, 2024, at 4 PM Pacific Time. During this workshop, instructors will build a real-time dashboard for analyzing pizza shop orders using OSS products: Bytewax, Pinot, and Streamlit.\nFor more details and to RSVP (attendance is free), please visit:\nhttps://bytewax.io/events/real-time-pizza-analytics\n\nI believe this workshop is especially noteworthy for those interested, as I've personally enjoyed migrating the previous solution from Kafka Streams to Bytewax. The solution is now more Python-friendly and the complexity of the codebase is significantly reduced. For me, it felt truly refreshing to rewrite it \ud83d\ude04 I believe many data engineers would prefer Python solutions over JVM based.\n\nI am still in the process of updating the repository and will share it later, but here is the previous version:\nhttps://dev.startree.ai/docs/pinot/demo-apps/pizza-shop", "author_fullname": "t2_zus64vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Workshop: Real time data streaming + Analytics + Visualization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2xai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710364229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m organizing a workshop next Tuesday, March 19, 2024, at 4 PM Pacific Time. During this workshop, instructors will build a real-time dashboard for analyzing pizza shop orders using OSS products: Bytewax, Pinot, and Streamlit.\nFor more details and to RSVP (attendance is free), please visit:\n&lt;a href=\"https://bytewax.io/events/real-time-pizza-analytics\"&gt;https://bytewax.io/events/real-time-pizza-analytics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I believe this workshop is especially noteworthy for those interested, as I&amp;#39;ve personally enjoyed migrating the previous solution from Kafka Streams to Bytewax. The solution is now more Python-friendly and the complexity of the codebase is significantly reduced. For me, it felt truly refreshing to rewrite it \ud83d\ude04 I believe many data engineers would prefer Python solutions over JVM based.&lt;/p&gt;\n\n&lt;p&gt;I am still in the process of updating the repository and will share it later, but here is the previous version:\n&lt;a href=\"https://dev.startree.ai/docs/pinot/demo-apps/pizza-shop\"&gt;https://dev.startree.ai/docs/pinot/demo-apps/pizza-shop&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?auto=webp&amp;s=9710ac602cc3d55cdc3483c30610f0d6cec287c7", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=be1e5d4935c553e543ed40f9063b0890186f9b65", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc522633caa9ca91f4222971361ed6867641bdfa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a14311bc251f6667bef9851c488608dafcfda35f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa1a7d640b445b93da6892292643b670a9e21ecd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=55556a2666f8268a495d077ff92ee5135aa6ee4b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zuVRsJ0ECO_zQVLsE5M031bHRfIX625iDDAqcBQ9y-0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c3598d6efc61818791e553aabc53f37918820c8", "width": 1080, "height": 607}], "variants": {}, "id": "kpggDHbug4GLpb_LymyREbDxwQCTGOuosNWiRAKAgVg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1be2xai", "is_robot_indexable": true, "report_reasons": null, "author": "oli_k", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2xai/virtual_workshop_real_time_data_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2xai/virtual_workshop_real_time_data_streaming/", "subreddit_subscribers": 168745, "created_utc": 1710364229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Link](https://www.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/) to the initial post. Posting this again after debugging. Since this is my first project, I appreciate your feedback on anything; be it Github readme, dashboard, etc.\n\n&amp;#x200B;\n\nLeveraging Schipol Dev API, I've built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard [here](https://aeroatlas.streamlit.app/). I'd love your feedback, suggestions, and opinions to enhance this data-driven journey! Also find the Github repo [here](https://github.com/suleman1412/schipol_flights_pipeline).\n\n&amp;#x200B;", "author_fullname": "t2_rw01dudv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updated: Just launched my first data engineering project!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdv1xv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710345609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/1b9hnn0/just_launched_my_first_data_engineering_project/\"&gt;Link&lt;/a&gt; to the initial post. Posting this again after debugging. Since this is my first project, I appreciate your feedback on anything; be it Github readme, dashboard, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Leveraging Schipol Dev API, I&amp;#39;ve built an interactive dashboard for flight data, while also fetching datasets from various sources stored in GCS Bucket. Using Google Cloud, Big Query, and MageAI for orchestration, the pipeline runs via Docker containers on a VM, scheduled as a cron job for market hours automation. Check out the dashboard &lt;a href=\"https://aeroatlas.streamlit.app/\"&gt;here&lt;/a&gt;. I&amp;#39;d love your feedback, suggestions, and opinions to enhance this data-driven journey! Also find the Github repo &lt;a href=\"https://github.com/suleman1412/schipol_flights_pipeline\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?auto=webp&amp;s=ede95ca400f22e057dffa04ff31de469ef538d82", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d897456f2eb1ccf0e4332fe0dc9bbf31d8785cf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ca7b49d3f21a52a175276cb6e52c44193295a8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e17c7da02f04519c29ac1a7849ad490919346c10", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d3f6fc21cae9cd51c7d0c363e2684ea79774a5f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54ecbc0a8baed2ce0f49d6dab5807c120ec0cdd5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/si4P21UOvS9TAaZ4KOfpz1zheQBJHRDt6_8fbxfWfh4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=465c26e0a14bb5641bcce7b228b1b687029074bc", "width": 1080, "height": 567}], "variants": {}, "id": "QDBuNMj6jujXmJHrzKao8hw5SfNdcufBYQsaXgPrC7Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1bdv1xv", "is_robot_indexable": true, "report_reasons": null, "author": "botuleman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdv1xv/updated_just_launched_my_first_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdv1xv/updated_just_launched_my_first_data_engineering/", "subreddit_subscribers": 168745, "created_utc": 1710345609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I am working as an Informatica developer with a  total of 7 yr of experience but now I think my career is not progressing as much. Please guide me what should i do next...TIA. ", "author_fullname": "t2_dwbp6nww0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica : career help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1beg9e1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710404461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I am working as an Informatica developer with a  total of 7 yr of experience but now I think my career is not progressing as much. Please guide me what should i do next...TIA. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1beg9e1", "is_robot_indexable": true, "report_reasons": null, "author": "amorcita_fishy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1beg9e1/informatica_career_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1beg9e1/informatica_career_help/", "subreddit_subscribers": 168745, "created_utc": 1710404461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n&amp;#x200B;\n\n# How to integrate Great Expecation Data Quality tests in Airflow?\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1) Orchestrate Modern Data Stack\n\nVlog on how to how to integrate Great Expectation Data Quality tests in the Apache Airflow.  We use the Great Expectation (GE) provider for Airlow and run the Great Expectations suite. The target data asset is a PostgreSQL table.  We use Airflow as the orchestrator for the ETL (ELT) Data piepline and GE as the testing framework\n\n[https://www.youtube.com/watch?v=WAgbFrHUk50](https://www.youtube.com/watch?v=WAgbFrHUk50)\n\nTopics covered:\n\n* Data Orchestartion\n* Airflow &amp; DAG\n* Airflow GE Provider\n* Run Modern Data Stack with Airflow\n\nTech Stack: **Airflow, Great Expecations, Data Quality, Python**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate Great Expecation Data Quality tests in Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be2kwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710363424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;How to integrate Great Expecation Data Quality tests in Airflow?&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; Orchestrate Modern Data Stack&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to how to integrate Great Expectation Data Quality tests in the Apache Airflow.  We use the Great Expectation (GE) provider for Airlow and run the Great Expectations suite. The target data asset is a PostgreSQL table.  We use Airflow as the orchestrator for the ETL (ELT) Data piepline and GE as the testing framework&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=WAgbFrHUk50\"&gt;https://www.youtube.com/watch?v=WAgbFrHUk50&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Orchestartion&lt;/li&gt;\n&lt;li&gt;Airflow &amp;amp; DAG&lt;/li&gt;\n&lt;li&gt;Airflow GE Provider&lt;/li&gt;\n&lt;li&gt;Run Modern Data Stack with Airflow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, Great Expecations, Data Quality, Python&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?auto=webp&amp;s=1f9fac17204c854b5b4d082002059c44d5ae03ed", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8be4ceb1eb56baade4c73afe89f795ba729582c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a24799e256cfd2e1a27df43a0bac89db7a456ad0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/b8HcC71hUZBtsg4TiNqi6bKNvIzjnyg76TIZCCp-XyA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb45dfe184a212d81531e5227e21e5f5f95a26b2", "width": 320, "height": 240}], "variants": {}, "id": "TSidoV9hmIfyC3VVXAqXTE2OWfjCP7yrcSm4ForS6lE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1be2kwd", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be2kwd/how_to_integrate_great_expecation_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be2kwd/how_to_integrate_great_expecation_data_quality/", "subreddit_subscribers": 168745, "created_utc": 1710363424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI've been thinking a lot about how we, as data professionals, are tackling data adoption hurdles, especially in areas like drug development and personalized medicine (Life Sciences); so I wrote this article. \n\n[https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare](https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare)\n\nAre you facing similar challenges? How are you managing them, and what strategies or tools have made a difference in your work?\n\nReally curious to hear if your experiences align with mine and how you're navigating this complex landscape.", "author_fullname": "t2_fosm1pwyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data in Life Sciences: Are We on the Same Page?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be1kpo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710361010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking a lot about how we, as data professionals, are tackling data adoption hurdles, especially in areas like drug development and personalized medicine (Life Sciences); so I wrote this article. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare\"&gt;https://www.datacoves.com/post/benefits-of-digital-transformation-in-healthcare&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Are you facing similar challenges? How are you managing them, and what strategies or tools have made a difference in your work?&lt;/p&gt;\n\n&lt;p&gt;Really curious to hear if your experiences align with mine and how you&amp;#39;re navigating this complex landscape.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?auto=webp&amp;s=91c90fdf2875134891d193f444905b830d0864da", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e5046c0a3229b2e9e21ed3054b87f1903055596", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86c79bee66d97e1e8dcb050394863d568359d343", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b69b996d84839071da5ae484eb249679d4b969d", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b2237495e1c0a2c721481a18987c1e1e4940a2a4", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ce5da23d057f738322d8874cda1f5d036e44aef", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/iIxtwAsUPqXntMCgJDyGLsViZ9LLJ_2mJ5bVdjpBJAc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd322b26a9ac0c1761783fa0722662cb6b7dd90e", "width": 1080, "height": 564}], "variants": {}, "id": "9AKl43XPJbE9__vNApnXsZxefA6nyXZTbapru4_2mhE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1be1kpo", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Queen-Mayra", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be1kpo/data_in_life_sciences_are_we_on_the_same_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be1kpo/data_in_life_sciences_are_we_on_the_same_page/", "subreddit_subscribers": 168745, "created_utc": 1710361010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa5dw92do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No More Surprises in Snowflake with Resource Monitors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 112, "top_awarded_type": null, "hide_score": true, "name": "t3_1beluak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QUxQS5-rJxsw4DNxTxU7vEO2v0bGx0prGYgZ550Vmv4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710424812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "baselit.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://baselit.ai/blog/no-more-surprises-in-snowflake-with-resource-monitors", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?auto=webp&amp;s=9d70cb747b97f736c5749073351847050f654940", "width": 1828, "height": 1466}, "resolutions": [{"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4bf59d16f8fc9b692ac26079b45b88b4a21e130", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a84b5b366df305c86f82e82d723c6354b9a4c3f", "width": 216, "height": 173}, {"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=759df7bf918a8c2ad35d5c3c8937c5d1ae47350e", "width": 320, "height": 256}, {"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4cbfd111553670f4f1d525ce062ab29ec1e80a4", "width": 640, "height": 513}, {"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d28a7e1aad9a673cd5ed34737de34b61f6f3cc8e", "width": 960, "height": 769}, {"url": "https://external-preview.redd.it/DDjJfmOLWdeegYWitTOLo-mfj1aGXABtsoRN8i9Ucbc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=154ce76085e2b80e2cb67a1befa6280b9f92bd4b", "width": 1080, "height": 866}], "variants": {}, "id": "WzHO6PPFvUncmnSdaLnK2OQyIu_HZYxmeHYRP8-VEDY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1beluak", "is_robot_indexable": true, "report_reasons": null, "author": "sahil_singla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1beluak/no_more_surprises_in_snowflake_with_resource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://baselit.ai/blog/no-more-surprises-in-snowflake-with-resource-monitors", "subreddit_subscribers": 168745, "created_utc": 1710424812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I once worked with a team who was in charge of some sales dashboards. Their process to update them was to have someone individually open the PDF's of every new invoice for the week, enter the dollar figures into an excel sheet, and then update the workbook  datasource with the new static excel file.\n\nI work for a global market leader, we are lapping the #2 company behind us 5 times over. I would estimate that 5-10% of our headcount is allocated to jobs like these.", "author_fullname": "t2_t1bnfnc4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the hardest you have ever seen someone work manually?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1beltlg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710425040.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710424759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I once worked with a team who was in charge of some sales dashboards. Their process to update them was to have someone individually open the PDF&amp;#39;s of every new invoice for the week, enter the dollar figures into an excel sheet, and then update the workbook  datasource with the new static excel file.&lt;/p&gt;\n\n&lt;p&gt;I work for a global market leader, we are lapping the #2 company behind us 5 times over. I would estimate that 5-10% of our headcount is allocated to jobs like these.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1beltlg", "is_robot_indexable": true, "report_reasons": null, "author": "bjogc42069", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1beltlg/what_is_the_hardest_you_have_ever_seen_someone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1beltlg/what_is_the_hardest_you_have_ever_seen_someone/", "subreddit_subscribers": 168745, "created_utc": 1710424759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.twingdata.com/p/identify-unused-columns-in-snowflake](https://blog.twingdata.com/p/identify-unused-columns-in-snowflake)\n\n  \nTLDR: If you're on enterprise Snowflake you can do it via a query. Otherwise there's a simple Python script that uses the sqlglot library to extract the physical columns and compares them against the info schema.  \n", "author_fullname": "t2_bp7tn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query + Script to identify unused columns in Snowflake and other data warehouses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1belgv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710423768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.twingdata.com/p/identify-unused-columns-in-snowflake\"&gt;https://blog.twingdata.com/p/identify-unused-columns-in-snowflake&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TLDR: If you&amp;#39;re on enterprise Snowflake you can do it via a query. Otherwise there&amp;#39;s a simple Python script that uses the sqlglot library to extract the physical columns and compares them against the info schema.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kc11xEfZAOJu-BtArNsgWQ9LLjxJL2VhgTlA7RmWrw4.jpg?auto=webp&amp;s=7a9fd4cbac369bdf44c0932caf089f3acf4f0183", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/kc11xEfZAOJu-BtArNsgWQ9LLjxJL2VhgTlA7RmWrw4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95df4917027026cfacaa016b5e3dba6ac427e5a1", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/kc11xEfZAOJu-BtArNsgWQ9LLjxJL2VhgTlA7RmWrw4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=798883132e928a3b65e3ac750e786fe2200c8ec5", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/kc11xEfZAOJu-BtArNsgWQ9LLjxJL2VhgTlA7RmWrw4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3e3d4248e553427fdc1d7972039b469fc247f84", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/kc11xEfZAOJu-BtArNsgWQ9LLjxJL2VhgTlA7RmWrw4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3cfb65a334b8b1c97d00db9a89200396f1cad03f", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/kc11xEfZAOJu-BtArNsgWQ9LLjxJL2VhgTlA7RmWrw4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d219b01314c5718db4f8d8186a6272a0846572c", "width": 960, "height": 562}], "variants": {}, "id": "3CvJ-CSBlahwziE_SAyoY8Vwk75zbSq4MidCUoIDcOI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1belgv1", "is_robot_indexable": true, "report_reasons": null, "author": "dangoldin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1belgv1/query_script_to_identify_unused_columns_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1belgv1/query_script_to_identify_unused_columns_in/", "subreddit_subscribers": 168745, "created_utc": 1710423768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Like title says.\n\nWhen do you feel that it is a time to move next company? Here is a list that I can think of\n\n- want to play with different type of data\n- hard to get promotion\n- not learning much\n- your function is less appreciated in the org\n- stayed one place too long\n- just want to try something new\n- want to relax and not working crazy\n\n\nI have been with one startup about 5 years. Working with decent size of data with Python, airflow, snowflake, spark, aws, k8s, docker, etc.\n\nI have been putting a lot of effort in this company although I'm at lower level. Several rounds of layoffs happened over the last 2 years and my team lost more than half.\n\nAlso a few of good team members left while company's revenue is still growing decently. Salary is lower side of median band.\n\nI still don't know which sector I want to try, but want to hear from other DE's when they decide to move. Do you have your own indicator? Or mostly goes with your feelings?", "author_fullname": "t2_ub3cyaaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When do you feel to move next?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be9w0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710381987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like title says.&lt;/p&gt;\n\n&lt;p&gt;When do you feel that it is a time to move next company? Here is a list that I can think of&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;want to play with different type of data&lt;/li&gt;\n&lt;li&gt;hard to get promotion&lt;/li&gt;\n&lt;li&gt;not learning much&lt;/li&gt;\n&lt;li&gt;your function is less appreciated in the org&lt;/li&gt;\n&lt;li&gt;stayed one place too long&lt;/li&gt;\n&lt;li&gt;just want to try something new&lt;/li&gt;\n&lt;li&gt;want to relax and not working crazy&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have been with one startup about 5 years. Working with decent size of data with Python, airflow, snowflake, spark, aws, k8s, docker, etc.&lt;/p&gt;\n\n&lt;p&gt;I have been putting a lot of effort in this company although I&amp;#39;m at lower level. Several rounds of layoffs happened over the last 2 years and my team lost more than half.&lt;/p&gt;\n\n&lt;p&gt;Also a few of good team members left while company&amp;#39;s revenue is still growing decently. Salary is lower side of median band.&lt;/p&gt;\n\n&lt;p&gt;I still don&amp;#39;t know which sector I want to try, but want to hear from other DE&amp;#39;s when they decide to move. Do you have your own indicator? Or mostly goes with your feelings?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1be9w0z", "is_robot_indexable": true, "report_reasons": null, "author": "winderous", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be9w0z/when_do_you_feel_to_move_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be9w0z/when_do_you_feel_to_move_next/", "subreddit_subscribers": 168745, "created_utc": 1710381987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a traditional backend engineer with lots of cloud experience and I'm interested in making a transition to the AI/ML world and I think a lot of my experience could be applicable best towards the aforementioned roles.\n\nFrom my limited research so far my understanding is that data engineers don't necessarily work with ML or even data science teams but just data in general whereas MLOps/ML platform/ML infrastructure engineers require a good understanding of ML and work on the entire ML-lifecycle infrastructure which may or may not include ETL pipelines. Did I get it right? What's your perspective?", "author_fullname": "t2_syp7tbbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering vs MLOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be7ccx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710375000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a traditional backend engineer with lots of cloud experience and I&amp;#39;m interested in making a transition to the AI/ML world and I think a lot of my experience could be applicable best towards the aforementioned roles.&lt;/p&gt;\n\n&lt;p&gt;From my limited research so far my understanding is that data engineers don&amp;#39;t necessarily work with ML or even data science teams but just data in general whereas MLOps/ML platform/ML infrastructure engineers require a good understanding of ML and work on the entire ML-lifecycle infrastructure which may or may not include ETL pipelines. Did I get it right? What&amp;#39;s your perspective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1be7ccx", "is_robot_indexable": true, "report_reasons": null, "author": "Low-Associate2521", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be7ccx/data_engineering_vs_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be7ccx/data_engineering_vs_mlops/", "subreddit_subscribers": 168745, "created_utc": 1710375000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined this company two years ago with next to no experience in data. I did some self-learning 6 months prior to joining and I already had some experience with Python from college, but that was it.\n\nOver the first year I was essentially a data analyst with &lt;5% data science work. I worked with controls engineers to get data off the equipment and into SQL tables. From there I built out dashboards in Power BI that showed relatively real-time metrics out on the shop floor. I then started to build out tables/queries to aggregate that data and send out daily reports. During this time I was learning a lot and honestly having a blast.\n\nAfter the dashboards I did some dabbling with condition monitoring sensors to try to drive towards predictive maintenance solutions. This totally flopped, we just didn't know enough about predictive maintenance and the sensors/math required to make a viable production ready solution.\n\nThe next year, I had the opportunity to dabble in Azure to better understand how we could bring some of this production/machine data into the cloud. This would help the business bring all our data sources together in the future. I dabbled in ADF, Azure Stream Analytics, and a few other Azure tools.  But my knowledge felt half-baked and disconnected. \n\nSince then I've basically hit a brick wall. Systems were changing, equipment was moving, and I was still a sole employee working alone in manufacturing. We began switching our ERP to Oracle so ERP data has essentially been off limits for me while IT works. It was bad data to begin with. then we wanted to start using a historian for manufacturing data so I again had to wait for IT to make implementations. Now, I'm at a point where I feel trapped. The historian is cool but ultimately does not allow me to learn traditional data engineering techniques/tools, the PLC programmers have limited time so I can't get new data from them, and extracting data from other data sources is something that IT likes to keep for themselves since I fall under the \"operations\" bucket. \n\nI'm alone, feel like I have very little mentorship in this space, and see roadblocks in nearly every direction. However, I can tell my director has a significant amount of trust in me. She always asks for my input to provide feedback to a \"global I4.0 committee\" that is forming. Additionally, she seems open to me getting professional training but data engineering in manufacturing feels super niche. It feels like normal courses don't apply. Networking, the tools used, etc are all different and create a unique set of problems.\n\nHow do I continue to develop? I like DE and may even see myself as a good software engineer in the future (not sure how common that switch happens), but as of right now I'm learning a totally different skillset and I'm unsure how many years it will be before a true \"data team\" exists that I could learn from in the manufacturing space.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I progress my career working in manufacturing? Look for something new or wait it out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1be75eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710374509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined this company two years ago with next to no experience in data. I did some self-learning 6 months prior to joining and I already had some experience with Python from college, but that was it.&lt;/p&gt;\n\n&lt;p&gt;Over the first year I was essentially a data analyst with &amp;lt;5% data science work. I worked with controls engineers to get data off the equipment and into SQL tables. From there I built out dashboards in Power BI that showed relatively real-time metrics out on the shop floor. I then started to build out tables/queries to aggregate that data and send out daily reports. During this time I was learning a lot and honestly having a blast.&lt;/p&gt;\n\n&lt;p&gt;After the dashboards I did some dabbling with condition monitoring sensors to try to drive towards predictive maintenance solutions. This totally flopped, we just didn&amp;#39;t know enough about predictive maintenance and the sensors/math required to make a viable production ready solution.&lt;/p&gt;\n\n&lt;p&gt;The next year, I had the opportunity to dabble in Azure to better understand how we could bring some of this production/machine data into the cloud. This would help the business bring all our data sources together in the future. I dabbled in ADF, Azure Stream Analytics, and a few other Azure tools.  But my knowledge felt half-baked and disconnected. &lt;/p&gt;\n\n&lt;p&gt;Since then I&amp;#39;ve basically hit a brick wall. Systems were changing, equipment was moving, and I was still a sole employee working alone in manufacturing. We began switching our ERP to Oracle so ERP data has essentially been off limits for me while IT works. It was bad data to begin with. then we wanted to start using a historian for manufacturing data so I again had to wait for IT to make implementations. Now, I&amp;#39;m at a point where I feel trapped. The historian is cool but ultimately does not allow me to learn traditional data engineering techniques/tools, the PLC programmers have limited time so I can&amp;#39;t get new data from them, and extracting data from other data sources is something that IT likes to keep for themselves since I fall under the &amp;quot;operations&amp;quot; bucket. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m alone, feel like I have very little mentorship in this space, and see roadblocks in nearly every direction. However, I can tell my director has a significant amount of trust in me. She always asks for my input to provide feedback to a &amp;quot;global I4.0 committee&amp;quot; that is forming. Additionally, she seems open to me getting professional training but data engineering in manufacturing feels super niche. It feels like normal courses don&amp;#39;t apply. Networking, the tools used, etc are all different and create a unique set of problems.&lt;/p&gt;\n\n&lt;p&gt;How do I continue to develop? I like DE and may even see myself as a good software engineer in the future (not sure how common that switch happens), but as of right now I&amp;#39;m learning a totally different skillset and I&amp;#39;m unsure how many years it will be before a true &amp;quot;data team&amp;quot; exists that I could learn from in the manufacturing space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1be75eb", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1be75eb/how_do_i_progress_my_career_working_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1be75eb/how_do_i_progress_my_career_working_in/", "subreddit_subscribers": 168745, "created_utc": 1710374509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are folk seeing a general trend in the particular pairings of open-source compute platforms and open table formats (OTF)? \n\nSpecifically: \n\n1. My _assumption_ is that #ApacheSpark [Databricks] is most often used with #DeltaLake [Databricks], and less so than with Hudi and Iceberg. Is that true?\n\n2. Does #ApacheFlink get used with #ApacheIceberg / #ApacheHudi / #DeltaLake equally when an OTF is involved, or weighted towards one or the other?\n\nI know that folk at the various respective vendors in this space are going to have a bunch of data points to share illustrating the pairings in permutations of favourable light ;) But I would love to hear from folk in the field too who have anecdotal evidence to share too :D\n\nTIA.", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink&amp;Spark - which OTF most commonly used with each?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bdyu6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710354558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are folk seeing a general trend in the particular pairings of open-source compute platforms and open table formats (OTF)? &lt;/p&gt;\n\n&lt;p&gt;Specifically: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;My &lt;em&gt;assumption&lt;/em&gt; is that #ApacheSpark [Databricks] is most often used with #DeltaLake [Databricks], and less so than with Hudi and Iceberg. Is that true?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Does #ApacheFlink get used with #ApacheIceberg / #ApacheHudi / #DeltaLake equally when an OTF is involved, or weighted towards one or the other?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I know that folk at the various respective vendors in this space are going to have a bunch of data points to share illustrating the pairings in permutations of favourable light ;) But I would love to hear from folk in the field too who have anecdotal evidence to share too :D&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bdyu6v", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bdyu6v/flinkspark_which_otf_most_commonly_used_with_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bdyu6v/flinkspark_which_otf_most_commonly_used_with_each/", "subreddit_subscribers": 168745, "created_utc": 1710354558.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}