{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_babvbok2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dear Hiring Managers in DS field, how to boost your chances for landing entry job, with no prior experience in DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5ho8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669496069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "z5ho8z", "is_robot_indexable": true, "report_reasons": null, "author": "jesteartyste", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5ho8z/dear_hiring_managers_in_ds_field_how_to_boost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5ho8z/dear_hiring_managers_in_ds_field_how_to_boost/", "subreddit_subscribers": 821867, "created_utc": 1669496069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**tl;dr: Dear hiring managers, when you're interviewing candidates for a job that requires knowledge of a technology, how important that knowledge is in comparison with research, data-science and system design experience?**\n\n&amp;#x200B;\n\nHi, sorry for the long title,\n\nI have been working for a startup for about a year, and on a personal level, I am having a great time. It is fully funded, and the bust in the economy didn't hit us hard. The is gone through a pivot, so the old product is funding the new product which I taking part in.\n\nOn the professional level, in the past year, I had the chance to work with NLP, tabular, and touch several subjects (feature selection/importance, data drift, time series). Because of the pivot, the architecture of the whole system needs to be defined. How we are working with clients, serving them models, making sure the models' performance doesn't decay over time, for example.\n\nConsequentially, in the past year, I read a lot, both blog posts, and academic papers. In general, the management is open to new ideas, so, being a researcher at heart I try to promote several projects with different departures.\n\nMy five-year plan is to move to one of the large companies (not necessarily FAANG, but who knows, I hope it doesn't sound like I am full of myself). I was taking the day to look into job descriptions in such companies, and I saw that many of them require familiarity with technologies like GCP/Hadoop/AWS and others that I am not familiar with.\n\nNow for the real question - I am entirely sure that taking the job at a startup for my first job was a great decision in terms of personal growth. Friends that started working for corporations have dealt with one or two tasks at most in the past year. They didn't take any part in planning, and their research experience is little to nothing. Nevertheless, while I worked mostly in Jupyter notebooks, they worked with giant Git repositories. They know Spark, Hadoop, AWS and probably more.\n\nI feel like I am in a good place, so I am not planning on leaving anytime soon, but given this five-year plan, when should be the ideal time to start looking for a new place?\n\n&amp;#x200B;\n\nEDIT: added the tl;dr", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Importance of technology knowledge (AWS, GCP, Spark) vs. system design and research for 2nd role Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5kco9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669505022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669502924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;tl;dr: Dear hiring managers, when you&amp;#39;re interviewing candidates for a job that requires knowledge of a technology, how important that knowledge is in comparison with research, data-science and system design experience?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hi, sorry for the long title,&lt;/p&gt;\n\n&lt;p&gt;I have been working for a startup for about a year, and on a personal level, I am having a great time. It is fully funded, and the bust in the economy didn&amp;#39;t hit us hard. The is gone through a pivot, so the old product is funding the new product which I taking part in.&lt;/p&gt;\n\n&lt;p&gt;On the professional level, in the past year, I had the chance to work with NLP, tabular, and touch several subjects (feature selection/importance, data drift, time series). Because of the pivot, the architecture of the whole system needs to be defined. How we are working with clients, serving them models, making sure the models&amp;#39; performance doesn&amp;#39;t decay over time, for example.&lt;/p&gt;\n\n&lt;p&gt;Consequentially, in the past year, I read a lot, both blog posts, and academic papers. In general, the management is open to new ideas, so, being a researcher at heart I try to promote several projects with different departures.&lt;/p&gt;\n\n&lt;p&gt;My five-year plan is to move to one of the large companies (not necessarily FAANG, but who knows, I hope it doesn&amp;#39;t sound like I am full of myself). I was taking the day to look into job descriptions in such companies, and I saw that many of them require familiarity with technologies like GCP/Hadoop/AWS and others that I am not familiar with.&lt;/p&gt;\n\n&lt;p&gt;Now for the real question - I am entirely sure that taking the job at a startup for my first job was a great decision in terms of personal growth. Friends that started working for corporations have dealt with one or two tasks at most in the past year. They didn&amp;#39;t take any part in planning, and their research experience is little to nothing. Nevertheless, while I worked mostly in Jupyter notebooks, they worked with giant Git repositories. They know Spark, Hadoop, AWS and probably more.&lt;/p&gt;\n\n&lt;p&gt;I feel like I am in a good place, so I am not planning on leaving anytime soon, but given this five-year plan, when should be the ideal time to start looking for a new place?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: added the tl;dr&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "z5kco9", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5kco9/importance_of_technology_knowledge_aws_gcp_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5kco9/importance_of_technology_knowledge_aws_gcp_spark/", "subreddit_subscribers": 821867, "created_utc": 1669502924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A bit of a newbie question, I\u2019m looking at the bustabit gambling site, and wondering what kind of calculation/algo is used to calculate when it busts and what plays a role in the odds of the house winning ?", "author_fullname": "t2_5yf5eocj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bustabit probability calculator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5dyvb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669486425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A bit of a newbie question, I\u2019m looking at the bustabit gambling site, and wondering what kind of calculation/algo is used to calculate when it busts and what plays a role in the odds of the house winning ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5dyvb", "is_robot_indexable": true, "report_reasons": null, "author": "Perrotz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5dyvb/bustabit_probability_calculator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5dyvb/bustabit_probability_calculator/", "subreddit_subscribers": 821867, "created_utc": 1669486425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! I am looking for a volunteer for my school assignment. I am currently in a MS in Data Science program and I\u2019m taking a course on \u201cEthics in Data Science\u201d. One of our assignments is to interview a data science professional and to discuss the person\u2019s experience with ethics issues in their professional career in both the technical and personnel/workplace sides, and if they think the issue was handled well. All names, companies, etc will be anonymous.\nIdeally, we would meet on a platform like Zoom (or whatever works for you) and discuss this for about 15-20 minutes. \nPlease comment or send me a direct message if you are willing to participate, and many thanks in advance!", "author_fullname": "t2_1n1kfbj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS ethics issues interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5k0wz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669502262.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669502066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I am looking for a volunteer for my school assignment. I am currently in a MS in Data Science program and I\u2019m taking a course on \u201cEthics in Data Science\u201d. One of our assignments is to interview a data science professional and to discuss the person\u2019s experience with ethics issues in their professional career in both the technical and personnel/workplace sides, and if they think the issue was handled well. All names, companies, etc will be anonymous.\nIdeally, we would meet on a platform like Zoom (or whatever works for you) and discuss this for about 15-20 minutes. \nPlease comment or send me a direct message if you are willing to participate, and many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5k0wz", "is_robot_indexable": true, "report_reasons": null, "author": "bauertank", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5k0wz/ds_ethics_issues_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5k0wz/ds_ethics_issues_interview/", "subreddit_subscribers": 821867, "created_utc": 1669502066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I came across this dilemma and wanted to consult with you - suppose I want to create a feature which is the change in amount of money in 1 year - lets say from 1.1.2022 to 1.1.2021 , and I only have historical data from 1.6.22 (1st June , not 6th Jan for the Americans here), would you do the difference from the 1st available date (even if the feature is 1 year difference) or would you mark it NA until you have all Data available?\n\nAny suggestions?", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Temporal features - what would you do if you have missing historical data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5je2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669500404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across this dilemma and wanted to consult with you - suppose I want to create a feature which is the change in amount of money in 1 year - lets say from 1.1.2022 to 1.1.2021 , and I only have historical data from 1.6.22 (1st June , not 6th Jan for the Americans here), would you do the difference from the 1st available date (even if the feature is 1 year difference) or would you mark it NA until you have all Data available?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5je2f", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5je2f/temporal_features_what_would_you_do_if_you_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5je2f/temporal_features_what_would_you_do_if_you_have/", "subreddit_subscribers": 821867, "created_utc": 1669500404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI need help with scraping Twitter. I have academic access to Twitter's API, which means I can get tweets 450 by 450. I am using tweepy.Cursor in a for loop but this results in me getting the same 450 tweets over and over again. What is the correct way of doing this? \n\nHere is the code I am working with:\n\n\tdef get_tweets(keywords, hashtags, tweet_nu, api, temp_folder):\n\n\t\ttotal_tweets = 0\n\n\t\tprint(\"\\nQuerying the Twitter API...\")\n\n\t\tquery = f\"{hashtags} {keywords}\"\n\t\tquery = f\"{query} -filter:retweets\"\n\n\t\tfinal_loops = int(tweet_nu/450)+1\n\n\t\tprint(f'\\nThe data will be gathered in {final_loops} iterations...\\n')\n\n\t\tfor loop in range(1, final_loops):\n\t\t\ttry:\n\t\t\t\ttweets = tweepy.Cursor(\n\t\t\t\t\tapi.search_tweets, query, lang=\"en\", tweet_mode=\"extended\"\n\t\t\t\t).items(450)\n\n\t\t\t\tprint('Getting data...')\n\n\t\t\t\tlist_tweets = [tweet for tweet in tweets]\n\n\t\t\t\ttotal_tweets = total_tweets + len(list_tweets)\n\n\t\t\t\tprint(f\"Acquired {total_tweets}/{tweet_nu} tweets...\")\n\n\t\t\t\tprint('Saving the data to the tmp folder...')\n\t\t\t\t\n\t\t\t\tsave_tweets(list_tweets, query, tweet_nu, total_tweets, temp_folder)\n\t\t\t\t\n\t\t\t\tsleep(sleep_time)\n\t\t\t\t\n\t\t\t\tprint('Save succeeded, moving on with the next iteration.\\n')\n\n\t\t\t\n\n\t\t\texcept Exception as e:\n\t\t\t\tprint(e)\n\t\t\t\tprint('Could not query Twitter API. Cannot continue.')\n\t\t\t\texit()", "author_fullname": "t2_kt7czr9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Twitter API/Tweepy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5jhyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669506117.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669500687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I need help with scraping Twitter. I have academic access to Twitter&amp;#39;s API, which means I can get tweets 450 by 450. I am using tweepy.Cursor in a for loop but this results in me getting the same 450 tweets over and over again. What is the correct way of doing this? &lt;/p&gt;\n\n&lt;p&gt;Here is the code I am working with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def get_tweets(keywords, hashtags, tweet_nu, api, temp_folder):\n\n    total_tweets = 0\n\n    print(&amp;quot;\\nQuerying the Twitter API...&amp;quot;)\n\n    query = f&amp;quot;{hashtags} {keywords}&amp;quot;\n    query = f&amp;quot;{query} -filter:retweets&amp;quot;\n\n    final_loops = int(tweet_nu/450)+1\n\n    print(f&amp;#39;\\nThe data will be gathered in {final_loops} iterations...\\n&amp;#39;)\n\n    for loop in range(1, final_loops):\n        try:\n            tweets = tweepy.Cursor(\n                api.search_tweets, query, lang=&amp;quot;en&amp;quot;, tweet_mode=&amp;quot;extended&amp;quot;\n            ).items(450)\n\n            print(&amp;#39;Getting data...&amp;#39;)\n\n            list_tweets = [tweet for tweet in tweets]\n\n            total_tweets = total_tweets + len(list_tweets)\n\n            print(f&amp;quot;Acquired {total_tweets}/{tweet_nu} tweets...&amp;quot;)\n\n            print(&amp;#39;Saving the data to the tmp folder...&amp;#39;)\n\n            save_tweets(list_tweets, query, tweet_nu, total_tweets, temp_folder)\n\n            sleep(sleep_time)\n\n            print(&amp;#39;Save succeeded, moving on with the next iteration.\\n&amp;#39;)\n\n\n\n        except Exception as e:\n            print(e)\n            print(&amp;#39;Could not query Twitter API. Cannot continue.&amp;#39;)\n            exit()\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5jhyk", "is_robot_indexable": true, "report_reasons": null, "author": "Rhizomix", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5jhyk/need_help_with_twitter_apitweepy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5jhyk/need_help_with_twitter_apitweepy/", "subreddit_subscribers": 821867, "created_utc": 1669500687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_k5g1lh0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting use of Python/Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5jtoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669501536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=33755016", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5jtoy", "is_robot_indexable": true, "report_reasons": null, "author": "G4M35", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5jtoy/interesting_use_of_pythondata_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=33755016", "subreddit_subscribers": 821867, "created_utc": 1669501536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, i think I didn\u2019t understand the use of the holdout set. I searched on google a little bit but it doesn\u2019t get clear for me. \n\nI thought that we need a holdout set when we do predictions and based on these predictions we start doing something. For example \u201echurn\u201c and \u201eno churn\u201c. When our model predicts a churn of a customer and we start to take action against that. Maybe the customer will not churn. This leads to the case that the prediction would be correct but with our effort we turned the decision of the customer to no churn. In such cases a hold out set would be useful. If we don\u2019t have a case like this and our actions have no impact on the predicted task, do we need a holdout set?", "author_fullname": "t2_399amgaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When do I have to use a holdout set?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z52zy7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.22, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669453512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, i think I didn\u2019t understand the use of the holdout set. I searched on google a little bit but it doesn\u2019t get clear for me. &lt;/p&gt;\n\n&lt;p&gt;I thought that we need a holdout set when we do predictions and based on these predictions we start doing something. For example \u201echurn\u201c and \u201eno churn\u201c. When our model predicts a churn of a customer and we start to take action against that. Maybe the customer will not churn. This leads to the case that the prediction would be correct but with our effort we turned the decision of the customer to no churn. In such cases a hold out set would be useful. If we don\u2019t have a case like this and our actions have no impact on the predicted task, do we need a holdout set?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z52zy7", "is_robot_indexable": true, "report_reasons": null, "author": "kongg18", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z52zy7/when_do_i_have_to_use_a_holdout_set/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z52zy7/when_do_i_have_to_use_a_holdout_set/", "subreddit_subscribers": 821867, "created_utc": 1669453512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you all type properly, without ever looking at the keyboard and using 10 fingers? How did you learn?\n\nI want to do it structurally for once hoping it will help prevent RSI. Can you recommend any tools, websites or whatever approches how you did it?", "author_fullname": "t2_s9fqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn proper typing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z51co2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.19, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669447729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you all type properly, without ever looking at the keyboard and using 10 fingers? How did you learn?&lt;/p&gt;\n\n&lt;p&gt;I want to do it structurally for once hoping it will help prevent RSI. Can you recommend any tools, websites or whatever approches how you did it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z51co2", "is_robot_indexable": true, "report_reasons": null, "author": "scriptosens", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z51co2/how_to_learn_proper_typing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z51co2/how_to_learn_proper_typing/", "subreddit_subscribers": 821867, "created_utc": 1669447729.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}