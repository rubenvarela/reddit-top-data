{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_babvbok2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dear Hiring Managers in DS field, how to boost your chances for landing entry job, with no prior experience in DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5ho8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 117, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 117, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669496069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "z5ho8z", "is_robot_indexable": true, "report_reasons": null, "author": "jesteartyste", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5ho8z/dear_hiring_managers_in_ds_field_how_to_boost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5ho8z/dear_hiring_managers_in_ds_field_how_to_boost/", "subreddit_subscribers": 821917, "created_utc": 1669496069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**tl;dr: Dear hiring managers, when you're interviewing candidates for a job that requires knowledge of a technology, how important that knowledge is in comparison with research, data-science and system design experience?**\n\n&amp;#x200B;\n\nHi, sorry for the long title,\n\nI have been working for a startup for about a year, and on a personal level, I am having a great time. It is fully funded, and the bust in the economy didn't hit us hard. The is gone through a pivot, so the old product is funding the new product which I taking part in.\n\nOn the professional level, in the past year, I had the chance to work with NLP, tabular, and touch several subjects (feature selection/importance, data drift, time series). Because of the pivot, the architecture of the whole system needs to be defined. How we are working with clients, serving them models, making sure the models' performance doesn't decay over time, for example.\n\nConsequentially, in the past year, I read a lot, both blog posts, and academic papers. In general, the management is open to new ideas, so, being a researcher at heart I try to promote several projects with different departures.\n\nMy five-year plan is to move to one of the large companies (not necessarily FAANG, but who knows, I hope it doesn't sound like I am full of myself). I was taking the day to look into job descriptions in such companies, and I saw that many of them require familiarity with technologies like GCP/Hadoop/AWS and others that I am not familiar with.\n\nNow for the real question - I am entirely sure that taking the job at a startup for my first job was a great decision in terms of personal growth. Friends that started working for corporations have dealt with one or two tasks at most in the past year. They didn't take any part in planning, and their research experience is little to nothing. Nevertheless, while I worked mostly in Jupyter notebooks, they worked with giant Git repositories. They know Spark, Hadoop, AWS and probably more.\n\nI feel like I am in a good place, so I am not planning on leaving anytime soon, but given this five-year plan, when should be the ideal time to start looking for a new place?\n\n&amp;#x200B;\n\nEDIT: added the tl;dr", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Importance of technology knowledge (AWS, GCP, Spark) vs. system design and research for 2nd role Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5kco9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669505022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669502924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;tl;dr: Dear hiring managers, when you&amp;#39;re interviewing candidates for a job that requires knowledge of a technology, how important that knowledge is in comparison with research, data-science and system design experience?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hi, sorry for the long title,&lt;/p&gt;\n\n&lt;p&gt;I have been working for a startup for about a year, and on a personal level, I am having a great time. It is fully funded, and the bust in the economy didn&amp;#39;t hit us hard. The is gone through a pivot, so the old product is funding the new product which I taking part in.&lt;/p&gt;\n\n&lt;p&gt;On the professional level, in the past year, I had the chance to work with NLP, tabular, and touch several subjects (feature selection/importance, data drift, time series). Because of the pivot, the architecture of the whole system needs to be defined. How we are working with clients, serving them models, making sure the models&amp;#39; performance doesn&amp;#39;t decay over time, for example.&lt;/p&gt;\n\n&lt;p&gt;Consequentially, in the past year, I read a lot, both blog posts, and academic papers. In general, the management is open to new ideas, so, being a researcher at heart I try to promote several projects with different departures.&lt;/p&gt;\n\n&lt;p&gt;My five-year plan is to move to one of the large companies (not necessarily FAANG, but who knows, I hope it doesn&amp;#39;t sound like I am full of myself). I was taking the day to look into job descriptions in such companies, and I saw that many of them require familiarity with technologies like GCP/Hadoop/AWS and others that I am not familiar with.&lt;/p&gt;\n\n&lt;p&gt;Now for the real question - I am entirely sure that taking the job at a startup for my first job was a great decision in terms of personal growth. Friends that started working for corporations have dealt with one or two tasks at most in the past year. They didn&amp;#39;t take any part in planning, and their research experience is little to nothing. Nevertheless, while I worked mostly in Jupyter notebooks, they worked with giant Git repositories. They know Spark, Hadoop, AWS and probably more.&lt;/p&gt;\n\n&lt;p&gt;I feel like I am in a good place, so I am not planning on leaving anytime soon, but given this five-year plan, when should be the ideal time to start looking for a new place?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: added the tl;dr&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "z5kco9", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5kco9/importance_of_technology_knowledge_aws_gcp_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5kco9/importance_of_technology_knowledge_aws_gcp_spark/", "subreddit_subscribers": 821917, "created_utc": 1669502924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! I am looking for a volunteer for my school assignment. I am currently in a MS in Data Science program and I\u2019m taking a course on \u201cEthics in Data Science\u201d. One of our assignments is to interview a data science professional and to discuss the person\u2019s experience with ethics issues in their professional career in both the technical and personnel/workplace sides, and if they think the issue was handled well. All names, companies, etc will be anonymous.\nIdeally, we would meet on a platform like Zoom (or whatever works for you) and discuss this for about 15-20 minutes. \nPlease comment or send me a direct message if you are willing to participate, and many thanks in advance!", "author_fullname": "t2_1n1kfbj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS ethics issues interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5k0wz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669502262.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669502066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I am looking for a volunteer for my school assignment. I am currently in a MS in Data Science program and I\u2019m taking a course on \u201cEthics in Data Science\u201d. One of our assignments is to interview a data science professional and to discuss the person\u2019s experience with ethics issues in their professional career in both the technical and personnel/workplace sides, and if they think the issue was handled well. All names, companies, etc will be anonymous.\nIdeally, we would meet on a platform like Zoom (or whatever works for you) and discuss this for about 15-20 minutes. \nPlease comment or send me a direct message if you are willing to participate, and many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5k0wz", "is_robot_indexable": true, "report_reasons": null, "author": "bauertank", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5k0wz/ds_ethics_issues_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5k0wz/ds_ethics_issues_interview/", "subreddit_subscribers": 821917, "created_utc": 1669502066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A bit of a newbie question, I\u2019m looking at the bustabit gambling site, and wondering what kind of calculation/algo is used to calculate when it busts and what plays a role in the odds of the house winning ?", "author_fullname": "t2_5yf5eocj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bustabit probability calculator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5dyvb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669486425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A bit of a newbie question, I\u2019m looking at the bustabit gambling site, and wondering what kind of calculation/algo is used to calculate when it busts and what plays a role in the odds of the house winning ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5dyvb", "is_robot_indexable": true, "report_reasons": null, "author": "Perrotz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5dyvb/bustabit_probability_calculator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5dyvb/bustabit_probability_calculator/", "subreddit_subscribers": 821917, "created_utc": 1669486425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I came across this dilemma and wanted to consult with you - suppose I want to create a feature which is the change in amount of money in 1 year - lets say from 1.1.2022 to 1.1.2021 , and I only have historical data from 1.6.22 (1st June , not 6th Jan for the Americans here), would you do the difference from the 1st available date (even if the feature is 1 year difference) or would you mark it NA until you have all Data available?\n\nAny suggestions?", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Temporal features - what would you do if you have missing historical data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5je2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669500404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across this dilemma and wanted to consult with you - suppose I want to create a feature which is the change in amount of money in 1 year - lets say from 1.1.2022 to 1.1.2021 , and I only have historical data from 1.6.22 (1st June , not 6th Jan for the Americans here), would you do the difference from the 1st available date (even if the feature is 1 year difference) or would you mark it NA until you have all Data available?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5je2f", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5je2f/temporal_features_what_would_you_do_if_you_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5je2f/temporal_features_what_would_you_do_if_you_have/", "subreddit_subscribers": 821917, "created_utc": 1669500404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI need help with scraping Twitter. I have academic access to Twitter's API, which means I can get tweets 450 by 450. I am using tweepy.Cursor in a for loop but this results in me getting the same 450 tweets over and over again. What is the correct way of doing this? \n\nHere is the code I am working with:\n\n\tdef get_tweets(keywords, hashtags, tweet_nu, api, temp_folder):\n\n\t\ttotal_tweets = 0\n\n\t\tprint(\"\\nQuerying the Twitter API...\")\n\n\t\tquery = f\"{hashtags} {keywords}\"\n\t\tquery = f\"{query} -filter:retweets\"\n\n\t\tfinal_loops = int(tweet_nu/450)+1\n\n\t\tprint(f'\\nThe data will be gathered in {final_loops} iterations...\\n')\n\n\t\tfor loop in range(1, final_loops):\n\t\t\ttry:\n\t\t\t\ttweets = tweepy.Cursor(\n\t\t\t\t\tapi.search_tweets, query, lang=\"en\", tweet_mode=\"extended\"\n\t\t\t\t).items(450)\n\n\t\t\t\tprint('Getting data...')\n\n\t\t\t\tlist_tweets = [tweet for tweet in tweets]\n\n\t\t\t\ttotal_tweets = total_tweets + len(list_tweets)\n\n\t\t\t\tprint(f\"Acquired {total_tweets}/{tweet_nu} tweets...\")\n\n\t\t\t\tprint('Saving the data to the tmp folder...')\n\t\t\t\t\n\t\t\t\tsave_tweets(list_tweets, query, tweet_nu, total_tweets, temp_folder)\n\t\t\t\t\n\t\t\t\tsleep(sleep_time)\n\t\t\t\t\n\t\t\t\tprint('Save succeeded, moving on with the next iteration.\\n')\n\n\t\t\t\n\n\t\t\texcept Exception as e:\n\t\t\t\tprint(e)\n\t\t\t\tprint('Could not query Twitter API. Cannot continue.')\n\t\t\t\texit()", "author_fullname": "t2_kt7czr9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Twitter API/Tweepy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5jhyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669506117.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669500687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I need help with scraping Twitter. I have academic access to Twitter&amp;#39;s API, which means I can get tweets 450 by 450. I am using tweepy.Cursor in a for loop but this results in me getting the same 450 tweets over and over again. What is the correct way of doing this? &lt;/p&gt;\n\n&lt;p&gt;Here is the code I am working with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def get_tweets(keywords, hashtags, tweet_nu, api, temp_folder):\n\n    total_tweets = 0\n\n    print(&amp;quot;\\nQuerying the Twitter API...&amp;quot;)\n\n    query = f&amp;quot;{hashtags} {keywords}&amp;quot;\n    query = f&amp;quot;{query} -filter:retweets&amp;quot;\n\n    final_loops = int(tweet_nu/450)+1\n\n    print(f&amp;#39;\\nThe data will be gathered in {final_loops} iterations...\\n&amp;#39;)\n\n    for loop in range(1, final_loops):\n        try:\n            tweets = tweepy.Cursor(\n                api.search_tweets, query, lang=&amp;quot;en&amp;quot;, tweet_mode=&amp;quot;extended&amp;quot;\n            ).items(450)\n\n            print(&amp;#39;Getting data...&amp;#39;)\n\n            list_tweets = [tweet for tweet in tweets]\n\n            total_tweets = total_tweets + len(list_tweets)\n\n            print(f&amp;quot;Acquired {total_tweets}/{tweet_nu} tweets...&amp;quot;)\n\n            print(&amp;#39;Saving the data to the tmp folder...&amp;#39;)\n\n            save_tweets(list_tweets, query, tweet_nu, total_tweets, temp_folder)\n\n            sleep(sleep_time)\n\n            print(&amp;#39;Save succeeded, moving on with the next iteration.\\n&amp;#39;)\n\n\n\n        except Exception as e:\n            print(e)\n            print(&amp;#39;Could not query Twitter API. Cannot continue.&amp;#39;)\n            exit()\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5jhyk", "is_robot_indexable": true, "report_reasons": null, "author": "Rhizomix", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5jhyk/need_help_with_twitter_apitweepy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5jhyk/need_help_with_twitter_apitweepy/", "subreddit_subscribers": 821917, "created_utc": 1669500687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_k5g1lh0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting use of Python/Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5jtoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669501536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=33755016", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5jtoy", "is_robot_indexable": true, "report_reasons": null, "author": "G4M35", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5jtoy/interesting_use_of_pythondata_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=33755016", "subreddit_subscribers": 821917, "created_utc": 1669501536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking to gather some ideas for projects that may include any of the following topics.\n\nTime series models, network analysis, market analysis, recommendation systems, etc. \n\nThank you!", "author_fullname": "t2_5m5g3zg6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help brainstorm ideas for a beginner data science project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5sdq3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669525926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to gather some ideas for projects that may include any of the following topics.&lt;/p&gt;\n\n&lt;p&gt;Time series models, network analysis, market analysis, recommendation systems, etc. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5sdq3", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Wrap_2150", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5sdq3/help_brainstorm_ideas_for_a_beginner_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5sdq3/help_brainstorm_ideas_for_a_beginner_data_science/", "subreddit_subscribers": 821917, "created_utc": 1669525926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m currently in grad school finishing a masters in data science analytics and i am just curious what people in the field would say are the skills i need to be an expert on. I\u2019d like to hit the ground running as soon as i get done with school.\n\nMy undergrad is in applied math so i have a really strong background in mathematics and i have spent a lot of time trying to learn c++ python and r.", "author_fullname": "t2_55oj6neb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I graduate next december w/ a masters in DS, what should I do to strengthen my portfolio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5qhnw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669520182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently in grad school finishing a masters in data science analytics and i am just curious what people in the field would say are the skills i need to be an expert on. I\u2019d like to hit the ground running as soon as i get done with school.&lt;/p&gt;\n\n&lt;p&gt;My undergrad is in applied math so i have a really strong background in mathematics and i have spent a lot of time trying to learn c++ python and r.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5qhnw", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable_Ease_8330", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5qhnw/i_graduate_next_december_w_a_masters_in_ds_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5qhnw/i_graduate_next_december_w_a_masters_in_ds_what/", "subreddit_subscribers": 821917, "created_utc": 1669520182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I saw this statement earlier and want to know if it\u2019s true \u201cApp advertisers are now able to market racially relevant services/products to you based off of what your front-facing camera sees (your face) during your session with said app. A.I. is able to determine your ethnicity and translate it into data points.\u201d", "author_fullname": "t2_ucc2mq8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this true? AI works with app advertisers to determine your race.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5s99b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669525528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw this statement earlier and want to know if it\u2019s true \u201cApp advertisers are now able to market racially relevant services/products to you based off of what your front-facing camera sees (your face) during your session with said app. A.I. is able to determine your ethnicity and translate it into data points.\u201d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5s99b", "is_robot_indexable": true, "report_reasons": null, "author": "hoddoggpal", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5s99b/is_this_true_ai_works_with_app_advertisers_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5s99b/is_this_true_ai_works_with_app_advertisers_to/", "subreddit_subscribers": 821917, "created_utc": 1669525528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am a data enthusiast and I want to learn data science. I like 365 data science but I do not have enough budget to subscribe any of the plans. \n\nIf any of you are trying to subscribe or update your annual plan, can you do it through the referred link below because it says if there is at least 5 users who subscribe their plans via my referred link , I can learn it for free and you will also get your benefit. Can you help me please?\n\nhttps://365datascience.com/r/fe67a8ad0c330cbaa2d66678e93a7b", "author_fullname": "t2_7h893k5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "365DataScience refer link", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5qkig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669520421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a data enthusiast and I want to learn data science. I like 365 data science but I do not have enough budget to subscribe any of the plans. &lt;/p&gt;\n\n&lt;p&gt;If any of you are trying to subscribe or update your annual plan, can you do it through the referred link below because it says if there is at least 5 users who subscribe their plans via my referred link , I can learn it for free and you will also get your benefit. Can you help me please?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://365datascience.com/r/fe67a8ad0c330cbaa2d66678e93a7b\"&gt;https://365datascience.com/r/fe67a8ad0c330cbaa2d66678e93a7b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z5qkig", "is_robot_indexable": true, "report_reasons": null, "author": "Unique-Ad5666", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5qkig/365datascience_refer_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z5qkig/365datascience_refer_link/", "subreddit_subscribers": 821917, "created_utc": 1669520421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, i think I didn\u2019t understand the use of the holdout set. I searched on google a little bit but it doesn\u2019t get clear for me. \n\nI thought that we need a holdout set when we do predictions and based on these predictions we start doing something. For example \u201echurn\u201c and \u201eno churn\u201c. When our model predicts a churn of a customer and we start to take action against that. Maybe the customer will not churn. This leads to the case that the prediction would be correct but with our effort we turned the decision of the customer to no churn. In such cases a hold out set would be useful. If we don\u2019t have a case like this and our actions have no impact on the predicted task, do we need a holdout set?", "author_fullname": "t2_399amgaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When do I have to use a holdout set?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z52zy7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.22, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669453512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, i think I didn\u2019t understand the use of the holdout set. I searched on google a little bit but it doesn\u2019t get clear for me. &lt;/p&gt;\n\n&lt;p&gt;I thought that we need a holdout set when we do predictions and based on these predictions we start doing something. For example \u201echurn\u201c and \u201eno churn\u201c. When our model predicts a churn of a customer and we start to take action against that. Maybe the customer will not churn. This leads to the case that the prediction would be correct but with our effort we turned the decision of the customer to no churn. In such cases a hold out set would be useful. If we don\u2019t have a case like this and our actions have no impact on the predicted task, do we need a holdout set?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z52zy7", "is_robot_indexable": true, "report_reasons": null, "author": "kongg18", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z52zy7/when_do_i_have_to_use_a_holdout_set/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z52zy7/when_do_i_have_to_use_a_holdout_set/", "subreddit_subscribers": 821917, "created_utc": 1669453512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/z5po29)", "author_fullname": "t2_7rzkvxvt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much time do yo spent in DB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5po29", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.1, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669517789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/z5po29\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "z5po29", "is_robot_indexable": true, "report_reasons": null, "author": "Capi_of_your_heart", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1669776989501, "options": [{"text": "&lt;1 day", "id": "20044286"}, {"text": "&lt;1 week", "id": "20044287"}, {"text": "&lt;1 month", "id": "20044288"}, {"text": "&lt;4 months", "id": "20044289"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 29, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z5po29/how_much_time_do_yo_spent_in_db/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/z5po29/how_much_time_do_yo_spent_in_db/", "subreddit_subscribers": 821917, "created_utc": 1669517789.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}