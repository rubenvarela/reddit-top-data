{"kind": "Listing", "data": {"after": null, "dist": 11, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am practicing mostly medium and few hard SQL and Python from scratascratch and leetcode. I feel confident of solving them but I am not a Data engineer by profession. I am a SQL server DBA in a product based firm. \n \nI have 8+ years of experience in IT but not sure \nhow far to market my resume and experience relevant to 8 years in DE when I appear for interview in near future. Should I be honest and say I am self learned DE or mention based on home projects as experience. \n\nPlease can someone provide some insights on how you cracked into DE world from other profession or IT background. Also would be very helpful if you disclose or share some of the personal projects that helped you attain a new DE roles. Thank you very much", "author_fullname": "t2_m6gnxiuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer projects for interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5fkds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669490561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am practicing mostly medium and few hard SQL and Python from scratascratch and leetcode. I feel confident of solving them but I am not a Data engineer by profession. I am a SQL server DBA in a product based firm. &lt;/p&gt;\n\n&lt;p&gt;I have 8+ years of experience in IT but not sure \nhow far to market my resume and experience relevant to 8 years in DE when I appear for interview in near future. Should I be honest and say I am self learned DE or mention based on home projects as experience. &lt;/p&gt;\n\n&lt;p&gt;Please can someone provide some insights on how you cracked into DE world from other profession or IT background. Also would be very helpful if you disclose or share some of the personal projects that helped you attain a new DE roles. Thank you very much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z5fkds", "is_robot_indexable": true, "report_reasons": null, "author": "rajekum512", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5fkds/data_engineer_projects_for_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5fkds/data_engineer_projects_for_interview/", "subreddit_subscribers": 81062, "created_utc": 1669490561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y\u2019all, I have a use case in which I query data from massive tables. Sometimes I need to make joins or sometimes just filtering. All these queries are performed in prestoSQL. The results from these queries are then saved to S3 in the form of parquet files, then they are processed in python and saved to a postgreSQL DB.\n\nThe results from the queries are not particularly big, at most 1-2GB.\n\nLately I noticed these queries have gotten more complicated and are taking more than 60 minutes to run. I spoke with a coworker, and they suggested that I switch to Spark. \n\nIf I understand correctly, Spark would still need to load the data into worker nodes and then filter and join data. So it would not improve performance significantly. On the flip side if I needed to apply transformations to this massive dataset, then Spark would be the right tool? Am I wrong?", "author_fullname": "t2_7e04ujnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PrestoSQL vs Spark to query data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5n5a3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669510473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all, I have a use case in which I query data from massive tables. Sometimes I need to make joins or sometimes just filtering. All these queries are performed in prestoSQL. The results from these queries are then saved to S3 in the form of parquet files, then they are processed in python and saved to a postgreSQL DB.&lt;/p&gt;\n\n&lt;p&gt;The results from the queries are not particularly big, at most 1-2GB.&lt;/p&gt;\n\n&lt;p&gt;Lately I noticed these queries have gotten more complicated and are taking more than 60 minutes to run. I spoke with a coworker, and they suggested that I switch to Spark. &lt;/p&gt;\n\n&lt;p&gt;If I understand correctly, Spark would still need to load the data into worker nodes and then filter and join data. So it would not improve performance significantly. On the flip side if I needed to apply transformations to this massive dataset, then Spark would be the right tool? Am I wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z5n5a3", "is_robot_indexable": true, "report_reasons": null, "author": "ThatGrayZ", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5n5a3/prestosql_vs_spark_to_query_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5n5a3/prestosql_vs_spark_to_query_data/", "subreddit_subscribers": 81062, "created_utc": 1669510473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hoping to cut past all of the Talend, IBM, Google buzzwords and understand Data Fabric.\n\nCan anyone help?\n\nWhat we have: structured and semi-structured data is landed in Snowflake from various sources (internal and external). We use dbt and Airflow (and a bit of python) to model the data across multiple databases, organised/split by business domain. Some of the data from business domain \u201cA\u201d is private, and stays in their data repository as modelled data. Some of it is considered shareable, and is exposed to the rest of the business through views which can be consumed by the other business units as source data. Same goes for other domains.\n\nData are available in fact &amp; dimensional models within each business domains \u2018hub\u2019. \n\nData can be accessed through SQL for analysts, exposed via APIs (FastAPI) for consumption by business systems, or pushed directly into business systems via their APIs (depending on whether there is a preference for pull vs. push).\n\nSo is this \u2018data fabric\u2019, or just some data marts plus some reverse ETL?\n\nWhere is the difference?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for non-marketing speak understanding of Data Fabric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5q9mk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669524492.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669519530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping to cut past all of the Talend, IBM, Google buzzwords and understand Data Fabric.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n\n&lt;p&gt;What we have: structured and semi-structured data is landed in Snowflake from various sources (internal and external). We use dbt and Airflow (and a bit of python) to model the data across multiple databases, organised/split by business domain. Some of the data from business domain \u201cA\u201d is private, and stays in their data repository as modelled data. Some of it is considered shareable, and is exposed to the rest of the business through views which can be consumed by the other business units as source data. Same goes for other domains.&lt;/p&gt;\n\n&lt;p&gt;Data are available in fact &amp;amp; dimensional models within each business domains \u2018hub\u2019. &lt;/p&gt;\n\n&lt;p&gt;Data can be accessed through SQL for analysts, exposed via APIs (FastAPI) for consumption by business systems, or pushed directly into business systems via their APIs (depending on whether there is a preference for pull vs. push).&lt;/p&gt;\n\n&lt;p&gt;So is this \u2018data fabric\u2019, or just some data marts plus some reverse ETL?&lt;/p&gt;\n\n&lt;p&gt;Where is the difference?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5q9mk", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5q9mk/looking_for_nonmarketing_speak_understanding_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5q9mk/looking_for_nonmarketing_speak_understanding_of/", "subreddit_subscribers": 81062, "created_utc": 1669519530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I was recently joined a new team and was tasked with helping to prototype an architecture design and the setup of airflow onto openshift - but I have certain reservations on the applicability of airflow for our team's use case.\n\nMy team wants to shift from using control-M to schedule our jobs and to use airflow to replace the current process. Most of our jobs and data sources will come from Snowflake tables in the future; And the team will be in-charge of transforming  the data from these tables to views for the user.\n\nHowever, I feel hesitant on pushing towards using airflow as the team does not want to rely on using stored procedures or most forms of SQL queries (save for joins) being used in airflow itself. The plan is to pull data from Snowflake and to process the data within the pythonoperator using pandas/snowpark, and to then finally write the data to a view. But as I understand it, airflow is not meant to be a data processing pipeline and the team doesn't want airflow to get too \"complex\" by integrating spark.\n\nShould we continue to migrate to airflow for our use case? Or are there other potential better solutions? Any help and advice is greatly appreciated!", "author_fullname": "t2_2ma0hvq1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should we shift from Control-M to Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z56ipf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669466081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I was recently joined a new team and was tasked with helping to prototype an architecture design and the setup of airflow onto openshift - but I have certain reservations on the applicability of airflow for our team&amp;#39;s use case.&lt;/p&gt;\n\n&lt;p&gt;My team wants to shift from using control-M to schedule our jobs and to use airflow to replace the current process. Most of our jobs and data sources will come from Snowflake tables in the future; And the team will be in-charge of transforming  the data from these tables to views for the user.&lt;/p&gt;\n\n&lt;p&gt;However, I feel hesitant on pushing towards using airflow as the team does not want to rely on using stored procedures or most forms of SQL queries (save for joins) being used in airflow itself. The plan is to pull data from Snowflake and to process the data within the pythonoperator using pandas/snowpark, and to then finally write the data to a view. But as I understand it, airflow is not meant to be a data processing pipeline and the team doesn&amp;#39;t want airflow to get too &amp;quot;complex&amp;quot; by integrating spark.&lt;/p&gt;\n\n&lt;p&gt;Should we continue to migrate to airflow for our use case? Or are there other potential better solutions? Any help and advice is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z56ipf", "is_robot_indexable": true, "report_reasons": null, "author": "pseudoduespp", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z56ipf/should_we_shift_from_controlm_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z56ipf/should_we_shift_from_controlm_to_airflow/", "subreddit_subscribers": 81062, "created_utc": 1669466081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody else been turned down for a job on financial probity reasons? Had an offer for a Quant job at a hedge fund, but because I got hit by the covid financial crisis I fell behind on bills. Now I am being turned down for roles. Anybody else seeing this?", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5brqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669480828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody else been turned down for a job on financial probity reasons? Had an offer for a Quant job at a hedge fund, but because I got hit by the covid financial crisis I fell behind on bills. Now I am being turned down for roles. Anybody else seeing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z5brqk", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5brqk/curious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5brqk/curious/", "subreddit_subscribers": 81062, "created_utc": 1669480828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Goal: migrate a snowflake table (150 million records) to postgres (it is on prem postgres database)\n\n\nCurrent limitations/stack we are using:\n\n- Docker/ecs container (10gb container space)\n- managed aws airflow\n- python\n\nWhat I currently have in mind:\n\n- Export Snowflake table to csv\n- read csv as dataframe (csv export is required for archiving purposes)\n- insert dataframe into Postgres using some Python library ?", "author_fullname": "t2_k95rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best approach to migrate Snowflake table to Postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5agab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669477391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Goal: migrate a snowflake table (150 million records) to postgres (it is on prem postgres database)&lt;/p&gt;\n\n&lt;p&gt;Current limitations/stack we are using:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Docker/ecs container (10gb container space)&lt;/li&gt;\n&lt;li&gt;managed aws airflow&lt;/li&gt;\n&lt;li&gt;python&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I currently have in mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Export Snowflake table to csv&lt;/li&gt;\n&lt;li&gt;read csv as dataframe (csv export is required for archiving purposes)&lt;/li&gt;\n&lt;li&gt;insert dataframe into Postgres using some Python library ?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5agab", "is_robot_indexable": true, "report_reasons": null, "author": "jaspar1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5agab/best_approach_to_migrate_snowflake_table_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5agab/best_approach_to_migrate_snowflake_table_to/", "subreddit_subscribers": 81062, "created_utc": 1669477391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to understand how pros think before deciding to use them (in a scenario you know for sure your application will need to be multi cloud)\n\nSuppose you're building a platform which needs ETL building in AWS for customer 1 and Azure for customer 2\n\nYou build ETL for 1 first and you end up using dynamic frame/bookmark etc glue specific features, now you get to 2 and see those vendor specific features aren't available\n\nshould 1 have used spark native features only? to save time resolving same mini problems across cloud vendors? even if the dynamic frame etc was best decision for that cloud?", "author_fullname": "t2_piwlmz4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To use vendor specific features or not? Dynamic frames for Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z542cd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669457385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to understand how pros think before deciding to use them (in a scenario you know for sure your application will need to be multi cloud)&lt;/p&gt;\n\n&lt;p&gt;Suppose you&amp;#39;re building a platform which needs ETL building in AWS for customer 1 and Azure for customer 2&lt;/p&gt;\n\n&lt;p&gt;You build ETL for 1 first and you end up using dynamic frame/bookmark etc glue specific features, now you get to 2 and see those vendor specific features aren&amp;#39;t available&lt;/p&gt;\n\n&lt;p&gt;should 1 have used spark native features only? to save time resolving same mini problems across cloud vendors? even if the dynamic frame etc was best decision for that cloud?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z542cd", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Story2003", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z542cd/to_use_vendor_specific_features_or_not_dynamic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z542cd/to_use_vendor_specific_features_or_not_dynamic/", "subreddit_subscribers": 81062, "created_utc": 1669457385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am exploring options to store several terabytes of data then interactively query them back for exploration etc. I know I could use presto, hive, S3 select or simply spark on parquet, I am open to choose my storage file format, such as delta, parquert, json etc. I am not chasing millisecond latency, up to a few seconds would suffice. However, we have a current infra. of postgreSQL and I am advocating against storing all these data there which I know will be expensive in terms of resource consumption. \n\nI know storing them on S3 and using engines like presto etc. would be several times cheaper. However I am not able to provide some data driven analysis to justify this point of view.  Is this assessment correct? Can someone share some insights into this?", "author_fullname": "t2_tbm1xg4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Presto vs PostgreSQL for data exploration user cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5u2f1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669531490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am exploring options to store several terabytes of data then interactively query them back for exploration etc. I know I could use presto, hive, S3 select or simply spark on parquet, I am open to choose my storage file format, such as delta, parquert, json etc. I am not chasing millisecond latency, up to a few seconds would suffice. However, we have a current infra. of postgreSQL and I am advocating against storing all these data there which I know will be expensive in terms of resource consumption. &lt;/p&gt;\n\n&lt;p&gt;I know storing them on S3 and using engines like presto etc. would be several times cheaper. However I am not able to provide some data driven analysis to justify this point of view.  Is this assessment correct? Can someone share some insights into this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5u2f1", "is_robot_indexable": true, "report_reasons": null, "author": "mayukhdutta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5u2f1/presto_vs_postgresql_for_data_exploration_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5u2f1/presto_vs_postgresql_for_data_exploration_user/", "subreddit_subscribers": 81062, "created_utc": 1669531490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_invkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing Spark DataFrame to HBase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z57p70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669469662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ayoublabiad.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ayoublabiad.me/posts/spark-to-hbase/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z57p70", "is_robot_indexable": true, "report_reasons": null, "author": "T3Z0", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z57p70/writing_spark_dataframe_to_hbase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ayoublabiad.me/posts/spark-to-hbase/", "subreddit_subscribers": 81062, "created_utc": 1669469662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a DE interview coming up in the next month. What are the go to resources for Python and SQL (end to end) that you'd recommend. TIA.", "author_fullname": "t2_q0hjyvx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Resources for SQL and Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5tcal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669529030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a DE interview coming up in the next month. What are the go to resources for Python and SQL (end to end) that you&amp;#39;d recommend. TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z5tcal", "is_robot_indexable": true, "report_reasons": null, "author": "Ready--Aim--Fire", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5tcal/interview_resources_for_sql_and_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5tcal/interview_resources_for_sql_and_python/", "subreddit_subscribers": 81062, "created_utc": 1669529030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have just been offered a TDP position as a data engineer, but when I applied it was as a data engineer/data scientist. My undergraduate degree is in Data Science. I was wondering if there was a significant difference between the 2, and what should I be expecting so that I can prepare for the role better.", "author_fullname": "t2_cauyq044", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Grad Job Question Regarding Title", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z54dss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669458555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just been offered a TDP position as a data engineer, but when I applied it was as a data engineer/data scientist. My undergraduate degree is in Data Science. I was wondering if there was a significant difference between the 2, and what should I be expecting so that I can prepare for the role better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z54dss", "is_robot_indexable": true, "report_reasons": null, "author": "honey1337", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z54dss/new_grad_job_question_regarding_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z54dss/new_grad_job_question_regarding_title/", "subreddit_subscribers": 81062, "created_utc": 1669458555.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}