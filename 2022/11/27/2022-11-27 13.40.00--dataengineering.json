{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am practicing mostly medium and few hard SQL and Python from scratascratch and leetcode. I feel confident of solving them but I am not a Data engineer by profession. I am a SQL server DBA in a product based firm. \n \nI have 8+ years of experience in IT but not sure \nhow far to market my resume and experience relevant to 8 years in DE when I appear for interview in near future. Should I be honest and say I am self learned DE or mention based on home projects as experience. \n\nPlease can someone provide some insights on how you cracked into DE world from other profession or IT background. Also would be very helpful if you disclose or share some of the personal projects that helped you attain a new DE roles. Thank you very much", "author_fullname": "t2_m6gnxiuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer projects for interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5fkds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669490561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am practicing mostly medium and few hard SQL and Python from scratascratch and leetcode. I feel confident of solving them but I am not a Data engineer by profession. I am a SQL server DBA in a product based firm. &lt;/p&gt;\n\n&lt;p&gt;I have 8+ years of experience in IT but not sure \nhow far to market my resume and experience relevant to 8 years in DE when I appear for interview in near future. Should I be honest and say I am self learned DE or mention based on home projects as experience. &lt;/p&gt;\n\n&lt;p&gt;Please can someone provide some insights on how you cracked into DE world from other profession or IT background. Also would be very helpful if you disclose or share some of the personal projects that helped you attain a new DE roles. Thank you very much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z5fkds", "is_robot_indexable": true, "report_reasons": null, "author": "rajekum512", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5fkds/data_engineer_projects_for_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5fkds/data_engineer_projects_for_interview/", "subreddit_subscribers": 81076, "created_utc": 1669490561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y\u2019all, I have a use case in which I query data from massive tables. Sometimes I need to make joins or sometimes just filtering. All these queries are performed in prestoSQL. The results from these queries are then saved to S3 in the form of parquet files, then they are processed in python and saved to a postgreSQL DB.\n\nThe results from the queries are not particularly big, at most 1-2GB.\n\nLately I noticed these queries have gotten more complicated and are taking more than 60 minutes to run. I spoke with a coworker, and they suggested that I switch to Spark. \n\nIf I understand correctly, Spark would still need to load the data into worker nodes and then filter and join data. So it would not improve performance significantly. On the flip side if I needed to apply transformations to this massive dataset, then Spark would be the right tool? Am I wrong?", "author_fullname": "t2_7e04ujnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PrestoSQL vs Spark to query data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5n5a3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669510473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all, I have a use case in which I query data from massive tables. Sometimes I need to make joins or sometimes just filtering. All these queries are performed in prestoSQL. The results from these queries are then saved to S3 in the form of parquet files, then they are processed in python and saved to a postgreSQL DB.&lt;/p&gt;\n\n&lt;p&gt;The results from the queries are not particularly big, at most 1-2GB.&lt;/p&gt;\n\n&lt;p&gt;Lately I noticed these queries have gotten more complicated and are taking more than 60 minutes to run. I spoke with a coworker, and they suggested that I switch to Spark. &lt;/p&gt;\n\n&lt;p&gt;If I understand correctly, Spark would still need to load the data into worker nodes and then filter and join data. So it would not improve performance significantly. On the flip side if I needed to apply transformations to this massive dataset, then Spark would be the right tool? Am I wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z5n5a3", "is_robot_indexable": true, "report_reasons": null, "author": "ThatGrayZ", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5n5a3/prestosql_vs_spark_to_query_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5n5a3/prestosql_vs_spark_to_query_data/", "subreddit_subscribers": 81076, "created_utc": 1669510473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hoping to cut past all of the Talend, IBM, Google buzzwords and understand Data Fabric.\n\nCan anyone help?\n\nWhat we have: structured and semi-structured data is landed in Snowflake from various sources (internal and external). We use dbt and Airflow (and a bit of python) to model the data across multiple databases, organised/split by business domain. Some of the data from business domain \u201cA\u201d is private, and stays in their data repository as modelled data. Some of it is considered shareable, and is exposed to the rest of the business through views which can be consumed by the other business units as source data. Same goes for other domains.\n\nData are available in fact &amp; dimensional models within each business domains \u2018hub\u2019. \n\nData can be accessed through SQL for analysts, exposed via APIs (FastAPI) for consumption by business systems, or pushed directly into business systems via their APIs (depending on whether there is a preference for pull vs. push).\n\nSo is this \u2018data fabric\u2019, or just some data marts plus some reverse ETL?\n\nWhere is the difference?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for non-marketing speak understanding of Data Fabric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5q9mk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669524492.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669519530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping to cut past all of the Talend, IBM, Google buzzwords and understand Data Fabric.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n\n&lt;p&gt;What we have: structured and semi-structured data is landed in Snowflake from various sources (internal and external). We use dbt and Airflow (and a bit of python) to model the data across multiple databases, organised/split by business domain. Some of the data from business domain \u201cA\u201d is private, and stays in their data repository as modelled data. Some of it is considered shareable, and is exposed to the rest of the business through views which can be consumed by the other business units as source data. Same goes for other domains.&lt;/p&gt;\n\n&lt;p&gt;Data are available in fact &amp;amp; dimensional models within each business domains \u2018hub\u2019. &lt;/p&gt;\n\n&lt;p&gt;Data can be accessed through SQL for analysts, exposed via APIs (FastAPI) for consumption by business systems, or pushed directly into business systems via their APIs (depending on whether there is a preference for pull vs. push).&lt;/p&gt;\n\n&lt;p&gt;So is this \u2018data fabric\u2019, or just some data marts plus some reverse ETL?&lt;/p&gt;\n\n&lt;p&gt;Where is the difference?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5q9mk", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5q9mk/looking_for_nonmarketing_speak_understanding_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5q9mk/looking_for_nonmarketing_speak_understanding_of/", "subreddit_subscribers": 81076, "created_utc": 1669519530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am exploring options to store several terabytes of data then interactively query them back for exploration etc. I know I could use presto, hive, S3 select or simply spark on parquet, I am open to choose my storage file format, such as delta, parquert, json etc. I am not chasing millisecond latency, up to a few seconds would suffice. However, we have a current infra. of postgreSQL and I am advocating against storing all these data there which I know will be expensive in terms of resource consumption. \n\nI know storing them on S3 and using engines like presto etc. would be several times cheaper. However I am not able to provide some data driven analysis to justify this point of view.  Is this assessment correct? Can someone share some insights into this?", "author_fullname": "t2_tbm1xg4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Presto vs PostgreSQL for data exploration user cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5u2f1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669531490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am exploring options to store several terabytes of data then interactively query them back for exploration etc. I know I could use presto, hive, S3 select or simply spark on parquet, I am open to choose my storage file format, such as delta, parquert, json etc. I am not chasing millisecond latency, up to a few seconds would suffice. However, we have a current infra. of postgreSQL and I am advocating against storing all these data there which I know will be expensive in terms of resource consumption. &lt;/p&gt;\n\n&lt;p&gt;I know storing them on S3 and using engines like presto etc. would be several times cheaper. However I am not able to provide some data driven analysis to justify this point of view.  Is this assessment correct? Can someone share some insights into this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5u2f1", "is_robot_indexable": true, "report_reasons": null, "author": "mayukhdutta", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5u2f1/presto_vs_postgresql_for_data_exploration_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5u2f1/presto_vs_postgresql_for_data_exploration_user/", "subreddit_subscribers": 81076, "created_utc": 1669531490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody else been turned down for a job on financial probity reasons? Had an offer for a Quant job at a hedge fund, but because I got hit by the covid financial crisis I fell behind on bills. Now I am being turned down for roles. Anybody else seeing this?", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5brqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669480828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody else been turned down for a job on financial probity reasons? Had an offer for a Quant job at a hedge fund, but because I got hit by the covid financial crisis I fell behind on bills. Now I am being turned down for roles. Anybody else seeing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z5brqk", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5brqk/curious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5brqk/curious/", "subreddit_subscribers": 81076, "created_utc": 1669480828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a DE interview coming up in the next month. What are the go to resources for Python and SQL (end to end) that you'd recommend. TIA.", "author_fullname": "t2_q0hjyvx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Resources for SQL and Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5tcal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669529030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a DE interview coming up in the next month. What are the go to resources for Python and SQL (end to end) that you&amp;#39;d recommend. TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z5tcal", "is_robot_indexable": true, "report_reasons": null, "author": "Ready--Aim--Fire", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5tcal/interview_resources_for_sql_and_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5tcal/interview_resources_for_sql_and_python/", "subreddit_subscribers": 81076, "created_utc": 1669529030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Goal: migrate a snowflake table (150 million records) to postgres (it is on prem postgres database)\n\n\nCurrent limitations/stack we are using:\n\n- Docker/ecs container (10gb container space)\n- managed aws airflow\n- python\n\nWhat I currently have in mind:\n\n- Export Snowflake table to csv\n- read csv as dataframe (csv export is required for archiving purposes)\n- insert dataframe into Postgres using some Python library ?", "author_fullname": "t2_k95rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best approach to migrate Snowflake table to Postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5agab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669477391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Goal: migrate a snowflake table (150 million records) to postgres (it is on prem postgres database)&lt;/p&gt;\n\n&lt;p&gt;Current limitations/stack we are using:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Docker/ecs container (10gb container space)&lt;/li&gt;\n&lt;li&gt;managed aws airflow&lt;/li&gt;\n&lt;li&gt;python&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I currently have in mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Export Snowflake table to csv&lt;/li&gt;\n&lt;li&gt;read csv as dataframe (csv export is required for archiving purposes)&lt;/li&gt;\n&lt;li&gt;insert dataframe into Postgres using some Python library ?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5agab", "is_robot_indexable": true, "report_reasons": null, "author": "jaspar1", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5agab/best_approach_to_migrate_snowflake_table_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5agab/best_approach_to_migrate_snowflake_table_to/", "subreddit_subscribers": 81076, "created_utc": 1669477391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_invkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing Spark DataFrame to HBase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z57p70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669469662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ayoublabiad.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ayoublabiad.me/posts/spark-to-hbase/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z57p70", "is_robot_indexable": true, "report_reasons": null, "author": "T3Z0", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z57p70/writing_spark_dataframe_to_hbase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ayoublabiad.me/posts/spark-to-hbase/", "subreddit_subscribers": 81076, "created_utc": 1669469662.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}