{"kind": "Listing", "data": {"after": "t3_z6k51u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_gsacrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsuccessful CD-backup with 10mb loss. I wonder why\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_z64gd0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 680, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 680, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_CON2lLLw0s8T5D3bxq7cqazpOKZhqqx1gf7_YYcQYo.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669564095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/s4zogvi83k2a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?auto=webp&amp;s=edbc4691e6896c87fcd34484fe6896ee4e45650d", "width": 3024, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d4ed397ad1dcc5d91f6c3e70affad3f239165628", "width": 108, "height": 108}, {"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=57e1837b619c4da987f9fa3d2887f7995f0deec3", "width": 216, "height": 216}, {"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f98933c1b181c164ee80d30eb2152b041077c90", "width": 320, "height": 320}, {"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=256ea7add3805389ea97ac85f3ee2825e08fecbd", "width": 640, "height": 640}, {"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b3cff8c089c13fba3a058d5e72cbe081c697b93c", "width": 960, "height": 960}, {"url": "https://preview.redd.it/s4zogvi83k2a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe95df3f98adfa1831a5ea09fc7b964b87d39765", "width": 1080, "height": 1080}], "variants": {}, "id": "cbOQEqKMBU6GQ73doidW97WM4t5AAcHovRhUhY4jpYk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "15TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "z64gd0", "is_robot_indexable": true, "report_reasons": null, "author": "alkoka", "discussion_type": null, "num_comments": 98, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/z64gd0/unsuccessful_cdbackup_with_10mb_loss_i_wonder_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/s4zogvi83k2a1.jpg", "subreddit_subscribers": 656537, "created_utc": 1669564095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just thought I would share my experience if it helps others in Australia with a similar experience.\n\nI shucked a Seagate 5TB Hard Drive I purchased from Amazon Australia on July 2022.  It was in my Unraid server and now refuses to power up at all, completely dead. \n\nI tried to use the return process on the Amazon site, but it doesn't work since its outside of the 30 day return window.  Since the drive itself has a 2 year warranty, I contacted chat.  They gave me a standard auto reply of \"You need to go back to the manufacturer for the warranty\" which is not how it works in Australia (in Australian consumer law, the retailer cannot refer you to the manufacturer or importer for warranty repairs).  I replied with this information, and the chat officer offered to have someone higher up call me on my phone.\n\nI received the phone call, and the phone support was perfectly fine.  I told them I needed to return a drive for warranty, but it was outside of the 30 days, but still has a 2 year warranty, and that I am in Australia, and purchased from Amazon Australia and needed to use them for the warranty.  He accepted it straight away, and sent me a brand new 5TB Seagate Drive (he asked if I wanted a refund or replacement, but since I use it I went with replacement).\n\nAll done and dusted, completely swapped under warranty!  Not sure how it works in other countries, but in Australia the manufacturer has the burden of proof to show that shucking the drive caused the failure before they can reject a warranty, and retailer are required to work with the consumer to facilitate the warranty process (they cannot refer to manufacturer).\n\nIf you are in Australia and need to refer to the specific detail around manufacturers warranties, just send them this: [https://www.accc.gov.au/consumers/problem-with-a-product-or-service-you-bought/repair-replace-refund-cancel](https://www.accc.gov.au/consumers/problem-with-a-product-or-service-you-bought/repair-replace-refund-cancel)", "author_fullname": "t2_97ru1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Successful experience with Seagate shucked drive warranty and Amazon in Australia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5wnft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 178, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 178, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669540664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just thought I would share my experience if it helps others in Australia with a similar experience.&lt;/p&gt;\n\n&lt;p&gt;I shucked a Seagate 5TB Hard Drive I purchased from Amazon Australia on July 2022.  It was in my Unraid server and now refuses to power up at all, completely dead. &lt;/p&gt;\n\n&lt;p&gt;I tried to use the return process on the Amazon site, but it doesn&amp;#39;t work since its outside of the 30 day return window.  Since the drive itself has a 2 year warranty, I contacted chat.  They gave me a standard auto reply of &amp;quot;You need to go back to the manufacturer for the warranty&amp;quot; which is not how it works in Australia (in Australian consumer law, the retailer cannot refer you to the manufacturer or importer for warranty repairs).  I replied with this information, and the chat officer offered to have someone higher up call me on my phone.&lt;/p&gt;\n\n&lt;p&gt;I received the phone call, and the phone support was perfectly fine.  I told them I needed to return a drive for warranty, but it was outside of the 30 days, but still has a 2 year warranty, and that I am in Australia, and purchased from Amazon Australia and needed to use them for the warranty.  He accepted it straight away, and sent me a brand new 5TB Seagate Drive (he asked if I wanted a refund or replacement, but since I use it I went with replacement).&lt;/p&gt;\n\n&lt;p&gt;All done and dusted, completely swapped under warranty!  Not sure how it works in other countries, but in Australia the manufacturer has the burden of proof to show that shucking the drive caused the failure before they can reject a warranty, and retailer are required to work with the consumer to facilitate the warranty process (they cannot refer to manufacturer).&lt;/p&gt;\n\n&lt;p&gt;If you are in Australia and need to refer to the specific detail around manufacturers warranties, just send them this: &lt;a href=\"https://www.accc.gov.au/consumers/problem-with-a-product-or-service-you-bought/repair-replace-refund-cancel\"&gt;https://www.accc.gov.au/consumers/problem-with-a-product-or-service-you-bought/repair-replace-refund-cancel&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kYgYPJxQHuNfHIehCMFgEP5oTl1c2s2s1ISzqlEBfZw.jpg?auto=webp&amp;s=69946f55186e74bc67d2d710c11f046da13a6ba9", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/kYgYPJxQHuNfHIehCMFgEP5oTl1c2s2s1ISzqlEBfZw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3db18616e62043ca576e083548323c9f9591253", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/kYgYPJxQHuNfHIehCMFgEP5oTl1c2s2s1ISzqlEBfZw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=386af2f6ea972720e14fa3fbf056bac6c9b33244", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/kYgYPJxQHuNfHIehCMFgEP5oTl1c2s2s1ISzqlEBfZw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e23d609ff104288a748a8755a7a47568214d6dd4", "width": 320, "height": 320}], "variants": {}, "id": "0Qwg0JuvFvUB9Yons4HzE81BxnnS4dWrXxiYaFetczI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z5wnft", "is_robot_indexable": true, "report_reasons": null, "author": "holastickboy", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z5wnft/successful_experience_with_seagate_shucked_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z5wnft/successful_experience_with_seagate_shucked_drive/", "subreddit_subscribers": 656537, "created_utc": 1669540664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m going to be using UnRAID. I bought a couple 18tb exos x18 manufacturer recertified drives (1 for data and 1 for parity). Should I test them? If so, how, which tests, and how long will it take? I\u2019m gonna be eager to use them when I get em haha. Thank you!", "author_fullname": "t2_dahbpb7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I have to run any tests on my hard drives before I use them? If so, which tests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z64fxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669564066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going to be using UnRAID. I bought a couple 18tb exos x18 manufacturer recertified drives (1 for data and 1 for parity). Should I test them? If so, how, which tests, and how long will it take? I\u2019m gonna be eager to use them when I get em haha. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z64fxo", "is_robot_indexable": true, "report_reasons": null, "author": "v-a-g", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z64fxo/do_i_have_to_run_any_tests_on_my_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z64fxo/do_i_have_to_run_any_tests_on_my_hard_drives/", "subreddit_subscribers": 656537, "created_utc": 1669564066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "You download your information from Facebook, and just thousands of files you need to open one by one. Is there a way to make this actually useful and accessible?", "author_fullname": "t2_4rtg6gja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can you actually use your facebook information downloaded?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6hro4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669595653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You download your information from Facebook, and just thousands of files you need to open one by one. Is there a way to make this actually useful and accessible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "z6hro4", "is_robot_indexable": true, "report_reasons": null, "author": "stackshockprism", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6hro4/how_can_you_actually_use_your_facebook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6hro4/how_can_you_actually_use_your_facebook/", "subreddit_subscribers": 656537, "created_utc": 1669595653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[This article](https://www.servethehome.com/wd-red-pro-20tb-launched-with-wickedly-weak-workload-rating/) on ServeTheHome got me thinking... in a RAID array where periodic \"scrubs\" or consistency checks are recommended to prevent bit rot, the entire disk has to be read. \n\nI did some quick math for my own array which uses HGST He10 10TB drives with 550TB/yr rated workload and the default MegaRAID settings of weekly consistency check AND patrol read, resulting in\n\n10TB * 2 * 52 = 1040TB/yr read\n\nWhile doing both of them monthly instead is\n\n10TB * 2 * 12 = 240TB/yr read, leaving 310TB/yr for actually using the drives\n\nI searched to see if anyone else had posted here or on other forums about this concern and couldn't find anything. Should I reduce the frequency to monthly to avoid 'wearing out' the drives, or is a weekly check needed to prevent bit rot on high capacity drives?\n\nEDIT: thanks for all the data points confirming monthly check is okay! I was going by some old threads like [this one](https://community.spiceworks.com/topic/1648419-lsi-megaraid-patrol-read-and-consistency-check-schedule-recommendations) which scared me into thinking I needed to keep the weekly default. I've switched mine to monthly now.", "author_fullname": "t2_10gstl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running weekly consistency checks on 10TB+ drives exceeds the rated annual workload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z68j76", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669583861.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669573609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.servethehome.com/wd-red-pro-20tb-launched-with-wickedly-weak-workload-rating/\"&gt;This article&lt;/a&gt; on ServeTheHome got me thinking... in a RAID array where periodic &amp;quot;scrubs&amp;quot; or consistency checks are recommended to prevent bit rot, the entire disk has to be read. &lt;/p&gt;\n\n&lt;p&gt;I did some quick math for my own array which uses HGST He10 10TB drives with 550TB/yr rated workload and the default MegaRAID settings of weekly consistency check AND patrol read, resulting in&lt;/p&gt;\n\n&lt;p&gt;10TB * 2 * 52 = 1040TB/yr read&lt;/p&gt;\n\n&lt;p&gt;While doing both of them monthly instead is&lt;/p&gt;\n\n&lt;p&gt;10TB * 2 * 12 = 240TB/yr read, leaving 310TB/yr for actually using the drives&lt;/p&gt;\n\n&lt;p&gt;I searched to see if anyone else had posted here or on other forums about this concern and couldn&amp;#39;t find anything. Should I reduce the frequency to monthly to avoid &amp;#39;wearing out&amp;#39; the drives, or is a weekly check needed to prevent bit rot on high capacity drives?&lt;/p&gt;\n\n&lt;p&gt;EDIT: thanks for all the data points confirming monthly check is okay! I was going by some old threads like &lt;a href=\"https://community.spiceworks.com/topic/1648419-lsi-megaraid-patrol-read-and-consistency-check-schedule-recommendations\"&gt;this one&lt;/a&gt; which scared me into thinking I needed to keep the weekly default. I&amp;#39;ve switched mine to monthly now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BUZXwSx4FYKZmj-VU6fkiJFn3ZbX_w4URhT0fUwD-mg.jpg?auto=webp&amp;s=cb351bd56b93ca009b377beba589db481b6848f8", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/BUZXwSx4FYKZmj-VU6fkiJFn3ZbX_w4URhT0fUwD-mg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35cecc1f6cc5bf3533dd0bb979ed4aaf207b5921", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/BUZXwSx4FYKZmj-VU6fkiJFn3ZbX_w4URhT0fUwD-mg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19630e261c1b90ff636bb0adcb95f3573d512bfb", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/BUZXwSx4FYKZmj-VU6fkiJFn3ZbX_w4URhT0fUwD-mg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d302121db869389decf9fd03a6cc3e66db8d9c6c", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/BUZXwSx4FYKZmj-VU6fkiJFn3ZbX_w4URhT0fUwD-mg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dd1a46d03245e6f7771d376e4f1768bd0befa817", "width": 640, "height": 480}], "variants": {}, "id": "Db_RhGlIp4EmXb0BNwixBz21lbTamvNQ-ZavgIbxi0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "z68j76", "is_robot_indexable": true, "report_reasons": null, "author": "denpa_", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z68j76/running_weekly_consistency_checks_on_10tb_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z68j76/running_weekly_consistency_checks_on_10tb_drives/", "subreddit_subscribers": 656537, "created_utc": 1669573609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve heard that If you\n\nA) watch a movie from an external hdd\n\nB) transfer data to an external hdd\n\nC) transfer data from an external hdd to somewhere else\n\n(So If you use It) The lifespan of the external hdd get shorter.\n\nNow my question is;\n\nDoes The Lifespan Of An External HDD Get Shorter When It\u2019s Plugged To A Device (or a USB Hub then into a device) (The HDD\u2019s Light Is On) However Without Being Used?", "author_fullname": "t2_4rs6ei0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does The Lifespan Of An External HDD Get Shorter When It\u2019s Plugged To A Device (The Light Is On) However Without Being Used", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5uujg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669534186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard that If you&lt;/p&gt;\n\n&lt;p&gt;A) watch a movie from an external hdd&lt;/p&gt;\n\n&lt;p&gt;B) transfer data to an external hdd&lt;/p&gt;\n\n&lt;p&gt;C) transfer data from an external hdd to somewhere else&lt;/p&gt;\n\n&lt;p&gt;(So If you use It) The lifespan of the external hdd get shorter.&lt;/p&gt;\n\n&lt;p&gt;Now my question is;&lt;/p&gt;\n\n&lt;p&gt;Does The Lifespan Of An External HDD Get Shorter When It\u2019s Plugged To A Device (or a USB Hub then into a device) (The HDD\u2019s Light Is On) However Without Being Used?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z5uujg", "is_robot_indexable": true, "report_reasons": null, "author": "mainecoon364", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z5uujg/does_the_lifespan_of_an_external_hdd_get_shorter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z5uujg/does_the_lifespan_of_an_external_hdd_get_shorter/", "subreddit_subscribers": 656537, "created_utc": 1669534186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Most here have at least 1TB+ my self included. I\u2019m a Mac user so I haven\u2019t found out how to scan a drive or a folder for corrupt files but so far I haven\u2019t encountered any issues. What are your experiences? \n\nAll my drives are stationary so nothings ever been dropped or exposed to water or anything which helps my case for sure.", "author_fullname": "t2_2o8t3n2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often have you experienced a corrupt file(s)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6e88z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669586931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most here have at least 1TB+ my self included. I\u2019m a Mac user so I haven\u2019t found out how to scan a drive or a folder for corrupt files but so far I haven\u2019t encountered any issues. What are your experiences? &lt;/p&gt;\n\n&lt;p&gt;All my drives are stationary so nothings ever been dropped or exposed to water or anything which helps my case for sure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6e88z", "is_robot_indexable": true, "report_reasons": null, "author": "QualitySound96", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6e88z/how_often_have_you_experienced_a_corrupt_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6e88z/how_often_have_you_experienced_a_corrupt_files/", "subreddit_subscribers": 656537, "created_utc": 1669586931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I have been backing up games for well over a decade now and have something like 60TB including artwork. I know a RAID isn\u2019t a backup and I had a bit of a scare the other day and I\u2019ve decided to get serious about making a backup. I was looking into tape drives and I never realized how expensive they were, but something needs done. So\u2026 what do you all recommend? I\u2019ve been looking at an IBM 3592-E08\n\nThank you.", "author_fullname": "t2_14mq9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "60+TB Gaming NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6aglm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669578136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I have been backing up games for well over a decade now and have something like 60TB including artwork. I know a RAID isn\u2019t a backup and I had a bit of a scare the other day and I\u2019ve decided to get serious about making a backup. I was looking into tape drives and I never realized how expensive they were, but something needs done. So\u2026 what do you all recommend? I\u2019ve been looking at an IBM 3592-E08&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6aglm", "is_robot_indexable": true, "report_reasons": null, "author": "Sasquatters", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6aglm/60tb_gaming_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6aglm/60tb_gaming_nas/", "subreddit_subscribers": 656537, "created_utc": 1669578136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been ripping some cds using exact audio copy with accurate rip setup. I tried to submit my results to the database and it says it successful however when I try to rip the CD again it says tracks not in accurate rip database. I tried disabling my firewall and using another computer but results are the same. Is there anything I could to so that my results get uploaded? No issues with the cds as well all ripped accurately according to cue tools.", "author_fullname": "t2_4evp94do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EAC accurate rip results wont upload to database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6ik0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669597777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been ripping some cds using exact audio copy with accurate rip setup. I tried to submit my results to the database and it says it successful however when I try to rip the CD again it says tracks not in accurate rip database. I tried disabling my firewall and using another computer but results are the same. Is there anything I could to so that my results get uploaded? No issues with the cds as well all ripped accurately according to cue tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6ik0v", "is_robot_indexable": true, "report_reasons": null, "author": "atitann", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6ik0v/eac_accurate_rip_results_wont_upload_to_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6ik0v/eac_accurate_rip_results_wont_upload_to_database/", "subreddit_subscribers": 656537, "created_utc": 1669597777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I hope everyone took advantage of Black Friday to fill your storage arrays. For those that bought external drives to shuck, I have a request. I\u2019m trying to help a couple friends get started in data hoarding and self hosting. Since I have a good stock of old spinners and the mini-PC\u2019s that I am using don\u2019t have internal SATA slots, I was hoping to buy some external enclosures for cheap to keep their costs down. \nI\u2019d recommend that you keep a couple enclosures for Warranty returns but if you have extras let me know. Thanks for your time. If this post violates any rules, I am extremely sorry and will delete it immediately.\n\nEdit: I was asked to include my location since I am asking if people are willing to ship items. I am located in Florida USA. Thanks for checking out the post.", "author_fullname": "t2_b6lf4lta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucked drive enclosures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z60zax", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669580860.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669554943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope everyone took advantage of Black Friday to fill your storage arrays. For those that bought external drives to shuck, I have a request. I\u2019m trying to help a couple friends get started in data hoarding and self hosting. Since I have a good stock of old spinners and the mini-PC\u2019s that I am using don\u2019t have internal SATA slots, I was hoping to buy some external enclosures for cheap to keep their costs down. \nI\u2019d recommend that you keep a couple enclosures for Warranty returns but if you have extras let me know. Thanks for your time. If this post violates any rules, I am extremely sorry and will delete it immediately.&lt;/p&gt;\n\n&lt;p&gt;Edit: I was asked to include my location since I am asking if people are willing to ship items. I am located in Florida USA. Thanks for checking out the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "24TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z60zax", "is_robot_indexable": true, "report_reasons": null, "author": "NotablyNotABot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/z60zax/shucked_drive_enclosures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z60zax/shucked_drive_enclosures/", "subreddit_subscribers": 656537, "created_utc": 1669554943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Got some new WD drives in a new NAS for my dad, but they're (or at least one of them is) making a clicking sound that's a bit concerning. I can't tell if this is normal or an issue (SMART checks pass, but I know that isn't a real tell of longevity)\n\nHere is a short audio recording I made directly next to the NAS. What do ya'll think?\n\n[An audio recording](https://icedrive.net/s/xh8SvtFxfTjTAzzvuZFRgxhb7Fb5)", "author_fullname": "t2_7gojn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New HDD's making clicking sound, SMART checks pass. They toast?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5uaue", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669532302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got some new WD drives in a new NAS for my dad, but they&amp;#39;re (or at least one of them is) making a clicking sound that&amp;#39;s a bit concerning. I can&amp;#39;t tell if this is normal or an issue (SMART checks pass, but I know that isn&amp;#39;t a real tell of longevity)&lt;/p&gt;\n\n&lt;p&gt;Here is a short audio recording I made directly next to the NAS. What do ya&amp;#39;ll think?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://icedrive.net/s/xh8SvtFxfTjTAzzvuZFRgxhb7Fb5\"&gt;An audio recording&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z5uaue", "is_robot_indexable": true, "report_reasons": null, "author": "Harrismcc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z5uaue/new_hdds_making_clicking_sound_smart_checks_pass/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z5uaue/new_hdds_making_clicking_sound_smart_checks_pass/", "subreddit_subscribers": 656537, "created_utc": 1669532302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings friends,\n\nI'm sitting on a pile of PDFs I'd like to organize and searchable. I've come across paperless, but building a NAS or a raspberry pi just to tag and search some PDFs seems overkill, and with 2 young kids and 2 more on the way, I don't have a huge amount of time to fiddle around with tech.\n\nCurrently, all that stuff is handled in Evernote, but if possible, I'd like to leave behind the world of proprietary systems for that task.\n\nAny advice?", "author_fullname": "t2_1233ak", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PDF library: Solution for OCR and tagging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6a1nd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669577146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings friends,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sitting on a pile of PDFs I&amp;#39;d like to organize and searchable. I&amp;#39;ve come across paperless, but building a NAS or a raspberry pi just to tag and search some PDFs seems overkill, and with 2 young kids and 2 more on the way, I don&amp;#39;t have a huge amount of time to fiddle around with tech.&lt;/p&gt;\n\n&lt;p&gt;Currently, all that stuff is handled in Evernote, but if possible, I&amp;#39;d like to leave behind the world of proprietary systems for that task.&lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6a1nd", "is_robot_indexable": true, "report_reasons": null, "author": "Gilgeam", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6a1nd/pdf_library_solution_for_ocr_and_tagging/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6a1nd/pdf_library_solution_for_ocr_and_tagging/", "subreddit_subscribers": 656537, "created_utc": 1669577146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've noticed on YouTube that various artists have a \" - Topic\" channel. I'm assuming it's an auto-generated amalgamation of videos by an artist that YouTube somehow put together, but I'm not sure.\n\nFor example, an artsit that I listen to, Federico Epis, has this channel: [https://www.youtube.com/channel/UC6pbfgM7skTJy6uRp-k7gfw](https://www.youtube.com/channel/UC6pbfgM7skTJy6uRp-k7gfw) (Federico Epis - Topic). When I explore the channel, I can only see playlists. There's no tab for \"Videos\". OK, fine, I can at least listen to the playlists.\n\nBrowsing Youtube further, however, I come across this video: [https://www.youtube.com/watch?v=e4ztScBoOtA&amp;ab\\_channel=FedericoEpis-Topic](https://www.youtube.com/watch?v=e4ztScBoOtA&amp;ab_channel=FedericoEpis-Topic). Apparently this is another video that belongs to the \"Federico Epis - Topic\" channel, but it cannot be found when looking at the channel link (the first link I provided in this post). The video is not considered \"unlisted\" so how come I didn't see it when I looked at the channel link?\n\nSo, here are my questions:\n\n1. What exactly is a \"Artist - Topic\" channel?\n2. How is it generated and what are the rules for a video to show up under a \"Artist - Topic\" channel if this auto-generated?\n3. How can I see all videos that are tagged to the \"Artist - Topic\" channel? (In this case, how can I see all the videos that are tagged to the \"Federico Epis - Topic\" channel?)", "author_fullname": "t2_74i2uwce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone help me understand what are \"Artist - Topic\" channels on YouTube?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6kbft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669602667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed on YouTube that various artists have a &amp;quot; - Topic&amp;quot; channel. I&amp;#39;m assuming it&amp;#39;s an auto-generated amalgamation of videos by an artist that YouTube somehow put together, but I&amp;#39;m not sure.&lt;/p&gt;\n\n&lt;p&gt;For example, an artsit that I listen to, Federico Epis, has this channel: &lt;a href=\"https://www.youtube.com/channel/UC6pbfgM7skTJy6uRp-k7gfw\"&gt;https://www.youtube.com/channel/UC6pbfgM7skTJy6uRp-k7gfw&lt;/a&gt; (Federico Epis - Topic). When I explore the channel, I can only see playlists. There&amp;#39;s no tab for &amp;quot;Videos&amp;quot;. OK, fine, I can at least listen to the playlists.&lt;/p&gt;\n\n&lt;p&gt;Browsing Youtube further, however, I come across this video: &lt;a href=\"https://www.youtube.com/watch?v=e4ztScBoOtA&amp;amp;ab_channel=FedericoEpis-Topic\"&gt;https://www.youtube.com/watch?v=e4ztScBoOtA&amp;amp;ab_channel=FedericoEpis-Topic&lt;/a&gt;. Apparently this is another video that belongs to the &amp;quot;Federico Epis - Topic&amp;quot; channel, but it cannot be found when looking at the channel link (the first link I provided in this post). The video is not considered &amp;quot;unlisted&amp;quot; so how come I didn&amp;#39;t see it when I looked at the channel link?&lt;/p&gt;\n\n&lt;p&gt;So, here are my questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What exactly is a &amp;quot;Artist - Topic&amp;quot; channel?&lt;/li&gt;\n&lt;li&gt;How is it generated and what are the rules for a video to show up under a &amp;quot;Artist - Topic&amp;quot; channel if this auto-generated?&lt;/li&gt;\n&lt;li&gt;How can I see all videos that are tagged to the &amp;quot;Artist - Topic&amp;quot; channel? (In this case, how can I see all the videos that are tagged to the &amp;quot;Federico Epis - Topic&amp;quot; channel?)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/k5Ff-zKorgztzJH_rYUjZzetG2LbOZ3oFBjSol8es0g.jpg?auto=webp&amp;s=5b33315284da2c60aa9ef5b3c7b1ce868bfdd5bb", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/k5Ff-zKorgztzJH_rYUjZzetG2LbOZ3oFBjSol8es0g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aadddbf6ebba588fa2ef8e45ff2954199ff3345a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/k5Ff-zKorgztzJH_rYUjZzetG2LbOZ3oFBjSol8es0g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7f88d73824973f9d72caf87dfdae35c32bc119f", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/k5Ff-zKorgztzJH_rYUjZzetG2LbOZ3oFBjSol8es0g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=373fa146344a0f0fe45a71596b593d7ad0471b11", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/k5Ff-zKorgztzJH_rYUjZzetG2LbOZ3oFBjSol8es0g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=77a98838fb18c5703c85bc1b9dd6e25008fc6e2c", "width": 640, "height": 640}], "variants": {}, "id": "duDU8ooauBcZ6hE0NSKN9Y1S548ZAxdMKQP-iL5vOFg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6kbft", "is_robot_indexable": true, "report_reasons": null, "author": "humelectra2000", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6kbft/can_someone_help_me_understand_what_are_artist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6kbft/can_someone_help_me_understand_what_are_artist/", "subreddit_subscribers": 656537, "created_utc": 1669602667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to search through all the messages over the past few months to the last year to see what was said and when. It's almost impossible to do and I need an easier way. I need to document things for a custody case, I don't really know a functional way to do it.", "author_fullname": "t2_4rtg6gja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to actually view, read, print, all texts and Facebook messages in a thread?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z65xk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669567588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to search through all the messages over the past few months to the last year to see what was said and when. It&amp;#39;s almost impossible to do and I need an easier way. I need to document things for a custody case, I don&amp;#39;t really know a functional way to do it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z65xk2", "is_robot_indexable": true, "report_reasons": null, "author": "stackshockprism", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z65xk2/how_to_actually_view_read_print_all_texts_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z65xk2/how_to_actually_view_read_print_all_texts_and/", "subreddit_subscribers": 656537, "created_utc": 1669567588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to set up a self hosted paperless instance and digitize all my physical documents.  I'd like to get a scanner than can scan a small stack of papers at a time, on both sides, and deposit them vita FTP/NFS/SMB/SMTP to a directory to be consumed by paperless.  I've heard there is also some detection feature for accidently scanning two pages stuck together, I probably want that as well.  I have no need to run this printer independently of a PC but I don't mind if it does.  Has anyone been through this and have a scanner that they like?  I'm happy to spend whatever budget to buy it for life and hit that price to performance sweet spot.  Better than replacing is down the line when it has problems..", "author_fullname": "t2_zjagd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a document scanner for Paperless-ng", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z65tem", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669567326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to set up a self hosted paperless instance and digitize all my physical documents.  I&amp;#39;d like to get a scanner than can scan a small stack of papers at a time, on both sides, and deposit them vita FTP/NFS/SMB/SMTP to a directory to be consumed by paperless.  I&amp;#39;ve heard there is also some detection feature for accidently scanning two pages stuck together, I probably want that as well.  I have no need to run this printer independently of a PC but I don&amp;#39;t mind if it does.  Has anyone been through this and have a scanner that they like?  I&amp;#39;m happy to spend whatever budget to buy it for life and hit that price to performance sweet spot.  Better than replacing is down the line when it has problems..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z65tem", "is_robot_indexable": true, "report_reasons": null, "author": "jswervedizzle", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z65tem/looking_for_a_document_scanner_for_paperlessng/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z65tem/looking_for_a_document_scanner_for_paperlessng/", "subreddit_subscribers": 656537, "created_utc": 1669567326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Redditors,\n\nI have a novice question.  \n\nDo 3.5\" drives that are used to write once and accessed once every blue moon because they are stored elsewhere have more durability than one inside a system that has daily usage or it does not matter?", "author_fullname": "t2_3luaynwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD longevity when not used", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z64ff3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669564033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Redditors,&lt;/p&gt;\n\n&lt;p&gt;I have a novice question.  &lt;/p&gt;\n\n&lt;p&gt;Do 3.5&amp;quot; drives that are used to write once and accessed once every blue moon because they are stored elsewhere have more durability than one inside a system that has daily usage or it does not matter?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z64ff3", "is_robot_indexable": true, "report_reasons": null, "author": "LightDarkCloud", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z64ff3/hdd_longevity_when_not_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z64ff3/hdd_longevity_when_not_used/", "subreddit_subscribers": 656537, "created_utc": 1669564033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "after using this guide [https://www.youtube.com/watch?v=NcoHC\\_colJI](https://www.youtube.com/watch?v=NcoHC_colJI) i have come to step 16 and gotten this error.\n\n'gallery-dl' is not recognized as an internal or external command, operable program or batch file.\n\ni don't know what the problem is if my path is wrong or i installed something wrong since helpful resources are pretty limited on this tool", "author_fullname": "t2_3vs8ycwi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with setting up gallery-dl", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z628cw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669558471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;after using this guide &lt;a href=\"https://www.youtube.com/watch?v=NcoHC_colJI\"&gt;https://www.youtube.com/watch?v=NcoHC_colJI&lt;/a&gt; i have come to step 16 and gotten this error.&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;gallery-dl&amp;#39; is not recognized as an internal or external command, operable program or batch file.&lt;/p&gt;\n\n&lt;p&gt;i don&amp;#39;t know what the problem is if my path is wrong or i installed something wrong since helpful resources are pretty limited on this tool&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Mm-0dQETfgbXW7_blV7WmJHiC52IUVlsyfKc-Okzzik.jpg?auto=webp&amp;s=b2d3d20b8f1463147fd4bf60b26421ca28b4ee78", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Mm-0dQETfgbXW7_blV7WmJHiC52IUVlsyfKc-Okzzik.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=962cfa6871366138a7784cd7bb9f72d8e4fa9ce1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Mm-0dQETfgbXW7_blV7WmJHiC52IUVlsyfKc-Okzzik.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=21ecfbe0f27ff8d16f7b0bea91f6910dfd5568db", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Mm-0dQETfgbXW7_blV7WmJHiC52IUVlsyfKc-Okzzik.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e847943dfe150a9a710d3b970204966ad667250", "width": 320, "height": 240}], "variants": {}, "id": "fvECVZjiYNCcUHBOVfz8Q9vhm-25KIEwn-GQdUMCCDc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z628cw", "is_robot_indexable": true, "report_reasons": null, "author": "totalpotat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z628cw/help_with_setting_up_gallerydl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z628cw/help_with_setting_up_gallerydl/", "subreddit_subscribers": 656537, "created_utc": 1669558471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had experiences in the past of having a zip file corrupt for some reason (bad sectors or something) and then lost the ability to read it at all. So all the contents was lost. I felt that if it wasn't zipped that perhaps only a single, or some of the files would be lost due to corruption instead of all of it.  This was long ago so I was wondering if this thinking was correct?  Is there an increased chance of data loss when lots of files are zipped together?", "author_fullname": "t2_8y2c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Zipping a safe way to store?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z620th", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669557908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had experiences in the past of having a zip file corrupt for some reason (bad sectors or something) and then lost the ability to read it at all. So all the contents was lost. I felt that if it wasn&amp;#39;t zipped that perhaps only a single, or some of the files would be lost due to corruption instead of all of it.  This was long ago so I was wondering if this thinking was correct?  Is there an increased chance of data loss when lots of files are zipped together?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z620th", "is_robot_indexable": true, "report_reasons": null, "author": "x0y0z0", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z620th/is_zipping_a_safe_way_to_store/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z620th/is_zipping_a_safe_way_to_store/", "subreddit_subscribers": 656537, "created_utc": 1669557908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning to build a NAS with unraid which will have 2x14, 2x8 TB,  for now. This NAS will be a standalone and act as NAS without Plex or  any other services. I want to have another system working as the main  server. I currently have few optoins at my disposal and was wondering  what would be the best use of current resources. Some are already built  systems and some need to be built.\n\nExpand-ability: slowly but not sure to what storage.\n\nPower consumption: Preferred low, as it might be idle 70% at least for the first year.\n\n&amp;#x200B;\n\nOption1 (Preferred option):\n\n[i5-2400](https://www.intel.com/content/www/us/en/products/sku/52207/intel-core-i52400-processor-6m-cache-up-to-3-40-ghz/specifications.html), 8GB (not expandable) ram as NAS and[ i5-8500T](https://ark.intel.com/content/www/us/en/ark/products/129941/intel-core-i58500t-processor-9m-cache-up-to-3-50-ghz.html), 16GB as the main server\n\nOption2:\n\n[i3-10105F](https://www.intel.com/content/www/us/en/products/sku/203474/intel-core-i310105f-processor-6m-cache-up-to-4-40-ghz/specifications.html), xGB (need to be built) and [i5-8500T](https://ark.intel.com/content/www/us/en/ark/products/129941/intel-core-i58500t-processor-9m-cache-up-to-3-50-ghz.html), 16GB - either can be used for either purpose\n\nOption3:\n\n[i7-6700](https://www.intel.com/content/www/us/en/products/sku/88195/intel-core-i76700k-processor-8m-cache-up-to-4-20-ghz/specifications.html), xGB (need to be built) and [i5-8500T](https://ark.intel.com/content/www/us/en/ark/products/129941/intel-core-i58500t-processor-9m-cache-up-to-3-50-ghz.html), 16GB - either can be used for either purpose\n\nOption4:\n\nUse either of the above systems to do the whole server in one massive system, which has all the HDD's and the main server.\n\n&amp;#x200B;\n\nComparison of CPU's  \n[https://www.cpubenchmark.net/compare/3231vs2565vs4175/Intel-i5-8500T-vs-Intel-i7-6700K-vs-Intel-i3-10105F](https://www.cpubenchmark.net/compare/3231vs2565vs4175/Intel-i5-8500T-vs-Intel-i7-6700K-vs-Intel-i3-10105F)\n\n&amp;#x200B;\n\nAlso, have a [1060](https://www.evga.com/products/specs/gpu.aspx?pn=e466f076-3e8f-4825-b4b0-f1863e893972), 6GB nvidia if that can be leveraged.\n\nAs mentioned would prefer to use the existing builds but wondering if 2nd gen would be sufficient enough.", "author_fullname": "t2_2lkmjxkk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[BUILD HELP] Choosing right CPU and RAM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z6ojsg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669615353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to build a NAS with unraid which will have 2x14, 2x8 TB,  for now. This NAS will be a standalone and act as NAS without Plex or  any other services. I want to have another system working as the main  server. I currently have few optoins at my disposal and was wondering  what would be the best use of current resources. Some are already built  systems and some need to be built.&lt;/p&gt;\n\n&lt;p&gt;Expand-ability: slowly but not sure to what storage.&lt;/p&gt;\n\n&lt;p&gt;Power consumption: Preferred low, as it might be idle 70% at least for the first year.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Option1 (Preferred option):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.intel.com/content/www/us/en/products/sku/52207/intel-core-i52400-processor-6m-cache-up-to-3-40-ghz/specifications.html\"&gt;i5-2400&lt;/a&gt;, 8GB (not expandable) ram as NAS and&lt;a href=\"https://ark.intel.com/content/www/us/en/ark/products/129941/intel-core-i58500t-processor-9m-cache-up-to-3-50-ghz.html\"&gt; i5-8500T&lt;/a&gt;, 16GB as the main server&lt;/p&gt;\n\n&lt;p&gt;Option2:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.intel.com/content/www/us/en/products/sku/203474/intel-core-i310105f-processor-6m-cache-up-to-4-40-ghz/specifications.html\"&gt;i3-10105F&lt;/a&gt;, xGB (need to be built) and &lt;a href=\"https://ark.intel.com/content/www/us/en/ark/products/129941/intel-core-i58500t-processor-9m-cache-up-to-3-50-ghz.html\"&gt;i5-8500T&lt;/a&gt;, 16GB - either can be used for either purpose&lt;/p&gt;\n\n&lt;p&gt;Option3:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.intel.com/content/www/us/en/products/sku/88195/intel-core-i76700k-processor-8m-cache-up-to-4-20-ghz/specifications.html\"&gt;i7-6700&lt;/a&gt;, xGB (need to be built) and &lt;a href=\"https://ark.intel.com/content/www/us/en/ark/products/129941/intel-core-i58500t-processor-9m-cache-up-to-3-50-ghz.html\"&gt;i5-8500T&lt;/a&gt;, 16GB - either can be used for either purpose&lt;/p&gt;\n\n&lt;p&gt;Option4:&lt;/p&gt;\n\n&lt;p&gt;Use either of the above systems to do the whole server in one massive system, which has all the HDD&amp;#39;s and the main server.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Comparison of CPU&amp;#39;s&lt;br/&gt;\n&lt;a href=\"https://www.cpubenchmark.net/compare/3231vs2565vs4175/Intel-i5-8500T-vs-Intel-i7-6700K-vs-Intel-i3-10105F\"&gt;https://www.cpubenchmark.net/compare/3231vs2565vs4175/Intel-i5-8500T-vs-Intel-i7-6700K-vs-Intel-i3-10105F&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also, have a &lt;a href=\"https://www.evga.com/products/specs/gpu.aspx?pn=e466f076-3e8f-4825-b4b0-f1863e893972\"&gt;1060&lt;/a&gt;, 6GB nvidia if that can be leveraged.&lt;/p&gt;\n\n&lt;p&gt;As mentioned would prefer to use the existing builds but wondering if 2nd gen would be sufficient enough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?auto=webp&amp;s=0402e358a1b5b71d7e7e3840908c20761a156712", "width": 586, "height": 387}, "resolutions": [{"url": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a95ee4184562ea6e68359542a9ba4fac4f67356", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db96825d26a40d3ff36bd9249696f6589a6c12f4", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/Hlbf52-zMgk3lZiQPiNlVwXxuQqfSuHNMRFDsvyExVQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=09df17da18177e610ef5f2a653e8af6a754ba14d", "width": 320, "height": 211}], "variants": {}, "id": "7wlnlsb1p8kqETD6MDhVPbujRAXC14mk8BJ3S2O8fCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6ojsg", "is_robot_indexable": true, "report_reasons": null, "author": "batmaniac77", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6ojsg/build_help_choosing_right_cpu_and_ram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6ojsg/build_help_choosing_right_cpu_and_ram/", "subreddit_subscribers": 656537, "created_utc": 1669615353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_11dj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate IronWolf Pro 20TB NAS Hard Drive 7200 RPM 256MB Cache CMR 340 / 20 TB, 17 a TB but 20TB drive.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z6og5b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669615063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "newegg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.newegg.com/seagate-ironwolf-pro-st20000ne000-20tb/p/N82E16822185007?Item=N82E16822185007&amp;ignorebbr=1&amp;cm_mmc=EMC-Automation112722-_-EMC-112722-Index-_-Desktop%20Internal%20Hard%20Drives-_-N82E16822185007&amp;ignorebbr=1&amp;cvtc=10647527", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z6og5b", "is_robot_indexable": true, "report_reasons": null, "author": "nando1969", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/z6og5b/seagate_ironwolf_pro_20tb_nas_hard_drive_7200_rpm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.newegg.com/seagate-ironwolf-pro-st20000ne000-20tb/p/N82E16822185007?Item=N82E16822185007&amp;ignorebbr=1&amp;cm_mmc=EMC-Automation112722-_-EMC-112722-Index-_-Desktop%20Internal%20Hard%20Drives-_-N82E16822185007&amp;ignorebbr=1&amp;cvtc=10647527", "subreddit_subscribers": 656537, "created_utc": 1669615063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, due to the massive rocket fire from the russian federation and the lack of light for almost half a day, I am trying to find an additional opportunity to have a backup copy and use it\n One of the options is a smartphone, but it does not support ext4/btrfs, only fat32.\n Is there any way to solve this problem?", "author_fullname": "t2_lo8e4f55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am trying to find an additional option to have a backup and use it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z6obui", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669614665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, due to the massive rocket fire from the russian federation and the lack of light for almost half a day, I am trying to find an additional opportunity to have a backup copy and use it\n One of the options is a smartphone, but it does not support ext4/btrfs, only fat32.\n Is there any way to solve this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "russian military ship, go to hell", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6obui", "is_robot_indexable": true, "report_reasons": null, "author": "kovach_ua", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/z6obui/i_am_trying_to_find_an_additional_option_to_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6obui/i_am_trying_to_find_an_additional_option_to_have/", "subreddit_subscribers": 656537, "created_utc": 1669614665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am using Syncovery and it has an option to compress each file it uploads. I am debating pros cons.\n\nMy initial (first time) upload will be 1.5 TB and about 160k files. I was thinking to do ultra compression since it is one time. That way, when I have to download/restore, it is less to download. But the initial backup will take 2-3 times longer with compression than if I do no compression.\n\nI'm hoping for some good insights from the community.\n\n[View Poll](https://www.reddit.com/poll/z6mw4w)", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Poll: Do folks compress their file level backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6mw4w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669610277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using Syncovery and it has an option to compress each file it uploads. I am debating pros cons.&lt;/p&gt;\n\n&lt;p&gt;My initial (first time) upload will be 1.5 TB and about 160k files. I was thinking to do ultra compression since it is one time. That way, when I have to download/restore, it is less to download. But the initial backup will take 2-3 times longer with compression than if I do no compression.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping for some good insights from the community.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/z6mw4w\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6mw4w", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1669869477674, "options": [{"text": "Yes, I compress", "id": "20063642"}, {"text": "No, I do not compress", "id": "20063643"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 46, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6mw4w/poll_do_folks_compress_their_file_level_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/DataHoarder/comments/z6mw4w/poll_do_folks_compress_their_file_level_backups/", "subreddit_subscribers": 656537, "created_utc": 1669610277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2000+ .fbx mo-cap animation library for free.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6kppk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2b9r7ngd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free Data", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "gamedev", "selftext": "**TLDR**: Over 2,000 free 3d humanoid character animations that can be used commercially. The only thing you can't do with them, is sell them, although you can redistribute them if they're free. **Download link is below the discalimer**, which you should at least read the top part of if you plan to use these.\n\n[Sample](https://reddit.com/link/z6djuc/video/34um1xs99k2a1/player)\n\n# Disclaimer and boring stuff:\n\n**I did not create the animations/assets used in this**. The data used in this project was obtained from [mocap.cs.cmu.edu](https://mocap.cs.cmu.edu).  The database was created with funding from NSF EIA-0196217. I converted it to .fbx \\*~~and .glTF~~ from .bvh files I got from [cgspeed.com](https://cgspeed.com) with the use of Blender. I also re-targeted it to an example CC0 model with the use of a Blender add-on, [Auto-Rig Pro](https://blendermarket.com/products/auto-rig-pro)(unfortunetly not free, but you don't need it to use these). The model was made by [Quaternius](https://quaternius.itch.io/). The animations are free to use/modify/redistribute, so long as you don't just sell them as animations.\n\n**I have no affiliation with any of these mentioned parties and  just because I'm allowed to use these assets and distribute them,  doesn't mean any of them necessarily endorse this use. Having read the  terms of use though, I feel like this is something they were intended for.** \n\nThis library has been converted several times, by several people. You might have seen it around. If you wanted to, you could convert it and distribute a \"competing\" version(so long as you don't charge anything). I've downloaded both Unreal and Unity versions, but neither of which were able to be opened in Blender(.uasset files and the Unity .fbx files weren't compatible with Blender), which is a problem because they're not quite game ready as is, and editing animations in either engine is not ideal. I've found a bunch of dead links to other versions, like a different one that was supposed to be .fbx, but since it was a dead link, it wasn't very helpful. I actually started converting these with Godot in mind because it's still newer and there aren't all the assets available like there are for Unreal/Unity. I also initially tried to convert to both .fbx and .glTF because .glTF is a little better for Godot. The .glTF file was somehow including small pieces of data left over from previous conversions no matter how much I tried cleaning up Blender between them. Basically, each conversion would be slightly larger than the previous. It was pretty small, but that does add up when you're iterating over 2,000 files. I improved the conversion script a bunch over the process of converting the library, so if for some reason people needed .glTF versions, I can actually efficiently convert to it now. All 3 of those engines take .fbx and even if you're using other 3D software than Blender, .fbx originates from AutoDesk, so it's perfectly compatible with Maya/3DMax(Or should be, those programs are too rich for my blood so I didn't test it).\n\n# Link:\n\n[https://rancidmilk.itch.io/free-character-animations](https://rancidmilk.itch.io/free-character-animations)\n\nI wasn't sure of the best way to distribute these. I chose [itch.io](https://itch.io) because it's intended for games/game assets and let's you upload a gb before you have to start bugging them for more space. I completely turned off any payment methods. If you wanted to thank me in any way, you could help me improve the animations for everyone to use. It would be nice to cobble together a game ready pack for people to use that's just plug and play and free.\n\n# More info:\n\nThere's a lot more info on the itch page. If you have questions, I'm happy to answer them, please look there before asking though.\n\n# Bonus Content:\n\nI've included my conversion script and added a control rig(which I double checked I'm also allowed to distribute) for easy animation editing. \n\n# Summary:\n\nSo, while I have a lot of effort/time into converting this library, I literally only made the included Blender script and assembled everything.", "author_fullname": "t2_rylxysdt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I converted a massive library of mo-cap animations to .fbx which you can use freely with ALMOST no restrictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/gamedev", "hidden": false, "pwls": 6, "link_flair_css_class": "assets cat-event", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"34um1xs99k2a1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/z6djuc/asset/34um1xs99k2a1/DASHPlaylist.mpd?a=1672209948%2CYjkzYjJlOGUxOTFjYzNhZDRiNGNjNDA4Y2NhNTIwMzZkY2NjZWNjNzhkNTA1YWVjODRkMzNiNjg1YmNiZWZlOA%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 720, "hlsUrl": "https://v.redd.it/link/z6djuc/asset/34um1xs99k2a1/HLSPlaylist.m3u8?a=1672209948%2CMjJkZTMzNTNmYTkyYjBhNDA0OTIxMGI3ZmU4M2RiYjg4Y2VlYWY4NjcxZTk0YjcwZDZhNDNkZGVmZWVlY2NlZQ%3D%3D&amp;v=1&amp;f=sd", "id": "34um1xs99k2a1", "isGif": false}}, "name": "t3_z6djuc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 643, "total_awards_received": 3, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Assets", "can_mod_post": false, "score": 643, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669585404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.gamedev", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: Over 2,000 free 3d humanoid character animations that can be used commercially. The only thing you can&amp;#39;t do with them, is sell them, although you can redistribute them if they&amp;#39;re free. &lt;strong&gt;Download link is below the discalimer&lt;/strong&gt;, which you should at least read the top part of if you plan to use these.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/z6djuc/video/34um1xs99k2a1/player\"&gt;Sample&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Disclaimer and boring stuff:&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;I did not create the animations/assets used in this&lt;/strong&gt;. The data used in this project was obtained from &lt;a href=\"https://mocap.cs.cmu.edu\"&gt;mocap.cs.cmu.edu&lt;/a&gt;.  The database was created with funding from NSF EIA-0196217. I converted it to .fbx *&lt;del&gt;and .glTF&lt;/del&gt; from .bvh files I got from &lt;a href=\"https://cgspeed.com\"&gt;cgspeed.com&lt;/a&gt; with the use of Blender. I also re-targeted it to an example CC0 model with the use of a Blender add-on, &lt;a href=\"https://blendermarket.com/products/auto-rig-pro\"&gt;Auto-Rig Pro&lt;/a&gt;(unfortunetly not free, but you don&amp;#39;t need it to use these). The model was made by &lt;a href=\"https://quaternius.itch.io/\"&gt;Quaternius&lt;/a&gt;. The animations are free to use/modify/redistribute, so long as you don&amp;#39;t just sell them as animations.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I have no affiliation with any of these mentioned parties and  just because I&amp;#39;m allowed to use these assets and distribute them,  doesn&amp;#39;t mean any of them necessarily endorse this use. Having read the  terms of use though, I feel like this is something they were intended for.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;This library has been converted several times, by several people. You might have seen it around. If you wanted to, you could convert it and distribute a &amp;quot;competing&amp;quot; version(so long as you don&amp;#39;t charge anything). I&amp;#39;ve downloaded both Unreal and Unity versions, but neither of which were able to be opened in Blender(.uasset files and the Unity .fbx files weren&amp;#39;t compatible with Blender), which is a problem because they&amp;#39;re not quite game ready as is, and editing animations in either engine is not ideal. I&amp;#39;ve found a bunch of dead links to other versions, like a different one that was supposed to be .fbx, but since it was a dead link, it wasn&amp;#39;t very helpful. I actually started converting these with Godot in mind because it&amp;#39;s still newer and there aren&amp;#39;t all the assets available like there are for Unreal/Unity. I also initially tried to convert to both .fbx and .glTF because .glTF is a little better for Godot. The .glTF file was somehow including small pieces of data left over from previous conversions no matter how much I tried cleaning up Blender between them. Basically, each conversion would be slightly larger than the previous. It was pretty small, but that does add up when you&amp;#39;re iterating over 2,000 files. I improved the conversion script a bunch over the process of converting the library, so if for some reason people needed .glTF versions, I can actually efficiently convert to it now. All 3 of those engines take .fbx and even if you&amp;#39;re using other 3D software than Blender, .fbx originates from AutoDesk, so it&amp;#39;s perfectly compatible with Maya/3DMax(Or should be, those programs are too rich for my blood so I didn&amp;#39;t test it).&lt;/p&gt;\n\n&lt;h1&gt;Link:&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://rancidmilk.itch.io/free-character-animations\"&gt;https://rancidmilk.itch.io/free-character-animations&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t sure of the best way to distribute these. I chose &lt;a href=\"https://itch.io\"&gt;itch.io&lt;/a&gt; because it&amp;#39;s intended for games/game assets and let&amp;#39;s you upload a gb before you have to start bugging them for more space. I completely turned off any payment methods. If you wanted to thank me in any way, you could help me improve the animations for everyone to use. It would be nice to cobble together a game ready pack for people to use that&amp;#39;s just plug and play and free.&lt;/p&gt;\n\n&lt;h1&gt;More info:&lt;/h1&gt;\n\n&lt;p&gt;There&amp;#39;s a lot more info on the itch page. If you have questions, I&amp;#39;m happy to answer them, please look there before asking though.&lt;/p&gt;\n\n&lt;h1&gt;Bonus Content:&lt;/h1&gt;\n\n&lt;p&gt;I&amp;#39;ve included my conversion script and added a control rig(which I double checked I&amp;#39;m also allowed to distribute) for easy animation editing. &lt;/p&gt;\n\n&lt;h1&gt;Summary:&lt;/h1&gt;\n\n&lt;p&gt;So, while I have a lot of effort/time into converting this library, I literally only made the included Blender script and assembled everything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 2, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "7272f776-ba6a-11e5-a76d-0eb130e0b479", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qi0a", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z6djuc", "is_robot_indexable": true, "report_reasons": null, "author": "RancidMilkGames", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/gamedev/comments/z6djuc/i_converted_a_massive_library_of_mocap_animations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/gamedev/comments/z6djuc/i_converted_a_massive_library_of_mocap_animations/", "subreddit_subscribers": 926901, "created_utc": 1669585404.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1669603832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.gamedev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/gamedev/comments/z6djuc/i_converted_a_massive_library_of_mocap_animations/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "z6kppk", "is_robot_indexable": true, "report_reasons": null, "author": "RustedBlade7", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_z6djuc", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6kppk/2000_fbx_mocap_animation_library_for_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/gamedev/comments/z6djuc/i_converted_a_massive_library_of_mocap_animations/", "subreddit_subscribers": 656537, "created_utc": 1669603832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have no idea if this is the right place to ask, but I\u2019m absolutely lost and I figured y\u2019all might be able help. I\u2019ve been working on a project that involves some image files from around 1997. The only issue is that (almost) all of the files I was given seem to be corrupted and unusable. They don\u2019t have any file extensions, and adding extensions doesn\u2019t work either. The most important images still seem to take up a decent bit of space, so is there any chance something like this could be salvaged? Figured I might as well shoot out this last cry for help, if you think you can help I\u2019d be glad to send over some of the problem files to look at. Thanks!", "author_fullname": "t2_8rjlxo5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Corrupted image files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6kfc5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669602979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have no idea if this is the right place to ask, but I\u2019m absolutely lost and I figured y\u2019all might be able help. I\u2019ve been working on a project that involves some image files from around 1997. The only issue is that (almost) all of the files I was given seem to be corrupted and unusable. They don\u2019t have any file extensions, and adding extensions doesn\u2019t work either. The most important images still seem to take up a decent bit of space, so is there any chance something like this could be salvaged? Figured I might as well shoot out this last cry for help, if you think you can help I\u2019d be glad to send over some of the problem files to look at. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6kfc5", "is_robot_indexable": true, "report_reasons": null, "author": "Pokeballersprime2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6kfc5/corrupted_image_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6kfc5/corrupted_image_files/", "subreddit_subscribers": 656537, "created_utc": 1669602979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have years and years of photos, videos, and work  spread across a few external HD\u2019s (1tb, 1tb, 5tb, 8tb)\nI have google photos and iCloud backup of the past two years of photos but looking to get a NAS setup to have the past decade all in one place and accessible from my phone \n\nI am using a Mac and looking into a synology NAS 4 bay and to load it up with 4 16tb \n\nEssentially I want to be able to access the photos to begin the sorting of them by month and year and eliminate duplicates. \n\nIs it a fairly simple process of just buying the equipment needed and installing the synology software and then dragging and dropping the files?", "author_fullname": "t2_4zhkc16p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not sure where to begin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z6k51u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669602145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have years and years of photos, videos, and work  spread across a few external HD\u2019s (1tb, 1tb, 5tb, 8tb)\nI have google photos and iCloud backup of the past two years of photos but looking to get a NAS setup to have the past decade all in one place and accessible from my phone &lt;/p&gt;\n\n&lt;p&gt;I am using a Mac and looking into a synology NAS 4 bay and to load it up with 4 16tb &lt;/p&gt;\n\n&lt;p&gt;Essentially I want to be able to access the photos to begin the sorting of them by month and year and eliminate duplicates. &lt;/p&gt;\n\n&lt;p&gt;Is it a fairly simple process of just buying the equipment needed and installing the synology software and then dragging and dropping the files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z6k51u", "is_robot_indexable": true, "report_reasons": null, "author": "hypnotizedent", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z6k51u/not_sure_where_to_begin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z6k51u/not_sure_where_to_begin/", "subreddit_subscribers": 656537, "created_utc": 1669602145.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}