{"kind": "Listing", "data": {"after": "t3_yjgbh2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have created a workspace for my data science projects and NGS pipelines. Contains RStudio, Jupyter Notebook, VSCode, and a file manager. It can use docker in docker and singularity and connect to the Tailscale network to bypass firewalls, thus allowing it to work from anywhere. I feel happy to share it if someone wants to use it - [https://github.com/kstawiski/seq-pipeline](https://github.com/kstawiski/seq-pipeline)\n\nhttps://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;format=png&amp;auto=webp&amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990", "author_fullname": "t2_ynu23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science workspace I have always dreamed about...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sj0t8r97wcx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 106, "x": 108, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8bb30e0f055501ce417a4f78341353cca5db8a2"}, {"y": 212, "x": 216, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=85ec5a74c9a9e642cbf2510be6e7bac8698e02ee"}, {"y": 315, "x": 320, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=11950b5e9eb528fa88ff4275ee230470a9bdf34e"}, {"y": 630, "x": 640, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c3de75d09b0334c15a5468f87facb1564a93b3cd"}, {"y": 945, "x": 960, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=797e10acdbd8bd82919c7db609201f832c5c9eb9"}], "s": {"y": 1024, "x": 1040, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;format=png&amp;auto=webp&amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990"}, "id": "sj0t8r97wcx91"}}, "name": "t3_yjb9ab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Y4uMld_b__F66QX0q4vXziOlb3BobsUKy3FhthWle2c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667315681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have created a workspace for my data science projects and NGS pipelines. Contains RStudio, Jupyter Notebook, VSCode, and a file manager. It can use docker in docker and singularity and connect to the Tailscale network to bypass firewalls, thus allowing it to work from anywhere. I feel happy to share it if someone wants to use it - &lt;a href=\"https://github.com/kstawiski/seq-pipeline\"&gt;https://github.com/kstawiski/seq-pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990\"&gt;https://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjb9ab", "is_robot_indexable": true, "report_reasons": null, "author": "kondi69", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjb9ab/data_science_workspace_i_have_always_dreamed_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjb9ab/data_science_workspace_i_have_always_dreamed_about/", "subreddit_subscribers": 816680, "created_utc": 1667315681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nI am working on an algorithm to predict cross sell opportunities. To do so I am evaluating the three models in the title. To do so I plan to do cross fold validation to pick the best model. My question is if during each fold do I need to hyper parameter tune the model? Or do I do that after I pick the best one?", "author_fullname": "t2_zivdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logistic Regression v Random Forest v XGBoost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj9u1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667312124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I am working on an algorithm to predict cross sell opportunities. To do so I am evaluating the three models in the title. To do so I plan to do cross fold validation to pick the best model. My question is if during each fold do I need to hyper parameter tune the model? Or do I do that after I pick the best one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj9u1l", "is_robot_indexable": true, "report_reasons": null, "author": "Meclimax", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj9u1l/logistic_regression_v_random_forest_v_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj9u1l/logistic_regression_v_random_forest_v_xgboost/", "subreddit_subscribers": 816680, "created_utc": 1667312124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\"Just sent your payment. Congrats on being the highest paid employee in the company\".\n\nSeems like a tactic to put pressure on me to do even more work or make me feel uncomfortable for getting paid. \n\nShould I just not reply? I am thinking just to ignore the comment and continue, and not to send him any reply, no comebacks. I don't want to be snarky. When there is a problem, I take full responsibility on it even if it's not my own problem, and am always the nicest person. \n\nI am the first employee in the startup, and who brings in the most amount of work, consistently, day and night (yes, sometimes working into the night to make deadlines happen when he lets us know the day or two before for work to be done for a big company we're working with). \n\nI started with a very low pay for months (barely enough to pay the bills) and just now was promoted, after my insistence, since I had to work in childcare to pay the bills. He is till underpaying, and paying only 70% of what a business data analyst gets.", "author_fullname": "t2_8zbxfqav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Boss Just Told Me...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjlzp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667338234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Just sent your payment. Congrats on being the highest paid employee in the company&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Seems like a tactic to put pressure on me to do even more work or make me feel uncomfortable for getting paid. &lt;/p&gt;\n\n&lt;p&gt;Should I just not reply? I am thinking just to ignore the comment and continue, and not to send him any reply, no comebacks. I don&amp;#39;t want to be snarky. When there is a problem, I take full responsibility on it even if it&amp;#39;s not my own problem, and am always the nicest person. &lt;/p&gt;\n\n&lt;p&gt;I am the first employee in the startup, and who brings in the most amount of work, consistently, day and night (yes, sometimes working into the night to make deadlines happen when he lets us know the day or two before for work to be done for a big company we&amp;#39;re working with). &lt;/p&gt;\n\n&lt;p&gt;I started with a very low pay for months (barely enough to pay the bills) and just now was promoted, after my insistence, since I had to work in childcare to pay the bills. He is till underpaying, and paying only 70% of what a business data analyst gets.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjlzp1", "is_robot_indexable": true, "report_reasons": null, "author": "sapiogirl", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjlzp1/my_boss_just_told_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjlzp1/my_boss_just_told_me/", "subreddit_subscribers": 816680, "created_utc": 1667338234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4ol32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview with a senior ML engineer working on detecting illegal logging using SAR satellites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yj96op", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/x3PIhdHyjqkG9A1xX6pQ-1W7xB1TjPa8j8_NTN2pQKQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667310518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mlpioneers.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.mlpioneers.com/tapio-iceye/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?auto=webp&amp;s=47be098c258f9ccc9d95d226678519862ebe1468", "width": 1601, "height": 1601}, "resolutions": [{"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f60d9858d3ccfb828ecebe816305842a088aff88", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55d2554e6a518e16336fd0ac796f868656477dde", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd2caf50a4d38c2d8cf34825f254287136205a24", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b80cc77cad3658fef99dc8fc1fed76ce189f697", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=221fe16b98422e24d5138cd921f4fddb2dea7a0a", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=95794f85000cb6323b7b4cb4c3f66642e242defd", "width": 1080, "height": 1080}], "variants": {}, "id": "v19rD2kKRf6MviDFMprdo9wKLVGZHeoj5aTI0q8_p5w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj96op", "is_robot_indexable": true, "report_reasons": null, "author": "shyssee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj96op/interview_with_a_senior_ml_engineer_working_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mlpioneers.com/tapio-iceye/", "subreddit_subscribers": 816680, "created_utc": 1667310518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you have favorite news sources which are very business-data science focused?  Do you attend conferences? Discord Channels? Is there some arxiv-esque site where the papers are focused on real world use cases?\n\n&amp;#x200B;\n\nTo provide context for this post  My past job was geared towards different fields, so I got very good at getting a high level view of a specific industry/use cases.  However, after changing to a more specialized field, I found it much more difficult to break past that initial layer.", "author_fullname": "t2_5puimv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you learn and keep up with use cases for data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj1wn4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667287395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have favorite news sources which are very business-data science focused?  Do you attend conferences? Discord Channels? Is there some arxiv-esque site where the papers are focused on real world use cases?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To provide context for this post  My past job was geared towards different fields, so I got very good at getting a high level view of a specific industry/use cases.  However, after changing to a more specialized field, I found it much more difficult to break past that initial layer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj1wn4", "is_robot_indexable": true, "report_reasons": null, "author": "shaner92", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj1wn4/how_do_you_learn_and_keep_up_with_use_cases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj1wn4/how_do_you_learn_and_keep_up_with_use_cases_for/", "subreddit_subscribers": 816680, "created_utc": 1667287395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Folks,\n\nFor any tensorflow developers out there or if you are generally interested in helping I need some help:\n\nI took the Tensorflow developer specialization on Coursera. I recently completed their 3rd course. I was quite overwhelmed frankly as I had never worked with NLP.  I really wanted to stop for a while and develop something of my own as a project to test my knowledge. I stumbled upon this idea of building a disease prediction model last week and I really wanted to get some ideas on my model. I scraped diseases, and their symptoms from internet. Symptoms being separated by commas with no sequential meaning.\n\n1. Some of my symptoms and disease names are multi word, is there any work around for that?\n\n2. I guess using LSTM is quite useless as symptoms are randomly separated by commas so no sequential meaning. Comments?\n\n3. I multiplied my dataset by using symptoms in various combinations for every disease. Is this fine?\n\n4. My approach so far has been to tokenize each symptom. I did not tokenize labels and rather created a dictionary with indexes. This is because some diseases \\*labels\\* were multi word so I cannot pass a token array as label.\n\n5. Should I go for one hot encoding rather?\n\nI pass the input through an embedding layer \\*\\*64 dimension\\*\\*, Global avg pooling 1D, Dense layer 100 relu activations, and 261 outputs softmax activation.\n\nI got 90% train and val accuracy. Is this approach right?\n\nAnother thing I wanted to do was to be able to predict symptoms from utterances, any suggestions?\n\nIf anyone is interested, feel free to join in the project", "author_fullname": "t2_rzwdmc0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions on an NLP project that I built", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjj8ps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667332273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,&lt;/p&gt;\n\n&lt;p&gt;For any tensorflow developers out there or if you are generally interested in helping I need some help:&lt;/p&gt;\n\n&lt;p&gt;I took the Tensorflow developer specialization on Coursera. I recently completed their 3rd course. I was quite overwhelmed frankly as I had never worked with NLP.  I really wanted to stop for a while and develop something of my own as a project to test my knowledge. I stumbled upon this idea of building a disease prediction model last week and I really wanted to get some ideas on my model. I scraped diseases, and their symptoms from internet. Symptoms being separated by commas with no sequential meaning.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Some of my symptoms and disease names are multi word, is there any work around for that?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I guess using LSTM is quite useless as symptoms are randomly separated by commas so no sequential meaning. Comments?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I multiplied my dataset by using symptoms in various combinations for every disease. Is this fine?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;My approach so far has been to tokenize each symptom. I did not tokenize labels and rather created a dictionary with indexes. This is because some diseases *labels* were multi word so I cannot pass a token array as label.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should I go for one hot encoding rather?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I pass the input through an embedding layer **64 dimension**, Global avg pooling 1D, Dense layer 100 relu activations, and 261 outputs softmax activation.&lt;/p&gt;\n\n&lt;p&gt;I got 90% train and val accuracy. Is this approach right?&lt;/p&gt;\n\n&lt;p&gt;Another thing I wanted to do was to be able to predict symptoms from utterances, any suggestions?&lt;/p&gt;\n\n&lt;p&gt;If anyone is interested, feel free to join in the project&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjj8ps", "is_robot_indexable": true, "report_reasons": null, "author": "Kind-Thing-7202", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjj8ps/need_suggestions_on_an_nlp_project_that_i_built/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjj8ps/need_suggestions_on_an_nlp_project_that_i_built/", "subreddit_subscribers": 816680, "created_utc": 1667332273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "During your data science internship, did you have an opportunity to finish a ML model from start to finish (by which I mean from project conception to model deployment), or did you find yourself assigned to a ML project which was already in a later stage (i.e Data Cleaning).\n\nI am asking because I want to compare my Data Science Internship experience. I had the opportunity to work on a lot of cool projects, but in the ML project, I only worked on the Data Collection, EDA, and Data Cleaning phase. I feel like I am at a disadvantage for entry level data scientist positions because I haven't actually produced a model in the professional environment.", "author_fullname": "t2_tlsfzwe0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Those with Data Science Internship experience - How much Machine Learning did you actually do during your internship?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj2gyr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667289525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;During your data science internship, did you have an opportunity to finish a ML model from start to finish (by which I mean from project conception to model deployment), or did you find yourself assigned to a ML project which was already in a later stage (i.e Data Cleaning).&lt;/p&gt;\n\n&lt;p&gt;I am asking because I want to compare my Data Science Internship experience. I had the opportunity to work on a lot of cool projects, but in the ML project, I only worked on the Data Collection, EDA, and Data Cleaning phase. I feel like I am at a disadvantage for entry level data scientist positions because I haven&amp;#39;t actually produced a model in the professional environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj2gyr", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Lynx-4094", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj2gyr/those_with_data_science_internship_experience_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj2gyr/those_with_data_science_internship_experience_how/", "subreddit_subscribers": 816680, "created_utc": 1667289525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I\u2019ve been going to university for computational physics (physics and computer science degree in one) and I\u2019ve been looking into data science. At my current job I was working part-time in order to focus on school. They\u2019ve recently gotten rid of the part-time position and now I have to work full-time. The problem is it\u2019s a 10 hour night shift position with an hour of commute to and from home. I\u2019m away from home for at least 12 hours of the day and have time to really only tackle one or two classes. \n\nI was hoping I could pick up a part-time position in the analytical world so I could finish school quicker while also gaining experience in a field I\u2019m interested in. What kind of part time jobs are the in the analytic world for someone like me to get my foot in the door?", "author_fullname": "t2_p8i5qcr2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any advice for a student trying to make it in the analytical world?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjr4bv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667351064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve been going to university for computational physics (physics and computer science degree in one) and I\u2019ve been looking into data science. At my current job I was working part-time in order to focus on school. They\u2019ve recently gotten rid of the part-time position and now I have to work full-time. The problem is it\u2019s a 10 hour night shift position with an hour of commute to and from home. I\u2019m away from home for at least 12 hours of the day and have time to really only tackle one or two classes. &lt;/p&gt;\n\n&lt;p&gt;I was hoping I could pick up a part-time position in the analytical world so I could finish school quicker while also gaining experience in a field I\u2019m interested in. What kind of part time jobs are the in the analytic world for someone like me to get my foot in the door?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yjr4bv", "is_robot_indexable": true, "report_reasons": null, "author": "__6EQUJ5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjr4bv/any_advice_for_a_student_trying_to_make_it_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjr4bv/any_advice_for_a_student_trying_to_make_it_in_the/", "subreddit_subscribers": 816680, "created_utc": 1667351064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a senior currently on the job hunt and I've seen a few of these \"Professional Development Programs\" where you basically rotate through different sectors of the company and learn how data science is applied at each one. What is the general consensus on programs like these? Also, does anyone have any idea how much they generally pay? What would your job title even be? Would they be more of a help or a hinder when seeking future employment afterward?", "author_fullname": "t2_4g45t9kc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional Development Programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiy98z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667275466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a senior currently on the job hunt and I&amp;#39;ve seen a few of these &amp;quot;Professional Development Programs&amp;quot; where you basically rotate through different sectors of the company and learn how data science is applied at each one. What is the general consensus on programs like these? Also, does anyone have any idea how much they generally pay? What would your job title even be? Would they be more of a help or a hinder when seeking future employment afterward?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yiy98z", "is_robot_indexable": true, "report_reasons": null, "author": "goBlue102_2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yiy98z/professional_development_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yiy98z/professional_development_programs/", "subreddit_subscribers": 816680, "created_utc": 1667275466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking to forecast demand for products and understand where my firm is doing well or poorly based on tracking various KPIs, complaints etc. \n\nHow do I approach this exercise? I have about 4 years of data to work with. E.g. Demand volumes, complaints, processing times, customer reviews etc.", "author_fullname": "t2_2ygw7tnt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjqaqg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667348857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to forecast demand for products and understand where my firm is doing well or poorly based on tracking various KPIs, complaints etc. &lt;/p&gt;\n\n&lt;p&gt;How do I approach this exercise? I have about 4 years of data to work with. E.g. Demand volumes, complaints, processing times, customer reviews etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjqaqg", "is_robot_indexable": true, "report_reasons": null, "author": "IStealCheesecake", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjqaqg/new_to_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjqaqg/new_to_forecasting/", "subreddit_subscribers": 816680, "created_utc": 1667348857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just popped into my head as I reflect on our marketing team trying to pay a vendor a godawful amount of money for what the vendor literally labels, \u201coff the shelf machine learning models.\u201d The deal, we open the gates to let them exfiltrate data, they use it to train models, they then sell those modes back to us and our competition\u2026\n\nWhat I\u2019m realizing now is that there is absolutely no reasonable way they can uphold a delete request from our customers because it would require they retire the old modes, retrain in fresh data, and redeploy to all their other clients. \n\nSimilarly if there is a request for transparency about what data we have access to and what it\u2019s being used for, if our competition is using models trained on our customers data from our data stores, then who knows how the hell they might be using that\u2026\n\nAnd for those curious, they are willing to give away our data assets because they don\u2019t want to wait for our internal teams to make them dashboards using our internal warehousing and data stores. That\u2019s literally it.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CCPA, GDPR and vendor supplied models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yji271", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667329872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just popped into my head as I reflect on our marketing team trying to pay a vendor a godawful amount of money for what the vendor literally labels, \u201coff the shelf machine learning models.\u201d The deal, we open the gates to let them exfiltrate data, they use it to train models, they then sell those modes back to us and our competition\u2026&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m realizing now is that there is absolutely no reasonable way they can uphold a delete request from our customers because it would require they retire the old modes, retrain in fresh data, and redeploy to all their other clients. &lt;/p&gt;\n\n&lt;p&gt;Similarly if there is a request for transparency about what data we have access to and what it\u2019s being used for, if our competition is using models trained on our customers data from our data stores, then who knows how the hell they might be using that\u2026&lt;/p&gt;\n\n&lt;p&gt;And for those curious, they are willing to give away our data assets because they don\u2019t want to wait for our internal teams to make them dashboards using our internal warehousing and data stores. That\u2019s literally it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yji271", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yji271/ccpa_gdpr_and_vendor_supplied_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yji271/ccpa_gdpr_and_vendor_supplied_models/", "subreddit_subscribers": 816680, "created_utc": 1667329872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to do clustering and then use that as a feature to improve the accuracy of my Multi class classifier. The dataset I am dealing with is Numerical and everything is encoded but my accuracy is not improving much after feature engineering and hyperparameter tuning. I am using XGboost classifier for my model. \nIf anyone can guide me on how I can use clustering as a feature for my classification model , I would be extremely grateful, thanks!", "author_fullname": "t2_ovzrn1bd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustering as a feature for Multi class classifier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjs5kj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667353857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to do clustering and then use that as a feature to improve the accuracy of my Multi class classifier. The dataset I am dealing with is Numerical and everything is encoded but my accuracy is not improving much after feature engineering and hyperparameter tuning. I am using XGboost classifier for my model. \nIf anyone can guide me on how I can use clustering as a feature for my classification model , I would be extremely grateful, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjs5kj", "is_robot_indexable": true, "report_reasons": null, "author": "napqueen-9175", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjs5kj/clustering_as_a_feature_for_multi_class_classifier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjs5kj/clustering_as_a_feature_for_multi_class_classifier/", "subreddit_subscribers": 816680, "created_utc": 1667353857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Spotify](https://open.spotify.com/playlist/6BoTD9WeyBN5rD5uyhbROO) | [Apple](https://music.apple.com/playlist/synthwave-focus-i/pl.u-b3b8Nm9C5MmMyM) | [Youtube](https://youtube.com/playlist?list=PLwO9YUACGAzS_XaTchS3qLgK5EGsb3qwa)", "author_fullname": "t2_oh0xutyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Here\u2019s a playlist of 7 hours of music with NO VOCALS I use to focus when I\u2019m coding/developing. Post yours as well if you also have one!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjrza6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667353368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://open.spotify.com/playlist/6BoTD9WeyBN5rD5uyhbROO\"&gt;Spotify&lt;/a&gt; | &lt;a href=\"https://music.apple.com/playlist/synthwave-focus-i/pl.u-b3b8Nm9C5MmMyM\"&gt;Apple&lt;/a&gt; | &lt;a href=\"https://youtube.com/playlist?list=PLwO9YUACGAzS_XaTchS3qLgK5EGsb3qwa\"&gt;Youtube&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-C-Ue-Llmn1VAvVNDfj7n_GMZUAnmZoKd5PO0yKj4rY.jpg?auto=webp&amp;s=abbdaf3e511f6217f7a88208768c30de720e33c9", "width": 640, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/-C-Ue-Llmn1VAvVNDfj7n_GMZUAnmZoKd5PO0yKj4rY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dd334cdf898f0efc2ac12e0a06796d96ccfbd050", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-C-Ue-Llmn1VAvVNDfj7n_GMZUAnmZoKd5PO0yKj4rY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=99ce9641044ba36f156df12bbb8778c3d01422f5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-C-Ue-Llmn1VAvVNDfj7n_GMZUAnmZoKd5PO0yKj4rY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=335cd80c321668aa1756c144ebbb8109b06de5e6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/-C-Ue-Llmn1VAvVNDfj7n_GMZUAnmZoKd5PO0yKj4rY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b7d609578510c6f2ced270d50bd60aabfc040a4", "width": 640, "height": 640}], "variants": {}, "id": "DwjNWp3GtO3fHai6T-YST8iwHBTAFqiWJSj0I2_23Yw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjrza6", "is_robot_indexable": true, "report_reasons": null, "author": "soundtrackrr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjrza6/heres_a_playlist_of_7_hours_of_music_with_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjrza6/heres_a_playlist_of_7_hours_of_music_with_no/", "subreddit_subscribers": 816680, "created_utc": 1667353368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My plan is to become a data scientist. So what I do first is to apply as a data analyst in companies. But one company called me and offered me a data governance position. Since I am a fresh graduate and it seems no one is currently accepting me as a data analyst, is it better to take this offer? If I do, how could I job hop or career shift in a data analyst role? Because based on what I've searched, the data governance role are more talking to people and securing/controlling the distribution of data and more of using flowcharts. I just hope I can also apply statistical test or dashboards for data visualization.", "author_fullname": "t2_t7fc22np", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science vs Data Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjrra2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667352755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My plan is to become a data scientist. So what I do first is to apply as a data analyst in companies. But one company called me and offered me a data governance position. Since I am a fresh graduate and it seems no one is currently accepting me as a data analyst, is it better to take this offer? If I do, how could I job hop or career shift in a data analyst role? Because based on what I&amp;#39;ve searched, the data governance role are more talking to people and securing/controlling the distribution of data and more of using flowcharts. I just hope I can also apply statistical test or dashboards for data visualization.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjrra2", "is_robot_indexable": true, "report_reasons": null, "author": "macsoup_33", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjrra2/data_science_vs_data_governance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjrra2/data_science_vs_data_governance/", "subreddit_subscribers": 816680, "created_utc": 1667352755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellow scientists. Im looking for the best methods of clustering. Whats the state of the art on this subject? Currently my goal is to do a profilling.\n\nIm not experienced on this field so any tip or info will be appreciated.", "author_fullname": "t2_zj7gj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best methods / state of the art for clustering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjp0ld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667345541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow scientists. Im looking for the best methods of clustering. Whats the state of the art on this subject? Currently my goal is to do a profilling.&lt;/p&gt;\n\n&lt;p&gt;Im not experienced on this field so any tip or info will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjp0ld", "is_robot_indexable": true, "report_reasons": null, "author": "2soonexecutus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjp0ld/best_methods_state_of_the_art_for_clustering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjp0ld/best_methods_state_of_the_art_for_clustering/", "subreddit_subscribers": 816680, "created_utc": 1667345541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_35unu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scala 3.1: Strict Exceptions And Faster Match", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_yjn3q5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Y9pHVX9lw3ST2FDZ8_4PiszNnqd5syZ-C6EuNqQZWrE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667340897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/i4k79srcBub", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?auto=webp&amp;s=da556830c45f1d07ef0bc5c816402ef713a2588e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4538ab1015641121ae49ed57d351e691a0f8e47f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=438e6d66ebded7f7c2afc1b3a8da4ab7c497ff50", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab2e10e2f84a6257039d5f368459a84565d85188", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7354fb86cf8fd4cdf462ef5f9c93a2678d7cee00", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc3e2abc57f8d5790b6fc5d4746f154617ff8474", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/CVt9v1oPpVQHbwadZxygOe7w5PPnOao_ok1jbVQ6-zQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4bb3515ce1ef446c7e849390c9c3d30ba34d00c1", "width": 1080, "height": 540}], "variants": {}, "id": "AgzNQB6LhvtgTV-fK5vT-rLcW2Xmb7o7mUwpF2hWkp0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjn3q5", "is_robot_indexable": true, "report_reasons": null, "author": "bear007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjn3q5/scala_31_strict_exceptions_and_faster_match/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/i4k79srcBub", "subreddit_subscribers": 816680, "created_utc": 1667340897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Important research findings: Taylor Swift Swear Projection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yjm43u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1v6k7o1o", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nhb6gtIiAjd80XZfq8FXeFkp2zRj_zIDLDjTtiofa90.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "TaylorSwift", "selftext": "We are all pleased that Taylor is starting to swear like she means it. But I've had real concerns about the recent rapid increase in swears per album. I decided to run some projections for studio albums 11 through 20. The trends are worrying.\n\nTaylor Swift 14 is likely to be released near 2030. Projections show that album will include 281 swears. It's going to be quite a different Taylor but I'm sure she can pull it off.\n\nBy 2039, things have really changed. Taylor Swift 20, released on her 50th birthday, may be the biggest album of the year.  But I am not sure how Swifties are going to react to the 2,570 swear words. It seems excessive, is Taylor OK? Maybe that's how all music sounds in 2039.\n\nI hope you found this information helpful.\n\nEDIT: u/vearson26's independent research has found that the average TSwift song contains 13 tracks, each track averaging 200 words, or 2600 average words per album.\n\nThe unavoidable conclusion is that \"2039\" could well be the first Taylor album which is literally all swear words. This is the singularity. The world beyond the singularity is unknowable. Good luck.  \n\n\nhttps://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;format=png&amp;auto=webp&amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da", "author_fullname": "t2_53f1pjmw", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Important research findings: Taylor Swift Swear Projection", "link_flair_richtext": [{"e": "text", "t": "News "}, {"a": ":news:", "e": "emoji", "u": "https://emoji.redditmedia.com/0l4sk2h3b3g31_t5_2rlwe/news"}], "subreddit_name_prefixed": "r/TaylorSwift", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v7yd3z0blmw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 181, "x": 108, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0ef8390ef5fc95bc44642d8d48deb188dc75d4d"}, {"y": 362, "x": 216, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=091780f2015815e184d2c43405b8952a115ff90b"}, {"y": 536, "x": 320, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=096a7bee056487308620b82b387855886377ad88"}, {"y": 1073, "x": 640, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=393f7ffbc06a9e26b8e8153ccf04a99d0dc02e6e"}], "s": {"y": 1551, "x": 925, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;format=png&amp;auto=webp&amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da"}, "id": "v7yd3z0blmw91"}}, "name": "t3_yg31p7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1969, "total_awards_received": 10, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News :news:", "can_mod_post": false, "score": 1969, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/nhb6gtIiAjd80XZfq8FXeFkp2zRj_zIDLDjTtiofa90.jpg", "edited": 1667064034.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 5, "gid_2": 1, "gid_3": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666997537.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.TaylorSwift", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are all pleased that Taylor is starting to swear like she means it. But I&amp;#39;ve had real concerns about the recent rapid increase in swears per album. I decided to run some projections for studio albums 11 through 20. The trends are worrying.&lt;/p&gt;\n\n&lt;p&gt;Taylor Swift 14 is likely to be released near 2030. Projections show that album will include 281 swears. It&amp;#39;s going to be quite a different Taylor but I&amp;#39;m sure she can pull it off.&lt;/p&gt;\n\n&lt;p&gt;By 2039, things have really changed. Taylor Swift 20, released on her 50th birthday, may be the biggest album of the year.  But I am not sure how Swifties are going to react to the 2,570 swear words. It seems excessive, is Taylor OK? Maybe that&amp;#39;s how all music sounds in 2039.&lt;/p&gt;\n\n&lt;p&gt;I hope you found this information helpful.&lt;/p&gt;\n\n&lt;p&gt;EDIT: &lt;a href=\"/u/vearson26\"&gt;u/vearson26&lt;/a&gt;&amp;#39;s independent research has found that the average TSwift song contains 13 tracks, each track averaging 200 words, or 2600 average words per album.&lt;/p&gt;\n\n&lt;p&gt;The unavoidable conclusion is that &amp;quot;2039&amp;quot; could well be the first Taylor album which is literally all swear words. This is the singularity. The world beyond the singularity is unknowable. Good luck.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da\"&gt;https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_31260000-2f4a-4b40-ad20-f5aa46a577bf", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Timeless_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Beauty that's forever. Gives %{coin_symbol}100 Coins each to the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Timeless Beauty", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=16&amp;height=16&amp;auto=webp&amp;s=9fdc2c55e7ddacb233466226c411fdd5474b9f02", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=32&amp;height=32&amp;auto=webp&amp;s=7b32657206f9bf592327fcf93be3141c88377738", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=48&amp;height=48&amp;auto=webp&amp;s=f9d7c94902a3fca13129f1562c1760fd2efed612", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=64&amp;height=64&amp;auto=webp&amp;s=5d7c3b3b8c15fea95896006200a6dea0eccb2820", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=128&amp;height=128&amp;auto=webp&amp;s=613f9c4ad715208edccb511aaccac33fe033111a", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 5, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 31, "coin_price": 1800, "id": "gid_3", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png", "days_of_premium": 31, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 700 Reddit Coins and a month of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Platinum", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "217b9500-828c-11e5-948b-0e373b482bcf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rlwe", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a4d8ff", "id": "yg31p7", "is_robot_indexable": true, "report_reasons": null, "author": "allthepassports", "discussion_type": null, "num_comments": 198, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "subreddit_subscribers": 328137, "created_utc": 1666997537.0, "num_crossposts": 5, "media": null, "is_video": false}], "created": 1667338529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.TaylorSwift", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjm43u", "is_robot_indexable": true, "report_reasons": null, "author": "Adam_24061", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yg31p7", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjm43u/important_research_findings_taylor_swift_swear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "subreddit_subscribers": 816680, "created_utc": 1667338529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lets say I have a dataset D with n instances and three pre-trained regressors, Ra, Rb and Rc.\n\nI can run each regressor on D, which will net me a set of predictions Pa, Pb and Pc. How can I measure how much these three regressors \"agree\" in their predictions?\n\nFor example, if my Y domain is [0,100] and for some instance they predict 10, 11 and 9, I would argue that they 'agree' in their decisions. If, on the other hand, the predictions returned are 1, 99, 30, then they 'disagree'. But this is rather qualitative and subjective, I'm looking for a quantitative metric.\n\nI guess another way of asking is, how can I measure how close a set of predictions Pa, Pb and Pc are from one another.\n\nI thought of computing the mean standard deviation on each instance, or maybe the mean KL divergence between all regressor pairs but I'm wondering if there exists a better metric. Maybe something like a kappa score, but for regression.\n\nThanks!", "author_fullname": "t2_62m1wp38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to measure the 'agreement' of a set of regressors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjkp4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667335491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667335300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a dataset D with n instances and three pre-trained regressors, Ra, Rb and Rc.&lt;/p&gt;\n\n&lt;p&gt;I can run each regressor on D, which will net me a set of predictions Pa, Pb and Pc. How can I measure how much these three regressors &amp;quot;agree&amp;quot; in their predictions?&lt;/p&gt;\n\n&lt;p&gt;For example, if my Y domain is [0,100] and for some instance they predict 10, 11 and 9, I would argue that they &amp;#39;agree&amp;#39; in their decisions. If, on the other hand, the predictions returned are 1, 99, 30, then they &amp;#39;disagree&amp;#39;. But this is rather qualitative and subjective, I&amp;#39;m looking for a quantitative metric.&lt;/p&gt;\n\n&lt;p&gt;I guess another way of asking is, how can I measure how close a set of predictions Pa, Pb and Pc are from one another.&lt;/p&gt;\n\n&lt;p&gt;I thought of computing the mean standard deviation on each instance, or maybe the mean KL divergence between all regressor pairs but I&amp;#39;m wondering if there exists a better metric. Maybe something like a kappa score, but for regression.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjkp4k", "is_robot_indexable": true, "report_reasons": null, "author": "Tricky-Variation-240", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjkp4k/how_to_measure_the_agreement_of_a_set_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjkp4k/how_to_measure_the_agreement_of_a_set_of/", "subreddit_subscribers": 816680, "created_utc": 1667335300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This article gives an example\n\n[https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a](https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a)\n\nWhat do you think?", "author_fullname": "t2_pwxlrv27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Organize Your Data Science Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjamgq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667314109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This article gives an example&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a\"&gt;https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjamgq", "is_robot_indexable": true, "report_reasons": null, "author": "Fast-Group-8501", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjamgq/how_to_organize_your_data_science_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjamgq/how_to_organize_your_data_science_project/", "subreddit_subscribers": 816680, "created_utc": 1667314109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I have a bivariate numerical time series. I want to design a statistical test to evaluate the correlation between the two variables.\n\nMy population is about 800 data points, I understand that I can get the Pearson correlation easily with pandas for example. In this case I get a strong positive correlation of 0.908. \n\nMy question is : if I wanted to make a correlation test on a sample of the time series, for the purpose of demonstration, would it even be relevant to sample a population of 800 data points?  \n\nIf yes, what method should I use to sample the time series?\n\nSorry if this has already been answered or isn't relevant I just can't find it by myself. Any help is greatly appreciated.", "author_fullname": "t2_nks6q3kg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First correlation test (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj82r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667307600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bivariate numerical time series. I want to design a statistical test to evaluate the correlation between the two variables.&lt;/p&gt;\n\n&lt;p&gt;My population is about 800 data points, I understand that I can get the Pearson correlation easily with pandas for example. In this case I get a strong positive correlation of 0.908. &lt;/p&gt;\n\n&lt;p&gt;My question is : if I wanted to make a correlation test on a sample of the time series, for the purpose of demonstration, would it even be relevant to sample a population of 800 data points?  &lt;/p&gt;\n\n&lt;p&gt;If yes, what method should I use to sample the time series?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this has already been answered or isn&amp;#39;t relevant I just can&amp;#39;t find it by myself. Any help is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj82r5", "is_robot_indexable": true, "report_reasons": null, "author": "datafrime", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj82r5/first_correlation_test_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj82r5/first_correlation_test_noob/", "subreddit_subscribers": 816680, "created_utc": 1667307600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:\n\n1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.\n\n2) Download the mp3 and metadata (date, title, etc.) for the podcast.\n\n3) Process audio using something like WisperAI.\n\n4) Store the data for analytics.\n\n**I'm wondering if anyone has recommendations for the above, specifically steps 1 and 2?** For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?\n\nThanks so much for any assistance here!", "author_fullname": "t2_10ctkxdy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast Audio &amp; Metadata Scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj7lp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667306241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:&lt;/p&gt;\n\n&lt;p&gt;1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.&lt;/p&gt;\n\n&lt;p&gt;2) Download the mp3 and metadata (date, title, etc.) for the podcast.&lt;/p&gt;\n\n&lt;p&gt;3) Process audio using something like WisperAI.&lt;/p&gt;\n\n&lt;p&gt;4) Store the data for analytics.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m wondering if anyone has recommendations for the above, specifically steps 1 and 2?&lt;/strong&gt; For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for any assistance here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj7lp1", "is_robot_indexable": true, "report_reasons": null, "author": "beige_coffee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj7lp1/podcast_audio_metadata_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj7lp1/podcast_audio_metadata_scraping/", "subreddit_subscribers": 816680, "created_utc": 1667306241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a question  regarding var. Im using this model to find significance of factors that influences consumer price index and i have found few variables such as GDP. Any idea how and what values am i looking for in the model to determine whether my factor have any  significance in relative to consumer price index of a country?", "author_fullname": "t2_7cmorcub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "vector autoregressive model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj37el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667292266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question  regarding var. Im using this model to find significance of factors that influences consumer price index and i have found few variables such as GDP. Any idea how and what values am i looking for in the model to determine whether my factor have any  significance in relative to consumer price index of a country?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj37el", "is_robot_indexable": true, "report_reasons": null, "author": "Economy_Seesaw_7791", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj37el/vector_autoregressive_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj37el/vector_autoregressive_model/", "subreddit_subscribers": 816680, "created_utc": 1667292266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title sounding stupid, let me clarify my question with the help of that quote :\n\n&gt;According to two recent Gartner reports, 85% of AI and machine learning projects fail to deliver, and only 53% of projects make it from prototypes to production.\n\nWhen you spend weeks/months on a project and it gets nowhere, do you try harder ? are you assigned to work on another task ? Do you feel ~~like you're the failure of the company~~ powerless ?\n\nOr is it just \"part of the deal\", win some, lose some. \n\nI'm also very curious as to how companies that extensively pay data scientists manage to benefit from their employees in case of failures/repeated failure on the long run.", "author_fullname": "t2_5blbvj00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens when one of your project fails ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjm8i3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667340077.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667338839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title sounding stupid, let me clarify my question with the help of that quote :&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;According to two recent Gartner reports, 85% of AI and machine learning projects fail to deliver, and only 53% of projects make it from prototypes to production.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;When you spend weeks/months on a project and it gets nowhere, do you try harder ? are you assigned to work on another task ? Do you feel &lt;del&gt;like you&amp;#39;re the failure of the company&lt;/del&gt; powerless ?&lt;/p&gt;\n\n&lt;p&gt;Or is it just &amp;quot;part of the deal&amp;quot;, win some, lose some. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also very curious as to how companies that extensively pay data scientists manage to benefit from their employees in case of failures/repeated failure on the long run.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjm8i3", "is_robot_indexable": true, "report_reasons": null, "author": "SaltySarcasticJohn", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjm8i3/what_happens_when_one_of_your_project_fails/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjm8i3/what_happens_when_one_of_your_project_fails/", "subreddit_subscribers": 816680, "created_utc": 1667338839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Due to me working on a project that I would like to add on my resume before I apply for jobs, I haven't aggressively pursued applying to jobs.\n\nIn terms of the timeline that companies follow for hiring, if I wait until spring to apply to jobs will the job opportunities be significantly restricted?", "author_fullname": "t2_1szbf83g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Grad Job Application Timeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjl2k6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667336114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Due to me working on a project that I would like to add on my resume before I apply for jobs, I haven&amp;#39;t aggressively pursued applying to jobs.&lt;/p&gt;\n\n&lt;p&gt;In terms of the timeline that companies follow for hiring, if I wait until spring to apply to jobs will the job opportunities be significantly restricted?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjl2k6", "is_robot_indexable": true, "report_reasons": null, "author": "MAVAAMUSICMACHINE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjl2k6/new_grad_job_application_timeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjl2k6/new_grad_job_application_timeline/", "subreddit_subscribers": 816680, "created_utc": 1667336114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have txt books.  They have a lot of pages. I want to sort words top used words. For example;\n\nI desire to have a code like this\n\n`python input.txt -sort-top-words output.txt`\n\nand\n\noutput.txt should have minimum 10.000 words like this:\n\n1. the\n2. of\n3. and\n4. house\n5. that... 10000: orange\n\nThere are several websites for this. But i want to do this myself via code. I think all programming languages can do this. I prefer \"python or javascript\" since i have some background these languages. How can i do this?", "author_fullname": "t2_7qf2od4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sorting top used words in my txt books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjgbh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667326372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have txt books.  They have a lot of pages. I want to sort words top used words. For example;&lt;/p&gt;\n\n&lt;p&gt;I desire to have a code like this&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;python input.txt -sort-top-words output.txt&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;and&lt;/p&gt;\n\n&lt;p&gt;output.txt should have minimum 10.000 words like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;the&lt;/li&gt;\n&lt;li&gt;of&lt;/li&gt;\n&lt;li&gt;and&lt;/li&gt;\n&lt;li&gt;house&lt;/li&gt;\n&lt;li&gt;that... 10000: orange&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There are several websites for this. But i want to do this myself via code. I think all programming languages can do this. I prefer &amp;quot;python or javascript&amp;quot; since i have some background these languages. How can i do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjgbh2", "is_robot_indexable": true, "report_reasons": null, "author": "birisix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjgbh2/sorting_top_used_words_in_my_txt_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjgbh2/sorting_top_used_words_in_my_txt_books/", "subreddit_subscribers": 816680, "created_utc": 1667326372.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}