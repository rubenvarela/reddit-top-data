{"kind": "Listing", "data": {"after": "t3_yk9oby", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I already work as a data scientist, and I get by. I'm coming from academia, I have quite some in depth stats training and previously used a lot of R, and have since transitioned to python and I find that with my academic training, the modelling, data wrangling, stats, visualizations etc come quite easily. But my computer science skills suck! Here are things I don't get:\n\nWhat's an interpreter? What's a bin? What's a path? Why when I follow this tutorial is postgres being funny and I have no knowledge base to debug it? How the hell can I get anything done at all with pycharm? Why does Airflow make me cry? The list goes on...\n\nThis lack of knowledge makes setting up ETL pipelines and data engineering challenging for me. Does anyone know any resources for improving computer science skills, preferably focused on where that is relevant for data science?\n\nMany thanks!", "author_fullname": "t2_lrovl6pi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to improve my computer science skills, please help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk0d3k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667380905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already work as a data scientist, and I get by. I&amp;#39;m coming from academia, I have quite some in depth stats training and previously used a lot of R, and have since transitioned to python and I find that with my academic training, the modelling, data wrangling, stats, visualizations etc come quite easily. But my computer science skills suck! Here are things I don&amp;#39;t get:&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s an interpreter? What&amp;#39;s a bin? What&amp;#39;s a path? Why when I follow this tutorial is postgres being funny and I have no knowledge base to debug it? How the hell can I get anything done at all with pycharm? Why does Airflow make me cry? The list goes on...&lt;/p&gt;\n\n&lt;p&gt;This lack of knowledge makes setting up ETL pipelines and data engineering challenging for me. Does anyone know any resources for improving computer science skills, preferably focused on where that is relevant for data science?&lt;/p&gt;\n\n&lt;p&gt;Many thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk0d3k", "is_robot_indexable": true, "report_reasons": null, "author": "likeamanyfacedgod", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk0d3k/i_need_to_improve_my_computer_science_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk0d3k/i_need_to_improve_my_computer_science_skills/", "subreddit_subscribers": 816831, "created_utc": 1667380905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3im2k46f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In what ways is abstract algebra related to machine learning and data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjtx83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667358771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjtx83", "is_robot_indexable": true, "report_reasons": null, "author": "bc_951", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjtx83/in_what_ways_is_abstract_algebra_related_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjtx83/in_what_ways_is_abstract_algebra_related_to/", "subreddit_subscribers": 816831, "created_utc": 1667358771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a junior in college, looking to get a master's in data science. I am curious if any jobs allow you to travel for data science. I feel that most opportunities are stationary as most work deals with internal company data, but I would love to know if there are any industries or positions that allow more travel opportunities.", "author_fullname": "t2_5fdiktrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any data science jobs that require travel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjtox5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667358087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a junior in college, looking to get a master&amp;#39;s in data science. I am curious if any jobs allow you to travel for data science. I feel that most opportunities are stationary as most work deals with internal company data, but I would love to know if there are any industries or positions that allow more travel opportunities.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjtox5", "is_robot_indexable": true, "report_reasons": null, "author": "waddupbigpimps_", "discussion_type": null, "num_comments": 62, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjtox5/are_there_any_data_science_jobs_that_require/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjtox5/are_there_any_data_science_jobs_that_require/", "subreddit_subscribers": 816831, "created_utc": 1667358087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_917kr96x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do data science job interviews have coding questions like for SWE? If not, what kind of technical questions are asked in DS interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8q1b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667404044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8q1b", "is_robot_indexable": true, "report_reasons": null, "author": "EurasianZaltpetre", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8q1b/do_data_science_job_interviews_have_coding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8q1b/do_data_science_job_interviews_have_coding/", "subreddit_subscribers": 816831, "created_utc": 1667404044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I did a coding challenge and had four interviews for a data scientist position which in the end they gave to another candidate. One of the reasons that they said they selected the other candidate was that he/she really blew them away with their solutions to the coding challenge. So I was wondering if anyone would be able to look at the solutions that I came up with, which weren't so impressive and give me feedback? Of course I don't have anything to offer your generosity in return, so hopefully there's someone out there who just enjoys these kinds of things and is willing to give me feedback :) Also, of course there might  be a lot of things that one could do given a long time, but I'm looking for feedback for things that could be realistically done in a couple of evenings or max a couple of full days.\n\nSo here is the challenge:\n\n[https://github.com/code-flightright/cs-data-engineer](https://github.com/code-flightright/cs-data-engineer)\n\nAnd here are my solutions:\n\n[https://github.com/SteveSizzou/coding\\_challenge](https://github.com/SteveSizzou/coding_challenge)\n\nAlso if anyone is generous enough it would be great to take it to PM's so I can really pick your brain on what I could have done better :)\n\nThanks in advance!", "author_fullname": "t2_9v3ti6di", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on my solutions to a coding challenge for a position that I didn't get.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk3zwb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667392573.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667392314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did a coding challenge and had four interviews for a data scientist position which in the end they gave to another candidate. One of the reasons that they said they selected the other candidate was that he/she really blew them away with their solutions to the coding challenge. So I was wondering if anyone would be able to look at the solutions that I came up with, which weren&amp;#39;t so impressive and give me feedback? Of course I don&amp;#39;t have anything to offer your generosity in return, so hopefully there&amp;#39;s someone out there who just enjoys these kinds of things and is willing to give me feedback :) Also, of course there might  be a lot of things that one could do given a long time, but I&amp;#39;m looking for feedback for things that could be realistically done in a couple of evenings or max a couple of full days.&lt;/p&gt;\n\n&lt;p&gt;So here is the challenge:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/code-flightright/cs-data-engineer\"&gt;https://github.com/code-flightright/cs-data-engineer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here are my solutions:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/SteveSizzou/coding_challenge\"&gt;https://github.com/SteveSizzou/coding_challenge&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also if anyone is generous enough it would be great to take it to PM&amp;#39;s so I can really pick your brain on what I could have done better :)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?auto=webp&amp;s=ea5aebf57a2ee69e5a500291fc98a83c03708164", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa6e4e678af2b45a1a24098fd2ce06b811ba5e0e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b136f12131c3e865be8931f006cb51ce48888fb0", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad348ef13d0606d667f77a7f2c96c70ba97ca3e8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39419e9af399fc90efa4335828acc85a9b419090", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae4e68d59dc4c8920ef5a027fc405094a26df463", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MKsK64pQavgtPwqUd1uxm951IQPfVxSXm4Y9B_B_m_4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=285720092734e85227426bc9d71fbeda287ffae2", "width": 1080, "height": 540}], "variants": {}, "id": "oqRaLSz_EFsvaAHA-ZRoPi0YbYAYL86sC64SUuBkSk4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk3zwb", "is_robot_indexable": true, "report_reasons": null, "author": "pd_w", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk3zwb/looking_for_feedback_on_my_solutions_to_a_coding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk3zwb/looking_for_feedback_on_my_solutions_to_a_coding/", "subreddit_subscribers": 816831, "created_utc": 1667392314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Folks,\n\nFor any tensorflow developers out there or if you are generally interested in helping I need some help:\n\nI took the Tensorflow developer specialization on Coursera. I recently completed their 3rd course. I was quite overwhelmed frankly as I had never worked with NLP.  I really wanted to stop for a while and develop something of my own as a project to test my knowledge. I stumbled upon this idea of building a disease prediction model last week and I really wanted to get some ideas on my model. I scraped diseases, and their symptoms from internet. Symptoms being separated by commas with no sequential meaning.\n\n1. Some of my symptoms and disease names are multi word, is there any work around for that?\n\n2. I guess using LSTM is quite useless as symptoms are randomly separated by commas so no sequential meaning. Comments?\n\n3. I multiplied my dataset by using symptoms in various combinations for every disease. Is this fine?\n\n4. My approach so far has been to tokenize each symptom. I did not tokenize labels and rather created a dictionary with indexes. This is because some diseases \\*labels\\* were multi word so I cannot pass a token array as label.\n\n5. Should I go for one hot encoding rather?\n\nI pass the input through an embedding layer \\*\\*64 dimension\\*\\*, Global avg pooling 1D, Dense layer 100 relu activations, and 261 outputs softmax activation.\n\nI got 90% train and val accuracy. Is this approach right?\n\nAnother thing I wanted to do was to be able to predict symptoms from utterances, any suggestions?\n\nIf anyone is interested, feel free to join in the project", "author_fullname": "t2_rzwdmc0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions on an NLP project that I built", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjj8ps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667332273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,&lt;/p&gt;\n\n&lt;p&gt;For any tensorflow developers out there or if you are generally interested in helping I need some help:&lt;/p&gt;\n\n&lt;p&gt;I took the Tensorflow developer specialization on Coursera. I recently completed their 3rd course. I was quite overwhelmed frankly as I had never worked with NLP.  I really wanted to stop for a while and develop something of my own as a project to test my knowledge. I stumbled upon this idea of building a disease prediction model last week and I really wanted to get some ideas on my model. I scraped diseases, and their symptoms from internet. Symptoms being separated by commas with no sequential meaning.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Some of my symptoms and disease names are multi word, is there any work around for that?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I guess using LSTM is quite useless as symptoms are randomly separated by commas so no sequential meaning. Comments?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I multiplied my dataset by using symptoms in various combinations for every disease. Is this fine?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;My approach so far has been to tokenize each symptom. I did not tokenize labels and rather created a dictionary with indexes. This is because some diseases *labels* were multi word so I cannot pass a token array as label.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should I go for one hot encoding rather?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I pass the input through an embedding layer **64 dimension**, Global avg pooling 1D, Dense layer 100 relu activations, and 261 outputs softmax activation.&lt;/p&gt;\n\n&lt;p&gt;I got 90% train and val accuracy. Is this approach right?&lt;/p&gt;\n\n&lt;p&gt;Another thing I wanted to do was to be able to predict symptoms from utterances, any suggestions?&lt;/p&gt;\n\n&lt;p&gt;If anyone is interested, feel free to join in the project&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjj8ps", "is_robot_indexable": true, "report_reasons": null, "author": "Kind-Thing-7202", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjj8ps/need_suggestions_on_an_nlp_project_that_i_built/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjj8ps/need_suggestions_on_an_nlp_project_that_i_built/", "subreddit_subscribers": 816831, "created_utc": 1667332273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in the UK for a utility contractor, mostly automating reports, building ML algorithms and leading a team of new data scientists. My question is, if strong domain knowledge is a fundamental component of being a data scientist, how does someone with 5+ years' experience in one industry change to another? Do they need to start again as a junior?   \n\n\nI'd love to hear your experiences of this situation.", "author_fullname": "t2_thyuhojz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does a Data Scientist change domains?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk62ve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667397725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in the UK for a utility contractor, mostly automating reports, building ML algorithms and leading a team of new data scientists. My question is, if strong domain knowledge is a fundamental component of being a data scientist, how does someone with 5+ years&amp;#39; experience in one industry change to another? Do they need to start again as a junior?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your experiences of this situation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk62ve", "is_robot_indexable": true, "report_reasons": null, "author": "StereotypicalIrish1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk62ve/how_does_a_data_scientist_change_domains/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk62ve/how_does_a_data_scientist_change_domains/", "subreddit_subscribers": 816831, "created_utc": 1667397725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nI'm looking for book recommendations about data science for evaluating data and showing relationships.  Pretty much a \"how-to approach\" for beginning analysis. I've seen [Practical Statistics for Data Scientists](https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/) recommended but I also came across [Data Science for Business](https://www.oreilly.com/library/view/data-science-for/9781449374273/) which talks about data mining and data analytical thinking. \n\nHere's an example:\n\nThe CEO says X is causing Y but the CFO says Z is causing Y.  I want to evaluate the data to prove/disprove either statement. I can use the variables that the CEO/CFO mentioned but what if they are both wrong.  Do I only use statistical methods to do this? What's the approach for this?\n\nAs a data engineer/database developer at my organization I have access to a TON of data so I've been choosing data science projects to work on for fun. The issue is, I realized I don't REALLY know how to evaluate the data to show relationships or prove/disprove a problem/question. \n\nI have taken several data science courses online (365DataScience), built ML models offered through the courses so I have a grasp on the overarching concepts. I've also recently started my undergrad for computation mathematics with a focus on data science but advanced math classes won't be for awhile. I can use Matplotlib/Seaborn and plot heat maps, scatter plots, histograms etc. and I make some assumptions but there is a lot I can't explain.\n\nLooking forward to comments and recommendations. Thank you!", "author_fullname": "t2_rdabwsdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendations for learning how to identify data relationships", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk5gj8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667396144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for book recommendations about data science for evaluating data and showing relationships.  Pretty much a &amp;quot;how-to approach&amp;quot; for beginning analysis. I&amp;#39;ve seen &lt;a href=\"https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/\"&gt;Practical Statistics for Data Scientists&lt;/a&gt; recommended but I also came across &lt;a href=\"https://www.oreilly.com/library/view/data-science-for/9781449374273/\"&gt;Data Science for Business&lt;/a&gt; which talks about data mining and data analytical thinking. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an example:&lt;/p&gt;\n\n&lt;p&gt;The CEO says X is causing Y but the CFO says Z is causing Y.  I want to evaluate the data to prove/disprove either statement. I can use the variables that the CEO/CFO mentioned but what if they are both wrong.  Do I only use statistical methods to do this? What&amp;#39;s the approach for this?&lt;/p&gt;\n\n&lt;p&gt;As a data engineer/database developer at my organization I have access to a TON of data so I&amp;#39;ve been choosing data science projects to work on for fun. The issue is, I realized I don&amp;#39;t REALLY know how to evaluate the data to show relationships or prove/disprove a problem/question. &lt;/p&gt;\n\n&lt;p&gt;I have taken several data science courses online (365DataScience), built ML models offered through the courses so I have a grasp on the overarching concepts. I&amp;#39;ve also recently started my undergrad for computation mathematics with a focus on data science but advanced math classes won&amp;#39;t be for awhile. I can use Matplotlib/Seaborn and plot heat maps, scatter plots, histograms etc. and I make some assumptions but there is a lot I can&amp;#39;t explain.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to comments and recommendations. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/U6cMnmBzGVJ9MZIEGynfdMEj3m7mrIl8X_iCczFPAmo.jpg?auto=webp&amp;s=5749fc4aaab34075f41bb4bedde35df8279b3c8c", "width": 140, "height": 184}, "resolutions": [{"url": "https://external-preview.redd.it/U6cMnmBzGVJ9MZIEGynfdMEj3m7mrIl8X_iCczFPAmo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e6292a117257a8bbae8560b444fef7f13f61043", "width": 108, "height": 141}], "variants": {}, "id": "LKabCUDORRpffyzOJQsS4p0w05yG3c1WUk2F0g_ASNE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk5gj8", "is_robot_indexable": true, "report_reasons": null, "author": "avb0101", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk5gj8/book_recommendations_for_learning_how_to_identify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk5gj8/book_recommendations_for_learning_how_to_identify/", "subreddit_subscribers": 816831, "created_utc": 1667396144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As of July 1st this year all health insurers in the US were required to publish files on their websites of all their negotiated prices they have for every possible medical procedure with every doctor in the country. In totality this data set equates to trillions of rows and hundreds of TB of data.\n\nI'm interested in building out a collaborative effort to aggregate all this data, but the cost of hosting seems to be a huge problem. What's the cheapest, effective way to host all this data in such a way that it's publicly accessible?", "author_fullname": "t2_457f1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help hosting trillions of rows of new health insurance public price data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk9gye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667405767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of July 1st this year all health insurers in the US were required to publish files on their websites of all their negotiated prices they have for every possible medical procedure with every doctor in the country. In totality this data set equates to trillions of rows and hundreds of TB of data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in building out a collaborative effort to aggregate all this data, but the cost of hosting seems to be a huge problem. What&amp;#39;s the cheapest, effective way to host all this data in such a way that it&amp;#39;s publicly accessible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk9gye", "is_robot_indexable": true, "report_reasons": null, "author": "invisiblelemur88", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk9gye/help_hosting_trillions_of_rows_of_new_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk9gye/help_hosting_trillions_of_rows_of_new_health/", "subreddit_subscribers": 816831, "created_utc": 1667405767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I\u2019ve been going to university for computational physics (physics and computer science degree in one) and I\u2019ve been looking into data science. At my current job I was working part-time in order to focus on school. They\u2019ve recently gotten rid of the part-time position and now I have to work full-time. The problem is it\u2019s a 10 hour night shift position with an hour of commute to and from home. I\u2019m away from home for at least 12 hours of the day and have time to really only tackle one or two classes. \n\nI was hoping I could pick up a part-time position in the analytical world so I could finish school quicker while also gaining experience in a field I\u2019m interested in. What kind of part time jobs are the in the analytic world for someone like me to get my foot in the door?", "author_fullname": "t2_p8i5qcr2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any advice for a student trying to make it in the analytical world?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjr4bv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667351064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve been going to university for computational physics (physics and computer science degree in one) and I\u2019ve been looking into data science. At my current job I was working part-time in order to focus on school. They\u2019ve recently gotten rid of the part-time position and now I have to work full-time. The problem is it\u2019s a 10 hour night shift position with an hour of commute to and from home. I\u2019m away from home for at least 12 hours of the day and have time to really only tackle one or two classes. &lt;/p&gt;\n\n&lt;p&gt;I was hoping I could pick up a part-time position in the analytical world so I could finish school quicker while also gaining experience in a field I\u2019m interested in. What kind of part time jobs are the in the analytic world for someone like me to get my foot in the door?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yjr4bv", "is_robot_indexable": true, "report_reasons": null, "author": "__6EQUJ5", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjr4bv/any_advice_for_a_student_trying_to_make_it_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjr4bv/any_advice_for_a_student_trying_to_make_it_in_the/", "subreddit_subscribers": 816831, "created_utc": 1667351064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been doing data sci for 4 years, but actually, I think that I'm pretty crap at it... I program really well in R, but no one wants it, my Python is intermediate. I'm pretty good at stats from my PhD days, but that doesn't really come in handy in practice. When I do am ML project it's always regression based and seems to do the trick.... I did some deep learning courses, but I'm not sure if there are really any use cases out there for that... I basically feel like I'm not particularly well specialized. What thing could i really work on to start doing more exciting work and improve my job outlook? For example, really killing it with the deep learning is my first intuition, but it seems that in practice this skill is not all that sought after or needed.... What do you think?", "author_fullname": "t2_lrovl6pi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skills do I need to really work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ykaxuh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667409178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been doing data sci for 4 years, but actually, I think that I&amp;#39;m pretty crap at it... I program really well in R, but no one wants it, my Python is intermediate. I&amp;#39;m pretty good at stats from my PhD days, but that doesn&amp;#39;t really come in handy in practice. When I do am ML project it&amp;#39;s always regression based and seems to do the trick.... I did some deep learning courses, but I&amp;#39;m not sure if there are really any use cases out there for that... I basically feel like I&amp;#39;m not particularly well specialized. What thing could i really work on to start doing more exciting work and improve my job outlook? For example, really killing it with the deep learning is my first intuition, but it seems that in practice this skill is not all that sought after or needed.... What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykaxuh", "is_robot_indexable": true, "report_reasons": null, "author": "likeamanyfacedgod", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykaxuh/what_skills_do_i_need_to_really_work_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykaxuh/what_skills_do_i_need_to_really_work_on/", "subreddit_subscribers": 816831, "created_utc": 1667409178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a classification model trained to predict 3 classes of labels. I want to know what feature combinations reliably predict each class. Is there an implementation in python which allows for this insight?", "author_fullname": "t2_kr695uqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to understand what features reliably predict my labels?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk3ex0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667390701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a classification model trained to predict 3 classes of labels. I want to know what feature combinations reliably predict each class. Is there an implementation in python which allows for this insight?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk3ex0", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Skin-3889", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk3ex0/how_to_understand_what_features_reliably_predict/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk3ex0/how_to_understand_what_features_reliably_predict/", "subreddit_subscribers": 816831, "created_utc": 1667390701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking to forecast demand for products and understand where my firm is doing well or poorly based on tracking various KPIs, complaints etc. \n\nHow do I approach this exercise? I have about 4 years of data to work with. E.g. Demand volumes, complaints, processing times, customer reviews etc.", "author_fullname": "t2_2ygw7tnt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjqaqg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667348857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to forecast demand for products and understand where my firm is doing well or poorly based on tracking various KPIs, complaints etc. &lt;/p&gt;\n\n&lt;p&gt;How do I approach this exercise? I have about 4 years of data to work with. E.g. Demand volumes, complaints, processing times, customer reviews etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjqaqg", "is_robot_indexable": true, "report_reasons": null, "author": "IStealCheesecake", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjqaqg/new_to_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjqaqg/new_to_forecasting/", "subreddit_subscribers": 816831, "created_utc": 1667348857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, I am a self-taught Data scientist and I just finished the Udacity SQL for Data Analysis. I am looking for projects to practice my SQL and also use it for visualization. \n\nPlease share any resources you think are worthwhile.", "author_fullname": "t2_eicfwc8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to Improve my SQL skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk2kso", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667388223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I am a self-taught Data scientist and I just finished the Udacity SQL for Data Analysis. I am looking for projects to practice my SQL and also use it for visualization. &lt;/p&gt;\n\n&lt;p&gt;Please share any resources you think are worthwhile.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk2kso", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic-Subject-900", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk2kso/looking_to_improve_my_sql_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk2kso/looking_to_improve_my_sql_skills/", "subreddit_subscribers": 816831, "created_utc": 1667388223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm not a data scientist, but I've been assigned a project somewhat in this category and I'm trying to improve my programs performance.\n\nI'm scanning through a 10TB file system with 800,000 directories and a ton of files in python. I'm storing some file meta data like: size, mtime, and user id in a pandas dataframe, and it's taking 20+ hours to complete. What's odd about this is if I just go through the file system and only record file paths, it only takes about 6 hours. Which I would say is pretty fair. \n\nI feel that my problem is a memory problem. The more data is store the slower the program gets. Im sure people in this field have to work through datasets this large or larger very frequently, and there are developed methods for doing so efficiently. \n\nIs there a better means to record file meta data than to just save it in a structure in memory?", "author_fullname": "t2_l8wunj9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for storing Large Datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8yoi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667404614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m not a data scientist, but I&amp;#39;ve been assigned a project somewhat in this category and I&amp;#39;m trying to improve my programs performance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m scanning through a 10TB file system with 800,000 directories and a ton of files in python. I&amp;#39;m storing some file meta data like: size, mtime, and user id in a pandas dataframe, and it&amp;#39;s taking 20+ hours to complete. What&amp;#39;s odd about this is if I just go through the file system and only record file paths, it only takes about 6 hours. Which I would say is pretty fair. &lt;/p&gt;\n\n&lt;p&gt;I feel that my problem is a memory problem. The more data is store the slower the program gets. Im sure people in this field have to work through datasets this large or larger very frequently, and there are developed methods for doing so efficiently. &lt;/p&gt;\n\n&lt;p&gt;Is there a better means to record file meta data than to just save it in a structure in memory?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8yoi", "is_robot_indexable": true, "report_reasons": null, "author": "CruderMermaid6", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8yoi/best_practices_for_storing_large_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8yoi/best_practices_for_storing_large_datasets/", "subreddit_subscribers": 816831, "created_utc": 1667404614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to load some data and do the following tasks:\n\n1. load data from csv\n2. encode data types\n3. normalize data\n4. .... more to come...\n5. split data into two\n\nIs there a common Python design pattern approach for this type of pipeline data analysis?\n\nNot sure exactly what I need but it reminds me a little of a ***Builder*** pattern.\n\n    var myObject = myBuilder.addName(\"John Doe\").addAge(15).build()\n\nI've seen some packages that look to support it using decorators, but not sure if that's overcomplicating things or even a common approach.", "author_fullname": "t2_293ojlay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Data Analysis Patterns - A pipeline design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8ski", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667404214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to load some data and do the following tasks:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;load data from csv&lt;/li&gt;\n&lt;li&gt;encode data types&lt;/li&gt;\n&lt;li&gt;normalize data&lt;/li&gt;\n&lt;li&gt;.... more to come...&lt;/li&gt;\n&lt;li&gt;split data into two&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there a common Python design pattern approach for this type of pipeline data analysis?&lt;/p&gt;\n\n&lt;p&gt;Not sure exactly what I need but it reminds me a little of a &lt;strong&gt;&lt;em&gt;Builder&lt;/em&gt;&lt;/strong&gt; pattern.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;var myObject = myBuilder.addName(&amp;quot;John Doe&amp;quot;).addAge(15).build()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ve seen some packages that look to support it using decorators, but not sure if that&amp;#39;s overcomplicating things or even a common approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8ski", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_buttons", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8ski/python_data_analysis_patterns_a_pipeline_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8ski/python_data_analysis_patterns_a_pipeline_design/", "subreddit_subscribers": 816831, "created_utc": 1667404214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been tasked with creating a production grade scalable distribution network routing optimization model with some additional nuances. I'm using Rust as it will use very large datasets and has many constraints. I presume using python computation will be very slow and can't take that risk. I'm quite adept in Rust FYI but didn't develop any AI/ML projects with it.\n\nSince I'm developing such a large scale project for the first time, I'm unsure as to how to arrive at a reasonable implementation timeframe since I may have to write the entire custom AI/ML model from scratch to accommodate for the uncommon nuances.\n\nSuggestions on how to make my work a bit easier from all of you experienced peeps are also welcome.", "author_fullname": "t2_ra4tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to report timelines to the management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8i01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667403508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been tasked with creating a production grade scalable distribution network routing optimization model with some additional nuances. I&amp;#39;m using Rust as it will use very large datasets and has many constraints. I presume using python computation will be very slow and can&amp;#39;t take that risk. I&amp;#39;m quite adept in Rust FYI but didn&amp;#39;t develop any AI/ML projects with it.&lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m developing such a large scale project for the first time, I&amp;#39;m unsure as to how to arrive at a reasonable implementation timeframe since I may have to write the entire custom AI/ML model from scratch to accommodate for the uncommon nuances.&lt;/p&gt;\n\n&lt;p&gt;Suggestions on how to make my work a bit easier from all of you experienced peeps are also welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8i01", "is_robot_indexable": true, "report_reasons": null, "author": "a_aniq", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8i01/how_to_report_timelines_to_the_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8i01/how_to_report_timelines_to_the_management/", "subreddit_subscribers": 816831, "created_utc": 1667403508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My plan is to become a data scientist. So what I do first is to apply as a data analyst in companies. But one company called me and offered me a data governance position. Since I am a fresh graduate and it seems no one is currently accepting me as a data analyst, is it better to take this offer? If I do, how could I job hop or career shift in a data analyst role? Because based on what I've searched, the data governance role are more talking to people and securing/controlling the distribution of data and more of using flowcharts. I just hope I can also apply statistical test or dashboards for data visualization.", "author_fullname": "t2_t7fc22np", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science vs Data Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjrra2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667352755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My plan is to become a data scientist. So what I do first is to apply as a data analyst in companies. But one company called me and offered me a data governance position. Since I am a fresh graduate and it seems no one is currently accepting me as a data analyst, is it better to take this offer? If I do, how could I job hop or career shift in a data analyst role? Because based on what I&amp;#39;ve searched, the data governance role are more talking to people and securing/controlling the distribution of data and more of using flowcharts. I just hope I can also apply statistical test or dashboards for data visualization.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjrra2", "is_robot_indexable": true, "report_reasons": null, "author": "macsoup_33", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjrra2/data_science_vs_data_governance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjrra2/data_science_vs_data_governance/", "subreddit_subscribers": 816831, "created_utc": 1667352755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Important research findings: Taylor Swift Swear Projection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yjm43u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1v6k7o1o", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nhb6gtIiAjd80XZfq8FXeFkp2zRj_zIDLDjTtiofa90.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "TaylorSwift", "selftext": "We are all pleased that Taylor is starting to swear like she means it. But I've had real concerns about the recent rapid increase in swears per album. I decided to run some projections for studio albums 11 through 20. The trends are worrying.\n\nTaylor Swift 14 is likely to be released near 2030. Projections show that album will include 281 swears. It's going to be quite a different Taylor but I'm sure she can pull it off.\n\nBy 2039, things have really changed. Taylor Swift 20, released on her 50th birthday, may be the biggest album of the year.  But I am not sure how Swifties are going to react to the 2,570 swear words. It seems excessive, is Taylor OK? Maybe that's how all music sounds in 2039.\n\nI hope you found this information helpful.\n\nEDIT: u/vearson26's independent research has found that the average TSwift song contains 13 tracks, each track averaging 200 words, or 2600 average words per album.\n\nThe unavoidable conclusion is that \"2039\" could well be the first Taylor album which is literally all swear words. This is the singularity. The world beyond the singularity is unknowable. Good luck.  \n\n\nhttps://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;format=png&amp;auto=webp&amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da", "author_fullname": "t2_53f1pjmw", "saved": false, "mod_reason_title": null, "gilded": 2, "clicked": false, "title": "Important research findings: Taylor Swift Swear Projection", "link_flair_richtext": [{"e": "text", "t": "News "}, {"a": ":news:", "e": "emoji", "u": "https://emoji.redditmedia.com/0l4sk2h3b3g31_t5_2rlwe/news"}], "subreddit_name_prefixed": "r/TaylorSwift", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v7yd3z0blmw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 181, "x": 108, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0ef8390ef5fc95bc44642d8d48deb188dc75d4d"}, {"y": 362, "x": 216, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=091780f2015815e184d2c43405b8952a115ff90b"}, {"y": 536, "x": 320, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=096a7bee056487308620b82b387855886377ad88"}, {"y": 1073, "x": 640, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=393f7ffbc06a9e26b8e8153ccf04a99d0dc02e6e"}], "s": {"y": 1551, "x": 925, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;format=png&amp;auto=webp&amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da"}, "id": "v7yd3z0blmw91"}}, "name": "t3_yg31p7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2463, "total_awards_received": 11, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News :news:", "can_mod_post": false, "score": 2463, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/nhb6gtIiAjd80XZfq8FXeFkp2zRj_zIDLDjTtiofa90.jpg", "edited": 1667064034.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 5, "gid_2": 2, "gid_3": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666997537.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.TaylorSwift", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are all pleased that Taylor is starting to swear like she means it. But I&amp;#39;ve had real concerns about the recent rapid increase in swears per album. I decided to run some projections for studio albums 11 through 20. The trends are worrying.&lt;/p&gt;\n\n&lt;p&gt;Taylor Swift 14 is likely to be released near 2030. Projections show that album will include 281 swears. It&amp;#39;s going to be quite a different Taylor but I&amp;#39;m sure she can pull it off.&lt;/p&gt;\n\n&lt;p&gt;By 2039, things have really changed. Taylor Swift 20, released on her 50th birthday, may be the biggest album of the year.  But I am not sure how Swifties are going to react to the 2,570 swear words. It seems excessive, is Taylor OK? Maybe that&amp;#39;s how all music sounds in 2039.&lt;/p&gt;\n\n&lt;p&gt;I hope you found this information helpful.&lt;/p&gt;\n\n&lt;p&gt;EDIT: &lt;a href=\"/u/vearson26\"&gt;u/vearson26&lt;/a&gt;&amp;#39;s independent research has found that the average TSwift song contains 13 tracks, each track averaging 200 words, or 2600 average words per album.&lt;/p&gt;\n\n&lt;p&gt;The unavoidable conclusion is that &amp;quot;2039&amp;quot; could well be the first Taylor album which is literally all swear words. This is the singularity. The world beyond the singularity is unknowable. Good luck.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da\"&gt;https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 5, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 2, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 31, "coin_price": 1800, "id": "gid_3", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png", "days_of_premium": 31, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 700 Reddit Coins and a month of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Platinum", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_31260000-2f4a-4b40-ad20-f5aa46a577bf", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Timeless_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Beauty that's forever. Gives %{coin_symbol}100 Coins each to the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Timeless Beauty", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=16&amp;height=16&amp;auto=webp&amp;s=9fdc2c55e7ddacb233466226c411fdd5474b9f02", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=32&amp;height=32&amp;auto=webp&amp;s=7b32657206f9bf592327fcf93be3141c88377738", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=48&amp;height=48&amp;auto=webp&amp;s=f9d7c94902a3fca13129f1562c1760fd2efed612", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=64&amp;height=64&amp;auto=webp&amp;s=5d7c3b3b8c15fea95896006200a6dea0eccb2820", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=128&amp;height=128&amp;auto=webp&amp;s=613f9c4ad715208edccb511aaccac33fe033111a", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "217b9500-828c-11e5-948b-0e373b482bcf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rlwe", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a4d8ff", "id": "yg31p7", "is_robot_indexable": true, "report_reasons": null, "author": "allthepassports", "discussion_type": null, "num_comments": 218, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "subreddit_subscribers": 328998, "created_utc": 1666997537.0, "num_crossposts": 6, "media": null, "is_video": false}], "created": 1667338529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.TaylorSwift", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjm43u", "is_robot_indexable": true, "report_reasons": null, "author": "Adam_24061", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yg31p7", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjm43u/important_research_findings_taylor_swift_swear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "subreddit_subscribers": 816831, "created_utc": 1667338529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lets say I have a dataset D with n instances and three pre-trained regressors, Ra, Rb and Rc.\n\nI can run each regressor on D, which will net me a set of predictions Pa, Pb and Pc. How can I measure how much these three regressors \"agree\" in their predictions?\n\nFor example, if my Y domain is [0,100] and for some instance they predict 10, 11 and 9, I would argue that they 'agree' in their decisions. If, on the other hand, the predictions returned are 1, 99, 30, then they 'disagree'. But this is rather qualitative and subjective, I'm looking for a quantitative metric.\n\nI guess another way of asking is, how can I measure how close a set of predictions Pa, Pb and Pc are from one another.\n\nI thought of computing the mean standard deviation on each instance, or maybe the mean KL divergence between all regressor pairs but I'm wondering if there exists a better metric. Maybe something like a kappa score, but for regression.\n\nThanks!", "author_fullname": "t2_62m1wp38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to measure the 'agreement' of a set of regressors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjkp4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667335491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667335300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a dataset D with n instances and three pre-trained regressors, Ra, Rb and Rc.&lt;/p&gt;\n\n&lt;p&gt;I can run each regressor on D, which will net me a set of predictions Pa, Pb and Pc. How can I measure how much these three regressors &amp;quot;agree&amp;quot; in their predictions?&lt;/p&gt;\n\n&lt;p&gt;For example, if my Y domain is [0,100] and for some instance they predict 10, 11 and 9, I would argue that they &amp;#39;agree&amp;#39; in their decisions. If, on the other hand, the predictions returned are 1, 99, 30, then they &amp;#39;disagree&amp;#39;. But this is rather qualitative and subjective, I&amp;#39;m looking for a quantitative metric.&lt;/p&gt;\n\n&lt;p&gt;I guess another way of asking is, how can I measure how close a set of predictions Pa, Pb and Pc are from one another.&lt;/p&gt;\n\n&lt;p&gt;I thought of computing the mean standard deviation on each instance, or maybe the mean KL divergence between all regressor pairs but I&amp;#39;m wondering if there exists a better metric. Maybe something like a kappa score, but for regression.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjkp4k", "is_robot_indexable": true, "report_reasons": null, "author": "Tricky-Variation-240", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjkp4k/how_to_measure_the_agreement_of_a_set_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjkp4k/how_to_measure_the_agreement_of_a_set_of/", "subreddit_subscribers": 816831, "created_utc": 1667335300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just popped into my head as I reflect on our marketing team trying to pay a vendor a godawful amount of money for what the vendor literally labels, \u201coff the shelf machine learning models.\u201d The deal, we open the gates to let them exfiltrate data, they use it to train models, they then sell those modes back to us and our competition\u2026\n\nWhat I\u2019m realizing now is that there is absolutely no reasonable way they can uphold a delete request from our customers because it would require they retire the old modes, retrain in fresh data, and redeploy to all their other clients. \n\nSimilarly if there is a request for transparency about what data we have access to and what it\u2019s being used for, if our competition is using models trained on our customers data from our data stores, then who knows how the hell they might be using that\u2026\n\nAnd for those curious, they are willing to give away our data assets because they don\u2019t want to wait for our internal teams to make them dashboards using our internal warehousing and data stores. That\u2019s literally it.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CCPA, GDPR and vendor supplied models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yji271", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667329872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just popped into my head as I reflect on our marketing team trying to pay a vendor a godawful amount of money for what the vendor literally labels, \u201coff the shelf machine learning models.\u201d The deal, we open the gates to let them exfiltrate data, they use it to train models, they then sell those modes back to us and our competition\u2026&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m realizing now is that there is absolutely no reasonable way they can uphold a delete request from our customers because it would require they retire the old modes, retrain in fresh data, and redeploy to all their other clients. &lt;/p&gt;\n\n&lt;p&gt;Similarly if there is a request for transparency about what data we have access to and what it\u2019s being used for, if our competition is using models trained on our customers data from our data stores, then who knows how the hell they might be using that\u2026&lt;/p&gt;\n\n&lt;p&gt;And for those curious, they are willing to give away our data assets because they don\u2019t want to wait for our internal teams to make them dashboards using our internal warehousing and data stores. That\u2019s literally it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yji271", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yji271/ccpa_gdpr_and_vendor_supplied_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yji271/ccpa_gdpr_and_vendor_supplied_models/", "subreddit_subscribers": 816831, "created_utc": 1667329872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/ykc7oc)", "author_fullname": "t2_cdlr4ijm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you that regularly share visualizations/communicate your results to business stakeholders.. what do you prefer to visualize data with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ykc7oc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667412086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/ykc7oc\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "ykc7oc", "is_robot_indexable": true, "report_reasons": null, "author": "Babbage224", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1667498486059, "options": [{"text": "Python (Matplotlib, seaborn, etc)", "id": "19554819"}, {"text": "R (ggplot2, plotly, etc.)", "id": "19554820"}, {"text": "Tableau", "id": "19554821"}, {"text": "PowerBI", "id": "19554822"}, {"text": "Excel", "id": "19554823"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 29, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykc7oc/for_those_of_you_that_regularly_share/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/ykc7oc/for_those_of_you_that_regularly_share/", "subreddit_subscribers": 816831, "created_utc": 1667412086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m open to any recommendations about data science talks/conferences/events worth going to (preferably on the west coast)!", "author_fullname": "t2_m0419", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which data science talks/conferences are worth going to?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ykbm3q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667410695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m open to any recommendations about data science talks/conferences/events worth going to (preferably on the west coast)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykbm3q", "is_robot_indexable": true, "report_reasons": null, "author": "jzasdf1212", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykbm3q/which_data_science_talksconferences_are_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykbm3q/which_data_science_talksconferences_are_worth/", "subreddit_subscribers": 816831, "created_utc": 1667410695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi I am actually studying a master degree in big data, and one teacher suggested we should by an additional keyboard and screen ( the screen already got it). My question is, if my laptop already has even the complete bloq num does still make sense to buy an additional keyboard? Thanks in advance", "author_fullname": "t2_6n2tqbeq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Additional keyboard as a Data Scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ykaeiz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667407936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am actually studying a master degree in big data, and one teacher suggested we should by an additional keyboard and screen ( the screen already got it). My question is, if my laptop already has even the complete bloq num does still make sense to buy an additional keyboard? Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykaeiz", "is_robot_indexable": true, "report_reasons": null, "author": "Estimate-Specialist", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykaeiz/additional_keyboard_as_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykaeiz/additional_keyboard_as_a_data_scientist/", "subreddit_subscribers": 816831, "created_utc": 1667407936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good news: **The submission deadline of** [**EvoMUSART 2023**](https://www.evostar.org/2023/evomusart/) **has been extended to November 16th!** \ud83d\ude4c\n\nYou still have time to submit your work to the 12th International Conference on Artificial Intelligence in Music, Sound, Art and Design (EvoMUSART).\n\nIf you work with Artificial Intelligence techniques applied to visual art, music, sound synthesis, architecture, video, poetry, design or other creative tasks, don't miss the opportunity to submit your work to EvoMUSART.\n\nEvoMUSART 2023 will be held in **Brno, Czech Republic**, between 12 and 14 April 2023. \ud83c\udde8\ud83c\uddff\n\nFor more information, visit the conference webpage: [https://www.evostar.org/2023/evomusart/](https://www.evostar.org/2023/evomusart/) \n\n&amp;#x200B;\n\nhttps://preview.redd.it/7hrjy2m7dkx91.png?width=2083&amp;format=png&amp;auto=webp&amp;s=b5a1e24303126d5d3eb25365c06e66f72a657989", "author_fullname": "t2_engq97zl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extended submission deadline \u2014 EvoMUSART 2023 conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7hrjy2m7dkx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=30294923e6c90cd7b02b8a18cb4cf3cacc27466f"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d5d715941d1e83d4b0af01ebed49c1c903bd832"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=810ee622d94b93830f6f95173af3aae4d12d33c3"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=78d3117918b9b6f2b8e2f0c5eceea5aa6f97b1c3"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=95d9b44922776a5065d11429cb11f834d9a2651f"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=960cac2e0cee98ca86706d4e31cb3237d7d31fad"}], "s": {"y": 1563, "x": 2083, "u": "https://preview.redd.it/7hrjy2m7dkx91.png?width=2083&amp;format=png&amp;auto=webp&amp;s=b5a1e24303126d5d3eb25365c06e66f72a657989"}, "id": "7hrjy2m7dkx91"}}, "name": "t3_yk9oby", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VNx3DyRsRzw_jXe2UzlkgaTIFgNtkbZ_Ff-FGWNUOgo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667406237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good news: &lt;strong&gt;The submission deadline of&lt;/strong&gt; &lt;a href=\"https://www.evostar.org/2023/evomusart/\"&gt;&lt;strong&gt;EvoMUSART 2023&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;has been extended to November 16th!&lt;/strong&gt; \ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;You still have time to submit your work to the 12th International Conference on Artificial Intelligence in Music, Sound, Art and Design (EvoMUSART).&lt;/p&gt;\n\n&lt;p&gt;If you work with Artificial Intelligence techniques applied to visual art, music, sound synthesis, architecture, video, poetry, design or other creative tasks, don&amp;#39;t miss the opportunity to submit your work to EvoMUSART.&lt;/p&gt;\n\n&lt;p&gt;EvoMUSART 2023 will be held in &lt;strong&gt;Brno, Czech Republic&lt;/strong&gt;, between 12 and 14 April 2023. \ud83c\udde8\ud83c\uddff&lt;/p&gt;\n\n&lt;p&gt;For more information, visit the conference webpage: &lt;a href=\"https://www.evostar.org/2023/evomusart/\"&gt;https://www.evostar.org/2023/evomusart/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7hrjy2m7dkx91.png?width=2083&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b5a1e24303126d5d3eb25365c06e66f72a657989\"&gt;https://preview.redd.it/7hrjy2m7dkx91.png?width=2083&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b5a1e24303126d5d3eb25365c06e66f72a657989&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk9oby", "is_robot_indexable": true, "report_reasons": null, "author": "evomusart_conference", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk9oby/extended_submission_deadline_evomusart_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk9oby/extended_submission_deadline_evomusart_2023/", "subreddit_subscribers": 816831, "created_utc": 1667406237.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}