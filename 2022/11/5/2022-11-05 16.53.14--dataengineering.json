{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cool ML Engineering diagram.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ymjubx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/R46WL4O-SxXLqPv9csUuZtH1s9udW0QVYbrV6q8gMhc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667621721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/77lc2zkhn3y91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/77lc2zkhn3y91.png?auto=webp&amp;s=9943349f8ce2aad65d17f819a243066e2f513b55", "width": 1080, "height": 1159}, "resolutions": [{"url": "https://preview.redd.it/77lc2zkhn3y91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e24c6ac3aa7c823d63db2ef76ade029f97f21ae", "width": 108, "height": 115}, {"url": "https://preview.redd.it/77lc2zkhn3y91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c5217070b9f2b5c7dc1b3df3a97ccbfdbb354dd4", "width": 216, "height": 231}, {"url": "https://preview.redd.it/77lc2zkhn3y91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1207b9de26362e1d48e3c2c50a3979c2620861b0", "width": 320, "height": 343}, {"url": "https://preview.redd.it/77lc2zkhn3y91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e5db11d6d76591018cd5d69dfc52dd2859a6453", "width": 640, "height": 686}, {"url": "https://preview.redd.it/77lc2zkhn3y91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b0c2bebc2b766813f1d7091108ce144265a7816a", "width": 960, "height": 1030}, {"url": "https://preview.redd.it/77lc2zkhn3y91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=197021d3c92c1308e15bf84071723e39ecbc39a8", "width": 1080, "height": 1159}], "variants": {}, "id": "UOxP6CxgiIHRO8bYMq6DqG90WFS48e8kQf7bfpU67LU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymjubx", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymjubx/cool_ml_engineering_diagram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/77lc2zkhn3y91.png", "subreddit_subscribers": 78987, "created_utc": 1667621721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Snowflake Architecture Overview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_ym47ac", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 81, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/yGXnh37_uGcE2kuS_FNHWYClXIyyKtAwwbAVfsKO530.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667581122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/snowflake-architecture", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?auto=webp&amp;s=8cf0c451337947e5197c9980f55034683b9b16b9", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e780c59f47c708f8dee670def7482bdd6d649802", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40336792cee0c641925209f0794ebb5cba7f4057", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=febd03fd9cd53a85bf8ab704acb70c6224087b2b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9f004a5d20cc564da854ddd555ac6e89bac02d5", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f689e9b4c383ec70ab60fb482977e9aa44d0fb7", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=553f3a2c6a205a75d743c5fb2ec490e975198688", "width": 1080, "height": 564}], "variants": {}, "id": "ZPdNCABw_PyJ7OjwDrehimG77P2Q-ZeCj5Nj9UZ8mCA"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ym47ac", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym47ac/snowflake_architecture_overview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/snowflake-architecture", "subreddit_subscribers": 78987, "created_utc": 1667581122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I've been a customer for ~ 4 years and loved their service / onboarding experience. My company uses Databricks on AWS.\n\nRecently, my team decided we needed to migrate to a [customer-managed VPC](https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html) deployment to accommodate other org wide architecture changes.\n\nOur prod and dev accounts were old and did not support this feature, so we had to create new ones. It turned out that this process was way more stressful than needed:\n\n- Their support is absolutely terrible. It took like 20 days just to confirm we needed to create a new account. \n\n- The new UI is sooooo buggy. I feel like I'm having a new issue every day.\n\nIs anyone having similar experiences? My company mostly uses Databricks to run infrequent Spark jobs, and we often think about trying out other features. The last few weeks, however, have made me really insecure about increasing our dependence on their products.", "author_fullname": "t2_h2eg6ehc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone having bad experiences with Databricks support / accounts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym6krd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667586755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a customer for ~ 4 years and loved their service / onboarding experience. My company uses Databricks on AWS.&lt;/p&gt;\n\n&lt;p&gt;Recently, my team decided we needed to migrate to a &lt;a href=\"https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html\"&gt;customer-managed VPC&lt;/a&gt; deployment to accommodate other org wide architecture changes.&lt;/p&gt;\n\n&lt;p&gt;Our prod and dev accounts were old and did not support this feature, so we had to create new ones. It turned out that this process was way more stressful than needed:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Their support is absolutely terrible. It took like 20 days just to confirm we needed to create a new account. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The new UI is sooooo buggy. I feel like I&amp;#39;m having a new issue every day.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is anyone having similar experiences? My company mostly uses Databricks to run infrequent Spark jobs, and we often think about trying out other features. The last few weeks, however, have made me really insecure about increasing our dependence on their products.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym6krd", "is_robot_indexable": true, "report_reasons": null, "author": "pid-1", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6krd/anyone_having_bad_experiences_with_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6krd/anyone_having_bad_experiences_with_databricks/", "subreddit_subscribers": 78987, "created_utc": 1667586755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone please educate me on why folks are talking about newer technologies like Snowflake etc are changing the game compared to cloud native solutions like Redshift, Azure Synapse etc?\n\nOr to ask in a different way, what am I gaining choosing a third party solution over What Azure, GCP and AWS already have running?", "author_fullname": "t2_arqcenpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the advantage of using Snowflake, DBT and/or Databricks over native cloud solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymfqvn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667609653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone please educate me on why folks are talking about newer technologies like Snowflake etc are changing the game compared to cloud native solutions like Redshift, Azure Synapse etc?&lt;/p&gt;\n\n&lt;p&gt;Or to ask in a different way, what am I gaining choosing a third party solution over What Azure, GCP and AWS already have running?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymfqvn", "is_robot_indexable": true, "report_reasons": null, "author": "AMadRam", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymfqvn/what_is_the_advantage_of_using_snowflake_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymfqvn/what_is_the_advantage_of_using_snowflake_dbt/", "subreddit_subscribers": 78987, "created_utc": 1667609653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI felt I just needed to get my words out into writing as it feels like a thousand thoughts are going through my head at the moment. For context, I have been with this organisation for just over 2 years now (18 months as D&amp;A Graduate, 10 months as a Data Engineer).\n\nI have been really enjoying my current role, having built production pipelines, assets, and even basically lead a Data Engineering sub-team for just over a month whilst the new DE lead onboarded and familiarised himself with internal processes. I know that when I'm properly in the zone (a bit corny), I can contribute greatly to key decisions like design / architecture and have that \"product\" mindset for Machine Learning use cases.\n\nI am now coming towards the end of support two ML use cases that are going into production, with work the naturally quietening down as we go into the December period. After coming out of the gym last night, I received a call from one of the DE leads who managed the team I was with in one of my placements during my graduate programme, telling me about this senior MLOps Engineer role and asking if I would consider applying for it.\n\nNow, I know I certainly wasn't the first choice given them have been trying to recruit these role for a while now with little success, however, to even be thought of for such a role I thought quite surprising. I told him that it would certainly be a role that I would be interested in given the experience I have had so far with these production use cases, and the thought process and decisions that need to be consider in order to actually productionise Machine Learning solutions for the business.\n\nI also think it would be a great time to join at this position as the team are very much at the early, early stages of their MLOps journey. So, I think it would be a great opportunity to be able to learn as I am doing it.\n\nHowever, and this is a big **however**, I have formally only been a Data Engineer for 10 months. I haven't had that much experience translating non-function business requirements into a design and implementation of a ML product. And my journey into cloud technologies has only just started.\n\nThis has just been a really ramble but I would love to see if anyone with more experience within the industry has thoughts to add to any of this?\n\n**Edit:** I also know that just because I'm because I'm being asked to consider applying, it does not guarantee that I will necessarily get the role.  ", "author_fullname": "t2_mf4javym", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Being asked to consider an internal Senior MLOps Engineer role within another team after just 10 months as a (Junior) Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym92xx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667593282.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667592767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I felt I just needed to get my words out into writing as it feels like a thousand thoughts are going through my head at the moment. For context, I have been with this organisation for just over 2 years now (18 months as D&amp;amp;A Graduate, 10 months as a Data Engineer).&lt;/p&gt;\n\n&lt;p&gt;I have been really enjoying my current role, having built production pipelines, assets, and even basically lead a Data Engineering sub-team for just over a month whilst the new DE lead onboarded and familiarised himself with internal processes. I know that when I&amp;#39;m properly in the zone (a bit corny), I can contribute greatly to key decisions like design / architecture and have that &amp;quot;product&amp;quot; mindset for Machine Learning use cases.&lt;/p&gt;\n\n&lt;p&gt;I am now coming towards the end of support two ML use cases that are going into production, with work the naturally quietening down as we go into the December period. After coming out of the gym last night, I received a call from one of the DE leads who managed the team I was with in one of my placements during my graduate programme, telling me about this senior MLOps Engineer role and asking if I would consider applying for it.&lt;/p&gt;\n\n&lt;p&gt;Now, I know I certainly wasn&amp;#39;t the first choice given them have been trying to recruit these role for a while now with little success, however, to even be thought of for such a role I thought quite surprising. I told him that it would certainly be a role that I would be interested in given the experience I have had so far with these production use cases, and the thought process and decisions that need to be consider in order to actually productionise Machine Learning solutions for the business.&lt;/p&gt;\n\n&lt;p&gt;I also think it would be a great time to join at this position as the team are very much at the early, early stages of their MLOps journey. So, I think it would be a great opportunity to be able to learn as I am doing it.&lt;/p&gt;\n\n&lt;p&gt;However, and this is a big &lt;strong&gt;however&lt;/strong&gt;, I have formally only been a Data Engineer for 10 months. I haven&amp;#39;t had that much experience translating non-function business requirements into a design and implementation of a ML product. And my journey into cloud technologies has only just started.&lt;/p&gt;\n\n&lt;p&gt;This has just been a really ramble but I would love to see if anyone with more experience within the industry has thoughts to add to any of this?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; I also know that just because I&amp;#39;m because I&amp;#39;m being asked to consider applying, it does not guarantee that I will necessarily get the role.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ym92xx", "is_robot_indexable": true, "report_reasons": null, "author": "Western-Opening-9212", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym92xx/being_asked_to_consider_an_internal_senior_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym92xx/being_asked_to_consider_an_internal_senior_mlops/", "subreddit_subscribers": 78987, "created_utc": 1667592767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL; DR;** Developing end-to-end data science infrastructure can get complex. So we wrote a three-part series of step-by-step tutorials to deploy a Data Science experimentation platform on AWS.\n\n\u2014\n\nHey everybody!\n\nDeveloping end-to-end data science infrastructure can get complex. For example, many of us might have struggled to try to integrate AWS services and deal with configuration, permissions, etc. At [Ploomber](https://ploomber.io/), we\u2019ve worked with many companies in a wide range of industries, such as energy, entertainment, computational chemistry, and genomics, so we are constantly looking for simple solutions to get them started with Data Science in the cloud.\n\nOne of the solutions that have worked best for many companies we\u2019ve worked for is AWS Batch, a service that allows you to execute computational jobs on-demand without managing a cluster. It\u2019s an excellent service for running Data Science and Machine Learning workloads. However, getting a good end-to-end experience is still challenging, so we wrote a detailed blog post series.\n\nhttps://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;format=png&amp;auto=webp&amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720\n\nWe are sharing this three-part series on deploying a Data Science Platform on AWS using our open-source software. By the end of the series, you\u2019ll be able to submit computational jobs to AWS scalable infrastructure with a single command.\n\nThe links:\n\n* [https://ploomber.io/blog/ds-platform-part-i](https://ploomber.io/blog/ds-platform-part-i) \\- Use AWS Batch and test the infrastructure by executing a task in a container\n* [https://ploomber.io/blog/ds-platform-part-ii](https://ploomber.io/blog/ds-platform-part-ii) \\- Configure Amazon ECR to push a Docker image to AWS and configure an S3 bucket to write the output of Data Science experiments.\n* [https://ploomber.io/blog/ds-platform-part-iii](https://ploomber.io/blog/ds-platform-part-iii) \\- Use Ploomber and Soopervisor (our open-source software) to run experiments in parallel and request resources dynamically (CPUs, RAM, and GPUs).\n\nAWS Batch strikes a good balance between ease of use and functionality. However, we\u2019ve learned a few things to optimize it (for example, to reduce container startup time), so we might add a fourth part to the series.\n\nIf you\u2019ve previously used AWS Batch, please share your experience. We\u2019d love to learn from you!\n\nPlease share your suggestions, ideas, and comments in general, as we want to build tools and solutions to make Data Science more accessible for everybody.", "author_fullname": "t2_8fgjjia7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A three-part series on deploying a Data Science Platform on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"j7qs8hrpbzx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=16998f22da2f7f0b986a863417b836c1494c50df"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3114d58f6712e4db055d5d8a6a3f119fa6dc19c"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=481405712c9b7ffc47aca6d17693f02aa0241922"}, {"y": 410, "x": 640, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b3fa0ced8fe2c908e2d0171cf15e2d93c14f828"}], "s": {"y": 512, "x": 798, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;format=png&amp;auto=webp&amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720"}, "id": "j7qs8hrpbzx91"}}, "name": "t3_ym6tk9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL; DR;&lt;/strong&gt; Developing end-to-end data science infrastructure can get complex. So we wrote a three-part series of step-by-step tutorials to deploy a Data Science experimentation platform on AWS.&lt;/p&gt;\n\n&lt;p&gt;\u2014&lt;/p&gt;\n\n&lt;p&gt;Hey everybody!&lt;/p&gt;\n\n&lt;p&gt;Developing end-to-end data science infrastructure can get complex. For example, many of us might have struggled to try to integrate AWS services and deal with configuration, permissions, etc. At &lt;a href=\"https://ploomber.io/\"&gt;Ploomber&lt;/a&gt;, we\u2019ve worked with many companies in a wide range of industries, such as energy, entertainment, computational chemistry, and genomics, so we are constantly looking for simple solutions to get them started with Data Science in the cloud.&lt;/p&gt;\n\n&lt;p&gt;One of the solutions that have worked best for many companies we\u2019ve worked for is AWS Batch, a service that allows you to execute computational jobs on-demand without managing a cluster. It\u2019s an excellent service for running Data Science and Machine Learning workloads. However, getting a good end-to-end experience is still challenging, so we wrote a detailed blog post series.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720\"&gt;https://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We are sharing this three-part series on deploying a Data Science Platform on AWS using our open-source software. By the end of the series, you\u2019ll be able to submit computational jobs to AWS scalable infrastructure with a single command.&lt;/p&gt;\n\n&lt;p&gt;The links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://ploomber.io/blog/ds-platform-part-i\"&gt;https://ploomber.io/blog/ds-platform-part-i&lt;/a&gt; - Use AWS Batch and test the infrastructure by executing a task in a container&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://ploomber.io/blog/ds-platform-part-ii\"&gt;https://ploomber.io/blog/ds-platform-part-ii&lt;/a&gt; - Configure Amazon ECR to push a Docker image to AWS and configure an S3 bucket to write the output of Data Science experiments.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://ploomber.io/blog/ds-platform-part-iii\"&gt;https://ploomber.io/blog/ds-platform-part-iii&lt;/a&gt; - Use Ploomber and Soopervisor (our open-source software) to run experiments in parallel and request resources dynamically (CPUs, RAM, and GPUs).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;AWS Batch strikes a good balance between ease of use and functionality. However, we\u2019ve learned a few things to optimize it (for example, to reduce container startup time), so we might add a fourth part to the series.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019ve previously used AWS Batch, please share your experience. We\u2019d love to learn from you!&lt;/p&gt;\n\n&lt;p&gt;Please share your suggestions, ideas, and comments in general, as we want to build tools and solutions to make Data Science more accessible for everybody.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ym6tk9", "is_robot_indexable": true, "report_reasons": null, "author": "fractalfox11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6tk9/a_threepart_series_on_deploying_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6tk9/a_threepart_series_on_deploying_a_data_science/", "subreddit_subscribers": 78987, "created_utc": 1667587347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I\u2019m looking for learning resources to create CI/CD processes for our Azure Databricks and GitHub repo. Is GitHub Actions the answer? Any recommendations or help is appreciated.", "author_fullname": "t2_a0qsnkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD with Databricks and GitHub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymr04r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667646735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I\u2019m looking for learning resources to create CI/CD processes for our Azure Databricks and GitHub repo. Is GitHub Actions the answer? Any recommendations or help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymr04r", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Membership-8", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymr04r/cicd_with_databricks_and_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymr04r/cicd_with_databricks_and_github/", "subreddit_subscribers": 78987, "created_utc": 1667646735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm moving some data from MongoDB to Snowflake, and I wanted to know what experienced data engineers would do when they build this ETL.\n\n**Option 1:** Write ETL in pure Python using `pymongo` and `sqlalchemy` without dependency on Airflow operators, such as `MongoToS3Operator` and `SnowflakeOperator` (except `PythonOperator` to call the final script). Once Python script is built, I can use Airflow only to call the ETL script. For me, the biggest appeal to this approach is that I can run this ETL line by line if I wanted to.\n\n**Option 2:** Write ETL using Airflow operators, such as `MongoToS3Operator` and `SnowflakeOperator`. Provided that I have access to a S3 bucket, I can use `MongoToS3Operator` to move data from MongoDB to S3, then use `SnowflakeOperator` to move data from S3 to Snowflake. This allows data transfer from MongoDB to Snowflake using only two Airflow operators.\n\nI personally prefer `Option 1` because I like being able to execute code line by line to see what's happening each step of the way. But `Option 2` may be more modern and elegant. Maybe I'm missing something about `Option 2`?", "author_fullname": "t2_ers4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving data from MongoDB to Snowflake using Apache Airflow: Would you use pure Python or use Airflow operators?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym6pjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667587344.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving some data from MongoDB to Snowflake, and I wanted to know what experienced data engineers would do when they build this ETL.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Write ETL in pure Python using &lt;code&gt;pymongo&lt;/code&gt; and &lt;code&gt;sqlalchemy&lt;/code&gt; without dependency on Airflow operators, such as &lt;code&gt;MongoToS3Operator&lt;/code&gt; and &lt;code&gt;SnowflakeOperator&lt;/code&gt; (except &lt;code&gt;PythonOperator&lt;/code&gt; to call the final script). Once Python script is built, I can use Airflow only to call the ETL script. For me, the biggest appeal to this approach is that I can run this ETL line by line if I wanted to.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; Write ETL using Airflow operators, such as &lt;code&gt;MongoToS3Operator&lt;/code&gt; and &lt;code&gt;SnowflakeOperator&lt;/code&gt;. Provided that I have access to a S3 bucket, I can use &lt;code&gt;MongoToS3Operator&lt;/code&gt; to move data from MongoDB to S3, then use &lt;code&gt;SnowflakeOperator&lt;/code&gt; to move data from S3 to Snowflake. This allows data transfer from MongoDB to Snowflake using only two Airflow operators.&lt;/p&gt;\n\n&lt;p&gt;I personally prefer &lt;code&gt;Option 1&lt;/code&gt; because I like being able to execute code line by line to see what&amp;#39;s happening each step of the way. But &lt;code&gt;Option 2&lt;/code&gt; may be more modern and elegant. Maybe I&amp;#39;m missing something about &lt;code&gt;Option 2&lt;/code&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym6pjw", "is_robot_indexable": true, "report_reasons": null, "author": "feelosophy13", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6pjw/moving_data_from_mongodb_to_snowflake_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6pjw/moving_data_from_mongodb_to_snowflake_using/", "subreddit_subscribers": 78987, "created_utc": 1667587080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \nI'm a very junior data scientist and I recently accepted a job at a new startup as a \"data guy\" - mostly data science, but as the startup is still small I will have to do some/a lot of data engineering too.\n\nThe whole data process is still very embryonic, and the tech stack is not well defined yet. They say they will value my word in this regard, but it's not like I know what a good data process looks like. \n\n I have disclosed that I have little experience in data engineering tasks (in everything, really), but I'm eager to learn and generally learn quickly - which is true. I already learned a lot on my own. They appreciated my attitude, character and background and wanted me on their team. I am willing to work my ass off, as I truly care about the product and would love to contribute in a significant way. However, the lack of a big team full of seniors scare me a bit. So I have come here for advices.\n\nDo you have any suggestion to nail this, or do a good enough job, or even not make a total mess? What to learn, what to focus on, what not to do,  general advices, so on and so forth?", "author_fullname": "t2_ck5meno7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will have some data engineering tasks at new job and I don't want to f this up. Advices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymb34i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1667633625.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667597516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, \nI&amp;#39;m a very junior data scientist and I recently accepted a job at a new startup as a &amp;quot;data guy&amp;quot; - mostly data science, but as the startup is still small I will have to do some/a lot of data engineering too.&lt;/p&gt;\n\n&lt;p&gt;The whole data process is still very embryonic, and the tech stack is not well defined yet. They say they will value my word in this regard, but it&amp;#39;s not like I know what a good data process looks like. &lt;/p&gt;\n\n&lt;p&gt;I have disclosed that I have little experience in data engineering tasks (in everything, really), but I&amp;#39;m eager to learn and generally learn quickly - which is true. I already learned a lot on my own. They appreciated my attitude, character and background and wanted me on their team. I am willing to work my ass off, as I truly care about the product and would love to contribute in a significant way. However, the lack of a big team full of seniors scare me a bit. So I have come here for advices.&lt;/p&gt;\n\n&lt;p&gt;Do you have any suggestion to nail this, or do a good enough job, or even not make a total mess? What to learn, what to focus on, what not to do,  general advices, so on and so forth?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ymb34i", "is_robot_indexable": true, "report_reasons": null, "author": "kiwibutterket", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymb34i/will_have_some_data_engineering_tasks_at_new_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymb34i/will_have_some_data_engineering_tasks_at_new_job/", "subreddit_subscribers": 78987, "created_utc": 1667597516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a working professional and want to get the certification in 7 days \nHoping that's reasonable.\n\nI have no cloud experience but have completed the virtual 5 day training", "author_fullname": "t2_f836ym4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what's the best roadmap for DP-900 after completing Microsoft training? Thinking of taking runes YouTube course or what else ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymt58v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667652892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a working professional and want to get the certification in 7 days \nHoping that&amp;#39;s reasonable.&lt;/p&gt;\n\n&lt;p&gt;I have no cloud experience but have completed the virtual 5 day training&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ymt58v", "is_robot_indexable": true, "report_reasons": null, "author": "Aggravating_Wind8365", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymt58v/whats_the_best_roadmap_for_dp900_after_completing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymt58v/whats_the_best_roadmap_for_dp900_after_completing/", "subreddit_subscribers": 78987, "created_utc": 1667652892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I specially want to hear from those who have used other tool like airflow, fivetran etc. Why do you like and dislike about adf?", "author_fullname": "t2_gpjiv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you guys think of azure data factory?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymlx7q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667628671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I specially want to hear from those who have used other tool like airflow, fivetran etc. Why do you like and dislike about adf?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymlx7q", "is_robot_indexable": true, "report_reasons": null, "author": "HBoogi", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymlx7q/what_do_you_guys_think_of_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymlx7q/what_do_you_guys_think_of_azure_data_factory/", "subreddit_subscribers": 78987, "created_utc": 1667628671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope to land a DE position in the future (1-2 years)\n\n* Is this a good start in terms of skill building?\n* Where should I focus energy in (personal projects/course work)?\n\nAny additional advice would be appreciated as well.\n\nThank y'all for the help. I've been lurking for about 6 months now; excellent community\n\nhttps://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;format=png&amp;auto=webp&amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9", "author_fullname": "t2_b3q17xix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Critique", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3tiegxo6dzx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f01739e67b03951e665615c96abd638d69a7d56"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5acd58c2f7fc66315918e5a8d0fea85a9facfea2"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcb526cdf06c50627cd0d46cbad9573d16c4b09b"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aab00e7488d0da4cc766bfe178a20ab97d3c079e"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=05a91b798f7d7f9ed7bdbe6afa8bb6551d7edb47"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17709b3867108f9c1667828d24ce175c1ad4c9f1"}], "s": {"y": 1584, "x": 1224, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;format=png&amp;auto=webp&amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9"}, "id": "3tiegxo6dzx91"}}, "name": "t3_ym6zei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3sMGi_a7jSPF-0MqyPREceP5NDpFwgIhMvLDes3cBf0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope to land a DE position in the future (1-2 years)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is this a good start in terms of skill building?&lt;/li&gt;\n&lt;li&gt;Where should I focus energy in (personal projects/course work)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any additional advice would be appreciated as well.&lt;/p&gt;\n\n&lt;p&gt;Thank y&amp;#39;all for the help. I&amp;#39;ve been lurking for about 6 months now; excellent community&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9\"&gt;https://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ym6zei", "is_robot_indexable": true, "report_reasons": null, "author": "MintLeafSpice", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6zei/resume_critique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6zei/resume_critique/", "subreddit_subscribers": 78987, "created_utc": 1667587754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have requirement to build SCD TYPE 2 table in delta lake, It's monthly load and columns do change in each refresh. We cannot have static columns. Any one have idea how can we implement without unpivoting the columns which would cause redundant data?", "author_fullname": "t2_g06clmjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement SCD Type 2 table with ever changing columns in each load?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymmf09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667630440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have requirement to build SCD TYPE 2 table in delta lake, It&amp;#39;s monthly load and columns do change in each refresh. We cannot have static columns. Any one have idea how can we implement without unpivoting the columns which would cause redundant data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ymmf09", "is_robot_indexable": true, "report_reasons": null, "author": "Junior_Abies_2213", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymmf09/how_to_implement_scd_type_2_table_with_ever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymmf09/how_to_implement_scd_type_2_table_with_ever/", "subreddit_subscribers": 78987, "created_utc": 1667630440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I want to know how to run a Python script that is hosted outside the Airflow env.\nI have airflow installed on WSL and my script is in the local system. So how can I achieve this? \nI want in the future to run Airflow on a server and that every user can schedule it's tasks using the server but running on their own computer. \nIdk if I'm explaining well..\n\nThanks in advance!", "author_fullname": "t2_5xg75zcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to run scripts outside wsl using airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yml7qn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667626264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I want to know how to run a Python script that is hosted outside the Airflow env.\nI have airflow installed on WSL and my script is in the local system. So how can I achieve this? \nI want in the future to run Airflow on a server and that every user can schedule it&amp;#39;s tasks using the server but running on their own computer. \nIdk if I&amp;#39;m explaining well..&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yml7qn", "is_robot_indexable": true, "report_reasons": null, "author": "aisakee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yml7qn/how_to_run_scripts_outside_wsl_using_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yml7qn/how_to_run_scripts_outside_wsl_using_airflow/", "subreddit_subscribers": 78987, "created_utc": 1667626264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nWe need to pull files (containing unstructured (plain text or html) or semi structured data (xml)) from an API on routine basis for stock market symbols and store the symbol + file data. The file data would then be used by data scientists for variety of things such as sentiment analysis etc.\n\nI need suggestions on how to persist this data efficiently and I am thinking of two options:\n\n\\- Store everything in Snowflake tables.. say with two columns (SYMBOL, TRANSCRIPT) and have data scientists use this table for their processing\n\n\\- Store the file in external staging area (S3 in this case) in a delimited format with compression.. say a CSV file with two columns SYMBOL, TRANSCRIPT.. And then have the data scientists query it directly from external stage for further processing.\n\nI am inclined to to choose second option (storing in S3) as it might cost effective, but having everything in Snowflake seems more convenient option as it eliminates external cloud dependencies.  Also I believe some of the traditional SQL functions don't work while querying data from external staging. So second option also has that limitation, but the data can always be moved in to temp tables for processing if needed.\n\nI would to get this sub's thoughts on this. Any other options apart from these two are welcome too.\n\nthanks.", "author_fullname": "t2_jfqnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing unstructured/semi structured data in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym5997", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667583905.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667583644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;We need to pull files (containing unstructured (plain text or html) or semi structured data (xml)) from an API on routine basis for stock market symbols and store the symbol + file data. The file data would then be used by data scientists for variety of things such as sentiment analysis etc.&lt;/p&gt;\n\n&lt;p&gt;I need suggestions on how to persist this data efficiently and I am thinking of two options:&lt;/p&gt;\n\n&lt;p&gt;- Store everything in Snowflake tables.. say with two columns (SYMBOL, TRANSCRIPT) and have data scientists use this table for their processing&lt;/p&gt;\n\n&lt;p&gt;- Store the file in external staging area (S3 in this case) in a delimited format with compression.. say a CSV file with two columns SYMBOL, TRANSCRIPT.. And then have the data scientists query it directly from external stage for further processing.&lt;/p&gt;\n\n&lt;p&gt;I am inclined to to choose second option (storing in S3) as it might cost effective, but having everything in Snowflake seems more convenient option as it eliminates external cloud dependencies.  Also I believe some of the traditional SQL functions don&amp;#39;t work while querying data from external staging. So second option also has that limitation, but the data can always be moved in to temp tables for processing if needed.&lt;/p&gt;\n\n&lt;p&gt;I would to get this sub&amp;#39;s thoughts on this. Any other options apart from these two are welcome too.&lt;/p&gt;\n\n&lt;p&gt;thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym5997", "is_robot_indexable": true, "report_reasons": null, "author": "curidpostn", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym5997/storing_unstructuredsemi_structured_data_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym5997/storing_unstructuredsemi_structured_data_in/", "subreddit_subscribers": 78987, "created_utc": 1667583644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently got my first role as a jr. data scientist. We're currently trying to move from housing our data on Google Sheets to SQL. However, I don't really don't know where to start in terms of implementation and data modelling? Any resources you'd recommend? In addition, are there any SQL servers (like PG Admin or Oracle) that are totally free or reasonably priced? And how do I go about comparing the functionality?", "author_fullname": "t2_17sa96g9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from GSheets to SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymi5gm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667616520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently got my first role as a jr. data scientist. We&amp;#39;re currently trying to move from housing our data on Google Sheets to SQL. However, I don&amp;#39;t really don&amp;#39;t know where to start in terms of implementation and data modelling? Any resources you&amp;#39;d recommend? In addition, are there any SQL servers (like PG Admin or Oracle) that are totally free or reasonably priced? And how do I go about comparing the functionality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ymi5gm", "is_robot_indexable": true, "report_reasons": null, "author": "LeasTEXH01", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymi5gm/transitioning_from_gsheets_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymi5gm/transitioning_from_gsheets_to_sql/", "subreddit_subscribers": 78987, "created_utc": 1667616520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\n  Has anyone taken a coding test in Byteboard? How are the questions..is it like Leetcode easy? \n\nThanks\n\nMR", "author_fullname": "t2_gp13ce3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Byteboard interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymags1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667596024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Has anyone taken a coding test in Byteboard? How are the questions..is it like Leetcode easy? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;MR&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ymags1", "is_robot_indexable": true, "report_reasons": null, "author": "meridian_12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymags1/byteboard_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymags1/byteboard_interview/", "subreddit_subscribers": 78987, "created_utc": 1667596024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nSo for a personal project, i have a script that pulls data from an api and ports it into snowflake. I want to visualize this data somehow and was curious to know what the best options are. snowflake does have a dashboards section, but are there better options that would make this stand out and/or something industry would really like to see?\n\n&amp;#x200B;\n\nThanks in advance!\n\n&amp;#x200B;\n\nedit: thanks guys for your responses!", "author_fullname": "t2_120yfzjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data in snowflake , how to visualize", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym6cw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667611585.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667586241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;So for a personal project, i have a script that pulls data from an api and ports it into snowflake. I want to visualize this data somehow and was curious to know what the best options are. snowflake does have a dashboards section, but are there better options that would make this stand out and/or something industry would really like to see?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit: thanks guys for your responses!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ym6cw3", "is_robot_indexable": true, "report_reasons": null, "author": "jin_liang", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6cw3/data_in_snowflake_how_to_visualize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6cw3/data_in_snowflake_how_to_visualize/", "subreddit_subscribers": 78987, "created_utc": 1667586241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working as a data engineer in a non-tech company. My day to day work involves fetching data from various internal sources like API, Data warehouse, Data lake, operational tables to name a few. After fetching the data, I transform it according to the business requirements and load it to whatever target the end users want it in. Finally, the data scientists create the dashboard as per end user requirements using the data from my target destination. \n\nJust to be clear, I have not been criticized, warned or questioned about my work. However, I just want to start demonstrating the value of my work to business users. It seems like the folks who create the final dashboard on my data find it relatively easier to show the value of their work to end business users.", "author_fullname": "t2_t6oufyru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to increase my visibility to business users as a data engineer? It seems like the final dashboard creators have a higher visibility and find it relatively easier to show the value of their work to end buisness users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymuxae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667657182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working as a data engineer in a non-tech company. My day to day work involves fetching data from various internal sources like API, Data warehouse, Data lake, operational tables to name a few. After fetching the data, I transform it according to the business requirements and load it to whatever target the end users want it in. Finally, the data scientists create the dashboard as per end user requirements using the data from my target destination. &lt;/p&gt;\n\n&lt;p&gt;Just to be clear, I have not been criticized, warned or questioned about my work. However, I just want to start demonstrating the value of my work to business users. It seems like the folks who create the final dashboard on my data find it relatively easier to show the value of their work to end business users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ymuxae", "is_robot_indexable": true, "report_reasons": null, "author": "MatchCaseFirst", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymuxae/how_to_increase_my_visibility_to_business_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymuxae/how_to_increase_my_visibility_to_business_users/", "subreddit_subscribers": 78987, "created_utc": 1667657182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have hosted Apache superset on Azure web app for PoC purpose \n\nIf you are using it in your company , where you are hosting it for production\n\nVirtual Machine ? Kubernetes ? Preset ?", "author_fullname": "t2_dgq3lsfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Superset hosting platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymtt2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667654581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have hosted Apache superset on Azure web app for PoC purpose &lt;/p&gt;\n\n&lt;p&gt;If you are using it in your company , where you are hosting it for production&lt;/p&gt;\n\n&lt;p&gt;Virtual Machine ? Kubernetes ? Preset ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ymtt2v", "is_robot_indexable": true, "report_reasons": null, "author": "authentichooman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymtt2v/apache_superset_hosting_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymtt2v/apache_superset_hosting_platform/", "subreddit_subscribers": 78987, "created_utc": 1667654581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am currently implementing an ingestion pipeline where the full data flow is:\n\n* Data is extracted from MySQL using Debezium and stored to Kafka (1 topic per database schema, we have \\~3000 schemas divided in \\~100 servers, different table schemas are stored in the confluent schema registry)\n* Data is fetched from kafka using a Spark Structured streaming application running N concurrent streaming queries where N is the number of database schemas inside the mysql server.\n* Data is both stored AS-IS - append to delta table - and upserted to a delta table to create a SCD2 table (custom logic inside `forEachBatch` is used, the batch `DataFrame` is cached before running all the operations)\n\nI have two questions:\n\n* Is there any open source project attempting to do the same that can be used as a reference implementation?\n* I am witnessing a strange phenomenon: In the Spark UI, it is shown that the time to process a batch is \\~35-40 seconds, but in reality if I look at the log messages I'm seeing that 3 minutes pass between the processing of two batches - during this time executors are completely idle. What could be causing this information inconsistency? I'll also add that there is a trigger set to ProcessingTime 60 seconds, so lower than those 3 minutes wait time. ", "author_fullname": "t2_3dhhvh7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka to Spark Streaming + Delta ingestion pipeline, weird slowdowns and reference implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymn4ok", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667633491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667633039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am currently implementing an ingestion pipeline where the full data flow is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data is extracted from MySQL using Debezium and stored to Kafka (1 topic per database schema, we have ~3000 schemas divided in ~100 servers, different table schemas are stored in the confluent schema registry)&lt;/li&gt;\n&lt;li&gt;Data is fetched from kafka using a Spark Structured streaming application running N concurrent streaming queries where N is the number of database schemas inside the mysql server.&lt;/li&gt;\n&lt;li&gt;Data is both stored AS-IS - append to delta table - and upserted to a delta table to create a SCD2 table (custom logic inside &lt;code&gt;forEachBatch&lt;/code&gt; is used, the batch &lt;code&gt;DataFrame&lt;/code&gt; is cached before running all the operations)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have two questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is there any open source project attempting to do the same that can be used as a reference implementation?&lt;/li&gt;\n&lt;li&gt;I am witnessing a strange phenomenon: In the Spark UI, it is shown that the time to process a batch is ~35-40 seconds, but in reality if I look at the log messages I&amp;#39;m seeing that 3 minutes pass between the processing of two batches - during this time executors are completely idle. What could be causing this information inconsistency? I&amp;#39;ll also add that there is a trigger set to ProcessingTime 60 seconds, so lower than those 3 minutes wait time. &lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6 YoE | Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ymn4ok", "is_robot_indexable": true, "report_reasons": null, "author": "vektor888", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ymn4ok/kafka_to_spark_streaming_delta_ingestion_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymn4ok/kafka_to_spark_streaming_delta_ingestion_pipeline/", "subreddit_subscribers": 78987, "created_utc": 1667633039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: \"Jack of all trades data engineer\" wondering if my situation is typical or abnormal. and inquiring if anybody has been in a similar situation as me and where you went/or would go from here. \n\nI've been working as a Senior Data Engineer (in title) for a non-profit organization for the last year with a very lean data team, bringing 10 years experience as a data analyst  -&gt; data scientist -&gt; azure data engineer, in that order.  I got hired to be their main azure guy and modernize their data ingestion pipelines, but ended up taking on much more upon hire deliberately.\n\nIn the last year, I've architected and built out a delta lake implementation for their ingestion processes, built their CI/CD pipelines and put everything in source control, became their cloud administrator and set up a completely new multi-subscription model with established naming conventions, tightened their roles/access policies, and put Azure policies in place to enforce resource consistency/uniformity/governance. Basically straightened up their entire absolute hell of a messy azure environment. \n\nI'm essentially their data engineer, data architect, devops engineer, and cloud administrator. Is this the norm for most data engineers out there?! I've gained a diverse amount of experience in a short time, and I love being a jack of all trades. The problem that i'm now facing is taking my experience to another company where I can take on another jack of all trades role and be compensated for it. Most roles I've interviewed for lately want to fit me into a square peg and have me \"choose one\". I'm making 135k in a mid cost of living city, but shooting for 167-208 which I've gathered is a reasonable range from recruiters I've spoken with. Consulting seems like the next logical choice, or a start up. Just wondering if anybody has been in a similar spot and where they went from here.", "author_fullname": "t2_5k5sp0q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next steps for jack of all trades azure data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym91uv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667592703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: &amp;quot;Jack of all trades data engineer&amp;quot; wondering if my situation is typical or abnormal. and inquiring if anybody has been in a similar situation as me and where you went/or would go from here. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a Senior Data Engineer (in title) for a non-profit organization for the last year with a very lean data team, bringing 10 years experience as a data analyst  -&amp;gt; data scientist -&amp;gt; azure data engineer, in that order.  I got hired to be their main azure guy and modernize their data ingestion pipelines, but ended up taking on much more upon hire deliberately.&lt;/p&gt;\n\n&lt;p&gt;In the last year, I&amp;#39;ve architected and built out a delta lake implementation for their ingestion processes, built their CI/CD pipelines and put everything in source control, became their cloud administrator and set up a completely new multi-subscription model with established naming conventions, tightened their roles/access policies, and put Azure policies in place to enforce resource consistency/uniformity/governance. Basically straightened up their entire absolute hell of a messy azure environment. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m essentially their data engineer, data architect, devops engineer, and cloud administrator. Is this the norm for most data engineers out there?! I&amp;#39;ve gained a diverse amount of experience in a short time, and I love being a jack of all trades. The problem that i&amp;#39;m now facing is taking my experience to another company where I can take on another jack of all trades role and be compensated for it. Most roles I&amp;#39;ve interviewed for lately want to fit me into a square peg and have me &amp;quot;choose one&amp;quot;. I&amp;#39;m making 135k in a mid cost of living city, but shooting for 167-208 which I&amp;#39;ve gathered is a reasonable range from recruiters I&amp;#39;ve spoken with. Consulting seems like the next logical choice, or a start up. Just wondering if anybody has been in a similar spot and where they went from here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ym91uv", "is_robot_indexable": true, "report_reasons": null, "author": "Nebula_369", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym91uv/next_steps_for_jack_of_all_trades_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym91uv/next_steps_for_jack_of_all_trades_azure_data/", "subreddit_subscribers": 78987, "created_utc": 1667592703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Databricks noob question here.\n\nWe have delta tables created via Databricks job and stored in an S3 bucket. Now we want to allow users in a Databricks workspace to read this delta table. What would be the \"proper\" way to do that, in order to optimize performances?\n\nCurrently, we use mount points to provide access to the table under dbfs/mnt. Should we instead import the table in the workspace catalog by CREATE TABLE AS &lt;table&gt; LOCATION s3:/&lt;s3_path&gt; and then possibly run optimize zorder to reduce query time for specific queries? Or are there other approaches?", "author_fullname": "t2_zlyww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making Delta tables available in Databricks Workspace", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym579k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667583509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Databricks noob question here.&lt;/p&gt;\n\n&lt;p&gt;We have delta tables created via Databricks job and stored in an S3 bucket. Now we want to allow users in a Databricks workspace to read this delta table. What would be the &amp;quot;proper&amp;quot; way to do that, in order to optimize performances?&lt;/p&gt;\n\n&lt;p&gt;Currently, we use mount points to provide access to the table under dbfs/mnt. Should we instead import the table in the workspace catalog by CREATE TABLE AS &amp;lt;table&amp;gt; LOCATION s3:/&amp;lt;s3_path&amp;gt; and then possibly run optimize zorder to reduce query time for specific queries? Or are there other approaches?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ym579k", "is_robot_indexable": true, "report_reasons": null, "author": "francesco1093", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym579k/making_delta_tables_available_in_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym579k/making_delta_tables_available_in_databricks/", "subreddit_subscribers": 78987, "created_utc": 1667583509.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}