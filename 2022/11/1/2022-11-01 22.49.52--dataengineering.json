{"kind": "Listing", "data": {"after": "t3_yiw4mu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the UI? Python scripts that call the databricks API? Terraform? Where do you store your definitions?\n\nI'm trying to understand if I'm better off defining DAGs and dependencies in something like airflow and just using that to trigger jobs. Even so I would still have to define the databricks jobs somewhere.", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how/where do you define your databricks jobs, tasks and workflows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yja3wj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667312795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the UI? Python scripts that call the databricks API? Terraform? Where do you store your definitions?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to understand if I&amp;#39;m better off defining DAGs and dependencies in something like airflow and just using that to trigger jobs. Even so I would still have to define the databricks jobs somewhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yja3wj", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yja3wj/howwhere_do_you_define_your_databricks_jobs_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yja3wj/howwhere_do_you_define_your_databricks_jobs_tasks/", "subreddit_subscribers": 78577, "created_utc": 1667312795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Came in as a junior and my time has been good but also rocky. I've learnt a lot but still require help from engineers to basic stuff. Next month will be my 6 month probation period ending. My manager has indirectly hinted that if I don't improve I'll be let go.\n\nWhat options do I have? Will other companies take me on if I'm let go? I'm gonna try pass probation of course, but I'd like to get a few ideas.\n\nThanks!", "author_fullname": "t2_81mnb4wb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do I do if I don't pass probation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yja59m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667312889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Came in as a junior and my time has been good but also rocky. I&amp;#39;ve learnt a lot but still require help from engineers to basic stuff. Next month will be my 6 month probation period ending. My manager has indirectly hinted that if I don&amp;#39;t improve I&amp;#39;ll be let go.&lt;/p&gt;\n\n&lt;p&gt;What options do I have? Will other companies take me on if I&amp;#39;m let go? I&amp;#39;m gonna try pass probation of course, but I&amp;#39;d like to get a few ideas.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yja59m", "is_robot_indexable": true, "report_reasons": null, "author": "Taurusamazing92", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yja59m/what_do_i_do_if_i_dont_pass_probation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yja59m/what_do_i_do_if_i_dont_pass_probation/", "subreddit_subscribers": 78577, "created_utc": 1667312889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Undergrad computer science student here, I just want to ask for some suggestions, it is for my capstone project i want my project to be related to data engineering/science/ai/ml because i want my capstone project to be unique, most of the projects i saw is all about web/application development and im not into that field, any suggestions please?\n\nP.s. please notify me if this kind of post is against the community rules. Thank you in advance", "author_fullname": "t2_i8exxe4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj13oe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667285772.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667284740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Undergrad computer science student here, I just want to ask for some suggestions, it is for my capstone project i want my project to be related to data engineering/science/ai/ml because i want my capstone project to be unique, most of the projects i saw is all about web/application development and im not into that field, any suggestions please?&lt;/p&gt;\n\n&lt;p&gt;P.s. please notify me if this kind of post is against the community rules. Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yj13oe", "is_robot_indexable": true, "report_reasons": null, "author": "Initial-Routine4506", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj13oe/suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj13oe/suggestions/", "subreddit_subscribers": 78577, "created_utc": 1667284740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join Trino Summit to hear engineers from Apple, Lyft, Shopify, Zillow, Goldman Sachs and much more talk about modern data virtualization with Trino", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_yjf5ep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/inudxb403Mm72WoCFAOC6uRj2NRM8pS9ehEk95R43_4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667324003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "trino.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://trino.io/blog/2022/10/31/trino-summit-2022-teaser-3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e0nSjQ4cxsBG9WGCTFG4EujWU1Yg8rbgaZ9ZmKNQcOU.jpg?auto=webp&amp;s=5daee15fd239d4d74bafc601a208131764506863", "width": 522, "height": 351}, "resolutions": [{"url": "https://external-preview.redd.it/e0nSjQ4cxsBG9WGCTFG4EujWU1Yg8rbgaZ9ZmKNQcOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0806449c02646894889be1f0481d64b2040ffb12", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/e0nSjQ4cxsBG9WGCTFG4EujWU1Yg8rbgaZ9ZmKNQcOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=199520633e806c86e4bd557e2443c2d14ef97c7e", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/e0nSjQ4cxsBG9WGCTFG4EujWU1Yg8rbgaZ9ZmKNQcOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1135a77eeeb17a0e756e0f177d0e66d129ed49c0", "width": 320, "height": 215}], "variants": {}, "id": "6_MKHeLQ6GYYLvzYgTGERsziEzb26hQ1Y72PrI1IBzQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yjf5ep", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjf5ep/join_trino_summit_to_hear_engineers_from_apple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://trino.io/blog/2022/10/31/trino-summit-2022-teaser-3", "subreddit_subscribers": 78577, "created_utc": 1667324003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nSo I am a bi analyst, do a lot of data architecturing, SQL based ELT and front end visualization. However, i try to branch out an learn new skills like cloud related skills, DBT and obviously python.\nPython seems like a endless pit to me tho and I don't really have usecases at work so I created some scripts over the last months and I feel like I could do this for years and still \"learn\" (which is not bad, I am just wondering how much I should invest before moving on to other skills). I also watched some pep8 and Styleguide videos as to learn proper coding ways and work with git.\nThings I did:\n- Webscrapping, cleaning and saving data to a DB.(pandas, sqlalchemy, pyodbc, beaoutifulsoup)\n\n- Basic apis, cleaning and saving data to a DB.\n(Requests, pandas)\n\n- Using all Json files in a directory, convert and flat them to CSVs. Merge Csvs based on a specific logic.\n\n- Compare product names based on their name likeliness and give similar products the same name.\n\nI would be interested by your input:)", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much python is enough for a beginner?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj42av", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667295061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;So I am a bi analyst, do a lot of data architecturing, SQL based ELT and front end visualization. However, i try to branch out an learn new skills like cloud related skills, DBT and obviously python.\nPython seems like a endless pit to me tho and I don&amp;#39;t really have usecases at work so I created some scripts over the last months and I feel like I could do this for years and still &amp;quot;learn&amp;quot; (which is not bad, I am just wondering how much I should invest before moving on to other skills). I also watched some pep8 and Styleguide videos as to learn proper coding ways and work with git.\nThings I did:\n- Webscrapping, cleaning and saving data to a DB.(pandas, sqlalchemy, pyodbc, beaoutifulsoup)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Basic apis, cleaning and saving data to a DB.\n(Requests, pandas)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Using all Json files in a directory, convert and flat them to CSVs. Merge Csvs based on a specific logic.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Compare product names based on their name likeliness and give similar products the same name.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would be interested by your input:)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yj42av", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj42av/how_much_python_is_enough_for_a_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj42av/how_much_python_is_enough_for_a_beginner/", "subreddit_subscribers": 78577, "created_utc": 1667295061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Know the differences between the two approaches, their distinct applications, and case studies that provide testimony to the company\u2019s success in data management across different domains and industries. Find out more about solutions for resolving dirty data issues through data verification and data validation. \n\nhttps://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;format=pjpg&amp;auto=webp&amp;s=019a8481ade8826fdf06aba1393338ab372840b0", "author_fullname": "t2_t9j61kdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Verification and Data Validation: The Differences and Why You Need It", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"egtua8b28bx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01698d29420423a4f428d14057ca29188b1ef7de"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4bfc1d8aa3c51712c8ebd2a31dd513dd4199248c"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e37d2f4961c101d128458c78c13d35d252fa3330"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c3e2b0020b84408d8f4341d31ba76fd9fde728e"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=45aa9a681ec56cfcf257eecfa00cb871113dec5d"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dac5fd85cca0e0ca4a972556076aa7bc09779dfc"}], "s": {"y": 4246, "x": 1240, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;format=pjpg&amp;auto=webp&amp;s=019a8481ade8826fdf06aba1393338ab372840b0"}, "id": "egtua8b28bx91"}}, "name": "t3_yj47k7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9FcC9D-wH_Qg8KrSMbbgBLxcsv9Xi54_CQaTclBSl9k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667295586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Know the differences between the two approaches, their distinct applications, and case studies that provide testimony to the company\u2019s success in data management across different domains and industries. Find out more about solutions for resolving dirty data issues through data verification and data validation. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=019a8481ade8826fdf06aba1393338ab372840b0\"&gt;https://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=019a8481ade8826fdf06aba1393338ab372840b0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yj47k7", "is_robot_indexable": true, "report_reasons": null, "author": "snehal-joshi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj47k7/data_verification_and_data_validation_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj47k7/data_verification_and_data_validation_the/", "subreddit_subscribers": 78577, "created_utc": 1667295586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Really interested in the usage of data and management APIs for connecting data teams and application ecosystems and wanted to see what others experience / need in this area.  The title should be pretty explanatory but happy to clarify.", "author_fullname": "t2_25rk1snv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those that are building APIs around your data practice, what would you say are the most important capabilities and who are your typical consumers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjk55l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667334103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Really interested in the usage of data and management APIs for connecting data teams and application ecosystems and wanted to see what others experience / need in this area.  The title should be pretty explanatory but happy to clarify.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yjk55l", "is_robot_indexable": true, "report_reasons": null, "author": "awebb78", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjk55l/to_those_that_are_building_apis_around_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjk55l/to_those_that_are_building_apis_around_your_data/", "subreddit_subscribers": 78577, "created_utc": 1667334103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had a few question on dataframes on spark. So from what I've read I think that there are three dataframes that can be used on there:\n\n* **Pandas dataframes**: These are dataframes that can be used with the Pandas library. They can't take advantage of the Spark's distributed computing.\n\n* **Spark Pandas dataframes**: These dataframes are similar and have someoverlap to the dataframes from the Pandas library. But they don't have 100% compatibility. They can however take advantage of Spark's distributed computing.\n\n* **Spark dataframes**: These dataframes are different from the Pandas dataframes. Some advantages are that they can be created from more sources than other dataframes and perhaps have other performance improvements.\n\nSo based on what I've read, should you only use the Spark dataframes when using Spark? And if so, in what cases should you alternate between the pandas and non-Pandas dataframes? Should you use the Pandas dataframes if you want to keep strong compatibility with the Pandas library? Are their other reasons to use one over the other?\n\nThanks!", "author_fullname": "t2_4zpyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataframes on spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjcccm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667318105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had a few question on dataframes on spark. So from what I&amp;#39;ve read I think that there are three dataframes that can be used on there:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pandas dataframes&lt;/strong&gt;: These are dataframes that can be used with the Pandas library. They can&amp;#39;t take advantage of the Spark&amp;#39;s distributed computing.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Spark Pandas dataframes&lt;/strong&gt;: These dataframes are similar and have someoverlap to the dataframes from the Pandas library. But they don&amp;#39;t have 100% compatibility. They can however take advantage of Spark&amp;#39;s distributed computing.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Spark dataframes&lt;/strong&gt;: These dataframes are different from the Pandas dataframes. Some advantages are that they can be created from more sources than other dataframes and perhaps have other performance improvements.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So based on what I&amp;#39;ve read, should you only use the Spark dataframes when using Spark? And if so, in what cases should you alternate between the pandas and non-Pandas dataframes? Should you use the Pandas dataframes if you want to keep strong compatibility with the Pandas library? Are their other reasons to use one over the other?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yjcccm", "is_robot_indexable": true, "report_reasons": null, "author": "beyphy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjcccm/dataframes_on_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjcccm/dataframes_on_spark/", "subreddit_subscribers": 78577, "created_utc": 1667318105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Description\n\n\\- How to run multiple ExternalPythonOperator (I need different packages / versions for different DAG tasks) after each other in serial without being dependent on the previous task's success \"upstream\\_fail\".\n\n\\- So it should just execute task after each other without caring about if any of them fails or succeeds.\n\n\\- You might ask than why not just create separate DAG files. The point of this is that I want to run a couple of extremely resource intense task after each other in a very much separate time period than any other tasks to make sure that they don't cause any disruption. They also have to be separated from each other because each one could disrupts each other just based on resource constrains both on the server and for other external reasons as well.\n\n&amp;#x200B;\n\n# My Code\n\n    import logging\n    import os\n    import shutil\n    import sys\n    import tempfile\n    import time\n    from pprint import pprint\n    \n    import pendulum\n    \n    from airflow import DAG\n    from airflow.decorators import task\n    \n    log = logging.getLogger(__name__)\n    PYTHON = sys.executable\n    BASE_DIR = tempfile.gettempdir()\n    \n    \n    my_default_args = {\n        'owner': 'me',\n        #'email': ['myemail@myemail.com'],\n        'email_on_failure': True,\n        #'email_on_retry': True,\n        #'retries': 1,\n    #     'retry_delay': timedelta(minutes=1)\n    }\n    \n    \n    with DAG(\n        dag_id='some_dag_id_comes_here',\n        schedule='1 * * * *', \n        start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"), # this is from whre it starts counting time to run taks, NOT like cron\n        catchup=False,\n        default_args=my_default_args,\n        tags=['xyz1'],\n        ) as dag:\n        u/task.external_python(task_id=\"task1\", python='/opt/airflow/my_env/bin/python3')\n        def func1(): \n            print('elements of task 1')\n            time.sleep(10)\n    \n        u/task.external_python(task_id=\"task2\", python='/opt/airflow/my_env/bin/python3')\n        def func2(): \n            print('elements of task 2')\n            time.sleep(10)\n    \n    \n        task1 &gt;&gt; task2", "author_fullname": "t2_qrm5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[AIRFLOW] - How to Trigger a DAG by another DAG, regardless of the success of a previous DAG in Airflow using Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yis4o5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667301190.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667258285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Description&lt;/h1&gt;\n\n&lt;p&gt;- How to run multiple ExternalPythonOperator (I need different packages / versions for different DAG tasks) after each other in serial without being dependent on the previous task&amp;#39;s success &amp;quot;upstream_fail&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;- So it should just execute task after each other without caring about if any of them fails or succeeds.&lt;/p&gt;\n\n&lt;p&gt;- You might ask than why not just create separate DAG files. The point of this is that I want to run a couple of extremely resource intense task after each other in a very much separate time period than any other tasks to make sure that they don&amp;#39;t cause any disruption. They also have to be separated from each other because each one could disrupts each other just based on resource constrains both on the server and for other external reasons as well.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;My Code&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;import logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport time\nfrom pprint import pprint\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\n\nlog = logging.getLogger(__name__)\nPYTHON = sys.executable\nBASE_DIR = tempfile.gettempdir()\n\n\nmy_default_args = {\n    &amp;#39;owner&amp;#39;: &amp;#39;me&amp;#39;,\n    #&amp;#39;email&amp;#39;: [&amp;#39;myemail@myemail.com&amp;#39;],\n    &amp;#39;email_on_failure&amp;#39;: True,\n    #&amp;#39;email_on_retry&amp;#39;: True,\n    #&amp;#39;retries&amp;#39;: 1,\n#     &amp;#39;retry_delay&amp;#39;: timedelta(minutes=1)\n}\n\n\nwith DAG(\n    dag_id=&amp;#39;some_dag_id_comes_here&amp;#39;,\n    schedule=&amp;#39;1 * * * *&amp;#39;, \n    start_date=pendulum.datetime(2021, 1, 1, tz=&amp;quot;UTC&amp;quot;), # this is from whre it starts counting time to run taks, NOT like cron\n    catchup=False,\n    default_args=my_default_args,\n    tags=[&amp;#39;xyz1&amp;#39;],\n    ) as dag:\n    u/task.external_python(task_id=&amp;quot;task1&amp;quot;, python=&amp;#39;/opt/airflow/my_env/bin/python3&amp;#39;)\n    def func1(): \n        print(&amp;#39;elements of task 1&amp;#39;)\n        time.sleep(10)\n\n    u/task.external_python(task_id=&amp;quot;task2&amp;quot;, python=&amp;#39;/opt/airflow/my_env/bin/python3&amp;#39;)\n    def func2(): \n        print(&amp;#39;elements of task 2&amp;#39;)\n        time.sleep(10)\n\n\n    task1 &amp;gt;&amp;gt; task2\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yis4o5", "is_robot_indexable": true, "report_reasons": null, "author": "glassAlloy", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yis4o5/airflow_how_to_trigger_a_dag_by_another_dag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yis4o5/airflow_how_to_trigger_a_dag_by_another_dag/", "subreddit_subscribers": 78577, "created_utc": 1667258285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is debating this as a possibility for our new framework. One of my coworkers thinks that\u2019s impossible but my other coworker has said she was able to do so effectively with her previous team. \n\nWhat are the pros and cons of having a snapshot and what are the pros and cons of not having a snapshot?\n\nOr does having a snapshot make little to no difference for deployment?", "author_fullname": "t2_ce84fkjd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you do a deployment for a framework in Jenkins without a snapshot? What are the pros and cons of doing so?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjc9m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667317946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is debating this as a possibility for our new framework. One of my coworkers thinks that\u2019s impossible but my other coworker has said she was able to do so effectively with her previous team. &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of having a snapshot and what are the pros and cons of not having a snapshot?&lt;/p&gt;\n\n&lt;p&gt;Or does having a snapshot make little to no difference for deployment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yjc9m7", "is_robot_indexable": true, "report_reasons": null, "author": "Unique_Glove1105", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjc9m7/can_you_do_a_deployment_for_a_framework_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjc9m7/can_you_do_a_deployment_for_a_framework_in/", "subreddit_subscribers": 78577, "created_utc": 1667317946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling out ELT workloads with CSV and stateless workers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yjaulo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GETuQdKluM6TeyaACVljvBjxnFzPzAhrD3IWzaf32KU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667314688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/scaling-out-elt-with-cq-and-csv", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?auto=webp&amp;s=ead95c6a370db7389385182aa845917d4e3ce318", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9fae2998fa23b3846d766b007e2e37cff443c862", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ad9fab6cf064c87fcb404e0381d9622d18cbe64f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe5c8f5bc719b70f5701fd794e353c55eb0a8043", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f86173948328dced9e0524b59bda7aaafcbc9854", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e0952b6e581d2d84ad3fc5f45e36abadf2ec62ab", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/KI0oX9wILAfZzbjyFyU85HL5yFrcDXMXZQOa0___O7M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d431513fd545956b78ea12ad7d310d40e999222", "width": 1080, "height": 565}], "variants": {}, "id": "Ba76dC3MEp0ZLM2qEUvifwxnYletdSniW83D-cN32Hk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yjaulo", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjaulo/scaling_out_elt_workloads_with_csv_and_stateless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/scaling-out-elt-with-cq-and-csv", "subreddit_subscribers": 78577, "created_utc": 1667314688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are folk's workflows for deleting or hashing a row or data in an S3 external table?   \n\n\nCurrently I'm thinking the only way to do this is to copy the entire table and transform that row, and then replace the entire table with that new copy of the table. However, that seems extremely inefficient. If there are multiple deletes, we might even need to batch that process up. It also needs to not conflict with new writes on that table.   \n\n\nDoes anyone else have any suggestions on this?", "author_fullname": "t2_5hx4y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deleting particular data from S3 External Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yizqco", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667280233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are folk&amp;#39;s workflows for deleting or hashing a row or data in an S3 external table?   &lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m thinking the only way to do this is to copy the entire table and transform that row, and then replace the entire table with that new copy of the table. However, that seems extremely inefficient. If there are multiple deletes, we might even need to batch that process up. It also needs to not conflict with new writes on that table.   &lt;/p&gt;\n\n&lt;p&gt;Does anyone else have any suggestions on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yizqco", "is_robot_indexable": true, "report_reasons": null, "author": "ShanghaiBebop", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yizqco/deleting_particular_data_from_s3_external_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yizqco/deleting_particular_data_from_s3_external_tables/", "subreddit_subscribers": 78577, "created_utc": 1667280233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently preparing for the Databricks Spark Associate Developer in PySpark. And one thing I'm noticing during my practise tests is that I always get stuck during the questions that ask about passing columns into a method. Even with the documentation available during the exam, I'm almost always choosing the wrong option.\n\nCan someone please help me with the difference between the below two ways of passing columns into a method and how to recognize the separation in the documentation:\n\n* method_name(col(\"colName1\"), col(\"colName2\") .. col(\"colNameN\"))\n\nvs\n\n* method_name(\"colName1\", \"colName2\", \"colName2\")\n\nAre these two types of argument passing not interchangeable? Both of them do work in a SELECT statement. So, my mind keeps thinking they work everywhere. How do I recognize this difference from the documentation?", "author_fullname": "t2_w64oyiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I always get confused between: col(\"colName\") and \"colName\" when passing them into a method. Please help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yix2zw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667272016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently preparing for the Databricks Spark Associate Developer in PySpark. And one thing I&amp;#39;m noticing during my practise tests is that I always get stuck during the questions that ask about passing columns into a method. Even with the documentation available during the exam, I&amp;#39;m almost always choosing the wrong option.&lt;/p&gt;\n\n&lt;p&gt;Can someone please help me with the difference between the below two ways of passing columns into a method and how to recognize the separation in the documentation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;method_name(col(&amp;quot;colName1&amp;quot;), col(&amp;quot;colName2&amp;quot;) .. col(&amp;quot;colNameN&amp;quot;))&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;vs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;method_name(&amp;quot;colName1&amp;quot;, &amp;quot;colName2&amp;quot;, &amp;quot;colName2&amp;quot;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are these two types of argument passing not interchangeable? Both of them do work in a SELECT statement. So, my mind keeps thinking they work everywhere. How do I recognize this difference from the documentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yix2zw", "is_robot_indexable": true, "report_reasons": null, "author": "thebestnobody", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yix2zw/i_always_get_confused_between_colcolname_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yix2zw/i_always_get_confused_between_colcolname_and/", "subreddit_subscribers": 78577, "created_utc": 1667272016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! \n\nI have absolutely 0 experience with JSON conversion. I work in the medical field and starting soon all insurance providers are required to post their fee schedule data. Because of this, they have made it extremely difficult to view their data. I have tried every basic conversion tactic, including Gigasheet and many more, but nothing seems to work. The link to the file is [https://www.bluecrossnc.com/about-us/policies-and-best-practices/transparency-coverage-mrf](https://www.bluecrossnc.com/about-us/policies-and-best-practices/transparency-coverage-mrf) and under the \"Non-ASO Groups\" there is a link that will download a 3.4 GB file. Any and all help would be very much appreciated for the medical practice I work for so thank you in advance for any advice.", "author_fullname": "t2_3ezxthj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HUGE JSON File Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjhp9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667329155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;I have absolutely 0 experience with JSON conversion. I work in the medical field and starting soon all insurance providers are required to post their fee schedule data. Because of this, they have made it extremely difficult to view their data. I have tried every basic conversion tactic, including Gigasheet and many more, but nothing seems to work. The link to the file is &lt;a href=\"https://www.bluecrossnc.com/about-us/policies-and-best-practices/transparency-coverage-mrf\"&gt;https://www.bluecrossnc.com/about-us/policies-and-best-practices/transparency-coverage-mrf&lt;/a&gt; and under the &amp;quot;Non-ASO Groups&amp;quot; there is a link that will download a 3.4 GB file. Any and all help would be very much appreciated for the medical practice I work for so thank you in advance for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yjhp9t", "is_robot_indexable": true, "report_reasons": null, "author": "toothierlake8", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjhp9t/huge_json_file_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjhp9t/huge_json_file_help/", "subreddit_subscribers": 78577, "created_utc": 1667329155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I usually try to stay abreast of changes in the labor markets, etc. I dunno if it's just me but I've seen \n\n* a slow down of job opportunities from LinkedIn,\n* a decrease in remote work, increase in hybrid \n* an increase of direct-to-my-inbox opportunities (which I try to avoid),\n* an increase in spam/calls\n* and most important  a decrease in the compensation packages\n\nI was just approached by a major financial institution for a principal data architect position - 100k for 10+ years of xp. I feel like six months ago I was at least getting higher quality opportunities. \n\nIs anyone else seeing this? What are your experiences? Any tips to get mitigate past this noise and get higher quality opportunities?\n\nEdit sorry on mobile", "author_fullname": "t2_7lvmv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are wages depressed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjgw42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667327720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667327516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I usually try to stay abreast of changes in the labor markets, etc. I dunno if it&amp;#39;s just me but I&amp;#39;ve seen &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a slow down of job opportunities from LinkedIn,&lt;/li&gt;\n&lt;li&gt;a decrease in remote work, increase in hybrid &lt;/li&gt;\n&lt;li&gt;an increase of direct-to-my-inbox opportunities (which I try to avoid),&lt;/li&gt;\n&lt;li&gt;an increase in spam/calls&lt;/li&gt;\n&lt;li&gt;and most important  a decrease in the compensation packages&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I was just approached by a major financial institution for a principal data architect position - 100k for 10+ years of xp. I feel like six months ago I was at least getting higher quality opportunities. &lt;/p&gt;\n\n&lt;p&gt;Is anyone else seeing this? What are your experiences? Any tips to get mitigate past this noise and get higher quality opportunities?&lt;/p&gt;\n\n&lt;p&gt;Edit sorry on mobile&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yjgw42", "is_robot_indexable": true, "report_reasons": null, "author": "claytonjr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjgw42/are_wages_depressed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjgw42/are_wages_depressed/", "subreddit_subscribers": 78577, "created_utc": 1667327516.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We all know about data quality checks and testing, but what are some best practices for code checks and deployments? Especially when you're running them on cloud using tools like Airflow where you share the same environment.", "author_fullname": "t2_elfguhp3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code deployments and testing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjed7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667322359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We all know about data quality checks and testing, but what are some best practices for code checks and deployments? Especially when you&amp;#39;re running them on cloud using tools like Airflow where you share the same environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yjed7j", "is_robot_indexable": true, "report_reasons": null, "author": "Long-Summer-Song", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjed7j/code_deployments_and_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjed7j/code_deployments_and_testing/", "subreddit_subscribers": 78577, "created_utc": 1667322359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thinking explicitly parsing the event data via. JSON key for fields that I want and capturing the measurements - one row per event. Assuming the raw json is accessible in the warehouse for future schema changes.", "author_fullname": "t2_15x3m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to transform JSON payloads into fact tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yium8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667265007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking explicitly parsing the event data via. JSON key for fields that I want and capturing the measurements - one row per event. Assuming the raw json is accessible in the warehouse for future schema changes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yium8p", "is_robot_indexable": true, "report_reasons": null, "author": "pewpscoops", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yium8p/best_way_to_transform_json_payloads_into_fact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yium8p/best_way_to_transform_json_payloads_into_fact/", "subreddit_subscribers": 78577, "created_utc": 1667265007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is docker a viable solution if you wanted to create a data warehouse on a clients environment that simply ETLs data from their on premise SQL Server (EHR for physician practice) into the docker container. This would make deployment for us such a breeze because all the settings can be configured in the docker file or docker compose YAML. \n\nI mean the container can just be kept running on whatever server or VM they are using and ideally there will be no or minimal down time. Service accounts will be created to do the maintenance task on the database. This isn't some massive Data warehouse we are taking about here btw. 10 TB tops in size and probably only users by a few dozen users are once.\n\nWe are really just looking for the easiest and quickest way to get a server running on their infrastructure that we can have the admin rights to since it's containerized it won't impact any of their other DB servers. \n\nAnyone have any feedback on this and why it's a good/bad idea ?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker for production Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjlnl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667337418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is docker a viable solution if you wanted to create a data warehouse on a clients environment that simply ETLs data from their on premise SQL Server (EHR for physician practice) into the docker container. This would make deployment for us such a breeze because all the settings can be configured in the docker file or docker compose YAML. &lt;/p&gt;\n\n&lt;p&gt;I mean the container can just be kept running on whatever server or VM they are using and ideally there will be no or minimal down time. Service accounts will be created to do the maintenance task on the database. This isn&amp;#39;t some massive Data warehouse we are taking about here btw. 10 TB tops in size and probably only users by a few dozen users are once.&lt;/p&gt;\n\n&lt;p&gt;We are really just looking for the easiest and quickest way to get a server running on their infrastructure that we can have the admin rights to since it&amp;#39;s containerized it won&amp;#39;t impact any of their other DB servers. &lt;/p&gt;\n\n&lt;p&gt;Anyone have any feedback on this and why it&amp;#39;s a good/bad idea ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yjlnl0", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjlnl0/docker_for_production_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjlnl0/docker_for_production_data_warehouse/", "subreddit_subscribers": 78577, "created_utc": 1667337418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I thought some of you may be interested in learning about a new free NLP data debugging tool my team just launched. \n\nWould love to hear what you think. We've had a lot of great feedback from NLP practitioners who found new insights into their production models. We are wondering what space to dive into next and would love some feedback.\n\nIt's called \"Galileo community.\" If you want to jump right in here is our page-\u00a0[https://www.rungalileo.io/](https://www.rungalileo.io/)\n\nWe have a Demo Hour event coming up on November 15th where you can follow along with our demo and learn how to debug data using a popular public dataset across training and production models.\n\nHere's what we will go through:\n\n\\- Identifying mislabeled data\n\n\\- Discovering data clusters that your model struggles with\u00a0\n\n\\- Detecting data drift between training and production models", "author_fullname": "t2_suo3oqc2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML data engineers - looking for feedback- would you find this instant data debugging tool useful (NLP only right now) - not open source but close it's free", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjgyqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667327661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I thought some of you may be interested in learning about a new free NLP data debugging tool my team just launched. &lt;/p&gt;\n\n&lt;p&gt;Would love to hear what you think. We&amp;#39;ve had a lot of great feedback from NLP practitioners who found new insights into their production models. We are wondering what space to dive into next and would love some feedback.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s called &amp;quot;Galileo community.&amp;quot; If you want to jump right in here is our page-\u00a0&lt;a href=\"https://www.rungalileo.io/\"&gt;https://www.rungalileo.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We have a Demo Hour event coming up on November 15th where you can follow along with our demo and learn how to debug data using a popular public dataset across training and production models.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what we will go through:&lt;/p&gt;\n\n&lt;p&gt;- Identifying mislabeled data&lt;/p&gt;\n\n&lt;p&gt;- Discovering data clusters that your model struggles with\u00a0&lt;/p&gt;\n\n&lt;p&gt;- Detecting data drift between training and production models&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?auto=webp&amp;s=26956c8b76e306196be26dac6823316965a158ea", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73269dc606de5748903cd3071efede94320d5585", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a5e66ec2c49815714fc050f925a36c0368a35bfa", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=357894c50d401bab88714325dc49e6f7072077a8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d83e0275c7b5f4d9044e73ed1a6ccbd7720cb2d9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ab42fc8e54fe4faa605f2d2530e3dcf77e96ec29", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/OvAvYt-9O4E8SG0cb9GwnFeWXhDuT09nP9n4TQqu6Oc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=201cd2665acbc077a1068aa20d060c4d3bacc150", "width": 1080, "height": 567}], "variants": {}, "id": "1XpG-0UrU7Ob0cGebmo1JzRM33GYm1mPqhZ2xFvJBEs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yjgyqj", "is_robot_indexable": true, "report_reasons": null, "author": "Diana_Galileo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjgyqj/ml_data_engineers_looking_for_feedback_would_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjgyqj/ml_data_engineers_looking_for_feedback_would_you/", "subreddit_subscribers": 78577, "created_utc": 1667327661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll try to keep this short:\n\n- I have 3 yrs experience as a data analyst\n- got an interview for a position \u201cassociate analytics engineer\u201d via recruiter at a company that I met when I interviewed for a different position at the company\n- analytics engineer salary at this company is $110k according to glassdoor\n- obviously an associate level position will pay less than that, but can anyone give insight to about how much less?\n\nJust don\u2019t want to overshoot or undershoot my ask, and googling salaries show me a huge range so I\u2019m really unsure. TIA!", "author_fullname": "t2_smy52e8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary expectations for analytics engineer in Los Angeles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjdzrk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667321565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll try to keep this short:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have 3 yrs experience as a data analyst&lt;/li&gt;\n&lt;li&gt;got an interview for a position \u201cassociate analytics engineer\u201d via recruiter at a company that I met when I interviewed for a different position at the company&lt;/li&gt;\n&lt;li&gt;analytics engineer salary at this company is $110k according to glassdoor&lt;/li&gt;\n&lt;li&gt;obviously an associate level position will pay less than that, but can anyone give insight to about how much less?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Just don\u2019t want to overshoot or undershoot my ask, and googling salaries show me a huge range so I\u2019m really unsure. TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yjdzrk", "is_robot_indexable": true, "report_reasons": null, "author": "emilythebus", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjdzrk/salary_expectations_for_analytics_engineer_in_los/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjdzrk/salary_expectations_for_analytics_engineer_in_los/", "subreddit_subscribers": 78577, "created_utc": 1667321565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1667318411.68, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjchhi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667318411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yjchhi", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjchhi/monthly_general_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/yjchhi/monthly_general_discussion/", "subreddit_subscribers": 78577, "created_utc": 1667318411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am mid 30s, and have worked as data warehouse engineer in the past using ETL tools for like 10 years. I made a career switch to move into business side and I hate it. I want to move back into the tech side. I would really help any feedback or advice you can give me.\n\nInterview prep so far:  \n1. Leetcode problems, and can solve easy/medium questions and difficult SQL problems.  \n2. ETL, Batch, Streaming data platform interview questions  \n3. Working knowledge of S3, Redshift  \n4. AWS Cloud fundamentals and knowledge of services  \n5. Kimball design principles\n\nI have a very limited hands on experience(Know the use case and basic principles) on:  \n1. Airflow  \n2. Spark  \n3. Lambda/Dockers/EMR etc.", "author_fullname": "t2_6lp7aig4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance mid life career and interview prep - please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjblkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667316482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am mid 30s, and have worked as data warehouse engineer in the past using ETL tools for like 10 years. I made a career switch to move into business side and I hate it. I want to move back into the tech side. I would really help any feedback or advice you can give me.&lt;/p&gt;\n\n&lt;p&gt;Interview prep so far:&lt;br/&gt;\n1. Leetcode problems, and can solve easy/medium questions and difficult SQL problems.&lt;br/&gt;\n2. ETL, Batch, Streaming data platform interview questions&lt;br/&gt;\n3. Working knowledge of S3, Redshift&lt;br/&gt;\n4. AWS Cloud fundamentals and knowledge of services&lt;br/&gt;\n5. Kimball design principles&lt;/p&gt;\n\n&lt;p&gt;I have a very limited hands on experience(Know the use case and basic principles) on:&lt;br/&gt;\n1. Airflow&lt;br/&gt;\n2. Spark&lt;br/&gt;\n3. Lambda/Dockers/EMR etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yjblkj", "is_robot_indexable": true, "report_reasons": null, "author": "ask_can", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yjblkj/guidance_mid_life_career_and_interview_prep_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yjblkj/guidance_mid_life_career_and_interview_prep_please/", "subreddit_subscribers": 78577, "created_utc": 1667316482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discover The New Way of Scheduling your DAGs in Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yj9ks1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/kPI2mPs-eQA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"The New Way of Scheduling DAGs in Airflow with Datasets\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The New Way of Scheduling DAGs in Airflow with Datasets", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/kPI2mPs-eQA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"The New Way of Scheduling DAGs in Airflow with Datasets\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/kPI2mPs-eQA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/kPI2mPs-eQA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"The New Way of Scheduling DAGs in Airflow with Datasets\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yj9ks1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fVakOE7qb2QZ6NY4QQJ2broiaLEqYAtMc1vOk3SfIPk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667311482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/kPI2mPs-eQA", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Il2vbKbiXvEPIPHKa8P5JS1UL-6UDpTXJz-KyiZM65U.jpg?auto=webp&amp;s=ebeb43ac2850c713c2085cf91106b8cc32db184c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Il2vbKbiXvEPIPHKa8P5JS1UL-6UDpTXJz-KyiZM65U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f918a0d2f9765052b970ad03cd62b429218f1c0", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Il2vbKbiXvEPIPHKa8P5JS1UL-6UDpTXJz-KyiZM65U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7da2deb6dc2b629e34a54ada8a3f7e7e9908759c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Il2vbKbiXvEPIPHKa8P5JS1UL-6UDpTXJz-KyiZM65U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19ab99811d10886fb16844e4347955797714f6ec", "width": 320, "height": 240}], "variants": {}, "id": "XPj1iviMZsknKBB_7LNX1FOFUam8I_hf8mtu0Z3bewo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yj9ks1", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj9ks1/discover_the_new_way_of_scheduling_your_dags_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/kPI2mPs-eQA", "subreddit_subscribers": 78577, "created_utc": 1667311482.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The New Way of Scheduling DAGs in Airflow with Datasets", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/kPI2mPs-eQA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"The New Way of Scheduling DAGs in Airflow with Datasets\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/kPI2mPs-eQA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:\n\n1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.\n\n2) Download the mp3 and metadata (date, title, etc.) for the podcast.\n\n3) Process audio using something like WisperAI.\n\n4) Store the data for analytics.\n\n**I'm wondering if anyone has recommendations for the above, specifically steps 1 and 2?** For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?\n\nThanks so much for any assistance here!", "author_fullname": "t2_10ctkxdy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast Audio &amp; Metadata Scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj7fps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667305757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:&lt;/p&gt;\n\n&lt;p&gt;1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.&lt;/p&gt;\n\n&lt;p&gt;2) Download the mp3 and metadata (date, title, etc.) for the podcast.&lt;/p&gt;\n\n&lt;p&gt;3) Process audio using something like WisperAI.&lt;/p&gt;\n\n&lt;p&gt;4) Store the data for analytics.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m wondering if anyone has recommendations for the above, specifically steps 1 and 2?&lt;/strong&gt; For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for any assistance here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yj7fps", "is_robot_indexable": true, "report_reasons": null, "author": "beige_coffee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj7fps/podcast_audio_metadata_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj7fps/podcast_audio_metadata_scraping/", "subreddit_subscribers": 78577, "created_utc": 1667305757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys any software like [https://datakubes.com/platform](https://datakubes.com/platform/) this? this is like a crud builder it uses php, it connect tru mysql, sql, have docker, etc. Any chance theres something else or alike in the market today?\n\nthank you", "author_fullname": "t2_reu1hc9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any builder like this https://datakubes.com/platform/ ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiw4mu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667269246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys any software like &lt;a href=\"https://datakubes.com/platform/\"&gt;https://datakubes.com/platform&lt;/a&gt; this? this is like a crud builder it uses php, it connect tru mysql, sql, have docker, etc. Any chance theres something else or alike in the market today?&lt;/p&gt;\n\n&lt;p&gt;thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Lu5h7_J4gT1o9h-xJ8ct1n5E19lLVyk0YlJXUkCjR2g.jpg?auto=webp&amp;s=e2887533810fc342b8c96e60f9b797e4584b128b", "width": 104, "height": 112}, "resolutions": [], "variants": {}, "id": "ngXrA2kHe4B0PBrXh3zt19r-S85EQedqV7osen_wHxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yiw4mu", "is_robot_indexable": true, "report_reasons": null, "author": "agaitan026", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yiw4mu/any_builder_like_this_httpsdatakubescomplatform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yiw4mu/any_builder_like_this_httpsdatakubescomplatform/", "subreddit_subscribers": 78577, "created_utc": 1667269246.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}