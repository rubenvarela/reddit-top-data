{"kind": "Listing", "data": {"after": "t3_yj9mj8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nI am working on an algorithm to predict cross sell opportunities. To do so I am evaluating the three models in the title. To do so I plan to do cross fold validation to pick the best model. My question is if during each fold do I need to hyper parameter tune the model? Or do I do that after I pick the best one?", "author_fullname": "t2_zivdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logistic Regression v Random Forest v XGBoost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj9u1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667312124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I am working on an algorithm to predict cross sell opportunities. To do so I am evaluating the three models in the title. To do so I plan to do cross fold validation to pick the best model. My question is if during each fold do I need to hyper parameter tune the model? Or do I do that after I pick the best one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj9u1l", "is_robot_indexable": true, "report_reasons": null, "author": "Meclimax", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj9u1l/logistic_regression_v_random_forest_v_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj9u1l/logistic_regression_v_random_forest_v_xgboost/", "subreddit_subscribers": 816630, "created_utc": 1667312124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have created a workspace for my data science projects and NGS pipelines. Contains RStudio, Jupyter Notebook, VSCode, and a file manager. It can use docker in docker and singularity and connect to the Tailscale network to bypass firewalls, thus allowing it to work from anywhere. I feel happy to share it if someone wants to use it - [https://github.com/kstawiski/seq-pipeline](https://github.com/kstawiski/seq-pipeline)\n\nhttps://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;format=png&amp;auto=webp&amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990", "author_fullname": "t2_ynu23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science workspace I have always dreamed about...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sj0t8r97wcx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 106, "x": 108, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8bb30e0f055501ce417a4f78341353cca5db8a2"}, {"y": 212, "x": 216, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=85ec5a74c9a9e642cbf2510be6e7bac8698e02ee"}, {"y": 315, "x": 320, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=11950b5e9eb528fa88ff4275ee230470a9bdf34e"}, {"y": 630, "x": 640, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c3de75d09b0334c15a5468f87facb1564a93b3cd"}, {"y": 945, "x": 960, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=797e10acdbd8bd82919c7db609201f832c5c9eb9"}], "s": {"y": 1024, "x": 1040, "u": "https://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;format=png&amp;auto=webp&amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990"}, "id": "sj0t8r97wcx91"}}, "name": "t3_yjb9ab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Y4uMld_b__F66QX0q4vXziOlb3BobsUKy3FhthWle2c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667315681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have created a workspace for my data science projects and NGS pipelines. Contains RStudio, Jupyter Notebook, VSCode, and a file manager. It can use docker in docker and singularity and connect to the Tailscale network to bypass firewalls, thus allowing it to work from anywhere. I feel happy to share it if someone wants to use it - &lt;a href=\"https://github.com/kstawiski/seq-pipeline\"&gt;https://github.com/kstawiski/seq-pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990\"&gt;https://preview.redd.it/sj0t8r97wcx91.png?width=1040&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2ef382a229e44cd7656d69cc6f2f1388396c2990&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjb9ab", "is_robot_indexable": true, "report_reasons": null, "author": "kondi69", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjb9ab/data_science_workspace_i_have_always_dreamed_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjb9ab/data_science_workspace_i_have_always_dreamed_about/", "subreddit_subscribers": 816630, "created_utc": 1667315681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4ol32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview with a senior ML engineer working on detecting illegal logging using SAR satellites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yj96op", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/x3PIhdHyjqkG9A1xX6pQ-1W7xB1TjPa8j8_NTN2pQKQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667310518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mlpioneers.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.mlpioneers.com/tapio-iceye/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?auto=webp&amp;s=47be098c258f9ccc9d95d226678519862ebe1468", "width": 1601, "height": 1601}, "resolutions": [{"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f60d9858d3ccfb828ecebe816305842a088aff88", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55d2554e6a518e16336fd0ac796f868656477dde", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd2caf50a4d38c2d8cf34825f254287136205a24", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b80cc77cad3658fef99dc8fc1fed76ce189f697", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=221fe16b98422e24d5138cd921f4fddb2dea7a0a", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/-vu9784e2nWmjWAW8EQbcY8zdO2H3f0-VYi1I_EJyHI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=95794f85000cb6323b7b4cb4c3f66642e242defd", "width": 1080, "height": 1080}], "variants": {}, "id": "v19rD2kKRf6MviDFMprdo9wKLVGZHeoj5aTI0q8_p5w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj96op", "is_robot_indexable": true, "report_reasons": null, "author": "shyssee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj96op/interview_with_a_senior_ml_engineer_working_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mlpioneers.com/tapio-iceye/", "subreddit_subscribers": 816630, "created_utc": 1667310518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1614sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vectory: a tool for tracking and comparing embeddings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": true, "name": "t3_yjlha8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sabAE41RYy4PyqeyNZn_kBii7cHu5ujy-yEVpdoyVsY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667337000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4b275q5amex91.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4b275q5amex91.gif?format=png8&amp;s=deee730ebb476095325a49adedd102feeda26a9d", "width": 600, "height": 298}, "resolutions": [{"url": "https://preview.redd.it/4b275q5amex91.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=44fff3cba1864e9bad776880824015cc78bde551", "width": 108, "height": 53}, {"url": "https://preview.redd.it/4b275q5amex91.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=e79ac19fec9e5868498095e475944f341d15b0fa", "width": 216, "height": 107}, {"url": "https://preview.redd.it/4b275q5amex91.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=59255f00da9139d27a130f96ee3dd1c2b83fa799", "width": 320, "height": 158}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/4b275q5amex91.gif?s=d55b1d4759a92da2c72895a71f9306fc021947f5", "width": 600, "height": 298}, "resolutions": [{"url": "https://preview.redd.it/4b275q5amex91.gif?width=108&amp;crop=smart&amp;s=6ec7eaa405a6dc61426a692cf1e3d5e85cb7caa5", "width": 108, "height": 53}, {"url": "https://preview.redd.it/4b275q5amex91.gif?width=216&amp;crop=smart&amp;s=1d4b199e1cd4d0f43734f43ecf0668dc88e98ece", "width": 216, "height": 107}, {"url": "https://preview.redd.it/4b275q5amex91.gif?width=320&amp;crop=smart&amp;s=cc19ded57201e8f295597c4e6279a8c47e25afee", "width": 320, "height": 158}]}, "mp4": {"source": {"url": "https://preview.redd.it/4b275q5amex91.gif?format=mp4&amp;s=ac773c7ac65f44e4ef1bb048803d296fff6436ad", "width": 600, "height": 298}, "resolutions": [{"url": "https://preview.redd.it/4b275q5amex91.gif?width=108&amp;format=mp4&amp;s=5453ab1ec01927c49225c2dc61d0be2146eaa8f7", "width": 108, "height": 53}, {"url": "https://preview.redd.it/4b275q5amex91.gif?width=216&amp;format=mp4&amp;s=2e0f939d7adec1df9211567c18d6503a3d80212a", "width": 216, "height": 107}, {"url": "https://preview.redd.it/4b275q5amex91.gif?width=320&amp;format=mp4&amp;s=ed5ef34fd1850fce5e3a96e979ea6a084ad4dd79", "width": 320, "height": 158}]}}, "id": "4P3CrjK88kg5SUBP6bptMckLTAiImRPQGMPsMO4EgsA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjlha8", "is_robot_indexable": true, "report_reasons": null, "author": "Leopiney", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjlha8/vectory_a_tool_for_tracking_and_comparing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4b275q5amex91.gif", "subreddit_subscribers": 816630, "created_utc": 1667337000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I'm studying Data Analytics right now through the Google certification, and once I land a job(any job\ud83d\ude02 not necessarily specific to data analysis) I intend on pursuing a degree in Data Science. \n\nRan across Data Cleaning, as you'd expect, pretty early on. And everything about it sounds really interesting and like something that I'd enjoy. I looked more into it, but over and over again things kept coming up about how the work keeps being forced on data scientists who don't want anything to do with data cleaning. \n\nSo my question is, is it possible to specialize specifically in data cleaning? And if so, are there specific certifications or other relevant education that I should pursue to do that? Is data cleaning at risk of being automated?", "author_fullname": "t2_lffj1vv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you specialize in data cleaning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjkjlx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667334966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I&amp;#39;m studying Data Analytics right now through the Google certification, and once I land a job(any job\ud83d\ude02 not necessarily specific to data analysis) I intend on pursuing a degree in Data Science. &lt;/p&gt;\n\n&lt;p&gt;Ran across Data Cleaning, as you&amp;#39;d expect, pretty early on. And everything about it sounds really interesting and like something that I&amp;#39;d enjoy. I looked more into it, but over and over again things kept coming up about how the work keeps being forced on data scientists who don&amp;#39;t want anything to do with data cleaning. &lt;/p&gt;\n\n&lt;p&gt;So my question is, is it possible to specialize specifically in data cleaning? And if so, are there specific certifications or other relevant education that I should pursue to do that? Is data cleaning at risk of being automated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjkjlx", "is_robot_indexable": true, "report_reasons": null, "author": "Seaforme", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjkjlx/can_you_specialize_in_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjkjlx/can_you_specialize_in_data_cleaning/", "subreddit_subscribers": 816630, "created_utc": 1667334966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you have favorite news sources which are very business-data science focused?  Do you attend conferences? Discord Channels? Is there some arxiv-esque site where the papers are focused on real world use cases?\n\n&amp;#x200B;\n\nTo provide context for this post  My past job was geared towards different fields, so I got very good at getting a high level view of a specific industry/use cases.  However, after changing to a more specialized field, I found it much more difficult to break past that initial layer.", "author_fullname": "t2_5puimv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you learn and keep up with use cases for data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj1wn4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667287395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have favorite news sources which are very business-data science focused?  Do you attend conferences? Discord Channels? Is there some arxiv-esque site where the papers are focused on real world use cases?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To provide context for this post  My past job was geared towards different fields, so I got very good at getting a high level view of a specific industry/use cases.  However, after changing to a more specialized field, I found it much more difficult to break past that initial layer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj1wn4", "is_robot_indexable": true, "report_reasons": null, "author": "shaner92", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj1wn4/how_do_you_learn_and_keep_up_with_use_cases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj1wn4/how_do_you_learn_and_keep_up_with_use_cases_for/", "subreddit_subscribers": 816630, "created_utc": 1667287395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Folks,\n\nFor any tensorflow developers out there or if you are generally interested in helping I need some help:\n\nI took the Tensorflow developer specialization on Coursera. I recently completed their 3rd course. I was quite overwhelmed frankly as I had never worked with NLP.  I really wanted to stop for a while and develop something of my own as a project to test my knowledge. I stumbled upon this idea of building a disease prediction model last week and I really wanted to get some ideas on my model. I scraped diseases, and their symptoms from internet. Symptoms being separated by commas with no sequential meaning.\n\n1. Some of my symptoms and disease names are multi word, is there any work around for that?\n\n2. I guess using LSTM is quite useless as symptoms are randomly separated by commas so no sequential meaning. Comments?\n\n3. I multiplied my dataset by using symptoms in various combinations for every disease. Is this fine?\n\n4. My approach so far has been to tokenize each symptom. I did not tokenize labels and rather created a dictionary with indexes. This is because some diseases \\*labels\\* were multi word so I cannot pass a token array as label.\n\n5. Should I go for one hot encoding rather?\n\nI pass the input through an embedding layer \\*\\*64 dimension\\*\\*, Global avg pooling 1D, Dense layer 100 relu activations, and 261 outputs softmax activation.\n\nI got 90% train and val accuracy. Is this approach right?\n\nAnother thing I wanted to do was to be able to predict symptoms from utterances, any suggestions?\n\nIf anyone is interested, feel free to join in the project", "author_fullname": "t2_rzwdmc0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions on an NLP project that I built", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjj8ps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667332273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,&lt;/p&gt;\n\n&lt;p&gt;For any tensorflow developers out there or if you are generally interested in helping I need some help:&lt;/p&gt;\n\n&lt;p&gt;I took the Tensorflow developer specialization on Coursera. I recently completed their 3rd course. I was quite overwhelmed frankly as I had never worked with NLP.  I really wanted to stop for a while and develop something of my own as a project to test my knowledge. I stumbled upon this idea of building a disease prediction model last week and I really wanted to get some ideas on my model. I scraped diseases, and their symptoms from internet. Symptoms being separated by commas with no sequential meaning.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Some of my symptoms and disease names are multi word, is there any work around for that?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I guess using LSTM is quite useless as symptoms are randomly separated by commas so no sequential meaning. Comments?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I multiplied my dataset by using symptoms in various combinations for every disease. Is this fine?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;My approach so far has been to tokenize each symptom. I did not tokenize labels and rather created a dictionary with indexes. This is because some diseases *labels* were multi word so I cannot pass a token array as label.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should I go for one hot encoding rather?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I pass the input through an embedding layer **64 dimension**, Global avg pooling 1D, Dense layer 100 relu activations, and 261 outputs softmax activation.&lt;/p&gt;\n\n&lt;p&gt;I got 90% train and val accuracy. Is this approach right?&lt;/p&gt;\n\n&lt;p&gt;Another thing I wanted to do was to be able to predict symptoms from utterances, any suggestions?&lt;/p&gt;\n\n&lt;p&gt;If anyone is interested, feel free to join in the project&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjj8ps", "is_robot_indexable": true, "report_reasons": null, "author": "Kind-Thing-7202", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjj8ps/need_suggestions_on_an_nlp_project_that_i_built/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjj8ps/need_suggestions_on_an_nlp_project_that_i_built/", "subreddit_subscribers": 816630, "created_utc": 1667332273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\"Just sent your payment. Congrats on being the highest paid employee in the company\".\n\nSeems like a tactic to put pressure on me to do even more work or make me feel uncomfortable for getting paid. \n\nShould I just not reply? I am thinking just to ignore the comment and continue, and not to send him any reply, no comebacks. I don't want to be snarky. When there is a problem, I take full responsibility on it even if it's not my own problem, and am always the nicest person. \n\nI am the first employee in the startup, and who brings in the most amount of work, consistently, day and night (yes, sometimes working into the night to make deadlines happen when he lets us know the day or two before for work to be done for a big company we're working with). \n\nI started with a very low pay for months (barely enough to pay the bills) and just now was promoted, after my insistence, since I had to work in childcare to pay the bills. He is till underpaying, and paying only 70% of what a business data analyst gets.", "author_fullname": "t2_8zbxfqav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Boss Just Told Me...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjlzp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667338234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Just sent your payment. Congrats on being the highest paid employee in the company&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Seems like a tactic to put pressure on me to do even more work or make me feel uncomfortable for getting paid. &lt;/p&gt;\n\n&lt;p&gt;Should I just not reply? I am thinking just to ignore the comment and continue, and not to send him any reply, no comebacks. I don&amp;#39;t want to be snarky. When there is a problem, I take full responsibility on it even if it&amp;#39;s not my own problem, and am always the nicest person. &lt;/p&gt;\n\n&lt;p&gt;I am the first employee in the startup, and who brings in the most amount of work, consistently, day and night (yes, sometimes working into the night to make deadlines happen when he lets us know the day or two before for work to be done for a big company we&amp;#39;re working with). &lt;/p&gt;\n\n&lt;p&gt;I started with a very low pay for months (barely enough to pay the bills) and just now was promoted, after my insistence, since I had to work in childcare to pay the bills. He is till underpaying, and paying only 70% of what a business data analyst gets.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjlzp1", "is_robot_indexable": true, "report_reasons": null, "author": "sapiogirl", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjlzp1/my_boss_just_told_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjlzp1/my_boss_just_told_me/", "subreddit_subscribers": 816630, "created_utc": 1667338234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "During your data science internship, did you have an opportunity to finish a ML model from start to finish (by which I mean from project conception to model deployment), or did you find yourself assigned to a ML project which was already in a later stage (i.e Data Cleaning).\n\nI am asking because I want to compare my Data Science Internship experience. I had the opportunity to work on a lot of cool projects, but in the ML project, I only worked on the Data Collection, EDA, and Data Cleaning phase. I feel like I am at a disadvantage for entry level data scientist positions because I haven't actually produced a model in the professional environment.", "author_fullname": "t2_tlsfzwe0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Those with Data Science Internship experience - How much Machine Learning did you actually do during your internship?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj2gyr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667289525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;During your data science internship, did you have an opportunity to finish a ML model from start to finish (by which I mean from project conception to model deployment), or did you find yourself assigned to a ML project which was already in a later stage (i.e Data Cleaning).&lt;/p&gt;\n\n&lt;p&gt;I am asking because I want to compare my Data Science Internship experience. I had the opportunity to work on a lot of cool projects, but in the ML project, I only worked on the Data Collection, EDA, and Data Cleaning phase. I feel like I am at a disadvantage for entry level data scientist positions because I haven&amp;#39;t actually produced a model in the professional environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj2gyr", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Lynx-4094", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj2gyr/those_with_data_science_internship_experience_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj2gyr/those_with_data_science_internship_experience_how/", "subreddit_subscribers": 816630, "created_utc": 1667289525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a senior currently on the job hunt and I've seen a few of these \"Professional Development Programs\" where you basically rotate through different sectors of the company and learn how data science is applied at each one. What is the general consensus on programs like these? Also, does anyone have any idea how much they generally pay? What would your job title even be? Would they be more of a help or a hinder when seeking future employment afterward?", "author_fullname": "t2_4g45t9kc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional Development Programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiy98z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667275466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a senior currently on the job hunt and I&amp;#39;ve seen a few of these &amp;quot;Professional Development Programs&amp;quot; where you basically rotate through different sectors of the company and learn how data science is applied at each one. What is the general consensus on programs like these? Also, does anyone have any idea how much they generally pay? What would your job title even be? Would they be more of a help or a hinder when seeking future employment afterward?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yiy98z", "is_robot_indexable": true, "report_reasons": null, "author": "goBlue102_2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yiy98z/professional_development_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yiy98z/professional_development_programs/", "subreddit_subscribers": 816630, "created_utc": 1667275466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title sounding stupid, let me clarify my question with the help of that quote :\n\n&gt;According to two recent Gartner reports, 85% of AI and machine learning projects fail to deliver, and only 53% of projects make it from prototypes to production.\n\nWhen you spend weeks/months on a project and it gets nowhere, do you try harder ? are you assigned to work on another task ? Do you feel ~~like you're the failure of the company~~ powerless ?\n\nOr is it just \"part of the deal\", win some, lose some. \n\nI'm also very curious as to how companies that extensively pay data scientists manage to benefit from their employees in case of failures/repeated failure on the long run.", "author_fullname": "t2_5blbvj00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens when one of your project fails ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjm8i3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667340077.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667338839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title sounding stupid, let me clarify my question with the help of that quote :&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;According to two recent Gartner reports, 85% of AI and machine learning projects fail to deliver, and only 53% of projects make it from prototypes to production.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;When you spend weeks/months on a project and it gets nowhere, do you try harder ? are you assigned to work on another task ? Do you feel &lt;del&gt;like you&amp;#39;re the failure of the company&lt;/del&gt; powerless ?&lt;/p&gt;\n\n&lt;p&gt;Or is it just &amp;quot;part of the deal&amp;quot;, win some, lose some. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also very curious as to how companies that extensively pay data scientists manage to benefit from their employees in case of failures/repeated failure on the long run.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjm8i3", "is_robot_indexable": true, "report_reasons": null, "author": "SaltySarcasticJohn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjm8i3/what_happens_when_one_of_your_project_fails/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjm8i3/what_happens_when_one_of_your_project_fails/", "subreddit_subscribers": 816630, "created_utc": 1667338839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Important research findings: Taylor Swift Swear Projection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_yjm43u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1v6k7o1o", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nhb6gtIiAjd80XZfq8FXeFkp2zRj_zIDLDjTtiofa90.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "TaylorSwift", "selftext": "We are all pleased that Taylor is starting to swear like she means it. But I've had real concerns about the recent rapid increase in swears per album. I decided to run some projections for studio albums 11 through 20. The trends are worrying.\n\nTaylor Swift 14 is likely to be released near 2030. Projections show that album will include 281 swears. It's going to be quite a different Taylor but I'm sure she can pull it off.\n\nBy 2039, things have really changed. Taylor Swift 20, released on her 50th birthday, may be the biggest album of the year.  But I am not sure how Swifties are going to react to the 2,570 swear words. It seems excessive, is Taylor OK? Maybe that's how all music sounds in 2039.\n\nI hope you found this information helpful.\n\nEDIT: u/vearson26's independent research has found that the average TSwift song contains 13 tracks, each track averaging 200 words, or 2600 average words per album.\n\nThe unavoidable conclusion is that \"2039\" could well be the first Taylor album which is literally all swear words. This is the singularity. The world beyond the singularity is unknowable. Good luck.  \n\n\nhttps://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;format=png&amp;auto=webp&amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da", "author_fullname": "t2_53f1pjmw", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Important research findings: Taylor Swift Swear Projection", "link_flair_richtext": [{"e": "text", "t": "News "}, {"a": ":news:", "e": "emoji", "u": "https://emoji.redditmedia.com/0l4sk2h3b3g31_t5_2rlwe/news"}], "subreddit_name_prefixed": "r/TaylorSwift", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v7yd3z0blmw91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 181, "x": 108, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0ef8390ef5fc95bc44642d8d48deb188dc75d4d"}, {"y": 362, "x": 216, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=091780f2015815e184d2c43405b8952a115ff90b"}, {"y": 536, "x": 320, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=096a7bee056487308620b82b387855886377ad88"}, {"y": 1073, "x": 640, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=393f7ffbc06a9e26b8e8153ccf04a99d0dc02e6e"}], "s": {"y": 1551, "x": 925, "u": "https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;format=png&amp;auto=webp&amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da"}, "id": "v7yd3z0blmw91"}}, "name": "t3_yg31p7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1803, "total_awards_received": 9, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News :news:", "can_mod_post": false, "score": 1803, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/nhb6gtIiAjd80XZfq8FXeFkp2zRj_zIDLDjTtiofa90.jpg", "edited": 1667064034.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 4, "gid_2": 1, "gid_3": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666997537.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.TaylorSwift", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are all pleased that Taylor is starting to swear like she means it. But I&amp;#39;ve had real concerns about the recent rapid increase in swears per album. I decided to run some projections for studio albums 11 through 20. The trends are worrying.&lt;/p&gt;\n\n&lt;p&gt;Taylor Swift 14 is likely to be released near 2030. Projections show that album will include 281 swears. It&amp;#39;s going to be quite a different Taylor but I&amp;#39;m sure she can pull it off.&lt;/p&gt;\n\n&lt;p&gt;By 2039, things have really changed. Taylor Swift 20, released on her 50th birthday, may be the biggest album of the year.  But I am not sure how Swifties are going to react to the 2,570 swear words. It seems excessive, is Taylor OK? Maybe that&amp;#39;s how all music sounds in 2039.&lt;/p&gt;\n\n&lt;p&gt;I hope you found this information helpful.&lt;/p&gt;\n\n&lt;p&gt;EDIT: &lt;a href=\"/u/vearson26\"&gt;u/vearson26&lt;/a&gt;&amp;#39;s independent research has found that the average TSwift song contains 13 tracks, each track averaging 200 words, or 2600 average words per album.&lt;/p&gt;\n\n&lt;p&gt;The unavoidable conclusion is that &amp;quot;2039&amp;quot; could well be the first Taylor album which is literally all swear words. This is the singularity. The world beyond the singularity is unknowable. Good luck.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da\"&gt;https://preview.redd.it/v7yd3z0blmw91.png?width=925&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82f218eb855949a6f641f46ed9bfddae1b0797da&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 4, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 31, "coin_price": 1800, "id": "gid_3", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png", "days_of_premium": 31, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 700 Reddit Coins and a month of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Platinum", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_31260000-2f4a-4b40-ad20-f5aa46a577bf", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Timeless_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Timeless_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Beauty that's forever. Gives %{coin_symbol}100 Coins each to the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Timeless Beauty", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=16&amp;height=16&amp;auto=webp&amp;s=9fdc2c55e7ddacb233466226c411fdd5474b9f02", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=32&amp;height=32&amp;auto=webp&amp;s=7b32657206f9bf592327fcf93be3141c88377738", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=48&amp;height=48&amp;auto=webp&amp;s=f9d7c94902a3fca13129f1562c1760fd2efed612", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=64&amp;height=64&amp;auto=webp&amp;s=5d7c3b3b8c15fea95896006200a6dea0eccb2820", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png?width=128&amp;height=128&amp;auto=webp&amp;s=613f9c4ad715208edccb511aaccac33fe033111a", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/08ps702w9l581_Timeless.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "217b9500-828c-11e5-948b-0e373b482bcf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rlwe", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a4d8ff", "id": "yg31p7", "is_robot_indexable": true, "report_reasons": null, "author": "allthepassports", "discussion_type": null, "num_comments": 193, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "subreddit_subscribers": 327662, "created_utc": 1666997537.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1667338529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.TaylorSwift", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjm43u", "is_robot_indexable": true, "report_reasons": null, "author": "Adam_24061", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yg31p7", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjm43u/important_research_findings_taylor_swift_swear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/TaylorSwift/comments/yg31p7/important_research_findings_taylor_swift_swear/", "subreddit_subscribers": 816630, "created_utc": 1667338529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Due to me working on a project that I would like to add on my resume before I apply for jobs, I haven't aggressively pursued applying to jobs.\n\nIn terms of the timeline that companies follow for hiring, if I wait until spring to apply to jobs will the job opportunities be significantly restricted?", "author_fullname": "t2_1szbf83g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Grad Job Application Timeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yjl2k6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667336114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Due to me working on a project that I would like to add on my resume before I apply for jobs, I haven&amp;#39;t aggressively pursued applying to jobs.&lt;/p&gt;\n\n&lt;p&gt;In terms of the timeline that companies follow for hiring, if I wait until spring to apply to jobs will the job opportunities be significantly restricted?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjl2k6", "is_robot_indexable": true, "report_reasons": null, "author": "MAVAAMUSICMACHINE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjl2k6/new_grad_job_application_timeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjl2k6/new_grad_job_application_timeline/", "subreddit_subscribers": 816630, "created_utc": 1667336114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just popped into my head as I reflect on our marketing team trying to pay a vendor a godawful amount of money for what the vendor literally labels, \u201coff the shelf machine learning models.\u201d The deal, we open the gates to let them exfiltrate data, they use it to train models, they then sell those modes back to us and our competition\u2026\n\nWhat I\u2019m realizing now is that there is absolutely no reasonable way they can uphold a delete request from our customers because it would require they retire the old modes, retrain in fresh data, and redeploy to all their other clients. \n\nSimilarly if there is a request for transparency about what data we have access to and what it\u2019s being used for, if our competition is using models trained on our customers data from our data stores, then who knows how the hell they might be using that\u2026\n\nAnd for those curious, they are willing to give away our data assets because they don\u2019t want to wait for our internal teams to make them dashboards using our internal warehousing and data stores. That\u2019s literally it.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CCPA, GDPR and vendor supplied models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yji271", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667329872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just popped into my head as I reflect on our marketing team trying to pay a vendor a godawful amount of money for what the vendor literally labels, \u201coff the shelf machine learning models.\u201d The deal, we open the gates to let them exfiltrate data, they use it to train models, they then sell those modes back to us and our competition\u2026&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m realizing now is that there is absolutely no reasonable way they can uphold a delete request from our customers because it would require they retire the old modes, retrain in fresh data, and redeploy to all their other clients. &lt;/p&gt;\n\n&lt;p&gt;Similarly if there is a request for transparency about what data we have access to and what it\u2019s being used for, if our competition is using models trained on our customers data from our data stores, then who knows how the hell they might be using that\u2026&lt;/p&gt;\n\n&lt;p&gt;And for those curious, they are willing to give away our data assets because they don\u2019t want to wait for our internal teams to make them dashboards using our internal warehousing and data stores. That\u2019s literally it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yji271", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yji271/ccpa_gdpr_and_vendor_supplied_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yji271/ccpa_gdpr_and_vendor_supplied_models/", "subreddit_subscribers": 816630, "created_utc": 1667329872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lets say I have a dataset D with n instances and three pre-trained regressors, Ra, Rb and Rc.\n\nI can run each regressor on D, which will net me a set of predictions Pa, Pb and Pc. How can I measure how much these three regressors \"agree\" in their predictions?\n\nFor example, if my Y domain is [0,100] and for some instance they predict 10, 11 and 9, I would argue that they 'agree' in their decisions. If, on the other hand, the predictions returned are 1, 99, 30, then they 'disagree'. But this is rather qualitative and subjective, I'm looking for a quantitative metric.\n\nI guess another way of asking is, how can I measure how close a set of predictions Pa, Pb and Pc are from one another.\n\nI thought of computing the mean standard deviation on each instance, or maybe the mean KL divergence between all regressor pairs but I'm wondering if there exists a better metric. Maybe something like a kappa score, but for regression.\n\nThanks!", "author_fullname": "t2_62m1wp38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to measure the 'agreement' of a set of regressors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjkp4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667335491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667335300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a dataset D with n instances and three pre-trained regressors, Ra, Rb and Rc.&lt;/p&gt;\n\n&lt;p&gt;I can run each regressor on D, which will net me a set of predictions Pa, Pb and Pc. How can I measure how much these three regressors &amp;quot;agree&amp;quot; in their predictions?&lt;/p&gt;\n\n&lt;p&gt;For example, if my Y domain is [0,100] and for some instance they predict 10, 11 and 9, I would argue that they &amp;#39;agree&amp;#39; in their decisions. If, on the other hand, the predictions returned are 1, 99, 30, then they &amp;#39;disagree&amp;#39;. But this is rather qualitative and subjective, I&amp;#39;m looking for a quantitative metric.&lt;/p&gt;\n\n&lt;p&gt;I guess another way of asking is, how can I measure how close a set of predictions Pa, Pb and Pc are from one another.&lt;/p&gt;\n\n&lt;p&gt;I thought of computing the mean standard deviation on each instance, or maybe the mean KL divergence between all regressor pairs but I&amp;#39;m wondering if there exists a better metric. Maybe something like a kappa score, but for regression.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjkp4k", "is_robot_indexable": true, "report_reasons": null, "author": "Tricky-Variation-240", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjkp4k/how_to_measure_the_agreement_of_a_set_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjkp4k/how_to_measure_the_agreement_of_a_set_of/", "subreddit_subscribers": 816630, "created_utc": 1667335300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This article gives an example\n\n[https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a](https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a)\n\nWhat do you think?", "author_fullname": "t2_pwxlrv27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Organize Your Data Science Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjamgq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667314109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This article gives an example&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a\"&gt;https://towardsdatascience.com/how-to-organize-your-data-science-project-dd6599cf000a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjamgq", "is_robot_indexable": true, "report_reasons": null, "author": "Fast-Group-8501", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjamgq/how_to_organize_your_data_science_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjamgq/how_to_organize_your_data_science_project/", "subreddit_subscribers": 816630, "created_utc": 1667314109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I have a bivariate numerical time series. I want to design a statistical test to evaluate the correlation between the two variables.\n\nMy population is about 800 data points, I understand that I can get the Pearson correlation easily with pandas for example. In this case I get a strong positive correlation of 0.908. \n\nMy question is : if I wanted to make a correlation test on a sample of the time series, for the purpose of demonstration, would it even be relevant to sample a population of 800 data points?  \n\nIf yes, what method should I use to sample the time series?\n\nSorry if this has already been answered or isn't relevant I just can't find it by myself. Any help is greatly appreciated.", "author_fullname": "t2_nks6q3kg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First correlation test (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj82r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667307600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bivariate numerical time series. I want to design a statistical test to evaluate the correlation between the two variables.&lt;/p&gt;\n\n&lt;p&gt;My population is about 800 data points, I understand that I can get the Pearson correlation easily with pandas for example. In this case I get a strong positive correlation of 0.908. &lt;/p&gt;\n\n&lt;p&gt;My question is : if I wanted to make a correlation test on a sample of the time series, for the purpose of demonstration, would it even be relevant to sample a population of 800 data points?  &lt;/p&gt;\n\n&lt;p&gt;If yes, what method should I use to sample the time series?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this has already been answered or isn&amp;#39;t relevant I just can&amp;#39;t find it by myself. Any help is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj82r5", "is_robot_indexable": true, "report_reasons": null, "author": "datafrime", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj82r5/first_correlation_test_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj82r5/first_correlation_test_noob/", "subreddit_subscribers": 816630, "created_utc": 1667307600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:\n\n1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.\n\n2) Download the mp3 and metadata (date, title, etc.) for the podcast.\n\n3) Process audio using something like WisperAI.\n\n4) Store the data for analytics.\n\n**I'm wondering if anyone has recommendations for the above, specifically steps 1 and 2?** For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?\n\nThanks so much for any assistance here!", "author_fullname": "t2_10ctkxdy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast Audio &amp; Metadata Scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj7lp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667306241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:&lt;/p&gt;\n\n&lt;p&gt;1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.&lt;/p&gt;\n\n&lt;p&gt;2) Download the mp3 and metadata (date, title, etc.) for the podcast.&lt;/p&gt;\n\n&lt;p&gt;3) Process audio using something like WisperAI.&lt;/p&gt;\n\n&lt;p&gt;4) Store the data for analytics.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m wondering if anyone has recommendations for the above, specifically steps 1 and 2?&lt;/strong&gt; For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for any assistance here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj7lp1", "is_robot_indexable": true, "report_reasons": null, "author": "beige_coffee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj7lp1/podcast_audio_metadata_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj7lp1/podcast_audio_metadata_scraping/", "subreddit_subscribers": 816630, "created_utc": 1667306241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a question  regarding var. Im using this model to find significance of factors that influences consumer price index and i have found few variables such as GDP. Any idea how and what values am i looking for in the model to determine whether my factor have any  significance in relative to consumer price index of a country?", "author_fullname": "t2_7cmorcub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "vector autoregressive model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj37el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667292266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question  regarding var. Im using this model to find significance of factors that influences consumer price index and i have found few variables such as GDP. Any idea how and what values am i looking for in the model to determine whether my factor have any  significance in relative to consumer price index of a country?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj37el", "is_robot_indexable": true, "report_reasons": null, "author": "Economy_Seesaw_7791", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj37el/vector_autoregressive_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj37el/vector_autoregressive_model/", "subreddit_subscribers": 816630, "created_utc": 1667292266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, will a Redhat ex180 certificate give me an edge when applying for Data Science jobs?\n\nThanks.", "author_fullname": "t2_8dw6ibl0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redhat Certificate (EX180)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiy5fu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667275192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, will a Redhat ex180 certificate give me an edge when applying for Data Science jobs?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yiy5fu", "is_robot_indexable": true, "report_reasons": null, "author": "AcanthocephalaRare81", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yiy5fu/redhat_certificate_ex180/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yiy5fu/redhat_certificate_ex180/", "subreddit_subscribers": 816630, "created_utc": 1667275192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have txt books.  They have a lot of pages. I want to sort words top used words. For example;\n\nI desire to have a code like this\n\n`python input.txt -sort-top-words output.txt`\n\nand\n\noutput.txt should have minimum 10.000 words like this:\n\n1. the\n2. of\n3. and\n4. house\n5. that... 10000: orange\n\nThere are several websites for this. But i want to do this myself via code. I think all programming languages can do this. I prefer \"python or javascript\" since i have some background these languages. How can i do this?", "author_fullname": "t2_7qf2od4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sorting top used words in my txt books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjgbh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667326372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have txt books.  They have a lot of pages. I want to sort words top used words. For example;&lt;/p&gt;\n\n&lt;p&gt;I desire to have a code like this&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;python input.txt -sort-top-words output.txt&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;and&lt;/p&gt;\n\n&lt;p&gt;output.txt should have minimum 10.000 words like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;the&lt;/li&gt;\n&lt;li&gt;of&lt;/li&gt;\n&lt;li&gt;and&lt;/li&gt;\n&lt;li&gt;house&lt;/li&gt;\n&lt;li&gt;that... 10000: orange&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There are several websites for this. But i want to do this myself via code. I think all programming languages can do this. I prefer &amp;quot;python or javascript&amp;quot; since i have some background these languages. How can i do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjgbh2", "is_robot_indexable": true, "report_reasons": null, "author": "birisix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjgbh2/sorting_top_used_words_in_my_txt_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjgbh2/sorting_top_used_words_in_my_txt_books/", "subreddit_subscribers": 816630, "created_utc": 1667326372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, so I am starting a new DS job with a massive pay increase and I'm wondering if it's worth it to purchase a personal laptop.\n\nThroughout my career, I've always just used the laptop that my company has provided for both worth and personal use - for all my previous jobs this has been a MacBook Pro.\n\nNow the issue comes in between jobs when I don't have a daily driver. Tbh I do own a 7 year old crusty windows laptop but it's painful to use and I would rather sell it and upgrade. \n\nI was planning to treat myself by buying a refurbished Macbook Pro or new MacBook Air - however my bf pointed out that it was a silly purchase for a such a niche use case. I know it's my money and I can choose what to do with it, but he does have a good point and the more I think about it the more guilty I feel as I'm guaranteed to get a MacBook Pro with my new job in a few weeks time.\n\nData scientists - do you own/see the need for a personal laptop? Are there any risks with using a work device for personal use (I would never torrent/do anything illegal on mine)", "author_fullname": "t2_12tncraf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need a personal laptop if you have a good one from work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj3ohk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667293718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, so I am starting a new DS job with a massive pay increase and I&amp;#39;m wondering if it&amp;#39;s worth it to purchase a personal laptop.&lt;/p&gt;\n\n&lt;p&gt;Throughout my career, I&amp;#39;ve always just used the laptop that my company has provided for both worth and personal use - for all my previous jobs this has been a MacBook Pro.&lt;/p&gt;\n\n&lt;p&gt;Now the issue comes in between jobs when I don&amp;#39;t have a daily driver. Tbh I do own a 7 year old crusty windows laptop but it&amp;#39;s painful to use and I would rather sell it and upgrade. &lt;/p&gt;\n\n&lt;p&gt;I was planning to treat myself by buying a refurbished Macbook Pro or new MacBook Air - however my bf pointed out that it was a silly purchase for a such a niche use case. I know it&amp;#39;s my money and I can choose what to do with it, but he does have a good point and the more I think about it the more guilty I feel as I&amp;#39;m guaranteed to get a MacBook Pro with my new job in a few weeks time.&lt;/p&gt;\n\n&lt;p&gt;Data scientists - do you own/see the need for a personal laptop? Are there any risks with using a work device for personal use (I would never torrent/do anything illegal on mine)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj3ohk", "is_robot_indexable": true, "report_reasons": null, "author": "ElfGaladriel", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj3ohk/do_you_need_a_personal_laptop_if_you_have_a_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj3ohk/do_you_need_a_personal_laptop_if_you_have_a_good/", "subreddit_subscribers": 816630, "created_utc": 1667293718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!  \n\n\nQuick introduction.  \n27y.o. Data analyst in Europe. I start my journey in IT as self-learner at age of 24, don't have a degree in CS. Get a internship as front end dev, then moved to backend dev with python and after 1.5y get a data analyst position within same company and from June this year get a data analyst position in 300+ emp company.  \nMy ultimate goal is to achieve some VP level of position in future(it can be easily 10+ y)  \nI'm currently a little bit confused of how exactly I should grow my career. Should I grow for another year/two within same company to achieve senior DA position? Should I start getting some bits of DS/ML? Since my goal to get top level of data related position, knowing only about data analytics would be not enough, right?  \nPeople who already achieved some senior/management positions, what would you advice for newcomer with big goals?  \nLooking to hear any advices, own experience etc.  \n\n\nHave a great day everyone!", "author_fullname": "t2_11m7513", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analyst looking for career grow advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj2x4w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667291209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;Quick introduction.&lt;br/&gt;\n27y.o. Data analyst in Europe. I start my journey in IT as self-learner at age of 24, don&amp;#39;t have a degree in CS. Get a internship as front end dev, then moved to backend dev with python and after 1.5y get a data analyst position within same company and from June this year get a data analyst position in 300+ emp company.&lt;br/&gt;\nMy ultimate goal is to achieve some VP level of position in future(it can be easily 10+ y)&lt;br/&gt;\nI&amp;#39;m currently a little bit confused of how exactly I should grow my career. Should I grow for another year/two within same company to achieve senior DA position? Should I start getting some bits of DS/ML? Since my goal to get top level of data related position, knowing only about data analytics would be not enough, right?&lt;br/&gt;\nPeople who already achieved some senior/management positions, what would you advice for newcomer with big goals?&lt;br/&gt;\nLooking to hear any advices, own experience etc.  &lt;/p&gt;\n\n&lt;p&gt;Have a great day everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj2x4w", "is_robot_indexable": true, "report_reasons": null, "author": "Hexynator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj2x4w/data_analyst_looking_for_career_grow_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yj2x4w/data_analyst_looking_for_career_grow_advice/", "subreddit_subscribers": 816630, "created_utc": 1667291209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It is from Multiple linear regression. one of the problems caused due to colinearity among predictors.", "author_fullname": "t2_9jype2jy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone explain the term 'Claims of casuality' ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yitlwk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667262243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is from Multiple linear regression. one of the problems caused due to colinearity among predictors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yitlwk", "is_robot_indexable": true, "report_reasons": null, "author": "-Sourabh", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yitlwk/can_anyone_explain_the_term_claims_of_casuality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yitlwk/can_anyone_explain_the_term_claims_of_casuality/", "subreddit_subscribers": 816630, "created_utc": 1667262243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to get large data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj9mj8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_tvmyd009", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "excel", "selftext": "I need a large data on any topic for an assignment of excel. The should should have about 3000-5000 entries/rows and about 6-8 columns with values. Anyone knows any site where i can get this kind of data?", "author_fullname": "t2_tvmyd009", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to get large data?", "link_flair_richtext": [{"e": "text", "t": "Waiting on OP"}], "subreddit_name_prefixed": "r/excel", "hidden": false, "pwls": 6, "link_flair_css_class": "waitingonop", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj9iaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Waiting on OP", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667311307.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.excel", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a large data on any topic for an assignment of excel. The should should have about 3000-5000 entries/rows and about 6-8 columns with values. Anyone knows any site where i can get this kind of data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "top", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "fb6ebbf6-05f3-11e3-9e5e-12313d21c6e5", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qur2", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#78bafe", "id": "yj9iaw", "is_robot_indexable": true, "report_reasons": null, "author": "Tempaccforassignment", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/excel/comments/yj9iaw/where_to_get_large_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/excel/comments/yj9iaw/where_to_get_large_data/", "subreddit_subscribers": 595085, "created_utc": 1667311307.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1667311602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.excel", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/excel/comments/yj9iaw/where_to_get_large_data/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yj9mj8", "is_robot_indexable": true, "report_reasons": null, "author": "Tempaccforassignment", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yj9iaw", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yj9mj8/where_to_get_large_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/excel/comments/yj9iaw/where_to_get_large_data/", "subreddit_subscribers": 816630, "created_utc": 1667311602.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}