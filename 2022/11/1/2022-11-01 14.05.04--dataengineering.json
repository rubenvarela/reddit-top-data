{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7ck5p6ie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You SHALL pass...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yie8d0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 268, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 268, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/lnEk2tVYT4GtFCmGwB-tTq3n4ISEBUmNufbFl1q91z4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667227728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4qpxmtlhm5x91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?auto=webp&amp;s=78bde491c0fec85b4895bbc83cc4395779f3fe8e", "width": 570, "height": 672}, "resolutions": [{"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=804267614c4a5fee3643f20aebe8a9b33271c42e", "width": 108, "height": 127}, {"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92e7086371a4f938dfa77991322aaf484688164f", "width": 216, "height": 254}, {"url": "https://preview.redd.it/4qpxmtlhm5x91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1684153ec2b42034b0851416b046dcc1d7d2f79", "width": 320, "height": 377}], "variants": {}, "id": "GznJQugTORHUdG19qbwt5U38fSJolrmKEJBXgjGZdgA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yie8d0", "is_robot_indexable": true, "report_reasons": null, "author": "Happy-Destruction", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yie8d0/you_shall_pass/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4qpxmtlhm5x91.jpg", "subreddit_subscribers": 78529, "created_utc": 1667227728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a server side/backend developer with an year of experience in developing web services with Java and Spring. For the last 3 months, I've been using Apache Beam's Java SDK for writing ETL pipelines for GCP Dataflow.  \n\nMy work role now requires me to make a permanent switch to DE, and complete the [Databricks Certified Associate Developer for Apache Spark](https://www.databricks.com/learn/certification/apache-spark-developer-associate)  certification. \n\nThe Catch is that the cert is only offered for either python or Scala but I'm currently only proficient with Java. I'm willing to learn either one of these languages but I'm confused about which one to go forward with. My dilemma is as follows:\n\n1) I dislike python but I feel like it's the `lingua franca' of DE and it's not really possible to make a career in this field without mastering it.\n\n2) I love Scala but feel that it might not be too useful other than this cert for DE.\n\n3) At my workplace we use all 3 but Scala is rarest.\n\nAny input would be appreciated, Thanks.", "author_fullname": "t2_3ucivv3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scala or Python for Data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yieto6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667229094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a server side/backend developer with an year of experience in developing web services with Java and Spring. For the last 3 months, I&amp;#39;ve been using Apache Beam&amp;#39;s Java SDK for writing ETL pipelines for GCP Dataflow.  &lt;/p&gt;\n\n&lt;p&gt;My work role now requires me to make a permanent switch to DE, and complete the &lt;a href=\"https://www.databricks.com/learn/certification/apache-spark-developer-associate\"&gt;Databricks Certified Associate Developer for Apache Spark&lt;/a&gt;  certification. &lt;/p&gt;\n\n&lt;p&gt;The Catch is that the cert is only offered for either python or Scala but I&amp;#39;m currently only proficient with Java. I&amp;#39;m willing to learn either one of these languages but I&amp;#39;m confused about which one to go forward with. My dilemma is as follows:&lt;/p&gt;\n\n&lt;p&gt;1) I dislike python but I feel like it&amp;#39;s the `lingua franca&amp;#39; of DE and it&amp;#39;s not really possible to make a career in this field without mastering it.&lt;/p&gt;\n\n&lt;p&gt;2) I love Scala but feel that it might not be too useful other than this cert for DE.&lt;/p&gt;\n\n&lt;p&gt;3) At my workplace we use all 3 but Scala is rarest.&lt;/p&gt;\n\n&lt;p&gt;Any input would be appreciated, Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?auto=webp&amp;s=28b9ae149e0b4d698c919c86cb9694173c82dafd", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0ab2e6d636c370b278c37013e4e3856a0298ace", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a856bb1f4d2eb3a4a805e32a57aff0511418a3e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1cfb4263d4a5010c46048b82c5393c49e142f48b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=04eed4dbb30b78c729da72ee176b3f9e18fab790", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9248e19e8c14006380c590c18b5e059b87fe8d14", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b675948c77f088256047dc00427e8ca3ecc8b1f7", "width": 1080, "height": 565}], "variants": {}, "id": "HwfMz-OF8GV89jc_qQVRVxc8W8oTe2mVUnnrYLKLhX8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yieto6", "is_robot_indexable": true, "report_reasons": null, "author": "forneptune", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/", "subreddit_subscribers": 78529, "created_utc": 1667229094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys :) \nWe are trying to find the best CI/CD solution for our team. \nWe are building DW in snowflake, and we are seeking a tool to automate the deployment method to all our SQL scripts between dev, test, and prod DB. (Today, we run it manually)\n\nThe tools we are looking at are: \n1. liquibase\n2. schemachange\n3. dbt\n4. flyway \n\nI\u2019ll like to hear opinions about these tools, cons/pros. \n\nThank you :)", "author_fullname": "t2_6xzfpjga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best CI/CD tool for snowflake development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yikcc7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667240921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys :) \nWe are trying to find the best CI/CD solution for our team. \nWe are building DW in snowflake, and we are seeking a tool to automate the deployment method to all our SQL scripts between dev, test, and prod DB. (Today, we run it manually)&lt;/p&gt;\n\n&lt;p&gt;The tools we are looking at are: \n1. liquibase\n2. schemachange\n3. dbt\n4. flyway &lt;/p&gt;\n\n&lt;p&gt;I\u2019ll like to hear opinions about these tools, cons/pros. &lt;/p&gt;\n\n&lt;p&gt;Thank you :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yikcc7", "is_robot_indexable": true, "report_reasons": null, "author": "Queasy-Claim-5972", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yikcc7/best_cicd_tool_for_snowflake_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yikcc7/best_cicd_tool_for_snowflake_development/", "subreddit_subscribers": 78529, "created_utc": 1667240921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear data engineers,\n\nI have over 8 years of experience in the domain of data analytics and consulting. I have decided to pivot to a data engineering role (I did work on a few data engineering projects too previously). If it matters, I am proficient in SQL, Python, Scala, Bash, Hive, Spark.\n\nSince this would be my first company in my new career, I have decided to keep the following criteria while looking for a company (in the priority order)\n\n* Companies where I can learn software engineering principles in general. Although I know most of the major tools/frameworks that a DE uses, I want to know how all of them fit together with rest of teams and business units\n* Places where I can focus solely on improving my skills\n* moderate work life balance\n* Salary is not a criteria, learning is\n\nWith the above criteria in mind, can you please suggest me some companies in India that you are aware of? If you are not from India, please suggest what should I look for when searching for companies and any other red flags\n\nI have decided not to go back to data analytics domain. So this move to DE is not an impulsive decision\n\n___\n\nMy 2 cents to people working in the domain of data analytics and ML\n\n* As cliched as it sounds, ponder over the question \"Where do you want to be in 5 years\". Based on what I have seen, most organizations will eventually move you to a more managerial/stakeholder facing/ppt making role. Observe yourself, do some introspection on if you would enjoy such roles a few years down the line. I didn't, not one bit\n* Prepare for being comfortable with ambiguity. With the right amount of effort, ML Models can be built, but tying it to daily business operations especially involving a lot of stakeholders is a much bigger beast. Do you enjoy doing it?", "author_fullname": "t2_szesl9z4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies in India with good learning opportunities for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiddau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667225654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear data engineers,&lt;/p&gt;\n\n&lt;p&gt;I have over 8 years of experience in the domain of data analytics and consulting. I have decided to pivot to a data engineering role (I did work on a few data engineering projects too previously). If it matters, I am proficient in SQL, Python, Scala, Bash, Hive, Spark.&lt;/p&gt;\n\n&lt;p&gt;Since this would be my first company in my new career, I have decided to keep the following criteria while looking for a company (in the priority order)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Companies where I can learn software engineering principles in general. Although I know most of the major tools/frameworks that a DE uses, I want to know how all of them fit together with rest of teams and business units&lt;/li&gt;\n&lt;li&gt;Places where I can focus solely on improving my skills&lt;/li&gt;\n&lt;li&gt;moderate work life balance&lt;/li&gt;\n&lt;li&gt;Salary is not a criteria, learning is&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With the above criteria in mind, can you please suggest me some companies in India that you are aware of? If you are not from India, please suggest what should I look for when searching for companies and any other red flags&lt;/p&gt;\n\n&lt;p&gt;I have decided not to go back to data analytics domain. So this move to DE is not an impulsive decision&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;My 2 cents to people working in the domain of data analytics and ML&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;As cliched as it sounds, ponder over the question &amp;quot;Where do you want to be in 5 years&amp;quot;. Based on what I have seen, most organizations will eventually move you to a more managerial/stakeholder facing/ppt making role. Observe yourself, do some introspection on if you would enjoy such roles a few years down the line. I didn&amp;#39;t, not one bit&lt;/li&gt;\n&lt;li&gt;Prepare for being comfortable with ambiguity. With the right amount of effort, ML Models can be built, but tying it to daily business operations especially involving a lot of stakeholders is a much bigger beast. Do you enjoy doing it?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yiddau", "is_robot_indexable": true, "report_reasons": null, "author": "yetanotherruser", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yiddau/companies_in_india_with_good_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yiddau/companies_in_india_with_good_learning/", "subreddit_subscribers": 78529, "created_utc": 1667225654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Undergrad computer science student here, I just want to ask for some suggestions, it is for my capstone project i want my project to be related to data engineering/science/ai/ml because i want my capstone project to be unique, most of the projects i saw is all about web/application development and im not into that field, any suggestions please?\n\nP.s. please notify me if this kind of post is against the community rules. Thank you in advance", "author_fullname": "t2_i8exxe4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj13oe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667285772.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667284740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Undergrad computer science student here, I just want to ask for some suggestions, it is for my capstone project i want my project to be related to data engineering/science/ai/ml because i want my capstone project to be unique, most of the projects i saw is all about web/application development and im not into that field, any suggestions please?&lt;/p&gt;\n\n&lt;p&gt;P.s. please notify me if this kind of post is against the community rules. Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yj13oe", "is_robot_indexable": true, "report_reasons": null, "author": "Initial-Routine4506", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj13oe/suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj13oe/suggestions/", "subreddit_subscribers": 78529, "created_utc": 1667284740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "need help deciding between swe vs de offers\n\nCompany 1: 88k (in person) full stack engineering position. Known for good work life balance. Good tech stack.\n\nCompany 2: 105k (remote) data engineering. not a lot of info on the company online.\n\n\nWould it be a good idea to be specializing so early in my career?", "author_fullname": "t2_c538n31m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on SWE vs DE for first job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yim9sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667244690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;need help deciding between swe vs de offers&lt;/p&gt;\n\n&lt;p&gt;Company 1: 88k (in person) full stack engineering position. Known for good work life balance. Good tech stack.&lt;/p&gt;\n\n&lt;p&gt;Company 2: 105k (remote) data engineering. not a lot of info on the company online.&lt;/p&gt;\n\n&lt;p&gt;Would it be a good idea to be specializing so early in my career?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yim9sf", "is_robot_indexable": true, "report_reasons": null, "author": "poetry1972", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yim9sf/advice_on_swe_vs_de_for_first_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yim9sf/advice_on_swe_vs_de_for_first_job/", "subreddit_subscribers": 78529, "created_utc": 1667244690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Description\n\n\\- How to run multiple ExternalPythonOperator (I need different packages / versions for different DAG tasks) after each other in serial without being dependent on the previous task's success \"upstream\\_fail\".\n\n\\- So it should just execute task after each other without caring about if any of them fails or succeeds.\n\n\\- You might ask than why not just create separate DAG files. The point of this is that I want to run a couple of extremely resource intense task after each other in a very much separate time period than any other tasks to make sure that they don't cause any disruption. They also have to be separated from each other because each one could disrupts each other just based on resource constrains both on the server and for other external reasons as well.\n\n&amp;#x200B;\n\n# My Code\n\n    import logging\n    import os\n    import shutil\n    import sys\n    import tempfile\n    import time\n    from pprint import pprint\n    \n    import pendulum\n    \n    from airflow import DAG\n    from airflow.decorators import task\n    \n    log = logging.getLogger(__name__)\n    PYTHON = sys.executable\n    BASE_DIR = tempfile.gettempdir()\n    \n    \n    my_default_args = {\n        'owner': 'me',\n        #'email': ['myemail@myemail.com'],\n        'email_on_failure': True,\n        #'email_on_retry': True,\n        #'retries': 1,\n    #     'retry_delay': timedelta(minutes=1)\n    }\n    \n    \n    with DAG(\n        dag_id='some_dag_id_comes_here',\n        schedule='1 * * * *', \n        start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"), # this is from whre it starts counting time to run taks, NOT like cron\n        catchup=False,\n        default_args=my_default_args,\n        tags=['xyz1'],\n        ) as dag:\n        u/task.external_python(task_id=\"task1\", python='/opt/airflow/my_env/bin/python3')\n        def func1(): \n            print('elements of task 1')\n            time.sleep(10)\n    \n        u/task.external_python(task_id=\"task2\", python='/opt/airflow/my_env/bin/python3')\n        def func2(): \n            print('elements of task 2')\n            time.sleep(10)\n    \n    \n        task1 &gt;&gt; task2", "author_fullname": "t2_qrm5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[AIRFLOW] - How to Trigger a DAG by another DAG, regardless of the success of a previous DAG in Airflow using Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yis4o5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667301190.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667258285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Description&lt;/h1&gt;\n\n&lt;p&gt;- How to run multiple ExternalPythonOperator (I need different packages / versions for different DAG tasks) after each other in serial without being dependent on the previous task&amp;#39;s success &amp;quot;upstream_fail&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;- So it should just execute task after each other without caring about if any of them fails or succeeds.&lt;/p&gt;\n\n&lt;p&gt;- You might ask than why not just create separate DAG files. The point of this is that I want to run a couple of extremely resource intense task after each other in a very much separate time period than any other tasks to make sure that they don&amp;#39;t cause any disruption. They also have to be separated from each other because each one could disrupts each other just based on resource constrains both on the server and for other external reasons as well.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;My Code&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;import logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport time\nfrom pprint import pprint\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\n\nlog = logging.getLogger(__name__)\nPYTHON = sys.executable\nBASE_DIR = tempfile.gettempdir()\n\n\nmy_default_args = {\n    &amp;#39;owner&amp;#39;: &amp;#39;me&amp;#39;,\n    #&amp;#39;email&amp;#39;: [&amp;#39;myemail@myemail.com&amp;#39;],\n    &amp;#39;email_on_failure&amp;#39;: True,\n    #&amp;#39;email_on_retry&amp;#39;: True,\n    #&amp;#39;retries&amp;#39;: 1,\n#     &amp;#39;retry_delay&amp;#39;: timedelta(minutes=1)\n}\n\n\nwith DAG(\n    dag_id=&amp;#39;some_dag_id_comes_here&amp;#39;,\n    schedule=&amp;#39;1 * * * *&amp;#39;, \n    start_date=pendulum.datetime(2021, 1, 1, tz=&amp;quot;UTC&amp;quot;), # this is from whre it starts counting time to run taks, NOT like cron\n    catchup=False,\n    default_args=my_default_args,\n    tags=[&amp;#39;xyz1&amp;#39;],\n    ) as dag:\n    u/task.external_python(task_id=&amp;quot;task1&amp;quot;, python=&amp;#39;/opt/airflow/my_env/bin/python3&amp;#39;)\n    def func1(): \n        print(&amp;#39;elements of task 1&amp;#39;)\n        time.sleep(10)\n\n    u/task.external_python(task_id=&amp;quot;task2&amp;quot;, python=&amp;#39;/opt/airflow/my_env/bin/python3&amp;#39;)\n    def func2(): \n        print(&amp;#39;elements of task 2&amp;#39;)\n        time.sleep(10)\n\n\n    task1 &amp;gt;&amp;gt; task2\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yis4o5", "is_robot_indexable": true, "report_reasons": null, "author": "glassAlloy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yis4o5/airflow_how_to_trigger_a_dag_by_another_dag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yis4o5/airflow_how_to_trigger_a_dag_by_another_dag/", "subreddit_subscribers": 78529, "created_utc": 1667258285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Know the differences between the two approaches, their distinct applications, and case studies that provide testimony to the company\u2019s success in data management across different domains and industries. Find out more about solutions for resolving dirty data issues through data verification and data validation. \n\nhttps://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;format=pjpg&amp;auto=webp&amp;s=019a8481ade8826fdf06aba1393338ab372840b0", "author_fullname": "t2_t9j61kdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Verification and Data Validation: The Differences and Why You Need It", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"egtua8b28bx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01698d29420423a4f428d14057ca29188b1ef7de"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4bfc1d8aa3c51712c8ebd2a31dd513dd4199248c"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e37d2f4961c101d128458c78c13d35d252fa3330"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c3e2b0020b84408d8f4341d31ba76fd9fde728e"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=45aa9a681ec56cfcf257eecfa00cb871113dec5d"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dac5fd85cca0e0ca4a972556076aa7bc09779dfc"}], "s": {"y": 4246, "x": 1240, "u": "https://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;format=pjpg&amp;auto=webp&amp;s=019a8481ade8826fdf06aba1393338ab372840b0"}, "id": "egtua8b28bx91"}}, "name": "t3_yj47k7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9FcC9D-wH_Qg8KrSMbbgBLxcsv9Xi54_CQaTclBSl9k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667295586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Know the differences between the two approaches, their distinct applications, and case studies that provide testimony to the company\u2019s success in data management across different domains and industries. Find out more about solutions for resolving dirty data issues through data verification and data validation. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=019a8481ade8826fdf06aba1393338ab372840b0\"&gt;https://preview.redd.it/egtua8b28bx91.jpg?width=1240&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=019a8481ade8826fdf06aba1393338ab372840b0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yj47k7", "is_robot_indexable": true, "report_reasons": null, "author": "snehal-joshi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj47k7/data_verification_and_data_validation_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj47k7/data_verification_and_data_validation_the/", "subreddit_subscribers": 78529, "created_utc": 1667295586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nSo I am a bi analyst, do a lot of data architecturing, SQL based ELT and front end visualization. However, i try to branch out an learn new skills like cloud related skills, DBT and obviously python.\nPython seems like a endless pit to me tho and I don't really have usecases at work so I created some scripts over the last months and I feel like I could do this for years and still \"learn\" (which is not bad, I am just wondering how much I should invest before moving on to other skills). I also watched some pep8 and Styleguide videos as to learn proper coding ways and work with git.\nThings I did:\n- Webscrapping, cleaning and saving data to a DB.(pandas, sqlalchemy, pyodbc, beaoutifulsoup)\n\n- Basic apis, cleaning and saving data to a DB.\n(Requests, pandas)\n\n- Using all Json files in a directory, convert and flat them to CSVs. Merge Csvs based on a specific logic.\n\n- Compare product names based on their name likeliness and give similar products the same name.\n\nI would be interested by your input:)", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much python is enough for a beginner?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yj42av", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667295061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;So I am a bi analyst, do a lot of data architecturing, SQL based ELT and front end visualization. However, i try to branch out an learn new skills like cloud related skills, DBT and obviously python.\nPython seems like a endless pit to me tho and I don&amp;#39;t really have usecases at work so I created some scripts over the last months and I feel like I could do this for years and still &amp;quot;learn&amp;quot; (which is not bad, I am just wondering how much I should invest before moving on to other skills). I also watched some pep8 and Styleguide videos as to learn proper coding ways and work with git.\nThings I did:\n- Webscrapping, cleaning and saving data to a DB.(pandas, sqlalchemy, pyodbc, beaoutifulsoup)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Basic apis, cleaning and saving data to a DB.\n(Requests, pandas)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Using all Json files in a directory, convert and flat them to CSVs. Merge Csvs based on a specific logic.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Compare product names based on their name likeliness and give similar products the same name.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would be interested by your input:)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yj42av", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj42av/how_much_python_is_enough_for_a_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj42av/how_much_python_is_enough_for_a_beginner/", "subreddit_subscribers": 78529, "created_utc": 1667295061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently preparing for the Databricks Spark Associate Developer in PySpark. And one thing I'm noticing during my practise tests is that I always get stuck during the questions that ask about passing columns into a method. Even with the documentation available during the exam, I'm almost always choosing the wrong option.\n\nCan someone please help me with the difference between the below two ways of passing columns into a method and how to recognize the separation in the documentation:\n\n* method_name(col(\"colName1\"), col(\"colName2\") .. col(\"colNameN\"))\n\nvs\n\n* method_name(\"colName1\", \"colName2\", \"colName2\")\n\nAre these two types of argument passing not interchangeable? Both of them do work in a SELECT statement. So, my mind keeps thinking they work everywhere. How do I recognize this difference from the documentation?", "author_fullname": "t2_w64oyiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I always get confused between: col(\"colName\") and \"colName\" when passing them into a method. Please help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yix2zw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667272016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently preparing for the Databricks Spark Associate Developer in PySpark. And one thing I&amp;#39;m noticing during my practise tests is that I always get stuck during the questions that ask about passing columns into a method. Even with the documentation available during the exam, I&amp;#39;m almost always choosing the wrong option.&lt;/p&gt;\n\n&lt;p&gt;Can someone please help me with the difference between the below two ways of passing columns into a method and how to recognize the separation in the documentation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;method_name(col(&amp;quot;colName1&amp;quot;), col(&amp;quot;colName2&amp;quot;) .. col(&amp;quot;colNameN&amp;quot;))&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;vs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;method_name(&amp;quot;colName1&amp;quot;, &amp;quot;colName2&amp;quot;, &amp;quot;colName2&amp;quot;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are these two types of argument passing not interchangeable? Both of them do work in a SELECT statement. So, my mind keeps thinking they work everywhere. How do I recognize this difference from the documentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yix2zw", "is_robot_indexable": true, "report_reasons": null, "author": "thebestnobody", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yix2zw/i_always_get_confused_between_colcolname_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yix2zw/i_always_get_confused_between_colcolname_and/", "subreddit_subscribers": 78529, "created_utc": 1667272016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are folk's workflows for deleting or hashing a row or data in an S3 external table?   \n\n\nCurrently I'm thinking the only way to do this is to copy the entire table and transform that row, and then replace the entire table with that new copy of the table. However, that seems extremely inefficient. If there are multiple deletes, we might even need to batch that process up. It also needs to not conflict with new writes on that table.   \n\n\nDoes anyone else have any suggestions on this?", "author_fullname": "t2_5hx4y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deleting particular data from S3 External Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yizqco", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667280233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are folk&amp;#39;s workflows for deleting or hashing a row or data in an S3 external table?   &lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m thinking the only way to do this is to copy the entire table and transform that row, and then replace the entire table with that new copy of the table. However, that seems extremely inefficient. If there are multiple deletes, we might even need to batch that process up. It also needs to not conflict with new writes on that table.   &lt;/p&gt;\n\n&lt;p&gt;Does anyone else have any suggestions on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yizqco", "is_robot_indexable": true, "report_reasons": null, "author": "ShanghaiBebop", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yizqco/deleting_particular_data_from_s3_external_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yizqco/deleting_particular_data_from_s3_external_tables/", "subreddit_subscribers": 78529, "created_utc": 1667280233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thinking explicitly parsing the event data via. JSON key for fields that I want and capturing the measurements - one row per event. Assuming the raw json is accessible in the warehouse for future schema changes.", "author_fullname": "t2_15x3m4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to transform JSON payloads into fact tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yium8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667265007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking explicitly parsing the event data via. JSON key for fields that I want and capturing the measurements - one row per event. Assuming the raw json is accessible in the warehouse for future schema changes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yium8p", "is_robot_indexable": true, "report_reasons": null, "author": "pewpscoops", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yium8p/best_way_to_transform_json_payloads_into_fact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yium8p/best_way_to_transform_json_payloads_into_fact/", "subreddit_subscribers": 78529, "created_utc": 1667265007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI\u2019m not sure which cloud platform to learn between AWS and GCP for data engineering. I don\u2019t have previous IT or cloud experience, but I\u2019m very motivated to learn whatever is necessary for either platform.\n\nThank you in advance!", "author_fullname": "t2_4841f127", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which cloud platform would be best to start learning for a beginner without previous cloud or IT experience, AWS or GCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yil3iw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667242401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not sure which cloud platform to learn between AWS and GCP for data engineering. I don\u2019t have previous IT or cloud experience, but I\u2019m very motivated to learn whatever is necessary for either platform.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yil3iw", "is_robot_indexable": true, "report_reasons": null, "author": "The-Fourth-Hokage", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yil3iw/which_cloud_platform_would_be_best_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yil3iw/which_cloud_platform_would_be_best_to_start/", "subreddit_subscribers": 78529, "created_utc": 1667242401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use AWS managed airflow service to handle our databricks and other scheduled pipelines. Our list of DAGs is really starting to grow and we\u2019d like to add some kind of version control system to our DAG development. Does anyone managed their DAGs in bitbucket? Does anyone have any best practices on how to manage DAGs? Right now each developer uploads their DAGs to an S3 bucket and then activates the DAGs in the Airflow UI when ready for production.  I\u2019m afraid that without versioning these DAGs that anything\u2019s could go wrong if someone uploads an unreviewed file.", "author_fullname": "t2_8y2a4hfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DAG version control process suggestions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yii0l2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667236327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use AWS managed airflow service to handle our databricks and other scheduled pipelines. Our list of DAGs is really starting to grow and we\u2019d like to add some kind of version control system to our DAG development. Does anyone managed their DAGs in bitbucket? Does anyone have any best practices on how to manage DAGs? Right now each developer uploads their DAGs to an S3 bucket and then activates the DAGs in the Airflow UI when ready for production.  I\u2019m afraid that without versioning these DAGs that anything\u2019s could go wrong if someone uploads an unreviewed file.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yii0l2", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Delay7227", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yii0l2/airflow_dag_version_control_process_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yii0l2/airflow_dag_version_control_process_suggestions/", "subreddit_subscribers": 78529, "created_utc": 1667236327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:\n\n1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.\n\n2) Download the mp3 and metadata (date, title, etc.) for the podcast.\n\n3) Process audio using something like WisperAI.\n\n4) Store the data for analytics.\n\n**I'm wondering if anyone has recommendations for the above, specifically steps 1 and 2?** For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?\n\nThanks so much for any assistance here!", "author_fullname": "t2_10ctkxdy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast Audio &amp; Metadata Scraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yj7fps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667305757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a side project and need to download podcast audio for processing and storage. This, roughly, involves the following steps:&lt;/p&gt;\n\n&lt;p&gt;1) Create an automated way to be notified when a new podcast is released. This can be in the form of receiving an HTTP message or even running a CRON job and checking a few times per day.&lt;/p&gt;\n\n&lt;p&gt;2) Download the mp3 and metadata (date, title, etc.) for the podcast.&lt;/p&gt;\n\n&lt;p&gt;3) Process audio using something like WisperAI.&lt;/p&gt;\n\n&lt;p&gt;4) Store the data for analytics.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m wondering if anyone has recommendations for the above, specifically steps 1 and 2?&lt;/strong&gt; For example, do you know of any tools (ex: API) I can leverage with Python to get podcast information daily? Or a reliable way to get high-quality audio files for many different podcasts?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for any assistance here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yj7fps", "is_robot_indexable": true, "report_reasons": null, "author": "beige_coffee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yj7fps/podcast_audio_metadata_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yj7fps/podcast_audio_metadata_scraping/", "subreddit_subscribers": 78529, "created_utc": 1667305757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys any software like [https://datakubes.com/platform](https://datakubes.com/platform/) this? this is like a crud builder it uses php, it connect tru mysql, sql, have docker, etc. Any chance theres something else or alike in the market today?\n\nthank you", "author_fullname": "t2_reu1hc9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any builder like this https://datakubes.com/platform/ ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiw4mu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667269246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys any software like &lt;a href=\"https://datakubes.com/platform/\"&gt;https://datakubes.com/platform&lt;/a&gt; this? this is like a crud builder it uses php, it connect tru mysql, sql, have docker, etc. Any chance theres something else or alike in the market today?&lt;/p&gt;\n\n&lt;p&gt;thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Lu5h7_J4gT1o9h-xJ8ct1n5E19lLVyk0YlJXUkCjR2g.jpg?auto=webp&amp;s=e2887533810fc342b8c96e60f9b797e4584b128b", "width": 104, "height": 112}, "resolutions": [], "variants": {}, "id": "ngXrA2kHe4B0PBrXh3zt19r-S85EQedqV7osen_wHxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yiw4mu", "is_robot_indexable": true, "report_reasons": null, "author": "agaitan026", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yiw4mu/any_builder_like_this_httpsdatakubescomplatform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yiw4mu/any_builder_like_this_httpsdatakubescomplatform/", "subreddit_subscribers": 78529, "created_utc": 1667269246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nAWS re:Invent 2022 is happening soon on November 28th and has tons to offer for everyone from hundreds of sessions, keynotes featuring AWS leadership, and numerous opportunities to connect with the AWS Cloud and Data community.\n\nInspired by this year's KubeCon, we're trying to build an unofficial Slack Community hoping to help bridge the networking gap by providing a platform where we can discuss sessions, share resources and allow members to schedule meetings with other re:Invent 2022 attendees, partners and sponsors. If you or your colleagues will be attending or wish to know more about the event, feel free to join the unofficial slack community here: [https://reinventslack.tech](https://reinventslack.tech)", "author_fullname": "t2_11gy3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS re:Invent 2022 Unofficial Slack Community", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yipzub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667252940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;AWS re:Invent 2022 is happening soon on November 28th and has tons to offer for everyone from hundreds of sessions, keynotes featuring AWS leadership, and numerous opportunities to connect with the AWS Cloud and Data community.&lt;/p&gt;\n\n&lt;p&gt;Inspired by this year&amp;#39;s KubeCon, we&amp;#39;re trying to build an unofficial Slack Community hoping to help bridge the networking gap by providing a platform where we can discuss sessions, share resources and allow members to schedule meetings with other re:Invent 2022 attendees, partners and sponsors. If you or your colleagues will be attending or wish to know more about the event, feel free to join the unofficial slack community here: &lt;a href=\"https://reinventslack.tech\"&gt;https://reinventslack.tech&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?auto=webp&amp;s=03c7d5c5583010be70b1d1ffe007245c54165a1b", "width": 6483, "height": 6483}, "resolutions": [{"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e89e446d32feadd9a270df4adba88c4496f4d0bd", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=94f32ec5faaf0f4ed3224c9612df6983085a6c0e", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d9c5ab99429e5184929117a53e310d7e16a0b93", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c094ddebc4538728959f29348166e8926f1587da", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=17d83b93b186ee0fa0d76dd83c5b2db08e064f99", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/lCclSGS9UTlhvaYf7Z8TjbTMlqLdLiL6cUUIuw3MXkA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bfaf034a76ce3dd48dc9ba4ef8ed2c09759fd4a3", "width": 1080, "height": 1080}], "variants": {}, "id": "KSo-LYNc2BmQbjOmVzLZYxkVAKFZeYGXR9Jtzg9hP9Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yipzub", "is_robot_indexable": true, "report_reasons": null, "author": "Sunb3am", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yipzub/aws_reinvent_2022_unofficial_slack_community/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yipzub/aws_reinvent_2022_unofficial_slack_community/", "subreddit_subscribers": 78529, "created_utc": 1667252940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am interested in the data economy  (https://en.m.wikipedia.org/wiki/Data_economy).  Can anybody recommend a book or article about the value of data and how the data is gathered, organized, and\u00a0exchanged\u00a0by a network of vendors as mentioned in the Wikipedia article.  Thanks for your help.", "author_fullname": "t2_rut8e7pb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data economics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yinugv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667247858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in the data economy  (&lt;a href=\"https://en.m.wikipedia.org/wiki/Data_economy\"&gt;https://en.m.wikipedia.org/wiki/Data_economy&lt;/a&gt;).  Can anybody recommend a book or article about the value of data and how the data is gathered, organized, and\u00a0exchanged\u00a0by a network of vendors as mentioned in the Wikipedia article.  Thanks for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yinugv", "is_robot_indexable": true, "report_reasons": null, "author": "Slight-Food-1151", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yinugv/data_economics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yinugv/data_economics/", "subreddit_subscribers": 78529, "created_utc": 1667247858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I would like to say a big thank you to this community for the daily dose of knowledge and the fun with it.... So I have a task and I am really close the deadline, so here it goes:\n\nSo there is a software(Ignition Maker) that is automating the pulling of the data from the IOT sensors and loading them into a Postgres DB.... now it turns out that the software they are using is creating some other tables which refer to the IOT sensors tagid and some other columns that contain metadata about the sensors....so If I am to get information about a particular device, I will have to do some joins which led me to create a VIEW. Now the thing is, the software that automates the pulling of the data, creates a different table automatically per month so that I can have a better understanding of the values that are generated and to also help for future analysis....\n\nNow, things to note, having to always do a JOIN to get the information I need is stressful, plus I think, it will even slow down the query time as the data expands and I currently have more than a million rows....\n\nSo my plan is to do a data model, in which I have a new database with new tables  that are redefined with tables that are NORMALIZED and have a better structure, so I can query them easily and most likely will have reduced JOINS...\n\nPlus I have to create interactive reports in which a user has a GUI where they can click on the list of IOT devices and select one of them and automatically they can see a bar or column graph of the highest value generated in all the week for that month.\n\n1. What do you think about this process?\n\n2. I am trying to see how I can do an ETL to achieve the live dumping of the data or query I will write to pull the data from the original db into my redifined Database\n\n&amp;#x200B;\n\nAlso: Part of the requirement is to  have a live backup or replication of the database but this is separate from this original problem stated above BUT I plan to just do a Master/Slave replication for that... BUT the pressing issue is having to pull the data and create live interactive reports, in which the user can select the timeframe he wants to set and see the values e.g I can check for data for  a device within September 15th to present and I just get a very nice report of the values.\n\n&amp;#x200B;\n\nPlease Help, I need suggestions and how I can go about this efficiently... Thank you", "author_fullname": "t2_mklzceft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating interactive and LIVE reports from IOT Sonsor data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yigtym", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667233714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I would like to say a big thank you to this community for the daily dose of knowledge and the fun with it.... So I have a task and I am really close the deadline, so here it goes:&lt;/p&gt;\n\n&lt;p&gt;So there is a software(Ignition Maker) that is automating the pulling of the data from the IOT sensors and loading them into a Postgres DB.... now it turns out that the software they are using is creating some other tables which refer to the IOT sensors tagid and some other columns that contain metadata about the sensors....so If I am to get information about a particular device, I will have to do some joins which led me to create a VIEW. Now the thing is, the software that automates the pulling of the data, creates a different table automatically per month so that I can have a better understanding of the values that are generated and to also help for future analysis....&lt;/p&gt;\n\n&lt;p&gt;Now, things to note, having to always do a JOIN to get the information I need is stressful, plus I think, it will even slow down the query time as the data expands and I currently have more than a million rows....&lt;/p&gt;\n\n&lt;p&gt;So my plan is to do a data model, in which I have a new database with new tables  that are redefined with tables that are NORMALIZED and have a better structure, so I can query them easily and most likely will have reduced JOINS...&lt;/p&gt;\n\n&lt;p&gt;Plus I have to create interactive reports in which a user has a GUI where they can click on the list of IOT devices and select one of them and automatically they can see a bar or column graph of the highest value generated in all the week for that month.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What do you think about this process?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am trying to see how I can do an ETL to achieve the live dumping of the data or query I will write to pull the data from the original db into my redifined Database&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also: Part of the requirement is to  have a live backup or replication of the database but this is separate from this original problem stated above BUT I plan to just do a Master/Slave replication for that... BUT the pressing issue is having to pull the data and create live interactive reports, in which the user can select the timeframe he wants to set and see the values e.g I can check for data for  a device within September 15th to present and I just get a very nice report of the values.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please Help, I need suggestions and how I can go about this efficiently... Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yigtym", "is_robot_indexable": true, "report_reasons": null, "author": "deedatagod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yigtym/creating_interactive_and_live_reports_from_iot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yigtym/creating_interactive_and_live_reports_from_iot/", "subreddit_subscribers": 78529, "created_utc": 1667233714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am writing a few dataframes (spark, scala) and it would be great if I could see the schema of the frames at compile time. I am assuming this is possible since scala is a statically typed language, but I might be wrong.\n\nIdeally it'd show me the schema once Intellij is done with compiling so that I don't have to execute the program every time I want to check that I haven't made a mistake.\n\n&amp;#x200B;\n\nHappy about any pointers and sorry if this is a stupid question.", "author_fullname": "t2_mxg4sp1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a plugin/way to show the schema of the dataframe I am creating at compile time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yidim7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667226014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am writing a few dataframes (spark, scala) and it would be great if I could see the schema of the frames at compile time. I am assuming this is possible since scala is a statically typed language, but I might be wrong.&lt;/p&gt;\n\n&lt;p&gt;Ideally it&amp;#39;d show me the schema once Intellij is done with compiling so that I don&amp;#39;t have to execute the program every time I want to check that I haven&amp;#39;t made a mistake.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Happy about any pointers and sorry if this is a stupid question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yidim7", "is_robot_indexable": true, "report_reasons": null, "author": "BlereTech", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yidim7/is_there_a_pluginway_to_show_the_schema_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yidim7/is_there_a_pluginway_to_show_the_schema_of_the/", "subreddit_subscribers": 78529, "created_utc": 1667226014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm interested in the Databricks Certification exams, especially for Data Engineering but they seem a bit too costy for personal reasons. Are there any Vouchers or any discounts events like Microsoft Ignite for Azure? At least I couldn't find similiar events through searching.\n\nAlready thanks and best regards!", "author_fullname": "t2_bgbrbly9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any Databricks Certification Vouchers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yiddn5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667225679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in the Databricks Certification exams, especially for Data Engineering but they seem a bit too costy for personal reasons. Are there any Vouchers or any discounts events like Microsoft Ignite for Azure? At least I couldn&amp;#39;t find similiar events through searching.&lt;/p&gt;\n\n&lt;p&gt;Already thanks and best regards!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yiddn5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Inspection3886", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yiddn5/are_there_any_databricks_certification_vouchers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yiddn5/are_there_any_databricks_certification_vouchers/", "subreddit_subscribers": 78529, "created_utc": 1667225679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to find a better living in this third world country. Is it even possible to get a remote job in first world country and they are willing to pay maybe half of the average market salary there for someone from third world country as a junior data engineer? Or do I need at least a senior or more level? $40k is really life-changing for me.", "author_fullname": "t2_tm5irceo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job for Third World Country with First World Country Company and Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yie5al", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667227523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to find a better living in this third world country. Is it even possible to get a remote job in first world country and they are willing to pay maybe half of the average market salary there for someone from third world country as a junior data engineer? Or do I need at least a senior or more level? $40k is really life-changing for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yie5al", "is_robot_indexable": true, "report_reasons": null, "author": "natas_m", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yie5al/job_for_third_world_country_with_first_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yie5al/job_for_third_world_country_with_first_world/", "subreddit_subscribers": 78529, "created_utc": 1667227523.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}