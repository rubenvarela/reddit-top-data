{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it illegal to web-scrape interest rates from banks? What if I am trying to understand historical pricing of investment/insurance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzeyqw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 145, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 145, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668873157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzeyqw", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzeyqw/is_it_illegal_to_webscrape_interest_rates_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzeyqw/is_it_illegal_to_webscrape_interest_rates_from/", "subreddit_subscribers": 820437, "created_utc": 1668873157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR - this is a throwaway rant. Ignore as you see fit.\n\n&amp;#x200B;\n\n`Begin rant`\n\n&amp;#x200B;\n\nSAS is trash and needs to be cast down into a pit, never to be thought of ever again.\n\n&amp;#x200B;\n\nExcel is trash for everything except sending files to people who are too busy/important/unmotivated to do better.\n\n&amp;#x200B;\n\nPutting thousands of lines of \"production code\" in Jupyter notebooks is trash. Well-structured code with comments, sane variable names and AT A MINIMUM SOME KIND OF UNIT TESTS should be baseline.\n\n&amp;#x200B;\n\nIf you never have time to write documentation or have code reviews but then complain that no one can help you with your OH SO COMPLEX processes, you deserve your self-inflicted pain.\n\n&amp;#x200B;\n\nIf your idea of version control is to have a directory full of the same file with cryptic names like v2, v2final, v2final\\_fixed, etc then for the love of God please take an afternoon to learn the basics of git.\n\n&amp;#x200B;\n\n`End rant`\n\n&amp;#x200B;\n\n*May your downvotes blot out the sun...*", "author_fullname": "t2_ueedxhac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fed up with bad practices (throwaway rant)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yz0ywt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668823672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR - this is a throwaway rant. Ignore as you see fit.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Begin rant&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SAS is trash and needs to be cast down into a pit, never to be thought of ever again.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Excel is trash for everything except sending files to people who are too busy/important/unmotivated to do better.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Putting thousands of lines of &amp;quot;production code&amp;quot; in Jupyter notebooks is trash. Well-structured code with comments, sane variable names and AT A MINIMUM SOME KIND OF UNIT TESTS should be baseline.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you never have time to write documentation or have code reviews but then complain that no one can help you with your OH SO COMPLEX processes, you deserve your self-inflicted pain.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If your idea of version control is to have a directory full of the same file with cryptic names like v2, v2final, v2final_fixed, etc then for the love of God please take an afternoon to learn the basics of git.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;End rant&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;May your downvotes blot out the sun...&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yz0ywt", "is_robot_indexable": true, "report_reasons": null, "author": "datsci_throwaway", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yz0ywt/fed_up_with_bad_practices_throwaway_rant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yz0ywt/fed_up_with_bad_practices_throwaway_rant/", "subreddit_subscribers": 820437, "created_utc": 1668823672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Firstly I want to apologize if any of my questions seem obvious or dumb. I'm still doing a lot of learning in this field so I would still appreciate any help I can get, even if the answer is obvious. I'm not sure if this belongs in stack overflow or not, but I thought I would give it a try here. \n\n&amp;#x200B;\n\nMy understanding for clustering has always been that you never need to split the data to training and testing since you don't have any labels or are ignoring the labels. But from some recent reading that I have done online, I see that some people are saying that train/test splitting is still necessary for some clustering algorithms (those that generate centroids). So I just have some scenarios listed below, and I was hoping if some people could help me better understand what I have done wrong in those scenarios and what I need to do to fix it.\n\n&amp;#x200B;\n\nFor all scenarios, my dataset is 95% unlabeled and 5% labeled, with 2 features. There has also been some scaling done on the dataset entirely prior to these scenarios. I know you're supposed to train/test split before scaling, but again, I thought you don't need to split for clustering.\n\n&amp;#x200B;\n\n**Scenario 1**\n\nUsing sklearn.cluster.KMeans, I ran KMeans on the dataset via the fit\\_predict() method. Then for the 5% of the labeled data, I use the clusters that were returned and compare it to the labels I have to see how close the clusters are to the labels. I now feel that what I have done now is incorrect because the method introduces data leakage. Was I supposed to train/test split first with the unlabeled/labeled data, then do the scaling separately, then fit() on the unlabeled data, then predict() on the labeled data?\n\n&amp;#x200B;\n\n**Scenario 2**\n\nUsing scipy.cluster.hierarchy.linkage, I ran linkage on the dataset to get my linkage array. I drew the dendrogram, selected a distance cutoff point and saw how many clusters I would get, and generated the cluster labels via the fcluster method. Then for the 5% of the labeled data, I use the clusters that were returned and compare it to the labels I have to see how close the clusters are to the labels. Am I doing anything wrong in this situation so far? I'm not sure what my next steps are from here. Since hierarchical clustering doesn't generate any centroids, how can it be used to properly classify/predict data?\n\n&amp;#x200B;\n\nThank you.", "author_fullname": "t2_srahw2ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confusion with using clustering algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yz1ajp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668824718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Firstly I want to apologize if any of my questions seem obvious or dumb. I&amp;#39;m still doing a lot of learning in this field so I would still appreciate any help I can get, even if the answer is obvious. I&amp;#39;m not sure if this belongs in stack overflow or not, but I thought I would give it a try here. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My understanding for clustering has always been that you never need to split the data to training and testing since you don&amp;#39;t have any labels or are ignoring the labels. But from some recent reading that I have done online, I see that some people are saying that train/test splitting is still necessary for some clustering algorithms (those that generate centroids). So I just have some scenarios listed below, and I was hoping if some people could help me better understand what I have done wrong in those scenarios and what I need to do to fix it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For all scenarios, my dataset is 95% unlabeled and 5% labeled, with 2 features. There has also been some scaling done on the dataset entirely prior to these scenarios. I know you&amp;#39;re supposed to train/test split before scaling, but again, I thought you don&amp;#39;t need to split for clustering.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Scenario 1&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Using sklearn.cluster.KMeans, I ran KMeans on the dataset via the fit_predict() method. Then for the 5% of the labeled data, I use the clusters that were returned and compare it to the labels I have to see how close the clusters are to the labels. I now feel that what I have done now is incorrect because the method introduces data leakage. Was I supposed to train/test split first with the unlabeled/labeled data, then do the scaling separately, then fit() on the unlabeled data, then predict() on the labeled data?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Scenario 2&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Using scipy.cluster.hierarchy.linkage, I ran linkage on the dataset to get my linkage array. I drew the dendrogram, selected a distance cutoff point and saw how many clusters I would get, and generated the cluster labels via the fcluster method. Then for the 5% of the labeled data, I use the clusters that were returned and compare it to the labels I have to see how close the clusters are to the labels. Am I doing anything wrong in this situation so far? I&amp;#39;m not sure what my next steps are from here. Since hierarchical clustering doesn&amp;#39;t generate any centroids, how can it be used to properly classify/predict data?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yz1ajp", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Mark-1360", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yz1ajp/confusion_with_using_clustering_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yz1ajp/confusion_with_using_clustering_algorithms/", "subreddit_subscribers": 820437, "created_utc": 1668824718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Awash in a sea of data, China authorities are trying to police the future.\n\nIt's not sci fi. Using vast data records on citizens, new software uses scoring and AI to predict crime and protest before they happen. Often the result is automated prejudice.\n\n\nhttps://www.nytimes.com/2022/06/25/technology/china-surveillance-police.html", "author_fullname": "t2_cb9r20lv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Awash in a sea of data, China authorities are trying to police the future", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yznxom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668896896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Awash in a sea of data, China authorities are trying to police the future.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not sci fi. Using vast data records on citizens, new software uses scoring and AI to predict crime and protest before they happen. Often the result is automated prejudice.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.nytimes.com/2022/06/25/technology/china-surveillance-police.html\"&gt;https://www.nytimes.com/2022/06/25/technology/china-surveillance-police.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FZFzla_Ius-GrNPJLR_h_jjLrp3tjUlJpT58OtYgzGY.jpg?auto=webp&amp;s=824195cf92f063bd1bed326e7fd4427abed4bf4c", "width": 1050, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/FZFzla_Ius-GrNPJLR_h_jjLrp3tjUlJpT58OtYgzGY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85230cc8a79c36d79b4a4552e80a862c724bea85", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/FZFzla_Ius-GrNPJLR_h_jjLrp3tjUlJpT58OtYgzGY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b15dd950776b10617f99f909ed928ee96c17f262", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/FZFzla_Ius-GrNPJLR_h_jjLrp3tjUlJpT58OtYgzGY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7584c1c2a810e5eb2cd472ed29fc5dd06b6e4170", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/FZFzla_Ius-GrNPJLR_h_jjLrp3tjUlJpT58OtYgzGY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5464e70c25d4117735a540ccd7adec33f61ea299", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/FZFzla_Ius-GrNPJLR_h_jjLrp3tjUlJpT58OtYgzGY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5922f560d778567b5db17274dea570ea29a31a99", "width": 960, "height": 502}], "variants": {}, "id": "YDXFbo6d6kApuU3ssym8xG6MXVUhY8hKoGvlSXnKi3M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yznxom", "is_robot_indexable": true, "report_reasons": null, "author": "Top_Primary9371", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yznxom/awash_in_a_sea_of_data_china_authorities_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yznxom/awash_in_a_sea_of_data_china_authorities_are/", "subreddit_subscribers": 820437, "created_utc": 1668896896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello. I did search on the community but did not find much information about this subject. I would like to discuss with you the importance of adopting a platform for ML projects life cycle and whether the platform might be really a block for junior practitioners. \n\nFor more than two decades CRISP-DM was the de-facto standard for data science process life cycle. There was other alternatives but it seems it gained popularity as it covers the end to end steps and it was simple to adopt. IBM was pushing it as well. \n\nIn 2016, Microsoft proposed a new variant of CRISP-DM called TDSP (Team Data Science Process) but for reasons that I do not know, it did not become an alternative for CRISP-DM on the market.  In 2021-2022, Azure, AWSm and GCP (maybe others) embraced MLOps.\n\nI have some questions for long time data scientists please. How important for your practice is to adopt a life cycle process? \n\nIs anyone still using CRISP-DM at the enterprise level? Any large enterprise adopted TDSP? \n\nAlthough MLOps might have some deficiencies, do you think it will be the new CRISP for the coming years?", "author_fullname": "t2_4sldj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Machine Learning Life Cycle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yznq5b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668896310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I did search on the community but did not find much information about this subject. I would like to discuss with you the importance of adopting a platform for ML projects life cycle and whether the platform might be really a block for junior practitioners. &lt;/p&gt;\n\n&lt;p&gt;For more than two decades CRISP-DM was the de-facto standard for data science process life cycle. There was other alternatives but it seems it gained popularity as it covers the end to end steps and it was simple to adopt. IBM was pushing it as well. &lt;/p&gt;\n\n&lt;p&gt;In 2016, Microsoft proposed a new variant of CRISP-DM called TDSP (Team Data Science Process) but for reasons that I do not know, it did not become an alternative for CRISP-DM on the market.  In 2021-2022, Azure, AWSm and GCP (maybe others) embraced MLOps.&lt;/p&gt;\n\n&lt;p&gt;I have some questions for long time data scientists please. How important for your practice is to adopt a life cycle process? &lt;/p&gt;\n\n&lt;p&gt;Is anyone still using CRISP-DM at the enterprise level? Any large enterprise adopted TDSP? &lt;/p&gt;\n\n&lt;p&gt;Although MLOps might have some deficiencies, do you think it will be the new CRISP for the coming years?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yznq5b", "is_robot_indexable": true, "report_reasons": null, "author": "bilalak", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yznq5b/machine_learning_life_cycle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yznq5b/machine_learning_life_cycle/", "subreddit_subscribers": 820437, "created_utc": 1668896310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand that in the case of K-means algorithn, we can use Silhouette Score to find the optimal cluster number.\n\nLet's say I want to use other clustering algorithms such as DBSCAN or Hierarchical Clustering. Can I use Silhouette Score to choose which clustering method performs best?\n\nThanks!", "author_fullname": "t2_dnekp18a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it reasonable to compare different clustering algorithms using Silhouette Score?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzir4v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668883022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that in the case of K-means algorithn, we can use Silhouette Score to find the optimal cluster number.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I want to use other clustering algorithms such as DBSCAN or Hierarchical Clustering. Can I use Silhouette Score to choose which clustering method performs best?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzir4v", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Deer8805", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzir4v/is_it_reasonable_to_compare_different_clustering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzir4v/is_it_reasonable_to_compare_different_clustering/", "subreddit_subscribers": 820437, "created_utc": 1668883022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It seems like every position for all data science related research positions are reserved for either people with doctorates or people who are pursuing one. Are there any ways to break into a research position with only a bachelors? I generally dislike working on \"business problems\" and want to have the opportunity to work on something more grand", "author_fullname": "t2_3pk73i4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are all research scientist positions reserved for PhDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yzqoer", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668904588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems like every position for all data science related research positions are reserved for either people with doctorates or people who are pursuing one. Are there any ways to break into a research position with only a bachelors? I generally dislike working on &amp;quot;business problems&amp;quot; and want to have the opportunity to work on something more grand&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yzqoer", "is_robot_indexable": true, "report_reasons": null, "author": "Sabrina_Morningstar", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzqoer/are_all_research_scientist_positions_reserved_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzqoer/are_all_research_scientist_positions_reserved_for/", "subreddit_subscribers": 820437, "created_utc": 1668904588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I was wondering if anyone knows a good implementation of a map matching algorithm in python that handles the coordinates of a vehicle's trajectory and returns them corrected. Thanks in advance!", "author_fullname": "t2_mxv861x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Map matching with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzofuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668898293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I was wondering if anyone knows a good implementation of a map matching algorithm in python that handles the coordinates of a vehicle&amp;#39;s trajectory and returns them corrected. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzofuq", "is_robot_indexable": true, "report_reasons": null, "author": "jejdudididjd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzofuq/map_matching_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzofuq/map_matching_with_python/", "subreddit_subscribers": 820437, "created_utc": 1668898293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a problem for fun and to add to my portfolio involving the public Stack Overflow dataset. I am trying to predict whether a question will receive an accepted answer using the body text, title, and post tags. Roughly 51% of all posts have an accepted answer so the data is nicely balanced.\n\nI cleaned the text by getting rid of HTML tags and code chunks, while retaining some of that info with counts and booleans and added some additional basic features (body length, number of sentences, number of code blocks, day of week, hour of day, etc.)\n\nI tried using Tfidf on the body text with only incremental improvement over a model with base features.  After learning more about Doc2vec I gave that a try with no improvement over Tfidf. \n\nI find it hard to believe that the title, tags, and body text have no information that would lend to better prediction accuracy. Am I approaching the problem the wrong way or is NLP just not the right tool in this situation?\n\nFwiw - I'm using grid search to optimize along the way (classification algo, Tfidf/Doc2vec params, etc.) and taking different sized samples from 10k-5M with samples larger than 100k generally not increasing accuracy. I'm also using CV for training then refitting on a test set with best params.", "author_fullname": "t2_12tp8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stuck on a text classification problem - Tfidf/Doc2vec not helping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzmtda", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668893832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a problem for fun and to add to my portfolio involving the public Stack Overflow dataset. I am trying to predict whether a question will receive an accepted answer using the body text, title, and post tags. Roughly 51% of all posts have an accepted answer so the data is nicely balanced.&lt;/p&gt;\n\n&lt;p&gt;I cleaned the text by getting rid of HTML tags and code chunks, while retaining some of that info with counts and booleans and added some additional basic features (body length, number of sentences, number of code blocks, day of week, hour of day, etc.)&lt;/p&gt;\n\n&lt;p&gt;I tried using Tfidf on the body text with only incremental improvement over a model with base features.  After learning more about Doc2vec I gave that a try with no improvement over Tfidf. &lt;/p&gt;\n\n&lt;p&gt;I find it hard to believe that the title, tags, and body text have no information that would lend to better prediction accuracy. Am I approaching the problem the wrong way or is NLP just not the right tool in this situation?&lt;/p&gt;\n\n&lt;p&gt;Fwiw - I&amp;#39;m using grid search to optimize along the way (classification algo, Tfidf/Doc2vec params, etc.) and taking different sized samples from 10k-5M with samples larger than 100k generally not increasing accuracy. I&amp;#39;m also using CV for training then refitting on a test set with best params.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzmtda", "is_robot_indexable": true, "report_reasons": null, "author": "Pepperoneous", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzmtda/stuck_on_a_text_classification_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzmtda/stuck_on_a_text_classification_problem/", "subreddit_subscribers": 820437, "created_utc": 1668893832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Has anyone here found a good method to shift an organization\u2019s A/B testing metric from revenue to net or ROI? Btw I work in direct mail which means super low response rates and right tailed revenue distributions.", "author_fullname": "t2_tj7ftssc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B testing - shift from Revenue to Net", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzkmod", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668887995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here found a good method to shift an organization\u2019s A/B testing metric from revenue to net or ROI? Btw I work in direct mail which means super low response rates and right tailed revenue distributions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzkmod", "is_robot_indexable": true, "report_reasons": null, "author": "Frequent-Lemon-1136", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzkmod/ab_testing_shift_from_revenue_to_net/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzkmod/ab_testing_shift_from_revenue_to_net/", "subreddit_subscribers": 820437, "created_utc": 1668887995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been at a Big Four consulting firm for two years. I've been on several projects and have great relationships with previous PMs. \n\nFor various reasons I've decided to search for a new job entirely (I also hate my current project after just two months). \n\nI could get references from a previous employer but that aside, is it bad to ask previous PMs from current firm for a reference? I know they would in general/in the future. This firm is so big they most likely don't know the people on my current project. \n\nAnyway just wondering if there's a protocol for that.", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it weird to ask previous managers in current company for a reference when job searching?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzj2wz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668883890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been at a Big Four consulting firm for two years. I&amp;#39;ve been on several projects and have great relationships with previous PMs. &lt;/p&gt;\n\n&lt;p&gt;For various reasons I&amp;#39;ve decided to search for a new job entirely (I also hate my current project after just two months). &lt;/p&gt;\n\n&lt;p&gt;I could get references from a previous employer but that aside, is it bad to ask previous PMs from current firm for a reference? I know they would in general/in the future. This firm is so big they most likely don&amp;#39;t know the people on my current project. &lt;/p&gt;\n\n&lt;p&gt;Anyway just wondering if there&amp;#39;s a protocol for that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yzj2wz", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzj2wz/is_it_weird_to_ask_previous_managers_in_current/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzj2wz/is_it_weird_to_ask_previous_managers_in_current/", "subreddit_subscribers": 820437, "created_utc": 1668883890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nI was working on a kaggle competition doing a simple classification problem with lightGBM. On the public leaderboard I was 1/18 (.004 ahead of #2) but dropped to 6/15 (and .01 behind the used to be #2) on the private leaderboard. Im trying to figure out how this happened. Did I overfit to the kaggle test set? I noticed my earlier submissions (like from 2 weeks ago) did the best. Can someone give me a pointer? How can I avoid something like this from happening again? Thanks", "author_fullname": "t2_qvszerk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bummer in kaggle competition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzkeoj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668887389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I was working on a kaggle competition doing a simple classification problem with lightGBM. On the public leaderboard I was 1/18 (.004 ahead of #2) but dropped to 6/15 (and .01 behind the used to be #2) on the private leaderboard. Im trying to figure out how this happened. Did I overfit to the kaggle test set? I noticed my earlier submissions (like from 2 weeks ago) did the best. Can someone give me a pointer? How can I avoid something like this from happening again? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzkeoj", "is_robot_indexable": true, "report_reasons": null, "author": "packagemanagers", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzkeoj/bummer_in_kaggle_competition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yzkeoj/bummer_in_kaggle_competition/", "subreddit_subscribers": 820437, "created_utc": 1668887389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_s7gus2pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does my research poster look so far? harsh criticism welcome \ud83e\udee3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_yzr4w3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/W-i8WpcXT358JNPY8SgmhSCKPIcw9cF60LI3WDTmlp4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668905974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6soa7blaq11a1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6soa7blaq11a1.jpg?auto=webp&amp;s=a0dac464baee6e45af953ddeaef246270e666020", "width": 1080, "height": 1920}, "resolutions": [{"url": "https://preview.redd.it/6soa7blaq11a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ee3599d3f393fe6316fa04cc05f9d0c5405e841", "width": 108, "height": 192}, {"url": "https://preview.redd.it/6soa7blaq11a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1962448cdda7ed9aa5f451434315eca5978ec553", "width": 216, "height": 384}, {"url": "https://preview.redd.it/6soa7blaq11a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8570f6107417b130d9588ded83de9637a8505b6", "width": 320, "height": 568}, {"url": "https://preview.redd.it/6soa7blaq11a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aba93a41f4d246bfcd32dd08d2cb5a321e7e12e9", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/6soa7blaq11a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2b87e8d383485075921a92570f43f3c14d2ecc5", "width": 960, "height": 1706}, {"url": "https://preview.redd.it/6soa7blaq11a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87c5092798ac404d328efb20520655ca2099c92b", "width": 1080, "height": 1920}], "variants": {}, "id": "B16gt8aTzg7Wagpw0Y-uvz_q-ilUxlvv-NPHH4RZSe4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yzr4w3", "is_robot_indexable": true, "report_reasons": null, "author": "ForeskinPenisEnvy", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yzr4w3/how_does_my_research_poster_look_so_far_harsh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6soa7blaq11a1.jpg", "subreddit_subscribers": 820437, "created_utc": 1668905974.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}