{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd love to hear how you all are approaching testing in the context of a data pipeline.\n\nEnd to end, unit testing, data quality... How do you validate the pipeline is doing what it should be doing?", "author_fullname": "t2_17dbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yystx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668800912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d love to hear how you all are approaching testing in the context of a data pipeline.&lt;/p&gt;\n\n&lt;p&gt;End to end, unit testing, data quality... How do you validate the pipeline is doing what it should be doing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yystx2", "is_robot_indexable": true, "report_reasons": null, "author": "killermouse0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yystx2/testing_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yystx2/testing_best_practices/", "subreddit_subscribers": 80383, "created_utc": 1668800912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019re currently using databricks for production ETL pipelines with notebooks and  finding it really hard when it comes to debugging and reusing code. Wondering if there\u2019s any alternatives people have come up with?", "author_fullname": "t2_biiuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those who use Databricks, do you use notebooks in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyzzfb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668820547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019re currently using databricks for production ETL pipelines with notebooks and  finding it really hard when it comes to debugging and reusing code. Wondering if there\u2019s any alternatives people have come up with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyzzfb", "is_robot_indexable": true, "report_reasons": null, "author": "shadyjezzboxx", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyzzfb/for_those_who_use_databricks_do_you_use_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyzzfb/for_those_who_use_databricks_do_you_use_notebooks/", "subreddit_subscribers": 80383, "created_utc": 1668820547.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a data engineer for 4 years now in tier 1 big tech, a startup and a FAANG. \n\nWe didn\u2019t have a separate test environment that\u2019s used solely for testing. Usually we write the processed data into a staging table in prod, run quality checks (like range checks, percent of missing values, percent of null values, etc) and if the validations pass, we write it into a prod table.\n\nThe idea is, we don\u2019t have a separate testing infrastructure. Staging tables in prod environmental and prod tables in prod environment. \n\nIs this the common practice!? Or do you all have long running testing infrastructure (environments) managed forever?!", "author_fullname": "t2_8r6amwln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you test your ETL pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yz4gtw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668835639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a data engineer for 4 years now in tier 1 big tech, a startup and a FAANG. &lt;/p&gt;\n\n&lt;p&gt;We didn\u2019t have a separate test environment that\u2019s used solely for testing. Usually we write the processed data into a staging table in prod, run quality checks (like range checks, percent of missing values, percent of null values, etc) and if the validations pass, we write it into a prod table.&lt;/p&gt;\n\n&lt;p&gt;The idea is, we don\u2019t have a separate testing infrastructure. Staging tables in prod environmental and prod tables in prod environment. &lt;/p&gt;\n\n&lt;p&gt;Is this the common practice!? Or do you all have long running testing infrastructure (environments) managed forever?!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yz4gtw", "is_robot_indexable": true, "report_reasons": null, "author": "money_noob_007", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yz4gtw/how_do_you_test_your_etl_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yz4gtw/how_do_you_test_your_etl_pipelines/", "subreddit_subscribers": 80383, "created_utc": 1668835639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We all know that on paper AWS is the biggest player and is very popular in the US. But I was wondering how it actually looks in the UE; what is your recent experience, either at your job or talking to other colleagues? Which provider is the \u201chot topic\u201d in countries such as Netherlands, Germany, Poland? Let me know, I\u2019m really curious! Recently every time I discuss this topic with friends I hear about companies moving to Azure, while AWS seems to be mentioned as rarely as GCP. Really curious to hear your experience lately in the EU!", "author_fullname": "t2_ihek8y8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud in Europe for 2023: Azure vs AWS vs GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyxr9n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668813985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We all know that on paper AWS is the biggest player and is very popular in the US. But I was wondering how it actually looks in the UE; what is your recent experience, either at your job or talking to other colleagues? Which provider is the \u201chot topic\u201d in countries such as Netherlands, Germany, Poland? Let me know, I\u2019m really curious! Recently every time I discuss this topic with friends I hear about companies moving to Azure, while AWS seems to be mentioned as rarely as GCP. Really curious to hear your experience lately in the EU!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyxr9n", "is_robot_indexable": true, "report_reasons": null, "author": "absurdherowaw", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyxr9n/cloud_in_europe_for_2023_azure_vs_aws_vs_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyxr9n/cloud_in_europe_for_2023_azure_vs_aws_vs_gcp/", "subreddit_subscribers": 80383, "created_utc": 1668813985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A lot of questions seems to be more oriented towards software engineers, like graph traversals and dynamic programming.\n\n\n\n\nMy experience interviewing for my data engineering job (well funded startup) has been easier python questions not found on Leetcode, like string manipulations and easy questions using a python dictionary.\n\n\n\nSince that is just one company, I wasn't sure how representative that is of all data engineering jobs.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to properly study python leetcode questions for data engineering interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yze61a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668871040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A lot of questions seems to be more oriented towards software engineers, like graph traversals and dynamic programming.&lt;/p&gt;\n\n&lt;p&gt;My experience interviewing for my data engineering job (well funded startup) has been easier python questions not found on Leetcode, like string manipulations and easy questions using a python dictionary.&lt;/p&gt;\n\n&lt;p&gt;Since that is just one company, I wasn&amp;#39;t sure how representative that is of all data engineering jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yze61a", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yze61a/how_to_properly_study_python_leetcode_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yze61a/how_to_properly_study_python_leetcode_questions/", "subreddit_subscribers": 80383, "created_utc": 1668871040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anybody here at a public company have to deal with SOX compliance and audits? Some of the requirements just seem like best practice, but others make working on the day to day quite cumbersome. Trying to find a good balance here.", "author_fullname": "t2_zblmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SOX compliance woes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yys6kl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668799238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody here at a public company have to deal with SOX compliance and audits? Some of the requirements just seem like best practice, but others make working on the day to day quite cumbersome. Trying to find a good balance here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yys6kl", "is_robot_indexable": true, "report_reasons": null, "author": "anxious_adhd_maybe", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yys6kl/sox_compliance_woes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yys6kl/sox_compliance_woes/", "subreddit_subscribers": 80383, "created_utc": 1668799238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If anyone wants to take a break from watching Twitter meltdown, here is a list of certifications related to databases and data engineering.....\n\n [Database Certification List - Advanced SQL Puzzles](https://advancedsqlpuzzles.com/2022/11/18/database-certification-list/)", "author_fullname": "t2_4d58zyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of Database related certifications here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyvab1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668807375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone wants to take a break from watching Twitter meltdown, here is a list of certifications related to databases and data engineering.....&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://advancedsqlpuzzles.com/2022/11/18/database-certification-list/\"&gt;Database Certification List - Advanced SQL Puzzles&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yyvab1", "is_robot_indexable": true, "report_reasons": null, "author": "sequel-beagle", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyvab1/list_of_database_related_certifications_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyvab1/list_of_database_related_certifications_here/", "subreddit_subscribers": 80383, "created_utc": 1668807375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Forgive what might be a simple question, I am but a humble data scientist.\n\nSo sometimes you want a DB table column to be a smallint or whatever to save space, assuming you'll never get values that are too large to be represented by the bytes you have available.\n\nI've been told in Snowflake this is largely unnecessary, as it will detect the size of the numbers and allocate storage appropriately. Basically it just ignores the precision and scale that you set the column as?\n\nRef: [https://docs.snowflake.com/en/sql-reference/data-types-numeric.html](https://docs.snowflake.com/en/sql-reference/data-types-numeric.html)", "author_fullname": "t2_d8yt2ssh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is specifying column precision and scale in Snowflake pointless?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzbcww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668862854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Forgive what might be a simple question, I am but a humble data scientist.&lt;/p&gt;\n\n&lt;p&gt;So sometimes you want a DB table column to be a smallint or whatever to save space, assuming you&amp;#39;ll never get values that are too large to be represented by the bytes you have available.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been told in Snowflake this is largely unnecessary, as it will detect the size of the numbers and allocate storage appropriately. Basically it just ignores the precision and scale that you set the column as?&lt;/p&gt;\n\n&lt;p&gt;Ref: &lt;a href=\"https://docs.snowflake.com/en/sql-reference/data-types-numeric.html\"&gt;https://docs.snowflake.com/en/sql-reference/data-types-numeric.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yzbcww", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Unit-385", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yzbcww/is_specifying_column_precision_and_scale_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yzbcww/is_specifying_column_precision_and_scale_in/", "subreddit_subscribers": 80383, "created_utc": 1668862854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys. \n\nWould like your opinion. \n\nI am setting up an architecture for a medium sized team who does machine learning and transformations using Databricks. \n\nEach machine learning project or transformation project will have their own git repo. We expect 40+ repo and 5+ member per project (so 5+ member per repo). \n\nOur users will work on their project\u2019s git repo by creating experiment branches. Since an iteration need multiple steps (say data gen, data transform, train, and so on), our users would like to have an ui for creating the workflow and run it. Databricks workflow makes this possible but we also would like to commit the workflow json into the branch so we can reproduce later. \n\nBasically, below will be the steps followed,\n\n1.\tCreate couple of notebooks and/or edit existing ones\n2.\tcommit the changes\n3.\topen an ui and it loads workflow from that branch \n4.\tEdit the workflow if needed based on the newly created worklow\n5.\tClick on Save &amp; Run which will commit the workflow json into their branch and then, runs it. \n\nCouple of weeks or months later, if someone wants to reproduce they just have to checkout this commit. Also, storing the workflow json will help in CI.\n\nIs it possible?\n\nAlso, multiple data preparation tasks are common across projects/repo and hence, would like to know if it is possible have some kind of common task drop-down which users can use to orchestrate. Is it possible?\n\nNote 1: Although I have mentioned Databricks workflow, I am open with any other solution. I checked Airflow but it does not have ui. \n\nNote 2: if it is helpful, I am using Azure.", "author_fullname": "t2_8vasr6so", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you track and version control orchestration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yz89pt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668851692.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668851186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys. &lt;/p&gt;\n\n&lt;p&gt;Would like your opinion. &lt;/p&gt;\n\n&lt;p&gt;I am setting up an architecture for a medium sized team who does machine learning and transformations using Databricks. &lt;/p&gt;\n\n&lt;p&gt;Each machine learning project or transformation project will have their own git repo. We expect 40+ repo and 5+ member per project (so 5+ member per repo). &lt;/p&gt;\n\n&lt;p&gt;Our users will work on their project\u2019s git repo by creating experiment branches. Since an iteration need multiple steps (say data gen, data transform, train, and so on), our users would like to have an ui for creating the workflow and run it. Databricks workflow makes this possible but we also would like to commit the workflow json into the branch so we can reproduce later. &lt;/p&gt;\n\n&lt;p&gt;Basically, below will be the steps followed,&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; Create couple of notebooks and/or edit existing ones&lt;/li&gt;\n&lt;li&gt; commit the changes&lt;/li&gt;\n&lt;li&gt; open an ui and it loads workflow from that branch &lt;/li&gt;\n&lt;li&gt; Edit the workflow if needed based on the newly created worklow&lt;/li&gt;\n&lt;li&gt; Click on Save &amp;amp; Run which will commit the workflow json into their branch and then, runs it. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Couple of weeks or months later, if someone wants to reproduce they just have to checkout this commit. Also, storing the workflow json will help in CI.&lt;/p&gt;\n\n&lt;p&gt;Is it possible?&lt;/p&gt;\n\n&lt;p&gt;Also, multiple data preparation tasks are common across projects/repo and hence, would like to know if it is possible have some kind of common task drop-down which users can use to orchestrate. Is it possible?&lt;/p&gt;\n\n&lt;p&gt;Note 1: Although I have mentioned Databricks workflow, I am open with any other solution. I checked Airflow but it does not have ui. &lt;/p&gt;\n\n&lt;p&gt;Note 2: if it is helpful, I am using Azure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yz89pt", "is_robot_indexable": true, "report_reasons": null, "author": "specialist_says_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yz89pt/how_do_you_track_and_version_control_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yz89pt/how_do_you_track_and_version_control_orchestration/", "subreddit_subscribers": 80383, "created_utc": 1668851186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI\u2019m a recent graduate student. I recently joined an organisation as a fresher.\nThey took me in as a Backend engineer (Java, C#). Currently they have an opening in Data Engineer position.\n\nIs it okay to start my career as a Data engineer. Or is it better to start of as a backend engineer and later transition to the data field. \n\nUltimately, I\u2019m interested in data science and it\u2019s related fields and hope to pursue my career in that field in the future. \n\nI would love to know some perspectives on this.\n\nThank you.", "author_fullname": "t2_u4liwpsg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software or Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yzc420", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668865225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI\u2019m a recent graduate student. I recently joined an organisation as a fresher.\nThey took me in as a Backend engineer (Java, C#). Currently they have an opening in Data Engineer position.&lt;/p&gt;\n\n&lt;p&gt;Is it okay to start my career as a Data engineer. Or is it better to start of as a backend engineer and later transition to the data field. &lt;/p&gt;\n\n&lt;p&gt;Ultimately, I\u2019m interested in data science and it\u2019s related fields and hope to pursue my career in that field in the future. &lt;/p&gt;\n\n&lt;p&gt;I would love to know some perspectives on this.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yzc420", "is_robot_indexable": true, "report_reasons": null, "author": "damiandzou", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yzc420/software_or_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yzc420/software_or_data_engineer/", "subreddit_subscribers": 80383, "created_utc": 1668865225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This [poll](https://www.reddit.com/r/dataengineering/comments/rs5tyb/how_much_of_your_time_is_spent_on_adhoc_or_one/) on the subreddit about a year ago says that 75% of data engineers surveyed spend more than 20% of their time on ad-hoc requests.\n\nI'd love to dive a layer deeper and learn what those requests typically look like and hear your thoughts on ad-hoc work.\n\n[View Poll](https://www.reddit.com/poll/yyyqv8)", "author_fullname": "t2_6bqha9t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do the majority of your ad-hoc requests look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyyqv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668816808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/rs5tyb/how_much_of_your_time_is_spent_on_adhoc_or_one/\"&gt;poll&lt;/a&gt; on the subreddit about a year ago says that 75% of data engineers surveyed spend more than 20% of their time on ad-hoc requests.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to dive a layer deeper and learn what those requests typically look like and hear your thoughts on ad-hoc work.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yyyqv8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyyqv8", "is_robot_indexable": true, "report_reasons": null, "author": "minkstink", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1669421608942, "options": [{"text": "Fetching data", "id": "19899532"}, {"text": "Visualizations", "id": "19899533"}, {"text": "Analysis", "id": "19899534"}, {"text": "Dashboards", "id": "19899535"}, {"text": "Other", "id": "19899536"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 194, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyyqv8/what_do_the_majority_of_your_adhoc_requests_look/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/yyyqv8/what_do_the_majority_of_your_adhoc_requests_look/", "subreddit_subscribers": 80383, "created_utc": 1668816808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any suggestions to be used as OLTP and contain cdc pipelines?", "author_fullname": "t2_tzc3ui2v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyu4ff", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668804257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions to be used as OLTP and contain cdc pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyu4ff", "is_robot_indexable": true, "report_reasons": null, "author": "RecognitionDue5403", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyu4ff/apache_doris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyu4ff/apache_doris/", "subreddit_subscribers": 80383, "created_utc": 1668804257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi, \ni have a scenario when i have a bucket in S3 of which small csv files are being dumped continuously. I want to set an EventBridge event that will trigger a lambda function once a file was dumped. The lambda should convert the csv into parquet. It will be partitioned by date so many many files during the day should be dumped in s3 and converted and appended to the parquet file for this partition. \n\nI wonder if that is possible - the lambda will create the partitioned parquet file for the first csv file of the day and will append consecutive file transformations into that file into that partition. \n\nthanks", "author_fullname": "t2_ctqlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting small csvs and convert to parquet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yzf499", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668873577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi, \ni have a scenario when i have a bucket in S3 of which small csv files are being dumped continuously. I want to set an EventBridge event that will trigger a lambda function once a file was dumped. The lambda should convert the csv into parquet. It will be partitioned by date so many many files during the day should be dumped in s3 and converted and appended to the parquet file for this partition. &lt;/p&gt;\n\n&lt;p&gt;I wonder if that is possible - the lambda will create the partitioned parquet file for the first csv file of the day and will append consecutive file transformations into that file into that partition. &lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yzf499", "is_robot_indexable": true, "report_reasons": null, "author": "Snirisl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yzf499/ingesting_small_csvs_and_convert_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yzf499/ingesting_small_csvs_and_convert_to_parquet/", "subreddit_subscribers": 80383, "created_utc": 1668873577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I only came across him yesterday, I was searching for some specific graphDB podcasts, his [podcast giving an intro to GtaphDBs](https://open.spotify.com/episode/6p44P6CnEYc8qcUenmGfUS?si=UrXQfLZ3TdWVSw1RWW67Dw&amp;utm_source=copy-link) popped up. It was 23mins and tbh I probably learned more about relational DBs than graphDBs, the graphDB part only started in the last 9mins and didn't give me anything I didn't know already\n\nHowever, I thought it had a really good method and style of explaining things, and clearly knows a lot about relationalDBs\n\nHe has some courses on Udemy, Database Engineering and Network Fundamentals that I'm considering purchasing - can anyone here offer any feedback on these, or his other courses?\n\nPS the podcast is also on YouTube if you don't have Spotify", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone tried Hussein Nasser's courses (Backend Engineering Show guy)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yza7ck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668858879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I only came across him yesterday, I was searching for some specific graphDB podcasts, his &lt;a href=\"https://open.spotify.com/episode/6p44P6CnEYc8qcUenmGfUS?si=UrXQfLZ3TdWVSw1RWW67Dw&amp;amp;utm_source=copy-link\"&gt;podcast giving an intro to GtaphDBs&lt;/a&gt; popped up. It was 23mins and tbh I probably learned more about relational DBs than graphDBs, the graphDB part only started in the last 9mins and didn&amp;#39;t give me anything I didn&amp;#39;t know already&lt;/p&gt;\n\n&lt;p&gt;However, I thought it had a really good method and style of explaining things, and clearly knows a lot about relationalDBs&lt;/p&gt;\n\n&lt;p&gt;He has some courses on Udemy, Database Engineering and Network Fundamentals that I&amp;#39;m considering purchasing - can anyone here offer any feedback on these, or his other courses?&lt;/p&gt;\n\n&lt;p&gt;PS the podcast is also on YouTube if you don&amp;#39;t have Spotify&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/D1FaNRHExY_J1uD1bJKqy0eWSlt3PYEgLabhD1U3wAg.jpg?auto=webp&amp;s=b65bba3fa1958f40aa5ee6464fcaa2efd80f12db", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/D1FaNRHExY_J1uD1bJKqy0eWSlt3PYEgLabhD1U3wAg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8fab323d75c11a52ee7fa1e5f200eac975b4e8e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/D1FaNRHExY_J1uD1bJKqy0eWSlt3PYEgLabhD1U3wAg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ef1bb33a5e7f8cfd18b605e6ff33cce38717a15", "width": 216, "height": 216}], "variants": {}, "id": "-w2hqfrHn_oFIJ56M5ArHHWkVNzgGOx2zemcoyr4Wec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yza7ck", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yza7ck/has_anyone_tried_hussein_nassers_courses_backend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yza7ck/has_anyone_tried_hussein_nassers_courses_backend/", "subreddit_subscribers": 80383, "created_utc": 1668858879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Service Resilience \u2014 part 1: Startup Technology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yz52hu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/kn9QF8ffK3d577lCWSaBJrvJ2xNfYDlzLu0MS506Jw0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668837886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/reversinglabs-engineering/service-resilience-part-1-startup-technology-c8b1a446ace3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DcpRfrMaSqCN5dBqDkZyLrznDPGu55_3Ihl4q43gMeI.jpg?auto=webp&amp;s=f2751a44cf19c35cbd066a5a73a39e02c7b9020a", "width": 562, "height": 422}, "resolutions": [{"url": "https://external-preview.redd.it/DcpRfrMaSqCN5dBqDkZyLrznDPGu55_3Ihl4q43gMeI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db0fb0054ebb5238cd33f12f0b7cc18ec1eab99a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DcpRfrMaSqCN5dBqDkZyLrznDPGu55_3Ihl4q43gMeI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=09734044ad5029ff8fcfe57f2b186074c2f14745", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/DcpRfrMaSqCN5dBqDkZyLrznDPGu55_3Ihl4q43gMeI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=562cb1a4984532706f974ae2921a16f1b32eec0f", "width": 320, "height": 240}], "variants": {}, "id": "Z3WQ5wMJJ_tekUA2NcJJEHLF1MqakV1kOiWzbd3E0iA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yz52hu", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yz52hu/service_resilience_part_1_startup_technology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/reversinglabs-engineering/service-resilience-part-1-startup-technology-c8b1a446ace3", "subreddit_subscribers": 80383, "created_utc": 1668837886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gd6jaom1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Udemy Courses \ud83d\ude02 waiting for me to start them..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yz3dhr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/diFCRLunsGl7zMdS4rFRQTSI-1-V7OAfd26r42HgfG4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668831737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/w1tzpo1klv0a1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?auto=webp&amp;s=0386821cbc24d5c59b8ce2be65d308d5408f5b7a", "width": 1080, "height": 3506}, "resolutions": [{"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=21f6c70eea5c294a394a926045bdac888f0c573a", "width": 108, "height": 216}, {"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=146ba2a8a4cbe8b582a4206f62c65a747e9eb6df", "width": 216, "height": 432}, {"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=844fa3d67f2a550d10393b42f85eea7ff8b19526", "width": 320, "height": 640}, {"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe63483b8d2a0c76e44199347ce88f9bae9807a5", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=28acac4e3364fad06047bdf1526a6d23d6c6dafc", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/w1tzpo1klv0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=486a5154e2909f85f1bec3bb3cbc5af8ac274a46", "width": 1080, "height": 2160}], "variants": {}, "id": "Hs0WSVvteL8z_Ea0hX8hKH-mOHAimkQiYqlifascWZg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yz3dhr", "is_robot_indexable": true, "report_reasons": null, "author": "No_Enthusiasm_9433", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yz3dhr/my_udemy_courses_waiting_for_me_to_start_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/w1tzpo1klv0a1.jpg", "subreddit_subscribers": 80383, "created_utc": 1668831737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1- Saying yes, and building on top of existing business goal as a quick solution without taking the blame for the outcome which is usually a failure. After agreeing to the project once all the red flags are conveyed to business. \n\n2- Building from ground up for a proper DS project to solve a problem.", "author_fullname": "t2_3ftiaba8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science and Building a project on existing business solutions. I consider this to be a red flag or two pronged problem...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyq13l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668793606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;1- Saying yes, and building on top of existing business goal as a quick solution without taking the blame for the outcome which is usually a failure. After agreeing to the project once all the red flags are conveyed to business. &lt;/p&gt;\n\n&lt;p&gt;2- Building from ground up for a proper DS project to solve a problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyq13l", "is_robot_indexable": true, "report_reasons": null, "author": "Zenith_N", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyq13l/data_science_and_building_a_project_on_existing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyq13l/data_science_and_building_a_project_on_existing/", "subreddit_subscribers": 80383, "created_utc": 1668793606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm trying to learn the delta architecture concept. I've got a problem understanding how to mange large incremental files. Delta concept assumes that bronze layer stores raw data, so if we have a bug in silver layer or we just want to make some adjustments,  we can always go back and recreate silver table (with unchanged bronze data).\n\nLet's say that we have a transactional table that grows 1 million rows per day. The business requirement is that the table should be refreshed daily. To fetch all the recent changes we need to go 3 days backwards every day and then insert/update data into production table.\n\nIn such case bronze daily extracts contain lots of overlapping data with other daily snapshots. Wouldn't it be better to load data incrementally into bronze layer right away (and save a lot of storage space)?", "author_fullname": "t2_33dfdmfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bronze layer (Delta Lake) data storage of incremental files.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyofae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668789569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m trying to learn the delta architecture concept. I&amp;#39;ve got a problem understanding how to mange large incremental files. Delta concept assumes that bronze layer stores raw data, so if we have a bug in silver layer or we just want to make some adjustments,  we can always go back and recreate silver table (with unchanged bronze data).&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say that we have a transactional table that grows 1 million rows per day. The business requirement is that the table should be refreshed daily. To fetch all the recent changes we need to go 3 days backwards every day and then insert/update data into production table.&lt;/p&gt;\n\n&lt;p&gt;In such case bronze daily extracts contain lots of overlapping data with other daily snapshots. Wouldn&amp;#39;t it be better to load data incrementally into bronze layer right away (and save a lot of storage space)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyofae", "is_robot_indexable": true, "report_reasons": null, "author": "bl_lato7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyofae/bronze_layer_delta_lake_data_storage_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyofae/bronze_layer_delta_lake_data_storage_of/", "subreddit_subscribers": 80383, "created_utc": 1668789569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Data Engineer Salary Levels are on the Growth Path Globally", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yyw5gz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5oBK72CoZwKGgWUhuhNVWixLaEFOG-x1rG8TGhhioBE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668809647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "emeritus.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://emeritus.org/blog/data-engineer-salary/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?auto=webp&amp;s=9e2f18eab877f2025734020a0bb949cc667b4d82", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=315721a44fb5585d73869824804f90d26999e545", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f225e5477836f9bec09b0361de8926b75a14e774", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=13306459fe00c2c502fdc5dfe00bbccb8f1e7cd0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa79ead1f8e164cf6c8cbaa336570fa900e9b1b6", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=995935e73a8e59d405393faffa9d8a400530a798", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/-hwo-9oLAAdUfSAPqqfx9Jrx_9xMbBBKqZbv5Ig2uuI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=67766212202860f39962899140c94dd4bd3bab20", "width": 1080, "height": 565}], "variants": {}, "id": "U43yxsPXARGHlUfQcHJBB_RukWG5uEW5fIs-m3fb-po"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yyw5gz", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyw5gz/why_data_engineer_salary_levels_are_on_the_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://emeritus.org/blog/data-engineer-salary/", "subreddit_subscribers": 80383, "created_utc": 1668809647.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}