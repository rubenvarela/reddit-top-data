{"kind": "Listing", "data": {"after": "t3_yyypj8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_d48yz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google and Amazon Helped the FBI Identify Z-Library's Operators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyj1dc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 637, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 637, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1668774878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "torrentfreak.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://torrentfreak.com/how-google-and-amazon-helped-the-fbi-identify-z-librarys-operators-221117/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyj1dc", "is_robot_indexable": true, "report_reasons": null, "author": "Prometheus720", "discussion_type": null, "num_comments": 158, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyj1dc/google_and_amazon_helped_the_fbi_identify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://torrentfreak.com/how-google-and-amazon-helped-the-fbi-identify-z-librarys-operators-221117/", "subreddit_subscribers": 654842, "created_utc": 1668774878.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_tlgcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A database of paper airplanes with easy to follow folding instructions, video tutorials and printable folding plans. Find the best paper airplanes that fly the furthest and stay aloft the longest.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yyhavo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 174, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 174, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/prZ5H2m6FUcoXaVYAgI4mTKRMuTFDWbsdOBELddMgW8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668769050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "foldnfly.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.foldnfly.com/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?auto=webp&amp;s=2e319bc9673fc40f1aec8c70febd71b2f84b10cb", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d37c2a5e835ea4c51b538aef5cbbd90f4e401217", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4d339c5a12d9cf0b1cf1a15d74138abbb400754", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b622d929f9312bf9d0f6019c52870b890a6d4ad", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d65b5cd84e8524d5d83e756f6a19fffc433d5b12", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=69a20c6d882a8d34f6c8dea2fec83e9b577a5f29", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94570fce0f309e51fd4ca001f841c5a99f97f58d", "width": 1080, "height": 567}], "variants": {}, "id": "uZ2zDM2Hy1FLstbjMCzVaGvaO0jNdvizg4F-yPk7isI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB Synology DS1819+", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyhavo", "is_robot_indexable": true, "report_reasons": null, "author": "PaddleMonkey", "discussion_type": null, "num_comments": 14, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yyhavo/a_database_of_paper_airplanes_with_easy_to_follow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.foldnfly.com/", "subreddit_subscribers": 654842, "created_utc": 1668769050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Rewritten for clarity because speedrunning a post like this tends to leave questions\n\nHow to get started:\n\n1. Install [Python](https://www.python.org/). There is a standalone .exe but this just makes it easier to upgrade and all that\n\n2. Run `pip install gallery-dl` in command prompt (windows) or Bash (Linux)\n\n3. From there running `gallery-dl &lt;url&gt;` in the same command line should download the url's contents\n\n## config.json\n\nThe config.json is located at `%APPDATA%\\gallery-dl\\config.json` (windows) and `/etc/gallery-dl.conf` (Linux)\n\nIf the folder/file doesn't exist, just making it yourself should work\n\nThe basic config I recommend is this. If this is your first time with gallery-dl it's safe to just replace the entire file with this. If it's not your first time you should know how to transplant this into your existing config\n\n    {\n        \"extractor\":{\n            \"cookies\": [\"&lt;your browser (firefox, chromium, etc)&gt;\"],\n            \"twitter\":{\n                \"users\": \"https://twitter.com/{legacy[screen_name]}\",\n                \"text-tweets\":true,\n                \"retweets\":true,\n                \"quoted\":true,\n                \"logout\":true,\n                \"replies\":true,\n                \"postprocessors\":[\n                    {\"name\": \"metadata\", \"event\": \"post\", \"filename\": \"{tweet_id}_main.json\"}\n                ]\n            }\n        }\n    }\n\nThe documentation for the config.json is [here](https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst) and the specific part about getting cookies from your browser is [here](https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst#extractorcookies)\n\nCurrently supplying your login as a username/password combo seems to be broken. Idk if this is an issue with twitter or gallery-dl but using browser cookies is just easier in the long run\n\n## URLs:\n\n[The twitter API limits getting a user's page to the latest ~3200 tweets](https://github.com/mikf/gallery-dl/issues/2226). To get the as much as possible I recommend getting the main tab, the media tab, *and* the URL when you search for `from:&lt;user&gt;`\n\nTo make downloading the media tab not immediately exit when it sees a duplicate image, you'll want to add `-o skip=true` to the command you put in the command line. This can also be specified in the config. I have mine set to 20 when I'm just updating an existing download. If it sees 20 known images in a row then it moves on to the next one.\n\nThe 3 URLs I recommend downloading are:\n\n- `https://www.twitter.com/&lt;user&gt;`\n- `https://www.twitter.com/&lt;user&gt;/media`\n- `https://twitter.com/search?q=from:&lt;user&gt;`\n\nTo get someone's likes the URL is `https://www.twitter.com/&lt;user&gt;/likes`\n\nTo get your bookmarks the URL is `https://twitter.com/i/bookmarks`\n\n**Note**: Because twitter honestly just sucks and has for quite a while, you should run each download a few times (again with `-o skip=true`) to make sure you get everything\n\n## Commands:\n\nAnd the commands you're running should look like `gallery-dl &lt;url&gt; --write-metadata -o skip=true`\n\n`--write-metadata` saves `.json` files with metadata about each image. the `\"postprocessors\"` part of the config already writes the metadata for the tweet itself but the per-image metadata has some extra stuff\n\nIf you run `gallery-dl -g https://twitter.com/&lt;your handle&gt;/following` you can get a list of everyone you follow.\n\n### Windows:\n\nIf you have a text editor that supports regex replacement (CTRL+H in Sublime Text. Enable the button that looks like a .*), you can paste the list gallery-dl gave you and replace `(.+\\/)([^/\\r\\n]+)` with `gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{$2}\"\"]\"`\n\nYou should see something along the lines of\n\n    gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{test1}\"\"]\"\n    gallery-dl https://twitter.com/test2               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{test2}\"\"]\"\n    gallery-dl https://twitter.com/test3               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{test3}\"\"]\"\n\nThen put an `@echo off` at the top of the file and save it as a `.bat`\n\n### Linux:\n\nIf you have a text editor that supports regex replacement, you can paste the list gallery-dl gave you and replace `(.+\\/)([^/\\r\\n]+)` with `gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{$2}\\\"]\"`\n\nYou should see something along the lines of\n\n    gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{test1}\\\"]\"\n    gallery-dl https://twitter.com/test2               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{test2}\\\"]\"\n    gallery-dl https://twitter.com/test3               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{test3}\\\"]\"\n\nThen save it as a `.sh` file\n\nIf, on either OS, the resulting commands has a bunch of `$1` and `$2` in it, replace the `$`s in the replacement string with `\\`s and do it again.\n\nAfter that, running the file should (assuming I got all the steps right) download everyone you follow\n\n.\n\nNow, if you excuse me, it's almost 6am and I need to sleep. I really hope I haven't made any catastrophic errors", "author_fullname": "t2_yj3jz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For everyone using gallery-dl to backup twitter: Make sure you do it right", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy8o9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668768882.0, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668738416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Rewritten for clarity because speedrunning a post like this tends to leave questions&lt;/p&gt;\n\n&lt;p&gt;How to get started:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Install &lt;a href=\"https://www.python.org/\"&gt;Python&lt;/a&gt;. There is a standalone .exe but this just makes it easier to upgrade and all that&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Run &lt;code&gt;pip install gallery-dl&lt;/code&gt; in command prompt (windows) or Bash (Linux)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;From there running &lt;code&gt;gallery-dl &amp;lt;url&amp;gt;&lt;/code&gt; in the same command line should download the url&amp;#39;s contents&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;config.json&lt;/h2&gt;\n\n&lt;p&gt;The config.json is located at &lt;code&gt;%APPDATA%\\gallery-dl\\config.json&lt;/code&gt; (windows) and &lt;code&gt;/etc/gallery-dl.conf&lt;/code&gt; (Linux)&lt;/p&gt;\n\n&lt;p&gt;If the folder/file doesn&amp;#39;t exist, just making it yourself should work&lt;/p&gt;\n\n&lt;p&gt;The basic config I recommend is this. If this is your first time with gallery-dl it&amp;#39;s safe to just replace the entire file with this. If it&amp;#39;s not your first time you should know how to transplant this into your existing config&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n    &amp;quot;extractor&amp;quot;:{\n        &amp;quot;cookies&amp;quot;: [&amp;quot;&amp;lt;your browser (firefox, chromium, etc)&amp;gt;&amp;quot;],\n        &amp;quot;twitter&amp;quot;:{\n            &amp;quot;users&amp;quot;: &amp;quot;https://twitter.com/{legacy[screen_name]}&amp;quot;,\n            &amp;quot;text-tweets&amp;quot;:true,\n            &amp;quot;retweets&amp;quot;:true,\n            &amp;quot;quoted&amp;quot;:true,\n            &amp;quot;logout&amp;quot;:true,\n            &amp;quot;replies&amp;quot;:true,\n            &amp;quot;postprocessors&amp;quot;:[\n                {&amp;quot;name&amp;quot;: &amp;quot;metadata&amp;quot;, &amp;quot;event&amp;quot;: &amp;quot;post&amp;quot;, &amp;quot;filename&amp;quot;: &amp;quot;{tweet_id}_main.json&amp;quot;}\n            ]\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The documentation for the config.json is &lt;a href=\"https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst\"&gt;here&lt;/a&gt; and the specific part about getting cookies from your browser is &lt;a href=\"https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst#extractorcookies\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently supplying your login as a username/password combo seems to be broken. Idk if this is an issue with twitter or gallery-dl but using browser cookies is just easier in the long run&lt;/p&gt;\n\n&lt;h2&gt;URLs:&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mikf/gallery-dl/issues/2226\"&gt;The twitter API limits getting a user&amp;#39;s page to the latest ~3200 tweets&lt;/a&gt;. To get the as much as possible I recommend getting the main tab, the media tab, &lt;em&gt;and&lt;/em&gt; the URL when you search for &lt;code&gt;from:&amp;lt;user&amp;gt;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;To make downloading the media tab not immediately exit when it sees a duplicate image, you&amp;#39;ll want to add &lt;code&gt;-o skip=true&lt;/code&gt; to the command you put in the command line. This can also be specified in the config. I have mine set to 20 when I&amp;#39;m just updating an existing download. If it sees 20 known images in a row then it moves on to the next one.&lt;/p&gt;\n\n&lt;p&gt;The 3 URLs I recommend downloading are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;https://www.twitter.com/&amp;lt;user&amp;gt;&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;https://www.twitter.com/&amp;lt;user&amp;gt;/media&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;https://twitter.com/search?q=from:&amp;lt;user&amp;gt;&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To get someone&amp;#39;s likes the URL is &lt;code&gt;https://www.twitter.com/&amp;lt;user&amp;gt;/likes&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;To get your bookmarks the URL is &lt;code&gt;https://twitter.com/i/bookmarks&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Because twitter honestly just sucks and has for quite a while, you should run each download a few times (again with &lt;code&gt;-o skip=true&lt;/code&gt;) to make sure you get everything&lt;/p&gt;\n\n&lt;h2&gt;Commands:&lt;/h2&gt;\n\n&lt;p&gt;And the commands you&amp;#39;re running should look like &lt;code&gt;gallery-dl &amp;lt;url&amp;gt; --write-metadata -o skip=true&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;--write-metadata&lt;/code&gt; saves &lt;code&gt;.json&lt;/code&gt; files with metadata about each image. the &lt;code&gt;&amp;quot;postprocessors&amp;quot;&lt;/code&gt; part of the config already writes the metadata for the tweet itself but the per-image metadata has some extra stuff&lt;/p&gt;\n\n&lt;p&gt;If you run &lt;code&gt;gallery-dl -g https://twitter.com/&amp;lt;your handle&amp;gt;/following&lt;/code&gt; you can get a list of everyone you follow.&lt;/p&gt;\n\n&lt;h3&gt;Windows:&lt;/h3&gt;\n\n&lt;p&gt;If you have a text editor that supports regex replacement (CTRL+H in Sublime Text. Enable the button that looks like a .*), you can paste the list gallery-dl gave you and replace &lt;code&gt;(.+\\/)([^/\\r\\n]+)&lt;/code&gt; with &lt;code&gt;gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{$2}&amp;quot;&amp;quot;]&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;You should see something along the lines of&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{test1}&amp;quot;&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test2               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{test2}&amp;quot;&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test3               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{test3}&amp;quot;&amp;quot;]&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then put an &lt;code&gt;@echo off&lt;/code&gt; at the top of the file and save it as a &lt;code&gt;.bat&lt;/code&gt;&lt;/p&gt;\n\n&lt;h3&gt;Linux:&lt;/h3&gt;\n\n&lt;p&gt;If you have a text editor that supports regex replacement, you can paste the list gallery-dl gave you and replace &lt;code&gt;(.+\\/)([^/\\r\\n]+)&lt;/code&gt; with &lt;code&gt;gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{$2}\\&amp;quot;]&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;You should see something along the lines of&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{test1}\\&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test2               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{test2}\\&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test3               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{test3}\\&amp;quot;]&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then save it as a &lt;code&gt;.sh&lt;/code&gt; file&lt;/p&gt;\n\n&lt;p&gt;If, on either OS, the resulting commands has a bunch of &lt;code&gt;$1&lt;/code&gt; and &lt;code&gt;$2&lt;/code&gt; in it, replace the &lt;code&gt;$&lt;/code&gt;s in the replacement string with &lt;code&gt;\\&lt;/code&gt;s and do it again.&lt;/p&gt;\n\n&lt;p&gt;After that, running the file should (assuming I got all the steps right) download everyone you follow&lt;/p&gt;\n\n&lt;p&gt;.&lt;/p&gt;\n\n&lt;p&gt;Now, if you excuse me, it&amp;#39;s almost 6am and I need to sleep. I really hope I haven&amp;#39;t made any catastrophic errors&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XACIlvLRgD0CrsIsxO7yWQMICHPINiGesu3WjxQxeXs.jpg?auto=webp&amp;s=c7f0d77306cb94adced1c514958fdf68f575791c", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/XACIlvLRgD0CrsIsxO7yWQMICHPINiGesu3WjxQxeXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0a156ee41a904137a12d7727f03ba51aa2a31c7", "width": 108, "height": 108}], "variants": {}, "id": "_QTobzuJkr1Zm6t-xAciOuvRRUG3sFX1cl1tVTmHCMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "The sexiest data storage medium", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy8o9w", "is_robot_indexable": true, "report_reasons": null, "author": "Scripter17", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yy8o9w/for_everyone_using_gallerydl_to_backup_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy8o9w/for_everyone_using_gallerydl_to_backup_twitter/", "subreddit_subscribers": 654842, "created_utc": 1668738416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16ljkt33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Well I guess there\u2019s a first time for everyone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yymt49", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZbfaJL2A04kigIvAfyli2o1vVNQh3VGu_QN4cP9SVsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668785375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jgn8k3cprr0a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?auto=webp&amp;s=9c7d9d7a0a06582b4e311f39efd681cadfb01e77", "width": 1105, "height": 1632}, "resolutions": [{"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f931b06fc41138c9b2c3f54645f061124f05666f", "width": 108, "height": 159}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b439c243abb4bd3fbb01a67d4ab5aa93ee90574f", "width": 216, "height": 319}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=837eccd77e3417c0ff37e6657b807dc9a33e0821", "width": 320, "height": 472}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eab28429ca47f669cebd02eefd7c2d67c9312fe6", "width": 640, "height": 945}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=179673b47e79d29e4b57f4c86e34cea65a58da30", "width": 960, "height": 1417}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16fa7c62fd867b4d191341381b1da98ae39ac430", "width": 1080, "height": 1595}], "variants": {}, "id": "ZNagWy__7ZPBH4futKvhBx4Oid-stmGTw1lkVZWWw-4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yymt49", "is_robot_indexable": true, "report_reasons": null, "author": "ddrfraser1", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yymt49/well_i_guess_theres_a_first_time_for_everyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jgn8k3cprr0a1.jpg", "subreddit_subscribers": 654842, "created_utc": 1668785375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I am probably way out of my depth here but r/Twitter redirected me here when I asked this question. In case Twitter actually does go away I am trying to download the entire Twitter feed of my best friend who passed away 5 years ago. I\u2019m currently just screenshotting favorites in a panic and googling returns old workarounds that don\u2019t work anymore. Any advice at all is appreciated, thank you.", "author_fullname": "t2_eo84n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download An Entire Twitter Feed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy8dii", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668737540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am probably way out of my depth here but &lt;a href=\"/r/Twitter\"&gt;r/Twitter&lt;/a&gt; redirected me here when I asked this question. In case Twitter actually does go away I am trying to download the entire Twitter feed of my best friend who passed away 5 years ago. I\u2019m currently just screenshotting favorites in a panic and googling returns old workarounds that don\u2019t work anymore. Any advice at all is appreciated, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy8dii", "is_robot_indexable": true, "report_reasons": null, "author": "plaidtuxedo", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy8dii/download_an_entire_twitter_feed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy8dii/download_an_entire_twitter_feed/", "subreddit_subscribers": 654842, "created_utc": 1668737540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a thread for current blackfriday storage discounts like last year?", "author_fullname": "t2_4y7ra1ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black Friday thread", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyc1vh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668749117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a thread for current blackfriday storage discounts like last year?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyc1vh", "is_robot_indexable": true, "report_reasons": null, "author": "HolUp-", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyc1vh/black_friday_thread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyc1vh/black_friday_thread/", "subreddit_subscribers": 654842, "created_utc": 1668749117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just built my first data hoarding server consisting of an 80tb Z2 pool. I'm already planning on getting my first HBA and tripping my storage. I've been lurking for years and I'm finally getting to dive in.", "author_fullname": "t2_4guaj6oe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I finally figured out how to download Linux iso's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_yyuy07", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9PMd6ZLDKUIgKQvlKO5gx-DoSeImBHRaMGhxT5k9Rr0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668806460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just built my first data hoarding server consisting of an 80tb Z2 pool. I&amp;#39;m already planning on getting my first HBA and tripping my storage. I&amp;#39;ve been lurking for years and I&amp;#39;m finally getting to dive in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3amajgheit0a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3amajgheit0a1.png?auto=webp&amp;s=33728bd7e21bdff5c5cceb21fcb8fec846ed1e26", "width": 999, "height": 588}, "resolutions": [{"url": "https://preview.redd.it/3amajgheit0a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=639fca09c8c1d69748f5ca7b8b37766dc37b0cbf", "width": 108, "height": 63}, {"url": "https://preview.redd.it/3amajgheit0a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ad2e2e887d3466762d7bc9766b39ed0a2ac0ba5f", "width": 216, "height": 127}, {"url": "https://preview.redd.it/3amajgheit0a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=da77ec763e3287f47279f8f71f59809f440505e1", "width": 320, "height": 188}, {"url": "https://preview.redd.it/3amajgheit0a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5113530ae0938d72471d2f9ae1c9bcaa9c05fe09", "width": 640, "height": 376}, {"url": "https://preview.redd.it/3amajgheit0a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=62f4051ba2ef1feefd2ee028e0e4d2b0f811354b", "width": 960, "height": 565}], "variants": {}, "id": "CYgxqhhJH8xYehf1bBRkj7TNpyzq59hgUPdj_3WgBzA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyuy07", "is_robot_indexable": true, "report_reasons": null, "author": "1Tekgnome", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyuy07/i_finally_figured_out_how_to_download_linux_isos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3amajgheit0a1.png", "subreddit_subscribers": 654842, "created_utc": 1668806460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7w4k6ew8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Users urged to archive tweets amid rumors of Twitter implosion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yymkm3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/eALEhho84LazRxOlfZEM6k9800EAMqAzryV6fTLtZc8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668784757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theguardian.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theguardian.com/technology/2022/nov/17/twitter-archive-tweets-company-shuts", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?auto=webp&amp;s=1a1c0054b85a7f182043ecc83a24c61ed68b81da", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28e937736e790e72762917e976d26195cfe61fd0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5be5a1ef1f03e74076ada75bb970130fe7d027e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ae5b4b15e0e9348a170bccc6ee4291f4410491b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=774d8fc94fb5c43dea6ec1a6270926be8c2df19a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7384756fc81363733e6c438330eac0e52e25f5ae", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5898eeaaa637f96d892c11a4b505afe236bc039", "width": 1080, "height": 567}], "variants": {}, "id": "e73AQNWJSsqrckdWSHBK6HJXAG6Ufrm3I_6DS13ZpN8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yymkm3", "is_robot_indexable": true, "report_reasons": null, "author": "Buddy_Deep", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yymkm3/users_urged_to_archive_tweets_amid_rumors_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theguardian.com/technology/2022/nov/17/twitter-archive-tweets-company-shuts", "subreddit_subscribers": 654842, "created_utc": 1668784757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Lots of options to scrape your tweets, but I have a lot of bookmarks I also wanna back up.\n\nI found a way to download all the tweet URLs into a csv ([Dewey](https://getdewey.co/)) and a way to download videos and gifs independently ([youtube-dl](https://youtube-dl-helper.github.io/)) but I can't find a way to do it all at the same time.\n\nEverything into a XML file would be ideal. Also if possible it would be nice for it to keep threads (which should be possible if not annoying)\n\nI found [this](https://gist.github.com/CJKinni/3063070) but it's very old code and has basically no chance to work", "author_fullname": "t2_ykkhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get all my Twitter bookmarks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy978v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668739972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of options to scrape your tweets, but I have a lot of bookmarks I also wanna back up.&lt;/p&gt;\n\n&lt;p&gt;I found a way to download all the tweet URLs into a csv (&lt;a href=\"https://getdewey.co/\"&gt;Dewey&lt;/a&gt;) and a way to download videos and gifs independently (&lt;a href=\"https://youtube-dl-helper.github.io/\"&gt;youtube-dl&lt;/a&gt;) but I can&amp;#39;t find a way to do it all at the same time.&lt;/p&gt;\n\n&lt;p&gt;Everything into a XML file would be ideal. Also if possible it would be nice for it to keep threads (which should be possible if not annoying)&lt;/p&gt;\n\n&lt;p&gt;I found &lt;a href=\"https://gist.github.com/CJKinni/3063070\"&gt;this&lt;/a&gt; but it&amp;#39;s very old code and has basically no chance to work&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?auto=webp&amp;s=e2d60ad36c7afe27744a4b4f63f20d3181954d4b", "width": 1015, "height": 494}, "resolutions": [{"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4de019e984fdeee8a89ce7e525e828568019fd28", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=06f53d6a2f1e4248b34fb2643cd2df9e85f63585", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=11aa0debd38927b0c86148157dd6fb2be3425330", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a008abc197d7c09c8a6d7c679a7a14dfeb6aff84", "width": 640, "height": 311}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8407e59962bf38175018cc891c88bea773d2b655", "width": 960, "height": 467}], "variants": {}, "id": "D83W6ubnaf9JIZcLbn0OsGoknMj1En17FJrGkylXYzs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy978v", "is_robot_indexable": true, "report_reasons": null, "author": "PowderPhysics", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy978v/how_to_get_all_my_twitter_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy978v/how_to_get_all_my_twitter_bookmarks/", "subreddit_subscribers": 654842, "created_utc": 1668739972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_b2shrkur", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "What is this thing on my hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"i40g9wwvvr0a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=793a3ae974bd591fb2d4781c80eaec27910410ca"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5224b71a795d71cc85d977cd6d1a2b829bdd2db5"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f4b827fa6e6fdd5c61042f75a935742f3c968cc"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=131320c996d2c26acf5d78acff7c2df98665565c"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5be753fdd2344d68ec0382ca48718e86c024778"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0feac3f8888ce304ad20e43eb99a5ffc05bbbdd"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/i40g9wwvvr0a1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=16dab7e23689bf923c0dd18ba8b7bb002140ae21"}, "id": "i40g9wwvvr0a1"}, "osz3n6xvvr0a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=34f52b8448be138eeccaf2784673eb1150053edc"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=48adc355b5682f44f06e4eba28187588715f3095"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eaa04afe009db8e2c09f5e94e93c4497839b0e37"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b6d4ef28007b1f5b40ed9f8ac3ed1512e8fe78f0"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97abc1766f81e0f27c7931042f31c8b638b95113"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2db173da054f960eb7b217202832871f277cd470"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/osz3n6xvvr0a1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=19e92dc457ccf5d0198f09b0d7e60f57651d4a4f"}, "id": "osz3n6xvvr0a1"}, "wnk8hywvvr0a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cad50935f3c350a07346de6fd7dcda50ebaf472"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=80c4e535a84932d5f0bad4f9c71a687ca238dc46"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=32bb22410cb34143334e5900a801ea796ba5a2b6"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d558078de65478936067e716947aa5dce4dd168"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e26afa2e69940421edf6106e42622f44f5f8026c"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bf73857aae0673adbda8103bc24bca040e2abb55"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/wnk8hywvvr0a1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=f38815e95ac3090f7cf2c34907220d8ff0dc8ae3"}, "id": "wnk8hywvvr0a1"}}, "name": "t3_yyubfa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 6, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "What is this thing, and if I wanted to connect it to my computer, do i take it off?", "media_id": "osz3n6xvvr0a1", "id": 210402447}, {"media_id": "wnk8hywvvr0a1", "id": 210402448}, {"media_id": "i40g9wwvvr0a1", "id": 210402449}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/64F24Bavw5WZANUyN9QdR_wkymY0jyeAV4oT_TgwCm8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668804787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yyubfa", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyubfa", "is_robot_indexable": true, "report_reasons": null, "author": "Nigerian_Waffles", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyubfa/what_is_this_thing_on_my_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yyubfa", "subreddit_subscribers": 654842, "created_utc": 1668804787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2t7fb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You've heard of big data, now get ready for cozy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yyrudp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eCQ07wI3jCO0nXAVQF4K_v3PhdWIKswmIvd3b6gso_w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668798336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dolthub.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dolthub.com/blog/2022-11-18-cozy-data/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IWhTDmK76tp8kZsqepOJVrkuxk96NQLFbBuP-ezXdDs.jpg?auto=webp&amp;s=374bf2efddadc222a849a3663deae926b156072e", "width": 1000, "height": 523}, "resolutions": [{"url": "https://external-preview.redd.it/IWhTDmK76tp8kZsqepOJVrkuxk96NQLFbBuP-ezXdDs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=452aa6d66beb6223db5710ab07abb9c5b1e9b39e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IWhTDmK76tp8kZsqepOJVrkuxk96NQLFbBuP-ezXdDs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae009a99e95eb52117f09fee23074109e9feacd0", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/IWhTDmK76tp8kZsqepOJVrkuxk96NQLFbBuP-ezXdDs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6b8fad7e13dcc4d9505070071342344fa95e545", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/IWhTDmK76tp8kZsqepOJVrkuxk96NQLFbBuP-ezXdDs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fcc7af62d076b125ead3b488bec0a9cb3c65a34", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/IWhTDmK76tp8kZsqepOJVrkuxk96NQLFbBuP-ezXdDs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60d0b9a18e5066d5bbb6c0da9a6480385d9f5060", "width": 960, "height": 502}], "variants": {}, "id": "BXS1AT07clwWnAlhvWWU_hm7yurdVaxCb1Hd5hxJz5o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyrudp", "is_robot_indexable": true, "report_reasons": null, "author": "zachm", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyrudp/youve_heard_of_big_data_now_get_ready_for_cozy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dolthub.com/blog/2022-11-18-cozy-data/", "subreddit_subscribers": 654842, "created_utc": 1668798336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Should i get 5 of these for my NAS? Curious if its worth it to use these or bite the bullet and get the Reds for a but more money.  \n\n\nThey are currently $199.99 at BestBuy\n\nWD - easystore 14TB External USB 3.0 Hard Drive - Black\n\nModel:WDBAMA0140HBK-NESNSKU:6425303\n\n[https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303](https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303)", "author_fullname": "t2_8wu8x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD - easystore 14TB External USB 3.0 Hard Drive For NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyk7mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Shuckable NAS Drives", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668778440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should i get 5 of these for my NAS? Curious if its worth it to use these or bite the bullet and get the Reds for a but more money.  &lt;/p&gt;\n\n&lt;p&gt;They are currently $199.99 at BestBuy&lt;/p&gt;\n\n&lt;p&gt;WD - easystore 14TB External USB 3.0 Hard Drive - Black&lt;/p&gt;\n\n&lt;p&gt;Model:WDBAMA0140HBK-NESNSKU:6425303&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303\"&gt;https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?auto=webp&amp;s=0d9dc09b0ad8bb581b3f12d19a61f850933bb13d", "width": 1452, "height": 5012}, "resolutions": [{"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f13038664e7cac7334520eb6f6219ebcaa06077d", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ced7daed466de03f936545afae108a381fbd5548", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99ce2e22c9b74024d7f6948409a3403bb9821faf", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a06827eb64f82327b663eeb4bcc50b34736b2469", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=959de205f67d48894b89a59f2999a355aea021a3", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f171001b6b2b3e2579548bf4f45f34f0ee94f5cb", "width": 1080, "height": 2160}], "variants": {}, "id": "v3nUqdM-I-azEYHHZp7B5iu55trREQB_4lBrJlrXTo0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yyk7mz", "is_robot_indexable": true, "report_reasons": null, "author": "ironman52885", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyk7mz/wd_easystore_14tb_external_usb_30_hard_drive_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyk7mz/wd_easystore_14tb_external_usb_30_hard_drive_for/", "subreddit_subscribers": 654842, "created_utc": 1668778440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nthis weekend, you can access every ebook on packtpub without a subscription.  \nDoes somebody have a script for a mass download? \n\nI searched on github but most of the scripts are outdated and none seems to be able to download books which you dont \"own\". \n\nMaybe a person with the skill is able to write a script this weekend. Sadly I dont have the knowledge to do so.", "author_fullname": "t2_303xiaj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "packtpub.com - free weekend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyoy34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668790897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;this weekend, you can access every ebook on packtpub without a subscription.&lt;br/&gt;\nDoes somebody have a script for a mass download? &lt;/p&gt;\n\n&lt;p&gt;I searched on github but most of the scripts are outdated and none seems to be able to download books which you dont &amp;quot;own&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;Maybe a person with the skill is able to write a script this weekend. Sadly I dont have the knowledge to do so.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyoy34", "is_robot_indexable": true, "report_reasons": null, "author": "D0mC0m", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyoy34/packtpubcom_free_weekend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyoy34/packtpubcom_free_weekend/", "subreddit_subscribers": 654842, "created_utc": 1668790897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "like on the title. i want to archive everything from the artists that I followed on Twitter just in case...", "author_fullname": "t2_60xzq29b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I download all media (pictures and videos) from everyone that I follow on Twitter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyi25r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668771657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;like on the title. i want to archive everything from the artists that I followed on Twitter just in case...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "newbie | 4TB ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyi25r", "is_robot_indexable": true, "report_reasons": null, "author": "HoangDung007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yyi25r/how_can_i_download_all_media_pictures_and_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyi25r/how_can_i_download_all_media_pictures_and_videos/", "subreddit_subscribers": 654842, "created_utc": 1668771657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all. So, I have here about 15 drives, with an eye toward getting a lot more. Currently they are stored in a full tower case, and a sans digital 5-bay rack. However, I would like to have them all consolidated into one case/rack. I want it to be just a plain storage unit, not an external raid controller; all that is handled by linux. Basically just a rack that provides power and slots. What should I be looking for?\r\n\r\nPS: totally unrelated, but why the hell is it so hard to find a full tower that doesn't have a bunch of stupid RGB with it? Grrr.", "author_fullname": "t2_nyaisr0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware suggestions for storing drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyecpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668757761.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668757530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. So, I have here about 15 drives, with an eye toward getting a lot more. Currently they are stored in a full tower case, and a sans digital 5-bay rack. However, I would like to have them all consolidated into one case/rack. I want it to be just a plain storage unit, not an external raid controller; all that is handled by linux. Basically just a rack that provides power and slots. What should I be looking for?&lt;/p&gt;\n\n&lt;p&gt;PS: totally unrelated, but why the hell is it so hard to find a full tower that doesn&amp;#39;t have a bunch of stupid RGB with it? Grrr.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyecpx", "is_robot_indexable": true, "report_reasons": null, "author": "the_purple_goat", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyecpx/hardware_suggestions_for_storing_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyecpx/hardware_suggestions_for_storing_drives/", "subreddit_subscribers": 654842, "created_utc": 1668757530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "*Note: I do have all the data I'm referring to backed up elsewhere*\n\nI'm on Windows 10 Pro and I've got two identical dynamic disks -- 3TB each with 2.4TB (or whatever) filled, each. I want to convert them to spanned or striped (haven't decided which, yet) but I don't seem to have the option -- it's greyed out in Disk Manager:\n\nhttps://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81\n\nDo I...need to shrink the disks to make room? I'm hesitant to try that without getting thoughts from others because it'll take the better part of a day, each disk. Do I...need to delete the volumes and create the array from scratch?\n\nI'd prefer a non-destructive option if possible. I'm willing to delete these because the data is backed up, but restoring it will be a PITA :)\n\nMuch appreciated.\n\nEdit: To anyone discovering this post in the future, here's what I ended up doing:\n\n* Deleting E:\\\\ merely allowed me the option to Extend D:\\\\ which doesn't cut it\n* Deleting D:\\\\ ALSO didn't give me the option to Stripe\n* Recreating  both volumes as Basic gave me the option to Stripe, but then it  wouldn't go through with the operation because there wasn't enough free  space on the drives??? Fucking hell\n* Deleted  partitions, created one 20MB partition on each drive, then finally was  able to Stripe the 99.9% remaining space on the two drives together. So  yeah I have 40MB between these drives that is pretty much useless so I  deleted those tiny partitions and will try to pretend they don't exist  and are constantly offending me", "author_fullname": "t2_36jz3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows: Can dynamic disks not be converted to spanned/striped?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"b203wafbjm0a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=94b6126cadbbbb1376df665d6a170fc771860b95"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ea9718fef595c82c340ac3622c2b2a951e1052b"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2265f302a5ff338b74ebf4de0a9b17ebb80d3252"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7cd33c67ecfeec80a2ec3738e382e54eecd19144"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=063565c5bab55cb108d470c859daba852a0a356d"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7893f3501b0345bcf7d35fda3017a05d217bb596"}], "s": {"y": 900, "x": 1440, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81"}, "id": "b203wafbjm0a1"}}, "name": "t3_yy99ds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vMb3XlrxBTmOW43DaRSvG5q-XrdleZUhBeYHO6lSV00.jpg", "edited": 1668806838.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668740163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Note: I do have all the data I&amp;#39;m referring to backed up elsewhere&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on Windows 10 Pro and I&amp;#39;ve got two identical dynamic disks -- 3TB each with 2.4TB (or whatever) filled, each. I want to convert them to spanned or striped (haven&amp;#39;t decided which, yet) but I don&amp;#39;t seem to have the option -- it&amp;#39;s greyed out in Disk Manager:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81\"&gt;https://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do I...need to shrink the disks to make room? I&amp;#39;m hesitant to try that without getting thoughts from others because it&amp;#39;ll take the better part of a day, each disk. Do I...need to delete the volumes and create the array from scratch?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefer a non-destructive option if possible. I&amp;#39;m willing to delete these because the data is backed up, but restoring it will be a PITA :)&lt;/p&gt;\n\n&lt;p&gt;Much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Edit: To anyone discovering this post in the future, here&amp;#39;s what I ended up doing:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Deleting E:\\ merely allowed me the option to Extend D:\\ which doesn&amp;#39;t cut it&lt;/li&gt;\n&lt;li&gt;Deleting D:\\ ALSO didn&amp;#39;t give me the option to Stripe&lt;/li&gt;\n&lt;li&gt;Recreating  both volumes as Basic gave me the option to Stripe, but then it  wouldn&amp;#39;t go through with the operation because there wasn&amp;#39;t enough free  space on the drives??? Fucking hell&lt;/li&gt;\n&lt;li&gt;Deleted  partitions, created one 20MB partition on each drive, then finally was  able to Stripe the 99.9% remaining space on the two drives together. So  yeah I have 40MB between these drives that is pretty much useless so I  deleted those tiny partitions and will try to pretend they don&amp;#39;t exist  and are constantly offending me&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy99ds", "is_robot_indexable": true, "report_reasons": null, "author": "eriksrx", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy99ds/windows_can_dynamic_disks_not_be_converted_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy99ds/windows_can_dynamic_disks_not_be_converted_to/", "subreddit_subscribers": 654842, "created_utc": 1668740163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow hoarders  \n\n\nAfter buying the DS920+ from Synology last month to replace my good old 10 or 11-year-old Thecus N2200 with 2x 1\u00a0TB, the time has come to buy the drives.  \nAt the moment, I have inside the DS920+, 3x 2 TB units + 1 TB unit.  \nMy idea in buying the NAS, is to have an easy place where to put my family photos, back up from the phones to the NAS automatically (ditching google photos), use a surveillance station with 2x cameras and the extra space is for building a media library.  \nI thought to buy 2 big units, shuck them, and put them inside the NAS in SHR RAID type; at the same time, put one 1 TB drive plus one 2 TB drive that came out of the NAS, inside the cases where the big drives came, connect them to RaspPIs with Rsync, one at my home other at brother-in-law, to automatically back up the family photos folder which I don't want to lose.\n\n&amp;#x200B;\n\nAfter looking at disk prices .com I found the 2 best deals at Amazon DE are the 18 TB Western Digital Elements units at \u20ac16.06/TB (\u20ac289) and the second-best deal is the WD My Book 16 TB at \u20ac16.5/TB (\u20ac264).  \n\n\nAfter reading around some older threads in the sub, I see some fellow hoarders point out the fact My Book has hardware encryption, making it not desirable to shuck and put it in the NAS. My first question is: Is this still true nowadays?  \nMy second question is, what drives are normally in?  \nI wanted to limit my expenses to around \u20ac300, which would get me 2x 8 TB, but this would also limit my future expandability, while 2x 16 TB seems much more future-proof for a bit more than \u20ac500.  \n\n\nIn your opinion, is this achieveable?  \nAre there any deals I should look into?  \n\n\nWhat would you buy nowadays?", "author_fullname": "t2_kmbe8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Another Elements vs MyBook thread", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yywkd1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668810751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow hoarders  &lt;/p&gt;\n\n&lt;p&gt;After buying the DS920+ from Synology last month to replace my good old 10 or 11-year-old Thecus N2200 with 2x 1\u00a0TB, the time has come to buy the drives.&lt;br/&gt;\nAt the moment, I have inside the DS920+, 3x 2 TB units + 1 TB unit.&lt;br/&gt;\nMy idea in buying the NAS, is to have an easy place where to put my family photos, back up from the phones to the NAS automatically (ditching google photos), use a surveillance station with 2x cameras and the extra space is for building a media library.&lt;br/&gt;\nI thought to buy 2 big units, shuck them, and put them inside the NAS in SHR RAID type; at the same time, put one 1 TB drive plus one 2 TB drive that came out of the NAS, inside the cases where the big drives came, connect them to RaspPIs with Rsync, one at my home other at brother-in-law, to automatically back up the family photos folder which I don&amp;#39;t want to lose.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;After looking at disk prices .com I found the 2 best deals at Amazon DE are the 18 TB Western Digital Elements units at \u20ac16.06/TB (\u20ac289) and the second-best deal is the WD My Book 16 TB at \u20ac16.5/TB (\u20ac264).  &lt;/p&gt;\n\n&lt;p&gt;After reading around some older threads in the sub, I see some fellow hoarders point out the fact My Book has hardware encryption, making it not desirable to shuck and put it in the NAS. My first question is: Is this still true nowadays?&lt;br/&gt;\nMy second question is, what drives are normally in?&lt;br/&gt;\nI wanted to limit my expenses to around \u20ac300, which would get me 2x 8 TB, but this would also limit my future expandability, while 2x 16 TB seems much more future-proof for a bit more than \u20ac500.  &lt;/p&gt;\n\n&lt;p&gt;In your opinion, is this achieveable?&lt;br/&gt;\nAre there any deals I should look into?  &lt;/p&gt;\n\n&lt;p&gt;What would you buy nowadays?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yywkd1", "is_robot_indexable": true, "report_reasons": null, "author": "Oinq", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yywkd1/another_elements_vs_mybook_thread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yywkd1/another_elements_vs_mybook_thread/", "subreddit_subscribers": 654842, "created_utc": 1668810751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyv5ap", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668807008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yyv5ap", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyv5ap/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/yyv5ap/datahoarder_discussion/", "subreddit_subscribers": 654842, "created_utc": 1668807008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nI'd like to set up a white box NAS that has some high-capacity HDDs with two mirrored 1TB or 2TB SSDs for additional fast storage. The goal with those is to keep the HDDs from spinning up every time the pool is accessed (for both a power and a noise perspective). I'd like for it to automatically shuffle data around periodically based on usage (i.e. most-used data stored on the SSDs).\n\nIs there anything that supports this? (Ideally with a nice GUI - nothing in Linux ever seems to \"just work\" from the command-line) I've messed around with TrueNAS in the past, but it doesn't seem like it can do any of what I'm mentioning (it cannot let the HDDs go to sleep (or something along those lines), cannot shuffle data around based on usage, and you can only use SSDs as a \"cache\" where the data is offloaded to the HDDs instead of having mirrored SSDs that actually store information).\n\nThank you", "author_fullname": "t2_2wj2od18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD + HDD Tiering Solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyt9fo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668802009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to set up a white box NAS that has some high-capacity HDDs with two mirrored 1TB or 2TB SSDs for additional fast storage. The goal with those is to keep the HDDs from spinning up every time the pool is accessed (for both a power and a noise perspective). I&amp;#39;d like for it to automatically shuffle data around periodically based on usage (i.e. most-used data stored on the SSDs).&lt;/p&gt;\n\n&lt;p&gt;Is there anything that supports this? (Ideally with a nice GUI - nothing in Linux ever seems to &amp;quot;just work&amp;quot; from the command-line) I&amp;#39;ve messed around with TrueNAS in the past, but it doesn&amp;#39;t seem like it can do any of what I&amp;#39;m mentioning (it cannot let the HDDs go to sleep (or something along those lines), cannot shuffle data around based on usage, and you can only use SSDs as a &amp;quot;cache&amp;quot; where the data is offloaded to the HDDs instead of having mirrored SSDs that actually store information).&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yyt9fo", "is_robot_indexable": true, "report_reasons": null, "author": "NateroniPizza", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyt9fo/ssd_hdd_tiering_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyt9fo/ssd_hdd_tiering_solution/", "subreddit_subscribers": 654842, "created_utc": 1668802009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "At first I was going to get two large 12-16 TB drives and put them into RAID 1, but after thinking about it is putting five or six 4 TB drives in RAID 5/6 a dumb idea for a beginner? The dollar/GB ratio is better and in case of a drive failure it's much cheaper to fix at $80-ish bucks a drive vs $220, but that is a lot more moving parts and probably over double the power in drives. I'm gonna be using it for ripping and hosting the family's DVD collection, my Blurays, PS2 games, and some important file backups. I'll be using a retired 4670k and 16gb of ram as the base for the system.\n\nActually, thinking about it now would it just be easier to see how far 4TB RAID 1 takes me and just upgrade to RAID 5/6 (if you can do that) from there if it looks like I can use all of those drives? Honestly I didn't really think about that until now.\n\nAlso, hardware or software RAID? Every time I look it up I see hardware RAID is a headache or software RAID is a headache, so I have no idea what the current consensus is.\n\nThanks for any help.", "author_fullname": "t2_507bd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First DIY NAS/home server, 2x big drives in RAID 1 or smaller drives in RAID 5/6?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyrhoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668797418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At first I was going to get two large 12-16 TB drives and put them into RAID 1, but after thinking about it is putting five or six 4 TB drives in RAID 5/6 a dumb idea for a beginner? The dollar/GB ratio is better and in case of a drive failure it&amp;#39;s much cheaper to fix at $80-ish bucks a drive vs $220, but that is a lot more moving parts and probably over double the power in drives. I&amp;#39;m gonna be using it for ripping and hosting the family&amp;#39;s DVD collection, my Blurays, PS2 games, and some important file backups. I&amp;#39;ll be using a retired 4670k and 16gb of ram as the base for the system.&lt;/p&gt;\n\n&lt;p&gt;Actually, thinking about it now would it just be easier to see how far 4TB RAID 1 takes me and just upgrade to RAID 5/6 (if you can do that) from there if it looks like I can use all of those drives? Honestly I didn&amp;#39;t really think about that until now.&lt;/p&gt;\n\n&lt;p&gt;Also, hardware or software RAID? Every time I look it up I see hardware RAID is a headache or software RAID is a headache, so I have no idea what the current consensus is.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyrhoh", "is_robot_indexable": true, "report_reasons": null, "author": "TwistedD85", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyrhoh/first_diy_nashome_server_2x_big_drives_in_raid_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyrhoh/first_diy_nashome_server_2x_big_drives_in_raid_1/", "subreddit_subscribers": 654842, "created_utc": 1668797418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Time for another giveaway! This time around, we are giving away an **IronWolf Pro 125 960GB SSD** to one lucky winner in this thread!\n\nHappy Holidays. We have reached out to the moderators regarding another giveaway because this subreddit is awesome and we love running activities with you all!\n\n**The prize is: one IronWolf Pro 125 960GB SSD**\n\nHow to enter:\n\nJust reply to this post once with a comment about what you are thankful for. **We ask entrants to please include the terms RunWithIronWolf and Seagate in your comment to be considered for the prize drawing.**\n\nFeel free to let us know just what you would do with the extra drive!\n\nSelection process/rules\n\nOne entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. **Entries are open until November 30th 2022, 23:59 UTC**. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n\nGeographic restrictions:\n\nOur policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)\n\nUS\n\nCanada (exc. Quebec and will require a basic skills-based question if winner is chosen by law)\n\nBrazil\n\nSouth America\n\nUnited Kingdom\n\nGermany\n\nFrance\n\nIberia\n\nAustralia\n\nNew Zealand\n\nKorea\n\nIndia\n\nMalaysia\n\nSingapore\n\nChina", "author_fullname": "t2_16nn7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Official Giveaway: November Seagate IronWolf Giveaway!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyqmrx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": "", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OFFICIAL", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668795165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Time for another giveaway! This time around, we are giving away an &lt;strong&gt;IronWolf Pro 125 960GB SSD&lt;/strong&gt; to one lucky winner in this thread!&lt;/p&gt;\n\n&lt;p&gt;Happy Holidays. We have reached out to the moderators regarding another giveaway because this subreddit is awesome and we love running activities with you all!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The prize is: one IronWolf Pro 125 960GB SSD&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How to enter:&lt;/p&gt;\n\n&lt;p&gt;Just reply to this post once with a comment about what you are thankful for. &lt;strong&gt;We ask entrants to please include the terms RunWithIronWolf and Seagate in your comment to be considered for the prize drawing.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Feel free to let us know just what you would do with the extra drive!&lt;/p&gt;\n\n&lt;p&gt;Selection process/rules&lt;/p&gt;\n\n&lt;p&gt;One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. &lt;strong&gt;Entries are open until November 30th 2022, 23:59 UTC&lt;/strong&gt;. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.&lt;/p&gt;\n\n&lt;p&gt;Geographic restrictions:&lt;/p&gt;\n\n&lt;p&gt;Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)&lt;/p&gt;\n\n&lt;p&gt;US&lt;/p&gt;\n\n&lt;p&gt;Canada (exc. Quebec and will require a basic skills-based question if winner is chosen by law)&lt;/p&gt;\n\n&lt;p&gt;Brazil&lt;/p&gt;\n\n&lt;p&gt;South America&lt;/p&gt;\n\n&lt;p&gt;United Kingdom&lt;/p&gt;\n\n&lt;p&gt;Germany&lt;/p&gt;\n\n&lt;p&gt;France&lt;/p&gt;\n\n&lt;p&gt;Iberia&lt;/p&gt;\n\n&lt;p&gt;Australia&lt;/p&gt;\n\n&lt;p&gt;New Zealand&lt;/p&gt;\n\n&lt;p&gt;Korea&lt;/p&gt;\n\n&lt;p&gt;India&lt;/p&gt;\n\n&lt;p&gt;Malaysia&lt;/p&gt;\n\n&lt;p&gt;Singapore&lt;/p&gt;\n\n&lt;p&gt;China&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "81f0a58e-b3f5-11ea-95d7-0e4db8ecc231", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "OFFICIAL SEAGATE", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "yyqmrx", "is_robot_indexable": true, "report_reasons": null, "author": "Seagate_Surfer", "discussion_type": null, "num_comments": 64, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yyqmrx/official_giveaway_november_seagate_ironwolf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyqmrx/official_giveaway_november_seagate_ironwolf/", "subreddit_subscribers": 654842, "created_utc": 1668795165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hiya. I've bought an old 8 bay server that came with\n\n* 4x 1TB drives in it\n* Supermicro X9DRH-7TF/7F/iTF/iF motherboard\n* Xeon E5-2603 1.80 GHz\n* 8gb or DDR3 1333 Mhz ram\n* Areca Arc-1222 pcie raid controller\n* A proprietary modified debian 6 by a local it company\n\nIt was working fine but then I thought let's try adding more drives into the remaining bays and see how that works\n\nWell. It didn't. I managed to expand the raidset but the proprietary software that runs filesharing was pretty obfuscated and locked down with how and what it sees. I've contacted the company and they said 'sorry mate, that things been out of support for years. buy a new one'\n\nSo I jumped onto the next logical step. Let's wipe the whole thing and install something else on it. So I wiped it and tried installing openmediavault.\n\nBooted into installer, all looking good.Installer sees all my raidcard volumes, all good.\n\nInstalled it on a dedicated 10GB OS partition on the raidcard, all good.\n\nReboot\n\nSee the grub window\n\nThen black screen with the cursor for 10 minutes\n\nThen barrage of errors\n\nThought maybe faulty USB stick or smtn, tried reinstalling from another stick and a usb SSD drive. Same result.\n\nNext thing I had tried is installing mediavault not onto a RAID volume but onto USB stick instead and booting from that.\n\nSurprise, that booted in just fine!\n\nBUT\n\nOS doesn't see any of the RAID card volumes. Well it only sees them partially\n\nIn the OS raidcard volumes sda, sdb can\u2019t be accessed or mounted.\n\nThey appear listed with **lsblk** and **cat /proc/partitions** and are listed in **/dev/disk/by-path** (but not in by-id/by-partuuid/by-uuid).\n\nBut they don't appear when using **fdisk -l** and similar commands\n\nI could find messages like\n\n*I/O error, dev sda, sector 0 op 0x0:(READ) flags 0x0 phys\\_seg 1 prio class 0*\n\n*Nov 11 10:35:06 openmediavault kernel: Buffer I/O error on dev sda, logical block 0, async page read*\n\nI've tried installing raidcard driver I had found on the Areca website\n\n**arcmsr\\_1.50.0X.09-2-OMV6.0.24-k5.16.0-0.bpo.4-amd64.deb**\n\nRebooted, but still had same issue of raid volumes being only partially seen.\n\nI had also installed their raidcard monitoring tool which works fine but doesn't see any raid controllers in the web gui it comes with.\n\nI've had emailed Areca support a month ago about this but considering its a 10 year old legacy product I doubt they'll ever come back to me.\n\nI'm 90% leaning towards it being a raidcard driver issue. Anyone familiar with these older Areca cards? Do I need to use an older OS possibly for it to work?\n\nIdeally I'd like to just install any OS on a Raidcard volume that would let me share drives over SMB.\n\nI think motherboard itself might have 8 sata ports so i could potentially plug drives into that but I'd lose any hot swapping ability by doing that.\n\nIs it possible to save this at all? It was working fine for few weeks with the original 4 drives and software in place till I decided to 'upgrade'...\n\nHere's a link to journalctllog of when I boot into OS off USB\n\n[https://pastebin.com/A7pum7UW](https://pastebin.com/A7pum7UW)", "author_fullname": "t2_16yjgj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with a bargain server i got : /", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyeyvz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668761335.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668759924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hiya. I&amp;#39;ve bought an old 8 bay server that came with&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4x 1TB drives in it&lt;/li&gt;\n&lt;li&gt;Supermicro X9DRH-7TF/7F/iTF/iF motherboard&lt;/li&gt;\n&lt;li&gt;Xeon E5-2603 1.80 GHz&lt;/li&gt;\n&lt;li&gt;8gb or DDR3 1333 Mhz ram&lt;/li&gt;\n&lt;li&gt;Areca Arc-1222 pcie raid controller&lt;/li&gt;\n&lt;li&gt;A proprietary modified debian 6 by a local it company&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It was working fine but then I thought let&amp;#39;s try adding more drives into the remaining bays and see how that works&lt;/p&gt;\n\n&lt;p&gt;Well. It didn&amp;#39;t. I managed to expand the raidset but the proprietary software that runs filesharing was pretty obfuscated and locked down with how and what it sees. I&amp;#39;ve contacted the company and they said &amp;#39;sorry mate, that things been out of support for years. buy a new one&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;So I jumped onto the next logical step. Let&amp;#39;s wipe the whole thing and install something else on it. So I wiped it and tried installing openmediavault.&lt;/p&gt;\n\n&lt;p&gt;Booted into installer, all looking good.Installer sees all my raidcard volumes, all good.&lt;/p&gt;\n\n&lt;p&gt;Installed it on a dedicated 10GB OS partition on the raidcard, all good.&lt;/p&gt;\n\n&lt;p&gt;Reboot&lt;/p&gt;\n\n&lt;p&gt;See the grub window&lt;/p&gt;\n\n&lt;p&gt;Then black screen with the cursor for 10 minutes&lt;/p&gt;\n\n&lt;p&gt;Then barrage of errors&lt;/p&gt;\n\n&lt;p&gt;Thought maybe faulty USB stick or smtn, tried reinstalling from another stick and a usb SSD drive. Same result.&lt;/p&gt;\n\n&lt;p&gt;Next thing I had tried is installing mediavault not onto a RAID volume but onto USB stick instead and booting from that.&lt;/p&gt;\n\n&lt;p&gt;Surprise, that booted in just fine!&lt;/p&gt;\n\n&lt;p&gt;BUT&lt;/p&gt;\n\n&lt;p&gt;OS doesn&amp;#39;t see any of the RAID card volumes. Well it only sees them partially&lt;/p&gt;\n\n&lt;p&gt;In the OS raidcard volumes sda, sdb can\u2019t be accessed or mounted.&lt;/p&gt;\n\n&lt;p&gt;They appear listed with &lt;strong&gt;lsblk&lt;/strong&gt; and &lt;strong&gt;cat /proc/partitions&lt;/strong&gt; and are listed in &lt;strong&gt;/dev/disk/by-path&lt;/strong&gt; (but not in by-id/by-partuuid/by-uuid).&lt;/p&gt;\n\n&lt;p&gt;But they don&amp;#39;t appear when using &lt;strong&gt;fdisk -l&lt;/strong&gt; and similar commands&lt;/p&gt;\n\n&lt;p&gt;I could find messages like&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I/O error, dev sda, sector 0 op 0x0:(READ) flags 0x0 phys_seg 1 prio class 0&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Nov 11 10:35:06 openmediavault kernel: Buffer I/O error on dev sda, logical block 0, async page read&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried installing raidcard driver I had found on the Areca website&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;arcmsr_1.50.0X.09-2-OMV6.0.24-k5.16.0-0.bpo.4-amd64.deb&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Rebooted, but still had same issue of raid volumes being only partially seen.&lt;/p&gt;\n\n&lt;p&gt;I had also installed their raidcard monitoring tool which works fine but doesn&amp;#39;t see any raid controllers in the web gui it comes with.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had emailed Areca support a month ago about this but considering its a 10 year old legacy product I doubt they&amp;#39;ll ever come back to me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m 90% leaning towards it being a raidcard driver issue. Anyone familiar with these older Areca cards? Do I need to use an older OS possibly for it to work?&lt;/p&gt;\n\n&lt;p&gt;Ideally I&amp;#39;d like to just install any OS on a Raidcard volume that would let me share drives over SMB.&lt;/p&gt;\n\n&lt;p&gt;I think motherboard itself might have 8 sata ports so i could potentially plug drives into that but I&amp;#39;d lose any hot swapping ability by doing that.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to save this at all? It was working fine for few weeks with the original 4 drives and software in place till I decided to &amp;#39;upgrade&amp;#39;...&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a link to journalctllog of when I boot into OS off USB&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/A7pum7UW\"&gt;https://pastebin.com/A7pum7UW&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;s=07c121a0180003f7373863af66192b6ff6a937da", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9c6a296446d05d873c629a30253398c4d29c1b", "width": 108, "height": 108}], "variants": {}, "id": "OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyeyvz", "is_robot_indexable": true, "report_reasons": null, "author": "poliver1988", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyeyvz/struggling_with_a_bargain_server_i_got/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyeyvz/struggling_with_a_bargain_server_i_got/", "subreddit_subscribers": 654842, "created_utc": 1668759924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two needs:\n\n1. backup 1.5 TB of data on my main machine to an S3 bucket (B2, S3, etc...)\n2. sync a sub folder (of the 1.5 TB) between my laptop and main machine\n\nI've always used SyncThing to sync my two machines (#2). But then I came across GoodSync and see that it can do both: P2P syncing and backing up.\n\nI looked around for other products that do both but can't find any. I thought I would check here before I pull the trigger.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is GoodSync the only product that backup to S3 buckets AND P2P sync with another machine on the LAN?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy9y67", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668742248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two needs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;backup 1.5 TB of data on my main machine to an S3 bucket (B2, S3, etc...)&lt;/li&gt;\n&lt;li&gt;sync a sub folder (of the 1.5 TB) between my laptop and main machine&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve always used SyncThing to sync my two machines (#2). But then I came across GoodSync and see that it can do both: P2P syncing and backing up.&lt;/p&gt;\n\n&lt;p&gt;I looked around for other products that do both but can&amp;#39;t find any. I thought I would check here before I pull the trigger.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy9y67", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy9y67/is_goodsync_the_only_product_that_backup_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy9y67/is_goodsync_the_only_product_that_backup_to_s3/", "subreddit_subscribers": 654842, "created_utc": 1668742248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been using `rclone` for years on my Linux server. I have a script I wrote that backed up data, logged in, and sent pretty HTML emails with status.\n\nFor complicated reasons, I am getting rid of my Linux server and moving everything to my daily driver Windows 10 machine.\n\nI don't have time or patience to write a new script. I know I can use my old Linux script using WSL or something but I'm hoping for something more native to Windows.\n\nI was looking at alternatives to `rclone` that are easier to use on Windows like GoodSync but, honestly, when I do research, everyone says they all have issues and `rclone` is the best (it is).\n\nI don't want to re-create the wheel. I feel like this is a common problem that someone must have solved.\n\nIf not, I feel like there is a huge opportunity here for someone to wrap a pretty basic GUI around `rclone` for Windows. Something that'll let you create scheduled tasks with features like email notifications and what not.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any robust backup scripts for Windows 10 loaded with features like email notifications, rich formatted logs, etc. so I don't have to re-create the wheel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yz0jp3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668822337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using &lt;code&gt;rclone&lt;/code&gt; for years on my Linux server. I have a script I wrote that backed up data, logged in, and sent pretty HTML emails with status.&lt;/p&gt;\n\n&lt;p&gt;For complicated reasons, I am getting rid of my Linux server and moving everything to my daily driver Windows 10 machine.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have time or patience to write a new script. I know I can use my old Linux script using WSL or something but I&amp;#39;m hoping for something more native to Windows.&lt;/p&gt;\n\n&lt;p&gt;I was looking at alternatives to &lt;code&gt;rclone&lt;/code&gt; that are easier to use on Windows like GoodSync but, honestly, when I do research, everyone says they all have issues and &lt;code&gt;rclone&lt;/code&gt; is the best (it is).&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to re-create the wheel. I feel like this is a common problem that someone must have solved.&lt;/p&gt;\n\n&lt;p&gt;If not, I feel like there is a huge opportunity here for someone to wrap a pretty basic GUI around &lt;code&gt;rclone&lt;/code&gt; for Windows. Something that&amp;#39;ll let you create scheduled tasks with features like email notifications and what not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yz0jp3", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yz0jp3/are_there_any_robust_backup_scripts_for_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yz0jp3/are_there_any_robust_backup_scripts_for_windows/", "subreddit_subscribers": 654842, "created_utc": 1668822337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys,\n\nI was told by someone I should download to D first and then transfer in order to not make the WD too busy.\n\nBut I don\u2019t have much space in D, so if I do this it may be a little annoying to download little portions and then transfer. And if I do so, I don\u2019t know if it\u2019s good whether I keep my WD constantly connected or disconnect and reconnect it several times.\n\nOn the other hand, I can just download directly to the WD. I just wonder if it\u2019s safe for it, as I\u2019ve heard the small ones which are not SSD are very sensitive and vulnerable.\n\nThanks in advance.", "author_fullname": "t2_16vs44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I download files directly to my 5tb WD Elements, or download to internal D drive and then transfer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyypj8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668816697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I was told by someone I should download to D first and then transfer in order to not make the WD too busy.&lt;/p&gt;\n\n&lt;p&gt;But I don\u2019t have much space in D, so if I do this it may be a little annoying to download little portions and then transfer. And if I do so, I don\u2019t know if it\u2019s good whether I keep my WD constantly connected or disconnect and reconnect it several times.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, I can just download directly to the WD. I just wonder if it\u2019s safe for it, as I\u2019ve heard the small ones which are not SSD are very sensitive and vulnerable.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyypj8", "is_robot_indexable": true, "report_reasons": null, "author": "toktok159", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyypj8/should_i_download_files_directly_to_my_5tb_wd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyypj8/should_i_download_files_directly_to_my_5tb_wd/", "subreddit_subscribers": 654842, "created_utc": 1668816697.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}