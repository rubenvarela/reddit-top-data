{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a large organization and share data permissions that 1,700 people in the org also have. I recently ran a query while investigating a dataset that returned sensitive information to the org. I was unaware of what it would return, stopped once I realized what it was, but am worried about the fallout. If it was an accident am I at risk of any repercussions?", "author_fullname": "t2_38elj5k6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Saw data I shouldn\u2019t have seen", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3xgak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669331516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a large organization and share data permissions that 1,700 people in the org also have. I recently ran a query while investigating a dataset that returned sensitive information to the org. I was unaware of what it would return, stopped once I realized what it was, but am worried about the fallout. If it was an accident am I at risk of any repercussions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3xgak", "is_robot_indexable": true, "report_reasons": null, "author": "afdsrewtg", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3xgak/saw_data_i_shouldnt_have_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3xgak/saw_data_i_shouldnt_have_seen/", "subreddit_subscribers": 80911, "created_utc": 1669331516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to build a portfolio site (not GitHub) that showcases all my projects in a visually appealing way. I'm aware about GitHub pages \u2013 not quite what I'm looking for.\n\nProblem is that my web development knowledge is minimal. And I don't want to go down the web development rabbit hole just to build a portfolio site.\n\nI've looked at [fastpages](https://fastpages.fast.ai/). But it's mainly for writing blog like content.\n\nWhat I'm looking for is a way to showcase my projects as tiles on the landing page. On click they should expand to show the details.\n\nIn addition it should have an about-me and my resume.", "author_fullname": "t2_pblux6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quickest way to build a portfolio site with minimal web development knowledge?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3o340", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669306831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to build a portfolio site (not GitHub) that showcases all my projects in a visually appealing way. I&amp;#39;m aware about GitHub pages \u2013 not quite what I&amp;#39;m looking for.&lt;/p&gt;\n\n&lt;p&gt;Problem is that my web development knowledge is minimal. And I don&amp;#39;t want to go down the web development rabbit hole just to build a portfolio site.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at &lt;a href=\"https://fastpages.fast.ai/\"&gt;fastpages&lt;/a&gt;. But it&amp;#39;s mainly for writing blog like content.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is a way to showcase my projects as tiles on the landing page. On click they should expand to show the details.&lt;/p&gt;\n\n&lt;p&gt;In addition it should have an about-me and my resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hWTW2xpgF2jQZc0p76GmCXQm895W3vkrDZA3K_gx6yI.jpg?auto=webp&amp;s=47c777c563d22912b7e699a7ed6ab0c00ad16f49", "width": 234, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/hWTW2xpgF2jQZc0p76GmCXQm895W3vkrDZA3K_gx6yI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a319550c129d6b66d478a63fd26625ab7f32915", "width": 108, "height": 138}, {"url": "https://external-preview.redd.it/hWTW2xpgF2jQZc0p76GmCXQm895W3vkrDZA3K_gx6yI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e9dbd154ff76c353ddc11b24723413b7c9da1a4c", "width": 216, "height": 276}], "variants": {}, "id": "6rsKEAYlH0fj3pQKUJhL3mgn8frT2UeC3KVsYSOHoSQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z3o340", "is_robot_indexable": true, "report_reasons": null, "author": "newplayer12345", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3o340/quickest_way_to_build_a_portfolio_site_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3o340/quickest_way_to_build_a_portfolio_site_with/", "subreddit_subscribers": 80911, "created_utc": 1669306831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I spent the last 4 years working with SSIS but now my boss ask me if we should keep using ssis or we should use another tool. Do you have any recommendation?", "author_fullname": "t2_smy5zdxu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3uj7a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669323767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I spent the last 4 years working with SSIS but now my boss ask me if we should keep using ssis or we should use another tool. Do you have any recommendation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3uj7a", "is_robot_indexable": true, "report_reasons": null, "author": "Worried_Caregiver673", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3uj7a/etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3uj7a/etl_tool/", "subreddit_subscribers": 80911, "created_utc": 1669323767.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a B2B company and have been assigned SAP-BI- Enterprise Data Engineer. In this, the tools I've been given are: \n\n1. Data management \n2. SAP HANA/BW \n3. BODS/EPM\n4. Master data management \n\nI'm getting paid less compared to software roles, what are your suggestions regarding this career starter? Should I start applying for other roles?", "author_fullname": "t2_7k0sexco", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been assigned SAP-Business Intelligence, is it a good career starter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3qlpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669313194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a B2B company and have been assigned SAP-BI- Enterprise Data Engineer. In this, the tools I&amp;#39;ve been given are: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data management &lt;/li&gt;\n&lt;li&gt;SAP HANA/BW &lt;/li&gt;\n&lt;li&gt;BODS/EPM&lt;/li&gt;\n&lt;li&gt;Master data management &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m getting paid less compared to software roles, what are your suggestions regarding this career starter? Should I start applying for other roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3qlpz", "is_robot_indexable": true, "report_reasons": null, "author": "ItsAXE93", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3qlpz/ive_been_assigned_sapbusiness_intelligence_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3qlpz/ive_been_assigned_sapbusiness_intelligence_is_it/", "subreddit_subscribers": 80911, "created_utc": 1669313194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your thoughts on joining a consultancy? For those that have made the move from working in a normal business in data engineering/BI to working in a consultancy and being more in a client facing role, advising etc?", "author_fullname": "t2_12rfbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on joining a consultancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3s2i1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669316942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your thoughts on joining a consultancy? For those that have made the move from working in a normal business in data engineering/BI to working in a consultancy and being more in a client facing role, advising etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3s2i1", "is_robot_indexable": true, "report_reasons": null, "author": "That_Sweet_Science", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3s2i1/thoughts_on_joining_a_consultancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3s2i1/thoughts_on_joining_a_consultancy/", "subreddit_subscribers": 80911, "created_utc": 1669316942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I have been assigned to do a data lake update based off of tables' changes from source system, the changes are fairly simple i.e. column length changes + few additional columns for about \\~100 tables, for the most part it's a pretty straight forward task i.e. truncate existing tables and then do schema changes and then repopulate everything from source, all of this can be done within a few hours, however, we have a couple of tables that are terribly huge i.e. 2 Billion to 5 billion records and they are a huge pain in the ass, I mean even with truncate and reload, they would take atleast a few days, just wanted to ask everyone how do you manage these schema changes? \n\nFor a few reasons, creating a new table and dumping everything from the old table to new table is not an option.\n\n  \nEdit 1: For reference,\n\nBefore:\n\n|A (varchar(10))|B (int)|C (decimal (18,2))|\n|:-|:-|:-|\n||||\n\nAfter:\n\n|A (varchar(20))|B (int)|X (int)|Y (bit)|C (decimal (18,4))|\n|:-|:-|:-|:-|:-|\n||||||\n\n  \nEdit 2: We are using SQL Server 2017", "author_fullname": "t2_2xpdiv8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage schema changes for extremely large tables i.e. Billion row tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3zzla", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669345533.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669338901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I have been assigned to do a data lake update based off of tables&amp;#39; changes from source system, the changes are fairly simple i.e. column length changes + few additional columns for about ~100 tables, for the most part it&amp;#39;s a pretty straight forward task i.e. truncate existing tables and then do schema changes and then repopulate everything from source, all of this can be done within a few hours, however, we have a couple of tables that are terribly huge i.e. 2 Billion to 5 billion records and they are a huge pain in the ass, I mean even with truncate and reload, they would take atleast a few days, just wanted to ask everyone how do you manage these schema changes? &lt;/p&gt;\n\n&lt;p&gt;For a few reasons, creating a new table and dumping everything from the old table to new table is not an option.&lt;/p&gt;\n\n&lt;p&gt;Edit 1: For reference,&lt;/p&gt;\n\n&lt;p&gt;Before:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;A (varchar(10))&lt;/th&gt;\n&lt;th align=\"left\"&gt;B (int)&lt;/th&gt;\n&lt;th align=\"left\"&gt;C (decimal (18,2))&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;After:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;A (varchar(20))&lt;/th&gt;\n&lt;th align=\"left\"&gt;B (int)&lt;/th&gt;\n&lt;th align=\"left\"&gt;X (int)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Y (bit)&lt;/th&gt;\n&lt;th align=\"left\"&gt;C (decimal (18,4))&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Edit 2: We are using SQL Server 2017&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3zzla", "is_robot_indexable": true, "report_reasons": null, "author": "_whitezetsu", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3zzla/how_do_you_manage_schema_changes_for_extremely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3zzla/how_do_you_manage_schema_changes_for_extremely/", "subreddit_subscribers": 80911, "created_utc": 1669338901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys hope every one is doing well. I was doing web scrapping and used a bit of regular expression in my code. My friend who is a software engineer says that using Regular expression in the code in his team is not allowed and SonarLint that they use for checking the quality of code throws up warning if it finds any regex. Is this specific to his team or in general is it a bad habit to use regex?", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Regular Expressions in code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3r801", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669314762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys hope every one is doing well. I was doing web scrapping and used a bit of regular expression in my code. My friend who is a software engineer says that using Regular expression in the code in his team is not allowed and SonarLint that they use for checking the quality of code throws up warning if it finds any regex. Is this specific to his team or in general is it a bad habit to use regex?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z3r801", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 16, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3r801/using_regular_expressions_in_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3r801/using_regular_expressions_in_code/", "subreddit_subscribers": 80911, "created_utc": 1669314762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6n3p4gou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create connection to Azure SQL database from Azure Data Factory using Managed Identity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_z3pum4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rZwoaYhDWTMjZf3mg6PjG0s7yJcdyJIL5hChexRFNTo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669311268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "azureops.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://azureops.org/articles/connect-azure-sql-from-data-factory-using-managed-identity/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?auto=webp&amp;s=69d377543539f3a3feca537e54fce9df2c70c862", "width": 1890, "height": 939}, "resolutions": [{"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f3666d32a31b10044952e7b011f0df6e1424125", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f291aeb3be47aa5932cdce7ba7c3855aa4de292", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e3bb0db6de62e355f1356b7950185eb40c6ef93", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=387d18f48806ec18e34f499922f28945122f744d", "width": 640, "height": 317}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=20f6287c889c88ea6e83359af95bd1bdb344b843", "width": 960, "height": 476}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=09d5d5e716940379bcfc7641c0b880d92b103b64", "width": 1080, "height": 536}], "variants": {}, "id": "Dn0PpBHGV2CWNBDb1yHTEO-oc5_jqU3k9EuRnXebXbI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3pum4", "is_robot_indexable": true, "report_reasons": null, "author": "k53r", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3pum4/how_to_create_connection_to_azure_sql_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://azureops.org/articles/connect-azure-sql-from-data-factory-using-managed-identity/", "subreddit_subscribers": 80911, "created_utc": 1669311268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assuming you can do what you need to do in both, which is your go-to method?\n\n[View Poll](https://www.reddit.com/poll/z4662h)", "author_fullname": "t2_6ae9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is your preferred method of filtering/cleaning data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z4662h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669357895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming you can do what you need to do in both, which is your go-to method?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/z4662h\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z4662h", "is_robot_indexable": true, "report_reasons": null, "author": "gerdes88", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1669530695874, "options": [{"text": "Built-in functions in spart, pandas etc.", "id": "20012155"}, {"text": "Regex", "id": "20012156"}, {"text": "Others", "id": "20012157"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 137, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z4662h/what_is_your_preferred_method_of/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/z4662h/what_is_your_preferred_method_of/", "subreddit_subscribers": 80911, "created_utc": 1669357895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let\u2019s say you have rows of aggregated data, so there are category fields and the a sum field. You want to reassign a portion of each record. Maybe you want 25% of each sum to be reassigned to another record. \n\nYou could split each record into two records and add a proration field which has 75% next to the first row and 25% next to the second row. Then you could change values in the 25% records however you wanted, or add fields for each proration.  Maybe you do this by joining the table to another table which has two records for each PK in the first table, and the proration, and then the information linked to each proration. \n\nI\u2019m sure there are many variations one could do, but I\u2019m wondering if this is so common it has a basic name I\u2019m not thinking of. \u201cSplit each row by proration.\u201d  Is that a thing, and is there a term for it?", "author_fullname": "t2_1nhgn5i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you call a process that splits/bifurcates records by percentage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z40rg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669341231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you have rows of aggregated data, so there are category fields and the a sum field. You want to reassign a portion of each record. Maybe you want 25% of each sum to be reassigned to another record. &lt;/p&gt;\n\n&lt;p&gt;You could split each record into two records and add a proration field which has 75% next to the first row and 25% next to the second row. Then you could change values in the 25% records however you wanted, or add fields for each proration.  Maybe you do this by joining the table to another table which has two records for each PK in the first table, and the proration, and then the information linked to each proration. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure there are many variations one could do, but I\u2019m wondering if this is so common it has a basic name I\u2019m not thinking of. \u201cSplit each row by proration.\u201d  Is that a thing, and is there a term for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z40rg8", "is_robot_indexable": true, "report_reasons": null, "author": "eerilyweird", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z40rg8/what_do_you_call_a_process_that_splitsbifurcates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z40rg8/what_do_you_call_a_process_that_splitsbifurcates/", "subreddit_subscribers": 80911, "created_utc": 1669341231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined a new company and my profile is data analyst. I have experience working as data scientist previously (where i mostly focused on model).\n\nIn this new job all i do is create logics to make a data set. This data is automated by a data engineer. But whole sql query to create the table is done by me. I don't feel like this is an analyts work. My work should start post data creation and involve reporting.\n\nI am confused about this job and thinking of leaving it as i don't enjoy this . I want to go to model creation. \n\nMay be my understanding of data analyst role is wrong itself but i have never heard analysts create datasets. \n\nPlease correct me if i am wrong.", "author_fullname": "t2_96kg5df4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on the taks that I do? Am I doing a data engineer's work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3sw47", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669319194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a new company and my profile is data analyst. I have experience working as data scientist previously (where i mostly focused on model).&lt;/p&gt;\n\n&lt;p&gt;In this new job all i do is create logics to make a data set. This data is automated by a data engineer. But whole sql query to create the table is done by me. I don&amp;#39;t feel like this is an analyts work. My work should start post data creation and involve reporting.&lt;/p&gt;\n\n&lt;p&gt;I am confused about this job and thinking of leaving it as i don&amp;#39;t enjoy this . I want to go to model creation. &lt;/p&gt;\n\n&lt;p&gt;May be my understanding of data analyst role is wrong itself but i have never heard analysts create datasets. &lt;/p&gt;\n\n&lt;p&gt;Please correct me if i am wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3sw47", "is_robot_indexable": true, "report_reasons": null, "author": "AC_PV_1526388", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3sw47/question_on_the_taks_that_i_do_am_i_doing_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3sw47/question_on_the_taks_that_i_do_am_i_doing_a_data/", "subreddit_subscribers": 80911, "created_utc": 1669319194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to run a stored procedure from Airflow but even when the stored proc is completed on the DB the airflow task still keeps on running. I have tried several things but to no success. \nPosted a question on stack oveflow with more details https://stackoverflow.com/questions/74561761/airflow-task-executing-stored-procedure-does-not-complete-even-if-the-stored-pro\n\nHelp appreciated \ud83d\ude03", "author_fullname": "t2_2jrdmyff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running stored procedures from Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3nw73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669306376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to run a stored procedure from Airflow but even when the stored proc is completed on the DB the airflow task still keeps on running. I have tried several things but to no success. \nPosted a question on stack oveflow with more details &lt;a href=\"https://stackoverflow.com/questions/74561761/airflow-task-executing-stored-procedure-does-not-complete-even-if-the-stored-pro\"&gt;https://stackoverflow.com/questions/74561761/airflow-task-executing-stored-procedure-does-not-complete-even-if-the-stored-pro&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Help appreciated \ud83d\ude03&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3nw73", "is_robot_indexable": true, "report_reasons": null, "author": "tejaswajain", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3nw73/running_stored_procedures_from_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3nw73/running_stored_procedures_from_airflow/", "subreddit_subscribers": 80911, "created_utc": 1669306376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI'm a web/game been recommended for a data engineering position that I'm not quite qualified for. However, I'm generally a quick study, and I'm very familiar with the data and stakeholders, so I think I'd make a good fit. I also have a long Christmas break to read up on things, and they are aware of my background.\n\nI will put together a quick demo to show, but I'm not quite sure which stack to use. I'm familiar with gcp, Kubernetes, docker, openshift and a tiny bit with aws, but I've only worked in already set up environments, I haven't set up anything myself.\n\nThe plan is to put together and simple front and backend (some javascript framework + c# or python) with a Redis database running in containers, and have it hosted as a website. I don't mind paying for this bit. My main concern is connecting everything, as in getting the backend fetch data from Redis, hosting the site on a url ect. I haven't found any resources that details the whole flow, so my knowledge is quite shattered.\n\nSo my question here is, what would be an easy stack to use for this? \n\nI hope I made sense, and thank you very much for taking your time to read this.", "author_fullname": "t2_71he9mqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me pick a stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3me88", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669302721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a web/game been recommended for a data engineering position that I&amp;#39;m not quite qualified for. However, I&amp;#39;m generally a quick study, and I&amp;#39;m very familiar with the data and stakeholders, so I think I&amp;#39;d make a good fit. I also have a long Christmas break to read up on things, and they are aware of my background.&lt;/p&gt;\n\n&lt;p&gt;I will put together a quick demo to show, but I&amp;#39;m not quite sure which stack to use. I&amp;#39;m familiar with gcp, Kubernetes, docker, openshift and a tiny bit with aws, but I&amp;#39;ve only worked in already set up environments, I haven&amp;#39;t set up anything myself.&lt;/p&gt;\n\n&lt;p&gt;The plan is to put together and simple front and backend (some javascript framework + c# or python) with a Redis database running in containers, and have it hosted as a website. I don&amp;#39;t mind paying for this bit. My main concern is connecting everything, as in getting the backend fetch data from Redis, hosting the site on a url ect. I haven&amp;#39;t found any resources that details the whole flow, so my knowledge is quite shattered.&lt;/p&gt;\n\n&lt;p&gt;So my question here is, what would be an easy stack to use for this? &lt;/p&gt;\n\n&lt;p&gt;I hope I made sense, and thank you very much for taking your time to read this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3me88", "is_robot_indexable": true, "report_reasons": null, "author": "Psykiatrin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3me88/help_me_pick_a_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3me88/help_me_pick_a_stack/", "subreddit_subscribers": 80911, "created_utc": 1669302721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3imshnks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Numpy intro in just 2 minutes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_z3hb9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "NumPy Introduction in 2 minutes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/99ne6gq5fbE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/z3hb9p", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qWDsuCfLlIg4GFN_B9LQrIo_al2oSzYyb_ca_H_-31s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669288394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/99ne6gq5fbE", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?auto=webp&amp;s=212c7ab5c4470a4b9c08e0c5a29d02fa36c32ceb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=14e041ea8f874bff4066d2054d06c9a6c840302b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=265625b7c47b3e6f108d048907026a681aff2bc1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6004a6ffb718ed8514b86e6dc5615844ca07da03", "width": 320, "height": 240}], "variants": {}, "id": "E1xmePiSN3RVJ1aNqDRPWaAYakZhWrAVTkFebAaxpGg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3hb9p", "is_robot_indexable": true, "report_reasons": null, "author": "jredrose", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3hb9p/numpy_intro_in_just_2_minutes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/99ne6gq5fbE", "subreddit_subscribers": 80911, "created_utc": 1669288394.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "NumPy Introduction in 2 minutes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/99ne6gq5fbE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been given a take home test for a data engineering role, I\u2019m stuck on one of the questions. \n\nThe question specifically asks about improving event data specifications. I know it\u2019s quite a data specific question, however are there any best practices when it comes to generating event data to make it easy to use and to overall improve query efficiency when using the data?\n\nI\u2019ve been searching online for a while and not having any luck. My background is analytics engineering and have had some exposure to this side of things so I\u2019m just looking for some advice. Maybe some materials where I can learn more about this.", "author_fullname": "t2_gpri19uv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for some help on a data engineering technical test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z49ol4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669371363.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669370541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been given a take home test for a data engineering role, I\u2019m stuck on one of the questions. &lt;/p&gt;\n\n&lt;p&gt;The question specifically asks about improving event data specifications. I know it\u2019s quite a data specific question, however are there any best practices when it comes to generating event data to make it easy to use and to overall improve query efficiency when using the data?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been searching online for a while and not having any luck. My background is analytics engineering and have had some exposure to this side of things so I\u2019m just looking for some advice. Maybe some materials where I can learn more about this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z49ol4", "is_robot_indexable": true, "report_reasons": null, "author": "Particular_Spring_35", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z49ol4/looking_for_some_help_on_a_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z49ol4/looking_for_some_help_on_a_data_engineering/", "subreddit_subscribers": 80911, "created_utc": 1669370541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nQuick question here. One of our vendors has an on-prem SQL database that they are using snapshot replication to keep my company's Azure SQL database updated.\n\nI need to set up ETL pipelines from our Azure SQL DB into a data warehouse, and I was unsure on if we enabled CDC on the Azure SQL database that it would keep track of the delta between the last two snapshot replications, or rather CDC would just have the full data insert each time. If it doesn't track the delta only, then our ETL pipelines would get quite costly.\n\nWould we need to use transactional replication here or am I misunderstanding something? Thanks.", "author_fullname": "t2_tql2kvxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does CDC take the delta when using SSMS snapshot replication?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z47wtq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669363934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Quick question here. One of our vendors has an on-prem SQL database that they are using snapshot replication to keep my company&amp;#39;s Azure SQL database updated.&lt;/p&gt;\n\n&lt;p&gt;I need to set up ETL pipelines from our Azure SQL DB into a data warehouse, and I was unsure on if we enabled CDC on the Azure SQL database that it would keep track of the delta between the last two snapshot replications, or rather CDC would just have the full data insert each time. If it doesn&amp;#39;t track the delta only, then our ETL pipelines would get quite costly.&lt;/p&gt;\n\n&lt;p&gt;Would we need to use transactional replication here or am I misunderstanding something? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z47wtq", "is_robot_indexable": true, "report_reasons": null, "author": "AzureNoob1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z47wtq/does_cdc_take_the_delta_when_using_ssms_snapshot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z47wtq/does_cdc_take_the_delta_when_using_ssms_snapshot/", "subreddit_subscribers": 80911, "created_utc": 1669363934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cbh6ollo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top Customer Data Platform (CDP) Trends for 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "name": "t3_z3nvz7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ob1tJ_9izOP5fM0iGSrFHsKbgnuydlsxAwbfl2ZIk90.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669306361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blastx.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.blastx.com/insights/top-cdp-trends-for-2022", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?auto=webp&amp;s=842dee6ba1200953badb3d32ef9244d2fbd6b924", "width": 1210, "height": 378}, "resolutions": [{"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce9db9aa8185098c693e793312cc1309bf77cf67", "width": 108, "height": 33}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8dc60e56f49398af7db0de0cf74c96d3416cf57", "width": 216, "height": 67}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02568390b3abb9097731c6ee0202a5a4ed7963a8", "width": 320, "height": 99}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8aeabd5e816a75309fc111445ab961d264af5cee", "width": 640, "height": 199}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=195d9edf1758d911fc8e53ea99b299b430e1c327", "width": 960, "height": 299}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15e97b07fbefe7e24d7ab17941f7ad72532ae71a", "width": 1080, "height": 337}], "variants": {}, "id": "2EJ0FEP4NEqMWYTbzuALRhJ1K269Y5K_NKsMo48sqR8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3nvz7", "is_robot_indexable": true, "report_reasons": null, "author": "ephemeral404", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3nvz7/top_customer_data_platform_cdp_trends_for_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.blastx.com/insights/top-cdp-trends-for-2022", "subreddit_subscribers": 80911, "created_utc": 1669306361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create and use data flow in Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_z47d6k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ySvg0lTmdlY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to create and use data flow in Azure Data Factory\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to create and use data flow in Azure Data Factory", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ySvg0lTmdlY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to create and use data flow in Azure Data Factory\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ySvg0lTmdlY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SoftWizCircle"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ySvg0lTmdlY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to create and use data flow in Azure Data Factory\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/z47d6k", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_WOlxPTwuv_9J_q-AVtbuQ3nXkocWfPto9psf7EQ1EI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669362002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ySvg0lTmdlY", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KADBGcB3aw1pZf9pWwzAOEQv5tyO_RM8g2Stfq1hZMw.jpg?auto=webp&amp;s=7ec13008b07996b213e054d66b192d55404cfff0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/KADBGcB3aw1pZf9pWwzAOEQv5tyO_RM8g2Stfq1hZMw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=90ea33cfc69035f15ef8d7bbd53406387ac04e7b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/KADBGcB3aw1pZf9pWwzAOEQv5tyO_RM8g2Stfq1hZMw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e1923da3362b92b2ef68cb146bacc48d49297d11", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/KADBGcB3aw1pZf9pWwzAOEQv5tyO_RM8g2Stfq1hZMw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=954c85d89f8339ef0910bc9af1c32bc1e3b049ba", "width": 320, "height": 240}], "variants": {}, "id": "2TIBerwoxwEaBrDmXYFtg-J4MbbOozCAELZh_OsMjfU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z47d6k", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z47d6k/how_to_create_and_use_data_flow_in_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ySvg0lTmdlY", "subreddit_subscribers": 80911, "created_utc": 1669362002.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to create and use data flow in Azure Data Factory", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ySvg0lTmdlY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"How to create and use data flow in Azure Data Factory\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ySvg0lTmdlY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SoftWizCircle"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rqcvpt75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quickly create ETL data flows with Prefect and CodeSquire.ai", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_z3jxag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XCK2m9XQKNLTwzXZDDb8WDeCI1vxKAttlObz2mmeITc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669296382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/7a3045sihw1a1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/7a3045sihw1a1.png?auto=webp&amp;s=9bac7336bd65de554376a89ee30c059e8ec3a3d9", "width": 2048, "height": 2048}, "resolutions": [{"url": "https://preview.redd.it/7a3045sihw1a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=217f177a95d9f409f3fe285a68118a2a0821d780", "width": 108, "height": 108}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=386d81b544bac8b706b7cd8ac6e0504b3a8d914f", "width": 216, "height": 216}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad1a6ec5beee8c44ace4a664b774fc858150fd68", "width": 320, "height": 320}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad0eeb3f499810280ba77a70af54850a6073e9d0", "width": 640, "height": 640}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=13832d97d750e927d7abd0d9081eec9be35a77d5", "width": 960, "height": 960}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6bad20fa09b5eda8ad766d2533ff7911a1635696", "width": 1080, "height": 1080}], "variants": {}, "id": "1WBFSZAxnBlXfQLQPkpXA0lbnyxT_u0Z0hmGrbifEHY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3jxag", "is_robot_indexable": true, "report_reasons": null, "author": "codesquire-ai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3jxag/quickly_create_etl_data_flows_with_prefect_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/7a3045sihw1a1.png", "subreddit_subscribers": 80911, "created_utc": 1669296382.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}