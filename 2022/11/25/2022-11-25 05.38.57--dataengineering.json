{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve just got a data engineering from BI developer role by transferring internally but my team is based outside of Europe and I have a bunch of tasks I\u2019m really struggling with. I don\u2019t really know the fundamentals but my boss said you\u2019ll pick them up over time. It\u2019s been two and a bit months and I feel like I\u2019ve not progressed at all and want to get better. There are senior data engineers locally but they\u2019re not in my team and I feel awkward about asking them for too much help. Where would you start and how would you complement your learning from scratch?", "author_fullname": "t2_bs6bpgld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019ve just got a data engineering from BI developer role by transferring internally and I\u2019m struggling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3frjt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669282859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve just got a data engineering from BI developer role by transferring internally but my team is based outside of Europe and I have a bunch of tasks I\u2019m really struggling with. I don\u2019t really know the fundamentals but my boss said you\u2019ll pick them up over time. It\u2019s been two and a bit months and I feel like I\u2019ve not progressed at all and want to get better. There are senior data engineers locally but they\u2019re not in my team and I feel awkward about asking them for too much help. Where would you start and how would you complement your learning from scratch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3frjt", "is_robot_indexable": true, "report_reasons": null, "author": "JackalTheFulgid", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3frjt/ive_just_got_a_data_engineering_from_bi_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3frjt/ive_just_got_a_data_engineering_from_bi_developer/", "subreddit_subscribers": 80889, "created_utc": 1669282859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to build a portfolio site (not GitHub) that showcases all my projects in a visually appealing way. I'm aware about GitHub pages \u2013 not quite what I'm looking for.\n\nProblem is that my web development knowledge is minimal. And I don't want to go down the web development rabbit hole just to build a portfolio site.\n\nI've looked at [fastpages](https://fastpages.fast.ai/). But it's mainly for writing blog like content.\n\nWhat I'm looking for is a way to showcase my projects as tiles on the landing page. On click they should expand to show the details.\n\nIn addition it should have an about-me and my resume.", "author_fullname": "t2_pblux6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quickest way to build a portfolio site with minimal web development knowledge?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3o340", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669306831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to build a portfolio site (not GitHub) that showcases all my projects in a visually appealing way. I&amp;#39;m aware about GitHub pages \u2013 not quite what I&amp;#39;m looking for.&lt;/p&gt;\n\n&lt;p&gt;Problem is that my web development knowledge is minimal. And I don&amp;#39;t want to go down the web development rabbit hole just to build a portfolio site.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at &lt;a href=\"https://fastpages.fast.ai/\"&gt;fastpages&lt;/a&gt;. But it&amp;#39;s mainly for writing blog like content.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is a way to showcase my projects as tiles on the landing page. On click they should expand to show the details.&lt;/p&gt;\n\n&lt;p&gt;In addition it should have an about-me and my resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hWTW2xpgF2jQZc0p76GmCXQm895W3vkrDZA3K_gx6yI.jpg?auto=webp&amp;s=47c777c563d22912b7e699a7ed6ab0c00ad16f49", "width": 234, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/hWTW2xpgF2jQZc0p76GmCXQm895W3vkrDZA3K_gx6yI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a319550c129d6b66d478a63fd26625ab7f32915", "width": 108, "height": 138}, {"url": "https://external-preview.redd.it/hWTW2xpgF2jQZc0p76GmCXQm895W3vkrDZA3K_gx6yI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e9dbd154ff76c353ddc11b24723413b7c9da1a4c", "width": 216, "height": 276}], "variants": {}, "id": "6rsKEAYlH0fj3pQKUJhL3mgn8frT2UeC3KVsYSOHoSQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z3o340", "is_robot_indexable": true, "report_reasons": null, "author": "newplayer12345", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3o340/quickest_way_to_build_a_portfolio_site_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3o340/quickest_way_to_build_a_portfolio_site_with/", "subreddit_subscribers": 80889, "created_utc": 1669306831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a large organization and share data permissions that 1,700 people in the org also have. I recently ran a query while investigating a dataset that returned sensitive information to the org. I was unaware of what it would return, stopped once I realized what it was, but am worried about the fallout. If it was an accident am I at risk of any repercussions?", "author_fullname": "t2_38elj5k6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Saw data I shouldn\u2019t have seen", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3xgak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669331516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a large organization and share data permissions that 1,700 people in the org also have. I recently ran a query while investigating a dataset that returned sensitive information to the org. I was unaware of what it would return, stopped once I realized what it was, but am worried about the fallout. If it was an accident am I at risk of any repercussions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3xgak", "is_robot_indexable": true, "report_reasons": null, "author": "afdsrewtg", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3xgak/saw_data_i_shouldnt_have_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3xgak/saw_data_i_shouldnt_have_seen/", "subreddit_subscribers": 80889, "created_utc": 1669331516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I spent the last 4 years working with SSIS but now my boss ask me if we should keep using ssis or we should use another tool. Do you have any recommendation?", "author_fullname": "t2_smy5zdxu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3uj7a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669323767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I spent the last 4 years working with SSIS but now my boss ask me if we should keep using ssis or we should use another tool. Do you have any recommendation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3uj7a", "is_robot_indexable": true, "report_reasons": null, "author": "Worried_Caregiver673", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3uj7a/etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3uj7a/etl_tool/", "subreddit_subscribers": 80889, "created_utc": 1669323767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a B2B company and have been assigned SAP-BI- Enterprise Data Engineer. In this, the tools I've been given are: \n\n1. Data management \n2. SAP HANA/BW \n3. BODS/EPM\n4. Master data management \n\nI'm getting paid less compared to software roles, what are your suggestions regarding this career starter? Should I start applying for other roles?", "author_fullname": "t2_7k0sexco", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been assigned SAP-Business Intelligence, is it a good career starter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3qlpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669313194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a B2B company and have been assigned SAP-BI- Enterprise Data Engineer. In this, the tools I&amp;#39;ve been given are: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data management &lt;/li&gt;\n&lt;li&gt;SAP HANA/BW &lt;/li&gt;\n&lt;li&gt;BODS/EPM&lt;/li&gt;\n&lt;li&gt;Master data management &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m getting paid less compared to software roles, what are your suggestions regarding this career starter? Should I start applying for other roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3qlpz", "is_robot_indexable": true, "report_reasons": null, "author": "ItsAXE93", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3qlpz/ive_been_assigned_sapbusiness_intelligence_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3qlpz/ive_been_assigned_sapbusiness_intelligence_is_it/", "subreddit_subscribers": 80889, "created_utc": 1669313194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any courses you would suggest to not miss in this sale? I want to revise basic DE topics ( hive , Hadoop) and do a good course for spark ( in depth) and probably AWS DE", "author_fullname": "t2_71fs5pjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Udemy black friday sale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3ck2b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669271564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any courses you would suggest to not miss in this sale? I want to revise basic DE topics ( hive , Hadoop) and do a good course for spark ( in depth) and probably AWS DE&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3ck2b", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Base1277", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3ck2b/udemy_black_friday_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3ck2b/udemy_black_friday_sale/", "subreddit_subscribers": 80889, "created_utc": 1669271564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your thoughts on joining a consultancy? For those that have made the move from working in a normal business in data engineering/BI to working in a consultancy and being more in a client facing role, advising etc?", "author_fullname": "t2_12rfbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on joining a consultancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3s2i1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669316942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your thoughts on joining a consultancy? For those that have made the move from working in a normal business in data engineering/BI to working in a consultancy and being more in a client facing role, advising etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3s2i1", "is_robot_indexable": true, "report_reasons": null, "author": "That_Sweet_Science", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3s2i1/thoughts_on_joining_a_consultancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3s2i1/thoughts_on_joining_a_consultancy/", "subreddit_subscribers": 80889, "created_utc": 1669316942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys hope every one is doing well. I was doing web scrapping and used a bit of regular expression in my code. My friend who is a software engineer says that using Regular expression in the code in his team is not allowed and SonarLint that they use for checking the quality of code throws up warning if it finds any regex. Is this specific to his team or in general is it a bad habit to use regex?", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Regular Expressions in code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3r801", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669314762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys hope every one is doing well. I was doing web scrapping and used a bit of regular expression in my code. My friend who is a software engineer says that using Regular expression in the code in his team is not allowed and SonarLint that they use for checking the quality of code throws up warning if it finds any regex. Is this specific to his team or in general is it a bad habit to use regex?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z3r801", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3r801/using_regular_expressions_in_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3r801/using_regular_expressions_in_code/", "subreddit_subscribers": 80889, "created_utc": 1669314762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I have been assigned to do a data lake update based off of tables' changes from source system, the changes are fairly simple i.e. column length changes + few additional columns for about \\~100 tables, for the most part it's a pretty straight forward task i.e. truncate existing tables and then do schema changes and then repopulate everything from source, all of this can be done within a few hours, however, we have a couple of tables that are terribly huge i.e. 2 Billion to 5 billion records and they are a huge pain in the ass, I mean even with truncate and reload, they would take atleast a few days, just wanted to ask everyone how do you manage these schema changes? \n\nFor a few reasons, creating a new table and dumping everything from the old table to new table is not an option.\n\n  \nEdit 1: For reference,\n\nBefore:\n\n|A (varchar(10))|B (int)|C (decimal (18,2))|\n|:-|:-|:-|\n||||\n\nAfter:\n\n|A (varchar(20))|B (int)|X (int)|Y (bit)|C (decimal (18,4))|\n|:-|:-|:-|:-|:-|\n||||||\n\n  \nEdit 2: We are using SQL Server 2017", "author_fullname": "t2_2xpdiv8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage schema changes for extremely large tables i.e. Billion row tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3zzla", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669345533.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669338901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I have been assigned to do a data lake update based off of tables&amp;#39; changes from source system, the changes are fairly simple i.e. column length changes + few additional columns for about ~100 tables, for the most part it&amp;#39;s a pretty straight forward task i.e. truncate existing tables and then do schema changes and then repopulate everything from source, all of this can be done within a few hours, however, we have a couple of tables that are terribly huge i.e. 2 Billion to 5 billion records and they are a huge pain in the ass, I mean even with truncate and reload, they would take atleast a few days, just wanted to ask everyone how do you manage these schema changes? &lt;/p&gt;\n\n&lt;p&gt;For a few reasons, creating a new table and dumping everything from the old table to new table is not an option.&lt;/p&gt;\n\n&lt;p&gt;Edit 1: For reference,&lt;/p&gt;\n\n&lt;p&gt;Before:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;A (varchar(10))&lt;/th&gt;\n&lt;th align=\"left\"&gt;B (int)&lt;/th&gt;\n&lt;th align=\"left\"&gt;C (decimal (18,2))&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;After:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;A (varchar(20))&lt;/th&gt;\n&lt;th align=\"left\"&gt;B (int)&lt;/th&gt;\n&lt;th align=\"left\"&gt;X (int)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Y (bit)&lt;/th&gt;\n&lt;th align=\"left\"&gt;C (decimal (18,4))&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Edit 2: We are using SQL Server 2017&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3zzla", "is_robot_indexable": true, "report_reasons": null, "author": "_whitezetsu", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3zzla/how_do_you_manage_schema_changes_for_extremely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3zzla/how_do_you_manage_schema_changes_for_extremely/", "subreddit_subscribers": 80889, "created_utc": 1669338901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6n3p4gou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create connection to Azure SQL database from Azure Data Factory using Managed Identity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_z3pum4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rZwoaYhDWTMjZf3mg6PjG0s7yJcdyJIL5hChexRFNTo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669311268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "azureops.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://azureops.org/articles/connect-azure-sql-from-data-factory-using-managed-identity/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?auto=webp&amp;s=69d377543539f3a3feca537e54fce9df2c70c862", "width": 1890, "height": 939}, "resolutions": [{"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f3666d32a31b10044952e7b011f0df6e1424125", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f291aeb3be47aa5932cdce7ba7c3855aa4de292", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e3bb0db6de62e355f1356b7950185eb40c6ef93", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=387d18f48806ec18e34f499922f28945122f744d", "width": 640, "height": 317}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=20f6287c889c88ea6e83359af95bd1bdb344b843", "width": 960, "height": 476}, {"url": "https://external-preview.redd.it/qz4bCeGan2Dp7XuO-1OfjB98jTfxpQmxdKIG2FXbsm0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=09d5d5e716940379bcfc7641c0b880d92b103b64", "width": 1080, "height": 536}], "variants": {}, "id": "Dn0PpBHGV2CWNBDb1yHTEO-oc5_jqU3k9EuRnXebXbI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3pum4", "is_robot_indexable": true, "report_reasons": null, "author": "k53r", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3pum4/how_to_create_connection_to_azure_sql_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://azureops.org/articles/connect-azure-sql-from-data-factory-using-managed-identity/", "subreddit_subscribers": 80889, "created_utc": 1669311268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI believe this to be a DE question, please correct.  \nI want to be able to email a client when a certain KPI gets above 95%. Our data is in AWS/redshift.  \n\n\nAny clues as to where I should start? Links, articles, keywords would all be helpful here.", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trigger an email to a client based upon a metric / kpi changing within Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3ftmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669283076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I believe this to be a DE question, please correct.&lt;br/&gt;\nI want to be able to email a client when a certain KPI gets above 95%. Our data is in AWS/redshift.  &lt;/p&gt;\n\n&lt;p&gt;Any clues as to where I should start? Links, articles, keywords would all be helpful here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3ftmf", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3ftmf/trigger_an_email_to_a_client_based_upon_a_metric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3ftmf/trigger_an_email_to_a_client_based_upon_a_metric/", "subreddit_subscribers": 80889, "created_utc": 1669283076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined a new company and my profile is data analyst. I have experience working as data scientist previously (where i mostly focused on model).\n\nIn this new job all i do is create logics to make a data set. This data is automated by a data engineer. But whole sql query to create the table is done by me. I don't feel like this is an analyts work. My work should start post data creation and involve reporting.\n\nI am confused about this job and thinking of leaving it as i don't enjoy this . I want to go to model creation. \n\nMay be my understanding of data analyst role is wrong itself but i have never heard analysts create datasets. \n\nPlease correct me if i am wrong.", "author_fullname": "t2_96kg5df4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on the taks that I do? Am I doing a data engineer's work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3sw47", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669319194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a new company and my profile is data analyst. I have experience working as data scientist previously (where i mostly focused on model).&lt;/p&gt;\n\n&lt;p&gt;In this new job all i do is create logics to make a data set. This data is automated by a data engineer. But whole sql query to create the table is done by me. I don&amp;#39;t feel like this is an analyts work. My work should start post data creation and involve reporting.&lt;/p&gt;\n\n&lt;p&gt;I am confused about this job and thinking of leaving it as i don&amp;#39;t enjoy this . I want to go to model creation. &lt;/p&gt;\n\n&lt;p&gt;May be my understanding of data analyst role is wrong itself but i have never heard analysts create datasets. &lt;/p&gt;\n\n&lt;p&gt;Please correct me if i am wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3sw47", "is_robot_indexable": true, "report_reasons": null, "author": "AC_PV_1526388", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3sw47/question_on_the_taks_that_i_do_am_i_doing_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3sw47/question_on_the_taks_that_i_do_am_i_doing_a_data/", "subreddit_subscribers": 80889, "created_utc": 1669319194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to run a stored procedure from Airflow but even when the stored proc is completed on the DB the airflow task still keeps on running. I have tried several things but to no success. \nPosted a question on stack oveflow with more details https://stackoverflow.com/questions/74561761/airflow-task-executing-stored-procedure-does-not-complete-even-if-the-stored-pro\n\nHelp appreciated \ud83d\ude03", "author_fullname": "t2_2jrdmyff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running stored procedures from Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3nw73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669306376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to run a stored procedure from Airflow but even when the stored proc is completed on the DB the airflow task still keeps on running. I have tried several things but to no success. \nPosted a question on stack oveflow with more details &lt;a href=\"https://stackoverflow.com/questions/74561761/airflow-task-executing-stored-procedure-does-not-complete-even-if-the-stored-pro\"&gt;https://stackoverflow.com/questions/74561761/airflow-task-executing-stored-procedure-does-not-complete-even-if-the-stored-pro&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Help appreciated \ud83d\ude03&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3nw73", "is_robot_indexable": true, "report_reasons": null, "author": "tejaswajain", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3nw73/running_stored_procedures_from_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3nw73/running_stored_procedures_from_airflow/", "subreddit_subscribers": 80889, "created_utc": 1669306376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI'm a web/game been recommended for a data engineering position that I'm not quite qualified for. However, I'm generally a quick study, and I'm very familiar with the data and stakeholders, so I think I'd make a good fit. I also have a long Christmas break to read up on things, and they are aware of my background.\n\nI will put together a quick demo to show, but I'm not quite sure which stack to use. I'm familiar with gcp, Kubernetes, docker, openshift and a tiny bit with aws, but I've only worked in already set up environments, I haven't set up anything myself.\n\nThe plan is to put together and simple front and backend (some javascript framework + c# or python) with a Redis database running in containers, and have it hosted as a website. I don't mind paying for this bit. My main concern is connecting everything, as in getting the backend fetch data from Redis, hosting the site on a url ect. I haven't found any resources that details the whole flow, so my knowledge is quite shattered.\n\nSo my question here is, what would be an easy stack to use for this? \n\nI hope I made sense, and thank you very much for taking your time to read this.", "author_fullname": "t2_71he9mqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me pick a stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3me88", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669302721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a web/game been recommended for a data engineering position that I&amp;#39;m not quite qualified for. However, I&amp;#39;m generally a quick study, and I&amp;#39;m very familiar with the data and stakeholders, so I think I&amp;#39;d make a good fit. I also have a long Christmas break to read up on things, and they are aware of my background.&lt;/p&gt;\n\n&lt;p&gt;I will put together a quick demo to show, but I&amp;#39;m not quite sure which stack to use. I&amp;#39;m familiar with gcp, Kubernetes, docker, openshift and a tiny bit with aws, but I&amp;#39;ve only worked in already set up environments, I haven&amp;#39;t set up anything myself.&lt;/p&gt;\n\n&lt;p&gt;The plan is to put together and simple front and backend (some javascript framework + c# or python) with a Redis database running in containers, and have it hosted as a website. I don&amp;#39;t mind paying for this bit. My main concern is connecting everything, as in getting the backend fetch data from Redis, hosting the site on a url ect. I haven&amp;#39;t found any resources that details the whole flow, so my knowledge is quite shattered.&lt;/p&gt;\n\n&lt;p&gt;So my question here is, what would be an easy stack to use for this? &lt;/p&gt;\n\n&lt;p&gt;I hope I made sense, and thank you very much for taking your time to read this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3me88", "is_robot_indexable": true, "report_reasons": null, "author": "Psykiatrin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3me88/help_me_pick_a_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3me88/help_me_pick_a_stack/", "subreddit_subscribers": 80889, "created_utc": 1669302721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3imshnks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Numpy intro in just 2 minutes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_z3hb9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "NumPy Introduction in 2 minutes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/99ne6gq5fbE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/z3hb9p", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qWDsuCfLlIg4GFN_B9LQrIo_al2oSzYyb_ca_H_-31s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669288394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/99ne6gq5fbE", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?auto=webp&amp;s=212c7ab5c4470a4b9c08e0c5a29d02fa36c32ceb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=14e041ea8f874bff4066d2054d06c9a6c840302b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=265625b7c47b3e6f108d048907026a681aff2bc1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/FS8X7b5DHA2SzwdsGdsZBUCzE-6AyhQ12GWrQlJk_6c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6004a6ffb718ed8514b86e6dc5615844ca07da03", "width": 320, "height": 240}], "variants": {}, "id": "E1xmePiSN3RVJ1aNqDRPWaAYakZhWrAVTkFebAaxpGg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3hb9p", "is_robot_indexable": true, "report_reasons": null, "author": "jredrose", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3hb9p/numpy_intro_in_just_2_minutes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/99ne6gq5fbE", "subreddit_subscribers": 80889, "created_utc": 1669288394.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "NumPy Introduction in 2 minutes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/99ne6gq5fbE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"NumPy Introduction in 2 minutes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/99ne6gq5fbE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s835r7du", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink - How data skew affects your performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 53, "top_awarded_type": null, "hide_score": false, "name": "t3_z3f28f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/238Yaqk0n2NRrjIhVTEVeTnq_spUWRKr6C_zM91lFJo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669280327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@sanr_71172/dealing-with-data-skew-in-flink-b7e4c82c35ef", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?auto=webp&amp;s=55f534c30598acb8574cabebff721a67607efc0c", "width": 1200, "height": 457}, "resolutions": [{"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5cde90e2bcfea3aa9733ee713cef27a4dfc82194", "width": 108, "height": 41}, {"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=da4dfaf50fa6d89cda311659f51cc9b0331fc6ef", "width": 216, "height": 82}, {"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82b80aa45d6663d1e9787cd0d1b6c79173751fdd", "width": 320, "height": 121}, {"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca6ed230662c6da8c06519b245b1643a9a18ac0a", "width": 640, "height": 243}, {"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ac408e94322086d045dce28f4c28b3dd9618392", "width": 960, "height": 365}, {"url": "https://external-preview.redd.it/1F84-mNs1iE0NHPKsT5zIf_9Any5uUjt8jn4ZDbs0UE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa21dc9154c687df6d3ea4deb25889846c4c31f0", "width": 1080, "height": 411}], "variants": {}, "id": "Ac4qHO8xIeOhAsyvZ9aMVbo5Be9kG-lo8ovJk1v0Lwc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3f28f", "is_robot_indexable": true, "report_reasons": null, "author": "sanr_sitecore", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3f28f/flink_how_data_skew_affects_your_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@sanr_71172/dealing-with-data-skew-in-flink-b7e4c82c35ef", "subreddit_subscribers": 80889, "created_utc": 1669280327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let\u2019s say you have rows of aggregated data, so there are category fields and the a sum field. You want to reassign a portion of each record. Maybe you want 25% of each sum to be reassigned to another record. \n\nYou could split each record into two records and add a proration field which has 75% next to the first row and 25% next to the second row. Then you could change values in the 25% records however you wanted, or add fields for each proration.  Maybe you do this by joining the table to another table which has two records for each PK in the first table, and the proration, and then the information linked to each proration. \n\nI\u2019m sure there are many variations one could do, but I\u2019m wondering if this is so common it has a basic name I\u2019m not thinking of. \u201cSplit each row by proration.\u201d  Is that a thing, and is there a term for it?", "author_fullname": "t2_1nhgn5i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you call a process that splits/bifurcates records by percentage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z40rg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669341231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you have rows of aggregated data, so there are category fields and the a sum field. You want to reassign a portion of each record. Maybe you want 25% of each sum to be reassigned to another record. &lt;/p&gt;\n\n&lt;p&gt;You could split each record into two records and add a proration field which has 75% next to the first row and 25% next to the second row. Then you could change values in the 25% records however you wanted, or add fields for each proration.  Maybe you do this by joining the table to another table which has two records for each PK in the first table, and the proration, and then the information linked to each proration. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure there are many variations one could do, but I\u2019m wondering if this is so common it has a basic name I\u2019m not thinking of. \u201cSplit each row by proration.\u201d  Is that a thing, and is there a term for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z40rg8", "is_robot_indexable": true, "report_reasons": null, "author": "eerilyweird", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z40rg8/what_do_you_call_a_process_that_splitsbifurcates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z40rg8/what_do_you_call_a_process_that_splitsbifurcates/", "subreddit_subscribers": 80889, "created_utc": 1669341231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m about to graduate in December and I\u2019ve been applying to junior DE roles. While I\u2019ve been receiving interviews, I feel like my resume is lacking in the projects section. So, I have just built an AI based full stack application, but now I need an end to end data eng project that will impress the hell out of recruiters. Here\u2019s some ideas I have so far:\n\n- Create a real time streaming etl pipeline using AWS that pulls data from a stock api and ultimately create a stock trading bot based off the data (not sure how exactly I can do this but I\u2019m open to suggestions)\n- create an end to end ETL pipeline which ingests data from something like Airbnb through scraping or an api, load it into S3, transform using AWS Glue + PySpark then load it to Athena or Redshift after which I would build visualizations with Tableau\n- Create an ELT pipeline where I\u2019d ingest data into S3 then data would be loaded into Redshift and I\u2019d use DBT to run transformations then use Tableau to build visuals\n\nAny thoughts or suggestions? Please help!!", "author_fullname": "t2_9ghl0zs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some ideas for a project!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3f004", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669280274.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669280088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m about to graduate in December and I\u2019ve been applying to junior DE roles. While I\u2019ve been receiving interviews, I feel like my resume is lacking in the projects section. So, I have just built an AI based full stack application, but now I need an end to end data eng project that will impress the hell out of recruiters. Here\u2019s some ideas I have so far:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create a real time streaming etl pipeline using AWS that pulls data from a stock api and ultimately create a stock trading bot based off the data (not sure how exactly I can do this but I\u2019m open to suggestions)&lt;/li&gt;\n&lt;li&gt;create an end to end ETL pipeline which ingests data from something like Airbnb through scraping or an api, load it into S3, transform using AWS Glue + PySpark then load it to Athena or Redshift after which I would build visualizations with Tableau&lt;/li&gt;\n&lt;li&gt;Create an ELT pipeline where I\u2019d ingest data into S3 then data would be loaded into Redshift and I\u2019d use DBT to run transformations then use Tableau to build visuals&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any thoughts or suggestions? Please help!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3f004", "is_robot_indexable": true, "report_reasons": null, "author": "Perfect_Kangaroo6233", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3f004/need_some_ideas_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3f004/need_some_ideas_for_a_project/", "subreddit_subscribers": 80889, "created_utc": 1669280088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am trying to write a structured streaming pyspark program that reads from a file source. If the file is empty I don't want to process the DF. I there a way I can do this?\n\n# Edit, my code\n\n    from pyspark.sql import SparkSession\n    from pyspark.sql.functions import *\n    from pyspark.sql.types import *\n    import smtplib\n    \n    \n    def mail(quote):\n      MY_EMAIL = \"sample@gmail.com\"\n      MY_PASSWORD = \"password\"\n      with smtplib.SMTP(\"smtp.gmail.com\") as connection:\n          connection.starttls()\n          connection.login(MY_EMAIL, MY_PASSWORD)\n          connection.sendmail(\n              from_addr=MY_EMAIL,\n              to_addrs=MY_EMAIL,\n              msg = f\"Subject:Error!\\n\\n{quote}\")\n    \n    def mail_msg(rowObject):\n        mail(rowObject[0].split(\"ERROR:\",1)[1])\n    \n    \n    spark = SparkSession \\\n        .builder \\\n        .appName(\"Stream_postgres_log\") \\\n        .getOrCreate()\n       \n    DF = spark \\\n      .readStream \\\n        .option(\"cleanSource\", \"archive\")\\\n        .option(\"sourceArchiveDir\",\"/home/archive\")\\\n        .text(\"/output\")\n    \n    \n    if \"Condition to check if streaming DF is empty\":\n       print(\"not working\")\n    else:\n       error_log_df = DF.filter(col(\"value\").like(\"%ERROR%\"))\n       error_log_df.printSchema()\n       query = error_log_df.writeStream \\\n            .foreach(mail_msg)\\\n            .start()  \n       query.awaitTermination()\n\n&amp;#x200B;", "author_fullname": "t2_cb7rpz4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Check if structured streaming dataframe is empty or not", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z3bj8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669293504.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669268273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am trying to write a structured streaming pyspark program that reads from a file source. If the file is empty I don&amp;#39;t want to process the DF. I there a way I can do this?&lt;/p&gt;\n\n&lt;h1&gt;Edit, my code&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport smtplib\n\n\ndef mail(quote):\n  MY_EMAIL = &amp;quot;sample@gmail.com&amp;quot;\n  MY_PASSWORD = &amp;quot;password&amp;quot;\n  with smtplib.SMTP(&amp;quot;smtp.gmail.com&amp;quot;) as connection:\n      connection.starttls()\n      connection.login(MY_EMAIL, MY_PASSWORD)\n      connection.sendmail(\n          from_addr=MY_EMAIL,\n          to_addrs=MY_EMAIL,\n          msg = f&amp;quot;Subject:Error!\\n\\n{quote}&amp;quot;)\n\ndef mail_msg(rowObject):\n    mail(rowObject[0].split(&amp;quot;ERROR:&amp;quot;,1)[1])\n\n\nspark = SparkSession \\\n    .builder \\\n    .appName(&amp;quot;Stream_postgres_log&amp;quot;) \\\n    .getOrCreate()\n\nDF = spark \\\n  .readStream \\\n    .option(&amp;quot;cleanSource&amp;quot;, &amp;quot;archive&amp;quot;)\\\n    .option(&amp;quot;sourceArchiveDir&amp;quot;,&amp;quot;/home/archive&amp;quot;)\\\n    .text(&amp;quot;/output&amp;quot;)\n\n\nif &amp;quot;Condition to check if streaming DF is empty&amp;quot;:\n   print(&amp;quot;not working&amp;quot;)\nelse:\n   error_log_df = DF.filter(col(&amp;quot;value&amp;quot;).like(&amp;quot;%ERROR%&amp;quot;))\n   error_log_df.printSchema()\n   query = error_log_df.writeStream \\\n        .foreach(mail_msg)\\\n        .start()  \n   query.awaitTermination()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z3bj8q", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_marshmellow19", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3bj8q/check_if_structured_streaming_dataframe_is_empty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3bj8q/check_if_structured_streaming_dataframe_is_empty/", "subreddit_subscribers": 80889, "created_utc": 1669268273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cbh6ollo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top Customer Data Platform (CDP) Trends for 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "name": "t3_z3nvz7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ob1tJ_9izOP5fM0iGSrFHsKbgnuydlsxAwbfl2ZIk90.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669306361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blastx.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.blastx.com/insights/top-cdp-trends-for-2022", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?auto=webp&amp;s=842dee6ba1200953badb3d32ef9244d2fbd6b924", "width": 1210, "height": 378}, "resolutions": [{"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce9db9aa8185098c693e793312cc1309bf77cf67", "width": 108, "height": 33}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8dc60e56f49398af7db0de0cf74c96d3416cf57", "width": 216, "height": 67}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02568390b3abb9097731c6ee0202a5a4ed7963a8", "width": 320, "height": 99}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8aeabd5e816a75309fc111445ab961d264af5cee", "width": 640, "height": 199}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=195d9edf1758d911fc8e53ea99b299b430e1c327", "width": 960, "height": 299}, {"url": "https://external-preview.redd.it/pekUERoSdF4Ej3XZ5Ed578A1jgYCpMMQWM3vqhZOelw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15e97b07fbefe7e24d7ab17941f7ad72532ae71a", "width": 1080, "height": 337}], "variants": {}, "id": "2EJ0FEP4NEqMWYTbzuALRhJ1K269Y5K_NKsMo48sqR8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3nvz7", "is_robot_indexable": true, "report_reasons": null, "author": "ephemeral404", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3nvz7/top_customer_data_platform_cdp_trends_for_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.blastx.com/insights/top-cdp-trends-for-2022", "subreddit_subscribers": 80889, "created_utc": 1669306361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rqcvpt75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quickly create ETL data flows with Prefect and CodeSquire.ai", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_z3jxag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XCK2m9XQKNLTwzXZDDb8WDeCI1vxKAttlObz2mmeITc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669296382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/7a3045sihw1a1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/7a3045sihw1a1.png?auto=webp&amp;s=9bac7336bd65de554376a89ee30c059e8ec3a3d9", "width": 2048, "height": 2048}, "resolutions": [{"url": "https://preview.redd.it/7a3045sihw1a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=217f177a95d9f409f3fe285a68118a2a0821d780", "width": 108, "height": 108}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=386d81b544bac8b706b7cd8ac6e0504b3a8d914f", "width": 216, "height": 216}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad1a6ec5beee8c44ace4a664b774fc858150fd68", "width": 320, "height": 320}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad0eeb3f499810280ba77a70af54850a6073e9d0", "width": 640, "height": 640}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=13832d97d750e927d7abd0d9081eec9be35a77d5", "width": 960, "height": 960}, {"url": "https://preview.redd.it/7a3045sihw1a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6bad20fa09b5eda8ad766d2533ff7911a1635696", "width": 1080, "height": 1080}], "variants": {}, "id": "1WBFSZAxnBlXfQLQPkpXA0lbnyxT_u0Z0hmGrbifEHY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3jxag", "is_robot_indexable": true, "report_reasons": null, "author": "codesquire-ai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3jxag/quickly_create_etl_data_flows_with_prefect_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/7a3045sihw1a1.png", "subreddit_subscribers": 80889, "created_utc": 1669296382.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}