{"kind": "Listing", "data": {"after": "t3_yw98q9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! A few months ago I defended my **Master Thesis on Big Data** and got the maximum grade of 10.0 with honors. I want to thank this subreddit for the help and advice received in one of my previous posts. Also, if you want to build something similar and you think the project can be usefull for you, feel free to ask me for the Github page (I cannot attach it here since it contains my name and I think it is against the PII data community rules).\n\nAs a summary, I built an **ETL process** to get information about the latest music listened to by **Twitter** users (by searching for the hashtag #NowPlaying) and then queried **Spotify** to get the song and artist data involved. I used **Spark** to run the ETL process, **Cassandra** to store the data, a custom web application for the final visualization (**Flask** \\+ table with DataTables + graph with Graph.js) and **Airflow** to orchestrate the data flow.\n\nIn the end I could not include the Cloud part, except for a deployment in a virtual machine (using GCP's Compute Engine) to make it accessible to the evaluation board and which is currently deactivated. However, now that I have finished it I plan to make small extensions in GCP, such as implementing the Data Warehouse or making some visualizations in Big Query, but without focusing so much on the documentation work.\n\nAny feedback on your final impression of this project would be appreciated, as my idea is to try to use it to get a junior DE position in Europe! And enjoy my skills creating gifs with PowerPoint \ud83e\udd23\n\nhttps://i.redd.it/trlt7kqunzz91.gif", "author_fullname": "t2_2wafit96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Master's thesis finished - Thank you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "media_metadata": {"trlt7kqunzz91": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=dcf9f49fc1dc696cee4bb98bc3ef6a8ae5178019"}, {"y": 80, "x": 216, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=6d3fbd27de6c495b3bfa89ef937758d8ad51a6c2"}, {"y": 119, "x": 320, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4596814c7dfda471353ac416d4da2b15dd9fc897"}, {"y": 238, "x": 640, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=c52885fdc782f41661b32b886cec46260a825467"}, {"y": 357, "x": 960, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=a14cc8d1fe20497aa1d14d8646fd4743035b52ec"}, {"y": 402, "x": 1080, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=b70fe2a12f897cb1d40e894dbe006470ee81cb12"}], "s": {"y": 804, "gif": "https://i.redd.it/trlt7kqunzz91.gif", "mp4": "https://preview.redd.it/trlt7kqunzz91.gif?format=mp4&amp;s=60de0ef64f1ee84c3256d34cd0ff672c666c236f", "x": 2160}, "id": "trlt7kqunzz91"}}, "name": "t3_yve7sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 126, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 126, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kqLkS9mk6LCtCnH7bpdRpeNBVb5ALLvK9vB_FPRClnY.jpg", "edited": 1668465119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668463649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! A few months ago I defended my &lt;strong&gt;Master Thesis on Big Data&lt;/strong&gt; and got the maximum grade of 10.0 with honors. I want to thank this subreddit for the help and advice received in one of my previous posts. Also, if you want to build something similar and you think the project can be usefull for you, feel free to ask me for the Github page (I cannot attach it here since it contains my name and I think it is against the PII data community rules).&lt;/p&gt;\n\n&lt;p&gt;As a summary, I built an &lt;strong&gt;ETL process&lt;/strong&gt; to get information about the latest music listened to by &lt;strong&gt;Twitter&lt;/strong&gt; users (by searching for the hashtag #NowPlaying) and then queried &lt;strong&gt;Spotify&lt;/strong&gt; to get the song and artist data involved. I used &lt;strong&gt;Spark&lt;/strong&gt; to run the ETL process, &lt;strong&gt;Cassandra&lt;/strong&gt; to store the data, a custom web application for the final visualization (&lt;strong&gt;Flask&lt;/strong&gt; + table with DataTables + graph with Graph.js) and &lt;strong&gt;Airflow&lt;/strong&gt; to orchestrate the data flow.&lt;/p&gt;\n\n&lt;p&gt;In the end I could not include the Cloud part, except for a deployment in a virtual machine (using GCP&amp;#39;s Compute Engine) to make it accessible to the evaluation board and which is currently deactivated. However, now that I have finished it I plan to make small extensions in GCP, such as implementing the Data Warehouse or making some visualizations in Big Query, but without focusing so much on the documentation work.&lt;/p&gt;\n\n&lt;p&gt;Any feedback on your final impression of this project would be appreciated, as my idea is to try to use it to get a junior DE position in Europe! And enjoy my skills creating gifs with PowerPoint \ud83e\udd23&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/trlt7kqunzz91.gif\"&gt;https://i.redd.it/trlt7kqunzz91.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "yve7sf", "is_robot_indexable": true, "report_reasons": null, "author": "Riesco", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yve7sf/masters_thesis_finished_thank_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yve7sf/masters_thesis_finished_thank_you/", "subreddit_subscribers": 80053, "created_utc": 1668463649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Faster Queries with Clustering: An introduction to Snowflake's most powerful optimization technique", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_yvgrmn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/gmAGDh8qasJbV_NaOlaaMuFC9crPpuaHwF6q1GhaqPw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668469922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/introduction-to-snowflake-clustering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?auto=webp&amp;s=6835e48dcaaa57428ea3fa0cfbe41a6c20f57d83", "width": 2392, "height": 1014}, "resolutions": [{"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b4fcf770225967050ca3e813bd87683fb72620e", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7738828c24c04310079260116cfb1e4148310b33", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1563e248fbc5533fa2c58cd48ece7b7b72b5d0c1", "width": 320, "height": 135}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f77f2787fa6b2f9339a66553fc3be295f6741e9", "width": 640, "height": 271}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8671b4f1c957ce5dbded3857fceb2afc5c5611e0", "width": 960, "height": 406}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7fcd1b2c8bfb2bef04d268259860896b33c81042", "width": 1080, "height": 457}], "variants": {}, "id": "0QuV0iDdaZz8gZjudQrjgY9B4ptI8JunYztAMYJLa4Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yvgrmn", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvgrmn/faster_queries_with_clustering_an_introduction_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/introduction-to-snowflake-clustering", "subreddit_subscribers": 80053, "created_utc": 1668469922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Airflow was released in\u00a0**2014**\u00a0by Maxime Beauchemin (of Airbnb). In those 8 years it\u2019s really dominated DE in the wild. However, many teams are putting out ideas to succeed Airflow.\n\nI\u2019d like to start a discussion:\n\nIs DE collectively moving on from Airflow, or \u2026 i***f it ain\u2019t broke, why fix it?!***\n\nWhat could be improved on Airflow (even v2):\n\n&amp;#x200B;\n\n* Lack of ability to test easily\n* Data sharing between tasks (TaskFlow API is a step in the right direction, but still limited by underlying design choices)\n* End up with NxM for sources and targets\n\n&amp;#x200B;\n\nHow might the market develop? (not 1 winner, for sure):\n\n* **Streaming, Kafka**\n   * Backbone of many of the large tech now\n   * Very advanced for many teams\n   * Will it completely replace batch?\n* **Fivetran and other tools that automate DE**\n   * Reduces reliance on hard to find DEs\n   * New pricing models based on credits make it more affordable\n* **Airbyte and DBT, Simple Airflow and DBT**\n   * simple model of commoditizing the \\[EL\\] and then DBT for the \\[T\\]\n   * makes \u2018analytics engineers\u2018 (analysts) much more productive but is limited for complex workloads perhaps (will adding python hooks change this)\n* **Dagster &amp; Prefect**\n   * Better composability\n   * Shared data between tasks\n   * Big enough feature improvements to move from Airflow?\n   * Is the community big enough yet?\n* **AWS Lambda (serverless)**\n   * Tooling underdeveloped\n   * 15 minute limit per lambda run\n* **Stick with Airflow 2**\n   * FOSS\n   * Move to Astronomer for managed services is growing somewhat\n   * Despite some productivity challenges, it is easy to support\n\n&amp;#x200B;\n\n**What do you think?**\n\n\\- What do you plan (concretely) on using in next 6 months?- What are you using now?\n\n&amp;#x200B;\n\n**Full disclosure:**  I hope this is an interesting discussion question! We are of course making [a new alternative (typhoondata.io)](https://typhoondata.io/)   but want to learn from the forum so I have not included our option directly in the list.", "author_fullname": "t2_crnoguki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After Airflow. Where next for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw3mk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668546144.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668532840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Airflow was released in\u00a0&lt;strong&gt;2014&lt;/strong&gt;\u00a0by Maxime Beauchemin (of Airbnb). In those 8 years it\u2019s really dominated DE in the wild. However, many teams are putting out ideas to succeed Airflow.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to start a discussion:&lt;/p&gt;\n\n&lt;p&gt;Is DE collectively moving on from Airflow, or \u2026 i&lt;strong&gt;&lt;em&gt;f it ain\u2019t broke, why fix it?!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;What could be improved on Airflow (even v2):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Lack of ability to test easily&lt;/li&gt;\n&lt;li&gt;Data sharing between tasks (TaskFlow API is a step in the right direction, but still limited by underlying design choices)&lt;/li&gt;\n&lt;li&gt;End up with NxM for sources and targets&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How might the market develop? (not 1 winner, for sure):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Streaming, Kafka&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Backbone of many of the large tech now&lt;/li&gt;\n&lt;li&gt;Very advanced for many teams&lt;/li&gt;\n&lt;li&gt;Will it completely replace batch?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fivetran and other tools that automate DE&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Reduces reliance on hard to find DEs&lt;/li&gt;\n&lt;li&gt;New pricing models based on credits make it more affordable&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Airbyte and DBT, Simple Airflow and DBT&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;simple model of commoditizing the [EL] and then DBT for the [T]&lt;/li&gt;\n&lt;li&gt;makes \u2018analytics engineers\u2018 (analysts) much more productive but is limited for complex workloads perhaps (will adding python hooks change this)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Dagster &amp;amp; Prefect&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Better composability&lt;/li&gt;\n&lt;li&gt;Shared data between tasks&lt;/li&gt;\n&lt;li&gt;Big enough feature improvements to move from Airflow?&lt;/li&gt;\n&lt;li&gt;Is the community big enough yet?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AWS Lambda (serverless)&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Tooling underdeveloped&lt;/li&gt;\n&lt;li&gt;15 minute limit per lambda run&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stick with Airflow 2&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;FOSS&lt;/li&gt;\n&lt;li&gt;Move to Astronomer for managed services is growing somewhat&lt;/li&gt;\n&lt;li&gt;Despite some productivity challenges, it is easy to support&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What do you think?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- What do you plan (concretely) on using in next 6 months?- What are you using now?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Full disclosure:&lt;/strong&gt;  I hope this is an interesting discussion question! We are of course making &lt;a href=\"https://typhoondata.io/\"&gt;a new alternative (typhoondata.io)&lt;/a&gt;   but want to learn from the forum so I have not included our option directly in the list.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?auto=webp&amp;s=0ccd7631658c9ca465afe7ddaada34d1598a8afc", "width": 600, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a794906fe1dc01d33c54746bf6f1d02726d5050", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b80f68957e3c9fdb3d6251a471eb8e8999fa837", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5996e2653640cef99d3c4d3a408ed9b270c6d9c7", "width": 320, "height": 160}], "variants": {}, "id": "mpduhDtughYqwqqQM2iBf4D_nFj2DW0HvTduyWYjmDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw3mk5", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful_Yam_8090", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw3mk5/after_airflow_where_next_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw3mk5/after_airflow_where_next_for_de/", "subreddit_subscribers": 80053, "created_utc": 1668532840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When it comes to finding an entry level de job, which skills are absolutely required to know beforehand and which skills are nice to have skills  that you can learn on the job later on?\n\nFrom what I've read Python, SQL are pretty much the only required skills and the rest are stuff you can learn on the job. How true is this?\n\nFor example, if I am comfortable with Python and SQL but only have surface level experience with all the other de specific tools... would they even consider me?\n\nOr will most companies expect me to have prior professional experience with all these de related tools?\n\nI've been working on a few (very simple) projects using Python, pandas, sql, Airflow and tableau mainly and I'm wondering if this is enough to start applying for jobs.\n\nI haven't incorporated any data warehouse, data lake, data streaming or used any cloud providers in my projects mostly because there's too much to learn all at once and I wanted to focus on a specific set of technologies.\n\nI'm hoping that if I can demonstrate my proficiency in Python and sql they will hopefully see that I can pick up the rest on the job.\n\nOr is my thinking all wrong. Please advise. Thanks.", "author_fullname": "t2_yex15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Must know skills vs nice to have skills when job hunting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvhs6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668472576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When it comes to finding an entry level de job, which skills are absolutely required to know beforehand and which skills are nice to have skills  that you can learn on the job later on?&lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve read Python, SQL are pretty much the only required skills and the rest are stuff you can learn on the job. How true is this?&lt;/p&gt;\n\n&lt;p&gt;For example, if I am comfortable with Python and SQL but only have surface level experience with all the other de specific tools... would they even consider me?&lt;/p&gt;\n\n&lt;p&gt;Or will most companies expect me to have prior professional experience with all these de related tools?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a few (very simple) projects using Python, pandas, sql, Airflow and tableau mainly and I&amp;#39;m wondering if this is enough to start applying for jobs.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t incorporated any data warehouse, data lake, data streaming or used any cloud providers in my projects mostly because there&amp;#39;s too much to learn all at once and I wanted to focus on a specific set of technologies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping that if I can demonstrate my proficiency in Python and sql they will hopefully see that I can pick up the rest on the job.&lt;/p&gt;\n\n&lt;p&gt;Or is my thinking all wrong. Please advise. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yvhs6v", "is_robot_indexable": true, "report_reasons": null, "author": "desperate-1", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvhs6v/must_know_skills_vs_nice_to_have_skills_when_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvhs6v/must_know_skills_vs_nice_to_have_skills_when_job/", "subreddit_subscribers": 80053, "created_utc": 1668472576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a new graduate and I am working as a data scientist in a startup for a 8 months. I started as a intern and now I am working full time. Unfortunately, my responsibilities are not exactly data science tasks. I can define it as data analysis and finding data sources for dev team. These tasks doesn't help me to improve my resume I can not develop myself in data field.\n\nActually I am more interested in data engineering and I want to switch to this field. I know Python and SQL but I don't have an expertise on these languages. Everyday I am visiting this subreddit and try to find a path. Some of them says \"SQL and Python is enough for entry level, just start to apply\". Other one says \"you should also build pipeline, make a project\" and maybe sometimes \"you should know dbt, airflow etc.\" so I feel I am lost. I was thinking this path before:\n\n* Improve yourself on SQL and start to solve leetcode.\n* Then learn cloud (aws).\n* After that build a pipeline, ETL project.\n* Now you can start to apply jobs.\n\nWhat do you think, what should I do now? This subreddit is so valuable and your opinions are really helpful for me. Thank you.", "author_fullname": "t2_qmoxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I start applying for jobs? I am lost.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw0jg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668526547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new graduate and I am working as a data scientist in a startup for a 8 months. I started as a intern and now I am working full time. Unfortunately, my responsibilities are not exactly data science tasks. I can define it as data analysis and finding data sources for dev team. These tasks doesn&amp;#39;t help me to improve my resume I can not develop myself in data field.&lt;/p&gt;\n\n&lt;p&gt;Actually I am more interested in data engineering and I want to switch to this field. I know Python and SQL but I don&amp;#39;t have an expertise on these languages. Everyday I am visiting this subreddit and try to find a path. Some of them says &amp;quot;SQL and Python is enough for entry level, just start to apply&amp;quot;. Other one says &amp;quot;you should also build pipeline, make a project&amp;quot; and maybe sometimes &amp;quot;you should know dbt, airflow etc.&amp;quot; so I feel I am lost. I was thinking this path before:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Improve yourself on SQL and start to solve leetcode.&lt;/li&gt;\n&lt;li&gt;Then learn cloud (aws).&lt;/li&gt;\n&lt;li&gt;After that build a pipeline, ETL project.&lt;/li&gt;\n&lt;li&gt;Now you can start to apply jobs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think, what should I do now? This subreddit is so valuable and your opinions are really helpful for me. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw0jg3", "is_robot_indexable": true, "report_reasons": null, "author": "lost4line", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw0jg3/should_i_start_applying_for_jobs_i_am_lost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw0jg3/should_i_start_applying_for_jobs_i_am_lost/", "subreddit_subscribers": 80053, "created_utc": 1668526547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI recently faced a decision I had to make at work whether to use asyncio or concurrent.futures ThreadPoolExecutor in order to do some concurrent fetching from a database for a backend service. (~30 fetching jobs, small and quick queries).\n\nI did some research online and found some very different opinions about these two approaches and couldn't quite decide what's best for this use case. \n\nThat had me wondering which approach do other data engineers tend to use with such problems?", "author_fullname": "t2_bikhahe4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python concurrency for Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw06ry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668547387.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668525781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently faced a decision I had to make at work whether to use asyncio or concurrent.futures ThreadPoolExecutor in order to do some concurrent fetching from a database for a backend service. (~30 fetching jobs, small and quick queries).&lt;/p&gt;\n\n&lt;p&gt;I did some research online and found some very different opinions about these two approaches and couldn&amp;#39;t quite decide what&amp;#39;s best for this use case. &lt;/p&gt;\n\n&lt;p&gt;That had me wondering which approach do other data engineers tend to use with such problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw06ry", "is_robot_indexable": true, "report_reasons": null, "author": "ConsistentAd1477", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw06ry/python_concurrency_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw06ry/python_concurrency_for_data_engineers/", "subreddit_subscribers": 80053, "created_utc": 1668525781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data mesh has been a really popular concept, but I've been surprised by how few pieces there are about how to operationalize a data mesh architecture. A  cool feature that a lot of companies use to get past the performance barrier to data federation is full query passthrough. To this end, I wrote a tutorial on how to use it below. Hope it helps you all out: [https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/](https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/)", "author_fullname": "t2_bd9mcb3k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Guide] Full query passthrough to enable the data mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw6j2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668539267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data mesh has been a really popular concept, but I&amp;#39;ve been surprised by how few pieces there are about how to operationalize a data mesh architecture. A  cool feature that a lot of companies use to get past the performance barrier to data federation is full query passthrough. To this end, I wrote a tutorial on how to use it below. Hope it helps you all out: &lt;a href=\"https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/\"&gt;https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?auto=webp&amp;s=2aa1e5b0e2b22d524df1c9d9a934793b88ad6e31", "width": 1234, "height": 574}, "resolutions": [{"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c5062d0fcc3a1bd0739a2c78484343ca772ea075", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bce6e57d8071ac00fd40feebbb63b883d6413a41", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d3626e50ab90bb5519b5da3035e06e088d82269", "width": 320, "height": 148}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e2711ecc9d4fd5a93f36e52fafe3be94204feb15", "width": 640, "height": 297}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23d8b10f222f9f8a8d6dd61bf735c3277d740c1a", "width": 960, "height": 446}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a28c956ade73a6ac95d7d67ccbba4f144a91a920", "width": 1080, "height": 502}], "variants": {}, "id": "ijJ6Xa2IDLeCS5kKwH08WIF4KC76IYswMsiKoXbp5Bg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yw6j2t", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Week6114", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw6j2t/guide_full_query_passthrough_to_enable_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw6j2t/guide_full_query_passthrough_to_enable_the_data/", "subreddit_subscribers": 80053, "created_utc": 1668539267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has any one written the DBT developer certificate exam?\n\nif so how did you prep?\n\n&amp;#x200B;\n\nto give some context, I have been using DBT now for a year at my work and my boss suggested that i write that exam, I booked it for the end of December and i found this [https://www.getdbt.com/assets/uploads/dbt\\_certificate\\_study\\_guide.pdf](https://www.getdbt.com/assets/uploads/dbt_certificate_study_guide.pdf)\n\n&amp;#x200B;\n\nbut I wasn't sure if going through it is enough to pass.", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Developer Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw3567", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668531833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has any one written the DBT developer certificate exam?&lt;/p&gt;\n\n&lt;p&gt;if so how did you prep?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;to give some context, I have been using DBT now for a year at my work and my boss suggested that i write that exam, I booked it for the end of December and i found this &lt;a href=\"https://www.getdbt.com/assets/uploads/dbt_certificate_study_guide.pdf\"&gt;https://www.getdbt.com/assets/uploads/dbt_certificate_study_guide.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;but I wasn&amp;#39;t sure if going through it is enough to pass.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw3567", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw3567/dbt_developer_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw3567/dbt_developer_certificate/", "subreddit_subscribers": 80053, "created_utc": 1668531833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have the task of replicating the data in from an Azure SQL DB and an AWS RDS SQL DB into a Snowflake data warehouse, and I am unsure the most cost effective way to do this.\n\n* Azure SQL DB has 25 GB of data, and grows at about 1 GB per month\n* AWS RDS SQL DB has 1.2 TB of data, and grows at about 5 GB per month\n\nMy task is to get both of these databases fully replicated into the Snowflake instance, and then keep the Snowflake instance updated on a daily cadence for our business intelligence reports.\n\nIs Azure Data Factory a good way to handle this? I don't need to transform the data during replication, but I am finding it difficult to estimate the cost of running the ADF replication pipelines each once per day.\n\nI am also a little confused on if ADF can support just replicating the delta from each source after the initial bulk loading is done into the Snowflake warehouse. I see conflicting information online about ADF's ability to just handle the delta with Snowflake as a sink, and that SnowPipe would need to be used for that instead.\n\nAre there better options out there for this use-case rather than ADF or SnowPipe? Thanks in advance for anyone that can give me some advice.", "author_fullname": "t2_tql2kvxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to set up replication pipelines from an Azure SQL DB + AWS RDS SQL DB into Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvw546", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668516253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have the task of replicating the data in from an Azure SQL DB and an AWS RDS SQL DB into a Snowflake data warehouse, and I am unsure the most cost effective way to do this.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure SQL DB has 25 GB of data, and grows at about 1 GB per month&lt;/li&gt;\n&lt;li&gt;AWS RDS SQL DB has 1.2 TB of data, and grows at about 5 GB per month&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My task is to get both of these databases fully replicated into the Snowflake instance, and then keep the Snowflake instance updated on a daily cadence for our business intelligence reports.&lt;/p&gt;\n\n&lt;p&gt;Is Azure Data Factory a good way to handle this? I don&amp;#39;t need to transform the data during replication, but I am finding it difficult to estimate the cost of running the ADF replication pipelines each once per day.&lt;/p&gt;\n\n&lt;p&gt;I am also a little confused on if ADF can support just replicating the delta from each source after the initial bulk loading is done into the Snowflake warehouse. I see conflicting information online about ADF&amp;#39;s ability to just handle the delta with Snowflake as a sink, and that SnowPipe would need to be used for that instead.&lt;/p&gt;\n\n&lt;p&gt;Are there better options out there for this use-case rather than ADF or SnowPipe? Thanks in advance for anyone that can give me some advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvw546", "is_robot_indexable": true, "report_reasons": null, "author": "AzureNoob1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvw546/best_way_to_set_up_replication_pipelines_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvw546/best_way_to_set_up_replication_pipelines_from_an/", "subreddit_subscribers": 80053, "created_utc": 1668516253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We can't be the only ones facing this issue in Bigquery.\n\nPrinciple of least privilege. A user should not be able to read any sensitive data unless they need to, and if they need to read it the reason should be documented and the privilege should best case temporary. At least if we want to make the DPO happy. Managing that at scale seems to be a hassle, feels like we're missing something obvious.\n\nWhat we as a team require (among other things):\n\n1. Tagging columns with policy tags\n2. Defining policy tag taxonomies\n3. Efficient access requests to datasets/tables/columns\n4. Audit privileges (anyone have access that shouldn't?)\n5. Privilege expiration \n\nFor any individual part it's totally doable to create our own custom solutions, but putting it all together it becomes cumbersome.\n\nFor example policy tags. Creating those in GCP is ok, and we could even have a script that creates them from code. Tagging columns with them however I don't have many solutions for, Dbt is the only one that probably could work for us, but I'm not sure how the source tables (CSVs etc loaded into BQ with Airflow) would fit into that picture, probably requires some restructuring. Adding onto that we also need to have a system for requesting fine-grained reader privilege on the tags.\n\nA bit long-winded. Have I missed any go-to resources? How do you guys manage policy tags and such?", "author_fullname": "t2_svio3uio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage GDPR in Bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yw8yrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668544994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We can&amp;#39;t be the only ones facing this issue in Bigquery.&lt;/p&gt;\n\n&lt;p&gt;Principle of least privilege. A user should not be able to read any sensitive data unless they need to, and if they need to read it the reason should be documented and the privilege should best case temporary. At least if we want to make the DPO happy. Managing that at scale seems to be a hassle, feels like we&amp;#39;re missing something obvious.&lt;/p&gt;\n\n&lt;p&gt;What we as a team require (among other things):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Tagging columns with policy tags&lt;/li&gt;\n&lt;li&gt;Defining policy tag taxonomies&lt;/li&gt;\n&lt;li&gt;Efficient access requests to datasets/tables/columns&lt;/li&gt;\n&lt;li&gt;Audit privileges (anyone have access that shouldn&amp;#39;t?)&lt;/li&gt;\n&lt;li&gt;Privilege expiration &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For any individual part it&amp;#39;s totally doable to create our own custom solutions, but putting it all together it becomes cumbersome.&lt;/p&gt;\n\n&lt;p&gt;For example policy tags. Creating those in GCP is ok, and we could even have a script that creates them from code. Tagging columns with them however I don&amp;#39;t have many solutions for, Dbt is the only one that probably could work for us, but I&amp;#39;m not sure how the source tables (CSVs etc loaded into BQ with Airflow) would fit into that picture, probably requires some restructuring. Adding onto that we also need to have a system for requesting fine-grained reader privilege on the tags.&lt;/p&gt;\n\n&lt;p&gt;A bit long-winded. Have I missed any go-to resources? How do you guys manage policy tags and such?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw8yrv", "is_robot_indexable": true, "report_reasons": null, "author": "Natural_Switch_8614", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw8yrv/how_do_you_manage_gdpr_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw8yrv/how_do_you_manage_gdpr_in_bigquery/", "subreddit_subscribers": 80053, "created_utc": 1668544994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI've got job offer from Gartner and Dunnhumby for the role of Data engineer. I've only 1 yoe in this field and I've working knowledge of ADF, Azure Synapse analytics,Databricks and PySpark.\n In Gartner, the work will be purely based on Azure Data stack (ADF, Azure Data Lake, Synapse) whereas in Dunnhumby it'll PySpark, Airflow, GCP, HBase. \n\nNow I don't have proper knowledge but I'm interested in all these.\nCan you please help me decide which would be better company to join considering the tech stack and future of DE.\n\nPS - I'm sorry if this post doesn't belong here but I'm really confused and I needed advice from professionals.", "author_fullname": "t2_6hnbzi4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which DE job offer should I accept?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvl185", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668481470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got job offer from Gartner and Dunnhumby for the role of Data engineer. I&amp;#39;ve only 1 yoe in this field and I&amp;#39;ve working knowledge of ADF, Azure Synapse analytics,Databricks and PySpark.\n In Gartner, the work will be purely based on Azure Data stack (ADF, Azure Data Lake, Synapse) whereas in Dunnhumby it&amp;#39;ll PySpark, Airflow, GCP, HBase. &lt;/p&gt;\n\n&lt;p&gt;Now I don&amp;#39;t have proper knowledge but I&amp;#39;m interested in all these.\nCan you please help me decide which would be better company to join considering the tech stack and future of DE.&lt;/p&gt;\n\n&lt;p&gt;PS - I&amp;#39;m sorry if this post doesn&amp;#39;t belong here but I&amp;#39;m really confused and I needed advice from professionals.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yvl185", "is_robot_indexable": true, "report_reasons": null, "author": "dipanshusheoran", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvl185/which_de_job_offer_should_i_accept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvl185/which_de_job_offer_should_i_accept/", "subreddit_subscribers": 80053, "created_utc": 1668481470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State Management for Cloud Native Streaming: Getting to the Core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yw6g0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tCrJjRMOZqAd9beY4o3cb1ipq85NYf1SVRKQqt2XEvY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668539067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave-labs.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave-labs.com/blog/state-management-for-cloud-native-streaming/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?auto=webp&amp;s=35f49010d5ff8fb2e64563c9e22e7f30e3429954", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77c9ce8993b766b1d3c55c37eff0e17e621d1d63", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cd995fc23561c9e6d806ca2b6e99214378bf2af", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0bb21e91c3a40670781b97dbab03350f18a603e7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4259042dfb6f278b2cd95b13c13ad7ef1b22f61", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=48686911ad6edd9bc84fbb027e5da86fe1c833e6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=933970c776740f42863ff83f4b20ed8e7ec682b5", "width": 1080, "height": 607}], "variants": {}, "id": "kZR2XqyHUc26qkWZUy5G4HdWSzR1DCliVsb8zkhmBEs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yw6g0s", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw6g0s/state_management_for_cloud_native_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave-labs.com/blog/state-management-for-cloud-native-streaming/", "subreddit_subscribers": 80053, "created_utc": 1668539067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm reading [*Fundamentals of Data Engineering*](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302)*.* Chapter 2 talks about metadata in depth.   \n\n\nI understand what metadata is in theory (data about data) but **I don't fully understand what it looks like in practice. If you have any example, let me know!**   \n\n\nHere's what I know so far about metadata in practice:\n\n* Documentation\n* Data dictionaries\n* Data models/ schema (example: documenting data models / schemas w/ dbt)\n* Data lineage (documenting the lifecycle of data from inception to its final state. Kinda like orchestration or DAGS)", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't wrap my head around \"metadata\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw5dya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668536586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reading &lt;a href=\"https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302\"&gt;&lt;em&gt;Fundamentals of Data Engineering&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt; Chapter 2 talks about metadata in depth.   &lt;/p&gt;\n\n&lt;p&gt;I understand what metadata is in theory (data about data) but &lt;strong&gt;I don&amp;#39;t fully understand what it looks like in practice. If you have any example, let me know!&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I know so far about metadata in practice:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Documentation&lt;/li&gt;\n&lt;li&gt;Data dictionaries&lt;/li&gt;\n&lt;li&gt;Data models/ schema (example: documenting data models / schemas w/ dbt)&lt;/li&gt;\n&lt;li&gt;Data lineage (documenting the lifecycle of data from inception to its final state. Kinda like orchestration or DAGS)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw5dya", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw5dya/cant_wrap_my_head_around_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw5dya/cant_wrap_my_head_around_metadata/", "subreddit_subscribers": 80053, "created_utc": 1668536586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_wxj1rz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How vectorization improves database performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yw0z51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1_9V4zWdYJ3f5OrlMGMsnDDtjSBVUY5oJRVULRe_Gxw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668527414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoworld.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoworld.com/article/3678300/how-vectorization-improves-database-performance.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?auto=webp&amp;s=2de46562324f1234705ff004863ac441380bac90", "width": 1200, "height": 1231}, "resolutions": [{"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1d895959685c3071284a787c1c65c1c9ad04f16", "width": 108, "height": 110}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=755bc79f8c465ef4017f8418baf23965dee9a37b", "width": 216, "height": 221}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=047c69df98d016ed9e54f397f810b87cadc54251", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e844915eea1f1cc02fed432baeeff3e39f59133d", "width": 640, "height": 656}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d7ae9ae66c7aaa01f6dd78eef1d6b05ac42461a", "width": 960, "height": 984}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cfbb1d51a30e2591e2ba6f4f288afc00e729311", "width": 1080, "height": 1107}], "variants": {}, "id": "PSkYnX0bO_VeNWvfjdFzn2fYuF2JR9dne_Zc-Km4668"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yw0z51", "is_robot_indexable": true, "report_reasons": null, "author": "lkang5280", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw0z51/how_vectorization_improves_database_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoworld.com/article/3678300/how-vectorization-improves-database-performance.html", "subreddit_subscribers": 80053, "created_utc": 1668527414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi all,\n\nI'm a data engineering consultant so I start a project at a new customer regularly. I have the technical skills and tools down nicely so the biggest challenge when working with new data is figuring out and remembering what every database, schema, table and column means or is for. Is there a way or tool to document data for myself in a user-friendly manner? Like I can pull automatically or write down any of the objects (db, schema, table, column, column value, constraint, etc) and write my own notes by them, making everything easily findable etc.\n\nI thought about using trello boards per db and a ticket per table or something, writing down column descriptions and general info in there, but I feel like there must be a better way to go about it.\n\nAny tips, tricks and tools are greatly appreciated!", "author_fullname": "t2_5877uyxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Documenting data for personal reference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvry50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668504223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineering consultant so I start a project at a new customer regularly. I have the technical skills and tools down nicely so the biggest challenge when working with new data is figuring out and remembering what every database, schema, table and column means or is for. Is there a way or tool to document data for myself in a user-friendly manner? Like I can pull automatically or write down any of the objects (db, schema, table, column, column value, constraint, etc) and write my own notes by them, making everything easily findable etc.&lt;/p&gt;\n\n&lt;p&gt;I thought about using trello boards per db and a ticket per table or something, writing down column descriptions and general info in there, but I feel like there must be a better way to go about it.&lt;/p&gt;\n\n&lt;p&gt;Any tips, tricks and tools are greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvry50", "is_robot_indexable": true, "report_reasons": null, "author": "v0nm1ll3r", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvry50/documenting_data_for_personal_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvry50/documenting_data_for_personal_reference/", "subreddit_subscribers": 80053, "created_utc": 1668504223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm confused as to what Airbyte exactly offers. I have more of a BI engineering background but also have plenty of experience developing data pipelines. I've tried watching a few videos of Airbyte but can't exactly figure out what it is. Is it a low-code solution? Does it include orchestration? What's it most comparable to?", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone explain Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw8pzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668544418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m confused as to what Airbyte exactly offers. I have more of a BI engineering background but also have plenty of experience developing data pipelines. I&amp;#39;ve tried watching a few videos of Airbyte but can&amp;#39;t exactly figure out what it is. Is it a low-code solution? Does it include orchestration? What&amp;#39;s it most comparable to?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw8pzx", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw8pzx/can_someone_explain_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw8pzx/can_someone_explain_airbyte/", "subreddit_subscribers": 80053, "created_utc": 1668544418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nWe need to move data from Maria DB to Snowflake. We get the Maria table data periodically in to S3 bucket (snowflake external stage) through a vendor CDC replication app. Every changes happening in Maria table would be written to S3 bucket all day around as JSON files with tablename-01.json,tablename-02.json etc. File sizes are expected to be less than 100mb.\n\nWe use Python to load the data from the S3 bucket in to Snowflake and Airflow to schedule the data movement. We would use Python Operator to run the Python script that contains COPY/MERGE statements. \n\nMy question is around setting up Airflow DAGS. We are planning to have one DAG per table. Since all DAGs would have similar tasks, the plan is to generate the DAGs dynamically.  So if there are 10 tables, we would have 10 DAGs each moving data for the respective table in to Snowflake.\n\nIs this approach fine or is there any other better way to do this data movement? General suggestions in setting up this pipeline are also welcome.\n\nthanks.", "author_fullname": "t2_jfqnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DAG set up for moving data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw6mzp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668539509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;We need to move data from Maria DB to Snowflake. We get the Maria table data periodically in to S3 bucket (snowflake external stage) through a vendor CDC replication app. Every changes happening in Maria table would be written to S3 bucket all day around as JSON files with tablename-01.json,tablename-02.json etc. File sizes are expected to be less than 100mb.&lt;/p&gt;\n\n&lt;p&gt;We use Python to load the data from the S3 bucket in to Snowflake and Airflow to schedule the data movement. We would use Python Operator to run the Python script that contains COPY/MERGE statements. &lt;/p&gt;\n\n&lt;p&gt;My question is around setting up Airflow DAGS. We are planning to have one DAG per table. Since all DAGs would have similar tasks, the plan is to generate the DAGs dynamically.  So if there are 10 tables, we would have 10 DAGs each moving data for the respective table in to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Is this approach fine or is there any other better way to do this data movement? General suggestions in setting up this pipeline are also welcome.&lt;/p&gt;\n\n&lt;p&gt;thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw6mzp", "is_robot_indexable": true, "report_reasons": null, "author": "curidpostn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw6mzp/airflow_dag_set_up_for_moving_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw6mzp/airflow_dag_set_up_for_moving_data/", "subreddit_subscribers": 80053, "created_utc": 1668539509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nMy company is small, sub 10 mill revenue. We\u2019ve just created a data engineering team after years of bodging it. The first thing I want to do is catalogue the data, so I\u2019m researching the various choices online. I\u2019m getting frustrated with the inability to find ballpark costs. The only mention I can see of Alation\u2019s offering is $198k per annum which prices it so far beyond our budget that it\u2019s a waste of my time to even consider it.\n\nWhat are small companies using for data cataloguing? What other DE tools are small companies using? We currently have a wild mix of in-house built tools in at least 4 different languages and it\u2019s all getting a bit creaky\u2026 \n\nThanks for your advice.", "author_fullname": "t2_9od90rps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data cataloguing (and other tools) - pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw4bv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668534291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;My company is small, sub 10 mill revenue. We\u2019ve just created a data engineering team after years of bodging it. The first thing I want to do is catalogue the data, so I\u2019m researching the various choices online. I\u2019m getting frustrated with the inability to find ballpark costs. The only mention I can see of Alation\u2019s offering is $198k per annum which prices it so far beyond our budget that it\u2019s a waste of my time to even consider it.&lt;/p&gt;\n\n&lt;p&gt;What are small companies using for data cataloguing? What other DE tools are small companies using? We currently have a wild mix of in-house built tools in at least 4 different languages and it\u2019s all getting a bit creaky\u2026 &lt;/p&gt;\n\n&lt;p&gt;Thanks for your advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw4bv1", "is_robot_indexable": true, "report_reasons": null, "author": "Acidulated", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw4bv1/data_cataloguing_and_other_tools_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw4bv1/data_cataloguing_and_other_tools_pricing/", "subreddit_subscribers": 80053, "created_utc": 1668534291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you're a self-employed data engineer or have been paid to build out data pipelines for companies, I have questions for you!\n\n&amp;#x200B;\n\n* How did you get started? Did a company reach out to you or vice versa?\n* How do you scope out a projects timeline for a company? Do you break down the work into increments?\n* How many years of prior experience do you have?\n* What \"stack\" have you used? What is necessary and what is substitutable?\n* How have you created your pricing model?", "author_fullname": "t2_6ztum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self Employeed DE Contractors Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw2ood", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668530899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re a self-employed data engineer or have been paid to build out data pipelines for companies, I have questions for you!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How did you get started? Did a company reach out to you or vice versa?&lt;/li&gt;\n&lt;li&gt;How do you scope out a projects timeline for a company? Do you break down the work into increments?&lt;/li&gt;\n&lt;li&gt;How many years of prior experience do you have?&lt;/li&gt;\n&lt;li&gt;What &amp;quot;stack&amp;quot; have you used? What is necessary and what is substitutable?&lt;/li&gt;\n&lt;li&gt;How have you created your pricing model?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw2ood", "is_robot_indexable": true, "report_reasons": null, "author": "reidism", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw2ood/self_employeed_de_contractors_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw2ood/self_employeed_de_contractors_questions/", "subreddit_subscribers": 80053, "created_utc": 1668530899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, \n\nI am currently working on a project (personal but hoping to commercialize it at some point). The idea is a website allowing the user to upload data in the form of CSV/Excel and the website would basically generate a full dashboard containing several graphs analyzing the data. Eventually, I would want to export those dashboards as pdfs or emaemailsil. \n\nThe data extraction part I am ok with.  I am able to build the data parsing part easily with Pandas . I am looking now for the best way to generate dashboards on the web app (based on the result of the processing done in python ). \n\nI had a quick look at the possibilities and I found Streamlit and Dash as two options. They seemed however more adapted to a scenario of a company building its own BI system than a service website. My assumption is based on a quick research and gut feeling so please correct me if I am wrong \n\nAny suggestions for tools and libraries? \n\nThanks in advance", "author_fullname": "t2_kzkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help need to pick the most adapted dashboard-generating tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw1ap6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668528068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, &lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project (personal but hoping to commercialize it at some point). The idea is a website allowing the user to upload data in the form of CSV/Excel and the website would basically generate a full dashboard containing several graphs analyzing the data. Eventually, I would want to export those dashboards as pdfs or emaemailsil. &lt;/p&gt;\n\n&lt;p&gt;The data extraction part I am ok with.  I am able to build the data parsing part easily with Pandas . I am looking now for the best way to generate dashboards on the web app (based on the result of the processing done in python ). &lt;/p&gt;\n\n&lt;p&gt;I had a quick look at the possibilities and I found Streamlit and Dash as two options. They seemed however more adapted to a scenario of a company building its own BI system than a service website. My assumption is based on a quick research and gut feeling so please correct me if I am wrong &lt;/p&gt;\n\n&lt;p&gt;Any suggestions for tools and libraries? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw1ap6", "is_robot_indexable": true, "report_reasons": null, "author": "mkhalil77", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw1ap6/help_need_to_pick_the_most_adapted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw1ap6/help_need_to_pick_the_most_adapted/", "subreddit_subscribers": 80053, "created_utc": 1668528068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an idea for a web application project that I want to build and I wanted to get peoples ideas on what the best approach should be. \n\nThe problem: A podcast I listen to doesn't name each podcast with a descriptive title. Each title is just a random phrase unrelated to description of the podcast. So it's difficult to go back and find a podcast or recommend an episode to a friend if you can't remember the title. \n\nSolution: I'd like to build a web application which consists of a search bar and has a list of episodes underneath the search bar. As you type into the search bar the list of episodes underneath gets filtered down. \n\nMy approach: I'm thinking that the first step would be to scrape the data and create a table with the title as one column and the episode description as the second column. Or potentially break the episode description into a number of tags and link the episode titles to their tags. \n\nHelp: After that I'm a bit lost. How should I best create these tables. How can I filter a list based on text in the search bar. Any ideas on this are appreciated. I'm sure this had also been done before so if there's a name for what I'm trying to do or specific learning resources please send them my way.", "author_fullname": "t2_303xrahc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to design a list which filters based on text in a search bar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvyvat", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668522639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an idea for a web application project that I want to build and I wanted to get peoples ideas on what the best approach should be. &lt;/p&gt;\n\n&lt;p&gt;The problem: A podcast I listen to doesn&amp;#39;t name each podcast with a descriptive title. Each title is just a random phrase unrelated to description of the podcast. So it&amp;#39;s difficult to go back and find a podcast or recommend an episode to a friend if you can&amp;#39;t remember the title. &lt;/p&gt;\n\n&lt;p&gt;Solution: I&amp;#39;d like to build a web application which consists of a search bar and has a list of episodes underneath the search bar. As you type into the search bar the list of episodes underneath gets filtered down. &lt;/p&gt;\n\n&lt;p&gt;My approach: I&amp;#39;m thinking that the first step would be to scrape the data and create a table with the title as one column and the episode description as the second column. Or potentially break the episode description into a number of tags and link the episode titles to their tags. &lt;/p&gt;\n\n&lt;p&gt;Help: After that I&amp;#39;m a bit lost. How should I best create these tables. How can I filter a list based on text in the search bar. Any ideas on this are appreciated. I&amp;#39;m sure this had also been done before so if there&amp;#39;s a name for what I&amp;#39;m trying to do or specific learning resources please send them my way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvyvat", "is_robot_indexable": true, "report_reasons": null, "author": "CorktoBoston2020", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvyvat/how_to_design_a_list_which_filters_based_on_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvyvat/how_to_design_a_list_which_filters_based_on_text/", "subreddit_subscribers": 80053, "created_utc": 1668522639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Relatively new to the space, coming from an SWE role, and am having trouble understanding the process between exploring data and turning it into a production pipeline.\n\nGeneral ETL pipelines make sense to me, but where I am confused is more 'analytics' pipelines -- ones that not only do transformations on data, but also do analysis during their transformations for visualizations, models, etc that require more contextual understanding of the data.\n\nIt is surprising to me that 'data scientists' will do EDA, provide the details via a notebook or something, and then DEs production-ize this after the fact, oftentimes using something entirely different that requires re-writing the query/code/etc (i.e., from pandas to pyspark).  \n\n\nFrom SWE perspective, it seems like it is an error-prone process and redundant.  \n\n\nI am also unclear on who owns new features/modifications from business during this loop.  \n\n\nDoes anyone have good case studies / anecdotal advice on how to unify this process? Or am I misrepresenting the process and it actually is supposed to be set up differently? Any pointers would be greatly appreciated.", "author_fullname": "t2_ub4hlwpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good Examples of the Data Engineering Lifecycle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvi2ld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668473378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Relatively new to the space, coming from an SWE role, and am having trouble understanding the process between exploring data and turning it into a production pipeline.&lt;/p&gt;\n\n&lt;p&gt;General ETL pipelines make sense to me, but where I am confused is more &amp;#39;analytics&amp;#39; pipelines -- ones that not only do transformations on data, but also do analysis during their transformations for visualizations, models, etc that require more contextual understanding of the data.&lt;/p&gt;\n\n&lt;p&gt;It is surprising to me that &amp;#39;data scientists&amp;#39; will do EDA, provide the details via a notebook or something, and then DEs production-ize this after the fact, oftentimes using something entirely different that requires re-writing the query/code/etc (i.e., from pandas to pyspark).  &lt;/p&gt;\n\n&lt;p&gt;From SWE perspective, it seems like it is an error-prone process and redundant.  &lt;/p&gt;\n\n&lt;p&gt;I am also unclear on who owns new features/modifications from business during this loop.  &lt;/p&gt;\n\n&lt;p&gt;Does anyone have good case studies / anecdotal advice on how to unify this process? Or am I misrepresenting the process and it actually is supposed to be set up differently? Any pointers would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvi2ld", "is_robot_indexable": true, "report_reasons": null, "author": "No_Bat835", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvi2ld/good_examples_of_the_data_engineering_lifecycle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvi2ld/good_examples_of_the_data_engineering_lifecycle/", "subreddit_subscribers": 80053, "created_utc": 1668473378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am an experienced professional with around 16 years of experience. I have worked a lot on data pipelines \\[for micro services mainly, not for ML\\] and AWS. Have very strong database and analytics experience (RDBMS, NOSql , AWS DBs, KAfka, AWS services like Kinesis, etc). I am thinking DS degree would expand my horizon into the ML area. But I would probably stick to DE as I really enjoy my work.", "author_fullname": "t2_7p3dtj69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How relevant would be a Masters in Data Science for a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ywaslt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668549301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an experienced professional with around 16 years of experience. I have worked a lot on data pipelines [for micro services mainly, not for ML] and AWS. Have very strong database and analytics experience (RDBMS, NOSql , AWS DBs, KAfka, AWS services like Kinesis, etc). I am thinking DS degree would expand my horizon into the ML area. But I would probably stick to DE as I really enjoy my work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywaslt", "is_robot_indexable": true, "report_reasons": null, "author": "Release-Helpful", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywaslt/how_relevant_would_be_a_masters_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywaslt/how_relevant_would_be_a_masters_in_data_science/", "subreddit_subscribers": 80053, "created_utc": 1668549301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Much like web development, embedded systems, DevOps, etc?\n\n[View Poll](https://www.reddit.com/poll/yw9gc6)", "author_fullname": "t2_et5pvnxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think Data Engineering is a specialization within Software Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yw9gc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668546135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Much like web development, embedded systems, DevOps, etc?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yw9gc6\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yw9gc6", "is_robot_indexable": true, "report_reasons": null, "author": "yabbagabbamappa", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1668805335878, "options": [{"text": "Yes, DE is a subfield / specialization within SWE.", "id": "19832574"}, {"text": "No.", "id": "19832575"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 79, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw9gc6/do_you_think_data_engineering_is_a_specialization/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/yw9gc6/do_you_think_data_engineering_is_a_specialization/", "subreddit_subscribers": 80053, "created_utc": 1668546135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, what are possible tools for triggering job on Databricks via some event, for example data delivered to s3?", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "event trigger jobs on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yw98q9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668545651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, what are possible tools for triggering job on Databricks via some event, for example data delivered to s3?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw98q9", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw98q9/event_trigger_jobs_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw98q9/event_trigger_jobs_on_databricks/", "subreddit_subscribers": 80053, "created_utc": 1668545651.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}