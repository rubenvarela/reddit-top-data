{"kind": "Listing", "data": {"after": "t3_yv4z3z", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! A few months ago I defended my **Master Thesis on Big Data** and got the maximum grade of 10.0 with honors. I want to thank this subreddit for the help and advice received in one of my previous posts. Also, if you want to build something similar and you think the project can be usefull for you, feel free to ask me for the Github page (I cannot attach it here since it contains my name and I think it is against the PII data community rules).\n\nAs a summary, I built an **ETL process** to get information about the latest music listened to by **Twitter** users (by searching for the hashtag #NowPlaying) and then queried **Spotify** to get the song and artist data involved. I used **Spark** to run the ETL process, **Cassandra** to store the data, a custom web application for the final visualization (**Flask** \\+ table with DataTables + graph with Graph.js) and **Airflow** to orchestrate the data flow.\n\nIn the end I could not include the Cloud part, except for a deployment in a virtual machine (using GCP's Compute Engine) to make it accessible to the evaluation board and which is currently deactivated. However, now that I have finished it I plan to make small extensions in GCP, such as implementing the Data Warehouse or making some visualizations in Big Query, but without focusing so much on the documentation work.\n\nAny feedback on your final impression of this project would be appreciated, as my idea is to try to use it to get a junior DE position in Europe! And enjoy my skills creating gifs with PowerPoint \ud83e\udd23\n\nhttps://i.redd.it/trlt7kqunzz91.gif", "author_fullname": "t2_2wafit96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Master's thesis finished - Thank you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "media_metadata": {"trlt7kqunzz91": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=dcf9f49fc1dc696cee4bb98bc3ef6a8ae5178019"}, {"y": 80, "x": 216, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=6d3fbd27de6c495b3bfa89ef937758d8ad51a6c2"}, {"y": 119, "x": 320, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4596814c7dfda471353ac416d4da2b15dd9fc897"}, {"y": 238, "x": 640, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=c52885fdc782f41661b32b886cec46260a825467"}, {"y": 357, "x": 960, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=a14cc8d1fe20497aa1d14d8646fd4743035b52ec"}, {"y": 402, "x": 1080, "u": "https://preview.redd.it/trlt7kqunzz91.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=b70fe2a12f897cb1d40e894dbe006470ee81cb12"}], "s": {"y": 804, "gif": "https://i.redd.it/trlt7kqunzz91.gif", "mp4": "https://preview.redd.it/trlt7kqunzz91.gif?format=mp4&amp;s=60de0ef64f1ee84c3256d34cd0ff672c666c236f", "x": 2160}, "id": "trlt7kqunzz91"}}, "name": "t3_yve7sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kqLkS9mk6LCtCnH7bpdRpeNBVb5ALLvK9vB_FPRClnY.jpg", "edited": 1668465119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668463649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! A few months ago I defended my &lt;strong&gt;Master Thesis on Big Data&lt;/strong&gt; and got the maximum grade of 10.0 with honors. I want to thank this subreddit for the help and advice received in one of my previous posts. Also, if you want to build something similar and you think the project can be usefull for you, feel free to ask me for the Github page (I cannot attach it here since it contains my name and I think it is against the PII data community rules).&lt;/p&gt;\n\n&lt;p&gt;As a summary, I built an &lt;strong&gt;ETL process&lt;/strong&gt; to get information about the latest music listened to by &lt;strong&gt;Twitter&lt;/strong&gt; users (by searching for the hashtag #NowPlaying) and then queried &lt;strong&gt;Spotify&lt;/strong&gt; to get the song and artist data involved. I used &lt;strong&gt;Spark&lt;/strong&gt; to run the ETL process, &lt;strong&gt;Cassandra&lt;/strong&gt; to store the data, a custom web application for the final visualization (&lt;strong&gt;Flask&lt;/strong&gt; + table with DataTables + graph with Graph.js) and &lt;strong&gt;Airflow&lt;/strong&gt; to orchestrate the data flow.&lt;/p&gt;\n\n&lt;p&gt;In the end I could not include the Cloud part, except for a deployment in a virtual machine (using GCP&amp;#39;s Compute Engine) to make it accessible to the evaluation board and which is currently deactivated. However, now that I have finished it I plan to make small extensions in GCP, such as implementing the Data Warehouse or making some visualizations in Big Query, but without focusing so much on the documentation work.&lt;/p&gt;\n\n&lt;p&gt;Any feedback on your final impression of this project would be appreciated, as my idea is to try to use it to get a junior DE position in Europe! And enjoy my skills creating gifs with PowerPoint \ud83e\udd23&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/trlt7kqunzz91.gif\"&gt;https://i.redd.it/trlt7kqunzz91.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "yve7sf", "is_robot_indexable": true, "report_reasons": null, "author": "Riesco", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yve7sf/masters_thesis_finished_thank_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yve7sf/masters_thesis_finished_thank_you/", "subreddit_subscribers": 80007, "created_utc": 1668463649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the best graph database usage scenario that you have encountered? I mean, something that made you say \"Wow, I didn't know that I could do that with graph databases\".", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best graph database usage scenario that you have encountered?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv1y0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668438108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best graph database usage scenario that you have encountered? I mean, something that made you say &amp;quot;Wow, I didn&amp;#39;t know that I could do that with graph databases&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yv1y0d", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv1y0d/what_is_the_best_graph_database_usage_scenario/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv1y0d/what_is_the_best_graph_database_usage_scenario/", "subreddit_subscribers": 80007, "created_utc": 1668438108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8h8kwca0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Things are so much different than a year ago, what are your thoughts on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yvp8aj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KT_AJfCdSwYwHXjQgQnax30xEN5gx9Z0_Vj21GsH58Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668494446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6ooft4bmq30a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?auto=webp&amp;s=d85a9d3a89f9de1fa8ef9f2bc5e8dddbc066cb5f", "width": 1080, "height": 1257}, "resolutions": [{"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1aec4149e4796eadf6ad4ae90eeb296ea8ca816", "width": 108, "height": 125}, {"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e26bb50dffb3bb65c47df8eba79def9309e4b33", "width": 216, "height": 251}, {"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9e0f6377fe98f084bc3b2952371b425fa52ff7ee", "width": 320, "height": 372}, {"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=94feec4059303efc9279beb8fdad096d8b04ef19", "width": 640, "height": 744}, {"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f853edb152694de84922a09b53a21ca6fb566b2", "width": 960, "height": 1117}, {"url": "https://preview.redd.it/6ooft4bmq30a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=217df00b368364fa7f8cd6d33a1ea658348f3b0f", "width": 1080, "height": 1257}], "variants": {}, "id": "81Eru1XsgvS-jLG81PmOz11r9L-cykAt8tbTNeP4iqs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvp8aj", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Veterinarian-45", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvp8aj/things_are_so_much_different_than_a_year_ago_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6ooft4bmq30a1.jpg", "subreddit_subscribers": 80007, "created_utc": 1668494446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Faster Queries with Clustering: An introduction to Snowflake's most powerful optimization technique", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_yvgrmn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/gmAGDh8qasJbV_NaOlaaMuFC9crPpuaHwF6q1GhaqPw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668469922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/introduction-to-snowflake-clustering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?auto=webp&amp;s=6835e48dcaaa57428ea3fa0cfbe41a6c20f57d83", "width": 2392, "height": 1014}, "resolutions": [{"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b4fcf770225967050ca3e813bd87683fb72620e", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7738828c24c04310079260116cfb1e4148310b33", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1563e248fbc5533fa2c58cd48ece7b7b72b5d0c1", "width": 320, "height": 135}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f77f2787fa6b2f9339a66553fc3be295f6741e9", "width": 640, "height": 271}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8671b4f1c957ce5dbded3857fceb2afc5c5611e0", "width": 960, "height": 406}, {"url": "https://external-preview.redd.it/NdzluZq_zdpoaRP0IUHF3qQqarfLS7xrseno1JQnvD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7fcd1b2c8bfb2bef04d268259860896b33c81042", "width": 1080, "height": 457}], "variants": {}, "id": "0QuV0iDdaZz8gZjudQrjgY9B4ptI8JunYztAMYJLa4Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yvgrmn", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvgrmn/faster_queries_with_clustering_an_introduction_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/introduction-to-snowflake-clustering", "subreddit_subscribers": 80007, "created_utc": 1668469922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure who will need this but I built a very simple and small tool to generate PySpark schema from JSON. I built it to solve one of my problem that I was facing. I had to handle complex JSON this way.\n\nThere are few bugs there but ya here it it. [Click here to try!!](https://preetranjan.github.io/pyspark-schema-generator/)\n\nThe github is here, [View on Github](https://github.com/PreetRanjan/pyspark-schema-generator). It has few simple features like JSON format and compare.\n\n&amp;#x200B;\n\n[Screenshot of the project](https://preview.redd.it/4jg90xz3dyz91.png?width=1171&amp;format=png&amp;auto=webp&amp;s=bd3be25f3f8f9f72d82b6d4db4a76baea4fa49b9)", "author_fullname": "t2_r1dyavvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A PySpark Schema Generator from JSON", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4jg90xz3dyz91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c5e8651d1e80e2a9e8e31e19550398b3f17d62a"}, {"y": 125, "x": 216, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d093adb5b206e4437bf1c7ad4b428630da032fd4"}, {"y": 185, "x": 320, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c044774924e48d401e62232355565c446ade3195"}, {"y": 371, "x": 640, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6afe62b9602814b90f37c564477d61ffdcc122eb"}, {"y": 557, "x": 960, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bee8a6aab5182eb60d4fa806938c0555566422fe"}, {"y": 627, "x": 1080, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f08668259f36fe9a91b6152b19b504d66529d304"}], "s": {"y": 680, "x": 1171, "u": "https://preview.redd.it/4jg90xz3dyz91.png?width=1171&amp;format=png&amp;auto=webp&amp;s=bd3be25f3f8f9f72d82b6d4db4a76baea4fa49b9"}, "id": "4jg90xz3dyz91"}}, "name": "t3_yv6lon", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bsXl4bc9J1PhGXcXoYCif1ZVExGpFQ_wVelMWBMk4uw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668447464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure who will need this but I built a very simple and small tool to generate PySpark schema from JSON. I built it to solve one of my problem that I was facing. I had to handle complex JSON this way.&lt;/p&gt;\n\n&lt;p&gt;There are few bugs there but ya here it it. &lt;a href=\"https://preetranjan.github.io/pyspark-schema-generator/\"&gt;Click here to try!!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The github is here, &lt;a href=\"https://github.com/PreetRanjan/pyspark-schema-generator\"&gt;View on Github&lt;/a&gt;. It has few simple features like JSON format and compare.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4jg90xz3dyz91.png?width=1171&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bd3be25f3f8f9f72d82b6d4db4a76baea4fa49b9\"&gt;Screenshot of the project&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yv6lon", "is_robot_indexable": true, "report_reasons": null, "author": "RegentSphinx", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv6lon/a_pyspark_schema_generator_from_json/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv6lon/a_pyspark_schema_generator_from_json/", "subreddit_subscribers": 80007, "created_utc": 1668447464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a web developer for 7 years and truly dread doing it now. I want to focus more on databases or cloud. It gets me excited when im working on databases. For some background, i never finished my college degree i got hired by a start up company before I could graduate I\u2019m now working for the government making 100k. I feel extremely lucky to land this job even without a degree but how hard would it be to transition to data engineering? Would certifications be enough? What path should i take? \n\nMy skills rn:\nNode.js typescript angular \nC# asp.net mvc\nBlazor \nSSMS SSRS SSIS \nPower Bi, dax\nAzure devops", "author_fullname": "t2_9bawc33i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Path to becoming Data Engineer 2022?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv1dof", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668436916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a web developer for 7 years and truly dread doing it now. I want to focus more on databases or cloud. It gets me excited when im working on databases. For some background, i never finished my college degree i got hired by a start up company before I could graduate I\u2019m now working for the government making 100k. I feel extremely lucky to land this job even without a degree but how hard would it be to transition to data engineering? Would certifications be enough? What path should i take? &lt;/p&gt;\n\n&lt;p&gt;My skills rn:\nNode.js typescript angular \nC# asp.net mvc\nBlazor \nSSMS SSRS SSIS \nPower Bi, dax\nAzure devops&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yv1dof", "is_robot_indexable": true, "report_reasons": null, "author": "Possible_Original326", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv1dof/path_to_becoming_data_engineer_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv1dof/path_to_becoming_data_engineer_2022/", "subreddit_subscribers": 80007, "created_utc": 1668436916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When it comes to finding an entry level de job, which skills are absolutely required to know beforehand and which skills are nice to have skills  that you can learn on the job later on?\n\nFrom what I've read Python, SQL are pretty much the only required skills and the rest are stuff you can learn on the job. How true is this?\n\nFor example, if I am comfortable with Python and SQL but only have surface level experience with all the other de specific tools... would they even consider me?\n\nOr will most companies expect me to have prior professional experience with all these de related tools?\n\nI've been working on a few (very simple) projects using Python, pandas, sql, Airflow and tableau mainly and I'm wondering if this is enough to start applying for jobs.\n\nI haven't incorporated any data warehouse, data lake, data streaming or used any cloud providers in my projects mostly because there's too much to learn all at once and I wanted to focus on a specific set of technologies.\n\nI'm hoping that if I can demonstrate my proficiency in Python and sql they will hopefully see that I can pick up the rest on the job.\n\nOr is my thinking all wrong. Please advise. Thanks.", "author_fullname": "t2_yex15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Must know skills vs nice to have skills when job hunting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvhs6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668472576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When it comes to finding an entry level de job, which skills are absolutely required to know beforehand and which skills are nice to have skills  that you can learn on the job later on?&lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve read Python, SQL are pretty much the only required skills and the rest are stuff you can learn on the job. How true is this?&lt;/p&gt;\n\n&lt;p&gt;For example, if I am comfortable with Python and SQL but only have surface level experience with all the other de specific tools... would they even consider me?&lt;/p&gt;\n\n&lt;p&gt;Or will most companies expect me to have prior professional experience with all these de related tools?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a few (very simple) projects using Python, pandas, sql, Airflow and tableau mainly and I&amp;#39;m wondering if this is enough to start applying for jobs.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t incorporated any data warehouse, data lake, data streaming or used any cloud providers in my projects mostly because there&amp;#39;s too much to learn all at once and I wanted to focus on a specific set of technologies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping that if I can demonstrate my proficiency in Python and sql they will hopefully see that I can pick up the rest on the job.&lt;/p&gt;\n\n&lt;p&gt;Or is my thinking all wrong. Please advise. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yvhs6v", "is_robot_indexable": true, "report_reasons": null, "author": "desperate-1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvhs6v/must_know_skills_vs_nice_to_have_skills_when_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvhs6v/must_know_skills_vs_nice_to_have_skills_when_job/", "subreddit_subscribers": 80007, "created_utc": 1668472576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compaction in Apache Iceberg: Fine-Tuning Your Iceberg Table\u2019s Data Files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 42, "top_awarded_type": null, "hide_score": false, "name": "t3_yv5yp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rgDtRAuYhvrcxOof1JQwoWaI-fmBHaWJYZgrMpjPUcc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668446199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/subsurface/compaction-in-apache-iceberg-fine-tuning-your-iceberg-tables-data-files/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yaYNe53o4GMeUwzFdbE8thxQMn_6xNxvYLsd-zbgq2Y.jpg?auto=webp&amp;s=a2c26887f1d6d7a9997b7628f5677260b6b2fed6", "width": 1010, "height": 304}, "resolutions": [{"url": "https://external-preview.redd.it/yaYNe53o4GMeUwzFdbE8thxQMn_6xNxvYLsd-zbgq2Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=178f619f3812bd07fb2145e7d1e4de13e4871887", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/yaYNe53o4GMeUwzFdbE8thxQMn_6xNxvYLsd-zbgq2Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1530c337ccaf733a9bf6af78c7d40ebbd091973a", "width": 216, "height": 65}, {"url": "https://external-preview.redd.it/yaYNe53o4GMeUwzFdbE8thxQMn_6xNxvYLsd-zbgq2Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a22316ac4710a9fcee1c562fd23d9f4b0db2ba04", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/yaYNe53o4GMeUwzFdbE8thxQMn_6xNxvYLsd-zbgq2Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=838d3bed9b15b2f67e101dc3478066e7307e3aa9", "width": 640, "height": 192}, {"url": "https://external-preview.redd.it/yaYNe53o4GMeUwzFdbE8thxQMn_6xNxvYLsd-zbgq2Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4e7a2fcedcba08b4fd2316420447e0df3cffa8ae", "width": 960, "height": 288}], "variants": {}, "id": "_3QLIej8-EtXQYfSFWVcRZq1EpXgFkyUELW9oAU7w9M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yv5yp3", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv5yp3/compaction_in_apache_iceberg_finetuning_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/subsurface/compaction-in-apache-iceberg-fine-tuning-your-iceberg-tables-data-files/", "subreddit_subscribers": 80007, "created_utc": 1668446199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8h8kwca0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Things are so much different than a year ago, what are your thoughts on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yvp7gg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/DyeoAgQtHcS-walCfO5KEmRF73i4HE_M3RsWNwNM8_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668494372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/xxl20deeq30a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/xxl20deeq30a1.jpg?auto=webp&amp;s=94cc4d9a635ebab6fc5ddd85e34f71191059c986", "width": 1080, "height": 1257}, "resolutions": [{"url": "https://preview.redd.it/xxl20deeq30a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=189d1a6228f581929f3252bb3a648f40c545be6d", "width": 108, "height": 125}, {"url": "https://preview.redd.it/xxl20deeq30a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9f4f53d829aacccee1c9df1c62d2578bb86b38f", "width": 216, "height": 251}, {"url": "https://preview.redd.it/xxl20deeq30a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e98e833ccd10fa30e24cb2b5c7624a25888797dc", "width": 320, "height": 372}, {"url": "https://preview.redd.it/xxl20deeq30a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4579e510b3737044c58057774479e352f90b716", "width": 640, "height": 744}, {"url": "https://preview.redd.it/xxl20deeq30a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9b41743f0deff98d169e0868c5d41c20c6c521f9", "width": 960, "height": 1117}, {"url": "https://preview.redd.it/xxl20deeq30a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=140a34eaadcbaf80d2d0124a85aff3007fe8dadb", "width": 1080, "height": 1257}], "variants": {}, "id": "jduW4lPrdLiEA7IMxHunns5kf5OLEWyW63WZYIMTLwk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvp7gg", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Veterinarian-45", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvp7gg/things_are_so_much_different_than_a_year_ago_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/xxl20deeq30a1.jpg", "subreddit_subscribers": 80007, "created_utc": 1668494372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I am interested to share with you my article about Terraform and its configuration on azure . I'll be happy if you share with me your thoughts and comments.\n https://link.medium.com/e6uKq8jUWub", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "get started with Terraform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv0u1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668435739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I am interested to share with you my article about Terraform and its configuration on azure . I&amp;#39;ll be happy if you share with me your thoughts and comments.\n &lt;a href=\"https://link.medium.com/e6uKq8jUWub\"&gt;https://link.medium.com/e6uKq8jUWub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?auto=webp&amp;s=b794eed6f59ce00534ff32164c84d6cc6a71d519", "width": 1200, "height": 624}, "resolutions": [{"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d986dd432f37582c06604fc3e452d3f024e380d7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=43b262d9de75a90e3d62fab593a2d2af57f8520d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59fe33412aa44ef6c1a6192990d54ea8e7dfef83", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ead6af24f208c6803f0710013c7c83768fa8efe1", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee6e5f62e1187b836ee558df3f7ae0d3c14587ff", "width": 960, "height": 499}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba2875d61f55ebb2c49c97de6b14ac17e01c1f75", "width": 1080, "height": 561}], "variants": {}, "id": "cHfT9jHacbTASq0gkcdy0nSLJDpzTh9DUF8H5O6wT6M"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yv0u1t", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv0u1t/get_started_with_terraform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv0u1t/get_started_with_terraform/", "subreddit_subscribers": 80007, "created_utc": 1668435739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI've got job offer from Gartner and Dunnhumby for the role of Data engineer. I've only 1 yoe in this field and I've working knowledge of ADF, Azure Synapse analytics,Databricks and PySpark.\n In Gartner, the work will be purely based on Azure Data stack (ADF, Azure Data Lake, Synapse) whereas in Dunnhumby it'll PySpark, Airflow, GCP, HBase. \n\nNow I don't have proper knowledge but I'm interested in all these.\nCan you please help me decide which would be better company to join considering the tech stack and future of DE.\n\nPS - I'm sorry if this post doesn't belong here but I'm really confused and I needed advice from professionals.", "author_fullname": "t2_6hnbzi4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which DE job offer should I accept?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvl185", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668481470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got job offer from Gartner and Dunnhumby for the role of Data engineer. I&amp;#39;ve only 1 yoe in this field and I&amp;#39;ve working knowledge of ADF, Azure Synapse analytics,Databricks and PySpark.\n In Gartner, the work will be purely based on Azure Data stack (ADF, Azure Data Lake, Synapse) whereas in Dunnhumby it&amp;#39;ll PySpark, Airflow, GCP, HBase. &lt;/p&gt;\n\n&lt;p&gt;Now I don&amp;#39;t have proper knowledge but I&amp;#39;m interested in all these.\nCan you please help me decide which would be better company to join considering the tech stack and future of DE.&lt;/p&gt;\n\n&lt;p&gt;PS - I&amp;#39;m sorry if this post doesn&amp;#39;t belong here but I&amp;#39;m really confused and I needed advice from professionals.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yvl185", "is_robot_indexable": true, "report_reasons": null, "author": "dipanshusheoran", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvl185/which_de_job_offer_should_i_accept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvl185/which_de_job_offer_should_i_accept/", "subreddit_subscribers": 80007, "created_utc": 1668481470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have a good suggestion where to prepare for GCP professional data engineer? What is the best course to take and take on google provided content on the same.", "author_fullname": "t2_9navdxud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP professional data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvair9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668455482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have a good suggestion where to prepare for GCP professional data engineer? What is the best course to take and take on google provided content on the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvair9", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-Grade2960", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvair9/gcp_professional_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvair9/gcp_professional_data_engineer/", "subreddit_subscribers": 80007, "created_utc": 1668455482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We are doing an on site team building activity for our tech department. Sure you can build robust data systems but can you engineer a structurally sound tower made out of spaghetti and marshmallows? Share your best team building stories.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yvafx5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wQMEFYjgjz2PbAbtfMtMfFwWQji0KU5zL4LnU_5jQHY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668455320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3qnba2u9i00a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?auto=webp&amp;s=ecea0a5a53b258fb24a3699beae6935584442fcf", "width": 2296, "height": 4080}, "resolutions": [{"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a021a716887160ebca3841d4244f77241275a51", "width": 108, "height": 191}, {"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=da58ddec931053f7ae385ce79073ceb3a6164e0c", "width": 216, "height": 383}, {"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53c202ab7c016deb6ffa2909caac13a663bf7546", "width": 320, "height": 568}, {"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce1aff6b77264b7813ace0833adfeb2cc4bbd1d9", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=965833813defd4538a6898920f331652eeaaa99c", "width": 960, "height": 1705}, {"url": "https://preview.redd.it/3qnba2u9i00a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=195fa553b27c3f95e4494347c03f8fde779aa53f", "width": 1080, "height": 1919}], "variants": {}, "id": "ld8n5uhR9PLh6A55Rbuy5G_BECXU2C6Dvtn0B-viV48"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvafx5", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvafx5/we_are_doing_an_on_site_team_building_activity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3qnba2u9i00a1.jpg", "subreddit_subscribers": 80007, "created_utc": 1668455320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, im new to data engineering and stuff and currently working in project where we are trying to make own ETL framework like fivetran and etc. Currently im stuck with the problem of how can we detect any source database schema change after initial sync. Like if there new column added to the table or column datatype has been changed. Can anyone suggest how to approach this problem.\n\nPs. For now source db is postgresql", "author_fullname": "t2_bpdkk6n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to detect database schema changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv9kug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668453883.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668453543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, im new to data engineering and stuff and currently working in project where we are trying to make own ETL framework like fivetran and etc. Currently im stuck with the problem of how can we detect any source database schema change after initial sync. Like if there new column added to the table or column datatype has been changed. Can anyone suggest how to approach this problem.&lt;/p&gt;\n\n&lt;p&gt;Ps. For now source db is postgresql&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv9kug", "is_robot_indexable": true, "report_reasons": null, "author": "pakhira55", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv9kug/how_to_detect_database_schema_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv9kug/how_to_detect_database_schema_changes/", "subreddit_subscribers": 80007, "created_utc": 1668453543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, i have been asked by my project manager to test the queries written by senior Devs acc to the usecases given to them to implement datamarts, currently I have very little knowledge about testing as I have never done it before and some advice from you guys will be really helpful", "author_fullname": "t2_fgjne05b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to test data Marts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv9270", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668452460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, i have been asked by my project manager to test the queries written by senior Devs acc to the usecases given to them to implement datamarts, currently I have very little knowledge about testing as I have never done it before and some advice from you guys will be really helpful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv9270", "is_robot_indexable": true, "report_reasons": null, "author": "NoPreference7274", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv9270/how_to_test_data_marts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv9270/how_to_test_data_marts/", "subreddit_subscribers": 80007, "created_utc": 1668452460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi all,\n\nI'm a data engineering consultant so I start a project at a new customer regularly. I have the technical skills and tools down nicely so the biggest challenge when working with new data is figuring out and remembering what every database, schema, table and column means or is for. Is there a way or tool to document data for myself in a user-friendly manner? Like I can pull automatically or write down any of the objects (db, schema, table, column, column value, constraint, etc) and write my own notes by them, making everything easily findable etc.\n\nI thought about using trello boards per db and a ticket per table or something, writing down column descriptions and general info in there, but I feel like there must be a better way to go about it.\n\nAny tips, tricks and tools are greatly appreciated!", "author_fullname": "t2_5877uyxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Documenting data for personal reference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yvry50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668504223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineering consultant so I start a project at a new customer regularly. I have the technical skills and tools down nicely so the biggest challenge when working with new data is figuring out and remembering what every database, schema, table and column means or is for. Is there a way or tool to document data for myself in a user-friendly manner? Like I can pull automatically or write down any of the objects (db, schema, table, column, column value, constraint, etc) and write my own notes by them, making everything easily findable etc.&lt;/p&gt;\n\n&lt;p&gt;I thought about using trello boards per db and a ticket per table or something, writing down column descriptions and general info in there, but I feel like there must be a better way to go about it.&lt;/p&gt;\n\n&lt;p&gt;Any tips, tricks and tools are greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvry50", "is_robot_indexable": true, "report_reasons": null, "author": "v0nm1ll3r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvry50/documenting_data_for_personal_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvry50/documenting_data_for_personal_reference/", "subreddit_subscribers": 80007, "created_utc": 1668504223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, \n\nA regular ol' SWE making some steps into the data engineering world. I'm liking the lake house architecture, and I'm looking to implement it within my start-up org. For me the ACID compliance and governance model through technologies like Trino, delta lake etc are really appealing to me. \n\nHowever, since I'm really new to this space I'm missing some key factors that relate to my core experience of a regular SWE, and that is gitops. In my mind, nothing that is deployable is not done somehow through a pipeline or some automated action from a git repo. I can't even comprehend doing it any other way anymore. \n\nHowever, from what I've seen, this doesn't seem to be the case in the data lake house world that I've seen. For example something like data bricks just looks like a Jupyter notebook with some loaded delta lake house connectors. Do DE's and DS just write ad hoc scripts here that create tables in the data lake? What's the industry best practice to versioning data engineering work?", "author_fullname": "t2_nsflng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gitops in a Data lakehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvdydl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668463065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;A regular ol&amp;#39; SWE making some steps into the data engineering world. I&amp;#39;m liking the lake house architecture, and I&amp;#39;m looking to implement it within my start-up org. For me the ACID compliance and governance model through technologies like Trino, delta lake etc are really appealing to me. &lt;/p&gt;\n\n&lt;p&gt;However, since I&amp;#39;m really new to this space I&amp;#39;m missing some key factors that relate to my core experience of a regular SWE, and that is gitops. In my mind, nothing that is deployable is not done somehow through a pipeline or some automated action from a git repo. I can&amp;#39;t even comprehend doing it any other way anymore. &lt;/p&gt;\n\n&lt;p&gt;However, from what I&amp;#39;ve seen, this doesn&amp;#39;t seem to be the case in the data lake house world that I&amp;#39;ve seen. For example something like data bricks just looks like a Jupyter notebook with some loaded delta lake house connectors. Do DE&amp;#39;s and DS just write ad hoc scripts here that create tables in the data lake? What&amp;#39;s the industry best practice to versioning data engineering work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvdydl", "is_robot_indexable": true, "report_reasons": null, "author": "CatabolicEdo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvdydl/gitops_in_a_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvdydl/gitops_in_a_data_lakehouse/", "subreddit_subscribers": 80007, "created_utc": 1668463065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings, \nI would like to hear your experiences with using Datavault and maybe suggestions on how to proceed. \nBackground infromation: I've been managing a 20+ internal application datavault in my organisation for 2+ years. The goal was to replace Dashboards directly connected to the applications with a Datawarehouse using the data vault model. \nSo, the problem: the longer the datavault is being used the further data quality is being degraded. Its easy to blame other's, duing the interviews they claimed that the business keys were unique, but after a while i observe that that is not the case. Or records being deleted while they specifically stated that that is not the case ( and the application even has a row closed column). The result is that dashboards based on the datawarehouse show incorrect numbers and we are to blame. \n\nExamples: \n1)Process explained to me: Sale records must be unique and have at least one product. If sale is annulled the record gets a sign that its annulled. \n1)Reality: If a product is no longer sold all sale records are purged from the system because reasons.... \n\n2)Process explained to me:An employee ID is unique and identifies a  single natural person\n2)Reality: A temp worker is replacing another temp worker, HR is lazy and just changes an existing ID persons name,age, ets. \n The challenge is that the data is not faulty at  any one point in time: Its just that processes are not adhered to and thus the only way to get correct data is to purge the data vault.", "author_fullname": "t2_ippbo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those who have worked with Datavault, do you have any suggestions on how to proceed ( story inside)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv0hcm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668434965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, \nI would like to hear your experiences with using Datavault and maybe suggestions on how to proceed. \nBackground infromation: I&amp;#39;ve been managing a 20+ internal application datavault in my organisation for 2+ years. The goal was to replace Dashboards directly connected to the applications with a Datawarehouse using the data vault model. \nSo, the problem: the longer the datavault is being used the further data quality is being degraded. Its easy to blame other&amp;#39;s, duing the interviews they claimed that the business keys were unique, but after a while i observe that that is not the case. Or records being deleted while they specifically stated that that is not the case ( and the application even has a row closed column). The result is that dashboards based on the datawarehouse show incorrect numbers and we are to blame. &lt;/p&gt;\n\n&lt;p&gt;Examples: \n1)Process explained to me: Sale records must be unique and have at least one product. If sale is annulled the record gets a sign that its annulled. \n1)Reality: If a product is no longer sold all sale records are purged from the system because reasons.... &lt;/p&gt;\n\n&lt;p&gt;2)Process explained to me:An employee ID is unique and identifies a  single natural person\n2)Reality: A temp worker is replacing another temp worker, HR is lazy and just changes an existing ID persons name,age, ets. \n The challenge is that the data is not faulty at  any one point in time: Its just that processes are not adhered to and thus the only way to get correct data is to purge the data vault.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv0hcm", "is_robot_indexable": true, "report_reasons": null, "author": "roadrussian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv0hcm/to_those_who_have_worked_with_datavault_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv0hcm/to_those_who_have_worked_with_datavault_do_you/", "subreddit_subscribers": 80007, "created_utc": 1668434965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ugjew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tulip: Schematizing Meta\u2019s data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yuxqor", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b8z_zdQvvuMArj5NFKjCmuYof4eSXcfNPz69X7FLX7g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668428550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "engineering.fb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://engineering.fb.com/2022/11/09/developer-tools/tulip-schematizing-metas-data-platform/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?auto=webp&amp;s=985d9e86a60cd42c7c5961832c39f69ed8c48fe3", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220d8d5f11385f3fe6570b772aeea4bbace3099a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=08170c62a860a68e2eecc7f37b0fea26567ddb35", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15e9b80a4c44d3b89ab20b5985f6eec284ea0ee1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aad16a28dc7cec8a06ac005a9fb6b186cb06ae21", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60a7dd1ce23d82dd958b95473c659ff4a03785b5", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=79e4e12be1474061277a14f00e22094ed77d7a57", "width": 1080, "height": 607}], "variants": {}, "id": "8UfhOBudgsBvsTzSSr5lnkSwwiBO5L0NuKwtFuEAhjI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yuxqor", "is_robot_indexable": true, "report_reasons": null, "author": "marcosluis2186", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuxqor/tulip_schematizing_metas_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://engineering.fb.com/2022/11/09/developer-tools/tulip-schematizing-metas-data-platform/", "subreddit_subscribers": 80007, "created_utc": 1668428550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we calculate credit used by Particular user or Role when warehouse is being shared between them.", "author_fullname": "t2_94sgtt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Credit Usage per User/Role ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvpp3j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668496090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we calculate credit used by Particular user or Role when warehouse is being shared between them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvpp3j", "is_robot_indexable": true, "report_reasons": null, "author": "manish__tomar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvpp3j/snowflake_credit_usage_per_userrole/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvpp3j/snowflake_credit_usage_per_userrole/", "subreddit_subscribers": 80007, "created_utc": 1668496090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Relatively new to the space, coming from an SWE/Ops role, and am having trouble understanding the gap between the process and tooling for data scientists exploring data and DEs turning it into a production pipeline.\n\nIt is surprising to me that data scientists and BAs will do EDA, provide vague details via a notebook or something, and then DEs 'production-ize' this after the fact, oftentimes using something entirely different that requires re-writing and optimizing the query/code/etc (i.e., from pandas to spark).\n\nFrom SWE perspective, it seems like it is an error-prone process and redundant, and I haven't been able to find anything highlighting how this is generally handled.\n\nDoes anyone have good case studies / anecdotal advice on how this process is supposed to work? Any good examples of how DEs and DSs work together in your experience?  Any pointers would be greatly appreciated.", "author_fullname": "t2_hkw0srb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good examples of the DE Lifecycle and synergy between DE/DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvkryj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668480753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Relatively new to the space, coming from an SWE/Ops role, and am having trouble understanding the gap between the process and tooling for data scientists exploring data and DEs turning it into a production pipeline.&lt;/p&gt;\n\n&lt;p&gt;It is surprising to me that data scientists and BAs will do EDA, provide vague details via a notebook or something, and then DEs &amp;#39;production-ize&amp;#39; this after the fact, oftentimes using something entirely different that requires re-writing and optimizing the query/code/etc (i.e., from pandas to spark).&lt;/p&gt;\n\n&lt;p&gt;From SWE perspective, it seems like it is an error-prone process and redundant, and I haven&amp;#39;t been able to find anything highlighting how this is generally handled.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have good case studies / anecdotal advice on how this process is supposed to work? Any good examples of how DEs and DSs work together in your experience?  Any pointers would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvkryj", "is_robot_indexable": true, "report_reasons": null, "author": "suralo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvkryj/any_good_examples_of_the_de_lifecycle_and_synergy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvkryj/any_good_examples_of_the_de_lifecycle_and_synergy/", "subreddit_subscribers": 80007, "created_utc": 1668480753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Relatively new to the space, coming from an SWE role, and am having trouble understanding the process between exploring data and turning it into a production pipeline.\n\nGeneral ETL pipelines make sense to me, but where I am confused is more 'analytics' pipelines -- ones that not only do transformations on data, but also do analysis during their transformations for visualizations, models, etc that require more contextual understanding of the data.\n\nIt is surprising to me that 'data scientists' will do EDA, provide the details via a notebook or something, and then DEs production-ize this after the fact, oftentimes using something entirely different that requires re-writing the query/code/etc (i.e., from pandas to pyspark).  \n\n\nFrom SWE perspective, it seems like it is an error-prone process and redundant.  \n\n\nI am also unclear on who owns new features/modifications from business during this loop.  \n\n\nDoes anyone have good case studies / anecdotal advice on how to unify this process? Or am I misrepresenting the process and it actually is supposed to be set up differently? Any pointers would be greatly appreciated.", "author_fullname": "t2_ub4hlwpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good Examples of the Data Engineering Lifecycle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvi2ld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668473378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Relatively new to the space, coming from an SWE role, and am having trouble understanding the process between exploring data and turning it into a production pipeline.&lt;/p&gt;\n\n&lt;p&gt;General ETL pipelines make sense to me, but where I am confused is more &amp;#39;analytics&amp;#39; pipelines -- ones that not only do transformations on data, but also do analysis during their transformations for visualizations, models, etc that require more contextual understanding of the data.&lt;/p&gt;\n\n&lt;p&gt;It is surprising to me that &amp;#39;data scientists&amp;#39; will do EDA, provide the details via a notebook or something, and then DEs production-ize this after the fact, oftentimes using something entirely different that requires re-writing the query/code/etc (i.e., from pandas to pyspark).  &lt;/p&gt;\n\n&lt;p&gt;From SWE perspective, it seems like it is an error-prone process and redundant.  &lt;/p&gt;\n\n&lt;p&gt;I am also unclear on who owns new features/modifications from business during this loop.  &lt;/p&gt;\n\n&lt;p&gt;Does anyone have good case studies / anecdotal advice on how to unify this process? Or am I misrepresenting the process and it actually is supposed to be set up differently? Any pointers would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yvi2ld", "is_robot_indexable": true, "report_reasons": null, "author": "No_Bat835", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvi2ld/good_examples_of_the_data_engineering_lifecycle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvi2ld/good_examples_of_the_data_engineering_lifecycle/", "subreddit_subscribers": 80007, "created_utc": 1668473378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to request for some aws access/permssions from the tech team. What permissions/access can I request. \nI would like to use redshift, aurora mysql, lambda, airflow.\n\nI have always used okta and things are pretty set up in my old job.\n\nSo what should I request for?", "author_fullname": "t2_3w9dfvgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What access &amp; Permissions do I need on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvcz5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668460770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to request for some aws access/permssions from the tech team. What permissions/access can I request. \nI would like to use redshift, aurora mysql, lambda, airflow.&lt;/p&gt;\n\n&lt;p&gt;I have always used okta and things are pretty set up in my old job.&lt;/p&gt;\n\n&lt;p&gt;So what should I request for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvcz5r", "is_robot_indexable": true, "report_reasons": null, "author": "mrmilata", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvcz5r/what_access_permissions_do_i_need_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvcz5r/what_access_permissions_do_i_need_on_aws/", "subreddit_subscribers": 80007, "created_utc": 1668460770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know if Delta Live Tables can stream data from a delta table? We currently have our source data for the DLT pipeline in delta format. I have successfully created a pipeline reading the data as parquet, but ideally we would want to read as delta. Does anyone have any insight on this?", "author_fullname": "t2_3mm882fo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion with Delta Live Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv7imp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668449294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know if Delta Live Tables can stream data from a delta table? We currently have our source data for the DLT pipeline in delta format. I have successfully created a pipeline reading the data as parquet, but ideally we would want to read as delta. Does anyone have any insight on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv7imp", "is_robot_indexable": true, "report_reasons": null, "author": "mcqueg", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv7imp/data_ingestion_with_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv7imp/data_ingestion_with_delta_live_tables/", "subreddit_subscribers": 80007, "created_utc": 1668449294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dremio Contributes the Arrow Flight SQL JDBC Driver to the Apache Arrow Community \u2013 The Latest of Many Contributions | Dremio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yv4z3z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VzybhJXLFA8l35ZZiFK_kRskUhsSQIe6puq46uqnwxk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668444257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/blog/dremio-contributes-the-arrow-flight-sql-jdbc-driver-to-the-apache-arrow-community-the-latest-of-many-contributions/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?auto=webp&amp;s=6e6cd51218e5daa44fda46e871254d67b4f0b028", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3ff4e8f3ca79122c80a3edca5e76f391dbe6bdfe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=33960553c96829ccee2547f8ab406130247c7384", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df3787d2c0c0fd87c0515f59c003c36736a729ec", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f2078e40e00eed2276fcc88816b7ba1fc0b1e1f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ce6f95c31b9473961006a3d143d79d7513af6c5", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=511268e51ae4130135da26f6139fe780805c37b2", "width": 1080, "height": 565}], "variants": {}, "id": "dwgv-bjmtKMXlgmwTW_CSzpXGhwr6pO9hwIr945P_3g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yv4z3z", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv4z3z/dremio_contributes_the_arrow_flight_sql_jdbc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/blog/dremio-contributes-the-arrow-flight-sql-jdbc-driver-to-the-apache-arrow-community-the-latest-of-many-contributions/", "subreddit_subscribers": 80007, "created_utc": 1668444257.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}