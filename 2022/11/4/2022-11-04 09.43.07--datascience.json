{"kind": "Listing", "data": {"after": "t3_ylrxxq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dv1qy8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Add it to the training set, Walmart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ylfpqx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 886, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 886, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/J8_0BpvFtCKSrQS42vGNBi1MYiGUfVlolDzuFR9rNbI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667511110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/irkcbvz41tx91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?auto=webp&amp;s=3eeebea51a0db8c7505d8dcedfa7a51d28a47eda", "width": 918, "height": 1530}, "resolutions": [{"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17681b92c04f89a5069d6060dcf9ec6bc5175953", "width": 108, "height": 180}, {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=36dca12dd4f1a82c7d4a698546271a198b5aae42", "width": 216, "height": 360}, {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62c6512e64131b9b06c4448406eb5c256cda068e", "width": 320, "height": 533}, {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4c8f3b471181c4747b7a49eb847a1da22d3bb58", "width": 640, "height": 1066}], "variants": {}, "id": "VitcyIruHSc5Syx21UOmHxbI5Z06g7YMBREl7rTcvBQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylfpqx", "is_robot_indexable": true, "report_reasons": null, "author": "ljh78", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylfpqx/add_it_to_the_training_set_walmart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/irkcbvz41tx91.jpg", "subreddit_subscribers": 817150, "created_utc": 1667511110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it just me or are the vast majority of job adverts on linked in right now for senior/lead/principal data scientists? (UK btw)\n\nI only saw a single advert for a junior role and this had over 200 applications in just a few a hours of being released.", "author_fullname": "t2_1rp1btfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No one is hiring juniors/ mid-level data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykyte6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 312, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 312, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667471938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just me or are the vast majority of job adverts on linked in right now for senior/lead/principal data scientists? (UK btw)&lt;/p&gt;\n\n&lt;p&gt;I only saw a single advert for a junior role and this had over 200 applications in just a few a hours of being released.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykyte6", "is_robot_indexable": true, "report_reasons": null, "author": "nullspace1729", "discussion_type": null, "num_comments": 91, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykyte6/no_one_is_hiring_juniors_midlevel_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykyte6/no_one_is_hiring_juniors_midlevel_data_scientists/", "subreddit_subscribers": 817150, "created_utc": 1667471938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_bb4m08u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing OpenAI GPT3 in Airtable. Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work pretty well. Any interesting use cases that you'd recommend testing with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ykybpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 51, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/igornefedovi/status/1588032734315704320", "author_name": "Igor Nefedov", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/igornefedovi", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ykybpj", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/H5M11fv0b8Wy11cjAmYQFWbHB-Y653u0jbpFjTdc5o4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667470649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/igornefedovi/status/1588032734315704320", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q3_cAr_0AWvl2doPMq2oGYGlBrKQB6CXdpzOFQmnUBk.jpg?auto=webp&amp;s=438a341ce2e08c3d99c58319f7ff907ff8f90806", "width": 140, "height": 78}, "resolutions": [{"url": "https://external-preview.redd.it/Q3_cAr_0AWvl2doPMq2oGYGlBrKQB6CXdpzOFQmnUBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cf5cae1ce8dfd29d83b91454d5da4ef40e8288b", "width": 108, "height": 60}], "variants": {}, "id": "HYnQ8FaO96_yByBsMJgxlZn_e9b7QzNp8IGJjv5tEac"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykybpj", "is_robot_indexable": true, "report_reasons": null, "author": "igornefedovi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykybpj/testing_openai_gpt3_in_airtable_finetuning_gpt3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/igornefedovi/status/1588032734315704320", "subreddit_subscribers": 817150, "created_utc": 1667470649.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/igornefedovi/status/1588032734315704320", "author_name": "Igor Nefedov", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/igornefedovi", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it not almost always better to use probability output? So the business had a view of the model confidence for each prediction and can act on this information rather than a more black box output?", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In a business context, why would you ever use a binary output for a binary classifier? Its it almost always better to output class probability so the business can set their own threshold?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykytgo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667471944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it not almost always better to use probability output? So the business had a view of the model confidence for each prediction and can act on this information rather than a more black box output?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykytgo", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykytgo/in_a_business_context_why_would_you_ever_use_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykytgo/in_a_business_context_why_would_you_ever_use_a/", "subreddit_subscribers": 817150, "created_utc": 1667471944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's great to see huge corporations like CVS trying to low-ball their senior data scientist . How do you even justify that low end of the salary range ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ylir6o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5dgAaM76PdXrozNx2Y8LkrJrYorb71JgXsY_dZvz7gM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667518922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mmiiac2w5vx91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mmiiac2w5vx91.png?auto=webp&amp;s=13a694b51dec1728a6affcada829d4916b11abfd", "width": 1080, "height": 1841}, "resolutions": [{"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e4872ed5dec112ad6dcd89260e92e65e10ecd01", "width": 108, "height": 184}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a71d2f44c9ac53e75c267c9cd0047143bd59f07", "width": 216, "height": 368}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4eebacb8a62b560d494e00072fcb7b3094c14042", "width": 320, "height": 545}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=272139c312067d8bc5cd800a88fa13946f5e2031", "width": 640, "height": 1090}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=69ad657cce5748effb5e8fce7f1fe7c5af1ef9ed", "width": 960, "height": 1636}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cf795e5cf6dd250ab34c77f79c579e1703e19b7c", "width": 1080, "height": 1841}], "variants": {}, "id": "w2Nb8mRHA2mwiamI1lTgc7BiyVY0KwF5aSD449DeM3I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylir6o", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylir6o/its_great_to_see_huge_corporations_like_cvs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mmiiac2w5vx91.png", "subreddit_subscribers": 817150, "created_utc": 1667518922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As my title suggests. I'm quite worried about the lay-offs happening, and I've overheard that data people are the first ones to let go. Is it true? Also do data engineers have more job security compared maybe data scientists/analysts?\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_tsoiffje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it true that when tech companies lay off people, usually data scientists/analysts/engineers are the first ones to let go? If it's true, does it mean that we have less job security compared with usual SWEs writing codes and building products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yli49w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667517367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As my title suggests. I&amp;#39;m quite worried about the lay-offs happening, and I&amp;#39;ve overheard that data people are the first ones to let go. Is it true? Also do data engineers have more job security compared maybe data scientists/analysts?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yli49w", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Maintenance-1871", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yli49w/is_it_true_that_when_tech_companies_lay_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yli49w/is_it_true_that_when_tech_companies_lay_off/", "subreddit_subscribers": 817150, "created_utc": 1667517367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When do you guys think FAANG will start rehiring for mid level data science/MLE roles with 2+ yoe?\n\n6 months?\n\n12 months?\n\n2 years?", "author_fullname": "t2_1ns77nex", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FAANG Hiring Again Timeframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylk4na", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": "", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "seniorflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667522587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When do you guys think FAANG will start rehiring for mid level data science/MLE roles with 2+ yoe?&lt;/p&gt;\n\n&lt;p&gt;6 months?&lt;/p&gt;\n\n&lt;p&gt;12 months?&lt;/p&gt;\n\n&lt;p&gt;2 years?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist MS|MBA ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylk4na", "is_robot_indexable": true, "report_reasons": null, "author": "DJAlaskaAndrew", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/ylk4na/faang_hiring_again_timeframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylk4na/faang_hiring_again_timeframe/", "subreddit_subscribers": 817150, "created_utc": 1667522587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a few years of analytics experience but have recently been looking to make a change. \n\nOver the course of my career I've had many interviews. I've done many case studies (some live, some take homes). I've answered lots of various technical and behavioral questions. You know the drill.\n\nBut not once had I been asked to literally calculate probabilities and shit live over an interview, until today. This seems like *such* bad practice to me. The question was a word problem, like something on a stats 101 homework assignment. There is quiet literally almost no value in asking questions like this.\n\nIt seems like these questions aren't all that uncommon in interviews...but they definitely ought to be!\n\nHow often have you been asked to do actual calculations during an interview?", "author_fullname": "t2_2s0os6oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asking Data Scientists to do calculations live in an interview is nuts.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yljrkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667521599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few years of analytics experience but have recently been looking to make a change. &lt;/p&gt;\n\n&lt;p&gt;Over the course of my career I&amp;#39;ve had many interviews. I&amp;#39;ve done many case studies (some live, some take homes). I&amp;#39;ve answered lots of various technical and behavioral questions. You know the drill.&lt;/p&gt;\n\n&lt;p&gt;But not once had I been asked to literally calculate probabilities and shit live over an interview, until today. This seems like &lt;em&gt;such&lt;/em&gt; bad practice to me. The question was a word problem, like something on a stats 101 homework assignment. There is quiet literally almost no value in asking questions like this.&lt;/p&gt;\n\n&lt;p&gt;It seems like these questions aren&amp;#39;t all that uncommon in interviews...but they definitely ought to be!&lt;/p&gt;\n\n&lt;p&gt;How often have you been asked to do actual calculations during an interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yljrkq", "is_robot_indexable": true, "report_reasons": null, "author": "randoma1231vd", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yljrkq/asking_data_scientists_to_do_calculations_live_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yljrkq/asking_data_scientists_to_do_calculations_live_in/", "subreddit_subscribers": 817150, "created_utc": 1667521599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\n&amp;#x200B;\n\nForgive me if this is not the right place to do this but I am studying data science myself and part of an assignment we have is to interview Data Scientist in the field regarding Data Ethics and create a summary of the results.\n\n&amp;#x200B;\n\nWould a few of you mind answering the following questions for me? I have tried getting in contact directly with people at banks, other universities and so forth but I am struggling to find people willing to conduct the \"Interview\". We need to attach proof that we conducted the interview, hence I need actual real data and am not about the business of \"fudging\" results.\n\nAssignment questions are as follows:\n\n\\--------\n\nDuring the interview, discuss the person\u2019s professional experience with ethics issues in their professional career on both the technical and personnel/workplace sides. This should include issues they directly experienced, and if they want, can include issues they heard about, as well. Pick two or three of the most memorable issues brought up by your interview, and ask some follow-up questions:\n\n* Do they feel the issue was handled well or not?\n* Were there situations that made it difficult to take the most ethical path?\n\n\\--------\n\nAny feedback would really be appreciated.\n\nThanks :)", "author_fullname": "t2_ntnaxuu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykysox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667471888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Forgive me if this is not the right place to do this but I am studying data science myself and part of an assignment we have is to interview Data Scientist in the field regarding Data Ethics and create a summary of the results.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would a few of you mind answering the following questions for me? I have tried getting in contact directly with people at banks, other universities and so forth but I am struggling to find people willing to conduct the &amp;quot;Interview&amp;quot;. We need to attach proof that we conducted the interview, hence I need actual real data and am not about the business of &amp;quot;fudging&amp;quot; results.&lt;/p&gt;\n\n&lt;p&gt;Assignment questions are as follows:&lt;/p&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;During the interview, discuss the person\u2019s professional experience with ethics issues in their professional career on both the technical and personnel/workplace sides. This should include issues they directly experienced, and if they want, can include issues they heard about, as well. Pick two or three of the most memorable issues brought up by your interview, and ask some follow-up questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do they feel the issue was handled well or not?&lt;/li&gt;\n&lt;li&gt;Were there situations that made it difficult to take the most ethical path?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;Any feedback would really be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykysox", "is_robot_indexable": true, "report_reasons": null, "author": "Eat-More-Brains", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykysox/data_science_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykysox/data_science_interview/", "subreddit_subscribers": 817150, "created_utc": 1667471888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have what I think may be a simple request, but I don\u2019t know where to start. I\u2019d like to use a program to figure out how many unique groups I have by sorting two lists into a 3rd list. Let\u2019s say list A has 100 locations, and list B has 20 products. All the items in list A require some of the products from list B. What I\u2019m hoping to do is drag the items from List B over the items in List A thus creating a group, ie \u201citem 1 in List A contains these 14 products\u201d (and I need items in List B to be reusable across all the items in List A). Then I want the program to tell me how many locations in List A are receiving the same products (and which locations). Then afterwards I\u2019ll know how many unique groupings of locations and products exist. I don\u2019t know if card sorting would actually work here or if I have the wrong idea about what card sorting is. I\u2019ve been able to do this in Excel somewhat successfully, but it\u2019s more maintenance than help. Just hoping someone might be able to point me in the right direction.", "author_fullname": "t2_bk6kyll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple request from a simpleton", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylcoe3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667504789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have what I think may be a simple request, but I don\u2019t know where to start. I\u2019d like to use a program to figure out how many unique groups I have by sorting two lists into a 3rd list. Let\u2019s say list A has 100 locations, and list B has 20 products. All the items in list A require some of the products from list B. What I\u2019m hoping to do is drag the items from List B over the items in List A thus creating a group, ie \u201citem 1 in List A contains these 14 products\u201d (and I need items in List B to be reusable across all the items in List A). Then I want the program to tell me how many locations in List A are receiving the same products (and which locations). Then afterwards I\u2019ll know how many unique groupings of locations and products exist. I don\u2019t know if card sorting would actually work here or if I have the wrong idea about what card sorting is. I\u2019ve been able to do this in Excel somewhat successfully, but it\u2019s more maintenance than help. Just hoping someone might be able to point me in the right direction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylcoe3", "is_robot_indexable": true, "report_reasons": null, "author": "DolphLundgrenMD", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylcoe3/a_simple_request_from_a_simpleton/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylcoe3/a_simple_request_from_a_simpleton/", "subreddit_subscribers": 817150, "created_utc": 1667504789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Even a tabular one could work, basically anything that can help!\n\nIn terms of tabular, I'm currently thinking off do an overall table per day of the week, then have another one under per day the hour. This can be a way but just wondering if there's an effective way to visualize it?\n\nI saw some examples like a heatmap but not sure if it can work, or how to do it.\n\nThe data is from ads data (clicks, impressions, installs, or etc.)", "author_fullname": "t2_7u37sy3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats a good visual to analyze/validate a dayparting strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylb8dh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667501673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Even a tabular one could work, basically anything that can help!&lt;/p&gt;\n\n&lt;p&gt;In terms of tabular, I&amp;#39;m currently thinking off do an overall table per day of the week, then have another one under per day the hour. This can be a way but just wondering if there&amp;#39;s an effective way to visualize it?&lt;/p&gt;\n\n&lt;p&gt;I saw some examples like a heatmap but not sure if it can work, or how to do it.&lt;/p&gt;\n\n&lt;p&gt;The data is from ads data (clicks, impressions, installs, or etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylb8dh", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive-Pup-28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylb8dh/whats_a_good_visual_to_analyzevalidate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylb8dh/whats_a_good_visual_to_analyzevalidate_a/", "subreddit_subscribers": 817150, "created_utc": 1667501673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there. I'm a university student who wants to learn data analytics and get a certificate online. I recently discovered 365 Data Science's free courses until November 21, and I was able to obtain coupon codes for a 60% discount on their annual subscription, which costs $174 per year.\n\nI'm interested in their [Data Analyst career track](https://learn.365datascience.com/career-tracks/data-analyst/). A total of 44 hours of course content plus exams is required for the certificate of completion.\n\nIs there anyone here who has used their learning platform? I'd be delighted to hear from some of you. I'd also like to hear from users of other platforms like DataQuest, DataCamp, and so on. I searched for the same question in this forum but only found spam promotional posts.\n\nI'm stuck between this course and the [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics). According to what I've read online, the Google one costs $39 per month and lasts 181 hours. Due to its lower cost and shorter duration, this makes me lean more toward the 365DS program.\n\nWhich certification has more credibility and is more useful? I'm looking for a more job-ready option and something to help me overcome my poor academic performance. Thank you,\u00a0any help would be greatly appreciated :)", "author_fullname": "t2_egf3g5uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take the 365DS Data Analyst Career Track?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yla99d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667499608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. I&amp;#39;m a university student who wants to learn data analytics and get a certificate online. I recently discovered 365 Data Science&amp;#39;s free courses until November 21, and I was able to obtain coupon codes for a 60% discount on their annual subscription, which costs $174 per year.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in their &lt;a href=\"https://learn.365datascience.com/career-tracks/data-analyst/\"&gt;Data Analyst career track&lt;/a&gt;. A total of 44 hours of course content plus exams is required for the certificate of completion.&lt;/p&gt;\n\n&lt;p&gt;Is there anyone here who has used their learning platform? I&amp;#39;d be delighted to hear from some of you. I&amp;#39;d also like to hear from users of other platforms like DataQuest, DataCamp, and so on. I searched for the same question in this forum but only found spam promotional posts.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m stuck between this course and the &lt;a href=\"https://www.coursera.org/professional-certificates/google-data-analytics\"&gt;Google Data Analytics Professional Certificate&lt;/a&gt;. According to what I&amp;#39;ve read online, the Google one costs $39 per month and lasts 181 hours. Due to its lower cost and shorter duration, this makes me lean more toward the 365DS program.&lt;/p&gt;\n\n&lt;p&gt;Which certification has more credibility and is more useful? I&amp;#39;m looking for a more job-ready option and something to help me overcome my poor academic performance. Thank you,\u00a0any help would be greatly appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?auto=webp&amp;s=2c79ec2c452bb4d01df675d2a739bd47f221a670", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=108658d3e7925b2e114ce4a4c04d5f4e4295487d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9561ba20aaf47ba07975c9cc270feb3b83108d8a", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82e442618be3944d045e58fadd5034487d2d6642", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0afa3e8d4b806ab74b5d8d146baf8afd3fa7b37", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7fd653b4af836fe5c3f3e7ad731464fa007c47fb", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=070e674c45fe1ce071fffe889a90255b231bbe82", "width": 1080, "height": 564}], "variants": {}, "id": "t7A4BY9o-aX-XTyFjhKEkiEB0ueAqjclZI80A8Moy40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yla99d", "is_robot_indexable": true, "report_reasons": null, "author": "nolettuceandtomatoes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yla99d/should_i_take_the_365ds_data_analyst_career_track/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yla99d/should_i_take_the_365ds_data_analyst_career_track/", "subreddit_subscribers": 817150, "created_utc": 1667499608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For you people who already studied in 365datascience... Is it worth the time?", "author_fullname": "t2_t6iqoxd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is 365datascience good enough for entry level job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylpebt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667538130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For you people who already studied in 365datascience... Is it worth the time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylpebt", "is_robot_indexable": true, "report_reasons": null, "author": "mbrtlchouia", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylpebt/is_365datascience_good_enough_for_entry_level_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylpebt/is_365datascience_good_enough_for_entry_level_job/", "subreddit_subscribers": 817150, "created_utc": 1667538130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8mgpbrkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping a car listing website - got the mileage and price of each car!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_ylj4ja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "My First Web Scraping Project", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "author_name": "CarlNx lvl", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xOKYxTHCKfQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCntYZbcwlB3MinNQvNv4dKw"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ylj4ja", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yRx1jfwiiU3arvw1prR7rYSionsX_QwSu94jyTddpW8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667519916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xOKYxTHCKfQ", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?auto=webp&amp;s=188a66b99d92bafa886f36f634f4c7888acc9963", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2672e6fc462836531eadde12e650cab524d15856", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=278d7b4bb9e8e151a3bc51e98fafe97aa1e2a98f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a10ac08fc629ca110efba96919c73d49a6cc7e3a", "width": 320, "height": 240}], "variants": {}, "id": "pLzfhouXMAx36Fj97I6GwgSwkYUdQHzB5Ndgruj1_wQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylj4ja", "is_robot_indexable": true, "report_reasons": null, "author": "carlnx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylj4ja/scraping_a_car_listing_website_got_the_mileage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xOKYxTHCKfQ", "subreddit_subscribers": 817150, "created_utc": 1667519916.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "My First Web Scraping Project", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "author_name": "CarlNx lvl", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xOKYxTHCKfQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCntYZbcwlB3MinNQvNv4dKw"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are looking for such platform and I am trying to see what others think of these products or what else is out there ?", "author_fullname": "t2_he02w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone evaluated third party platforms such as panalgo or aetion or other ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylj3nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667519852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are looking for such platform and I am trying to see what others think of these products or what else is out there ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylj3nj", "is_robot_indexable": true, "report_reasons": null, "author": "Vervain7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylj3nj/has_anyone_evaluated_third_party_platforms_such/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylj3nj/has_anyone_evaluated_third_party_platforms_such/", "subreddit_subscribers": 817150, "created_utc": 1667519852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello friends!\n\nI'm trying to build a book similarity model to evaluate how similar two books are. I have multiple text fields such as:\n\n* title\n* author\n* subject\n* description (long text)\n* table of content (long text)\n\nUntil now I was concatenating everything into one string and producing one TF-IDF vector for each book. Then I was simply running cosine similarity.\n\nNow I came to realize some features are more important than others. For example title similarity is more important than subject similarity, but I don't know how to incorporate that into the model. I was thinking of constructing a TF-IDF vector for each column and then calculating similarities separately, then weighting the similarity scores themselves. Is there a better way to achieve this?\n\nThank you!", "author_fullname": "t2_286kcv5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple Text Features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylhg0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667515967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to build a book similarity model to evaluate how similar two books are. I have multiple text fields such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;title&lt;/li&gt;\n&lt;li&gt;author&lt;/li&gt;\n&lt;li&gt;subject&lt;/li&gt;\n&lt;li&gt;description (long text)&lt;/li&gt;\n&lt;li&gt;table of content (long text)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Until now I was concatenating everything into one string and producing one TF-IDF vector for each book. Then I was simply running cosine similarity.&lt;/p&gt;\n\n&lt;p&gt;Now I came to realize some features are more important than others. For example title similarity is more important than subject similarity, but I don&amp;#39;t know how to incorporate that into the model. I was thinking of constructing a TF-IDF vector for each column and then calculating similarities separately, then weighting the similarity scores themselves. Is there a better way to achieve this?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylhg0b", "is_robot_indexable": true, "report_reasons": null, "author": "thecrixus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylhg0b/multiple_text_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylhg0b/multiple_text_features/", "subreddit_subscribers": 817150, "created_utc": 1667515967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey just wondering if anyone has some good resources to dive deep into quantitative analytics(books, websites, videos, etc.)", "author_fullname": "t2_9mx4u3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best resources for quantitative analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylhcsv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667515795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey just wondering if anyone has some good resources to dive deep into quantitative analytics(books, websites, videos, etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylhcsv", "is_robot_indexable": true, "report_reasons": null, "author": "Vnix7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylhcsv/best_resources_for_quantitative_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylhcsv/best_resources_for_quantitative_analytics/", "subreddit_subscribers": 817150, "created_utc": 1667515795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everybody\n\nA long time ago I came here asking for guidance on the world of data from there to here I've been improving and practicing, without belting the internships. That's why I'm coming back here looking for an international opportunity (Especially with the instability that Brazil and Latin America are experiencing), any help is welcome and whatever I can help just call, I'm here to network.\n\n[Linkedin](https://www.linkedin.com/in/matheussbrandao/?locale=en_US)", "author_fullname": "t2_3bymdoy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an international network and guidance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylf3m2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667509839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody&lt;/p&gt;\n\n&lt;p&gt;A long time ago I came here asking for guidance on the world of data from there to here I&amp;#39;ve been improving and practicing, without belting the internships. That&amp;#39;s why I&amp;#39;m coming back here looking for an international opportunity (Especially with the instability that Brazil and Latin America are experiencing), any help is welcome and whatever I can help just call, I&amp;#39;m here to network.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/in/matheussbrandao/?locale=en_US\"&gt;Linkedin&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylf3m2", "is_robot_indexable": true, "report_reasons": null, "author": "mathsugar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylf3m2/looking_for_an_international_network_and_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylf3m2/looking_for_an_international_network_and_guidance/", "subreddit_subscribers": 817150, "created_utc": 1667509839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm trying to reverse engineer in my mind the process of returning summary statistics for a large dataset very quickly. I am thinking for example, returning data to a front end to create some charts on a webpage.\n\nLet's say we have a database recording the results of 20,000 matches of a game. The matches have all sorts of data, for example damage done by a certain spell every 10 seconds. It's a lot of data.\n\nWe now want to return the total damage of the spell, \"fireball\", throughout all of the matches. A silly approach would be, every time a user visits a webpage, sum across all 20,000 matches find where spell = \"fireball\" and sum up each damage bit to get the total. This computation would take time regardless of overpaying for high levels of computational power.\n\nWhat I would consider doing in this case is create a new statistics portion of the database. It would include total damage for fireball. Each time you would finish a match, or at another time interval, you would simply add the damage to the total.\n\nWhen you want your statistics, you simply ping the fireball statistics and return the data. I think that this would work great because it would put minor computation requirements on your server frequently rather than massive computation whenever a user wants his stats.\n\nA problem comes up with this approach, what if you needed to report more complex statistics that you can't simply add to every time? If you wanted 95th quartile, or median, you would need to go through every game session and get yourself the entire series (let's call this a full database scan).\n\n**My question:** What sorts of approaches in data management are given for computing up to date complex statistics over large data sets? Would it be a batched process where we are not doing a full database scan every match, but perhaps every 500 matches? Is there any reading I can do to understand these types data/database management practices?", "author_fullname": "t2_4xizssma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serving Complex Statistics from Large Databases as Quickly As Possible", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylewcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667509424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to reverse engineer in my mind the process of returning summary statistics for a large dataset very quickly. I am thinking for example, returning data to a front end to create some charts on a webpage.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we have a database recording the results of 20,000 matches of a game. The matches have all sorts of data, for example damage done by a certain spell every 10 seconds. It&amp;#39;s a lot of data.&lt;/p&gt;\n\n&lt;p&gt;We now want to return the total damage of the spell, &amp;quot;fireball&amp;quot;, throughout all of the matches. A silly approach would be, every time a user visits a webpage, sum across all 20,000 matches find where spell = &amp;quot;fireball&amp;quot; and sum up each damage bit to get the total. This computation would take time regardless of overpaying for high levels of computational power.&lt;/p&gt;\n\n&lt;p&gt;What I would consider doing in this case is create a new statistics portion of the database. It would include total damage for fireball. Each time you would finish a match, or at another time interval, you would simply add the damage to the total.&lt;/p&gt;\n\n&lt;p&gt;When you want your statistics, you simply ping the fireball statistics and return the data. I think that this would work great because it would put minor computation requirements on your server frequently rather than massive computation whenever a user wants his stats.&lt;/p&gt;\n\n&lt;p&gt;A problem comes up with this approach, what if you needed to report more complex statistics that you can&amp;#39;t simply add to every time? If you wanted 95th quartile, or median, you would need to go through every game session and get yourself the entire series (let&amp;#39;s call this a full database scan).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My question:&lt;/strong&gt; What sorts of approaches in data management are given for computing up to date complex statistics over large data sets? Would it be a batched process where we are not doing a full database scan every match, but perhaps every 500 matches? Is there any reading I can do to understand these types data/database management practices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylewcw", "is_robot_indexable": true, "report_reasons": null, "author": "gunnerydota", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylewcw/serving_complex_statistics_from_large_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylewcw/serving_complex_statistics_from_large_databases/", "subreddit_subscribers": 817150, "created_utc": 1667509424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I worked on the project and practically built everything from ground up however after a few months the team needs me to help answer questions on a portion  my teammates worked on. I am familiar with the whole process so I am the only one who knows time-series since the other than a DS is on maternity leave.\n\nI asked for part time during my studies and full time but they didn\u2019t give me anything and half assed any attempted to give me a job. However now that they are struggling they are asking for free consultations. \n\nthey put a new kid on the project but still do not have people qualified or knowledgeable enough to maintain and uphold the quality. So i am worried they would expect me to train their employees for free without them offering anything in return.\n\nNote: i put everything properly on documentation as well as how to trouble shoot potential problems.", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project manager reached out to me for help to answer questions on deployment after the end of my internship.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl8gmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667495827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I worked on the project and practically built everything from ground up however after a few months the team needs me to help answer questions on a portion  my teammates worked on. I am familiar with the whole process so I am the only one who knows time-series since the other than a DS is on maternity leave.&lt;/p&gt;\n\n&lt;p&gt;I asked for part time during my studies and full time but they didn\u2019t give me anything and half assed any attempted to give me a job. However now that they are struggling they are asking for free consultations. &lt;/p&gt;\n\n&lt;p&gt;they put a new kid on the project but still do not have people qualified or knowledgeable enough to maintain and uphold the quality. So i am worried they would expect me to train their employees for free without them offering anything in return.&lt;/p&gt;\n\n&lt;p&gt;Note: i put everything properly on documentation as well as how to trouble shoot potential problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl8gmi", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl8gmi/project_manager_reached_out_to_me_for_help_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl8gmi/project_manager_reached_out_to_me_for_help_to/", "subreddit_subscribers": 817150, "created_utc": 1667495827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Fundamentals of Data Engineering by Joe Reis and Matthew Housley.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl6qnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mh2cfxap", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Fundamentals of Data Engineering](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302) has received a lot of good reviews in the data world, and I\u2019ve been meaning to read it.Turns out lots of folks have been meaning to read it too, so I put together a book club!\n\nI'm not being paid to promote this book in any way, shape, or form. I have no business affiliation with the authors. I just want to read it in a book club.**Here\u2019s a brief overview of the book club:**\\- All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.**Schedule:**\n\n* [**November 18th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-11&amp;date=2022-11-18)**:** Discuss Chapters 1-3\n* [**December 2nd**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-02)**:** Discuss Chapters 4-7\n* [**December 8th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-08)**:** Live AMA with Joe Reis, the author\n* [**December 16th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-16)**:** Discuss Chapters 8-11\n\nWe currently have 20+ people participating!If this sounds interesting to you, find additional details and schedule [here](https://calendly.com/jparkerrogers/oa-book-club?month=2022-11).", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Fundamentals of Data Engineering by Joe Reis and Matthew Housley.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykbcfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 160, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 160, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667434000.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667410085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302\"&gt;Fundamentals of Data Engineering&lt;/a&gt; has received a lot of good reviews in the data world, and I\u2019ve been meaning to read it.Turns out lots of folks have been meaning to read it too, so I put together a book club!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not being paid to promote this book in any way, shape, or form. I have no business affiliation with the authors. I just want to read it in a book club.&lt;strong&gt;Here\u2019s a brief overview of the book club:&lt;/strong&gt;- All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.&lt;strong&gt;Schedule:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-11&amp;amp;date=2022-11-18\"&gt;&lt;strong&gt;November 18th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 1-3&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-02\"&gt;&lt;strong&gt;December 2nd&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 4-7&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-08\"&gt;&lt;strong&gt;December 8th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Live AMA with Joe Reis, the author&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-16\"&gt;&lt;strong&gt;December 16th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 8-11&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We currently have 20+ people participating!If this sounds interesting to you, find additional details and schedule &lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-11\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ykbcfo", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "subreddit_subscribers": 78873, "created_utc": 1667410085.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1667491606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl6qnq", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ykbcfo", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl6qnq/book_club_fundamentals_of_data_engineering_by_joe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "subreddit_subscribers": 817150, "created_utc": 1667491606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m not sure exactly how to phrase this. Professional DS with 15 years experience. I have no problems doing everything locally or on a web server if someone sets one up for me. For example, my company has a process to deploy Python scripts via restful API. The engineer taught me how to deploy what in need but when something breaks I am lost. How would I learn to fix bugs or setup my own type of service? Another issue. Someone is sending me a huge data file across a subnet at 5MB per second. Often the job fails. I would like to try to fix this. How do I learn about this. I don\u2019t even know what it\u2019s called. I\u2019m tired of waiting on other people to solve my problems.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources for architecture and networks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1w7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667479497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not sure exactly how to phrase this. Professional DS with 15 years experience. I have no problems doing everything locally or on a web server if someone sets one up for me. For example, my company has a process to deploy Python scripts via restful API. The engineer taught me how to deploy what in need but when something breaks I am lost. How would I learn to fix bugs or setup my own type of service? Another issue. Someone is sending me a huge data file across a subnet at 5MB per second. Often the job fails. I would like to try to fix this. How do I learn about this. I don\u2019t even know what it\u2019s called. I\u2019m tired of waiting on other people to solve my problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl1w7d", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl1w7d/good_resources_for_architecture_and_networks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl1w7d/good_resources_for_architecture_and_networks/", "subreddit_subscribers": 817150, "created_utc": 1667479497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm finding parallelising an r task (which basically means assigning work to a separate r session) requires all data in my environment to be copied over to the cache of the new core. If I'm working with just 10gb of data, my machine is losing more time copying data than it's saving by parallelising. This means I can't even split up CV tasks on windows, which should be trivial to parallelise.\n\nIs there an obvious alternative to this approach? And am I right in saying running on Linux would avoid this bottleneck?", "author_fullname": "t2_1rwftqt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does lack of fork parallelisation make windows an impractical OS for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl10to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667477285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finding parallelising an r task (which basically means assigning work to a separate r session) requires all data in my environment to be copied over to the cache of the new core. If I&amp;#39;m working with just 10gb of data, my machine is losing more time copying data than it&amp;#39;s saving by parallelising. This means I can&amp;#39;t even split up CV tasks on windows, which should be trivial to parallelise.&lt;/p&gt;\n\n&lt;p&gt;Is there an obvious alternative to this approach? And am I right in saying running on Linux would avoid this bottleneck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl10to", "is_robot_indexable": true, "report_reasons": null, "author": "theAbominablySlowMan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl10to/does_lack_of_fork_parallelisation_make_windows_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl10to/does_lack_of_fork_parallelisation_make_windows_an/", "subreddit_subscribers": 817150, "created_utc": 1667477285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_80wts4h1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I'm applying for Data Science full-time graduate roles for Summer/Fall 2023 start. I'm getting through the initial screen for SWE roles, but not for DS. I want to do DS, but expanded my search to SWE since I'm not getting interviews. What's wrong with my resume? TIA!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"q7vzrd2d2wx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28cd505afdfbfc763d9d2f6093f4df91b5738677"}, {"y": 278, "x": 216, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=65e0e35fa3408471fbf3083df656c2642052e337"}, {"y": 412, "x": 320, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3906e01657ee70afcf1e2020cdb9a69b131e6e0b"}, {"y": 825, "x": 640, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8da9b77d1e9165471bed1f7d416d70cd10f07db7"}, {"y": 1238, "x": 960, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=191bc16e83ab4227fe250c9cb3ac0a5ccaa3f074"}, {"y": 1393, "x": 1080, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd7d3850f64267c1c40ce2db9e6d177ac95fb6a9"}], "s": {"y": 1414, "x": 1096, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=1096&amp;format=png&amp;auto=webp&amp;s=ac573fcd725bb142b4d534cd93a48867c0b2f436"}, "id": "q7vzrd2d2wx91"}, "p2z56zsc2wx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8aca13c0831e6d8bc18ac334f4d2583c2fe8a2d5"}, {"y": 278, "x": 216, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3dc5d8dd58367cf7e7499a5d12cede643b6373b"}, {"y": 413, "x": 320, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c088841a0730a4210c48721913aedeedb3371c35"}, {"y": 826, "x": 640, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=144586176c5b20eb0ae50f248da07494c4c4ca3d"}, {"y": 1239, "x": 960, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=51f8670e91a8a36b78c84d775fd9a42d50575fb1"}, {"y": 1394, "x": 1080, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94ab1c8b0c6bddb552b660a44c1e96f409a45ec2"}], "s": {"y": 1410, "x": 1092, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=1092&amp;format=png&amp;auto=webp&amp;s=c4ae9b75b8cf50adaec449cf708e1807d49fb887"}, "id": "p2z56zsc2wx91"}}, "name": "t3_yls2jd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "resume-p1", "media_id": "q7vzrd2d2wx91", "id": 205330261}, {"caption": "resume-p2", "media_id": "p2z56zsc2wx91", "id": 205330262}]}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DmJOeKJ-K65ggtu8hYjsX_z50teLgvnu7KThSs7NKOc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667547967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yls2jd", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yls2jd", "is_robot_indexable": true, "report_reasons": null, "author": "okbutfirst_coffee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yls2jd/im_applying_for_data_science_fulltime_graduate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yls2jd", "subreddit_subscribers": 817150, "created_utc": 1667547967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm a software engineer who is learning about deep learning + machine learning.\n\nI've been exploring time series prediction using TensorFlow, PyTorch, prophet etc.\n\nAssuming you can nicely split your data for training, test, validation is there a library or framework that lets you pass this exactly dataset to multiple or many different time series libraries and plot + evaluate the MAPE + other statistics?\n\nExample:\n\n* I nicely load, feature engineer and split my datasets\n* I then want to pass these into the following:\n   * prophet\n   * neuralprophet\n   * keras\n   * TensorFlow probability\n   * etc\n* And then I want to plot all of these results (MAPE etc) sorted from lowest to highest etc\n\nI presume (hope) that this has been solved for already and that I wouldn't have to roll my own version but just wondering what's out there?\n\nThis was the post that inspired me to ask the question\n\n[https://bytepawn.com/comparing-neuralprophet-and-prophet-for-timeseries-forecasting.html](https://bytepawn.com/comparing-neuralprophet-and-prophet-for-timeseries-forecasting.html)\n\nThanks", "author_fullname": "t2_sdb0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Framework to compare TimeSeries models against a single set of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylrxxq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667547457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a software engineer who is learning about deep learning + machine learning.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been exploring time series prediction using TensorFlow, PyTorch, prophet etc.&lt;/p&gt;\n\n&lt;p&gt;Assuming you can nicely split your data for training, test, validation is there a library or framework that lets you pass this exactly dataset to multiple or many different time series libraries and plot + evaluate the MAPE + other statistics?&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I nicely load, feature engineer and split my datasets&lt;/li&gt;\n&lt;li&gt;I then want to pass these into the following:\n\n&lt;ul&gt;\n&lt;li&gt;prophet&lt;/li&gt;\n&lt;li&gt;neuralprophet&lt;/li&gt;\n&lt;li&gt;keras&lt;/li&gt;\n&lt;li&gt;TensorFlow probability&lt;/li&gt;\n&lt;li&gt;etc&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;And then I want to plot all of these results (MAPE etc) sorted from lowest to highest etc&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I presume (hope) that this has been solved for already and that I wouldn&amp;#39;t have to roll my own version but just wondering what&amp;#39;s out there?&lt;/p&gt;\n\n&lt;p&gt;This was the post that inspired me to ask the question&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://bytepawn.com/comparing-neuralprophet-and-prophet-for-timeseries-forecasting.html\"&gt;https://bytepawn.com/comparing-neuralprophet-and-prophet-for-timeseries-forecasting.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylrxxq", "is_robot_indexable": true, "report_reasons": null, "author": "Javaguy44", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylrxxq/framework_to_compare_timeseries_models_against_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylrxxq/framework_to_compare_timeseries_models_against_a/", "subreddit_subscribers": 817150, "created_utc": 1667547457.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}