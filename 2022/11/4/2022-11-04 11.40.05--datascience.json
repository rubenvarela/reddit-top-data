{"kind": "Listing", "data": {"after": "t3_yls2jd", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dv1qy8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Add it to the training set, Walmart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ylfpqx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 980, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 980, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/J8_0BpvFtCKSrQS42vGNBi1MYiGUfVlolDzuFR9rNbI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667511110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/irkcbvz41tx91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?auto=webp&amp;s=3eeebea51a0db8c7505d8dcedfa7a51d28a47eda", "width": 918, "height": 1530}, "resolutions": [{"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17681b92c04f89a5069d6060dcf9ec6bc5175953", "width": 108, "height": 180}, {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=36dca12dd4f1a82c7d4a698546271a198b5aae42", "width": 216, "height": 360}, {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62c6512e64131b9b06c4448406eb5c256cda068e", "width": 320, "height": 533}, {"url": "https://preview.redd.it/irkcbvz41tx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4c8f3b471181c4747b7a49eb847a1da22d3bb58", "width": 640, "height": 1066}], "variants": {}, "id": "VitcyIruHSc5Syx21UOmHxbI5Z06g7YMBREl7rTcvBQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylfpqx", "is_robot_indexable": true, "report_reasons": null, "author": "ljh78", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylfpqx/add_it_to_the_training_set_walmart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/irkcbvz41tx91.jpg", "subreddit_subscribers": 817163, "created_utc": 1667511110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's great to see huge corporations like CVS trying to low-ball their senior data scientist . How do you even justify that low end of the salary range ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ylir6o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5dgAaM76PdXrozNx2Y8LkrJrYorb71JgXsY_dZvz7gM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667518922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mmiiac2w5vx91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mmiiac2w5vx91.png?auto=webp&amp;s=13a694b51dec1728a6affcada829d4916b11abfd", "width": 1080, "height": 1841}, "resolutions": [{"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e4872ed5dec112ad6dcd89260e92e65e10ecd01", "width": 108, "height": 184}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a71d2f44c9ac53e75c267c9cd0047143bd59f07", "width": 216, "height": 368}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4eebacb8a62b560d494e00072fcb7b3094c14042", "width": 320, "height": 545}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=272139c312067d8bc5cd800a88fa13946f5e2031", "width": 640, "height": 1090}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=69ad657cce5748effb5e8fce7f1fe7c5af1ef9ed", "width": 960, "height": 1636}, {"url": "https://preview.redd.it/mmiiac2w5vx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cf795e5cf6dd250ab34c77f79c579e1703e19b7c", "width": 1080, "height": 1841}], "variants": {}, "id": "w2Nb8mRHA2mwiamI1lTgc7BiyVY0KwF5aSD449DeM3I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylir6o", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylir6o/its_great_to_see_huge_corporations_like_cvs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mmiiac2w5vx91.png", "subreddit_subscribers": 817163, "created_utc": 1667518922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As my title suggests. I'm quite worried about the lay-offs happening, and I've overheard that data people are the first ones to let go. Is it true? Also do data engineers have more job security compared maybe data scientists/analysts?\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_tsoiffje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it true that when tech companies lay off people, usually data scientists/analysts/engineers are the first ones to let go? If it's true, does it mean that we have less job security compared with usual SWEs writing codes and building products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yli49w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667517367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As my title suggests. I&amp;#39;m quite worried about the lay-offs happening, and I&amp;#39;ve overheard that data people are the first ones to let go. Is it true? Also do data engineers have more job security compared maybe data scientists/analysts?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yli49w", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Maintenance-1871", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yli49w/is_it_true_that_when_tech_companies_lay_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yli49w/is_it_true_that_when_tech_companies_lay_off/", "subreddit_subscribers": 817163, "created_utc": 1667517367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When do you guys think FAANG will start rehiring for mid level data science/MLE roles with 2+ yoe?\n\n6 months?\n\n12 months?\n\n2 years?", "author_fullname": "t2_1ns77nex", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FAANG Hiring Again Timeframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylk4na", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": "", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "seniorflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667522587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When do you guys think FAANG will start rehiring for mid level data science/MLE roles with 2+ yoe?&lt;/p&gt;\n\n&lt;p&gt;6 months?&lt;/p&gt;\n\n&lt;p&gt;12 months?&lt;/p&gt;\n\n&lt;p&gt;2 years?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist MS|MBA ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylk4na", "is_robot_indexable": true, "report_reasons": null, "author": "DJAlaskaAndrew", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/ylk4na/faang_hiring_again_timeframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylk4na/faang_hiring_again_timeframe/", "subreddit_subscribers": 817163, "created_utc": 1667522587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a few years of analytics experience but have recently been looking to make a change. \n\nOver the course of my career I've had many interviews. I've done many case studies (some live, some take homes). I've answered lots of various technical and behavioral questions. You know the drill.\n\nBut not once had I been asked to literally calculate probabilities and shit live over an interview, until today. This seems like *such* bad practice to me. The question was a word problem, like something on a stats 101 homework assignment. There is quiet literally almost no value in asking questions like this.\n\nIt seems like these questions aren't all that uncommon in interviews...but they definitely ought to be!\n\nHow often have you been asked to do actual calculations during an interview?", "author_fullname": "t2_2s0os6oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asking Data Scientists to do calculations live in an interview is nuts.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yljrkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667521599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few years of analytics experience but have recently been looking to make a change. &lt;/p&gt;\n\n&lt;p&gt;Over the course of my career I&amp;#39;ve had many interviews. I&amp;#39;ve done many case studies (some live, some take homes). I&amp;#39;ve answered lots of various technical and behavioral questions. You know the drill.&lt;/p&gt;\n\n&lt;p&gt;But not once had I been asked to literally calculate probabilities and shit live over an interview, until today. This seems like &lt;em&gt;such&lt;/em&gt; bad practice to me. The question was a word problem, like something on a stats 101 homework assignment. There is quiet literally almost no value in asking questions like this.&lt;/p&gt;\n\n&lt;p&gt;It seems like these questions aren&amp;#39;t all that uncommon in interviews...but they definitely ought to be!&lt;/p&gt;\n\n&lt;p&gt;How often have you been asked to do actual calculations during an interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yljrkq", "is_robot_indexable": true, "report_reasons": null, "author": "randoma1231vd", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yljrkq/asking_data_scientists_to_do_calculations_live_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yljrkq/asking_data_scientists_to_do_calculations_live_in/", "subreddit_subscribers": 817163, "created_utc": 1667521599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In our company, we are mainly working on handling duplicate data. Not the exact matches, similar records, too. What are the common problems in your company and how you are handling these issues?", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most common data processing problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ylv12d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667557544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In our company, we are mainly working on handling duplicate data. Not the exact matches, similar records, too. What are the common problems in your company and how you are handling these issues?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylv12d", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylv12d/what_is_the_most_common_data_processing_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylv12d/what_is_the_most_common_data_processing_problem/", "subreddit_subscribers": 817163, "created_utc": 1667557544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7ao0u2en", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you apply to US based roles from an international country?? (applying for jobs from companies that sponsor visas). Would you even get a response?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yluqeg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667556581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yluqeg", "is_robot_indexable": true, "report_reasons": null, "author": "the_scientist-7367", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yluqeg/can_you_apply_to_us_based_roles_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yluqeg/can_you_apply_to_us_based_roles_from_an/", "subreddit_subscribers": 817163, "created_utc": 1667556581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI would like to start with Python for data science. \n\nCan anybody recommend me a good book for beginners with no knowledge of Python?\n\n\nThanks!", "author_fullname": "t2_9b3fk8ea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to start with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ylui33", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667555969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I would like to start with Python for data science. &lt;/p&gt;\n\n&lt;p&gt;Can anybody recommend me a good book for beginners with no knowledge of Python?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylui33", "is_robot_indexable": true, "report_reasons": null, "author": "TheGuyFromTheSummit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylui33/how_to_start_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylui33/how_to_start_with_python/", "subreddit_subscribers": 817163, "created_utc": 1667555969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have what I think may be a simple request, but I don\u2019t know where to start. I\u2019d like to use a program to figure out how many unique groups I have by sorting two lists into a 3rd list. Let\u2019s say list A has 100 locations, and list B has 20 products. All the items in list A require some of the products from list B. What I\u2019m hoping to do is drag the items from List B over the items in List A thus creating a group, ie \u201citem 1 in List A contains these 14 products\u201d (and I need items in List B to be reusable across all the items in List A). Then I want the program to tell me how many locations in List A are receiving the same products (and which locations). Then afterwards I\u2019ll know how many unique groupings of locations and products exist. I don\u2019t know if card sorting would actually work here or if I have the wrong idea about what card sorting is. I\u2019ve been able to do this in Excel somewhat successfully, but it\u2019s more maintenance than help. Just hoping someone might be able to point me in the right direction.", "author_fullname": "t2_bk6kyll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple request from a simpleton", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylcoe3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667504789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have what I think may be a simple request, but I don\u2019t know where to start. I\u2019d like to use a program to figure out how many unique groups I have by sorting two lists into a 3rd list. Let\u2019s say list A has 100 locations, and list B has 20 products. All the items in list A require some of the products from list B. What I\u2019m hoping to do is drag the items from List B over the items in List A thus creating a group, ie \u201citem 1 in List A contains these 14 products\u201d (and I need items in List B to be reusable across all the items in List A). Then I want the program to tell me how many locations in List A are receiving the same products (and which locations). Then afterwards I\u2019ll know how many unique groupings of locations and products exist. I don\u2019t know if card sorting would actually work here or if I have the wrong idea about what card sorting is. I\u2019ve been able to do this in Excel somewhat successfully, but it\u2019s more maintenance than help. Just hoping someone might be able to point me in the right direction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylcoe3", "is_robot_indexable": true, "report_reasons": null, "author": "DolphLundgrenMD", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylcoe3/a_simple_request_from_a_simpleton/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylcoe3/a_simple_request_from_a_simpleton/", "subreddit_subscribers": 817163, "created_utc": 1667504789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Even a tabular one could work, basically anything that can help!\n\nIn terms of tabular, I'm currently thinking off do an overall table per day of the week, then have another one under per day the hour. This can be a way but just wondering if there's an effective way to visualize it?\n\nI saw some examples like a heatmap but not sure if it can work, or how to do it.\n\nThe data is from ads data (clicks, impressions, installs, or etc.)", "author_fullname": "t2_7u37sy3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats a good visual to analyze/validate a dayparting strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylb8dh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667501673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Even a tabular one could work, basically anything that can help!&lt;/p&gt;\n\n&lt;p&gt;In terms of tabular, I&amp;#39;m currently thinking off do an overall table per day of the week, then have another one under per day the hour. This can be a way but just wondering if there&amp;#39;s an effective way to visualize it?&lt;/p&gt;\n\n&lt;p&gt;I saw some examples like a heatmap but not sure if it can work, or how to do it.&lt;/p&gt;\n\n&lt;p&gt;The data is from ads data (clicks, impressions, installs, or etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylb8dh", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive-Pup-28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylb8dh/whats_a_good_visual_to_analyzevalidate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylb8dh/whats_a_good_visual_to_analyzevalidate_a/", "subreddit_subscribers": 817163, "created_utc": 1667501673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there. I'm a university student who wants to learn data analytics and get a certificate online. I recently discovered 365 Data Science's free courses until November 21, and I was able to obtain coupon codes for a 60% discount on their annual subscription, which costs $174 per year.\n\nI'm interested in their [Data Analyst career track](https://learn.365datascience.com/career-tracks/data-analyst/). A total of 44 hours of course content plus exams is required for the certificate of completion.\n\nIs there anyone here who has used their learning platform? I'd be delighted to hear from some of you. I'd also like to hear from users of other platforms like DataQuest, DataCamp, and so on. I searched for the same question in this forum but only found spam promotional posts.\n\nI'm stuck between this course and the [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics). According to what I've read online, the Google one costs $39 per month and lasts 181 hours. Due to its lower cost and shorter duration, this makes me lean more toward the 365DS program.\n\nWhich certification has more credibility and is more useful? I'm looking for a more job-ready option and something to help me overcome my poor academic performance. Thank you,\u00a0any help would be greatly appreciated :)", "author_fullname": "t2_egf3g5uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take the 365DS Data Analyst Career Track?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yla99d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667499608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. I&amp;#39;m a university student who wants to learn data analytics and get a certificate online. I recently discovered 365 Data Science&amp;#39;s free courses until November 21, and I was able to obtain coupon codes for a 60% discount on their annual subscription, which costs $174 per year.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in their &lt;a href=\"https://learn.365datascience.com/career-tracks/data-analyst/\"&gt;Data Analyst career track&lt;/a&gt;. A total of 44 hours of course content plus exams is required for the certificate of completion.&lt;/p&gt;\n\n&lt;p&gt;Is there anyone here who has used their learning platform? I&amp;#39;d be delighted to hear from some of you. I&amp;#39;d also like to hear from users of other platforms like DataQuest, DataCamp, and so on. I searched for the same question in this forum but only found spam promotional posts.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m stuck between this course and the &lt;a href=\"https://www.coursera.org/professional-certificates/google-data-analytics\"&gt;Google Data Analytics Professional Certificate&lt;/a&gt;. According to what I&amp;#39;ve read online, the Google one costs $39 per month and lasts 181 hours. Due to its lower cost and shorter duration, this makes me lean more toward the 365DS program.&lt;/p&gt;\n\n&lt;p&gt;Which certification has more credibility and is more useful? I&amp;#39;m looking for a more job-ready option and something to help me overcome my poor academic performance. Thank you,\u00a0any help would be greatly appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?auto=webp&amp;s=2c79ec2c452bb4d01df675d2a739bd47f221a670", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=108658d3e7925b2e114ce4a4c04d5f4e4295487d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9561ba20aaf47ba07975c9cc270feb3b83108d8a", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82e442618be3944d045e58fadd5034487d2d6642", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0afa3e8d4b806ab74b5d8d146baf8afd3fa7b37", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7fd653b4af836fe5c3f3e7ad731464fa007c47fb", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=070e674c45fe1ce071fffe889a90255b231bbe82", "width": 1080, "height": 564}], "variants": {}, "id": "t7A4BY9o-aX-XTyFjhKEkiEB0ueAqjclZI80A8Moy40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yla99d", "is_robot_indexable": true, "report_reasons": null, "author": "nolettuceandtomatoes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yla99d/should_i_take_the_365ds_data_analyst_career_track/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yla99d/should_i_take_the_365ds_data_analyst_career_track/", "subreddit_subscribers": 817163, "created_utc": 1667499608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nThe emergence of data science as a field of study and practical application over the last century has resulted in the development of technologies such as deep learning, NLP, and computer vision. In general, it has facilitated the emergence of machine learning (ML) as a method of working towards artificial intelligence (AI), a field of technology that is rapidly transforming the way we work and live.\n\nBig Data, predictive analytics, and **artificial intelligence** are examples of data science concepts with both theoretical and practical applications. If data is the information age's oil and machine learning is the engine, then data science is the digital domain's equivalent of the physical laws that cause combustion and pistons to move.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/xgnapf500xx91.png?width=1920&amp;format=png&amp;auto=webp&amp;s=2a2c93d9a6703e6e8d25e17a5ccd22dd01dfbb1e\n\n# Data Science Trends \n\nA key point to remember is that as the importance of understanding how to work with data grows, so does the science behind it. It was considered a niche crossover subject straddling statistics, mathematics, and computing ten years ago and taught at several universities. Its significance in the world of business and commerce is well established today, and there are numerous paths, including online [**data science certification courses in Mumbai** ](https://www.learnbay.co/data-science-course-training-in-mumbai)and on-the-job training, that can equip us to apply these principles. This has resulted in the much-discussed \"democratization\" of data science, which will undoubtedly impact trends discussed in 2022 and beyond.\n\n* **TinyML and Small Data**\n\nBig Data refers to the rapid increase in the digital data we generate, collect, and analyze. But it's not just the data that's large; the ML algorithms we use to process it can also be quite large. GPT-3, the most complex and largest system capable of modeling human language, has approximately 175 billion parameters.\n\nThis is fine if you're working on cloud-based systems with unlimited bandwidth, but it is far from covering all the use cases where ML can add value. As a result, the concept of \"small data\" has emerged as a paradigm to facilitate rapid, cognitive analysis of the most critical data in situations where time, bandwidth, or energy expenditure are crucial. It is closely related to the idea of edge computing. When attempting to avoid a traffic collision in an emergency, self-driving cars, for example, cannot rely on being able to send and receive data from a centralized cloud server.\n\nTinyML refers to machine learning algorithms designed to take up as little space as possible to run on low-powered hardware near the action. By 2022, it will be found in many embedded systems, including wearables, home appliances, automobiles, industrial equipment, and agricultural machinery, making them more innovative and valuable.\n\nThis is about how businesses use our data to provide us with increasingly valuable, worthwhile, or enjoyable experiences. This could imply less friction and hassle in e-commerce, more user-friendly interfaces and front-ends in the software we use, or spending less time on hold and being transferred between departments when we contact customer service.\n\n* **Deepfakes, generative AI, and synthetic data are all examples of Artificial Intelligence**\n\nWhen terrifyingly realistic \"deep fake\" videos went viral this year, many of us were duped into thinking Tom Cruise had started posting on TikTok. The technology behind this is known as generative AI, and it aims to generate or create something that does not exist in reality, in this case, Tom Cruise regaling us with tales of meeting Mikhail Gorbachev. The arts and entertainment industries have quickly embraced generative AI, with Martin Scorsese de-aging Robert DeNiro in The Irishman and (spoiler alert) a young Mark Hamill appearing in The Mandalorian.\n\n* **Convergence**\n\nAI, the internet of things (IoT), cloud computing, and ultrafast networks such as 5G are the foundations of digital transformation, and data is the fuel that powers them all. All these technologies exist separately, but they can do much more when combined. Artificial intelligence enables IoT devices to act intelligently, interacting with one another with as little human intervention as possible, resulting in a wave of automation and the creation of smart homes, smart factories, and smart cities. 5G and other ultra-fast networks not only enable faster data transmission;\n\n* **AutoML**\n\nAcronym for \"automated machine learning.\" As stated in the introduction, AutoML is an exciting trend that hastened the \"democratization\" of data science. It is aimed at experts whose specialized knowledge and insights put them in an ideal position to develop solutions to the most pressing problems in their respective fields. However, they frequently need more coding knowledge to apply AI to those problems. AutoML solution developers hope to create tools and platforms that anyone can use to build their ML apps.\n\nA large portion of a data scientist's time is frequently spent on data cleansing and preparation - tasks that require data skills and are often repetitive and mundane. AutoML involves automating those tasks at its most basic, but it is increasingly also about developing models, algorithms, and neural networks. \n\nHope you enjoyed reading this article on top data science trends. Join the remarkable [**data science course in Mumbai**](https://www.learnbay.co/data-science-course-training-in-mumbai) to reinvent your career in this exciting field and land dream positions in  MAANG companies.", "author_fullname": "t2_t1dm3ojv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The 4 Popular Data Science Trends in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "media_metadata": {"xgnapf500xx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/xgnapf500xx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=789eee56161f40f3baee171e1eabcfcf6694eded"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/xgnapf500xx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d176a83abe1514e0a99f5215ede6244cdc8b6d79"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/xgnapf500xx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=632e2815c908d97a4f27810a891ec7031e10b464"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/xgnapf500xx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e3b44863a47916a13663be1ef590b5ede7a4f23"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/xgnapf500xx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=55f2b7f5bec2499b691c12cb67854ddac7c58c2a"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/xgnapf500xx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c97ce67f6b4010485760e1281b2534b0b0e6643"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/xgnapf500xx91.png?width=1920&amp;format=png&amp;auto=webp&amp;s=2a2c93d9a6703e6e8d25e17a5ccd22dd01dfbb1e"}, "id": "xgnapf500xx91"}}, "name": "t3_ylvm3o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oTo3pIty8ANsn7yNeQCNpJlV_vRw6yaSjUg5uD14GNI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667559182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The emergence of data science as a field of study and practical application over the last century has resulted in the development of technologies such as deep learning, NLP, and computer vision. In general, it has facilitated the emergence of machine learning (ML) as a method of working towards artificial intelligence (AI), a field of technology that is rapidly transforming the way we work and live.&lt;/p&gt;\n\n&lt;p&gt;Big Data, predictive analytics, and &lt;strong&gt;artificial intelligence&lt;/strong&gt; are examples of data science concepts with both theoretical and practical applications. If data is the information age&amp;#39;s oil and machine learning is the engine, then data science is the digital domain&amp;#39;s equivalent of the physical laws that cause combustion and pistons to move.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xgnapf500xx91.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a2c93d9a6703e6e8d25e17a5ccd22dd01dfbb1e\"&gt;https://preview.redd.it/xgnapf500xx91.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a2c93d9a6703e6e8d25e17a5ccd22dd01dfbb1e&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Data Science Trends&lt;/h1&gt;\n\n&lt;p&gt;A key point to remember is that as the importance of understanding how to work with data grows, so does the science behind it. It was considered a niche crossover subject straddling statistics, mathematics, and computing ten years ago and taught at several universities. Its significance in the world of business and commerce is well established today, and there are numerous paths, including online &lt;a href=\"https://www.learnbay.co/data-science-course-training-in-mumbai\"&gt;&lt;strong&gt;data science certification courses in Mumbai&lt;/strong&gt; &lt;/a&gt;and on-the-job training, that can equip us to apply these principles. This has resulted in the much-discussed &amp;quot;democratization&amp;quot; of data science, which will undoubtedly impact trends discussed in 2022 and beyond.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;TinyML and Small Data&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Big Data refers to the rapid increase in the digital data we generate, collect, and analyze. But it&amp;#39;s not just the data that&amp;#39;s large; the ML algorithms we use to process it can also be quite large. GPT-3, the most complex and largest system capable of modeling human language, has approximately 175 billion parameters.&lt;/p&gt;\n\n&lt;p&gt;This is fine if you&amp;#39;re working on cloud-based systems with unlimited bandwidth, but it is far from covering all the use cases where ML can add value. As a result, the concept of &amp;quot;small data&amp;quot; has emerged as a paradigm to facilitate rapid, cognitive analysis of the most critical data in situations where time, bandwidth, or energy expenditure are crucial. It is closely related to the idea of edge computing. When attempting to avoid a traffic collision in an emergency, self-driving cars, for example, cannot rely on being able to send and receive data from a centralized cloud server.&lt;/p&gt;\n\n&lt;p&gt;TinyML refers to machine learning algorithms designed to take up as little space as possible to run on low-powered hardware near the action. By 2022, it will be found in many embedded systems, including wearables, home appliances, automobiles, industrial equipment, and agricultural machinery, making them more innovative and valuable.&lt;/p&gt;\n\n&lt;p&gt;This is about how businesses use our data to provide us with increasingly valuable, worthwhile, or enjoyable experiences. This could imply less friction and hassle in e-commerce, more user-friendly interfaces and front-ends in the software we use, or spending less time on hold and being transferred between departments when we contact customer service.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Deepfakes, generative AI, and synthetic data are all examples of Artificial Intelligence&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;When terrifyingly realistic &amp;quot;deep fake&amp;quot; videos went viral this year, many of us were duped into thinking Tom Cruise had started posting on TikTok. The technology behind this is known as generative AI, and it aims to generate or create something that does not exist in reality, in this case, Tom Cruise regaling us with tales of meeting Mikhail Gorbachev. The arts and entertainment industries have quickly embraced generative AI, with Martin Scorsese de-aging Robert DeNiro in The Irishman and (spoiler alert) a young Mark Hamill appearing in The Mandalorian.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;AI, the internet of things (IoT), cloud computing, and ultrafast networks such as 5G are the foundations of digital transformation, and data is the fuel that powers them all. All these technologies exist separately, but they can do much more when combined. Artificial intelligence enables IoT devices to act intelligently, interacting with one another with as little human intervention as possible, resulting in a wave of automation and the creation of smart homes, smart factories, and smart cities. 5G and other ultra-fast networks not only enable faster data transmission;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;AutoML&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Acronym for &amp;quot;automated machine learning.&amp;quot; As stated in the introduction, AutoML is an exciting trend that hastened the &amp;quot;democratization&amp;quot; of data science. It is aimed at experts whose specialized knowledge and insights put them in an ideal position to develop solutions to the most pressing problems in their respective fields. However, they frequently need more coding knowledge to apply AI to those problems. AutoML solution developers hope to create tools and platforms that anyone can use to build their ML apps.&lt;/p&gt;\n\n&lt;p&gt;A large portion of a data scientist&amp;#39;s time is frequently spent on data cleansing and preparation - tasks that require data skills and are often repetitive and mundane. AutoML involves automating those tasks at its most basic, but it is increasingly also about developing models, algorithms, and neural networks. &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoyed reading this article on top data science trends. Join the remarkable &lt;a href=\"https://www.learnbay.co/data-science-course-training-in-mumbai\"&gt;&lt;strong&gt;data science course in Mumbai&lt;/strong&gt;&lt;/a&gt; to reinvent your career in this exciting field and land dream positions in  MAANG companies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylvm3o", "is_robot_indexable": true, "report_reasons": null, "author": "Important-Drop-5766", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylvm3o/the_4_popular_data_science_trends_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylvm3o/the_4_popular_data_science_trends_in_2022/", "subreddit_subscribers": 817163, "created_utc": 1667559182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "365 Data Science is offering all their course and exams for free for three weeks! I am already on my second course and loving it! It's the duolingo of data science learning. [https://365datascience.com/free-days-2022/](https://365datascience.com/free-days-2022/)\n\nhttps://preview.redd.it/sqljtn2kowx91.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=68a634d0a8686660df0478293b709e712c8e6358", "author_fullname": "t2_tyorn1da", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Data Science Courses Until November 21", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"sqljtn2kowx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b278e083e1e1958728d0a24f6035ef7119ad42d9"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13a883416b295f30f6c6d29370cc83638932e81e"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d52e37e893a430b53e189efbf9a1284b9ae247cf"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e0fbc066b8af4c74b1002e72371069c5fa8ca5e"}, {"y": 960, "x": 960, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bb61b555eeeffc50de8edfb8203f35e3e70e1181"}, {"y": 1080, "x": 1080, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dfdd178c78851b9cc96df015e397ae1a1c3bafe5"}], "s": {"y": 1200, "x": 1200, "u": "https://preview.redd.it/sqljtn2kowx91.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=68a634d0a8686660df0478293b709e712c8e6358"}, "id": "sqljtn2kowx91"}}, "name": "t3_ylu9mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_qeXAUe4Cxt4UApFIBODBWsarhTQJEOTbQQgNqKReYM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667555282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;365 Data Science is offering all their course and exams for free for three weeks! I am already on my second course and loving it! It&amp;#39;s the duolingo of data science learning. &lt;a href=\"https://365datascience.com/free-days-2022/\"&gt;https://365datascience.com/free-days-2022/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sqljtn2kowx91.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=68a634d0a8686660df0478293b709e712c8e6358\"&gt;https://preview.redd.it/sqljtn2kowx91.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=68a634d0a8686660df0478293b709e712c8e6358&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylu9mz", "is_robot_indexable": true, "report_reasons": null, "author": "hauntedmind9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylu9mz/free_data_science_courses_until_november_21/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylu9mz/free_data_science_courses_until_november_21/", "subreddit_subscribers": 817163, "created_utc": 1667555282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For you people who already studied in 365datascience... Is it worth the time?", "author_fullname": "t2_t6iqoxd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is 365datascience good enough for entry level job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylpebt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667538130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For you people who already studied in 365datascience... Is it worth the time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylpebt", "is_robot_indexable": true, "report_reasons": null, "author": "mbrtlchouia", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylpebt/is_365datascience_good_enough_for_entry_level_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylpebt/is_365datascience_good_enough_for_entry_level_job/", "subreddit_subscribers": 817163, "created_utc": 1667538130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8mgpbrkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping a car listing website - got the mileage and price of each car!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_ylj4ja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "My First Web Scraping Project", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "author_name": "CarlNx lvl", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xOKYxTHCKfQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCntYZbcwlB3MinNQvNv4dKw"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ylj4ja", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yRx1jfwiiU3arvw1prR7rYSionsX_QwSu94jyTddpW8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667519916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xOKYxTHCKfQ", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?auto=webp&amp;s=188a66b99d92bafa886f36f634f4c7888acc9963", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2672e6fc462836531eadde12e650cab524d15856", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=278d7b4bb9e8e151a3bc51e98fafe97aa1e2a98f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/MTjUXIcRuUZKeE8OzylB8sW2jdoiNOa6hYnAStFW_Cs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a10ac08fc629ca110efba96919c73d49a6cc7e3a", "width": 320, "height": 240}], "variants": {}, "id": "pLzfhouXMAx36Fj97I6GwgSwkYUdQHzB5Ndgruj1_wQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylj4ja", "is_robot_indexable": true, "report_reasons": null, "author": "carlnx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylj4ja/scraping_a_car_listing_website_got_the_mileage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xOKYxTHCKfQ", "subreddit_subscribers": 817163, "created_utc": 1667519916.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "My First Web Scraping Project", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xOKYxTHCKfQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"My First Web Scraping Project\"&gt;&lt;/iframe&gt;", "author_name": "CarlNx lvl", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xOKYxTHCKfQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/channel/UCntYZbcwlB3MinNQvNv4dKw"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are looking for such platform and I am trying to see what others think of these products or what else is out there ?", "author_fullname": "t2_he02w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone evaluated third party platforms such as panalgo or aetion or other ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylj3nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667519852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are looking for such platform and I am trying to see what others think of these products or what else is out there ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylj3nj", "is_robot_indexable": true, "report_reasons": null, "author": "Vervain7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylj3nj/has_anyone_evaluated_third_party_platforms_such/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylj3nj/has_anyone_evaluated_third_party_platforms_such/", "subreddit_subscribers": 817163, "created_utc": 1667519852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello friends!\n\nI'm trying to build a book similarity model to evaluate how similar two books are. I have multiple text fields such as:\n\n* title\n* author\n* subject\n* description (long text)\n* table of content (long text)\n\nUntil now I was concatenating everything into one string and producing one TF-IDF vector for each book. Then I was simply running cosine similarity.\n\nNow I came to realize some features are more important than others. For example title similarity is more important than subject similarity, but I don't know how to incorporate that into the model. I was thinking of constructing a TF-IDF vector for each column and then calculating similarities separately, then weighting the similarity scores themselves. Is there a better way to achieve this?\n\nThank you!", "author_fullname": "t2_286kcv5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple Text Features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylhg0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667515967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to build a book similarity model to evaluate how similar two books are. I have multiple text fields such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;title&lt;/li&gt;\n&lt;li&gt;author&lt;/li&gt;\n&lt;li&gt;subject&lt;/li&gt;\n&lt;li&gt;description (long text)&lt;/li&gt;\n&lt;li&gt;table of content (long text)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Until now I was concatenating everything into one string and producing one TF-IDF vector for each book. Then I was simply running cosine similarity.&lt;/p&gt;\n\n&lt;p&gt;Now I came to realize some features are more important than others. For example title similarity is more important than subject similarity, but I don&amp;#39;t know how to incorporate that into the model. I was thinking of constructing a TF-IDF vector for each column and then calculating similarities separately, then weighting the similarity scores themselves. Is there a better way to achieve this?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylhg0b", "is_robot_indexable": true, "report_reasons": null, "author": "thecrixus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylhg0b/multiple_text_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylhg0b/multiple_text_features/", "subreddit_subscribers": 817163, "created_utc": 1667515967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey just wondering if anyone has some good resources to dive deep into quantitative analytics(books, websites, videos, etc.)", "author_fullname": "t2_9mx4u3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best resources for quantitative analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylhcsv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667515795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey just wondering if anyone has some good resources to dive deep into quantitative analytics(books, websites, videos, etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylhcsv", "is_robot_indexable": true, "report_reasons": null, "author": "Vnix7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylhcsv/best_resources_for_quantitative_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylhcsv/best_resources_for_quantitative_analytics/", "subreddit_subscribers": 817163, "created_utc": 1667515795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everybody\n\nA long time ago I came here asking for guidance on the world of data from there to here I've been improving and practicing, without belting the internships. That's why I'm coming back here looking for an international opportunity (Especially with the instability that Brazil and Latin America are experiencing), any help is welcome and whatever I can help just call, I'm here to network.\n\n[Linkedin](https://www.linkedin.com/in/matheussbrandao/?locale=en_US)", "author_fullname": "t2_3bymdoy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an international network and guidance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylf3m2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667509839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody&lt;/p&gt;\n\n&lt;p&gt;A long time ago I came here asking for guidance on the world of data from there to here I&amp;#39;ve been improving and practicing, without belting the internships. That&amp;#39;s why I&amp;#39;m coming back here looking for an international opportunity (Especially with the instability that Brazil and Latin America are experiencing), any help is welcome and whatever I can help just call, I&amp;#39;m here to network.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/in/matheussbrandao/?locale=en_US\"&gt;Linkedin&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylf3m2", "is_robot_indexable": true, "report_reasons": null, "author": "mathsugar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylf3m2/looking_for_an_international_network_and_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylf3m2/looking_for_an_international_network_and_guidance/", "subreddit_subscribers": 817163, "created_utc": 1667509839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm trying to reverse engineer in my mind the process of returning summary statistics for a large dataset very quickly. I am thinking for example, returning data to a front end to create some charts on a webpage.\n\nLet's say we have a database recording the results of 20,000 matches of a game. The matches have all sorts of data, for example damage done by a certain spell every 10 seconds. It's a lot of data.\n\nWe now want to return the total damage of the spell, \"fireball\", throughout all of the matches. A silly approach would be, every time a user visits a webpage, sum across all 20,000 matches find where spell = \"fireball\" and sum up each damage bit to get the total. This computation would take time regardless of overpaying for high levels of computational power.\n\nWhat I would consider doing in this case is create a new statistics portion of the database. It would include total damage for fireball. Each time you would finish a match, or at another time interval, you would simply add the damage to the total.\n\nWhen you want your statistics, you simply ping the fireball statistics and return the data. I think that this would work great because it would put minor computation requirements on your server frequently rather than massive computation whenever a user wants his stats.\n\nA problem comes up with this approach, what if you needed to report more complex statistics that you can't simply add to every time? If you wanted 95th quartile, or median, you would need to go through every game session and get yourself the entire series (let's call this a full database scan).\n\n**My question:** What sorts of approaches in data management are given for computing up to date complex statistics over large data sets? Would it be a batched process where we are not doing a full database scan every match, but perhaps every 500 matches? Is there any reading I can do to understand these types data/database management practices?", "author_fullname": "t2_4xizssma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serving Complex Statistics from Large Databases as Quickly As Possible", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylewcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667509424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to reverse engineer in my mind the process of returning summary statistics for a large dataset very quickly. I am thinking for example, returning data to a front end to create some charts on a webpage.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we have a database recording the results of 20,000 matches of a game. The matches have all sorts of data, for example damage done by a certain spell every 10 seconds. It&amp;#39;s a lot of data.&lt;/p&gt;\n\n&lt;p&gt;We now want to return the total damage of the spell, &amp;quot;fireball&amp;quot;, throughout all of the matches. A silly approach would be, every time a user visits a webpage, sum across all 20,000 matches find where spell = &amp;quot;fireball&amp;quot; and sum up each damage bit to get the total. This computation would take time regardless of overpaying for high levels of computational power.&lt;/p&gt;\n\n&lt;p&gt;What I would consider doing in this case is create a new statistics portion of the database. It would include total damage for fireball. Each time you would finish a match, or at another time interval, you would simply add the damage to the total.&lt;/p&gt;\n\n&lt;p&gt;When you want your statistics, you simply ping the fireball statistics and return the data. I think that this would work great because it would put minor computation requirements on your server frequently rather than massive computation whenever a user wants his stats.&lt;/p&gt;\n\n&lt;p&gt;A problem comes up with this approach, what if you needed to report more complex statistics that you can&amp;#39;t simply add to every time? If you wanted 95th quartile, or median, you would need to go through every game session and get yourself the entire series (let&amp;#39;s call this a full database scan).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My question:&lt;/strong&gt; What sorts of approaches in data management are given for computing up to date complex statistics over large data sets? Would it be a batched process where we are not doing a full database scan every match, but perhaps every 500 matches? Is there any reading I can do to understand these types data/database management practices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ylewcw", "is_robot_indexable": true, "report_reasons": null, "author": "gunnerydota", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ylewcw/serving_complex_statistics_from_large_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ylewcw/serving_complex_statistics_from_large_databases/", "subreddit_subscribers": 817163, "created_utc": 1667509424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I worked on the project and practically built everything from ground up however after a few months the team needs me to help answer questions on a portion  my teammates worked on. I am familiar with the whole process so I am the only one who knows time-series since the other than a DS is on maternity leave.\n\nI asked for part time during my studies and full time but they didn\u2019t give me anything and half assed any attempted to give me a job. However now that they are struggling they are asking for free consultations. \n\nthey put a new kid on the project but still do not have people qualified or knowledgeable enough to maintain and uphold the quality. So i am worried they would expect me to train their employees for free without them offering anything in return.\n\nNote: i put everything properly on documentation as well as how to trouble shoot potential problems.", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project manager reached out to me for help to answer questions on deployment after the end of my internship.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl8gmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667495827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I worked on the project and practically built everything from ground up however after a few months the team needs me to help answer questions on a portion  my teammates worked on. I am familiar with the whole process so I am the only one who knows time-series since the other than a DS is on maternity leave.&lt;/p&gt;\n\n&lt;p&gt;I asked for part time during my studies and full time but they didn\u2019t give me anything and half assed any attempted to give me a job. However now that they are struggling they are asking for free consultations. &lt;/p&gt;\n\n&lt;p&gt;they put a new kid on the project but still do not have people qualified or knowledgeable enough to maintain and uphold the quality. So i am worried they would expect me to train their employees for free without them offering anything in return.&lt;/p&gt;\n\n&lt;p&gt;Note: i put everything properly on documentation as well as how to trouble shoot potential problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl8gmi", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl8gmi/project_manager_reached_out_to_me_for_help_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl8gmi/project_manager_reached_out_to_me_for_help_to/", "subreddit_subscribers": 817163, "created_utc": 1667495827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Fundamentals of Data Engineering by Joe Reis and Matthew Housley.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl6qnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mh2cfxap", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Fundamentals of Data Engineering](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302) has received a lot of good reviews in the data world, and I\u2019ve been meaning to read it.Turns out lots of folks have been meaning to read it too, so I put together a book club!\n\nI'm not being paid to promote this book in any way, shape, or form. I have no business affiliation with the authors. I just want to read it in a book club.**Here\u2019s a brief overview of the book club:**\\- All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.**Schedule:**\n\n* [**November 18th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-11&amp;date=2022-11-18)**:** Discuss Chapters 1-3\n* [**December 2nd**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-02)**:** Discuss Chapters 4-7\n* [**December 8th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-08)**:** Live AMA with Joe Reis, the author\n* [**December 16th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-16)**:** Discuss Chapters 8-11\n\nWe currently have 20+ people participating!If this sounds interesting to you, find additional details and schedule [here](https://calendly.com/jparkerrogers/oa-book-club?month=2022-11).", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Fundamentals of Data Engineering by Joe Reis and Matthew Housley.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykbcfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 162, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 162, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667434000.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667410085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302\"&gt;Fundamentals of Data Engineering&lt;/a&gt; has received a lot of good reviews in the data world, and I\u2019ve been meaning to read it.Turns out lots of folks have been meaning to read it too, so I put together a book club!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not being paid to promote this book in any way, shape, or form. I have no business affiliation with the authors. I just want to read it in a book club.&lt;strong&gt;Here\u2019s a brief overview of the book club:&lt;/strong&gt;- All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.&lt;strong&gt;Schedule:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-11&amp;amp;date=2022-11-18\"&gt;&lt;strong&gt;November 18th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 1-3&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-02\"&gt;&lt;strong&gt;December 2nd&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 4-7&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-08\"&gt;&lt;strong&gt;December 8th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Live AMA with Joe Reis, the author&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-16\"&gt;&lt;strong&gt;December 16th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 8-11&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We currently have 20+ people participating!If this sounds interesting to you, find additional details and schedule &lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-11\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ykbcfo", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "subreddit_subscribers": 78876, "created_utc": 1667410085.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1667491606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl6qnq", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ykbcfo", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl6qnq/book_club_fundamentals_of_data_engineering_by_joe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "subreddit_subscribers": 817163, "created_utc": 1667491606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m not sure exactly how to phrase this. Professional DS with 15 years experience. I have no problems doing everything locally or on a web server if someone sets one up for me. For example, my company has a process to deploy Python scripts via restful API. The engineer taught me how to deploy what in need but when something breaks I am lost. How would I learn to fix bugs or setup my own type of service? Another issue. Someone is sending me a huge data file across a subnet at 5MB per second. Often the job fails. I would like to try to fix this. How do I learn about this. I don\u2019t even know what it\u2019s called. I\u2019m tired of waiting on other people to solve my problems.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources for architecture and networks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1w7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667479497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not sure exactly how to phrase this. Professional DS with 15 years experience. I have no problems doing everything locally or on a web server if someone sets one up for me. For example, my company has a process to deploy Python scripts via restful API. The engineer taught me how to deploy what in need but when something breaks I am lost. How would I learn to fix bugs or setup my own type of service? Another issue. Someone is sending me a huge data file across a subnet at 5MB per second. Often the job fails. I would like to try to fix this. How do I learn about this. I don\u2019t even know what it\u2019s called. I\u2019m tired of waiting on other people to solve my problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl1w7d", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl1w7d/good_resources_for_architecture_and_networks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl1w7d/good_resources_for_architecture_and_networks/", "subreddit_subscribers": 817163, "created_utc": 1667479497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm finding parallelising an r task (which basically means assigning work to a separate r session) requires all data in my environment to be copied over to the cache of the new core. If I'm working with just 10gb of data, my machine is losing more time copying data than it's saving by parallelising. This means I can't even split up CV tasks on windows, which should be trivial to parallelise.\n\nIs there an obvious alternative to this approach? And am I right in saying running on Linux would avoid this bottleneck?", "author_fullname": "t2_1rwftqt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does lack of fork parallelisation make windows an impractical OS for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl10to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667477285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finding parallelising an r task (which basically means assigning work to a separate r session) requires all data in my environment to be copied over to the cache of the new core. If I&amp;#39;m working with just 10gb of data, my machine is losing more time copying data than it&amp;#39;s saving by parallelising. This means I can&amp;#39;t even split up CV tasks on windows, which should be trivial to parallelise.&lt;/p&gt;\n\n&lt;p&gt;Is there an obvious alternative to this approach? And am I right in saying running on Linux would avoid this bottleneck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl10to", "is_robot_indexable": true, "report_reasons": null, "author": "theAbominablySlowMan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl10to/does_lack_of_fork_parallelisation_make_windows_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl10to/does_lack_of_fork_parallelisation_make_windows_an/", "subreddit_subscribers": 817163, "created_utc": 1667477285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_80wts4h1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I'm applying for Data Science full-time graduate roles for Summer/Fall 2023 start. I'm getting through the initial screen for SWE roles, but not for DS. I want to do DS, but expanded my search to SWE since I'm not getting interviews. What's wrong with my resume? TIA!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"q7vzrd2d2wx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28cd505afdfbfc763d9d2f6093f4df91b5738677"}, {"y": 278, "x": 216, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=65e0e35fa3408471fbf3083df656c2642052e337"}, {"y": 412, "x": 320, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3906e01657ee70afcf1e2020cdb9a69b131e6e0b"}, {"y": 825, "x": 640, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8da9b77d1e9165471bed1f7d416d70cd10f07db7"}, {"y": 1238, "x": 960, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=191bc16e83ab4227fe250c9cb3ac0a5ccaa3f074"}, {"y": 1393, "x": 1080, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd7d3850f64267c1c40ce2db9e6d177ac95fb6a9"}], "s": {"y": 1414, "x": 1096, "u": "https://preview.redd.it/q7vzrd2d2wx91.png?width=1096&amp;format=png&amp;auto=webp&amp;s=ac573fcd725bb142b4d534cd93a48867c0b2f436"}, "id": "q7vzrd2d2wx91"}, "p2z56zsc2wx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8aca13c0831e6d8bc18ac334f4d2583c2fe8a2d5"}, {"y": 278, "x": 216, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3dc5d8dd58367cf7e7499a5d12cede643b6373b"}, {"y": 413, "x": 320, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c088841a0730a4210c48721913aedeedb3371c35"}, {"y": 826, "x": 640, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=144586176c5b20eb0ae50f248da07494c4c4ca3d"}, {"y": 1239, "x": 960, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=51f8670e91a8a36b78c84d775fd9a42d50575fb1"}, {"y": 1394, "x": 1080, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94ab1c8b0c6bddb552b660a44c1e96f409a45ec2"}], "s": {"y": 1410, "x": 1092, "u": "https://preview.redd.it/p2z56zsc2wx91.png?width=1092&amp;format=png&amp;auto=webp&amp;s=c4ae9b75b8cf50adaec449cf708e1807d49fb887"}, "id": "p2z56zsc2wx91"}}, "name": "t3_yls2jd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "resume-p1", "media_id": "q7vzrd2d2wx91", "id": 205330261}, {"caption": "resume-p2", "media_id": "p2z56zsc2wx91", "id": 205330262}]}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DmJOeKJ-K65ggtu8hYjsX_z50teLgvnu7KThSs7NKOc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667547967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yls2jd", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yls2jd", "is_robot_indexable": true, "report_reasons": null, "author": "okbutfirst_coffee", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yls2jd/im_applying_for_data_science_fulltime_graduate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yls2jd", "subreddit_subscribers": 817163, "created_utc": 1667547967.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}