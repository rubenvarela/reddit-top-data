{"kind": "Listing", "data": {"after": "t3_ylk7nv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Howdy guys, we're a small team working on an API that helps users access, filter, and fuse (e.g. interpolate on-demand) large multidimensional geospatial datasets with minimal setup on the cloud. Practically, this means users can accelerate data engineering/ETL, and incorporate more data variety and volume into their models, all without breaking the bank. It's also well-designed for people who have never worked with this kind of data before. \n\nYou can learn more on our [website](https://pharossoftware.com/) \n\nAnyways, the data we're working with (weather, remote sensing) is quite applicable to crop intel, energy modeling, and more. And I'd love to connect with folks in the industry so we can learn more about your needs, pain points. I can't offer much other than lots of free credits and hopefully a fun conversation about a very cutting-edge space!\n\nComment here or DM me if interested! Thanks :)", "author_fullname": "t2_nx2zqyff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any folks doing data engineering in the agriculture or energy space?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylebcr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667508225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy guys, we&amp;#39;re a small team working on an API that helps users access, filter, and fuse (e.g. interpolate on-demand) large multidimensional geospatial datasets with minimal setup on the cloud. Practically, this means users can accelerate data engineering/ETL, and incorporate more data variety and volume into their models, all without breaking the bank. It&amp;#39;s also well-designed for people who have never worked with this kind of data before. &lt;/p&gt;\n\n&lt;p&gt;You can learn more on our &lt;a href=\"https://pharossoftware.com/\"&gt;website&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Anyways, the data we&amp;#39;re working with (weather, remote sensing) is quite applicable to crop intel, energy modeling, and more. And I&amp;#39;d love to connect with folks in the industry so we can learn more about your needs, pain points. I can&amp;#39;t offer much other than lots of free credits and hopefully a fun conversation about a very cutting-edge space!&lt;/p&gt;\n\n&lt;p&gt;Comment here or DM me if interested! Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ylebcr", "is_robot_indexable": true, "report_reasons": null, "author": "mightylighthouse", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylebcr/any_folks_doing_data_engineering_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylebcr/any_folks_doing_data_engineering_in_the/", "subreddit_subscribers": 78861, "created_utc": 1667508225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If I've got a REST endpoint that I want to poll for data periodically and load into an object store or Cloud DW, what's an idiomatic way nowadays to do this? \n\nI've seen FiveTran et al for pulling from predefined APIs on SaaS etc, but for bespoke endpoints is there a tool or common pattern? Or do I just write some Python or bash and stick it under a crontab? \n\nAn example of the kind of endpoint I have in mind is [this one](http://environment.data.gov.uk/flood-monitoring/id/stations/L2404) from the [UK Environment Agency](http://environment.data.gov.uk/flood-monitoring/doc/reference#api-summary)\n\nTIA!", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool/technique do you use for polling data from a REST source and loading it into object store/cloud DW?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykznde", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667474035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I&amp;#39;ve got a REST endpoint that I want to poll for data periodically and load into an object store or Cloud DW, what&amp;#39;s an idiomatic way nowadays to do this? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen FiveTran et al for pulling from predefined APIs on SaaS etc, but for bespoke endpoints is there a tool or common pattern? Or do I just write some Python or bash and stick it under a crontab? &lt;/p&gt;\n\n&lt;p&gt;An example of the kind of endpoint I have in mind is &lt;a href=\"http://environment.data.gov.uk/flood-monitoring/id/stations/L2404\"&gt;this one&lt;/a&gt; from the &lt;a href=\"http://environment.data.gov.uk/flood-monitoring/doc/reference#api-summary\"&gt;UK Environment Agency&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ykznde", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ykznde/what_tooltechnique_do_you_use_for_polling_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ykznde/what_tooltechnique_do_you_use_for_polling_data/", "subreddit_subscribers": 78861, "created_utc": 1667474035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_pool46q", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "How we've implemented our RBAC on Snowflake with Permifrost at Yousign", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_yl2cay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 21, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/BtKJDFBDV9-_zcU7J15dt6mmgwelJ8dCRui2zOAxI3Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667480694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/yousign-engineering-product/snowflake-rbac-implementation-with-permifrost-3d30652825ad", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ioTe1Fh_dhzIODnzvIEBpnpr_G-5rSI0Sc1Xy3ivhBo.jpg?auto=webp&amp;s=0d59ae22afa4cd68ec5e6feb4467b6ebb656fc00", "width": 959, "height": 584}, "resolutions": [{"url": "https://external-preview.redd.it/ioTe1Fh_dhzIODnzvIEBpnpr_G-5rSI0Sc1Xy3ivhBo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e4dcab6c4ab770cb4106d086e8bc5b5720a7250c", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/ioTe1Fh_dhzIODnzvIEBpnpr_G-5rSI0Sc1Xy3ivhBo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0333e06b66889f8a9e70544c18a38c6fc60c9179", "width": 216, "height": 131}, {"url": "https://external-preview.redd.it/ioTe1Fh_dhzIODnzvIEBpnpr_G-5rSI0Sc1Xy3ivhBo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d521dc073668691ef29843753a0627740de8221f", "width": 320, "height": 194}, {"url": "https://external-preview.redd.it/ioTe1Fh_dhzIODnzvIEBpnpr_G-5rSI0Sc1Xy3ivhBo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=547f33e801023c8adf6bb4323c7ec60744bf20ff", "width": 640, "height": 389}], "variants": {}, "id": "HV-KF7WRfPSIXcv-A2GWzA9HIqGkfqa2fwWWXMbrCes"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yl2cay", "is_robot_indexable": true, "report_reasons": null, "author": "parudod", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl2cay/how_weve_implemented_our_rbac_on_snowflake_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/yousign-engineering-product/snowflake-rbac-implementation-with-permifrost-3d30652825ad", "subreddit_subscribers": 78861, "created_utc": 1667480694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to understand if this tech is still relevant and who/why you'd actually use it", "author_fullname": "t2_10ixfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What actually is master data management and what do MDM tools do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1r8m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667479106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand if this tech is still relevant and who/why you&amp;#39;d actually use it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yl1r8m", "is_robot_indexable": true, "report_reasons": null, "author": "realtrevorfaux", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl1r8m/what_actually_is_master_data_management_and_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl1r8m/what_actually_is_master_data_management_and_what/", "subreddit_subscribers": 78861, "created_utc": 1667479106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see that there is not much discussion around ensuring proper reliability/error handling for Kafka consumers. Here's the link to the blog post which deep dives into this topic.  There are some parts which are relevant only to Go programmers but we tried to keep the blog post as generic as possible to help people understand this pattern :)\n\n[https://medium.com/opendoor-labs/how-we-improved-reliability-of-kafka-consumers-441ccec1416d](https://medium.com/opendoor-labs/how-we-improved-reliability-of-kafka-consumers-441ccec1416d)", "author_fullname": "t2_5arv7drp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka consumer reliability with multithreading", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl35yi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667482860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see that there is not much discussion around ensuring proper reliability/error handling for Kafka consumers. Here&amp;#39;s the link to the blog post which deep dives into this topic.  There are some parts which are relevant only to Go programmers but we tried to keep the blog post as generic as possible to help people understand this pattern :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/opendoor-labs/how-we-improved-reliability-of-kafka-consumers-441ccec1416d\"&gt;https://medium.com/opendoor-labs/how-we-improved-reliability-of-kafka-consumers-441ccec1416d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V1ZrGHUi0gsVi1mF4XibNu9XFn3oTOOuFj2w63XxURA.jpg?auto=webp&amp;s=8d16fb296ec484ae0c7a8400244fbef6439f28f2", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/V1ZrGHUi0gsVi1mF4XibNu9XFn3oTOOuFj2w63XxURA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=19922e7691c905df1a389e73bb43448d3a289bb0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/V1ZrGHUi0gsVi1mF4XibNu9XFn3oTOOuFj2w63XxURA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=22fa8d4a3838500916c344c860ecfbe1825b51bd", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/V1ZrGHUi0gsVi1mF4XibNu9XFn3oTOOuFj2w63XxURA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82cb8193584241a04f883ba23d087fd6e14356cd", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/V1ZrGHUi0gsVi1mF4XibNu9XFn3oTOOuFj2w63XxURA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a693a3f035aef50bc8549dc2d157b7f20d293df", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/V1ZrGHUi0gsVi1mF4XibNu9XFn3oTOOuFj2w63XxURA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d38a1f47bc7a7736b41314b2b66683458fb7b5b", "width": 960, "height": 480}], "variants": {}, "id": "uY9J9rUK_nGiSZgwu-NvA3oQ1cWYDuEhEIKSygIpdZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yl35yi", "is_robot_indexable": true, "report_reasons": null, "author": "bitsplease101", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl35yi/kafka_consumer_reliability_with_multithreading/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl35yi/kafka_consumer_reliability_with_multithreading/", "subreddit_subscribers": 78861, "created_utc": 1667482860.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey people. I have difficulty delimiting the field of Data Engineering. I frequently see certification limited to a certain cloud platform, yet the job market announces jobs for \"Data Engineer\" as is. Does that mean there are two types, platform specific data engineers and generic ones? Thanks!", "author_fullname": "t2_7qlvsbrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Types of Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl2d5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667480754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey people. I have difficulty delimiting the field of Data Engineering. I frequently see certification limited to a certain cloud platform, yet the job market announces jobs for &amp;quot;Data Engineer&amp;quot; as is. Does that mean there are two types, platform specific data engineers and generic ones? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yl2d5n", "is_robot_indexable": true, "report_reasons": null, "author": "Imaginary-Style-5796", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl2d5n/types_of_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl2d5n/types_of_data_engineers/", "subreddit_subscribers": 78861, "created_utc": 1667480754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, Transitioning from Data Analytics into Data Engineering but I\u2019m doing some DE work as a Data Analyst intern it seems. I am going to be be assisting using SSIS and doing some azure work in the future here but what I\u2019ve been doing a lot of was going into the Power Query editor through PBI desktop and cleaning data and making it more accessible there.\n\n I was wondering, would this be considered valuable ETL experience from an employer\u2019s perspective? I know this may be a stupid question but I just want to know what I should prioritize putting on my resume when it comes time I move up into a full on DE job (I\u2019m a current CS major btw)", "author_fullname": "t2_55fytx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worth putting ETL work with PowerQuery on resume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1tu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667479604.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667479313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, Transitioning from Data Analytics into Data Engineering but I\u2019m doing some DE work as a Data Analyst intern it seems. I am going to be be assisting using SSIS and doing some azure work in the future here but what I\u2019ve been doing a lot of was going into the Power Query editor through PBI desktop and cleaning data and making it more accessible there.&lt;/p&gt;\n\n&lt;p&gt;I was wondering, would this be considered valuable ETL experience from an employer\u2019s perspective? I know this may be a stupid question but I just want to know what I should prioritize putting on my resume when it comes time I move up into a full on DE job (I\u2019m a current CS major btw)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yl1tu8", "is_robot_indexable": true, "report_reasons": null, "author": "ToothPickLegs", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl1tu8/worth_putting_etl_work_with_powerquery_on_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl1tu8/worth_putting_etl_work_with_powerquery_on_resume/", "subreddit_subscribers": 78861, "created_utc": 1667479313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone! I am a civil engineer but I switched to this profession because I found it more interesting than what I studied before, also it is paid much better. For the past few months I\u2019ve been learning Power BI, SQL, Python, etc, all the things that everyone recommends to this kind of job, but I would like to get into a Master\u2019s Degree in any country that fits best for this kind of studies, I wonder if anyone has a recommendation for me to choose? I\u2019ve been watching videos on YouTube but none of them really express the kind of answer I am looking for.\n\nThanks for you help!", "author_fullname": "t2_ngtjo999", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best country/university to study a master\u2019s degree in the data field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl92mf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667497217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I am a civil engineer but I switched to this profession because I found it more interesting than what I studied before, also it is paid much better. For the past few months I\u2019ve been learning Power BI, SQL, Python, etc, all the things that everyone recommends to this kind of job, but I would like to get into a Master\u2019s Degree in any country that fits best for this kind of studies, I wonder if anyone has a recommendation for me to choose? I\u2019ve been watching videos on YouTube but none of them really express the kind of answer I am looking for.&lt;/p&gt;\n\n&lt;p&gt;Thanks for you help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yl92mf", "is_robot_indexable": true, "report_reasons": null, "author": "sergionicolas28", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl92mf/whats_the_best_countryuniversity_to_study_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl92mf/whats_the_best_countryuniversity_to_study_a/", "subreddit_subscribers": 78861, "created_utc": 1667497217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nAs   my title suggests. I'm quite worried about the lay-offs happening, and   I've overheard that data people are the first ones to let go. Is it   true? Also do data engineers have more job security compared maybe data   scientists/analysts?\n\nThanks!", "author_fullname": "t2_tsoiffje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it true that when tech companies lay off people, usually data scientists/analysts/engineers are the first ones to let go? If it's true, does it mean that data people have less job security compared with usual SWEs writing codes and building products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yli65g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667517475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As   my title suggests. I&amp;#39;m quite worried about the lay-offs happening, and   I&amp;#39;ve overheard that data people are the first ones to let go. Is it   true? Also do data engineers have more job security compared maybe data   scientists/analysts?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yli65g", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Maintenance-1871", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yli65g/is_it_true_that_when_tech_companies_lay_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yli65g/is_it_true_that_when_tech_companies_lay_off/", "subreddit_subscribers": 78861, "created_utc": 1667517475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data engineers out there,\n\nI wanted to request for a pathway and some resume tips to transition from data integration to data engineering roles.\n\nTo give a background, I have developed data integration APIs using packaged tools and java. I understand how to connect to various source systems, pull out data and perform data mapping to convert data from and between formats like JSON, XML etc.\n\nNow I want to transition into a more technical data pipleline building kind of a role of Data Engineering. \n\nHow and where do I start? Is my background even relevant to data engineering to an extent or is it completely scrap when it comes to data engineering?\n\nAny feedback, pointers, advice would be much appreciated. I am currently looking for Data Engineering internships.", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on Data Integration to Data Engineering transitioning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylcb5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667503955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data engineers out there,&lt;/p&gt;\n\n&lt;p&gt;I wanted to request for a pathway and some resume tips to transition from data integration to data engineering roles.&lt;/p&gt;\n\n&lt;p&gt;To give a background, I have developed data integration APIs using packaged tools and java. I understand how to connect to various source systems, pull out data and perform data mapping to convert data from and between formats like JSON, XML etc.&lt;/p&gt;\n\n&lt;p&gt;Now I want to transition into a more technical data pipleline building kind of a role of Data Engineering. &lt;/p&gt;\n\n&lt;p&gt;How and where do I start? Is my background even relevant to data engineering to an extent or is it completely scrap when it comes to data engineering?&lt;/p&gt;\n\n&lt;p&gt;Any feedback, pointers, advice would be much appreciated. I am currently looking for Data Engineering internships.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ylcb5q", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylcb5q/need_advice_on_data_integration_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylcb5q/need_advice_on_data_integration_to_data/", "subreddit_subscribers": 78861, "created_utc": 1667503955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Heys guys,\nAny alternatives to Analysis Services? Currently using Azure Analysis Services but was wondering if any cost-effective tool is available in Azure such as Synapse, Databricks SQL etc?\nThanks in advance", "author_fullname": "t2_a89nyl1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analysis Services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1yrg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667479687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heys guys,\nAny alternatives to Analysis Services? Currently using Azure Analysis Services but was wondering if any cost-effective tool is available in Azure such as Synapse, Databricks SQL etc?\nThanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yl1yrg", "is_robot_indexable": true, "report_reasons": null, "author": "UnderstandingFair150", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl1yrg/analysis_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl1yrg/analysis_services/", "subreddit_subscribers": 78861, "created_utc": 1667479687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am helping my partner to build a ETL data integration academic project. The stack we want to use is Azure Data lake, ADF pipeline, Data bricks for transformation and Snowflake for storage. Ingest the data into data lake via REST API calls. \n\nCould some please suggest what kind of public APIs we can use to consume data with better scope to do transformations, data cleaning in the note book? we are looking for a dataset with at least half a million records. \n\nTIA", "author_fullname": "t2_2jqgdsp3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure ETL Data Pipeline Use case Inputs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yllswl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667527252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am helping my partner to build a ETL data integration academic project. The stack we want to use is Azure Data lake, ADF pipeline, Data bricks for transformation and Snowflake for storage. Ingest the data into data lake via REST API calls. &lt;/p&gt;\n\n&lt;p&gt;Could some please suggest what kind of public APIs we can use to consume data with better scope to do transformations, data cleaning in the note book? we are looking for a dataset with at least half a million records. &lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yllswl", "is_robot_indexable": true, "report_reasons": null, "author": "SpareSmileBravo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yllswl/azure_etl_data_pipeline_use_case_inputs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yllswl/azure_etl_data_pipeline_use_case_inputs/", "subreddit_subscribers": 78861, "created_utc": 1667527252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI built a sample spark-scala etl with maven as a build tool and a janky pom.xml. \n\n[https://github.com/dionesh12/sparkETLScalaExample](https://github.com/dionesh12/sparkETLScalaExample)\n\nI am not a developer nor a tech head  and I basically solve bugs as I go about my day during my previous job.I am as people say \"in between jobs\"  and was extremely motivated today and not burnt out.\n\nI am saying this because I know that the coding standards might not be upto par and probably the wrong flair.\n\nAnyway , please let me know if you found the code example useful. Also please do let me know  if any improvements are needed.\n\nAlso,if you found it helpful   please let me know.", "author_fullname": "t2_ty1lgaw7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Sample Spark Scala ETL Using Maven.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylc13c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667503302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I built a sample spark-scala etl with maven as a build tool and a janky pom.xml. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dionesh12/sparkETLScalaExample\"&gt;https://github.com/dionesh12/sparkETLScalaExample&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am not a developer nor a tech head  and I basically solve bugs as I go about my day during my previous job.I am as people say &amp;quot;in between jobs&amp;quot;  and was extremely motivated today and not burnt out.&lt;/p&gt;\n\n&lt;p&gt;I am saying this because I know that the coding standards might not be upto par and probably the wrong flair.&lt;/p&gt;\n\n&lt;p&gt;Anyway , please let me know if you found the code example useful. Also please do let me know  if any improvements are needed.&lt;/p&gt;\n\n&lt;p&gt;Also,if you found it helpful   please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?auto=webp&amp;s=a040425c8f6fdb325f80332a287d99ae539923b0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f0cfc232b749b98b21f8a10e4e3ed6b709703fa", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=890a1e19437bcecf4469ce3d8ec830b583e33da1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1546b979d22d314ca85224968009672eea48fafa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=21847e3509e223d9898458c6d3a0d8b485d743b3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a52c50195dc4da0171ba08ad9cf09fdd3134ef9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a903ad2826d36822b72baa43c0e1fa1edd700a15", "width": 1080, "height": 540}], "variants": {}, "id": "KXbRgB3ZA_AFiyLKrvhpL9_M8RRJ8oN7FwkIRwcyx4s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "ylc13c", "is_robot_indexable": true, "report_reasons": null, "author": "krosMios", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylc13c/a_sample_spark_scala_etl_using_maven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylc13c/a_sample_spark_scala_etl_using_maven/", "subreddit_subscribers": 78861, "created_utc": 1667503302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Folks, let's assume you have a table (table\\_1) with 150 columns in a columnar database that contains raw data ingested from a source on daily basis.\n\nYou have a second table (table\\_2) with 25 columns in the same columnar database that contains a section of raw data ingested from the same source on daily basis.\n\nAssuming that\n\n\\- all columns are of type varchar (length 1024)\n\n\\- no network bandwidth limit between data source and database\n\n\\- number of rows in each load is the same for both tables (e.g: 100K rows)\n\n\\- quality of data is the same in both cases.\n\nQuestion:\n\n\\- During the daily load process, which table would have ingested more records in a given time frame (e.g.: 30 seconds)?\n\n\\- What are the factors that could impact the number of rows ingested over a time frame?", "author_fullname": "t2_embis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are advantages/disadvantages of a wide table (e.x.: 100s columns) vs normal table (10s columns) when loading data into them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl6o5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667501305.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667491439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Folks, let&amp;#39;s assume you have a table (table_1) with 150 columns in a columnar database that contains raw data ingested from a source on daily basis.&lt;/p&gt;\n\n&lt;p&gt;You have a second table (table_2) with 25 columns in the same columnar database that contains a section of raw data ingested from the same source on daily basis.&lt;/p&gt;\n\n&lt;p&gt;Assuming that&lt;/p&gt;\n\n&lt;p&gt;- all columns are of type varchar (length 1024)&lt;/p&gt;\n\n&lt;p&gt;- no network bandwidth limit between data source and database&lt;/p&gt;\n\n&lt;p&gt;- number of rows in each load is the same for both tables (e.g: 100K rows)&lt;/p&gt;\n\n&lt;p&gt;- quality of data is the same in both cases.&lt;/p&gt;\n\n&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;- During the daily load process, which table would have ingested more records in a given time frame (e.g.: 30 seconds)?&lt;/p&gt;\n\n&lt;p&gt;- What are the factors that could impact the number of rows ingested over a time frame?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yl6o5r", "is_robot_indexable": true, "report_reasons": null, "author": "bajams", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl6o5r/what_are_advantagesdisadvantages_of_a_wide_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl6o5r/what_are_advantagesdisadvantages_of_a_wide_table/", "subreddit_subscribers": 78861, "created_utc": 1667491439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I wanted get your point of view on my current situation : \n\n  \nAfter several years of working in the field, I now have lots of experience is most of it data life cycle.  \nI'm now experienced with different tools, warehouses , modelization &amp; cloud services &amp; devops (ci/cd, terraform) and more advanced concepts (Big Data, monitoring, data lineage, data discovery, quality testing &amp; resilience testing). \n\nTherefore, there is one gap on my skills for a Data Engineer which is Real Time stacks (kafka, flink ..). I've been tweaking with them at school but nothing more .. I never had the occasion to use it, on my past jobs, we were using near-real time to fill the high frequency use-case (5mins/run) to be able to keep the same stack, guideliness and skillset.  \n\n\nHow big of a gap do you think this is ? How important is it : is it worth filling this gap ?   \nMy heart makes me want to learn more about Kubernetes &amp; more advanced concepts to build fully fledged applications, but I feel like it may be better for me to focus on my weakness first ?", "author_fullname": "t2_txucj9ys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it to grasp real-time stack ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl514o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667487578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I wanted get your point of view on my current situation : &lt;/p&gt;\n\n&lt;p&gt;After several years of working in the field, I now have lots of experience is most of it data life cycle.&lt;br/&gt;\nI&amp;#39;m now experienced with different tools, warehouses , modelization &amp;amp; cloud services &amp;amp; devops (ci/cd, terraform) and more advanced concepts (Big Data, monitoring, data lineage, data discovery, quality testing &amp;amp; resilience testing). &lt;/p&gt;\n\n&lt;p&gt;Therefore, there is one gap on my skills for a Data Engineer which is Real Time stacks (kafka, flink ..). I&amp;#39;ve been tweaking with them at school but nothing more .. I never had the occasion to use it, on my past jobs, we were using near-real time to fill the high frequency use-case (5mins/run) to be able to keep the same stack, guideliness and skillset.  &lt;/p&gt;\n\n&lt;p&gt;How big of a gap do you think this is ? How important is it : is it worth filling this gap ?&lt;br/&gt;\nMy heart makes me want to learn more about Kubernetes &amp;amp; more advanced concepts to build fully fledged applications, but I feel like it may be better for me to focus on my weakness first ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yl514o", "is_robot_indexable": true, "report_reasons": null, "author": "nxt-engineering", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yl514o/how_hard_is_it_to_grasp_realtime_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl514o/how_hard_is_it_to_grasp_realtime_stack/", "subreddit_subscribers": 78861, "created_utc": 1667487578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "how close are these 2 fields? i\u2019m reading through job descriptions and responsibilities and there are quite a significant amount of similarities; almost as if the developer can move horizontally into engineering.", "author_fullname": "t2_ht40qce8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "bi developer and data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykx7wt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667467579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how close are these 2 fields? i\u2019m reading through job descriptions and responsibilities and there are quite a significant amount of similarities; almost as if the developer can move horizontally into engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ykx7wt", "is_robot_indexable": true, "report_reasons": null, "author": "phoot_in_the_door", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ykx7wt/bi_developer_and_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ykx7wt/bi_developer_and_data_engineer/", "subreddit_subscribers": 78861, "created_utc": 1667467579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIn the process of teaching myself dbt. Have run into a bit of a snag trying to iterate over a result set from a seed table. Seed table CSV is pretty basic here, just trying to prove the concept\n\n&amp;#x200B;\n\n|1|New York||\n|:-|:-|:-|\n|2|Florida||\n|3|Oregon||\n|4|New Mexico||\n|5|Texas||\n|6|Colorado||\n\n    {% set my_seed_query %}\n    select * from {{ ref('my_seed_table') }} \n    {% endset %}\n    {% set results = run_query('select * from my_seed_query') %}\n    {% if execute  %}\n    {% set results_sv_list = results.columns[1].values() %}\n    {% else %}\n    {% set results_sv_list = [] %}\n    {% endif %} \n    {% for item in results_sv_list %}\n     {{ print(item) }} \n    {% endfor  %}\n\n&amp;#x200B;\n\nI've tried some variation on this\n\n    with my_seed_query as (\n     select * from {{ ref('my_seed_table') }}\n    )\n    \n    {% set results = run_query('select * from my_seed_query') %}\n    {% if execute  %}\n    {% set results_sv_list = results.columns[1].values() %}\n    {% else %}\n    {% set results_sv_list = [] %}\n    {% endif %}\n    {% for item in results_sv_list %}\n        {{ print(item) }}\n    {% endfor  %}\n\nand also\n\n    {% set my_seed_query %}\n     select * from {{ ref('my_seed_table') }}\n    {% endset %}\n    {% set results = run_query(my_seed_query) %}\n    {% if execute  %}\n    {% set results_sv_list = results.columns[1].values() %}\n    {% else %}\n    {% set results_sv_list = [] %}\n    {% endif %}\n    {% for item in results_sv_list %}\n        {{ print(item) }}\n    {% endfor  %}\n\nAll of the above produce various errors\n\nHowever, the code below works as expected and returns a result table, so the seed table is being resolved with ref(...) command, at least in the scenario below\n\n    with my_seed_query as (\n     select * from {{ ref('my_seed_table') }}\n    )\n    \n    select * from my_seed_query", "author_fullname": "t2_osgmm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt jinja question arounds seeds and loops", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yll0e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667525007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;In the process of teaching myself dbt. Have run into a bit of a snag trying to iterate over a result set from a seed table. Seed table CSV is pretty basic here, just trying to prove the concept&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;1&lt;/th&gt;\n&lt;th align=\"left\"&gt;New York&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;Florida&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;Oregon&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;New Mexico&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;Texas&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;td align=\"left\"&gt;Colorado&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;pre&gt;&lt;code&gt;{% set my_seed_query %}\nselect * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }} \n{% endset %}\n{% set results = run_query(&amp;#39;select * from my_seed_query&amp;#39;) %}\n{% if execute  %}\n{% set results_sv_list = results.columns[1].values() %}\n{% else %}\n{% set results_sv_list = [] %}\n{% endif %} \n{% for item in results_sv_list %}\n {{ print(item) }} \n{% endfor  %}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried some variation on this&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with my_seed_query as (\n select * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }}\n)\n\n{% set results = run_query(&amp;#39;select * from my_seed_query&amp;#39;) %}\n{% if execute  %}\n{% set results_sv_list = results.columns[1].values() %}\n{% else %}\n{% set results_sv_list = [] %}\n{% endif %}\n{% for item in results_sv_list %}\n    {{ print(item) }}\n{% endfor  %}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;and also&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{% set my_seed_query %}\n select * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }}\n{% endset %}\n{% set results = run_query(my_seed_query) %}\n{% if execute  %}\n{% set results_sv_list = results.columns[1].values() %}\n{% else %}\n{% set results_sv_list = [] %}\n{% endif %}\n{% for item in results_sv_list %}\n    {{ print(item) }}\n{% endfor  %}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;All of the above produce various errors&lt;/p&gt;\n\n&lt;p&gt;However, the code below works as expected and returns a result table, so the seed table is being resolved with ref(...) command, at least in the scenario below&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with my_seed_query as (\n select * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }}\n)\n\nselect * from my_seed_query\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yll0e8", "is_robot_indexable": true, "report_reasons": null, "author": "rmz76", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yll0e8/dbt_jinja_question_arounds_seeds_and_loops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yll0e8/dbt_jinja_question_arounds_seeds_and_loops/", "subreddit_subscribers": 78861, "created_utc": 1667525007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious to know if anyone has worked with MongoDB in cases where the resume point it lost. \n\nThere are cases where the connectivity between the consumer (eg NodeJS) app loses the connection. If the connection is down for long enough the MongoDB oplog overflows so you can never resume from that point again.\n\nWhat are some patterns you would use to handle this scenario?\n\nMy immediate thought is well, we log the time when the failure occurred. We then simply query Mongo directly for any documents updated from that point. Then resume streaming.\n\nI can\u2019t help but think there\u2019s a cleaner pattern\ud83e\udd14", "author_fullname": "t2_htptc13q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MongoDB ChangeStream Connection Failure Handling - ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylkr1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667524293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to know if anyone has worked with MongoDB in cases where the resume point it lost. &lt;/p&gt;\n\n&lt;p&gt;There are cases where the connectivity between the consumer (eg NodeJS) app loses the connection. If the connection is down for long enough the MongoDB oplog overflows so you can never resume from that point again.&lt;/p&gt;\n\n&lt;p&gt;What are some patterns you would use to handle this scenario?&lt;/p&gt;\n\n&lt;p&gt;My immediate thought is well, we log the time when the failure occurred. We then simply query Mongo directly for any documents updated from that point. Then resume streaming.&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t help but think there\u2019s a cleaner pattern\ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ylkr1a", "is_robot_indexable": true, "report_reasons": null, "author": "Main_Tap_1256", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylkr1a/mongodb_changestream_connection_failure_handling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylkr1a/mongodb_changestream_connection_failure_handling/", "subreddit_subscribers": 78861, "created_utc": 1667524293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most that I know are generic data related and not only about data engineering. Thanks in advance", "author_fullname": "t2_f6oj9cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which data engineering blogs/youtube channels do you access?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yljupv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667521838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most that I know are generic data related and not only about data engineering. Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yljupv", "is_robot_indexable": true, "report_reasons": null, "author": "imsg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yljupv/which_data_engineering_blogsyoutube_channels_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yljupv/which_data_engineering_blogsyoutube_channels_do/", "subreddit_subscribers": 78861, "created_utc": 1667521838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I am a data scientist and software engineer and I have a data pipeline problem I need to tackle. I did some research but encountered some obstacles.\n\nAny advice from people on orchestration/useful tools is welcome.\n\nI am not a data engineer so some of my terminologies might be off.\n\n## Objective\n\nSo the objective is that I have multiple sources of unclean data stored in different services (e.g GCP) and other formats (.csv, .json) sometimes with complex logic. I want to format the data for each source and store it in a production-ready database used by the backend (Postgres). This procedure will happen 4-5 times a year or even monthly.\n\nOn the side, I would like to be able to load the data into some big data framework such as delta lake or BigQuery to explore them and refine the algorithm which loads the data to the backend DB.\n\n## What I have\n\nRight now because the data is not that big I spawn a VM on GCP and download the data, format them, process them and store them in a MongoDB (soon to become Postgres) using prefect (v1).\n\nHowever, the problem is that our data is about to grow and the processing step has some data science that is already really heavy in calculations (it might take a day or two on a 64GB GCP VM).\n\nOnce the data grows this is going to be impossible.\n\n## What I tried\n\nSo I started searching about ETL in cloud platforms and came across different tools such as apache beam (Dataflow), airflow (Cloud Composer), and spark (Databricks).\n\n1. I have tried using apache beam but this tool seems to integrate well with BigQuery, which is not my main objective, and it is not designed to load data to DBS like Postgres (especially the python version). Also, coding things data science-specific things in it like correlations seems a nightmare.\n2. I am right now checking Databricks which seems like a cool option to create data lakes. As far as I understand they manage my cluster on GCP and run spark on it. This looks like an easier way to load data to my data lake, but Delta Lake is not OLTP which is my main concern.\n3. I also checked airflow on GCP but would like to avoid defining resources, services, nodes, clusters, etc, as my data is big and sometimes my program crashes with OOM. \n\nThing is that every ETL research I do relates to OLAP which is nice but I want to primarily load our production DB. I searched about ELT or reverse ETL but I do not get many meaningful results so I feel like there is something completely off here, either about my terminologies or what I am trying to do.\n\nAny advice would be greatly appreciated.", "author_fullname": "t2_ist94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud: Workflow to load data to OLTP (MySQL/Postgres etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylhkfz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667516222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I am a data scientist and software engineer and I have a data pipeline problem I need to tackle. I did some research but encountered some obstacles.&lt;/p&gt;\n\n&lt;p&gt;Any advice from people on orchestration/useful tools is welcome.&lt;/p&gt;\n\n&lt;p&gt;I am not a data engineer so some of my terminologies might be off.&lt;/p&gt;\n\n&lt;h2&gt;Objective&lt;/h2&gt;\n\n&lt;p&gt;So the objective is that I have multiple sources of unclean data stored in different services (e.g GCP) and other formats (.csv, .json) sometimes with complex logic. I want to format the data for each source and store it in a production-ready database used by the backend (Postgres). This procedure will happen 4-5 times a year or even monthly.&lt;/p&gt;\n\n&lt;p&gt;On the side, I would like to be able to load the data into some big data framework such as delta lake or BigQuery to explore them and refine the algorithm which loads the data to the backend DB.&lt;/p&gt;\n\n&lt;h2&gt;What I have&lt;/h2&gt;\n\n&lt;p&gt;Right now because the data is not that big I spawn a VM on GCP and download the data, format them, process them and store them in a MongoDB (soon to become Postgres) using prefect (v1).&lt;/p&gt;\n\n&lt;p&gt;However, the problem is that our data is about to grow and the processing step has some data science that is already really heavy in calculations (it might take a day or two on a 64GB GCP VM).&lt;/p&gt;\n\n&lt;p&gt;Once the data grows this is going to be impossible.&lt;/p&gt;\n\n&lt;h2&gt;What I tried&lt;/h2&gt;\n\n&lt;p&gt;So I started searching about ETL in cloud platforms and came across different tools such as apache beam (Dataflow), airflow (Cloud Composer), and spark (Databricks).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I have tried using apache beam but this tool seems to integrate well with BigQuery, which is not my main objective, and it is not designed to load data to DBS like Postgres (especially the python version). Also, coding things data science-specific things in it like correlations seems a nightmare.&lt;/li&gt;\n&lt;li&gt;I am right now checking Databricks which seems like a cool option to create data lakes. As far as I understand they manage my cluster on GCP and run spark on it. This looks like an easier way to load data to my data lake, but Delta Lake is not OLTP which is my main concern.&lt;/li&gt;\n&lt;li&gt;I also checked airflow on GCP but would like to avoid defining resources, services, nodes, clusters, etc, as my data is big and sometimes my program crashes with OOM. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thing is that every ETL research I do relates to OLAP which is nice but I want to primarily load our production DB. I searched about ELT or reverse ETL but I do not get many meaningful results so I feel like there is something completely off here, either about my terminologies or what I am trying to do.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ylhkfz", "is_robot_indexable": true, "report_reasons": null, "author": "t_char", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylhkfz/cloud_workflow_to_load_data_to_oltp_mysqlpostgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylhkfz/cloud_workflow_to_load_data_to_oltp_mysqlpostgres/", "subreddit_subscribers": 78861, "created_utc": 1667516222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen a couple of people suggesting me (recent grad, interested in all data related fields) to find a mentor. They usually stop at that, without explaining how to?\n\nI'm being genuine, should I just contact some senior on linkedin?\n\n&amp;#x200B;\n\n&gt;Hey, you sound like you know a lot, can you teach me senpai?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I get a mentor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylg7lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667514400.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667513484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a couple of people suggesting me (recent grad, interested in all data related fields) to find a mentor. They usually stop at that, without explaining how to?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m being genuine, should I just contact some senior on linkedin?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Hey, you sound like you know a lot, can you teach me senpai?&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ylg7lu", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylg7lu/how_can_i_get_a_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylg7lu/how_can_i_get_a_mentor/", "subreddit_subscribers": 78861, "created_utc": 1667513484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe I'm going to ask a bit much here but...\n\n&amp;#x200B;\n\nI'm studying ICT software engineering and am currently doing my internship for an organization ruling one of the province in my country (the Netherlands) and their goal is to get all wrongdoings on a map to indicate concentrations. They developed a Power BI solution with the icon map add-on. The map is mostly filled with data from numerous district law organizations. They create an data extract (Excel) every three months and format them to only the three fields when, what and where. Then the where will be anonymised and finally the file will be uploaded to a SharePoint environment that Power BI pulls data from.\n\nMy assignment is to research ways to improve this. So researching if there's a better way to create this map (I already see a lot of benefits in ArcGIS, they also already work with it). But also improving the dataflow, a big problem is information privacy and security. So you have to be sure to only deal with the data that's telling what, where and when. Beside that all the data stays \"inside\" the used systems, so it's not stored on a database or anything.\n\nSorry if it's unclear, I tried my best to explain it in English.\n\n&amp;#x200B;\n\nFinally my question is, what things should I be looking for or researching for? I normally know you should do your own research, but I just wanna be pushed in the right direction. I already wrote down these topics:\n\n\\- Azure data pipelines  \n\\- ETL/ELT tooling  \n\\- API (not all of the used systems have an API   \n\\- AWS Glue\n\n&amp;#x200B;\n\nThank you so much in advance", "author_fullname": "t2_31sddeha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for options to do data transformations from a lot of systems into one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl6grz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667490961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe I&amp;#39;m going to ask a bit much here but...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m studying ICT software engineering and am currently doing my internship for an organization ruling one of the province in my country (the Netherlands) and their goal is to get all wrongdoings on a map to indicate concentrations. They developed a Power BI solution with the icon map add-on. The map is mostly filled with data from numerous district law organizations. They create an data extract (Excel) every three months and format them to only the three fields when, what and where. Then the where will be anonymised and finally the file will be uploaded to a SharePoint environment that Power BI pulls data from.&lt;/p&gt;\n\n&lt;p&gt;My assignment is to research ways to improve this. So researching if there&amp;#39;s a better way to create this map (I already see a lot of benefits in ArcGIS, they also already work with it). But also improving the dataflow, a big problem is information privacy and security. So you have to be sure to only deal with the data that&amp;#39;s telling what, where and when. Beside that all the data stays &amp;quot;inside&amp;quot; the used systems, so it&amp;#39;s not stored on a database or anything.&lt;/p&gt;\n\n&lt;p&gt;Sorry if it&amp;#39;s unclear, I tried my best to explain it in English.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Finally my question is, what things should I be looking for or researching for? I normally know you should do your own research, but I just wanna be pushed in the right direction. I already wrote down these topics:&lt;/p&gt;\n\n&lt;p&gt;- Azure data pipelines&lt;br/&gt;\n- ETL/ELT tooling&lt;br/&gt;\n- API (not all of the used systems have an API&lt;br/&gt;\n- AWS Glue&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yl6grz", "is_robot_indexable": true, "report_reasons": null, "author": "Milofow", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl6grz/looking_for_options_to_do_data_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl6grz/looking_for_options_to_do_data_transformations/", "subreddit_subscribers": 78861, "created_utc": 1667490961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been a small company analytics engineer (with a healthy dose of ETL/ELT) for the past 5-6 years. Looking for advice beyond what is currently available at the company and was curious where similar professionals go for general management and career advice?\n\nWe are refactoring our data warehouse that was built by data scientists and would love to discuss similar takes and scenarios.\n\nWhere do you go for advice?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small business/startup engineers - where do you go when you need advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1jdu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667478497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been a small company analytics engineer (with a healthy dose of ETL/ELT) for the past 5-6 years. Looking for advice beyond what is currently available at the company and was curious where similar professionals go for general management and career advice?&lt;/p&gt;\n\n&lt;p&gt;We are refactoring our data warehouse that was built by data scientists and would love to discuss similar takes and scenarios.&lt;/p&gt;\n\n&lt;p&gt;Where do you go for advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yl1jdu", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yl1jdu/small_businessstartup_engineers_where_do_you_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yl1jdu/small_businessstartup_engineers_where_do_you_go/", "subreddit_subscribers": 78861, "created_utc": 1667478497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just a little curious on how stream analytics work. What is the underlying mechanism? I am not able to find any good blogs or articles over it. So any answer or any links to some good articles will be really appreciated :)", "author_fullname": "t2_3qcs2dxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does stream analytics(Azure) works internally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yktj3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667454210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a little curious on how stream analytics work. What is the underlying mechanism? I am not able to find any good blogs or articles over it. So any answer or any links to some good articles will be really appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yktj3i", "is_robot_indexable": true, "report_reasons": null, "author": "chilllman", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yktj3i/how_does_stream_analyticsazure_works_internally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yktj3i/how_does_stream_analyticsazure_works_internally/", "subreddit_subscribers": 78861, "created_utc": 1667454210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What was one section of the Data Engineer Interview you felt like you studied for no reason or over-prepared?", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer Interview Wrong Prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylk7nv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667522817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What was one section of the Data Engineer Interview you felt like you studied for no reason or over-prepared?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer At Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ylk7nv", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ylk7nv/data_engineer_interview_wrong_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylk7nv/data_engineer_interview_wrong_prep/", "subreddit_subscribers": 78861, "created_utc": 1667522817.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}