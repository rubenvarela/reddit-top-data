{"kind": "Listing", "data": {"after": "t3_ylkr1a", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking towards expanding my knowledge in this field. Are there some courses (or even books) that are maybe not specific to one technology, but are very useful to improve in this field and you can recommend?", "author_fullname": "t2_xcba5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some highly recommended courses for data engineers (that are already working in this field so not \"from zero\")?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yluu6c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667556922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking towards expanding my knowledge in this field. Are there some courses (or even books) that are maybe not specific to one technology, but are very useful to improve in this field and you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yluu6c", "is_robot_indexable": true, "report_reasons": null, "author": "mackbenc", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yluu6c/what_are_some_highly_recommended_courses_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yluu6c/what_are_some_highly_recommended_courses_for_data/", "subreddit_subscribers": 78914, "created_utc": 1667556922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nAs   my title suggests. I'm quite worried about the lay-offs happening, and   I've overheard that data people are the first ones to let go. Is it   true? Also do data engineers have more job security compared maybe data   scientists/analysts?\n\nThanks!", "author_fullname": "t2_tsoiffje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it true that when tech companies lay off people, usually data scientists/analysts/engineers are the first ones to let go? If it's true, does it mean that data people have less job security compared with usual SWEs writing codes and building products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yli65g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667517475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As   my title suggests. I&amp;#39;m quite worried about the lay-offs happening, and   I&amp;#39;ve overheard that data people are the first ones to let go. Is it   true? Also do data engineers have more job security compared maybe data   scientists/analysts?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yli65g", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Maintenance-1871", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yli65g/is_it_true_that_when_tech_companies_lay_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yli65g/is_it_true_that_when_tech_companies_lay_off/", "subreddit_subscribers": 78914, "created_utc": 1667517475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Howdy guys, we're a small team working on an API that helps users access, filter, and fuse (e.g. interpolate on-demand) large multidimensional geospatial datasets with minimal setup on the cloud. Practically, this means users can accelerate data engineering/ETL, and incorporate more data variety and volume into their models, all without breaking the bank. It's also well-designed for people who have never worked with this kind of data before. \n\nYou can learn more on our [website](https://pharossoftware.com/) \n\nAnyways, the data we're working with (weather, remote sensing) is quite applicable to crop intel, energy modeling, and more. And I'd love to connect with folks in the industry so we can learn more about your needs, pain points. I can't offer much other than lots of free credits and hopefully a fun conversation about a very cutting-edge space!\n\nComment here or DM me if interested! Thanks :)", "author_fullname": "t2_nx2zqyff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any folks doing data engineering in the agriculture or energy space?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylebcr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667508225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy guys, we&amp;#39;re a small team working on an API that helps users access, filter, and fuse (e.g. interpolate on-demand) large multidimensional geospatial datasets with minimal setup on the cloud. Practically, this means users can accelerate data engineering/ETL, and incorporate more data variety and volume into their models, all without breaking the bank. It&amp;#39;s also well-designed for people who have never worked with this kind of data before. &lt;/p&gt;\n\n&lt;p&gt;You can learn more on our &lt;a href=\"https://pharossoftware.com/\"&gt;website&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Anyways, the data we&amp;#39;re working with (weather, remote sensing) is quite applicable to crop intel, energy modeling, and more. And I&amp;#39;d love to connect with folks in the industry so we can learn more about your needs, pain points. I can&amp;#39;t offer much other than lots of free credits and hopefully a fun conversation about a very cutting-edge space!&lt;/p&gt;\n\n&lt;p&gt;Comment here or DM me if interested! Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ylebcr", "is_robot_indexable": true, "report_reasons": null, "author": "mightylighthouse", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylebcr/any_folks_doing_data_engineering_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylebcr/any_folks_doing_data_engineering_in_the/", "subreddit_subscribers": 78914, "created_utc": 1667508225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most that I know are generic data related and not only about data engineering. Thanks in advance", "author_fullname": "t2_f6oj9cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which data engineering blogs/youtube channels do you access?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yljupv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667521838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most that I know are generic data related and not only about data engineering. Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yljupv", "is_robot_indexable": true, "report_reasons": null, "author": "imsg", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yljupv/which_data_engineering_blogsyoutube_channels_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yljupv/which_data_engineering_blogsyoutube_channels_do/", "subreddit_subscribers": 78914, "created_utc": 1667521838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Architecture Overview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_ym47ac", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yGXnh37_uGcE2kuS_FNHWYClXIyyKtAwwbAVfsKO530.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667581122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/snowflake-architecture", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?auto=webp&amp;s=8cf0c451337947e5197c9980f55034683b9b16b9", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e780c59f47c708f8dee670def7482bdd6d649802", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40336792cee0c641925209f0794ebb5cba7f4057", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=febd03fd9cd53a85bf8ab704acb70c6224087b2b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9f004a5d20cc564da854ddd555ac6e89bac02d5", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f689e9b4c383ec70ab60fb482977e9aa44d0fb7", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/wLLvDK-mih-0Oi61400ZH5HZfl4H95veymOHOfihNkw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=553f3a2c6a205a75d743c5fb2ec490e975198688", "width": 1080, "height": 564}], "variants": {}, "id": "ZPdNCABw_PyJ7OjwDrehimG77P2Q-ZeCj5Nj9UZ8mCA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ym47ac", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym47ac/snowflake_architecture_overview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/snowflake-architecture", "subreddit_subscribers": 78914, "created_utc": 1667581122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \n\nOur lead architect has written an in-depth post on this topic. We leave it here, hoping it would be helpful for many in this community. Feel free to reach out to us.\n\n[Database Replication with Change Data Capture over Kafka](https://klarrio.medium.com/database-replication-with-change-data-capture-over-kafka-975bc60cecce)", "author_fullname": "t2_hdoa4gp4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Replication with Change Data Capture over Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylyak7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667566511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;Our lead architect has written an in-depth post on this topic. We leave it here, hoping it would be helpful for many in this community. Feel free to reach out to us.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://klarrio.medium.com/database-replication-with-change-data-capture-over-kafka-975bc60cecce\"&gt;Database Replication with Change Data Capture over Kafka&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?auto=webp&amp;s=1780f0f33d35c148d1323c51d6e41d25ff13ddb3", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41bf0bfb585291e6b7423e84bef29715d6bc5408", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=953eb7d6bc98429cf6c9fef425de113a8e883e71", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c244c369e6208e28ad4c024a199f6a84bc2fd37", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=019285650aa3483e35257b15db054531369bf425", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3691c9b0e6e21852cdfa09eee0dff4566d1b77b9", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/4RFbB6z3uDXiXS1dMU7oeFTIcgLJHDaQ7aWAG4xvK-I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=30a947850f664e347b73567de816294813487794", "width": 1080, "height": 564}], "variants": {}, "id": "_qRWCOgx306LX6ghGfMxuU-HoNtBBGOTjsun2VNTAEE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ylyak7", "is_robot_indexable": true, "report_reasons": null, "author": "Klarrio", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylyak7/database_replication_with_change_data_capture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylyak7/database_replication_with_change_data_capture/", "subreddit_subscribers": 78914, "created_utc": 1667566511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am helping my partner to build a ETL data integration academic project. The stack we want to use is Azure Data lake, ADF pipeline, Data bricks for transformation and Snowflake for storage. Ingest the data into data lake via REST API calls. \n\nCould some please suggest what kind of public APIs we can use to consume data with better scope to do transformations, data cleaning in the note book? we are looking for a dataset with at least half a million records. \n\nTIA", "author_fullname": "t2_2jqgdsp3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure ETL Data Pipeline Use case Inputs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yllswl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667527252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am helping my partner to build a ETL data integration academic project. The stack we want to use is Azure Data lake, ADF pipeline, Data bricks for transformation and Snowflake for storage. Ingest the data into data lake via REST API calls. &lt;/p&gt;\n\n&lt;p&gt;Could some please suggest what kind of public APIs we can use to consume data with better scope to do transformations, data cleaning in the note book? we are looking for a dataset with at least half a million records. &lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yllswl", "is_robot_indexable": true, "report_reasons": null, "author": "SpareSmileBravo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yllswl/azure_etl_data_pipeline_use_case_inputs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yllswl/azure_etl_data_pipeline_use_case_inputs/", "subreddit_subscribers": 78914, "created_utc": 1667527252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interview today for a regional hospital. Pretty stoked because it would be a huge step up for me. Part of me is worried about the technical qualifications because I haven't used some of the tools but have been reading up on them (thanks to a Redditor for helping me find sources). I'm just going to be honest if I get stumped, I won't try and BS my answers.\n\nThe job seems to be a mix of Data Engineer, BIA, Data Analyst. I was able to score an interview because of a referral but I do hope they saw more in me from my resume.\n\nWish me luck!", "author_fullname": "t2_a4wvyz1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have an interview today for Business Intelligence Analyst today", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym1f53", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667574378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interview today for a regional hospital. Pretty stoked because it would be a huge step up for me. Part of me is worried about the technical qualifications because I haven&amp;#39;t used some of the tools but have been reading up on them (thanks to a Redditor for helping me find sources). I&amp;#39;m just going to be honest if I get stumped, I won&amp;#39;t try and BS my answers.&lt;/p&gt;\n\n&lt;p&gt;The job seems to be a mix of Data Engineer, BIA, Data Analyst. I was able to score an interview because of a referral but I do hope they saw more in me from my resume.&lt;/p&gt;\n\n&lt;p&gt;Wish me luck!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ym1f53", "is_robot_indexable": true, "report_reasons": null, "author": "HeavyFuckingMetalx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym1f53/have_an_interview_today_for_business_intelligence/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym1f53/have_an_interview_today_for_business_intelligence/", "subreddit_subscribers": 78914, "created_utc": 1667574378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently planning a refactoring of the data stack in my company, including our BI tools of choice.\n\nWe're currently using Redash, but it's obviously not self service. I want to give other departments the freedom to at the very least answer some basic questions they may have without having to rely on a data analyst every time.\n\nThe skill range of these people however varies greatly: there's some that are very proficient with excel and can write some SQL, others that barely manage to tie their shoelaces.\n\nI'm currently testing Metabase, and while I like its intuitive interface, there are some intricacies that may lead someone to shoot themselves in the foot.\n\nWhich BI tool would you recommend?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What BI tool would you recommend for self-servicing dummies? (possibly FOSS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylv4fo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667557854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently planning a refactoring of the data stack in my company, including our BI tools of choice.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently using Redash, but it&amp;#39;s obviously not self service. I want to give other departments the freedom to at the very least answer some basic questions they may have without having to rely on a data analyst every time.&lt;/p&gt;\n\n&lt;p&gt;The skill range of these people however varies greatly: there&amp;#39;s some that are very proficient with excel and can write some SQL, others that barely manage to tie their shoelaces.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently testing Metabase, and while I like its intuitive interface, there are some intricacies that may lead someone to shoot themselves in the foot.&lt;/p&gt;\n\n&lt;p&gt;Which BI tool would you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ylv4fo", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylv4fo/what_bi_tool_would_you_recommend_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylv4fo/what_bi_tool_would_you_recommend_for/", "subreddit_subscribers": 78914, "created_utc": 1667557854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been hearing/seeing more of this product but I'm struggling to understand the value it provides.  \n\nIt seems to me just another way to automate spinning up cloud resources.  We use Azure at my work and how is this different from just using azure CLI scripts to do the same thing?   \n\nSpinning up a VM, even through the GUI, takes like 3 minutes. Why would one do that through terraform?  \n\nWhat am I missing?", "author_fullname": "t2_szv0ygic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5 Terraform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym067q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667571257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been hearing/seeing more of this product but I&amp;#39;m struggling to understand the value it provides.  &lt;/p&gt;\n\n&lt;p&gt;It seems to me just another way to automate spinning up cloud resources.  We use Azure at my work and how is this different from just using azure CLI scripts to do the same thing?   &lt;/p&gt;\n\n&lt;p&gt;Spinning up a VM, even through the GUI, takes like 3 minutes. Why would one do that through terraform?  &lt;/p&gt;\n\n&lt;p&gt;What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym067q", "is_robot_indexable": true, "report_reasons": null, "author": "Hippodick666420", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym067q/eli5_terraform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym067q/eli5_terraform/", "subreddit_subscribers": 78914, "created_utc": 1667571257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Get bonking as a Lambda Warrior, strike swiftly like an Eventbridge Ranger or uncover mysteries as a Dynamo DB Mage - Choose wisely:  \n[https://serverless-summit.io/](https://serverless-summit.io/)  \nSee you on the other side! \ud83d\ude4c\ud83c\udffb\n\nStay Serverless! \u26a1\ufe0f\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qtv5wyhefwx91.png?width=2851&amp;format=png&amp;auto=webp&amp;s=af5b351b37f71c54d9818298104e9ba3d8b470d1", "author_fullname": "t2_ptnsnlti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join the Serverless Summit 22 for an adventure! \ud83d\udcab\ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qtv5wyhefwx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d034976c768b561221b38d567d0ad3cb15d87c34"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9a3152d108234a71339e7fb6fa29789b3550b17"}, {"y": 228, "x": 320, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=845fd2828518476a0bcaa079a55e2a66fbec8265"}, {"y": 457, "x": 640, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b79127cb0c3bfb7e5aa82c1f9a448e975ae6cb0"}, {"y": 686, "x": 960, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d53b5146842ec7ac19f1e9115b0afe86342a28db"}, {"y": 772, "x": 1080, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1c34c18350aebeede40016a6f9c0bb4724648c45"}], "s": {"y": 2038, "x": 2851, "u": "https://preview.redd.it/qtv5wyhefwx91.png?width=2851&amp;format=png&amp;auto=webp&amp;s=af5b351b37f71c54d9818298104e9ba3d8b470d1"}, "id": "qtv5wyhefwx91"}}, "name": "t3_ylta1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xerDVDca0YLqViA4-BRdctgfVbElcvGE9GYdwZEA7Lo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667552261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Get bonking as a Lambda Warrior, strike swiftly like an Eventbridge Ranger or uncover mysteries as a Dynamo DB Mage - Choose wisely:&lt;br/&gt;\n&lt;a href=\"https://serverless-summit.io/\"&gt;https://serverless-summit.io/&lt;/a&gt;&lt;br/&gt;\nSee you on the other side! \ud83d\ude4c\ud83c\udffb&lt;/p&gt;\n\n&lt;p&gt;Stay Serverless! \u26a1\ufe0f&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qtv5wyhefwx91.png?width=2851&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=af5b351b37f71c54d9818298104e9ba3d8b470d1\"&gt;https://preview.redd.it/qtv5wyhefwx91.png?width=2851&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=af5b351b37f71c54d9818298104e9ba3d8b470d1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ylta1z", "is_robot_indexable": true, "report_reasons": null, "author": "nikita-salanovich", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylta1z/join_the_serverless_summit_22_for_an_adventure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylta1z/join_the_serverless_summit_22_for_an_adventure/", "subreddit_subscribers": 78914, "created_utc": 1667552261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIn the process of teaching myself dbt. Have run into a bit of a snag trying to iterate over a result set from a seed table. Seed table CSV is pretty basic here, just trying to prove the concept\n\n&amp;#x200B;\n\n|1|New York||\n|:-|:-|:-|\n|2|Florida||\n|3|Oregon||\n|4|New Mexico||\n|5|Texas||\n|6|Colorado||\n\n    {% set my_seed_query %}\n    select * from {{ ref('my_seed_table') }} \n    {% endset %}\n    {% set results = run_query('select * from my_seed_query') %}\n    {% if execute  %}\n    {% set results_sv_list = results.columns[1].values() %}\n    {% else %}\n    {% set results_sv_list = [] %}\n    {% endif %} \n    {% for item in results_sv_list %}\n     {{ print(item) }} \n    {% endfor  %}\n\n&amp;#x200B;\n\nI've tried some variation on this\n\n    with my_seed_query as (\n     select * from {{ ref('my_seed_table') }}\n    )\n    \n    {% set results = run_query('select * from my_seed_query') %}\n    {% if execute  %}\n    {% set results_sv_list = results.columns[1].values() %}\n    {% else %}\n    {% set results_sv_list = [] %}\n    {% endif %}\n    {% for item in results_sv_list %}\n        {{ print(item) }}\n    {% endfor  %}\n\nand also\n\n    {% set my_seed_query %}\n     select * from {{ ref('my_seed_table') }}\n    {% endset %}\n    {% set results = run_query(my_seed_query) %}\n    {% if execute  %}\n    {% set results_sv_list = results.columns[1].values() %}\n    {% else %}\n    {% set results_sv_list = [] %}\n    {% endif %}\n    {% for item in results_sv_list %}\n        {{ print(item) }}\n    {% endfor  %}\n\nAll of the above produce various errors\n\nHowever, the code below works as expected and returns a result table, so the seed table is being resolved with ref(...) command, at least in the scenario below\n\n    with my_seed_query as (\n     select * from {{ ref('my_seed_table') }}\n    )\n    \n    select * from my_seed_query", "author_fullname": "t2_osgmm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt jinja question arounds seeds and loops", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yll0e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667525007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;In the process of teaching myself dbt. Have run into a bit of a snag trying to iterate over a result set from a seed table. Seed table CSV is pretty basic here, just trying to prove the concept&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;1&lt;/th&gt;\n&lt;th align=\"left\"&gt;New York&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;Florida&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;Oregon&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;New Mexico&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;Texas&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;td align=\"left\"&gt;Colorado&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;pre&gt;&lt;code&gt;{% set my_seed_query %}\nselect * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }} \n{% endset %}\n{% set results = run_query(&amp;#39;select * from my_seed_query&amp;#39;) %}\n{% if execute  %}\n{% set results_sv_list = results.columns[1].values() %}\n{% else %}\n{% set results_sv_list = [] %}\n{% endif %} \n{% for item in results_sv_list %}\n {{ print(item) }} \n{% endfor  %}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried some variation on this&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with my_seed_query as (\n select * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }}\n)\n\n{% set results = run_query(&amp;#39;select * from my_seed_query&amp;#39;) %}\n{% if execute  %}\n{% set results_sv_list = results.columns[1].values() %}\n{% else %}\n{% set results_sv_list = [] %}\n{% endif %}\n{% for item in results_sv_list %}\n    {{ print(item) }}\n{% endfor  %}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;and also&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{% set my_seed_query %}\n select * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }}\n{% endset %}\n{% set results = run_query(my_seed_query) %}\n{% if execute  %}\n{% set results_sv_list = results.columns[1].values() %}\n{% else %}\n{% set results_sv_list = [] %}\n{% endif %}\n{% for item in results_sv_list %}\n    {{ print(item) }}\n{% endfor  %}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;All of the above produce various errors&lt;/p&gt;\n\n&lt;p&gt;However, the code below works as expected and returns a result table, so the seed table is being resolved with ref(...) command, at least in the scenario below&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with my_seed_query as (\n select * from {{ ref(&amp;#39;my_seed_table&amp;#39;) }}\n)\n\nselect * from my_seed_query\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yll0e8", "is_robot_indexable": true, "report_reasons": null, "author": "rmz76", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yll0e8/dbt_jinja_question_arounds_seeds_and_loops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yll0e8/dbt_jinja_question_arounds_seeds_and_loops/", "subreddit_subscribers": 78914, "created_utc": 1667525007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data engineers out there,\n\nI wanted to request for a pathway and some resume tips to transition from data integration to data engineering roles.\n\nTo give a background, I have developed data integration APIs using packaged tools and java. I understand how to connect to various source systems, pull out data and perform data mapping to convert data from and between formats like JSON, XML etc.\n\nNow I want to transition into a more technical data pipleline building kind of a role of Data Engineering. \n\nHow and where do I start? Is my background even relevant to data engineering to an extent or is it completely scrap when it comes to data engineering?\n\nAny feedback, pointers, advice would be much appreciated. I am currently looking for Data Engineering internships.", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on Data Integration to Data Engineering transitioning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylcb5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667503955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data engineers out there,&lt;/p&gt;\n\n&lt;p&gt;I wanted to request for a pathway and some resume tips to transition from data integration to data engineering roles.&lt;/p&gt;\n\n&lt;p&gt;To give a background, I have developed data integration APIs using packaged tools and java. I understand how to connect to various source systems, pull out data and perform data mapping to convert data from and between formats like JSON, XML etc.&lt;/p&gt;\n\n&lt;p&gt;Now I want to transition into a more technical data pipleline building kind of a role of Data Engineering. &lt;/p&gt;\n\n&lt;p&gt;How and where do I start? Is my background even relevant to data engineering to an extent or is it completely scrap when it comes to data engineering?&lt;/p&gt;\n\n&lt;p&gt;Any feedback, pointers, advice would be much appreciated. I am currently looking for Data Engineering internships.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ylcb5q", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylcb5q/need_advice_on_data_integration_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylcb5q/need_advice_on_data_integration_to_data/", "subreddit_subscribers": 78914, "created_utc": 1667503955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI built a sample spark-scala etl with maven as a build tool and a janky pom.xml. \n\n[https://github.com/dionesh12/sparkETLScalaExample](https://github.com/dionesh12/sparkETLScalaExample)\n\nI am not a developer nor a tech head  and I basically solve bugs as I go about my day during my previous job.I am as people say \"in between jobs\"  and was extremely motivated today and not burnt out.\n\nI am saying this because I know that the coding standards might not be upto par and probably the wrong flair.\n\nAnyway , please let me know if you found the code example useful. Also please do let me know  if any improvements are needed.\n\nAlso,if you found it helpful   please let me know.", "author_fullname": "t2_ty1lgaw7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Sample Spark Scala ETL Using Maven.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylc13c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667503302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I built a sample spark-scala etl with maven as a build tool and a janky pom.xml. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dionesh12/sparkETLScalaExample\"&gt;https://github.com/dionesh12/sparkETLScalaExample&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am not a developer nor a tech head  and I basically solve bugs as I go about my day during my previous job.I am as people say &amp;quot;in between jobs&amp;quot;  and was extremely motivated today and not burnt out.&lt;/p&gt;\n\n&lt;p&gt;I am saying this because I know that the coding standards might not be upto par and probably the wrong flair.&lt;/p&gt;\n\n&lt;p&gt;Anyway , please let me know if you found the code example useful. Also please do let me know  if any improvements are needed.&lt;/p&gt;\n\n&lt;p&gt;Also,if you found it helpful   please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?auto=webp&amp;s=a040425c8f6fdb325f80332a287d99ae539923b0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f0cfc232b749b98b21f8a10e4e3ed6b709703fa", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=890a1e19437bcecf4469ce3d8ec830b583e33da1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1546b979d22d314ca85224968009672eea48fafa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=21847e3509e223d9898458c6d3a0d8b485d743b3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a52c50195dc4da0171ba08ad9cf09fdd3134ef9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cvAYPHXnQoJ83ehhcRiFQrkJZ52z-_yDcinlBC8Xtlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a903ad2826d36822b72baa43c0e1fa1edd700a15", "width": 1080, "height": 540}], "variants": {}, "id": "KXbRgB3ZA_AFiyLKrvhpL9_M8RRJ8oN7FwkIRwcyx4s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "ylc13c", "is_robot_indexable": true, "report_reasons": null, "author": "krosMios", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylc13c/a_sample_spark_scala_etl_using_maven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylc13c/a_sample_spark_scala_etl_using_maven/", "subreddit_subscribers": 78914, "created_utc": 1667503302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope to land a DE position in the future (1-2 years)\n\n* Is this a good start in terms of skill building?\n* Where should I focus energy in (personal projects/course work)?\n\nAny additional advice would be appreciated as well.\n\nThank y'all for the help. I've been lurking for about 6 months now; excellent community\n\nhttps://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;format=png&amp;auto=webp&amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9", "author_fullname": "t2_b3q17xix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Critique", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"3tiegxo6dzx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f01739e67b03951e665615c96abd638d69a7d56"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5acd58c2f7fc66315918e5a8d0fea85a9facfea2"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bcb526cdf06c50627cd0d46cbad9573d16c4b09b"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aab00e7488d0da4cc766bfe178a20ab97d3c079e"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=05a91b798f7d7f9ed7bdbe6afa8bb6551d7edb47"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17709b3867108f9c1667828d24ce175c1ad4c9f1"}], "s": {"y": 1584, "x": 1224, "u": "https://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;format=png&amp;auto=webp&amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9"}, "id": "3tiegxo6dzx91"}}, "name": "t3_ym6zei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3sMGi_a7jSPF-0MqyPREceP5NDpFwgIhMvLDes3cBf0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope to land a DE position in the future (1-2 years)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is this a good start in terms of skill building?&lt;/li&gt;\n&lt;li&gt;Where should I focus energy in (personal projects/course work)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any additional advice would be appreciated as well.&lt;/p&gt;\n\n&lt;p&gt;Thank y&amp;#39;all for the help. I&amp;#39;ve been lurking for about 6 months now; excellent community&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9\"&gt;https://preview.redd.it/3tiegxo6dzx91.png?width=1224&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=880fa077fadc0aa496e2565d0ec3755f2d85b6b9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ym6zei", "is_robot_indexable": true, "report_reasons": null, "author": "MintLeafSpice", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6zei/resume_critique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6zei/resume_critique/", "subreddit_subscribers": 78914, "created_utc": 1667587754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi guys,\n\nI'm attempting to read in a large number of individual xml files into a spark dataframe. In order to do this using spark-xml I have defined a schema via an xsd file. when asking to read the batch in, spark raises an error that there are duplicates of a certain column. It may be worth noting here that every column in the xmls has a minoccurances of 0 i.e. may or may not exist in any given file, so the schema i am applying to the data on read in uses the nullable=True variable to represent this.\n\nthrough experimentation I have been able to identify an odd occurance, namely:\n\n* in a list of N files, i get the above error of duplicate columns \n* I am able to read the first M files in to a dataframe using my schema fine\n* weirdly I am also able to read the remaining N-M files into another dataframe, also using my schema\n* when producing these two dataframes, their df.schema objects do not match to either each other or to the schema i initially specified\n\nany ideas whats going wrong here? I was under the impression that by providing a schema in the read options, I would be enforcing the schema for the whole table but this is clearly not the case. It also seems odd to me that both halves of the file list can separately be read in using that schema but not together. is this an issue where the schema i have defined is just not being used somehow? \n\n&amp;#x200B;\n\ncheers :)", "author_fullname": "t2_8lxowib5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark XML readin schema error?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ym6x8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m attempting to read in a large number of individual xml files into a spark dataframe. In order to do this using spark-xml I have defined a schema via an xsd file. when asking to read the batch in, spark raises an error that there are duplicates of a certain column. It may be worth noting here that every column in the xmls has a minoccurances of 0 i.e. may or may not exist in any given file, so the schema i am applying to the data on read in uses the nullable=True variable to represent this.&lt;/p&gt;\n\n&lt;p&gt;through experimentation I have been able to identify an odd occurance, namely:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;in a list of N files, i get the above error of duplicate columns &lt;/li&gt;\n&lt;li&gt;I am able to read the first M files in to a dataframe using my schema fine&lt;/li&gt;\n&lt;li&gt;weirdly I am also able to read the remaining N-M files into another dataframe, also using my schema&lt;/li&gt;\n&lt;li&gt;when producing these two dataframes, their df.schema objects do not match to either each other or to the schema i initially specified&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;any ideas whats going wrong here? I was under the impression that by providing a schema in the read options, I would be enforcing the schema for the whole table but this is clearly not the case. It also seems odd to me that both halves of the file list can separately be read in using that schema but not together. is this an issue where the schema i have defined is just not being used somehow? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;cheers :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ym6x8j", "is_robot_indexable": true, "report_reasons": null, "author": "One_Hearing986", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6x8j/spark_xml_readin_schema_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6x8j/spark_xml_readin_schema_error/", "subreddit_subscribers": 78914, "created_utc": 1667587601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL; DR;** Developing end-to-end data science infrastructure can get complex. So we wrote a three-part series of step-by-step tutorials to deploy a Data Science experimentation platform on AWS.\n\n\u2014\n\nHey everybody!\n\nDeveloping end-to-end data science infrastructure can get complex. For example, many of us might have struggled to try to integrate AWS services and deal with configuration, permissions, etc. At [Ploomber](https://ploomber.io/), we\u2019ve worked with many companies in a wide range of industries, such as energy, entertainment, computational chemistry, and genomics, so we are constantly looking for simple solutions to get them started with Data Science in the cloud.\n\nOne of the solutions that have worked best for many companies we\u2019ve worked for is AWS Batch, a service that allows you to execute computational jobs on-demand without managing a cluster. It\u2019s an excellent service for running Data Science and Machine Learning workloads. However, getting a good end-to-end experience is still challenging, so we wrote a detailed blog post series.\n\nhttps://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;format=png&amp;auto=webp&amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720\n\nWe are sharing this three-part series on deploying a Data Science Platform on AWS using our open-source software. By the end of the series, you\u2019ll be able to submit computational jobs to AWS scalable infrastructure with a single command.\n\nThe links:\n\n* [https://ploomber.io/blog/ds-platform-part-i](https://ploomber.io/blog/ds-platform-part-i) \\- Use AWS Batch and test the infrastructure by executing a task in a container\n* [https://ploomber.io/blog/ds-platform-part-ii](https://ploomber.io/blog/ds-platform-part-ii) \\- Configure Amazon ECR to push a Docker image to AWS and configure an S3 bucket to write the output of Data Science experiments.\n* [https://ploomber.io/blog/ds-platform-part-iii](https://ploomber.io/blog/ds-platform-part-iii) \\- Use Ploomber and Soopervisor (our open-source software) to run experiments in parallel and request resources dynamically (CPUs, RAM, and GPUs).\n\nAWS Batch strikes a good balance between ease of use and functionality. However, we\u2019ve learned a few things to optimize it (for example, to reduce container startup time), so we might add a fourth part to the series.\n\nIf you\u2019ve previously used AWS Batch, please share your experience. We\u2019d love to learn from you!\n\nPlease share your suggestions, ideas, and comments in general, as we want to build tools and solutions to make Data Science more accessible for everybody.", "author_fullname": "t2_8fgjjia7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A three-part series on deploying a Data Science Platform on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "media_metadata": {"j7qs8hrpbzx91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=16998f22da2f7f0b986a863417b836c1494c50df"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3114d58f6712e4db055d5d8a6a3f119fa6dc19c"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=481405712c9b7ffc47aca6d17693f02aa0241922"}, {"y": 410, "x": 640, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b3fa0ced8fe2c908e2d0171cf15e2d93c14f828"}], "s": {"y": 512, "x": 798, "u": "https://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;format=png&amp;auto=webp&amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720"}, "id": "j7qs8hrpbzx91"}}, "name": "t3_ym6tk9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL; DR;&lt;/strong&gt; Developing end-to-end data science infrastructure can get complex. So we wrote a three-part series of step-by-step tutorials to deploy a Data Science experimentation platform on AWS.&lt;/p&gt;\n\n&lt;p&gt;\u2014&lt;/p&gt;\n\n&lt;p&gt;Hey everybody!&lt;/p&gt;\n\n&lt;p&gt;Developing end-to-end data science infrastructure can get complex. For example, many of us might have struggled to try to integrate AWS services and deal with configuration, permissions, etc. At &lt;a href=\"https://ploomber.io/\"&gt;Ploomber&lt;/a&gt;, we\u2019ve worked with many companies in a wide range of industries, such as energy, entertainment, computational chemistry, and genomics, so we are constantly looking for simple solutions to get them started with Data Science in the cloud.&lt;/p&gt;\n\n&lt;p&gt;One of the solutions that have worked best for many companies we\u2019ve worked for is AWS Batch, a service that allows you to execute computational jobs on-demand without managing a cluster. It\u2019s an excellent service for running Data Science and Machine Learning workloads. However, getting a good end-to-end experience is still challenging, so we wrote a detailed blog post series.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720\"&gt;https://preview.redd.it/j7qs8hrpbzx91.png?width=798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9f48a6bda45df0deadea2afe78b6adf7a198e720&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We are sharing this three-part series on deploying a Data Science Platform on AWS using our open-source software. By the end of the series, you\u2019ll be able to submit computational jobs to AWS scalable infrastructure with a single command.&lt;/p&gt;\n\n&lt;p&gt;The links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://ploomber.io/blog/ds-platform-part-i\"&gt;https://ploomber.io/blog/ds-platform-part-i&lt;/a&gt; - Use AWS Batch and test the infrastructure by executing a task in a container&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://ploomber.io/blog/ds-platform-part-ii\"&gt;https://ploomber.io/blog/ds-platform-part-ii&lt;/a&gt; - Configure Amazon ECR to push a Docker image to AWS and configure an S3 bucket to write the output of Data Science experiments.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://ploomber.io/blog/ds-platform-part-iii\"&gt;https://ploomber.io/blog/ds-platform-part-iii&lt;/a&gt; - Use Ploomber and Soopervisor (our open-source software) to run experiments in parallel and request resources dynamically (CPUs, RAM, and GPUs).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;AWS Batch strikes a good balance between ease of use and functionality. However, we\u2019ve learned a few things to optimize it (for example, to reduce container startup time), so we might add a fourth part to the series.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019ve previously used AWS Batch, please share your experience. We\u2019d love to learn from you!&lt;/p&gt;\n\n&lt;p&gt;Please share your suggestions, ideas, and comments in general, as we want to build tools and solutions to make Data Science more accessible for everybody.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ym6tk9", "is_robot_indexable": true, "report_reasons": null, "author": "fractalfox11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6tk9/a_threepart_series_on_deploying_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6tk9/a_threepart_series_on_deploying_a_data_science/", "subreddit_subscribers": 78914, "created_utc": 1667587347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm moving some data from MongoDB to Snowflake, and I wanted to know what experienced data engineers would do when they build this ETL.\n\n**Option 1:** Write ETL in pure Python using `pymongo` and `sqlalchemy` without dependency on Airflow operators, such as `MongoToS3Operator` and `SnowflakeOperator` (except `PythonOperator` to call the final script). Once Python script is built, I can use Airflow only to call the ETL script. For me, the biggest appeal to this approach is that I can run this ETL line by line if I wanted to.\n\n**Option 2:** Write ETL using Airflow operators, such as `MongoToS3Operator` and `SnowflakeOperator`. Provided that I have access to a S3 bucket, I can use `MongoToS3Operator` to move data from MongoDB to S3, then use `SnowflakeOperator` to move data from S3 to Snowflake. This allows data transfer from MongoDB to Snowflake using only two Airflow operators.\n\nI personally prefer `Option 1` because I like being able to execute code line by line to see what's happening each step of the way. But `Option 2` may be more modern and elegant. Maybe I'm missing something about `Option 2`?", "author_fullname": "t2_ers4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving data from MongoDB to Snowflake using Apache Airflow: Would you use pure Python or use Airflow operators?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ym6pjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667587344.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667587080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving some data from MongoDB to Snowflake, and I wanted to know what experienced data engineers would do when they build this ETL.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Write ETL in pure Python using &lt;code&gt;pymongo&lt;/code&gt; and &lt;code&gt;sqlalchemy&lt;/code&gt; without dependency on Airflow operators, such as &lt;code&gt;MongoToS3Operator&lt;/code&gt; and &lt;code&gt;SnowflakeOperator&lt;/code&gt; (except &lt;code&gt;PythonOperator&lt;/code&gt; to call the final script). Once Python script is built, I can use Airflow only to call the ETL script. For me, the biggest appeal to this approach is that I can run this ETL line by line if I wanted to.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; Write ETL using Airflow operators, such as &lt;code&gt;MongoToS3Operator&lt;/code&gt; and &lt;code&gt;SnowflakeOperator&lt;/code&gt;. Provided that I have access to a S3 bucket, I can use &lt;code&gt;MongoToS3Operator&lt;/code&gt; to move data from MongoDB to S3, then use &lt;code&gt;SnowflakeOperator&lt;/code&gt; to move data from S3 to Snowflake. This allows data transfer from MongoDB to Snowflake using only two Airflow operators.&lt;/p&gt;\n\n&lt;p&gt;I personally prefer &lt;code&gt;Option 1&lt;/code&gt; because I like being able to execute code line by line to see what&amp;#39;s happening each step of the way. But &lt;code&gt;Option 2&lt;/code&gt; may be more modern and elegant. Maybe I&amp;#39;m missing something about &lt;code&gt;Option 2&lt;/code&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym6pjw", "is_robot_indexable": true, "report_reasons": null, "author": "feelosophy13", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6pjw/moving_data_from_mongodb_to_snowflake_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6pjw/moving_data_from_mongodb_to_snowflake_using/", "subreddit_subscribers": 78914, "created_utc": 1667587080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I've been a customer for ~ 4 years and loved their service / onboarding experience. My company uses Databricks on AWS.\n\nRecently, my team decided we needed to migrate to a [customer-managed VPC](https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html) deployment to accommodate other org wide architecture changes.\n\nOur prod and dev accounts were old and did not support this feature, so we had to create new ones. It turned out that this process was way more stressful than needed:\n\n- Their support is absolutely terrible. It took like 20 days just to confirm we needed to create a new account. \n\n- The new UI is sooooo buggy. I feel like I'm having a new issue every day.\n\nIs anyone having similar experiences? My company mostly uses Databricks to run infrequent Spark jobs, and we often think about trying out other features. The last few weeks, however, have made me really insecure about increasing our dependence on their products.", "author_fullname": "t2_h2eg6ehc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone having bad experiences with Databricks support / accounts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ym6krd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667586755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a customer for ~ 4 years and loved their service / onboarding experience. My company uses Databricks on AWS.&lt;/p&gt;\n\n&lt;p&gt;Recently, my team decided we needed to migrate to a &lt;a href=\"https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html\"&gt;customer-managed VPC&lt;/a&gt; deployment to accommodate other org wide architecture changes.&lt;/p&gt;\n\n&lt;p&gt;Our prod and dev accounts were old and did not support this feature, so we had to create new ones. It turned out that this process was way more stressful than needed:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Their support is absolutely terrible. It took like 20 days just to confirm we needed to create a new account. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The new UI is sooooo buggy. I feel like I&amp;#39;m having a new issue every day.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is anyone having similar experiences? My company mostly uses Databricks to run infrequent Spark jobs, and we often think about trying out other features. The last few weeks, however, have made me really insecure about increasing our dependence on their products.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym6krd", "is_robot_indexable": true, "report_reasons": null, "author": "pid-1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6krd/anyone_having_bad_experiences_with_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6krd/anyone_having_bad_experiences_with_databricks/", "subreddit_subscribers": 78914, "created_utc": 1667586755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nSo for a personal project, i have a script that pulls data from an api and ports it into snowflake. I want to visualize this data somehow and was curious to know what the best options are. snowflake does have a dashboards section, but are there better options that would make this stand out and/or something industry would really like to see?\n\n&amp;#x200B;\n\nThanks in advance!", "author_fullname": "t2_120yfzjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data in snowflake , how to visualize", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ym6cw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667586241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;So for a personal project, i have a script that pulls data from an api and ports it into snowflake. I want to visualize this data somehow and was curious to know what the best options are. snowflake does have a dashboards section, but are there better options that would make this stand out and/or something industry would really like to see?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ym6cw3", "is_robot_indexable": true, "report_reasons": null, "author": "jin_liang", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym6cw3/data_in_snowflake_how_to_visualize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym6cw3/data_in_snowflake_how_to_visualize/", "subreddit_subscribers": 78914, "created_utc": 1667586241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kot5xpvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": true, "name": "t3_ym59e3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 64, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TLMktHLDXE-0Xd0UXN_fQUvESKJLDiF04zC2XQbqNjw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667583655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/comm/jobs/view/3342563509/?trackingId=%2FTIp%2FqzSTNyrJB3Up48HNQ%3D%3D&amp;refId=pb0UiePASlWRdJjevZONPw%3D%3D&amp;lipi=LzhrYz6kRt2aH6RrzaW5dQ%3D%3D&amp;midToken=AQG5NP8I4klw2g&amp;midSig=00_FJMUnaq5Gw1&amp;trk=eml-jobs_jymbii_digest-job_card-0-jobcard_body&amp;trkEmail=eml-jobs_jymbii_digest-job_card-0-jobcard_body-null-6ljjld~la2rvuad~5p-null-null&amp;eid=6ljjld-la2rvuad-5p", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;s=52cc36e047bdca039326e84d3b7ce7aabaf12be6", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ym59e3", "is_robot_indexable": true, "report_reasons": null, "author": "BigLeagueChu06", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym59e3/data_engineering_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/comm/jobs/view/3342563509/?trackingId=%2FTIp%2FqzSTNyrJB3Up48HNQ%3D%3D&amp;refId=pb0UiePASlWRdJjevZONPw%3D%3D&amp;lipi=LzhrYz6kRt2aH6RrzaW5dQ%3D%3D&amp;midToken=AQG5NP8I4klw2g&amp;midSig=00_FJMUnaq5Gw1&amp;trk=eml-jobs_jymbii_digest-job_card-0-jobcard_body&amp;trkEmail=eml-jobs_jymbii_digest-job_card-0-jobcard_body-null-6ljjld~la2rvuad~5p-null-null&amp;eid=6ljjld-la2rvuad-5p", "subreddit_subscribers": 78914, "created_utc": 1667583655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nWe need to pull files (containing unstructured (plain text or html) or semi structured data (xml)) from an API on routine basis for stock market symbols and store the symbol + file data. The file data would then be used by data scientists for variety of things such as sentiment analysis etc.\n\nI need suggestions on how to persist this data efficiently and I am thinking of two options:\n\n\\- Store everything in Snowflake tables.. say with two columns (SYMBOL, TRANSCRIPT) and have data scientists use this table for their processing\n\n\\- Store the file in external staging area (S3 in this case) in a delimited format with compression.. say a CSV file with two columns SYMBOL, TRANSCRIPT.. And then have the data scientists query it directly from external stage for further processing.\n\nI am inclined to to choose second option (storing in S3) as it might cost effective, but having everything in Snowflake seems more convenient option as it eliminates external cloud dependencies.  Also I believe some of the traditional SQL functions don't work while querying data from external staging. So second option also has that limitation, but the data can always be moved in to temp tables for processing if needed.\n\nI would to get this sub's thoughts on this. Any other options apart from these two are welcome too.\n\nthanks.", "author_fullname": "t2_jfqnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing unstructured/semi structured data in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ym5997", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667583905.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667583644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;We need to pull files (containing unstructured (plain text or html) or semi structured data (xml)) from an API on routine basis for stock market symbols and store the symbol + file data. The file data would then be used by data scientists for variety of things such as sentiment analysis etc.&lt;/p&gt;\n\n&lt;p&gt;I need suggestions on how to persist this data efficiently and I am thinking of two options:&lt;/p&gt;\n\n&lt;p&gt;- Store everything in Snowflake tables.. say with two columns (SYMBOL, TRANSCRIPT) and have data scientists use this table for their processing&lt;/p&gt;\n\n&lt;p&gt;- Store the file in external staging area (S3 in this case) in a delimited format with compression.. say a CSV file with two columns SYMBOL, TRANSCRIPT.. And then have the data scientists query it directly from external stage for further processing.&lt;/p&gt;\n\n&lt;p&gt;I am inclined to to choose second option (storing in S3) as it might cost effective, but having everything in Snowflake seems more convenient option as it eliminates external cloud dependencies.  Also I believe some of the traditional SQL functions don&amp;#39;t work while querying data from external staging. So second option also has that limitation, but the data can always be moved in to temp tables for processing if needed.&lt;/p&gt;\n\n&lt;p&gt;I would to get this sub&amp;#39;s thoughts on this. Any other options apart from these two are welcome too.&lt;/p&gt;\n\n&lt;p&gt;thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ym5997", "is_robot_indexable": true, "report_reasons": null, "author": "curidpostn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym5997/storing_unstructuredsemi_structured_data_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym5997/storing_unstructuredsemi_structured_data_in/", "subreddit_subscribers": 78914, "created_utc": 1667583644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Databricks noob question here.\n\nWe have delta tables created via Databricks job and stored in an S3 bucket. Now we want to allow users in a Databricks workspace to read this delta table. What would be the \"proper\" way to do that, in order to optimize performances?\n\nCurrently, we use mount points to provide access to the table under dbfs/mnt. Should we instead import the table in the workspace catalog by CREATE TABLE AS &lt;table&gt; LOCATION s3:/&lt;s3_path&gt; and then possibly run optimize zorder to reduce query time for specific queries? Or are there other approaches?", "author_fullname": "t2_zlyww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making Delta tables available in Databricks Workspace", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym579k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667583509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Databricks noob question here.&lt;/p&gt;\n\n&lt;p&gt;We have delta tables created via Databricks job and stored in an S3 bucket. Now we want to allow users in a Databricks workspace to read this delta table. What would be the &amp;quot;proper&amp;quot; way to do that, in order to optimize performances?&lt;/p&gt;\n\n&lt;p&gt;Currently, we use mount points to provide access to the table under dbfs/mnt. Should we instead import the table in the workspace catalog by CREATE TABLE AS &amp;lt;table&amp;gt; LOCATION s3:/&amp;lt;s3_path&amp;gt; and then possibly run optimize zorder to reduce query time for specific queries? Or are there other approaches?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ym579k", "is_robot_indexable": true, "report_reasons": null, "author": "francesco1093", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym579k/making_delta_tables_available_in_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym579k/making_delta_tables_available_in_databricks/", "subreddit_subscribers": 78914, "created_utc": 1667583509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to get databricks jobs details like their name, job id, scheduling info, etc in a databricks notebook without using any APIs? PS: Both jobs and notebook run on the same cluster.", "author_fullname": "t2_bigv1te1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to get this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ym275i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667576282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to get databricks jobs details like their name, job id, scheduling info, etc in a databricks notebook without using any APIs? PS: Both jobs and notebook run on the same cluster.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ym275i", "is_robot_indexable": true, "report_reasons": null, "author": "SD_strange", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ym275i/is_it_possible_to_get_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ym275i/is_it_possible_to_get_this/", "subreddit_subscribers": 78914, "created_utc": 1667576282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious to know if anyone has worked with MongoDB in cases where the resume point it lost. \n\nThere are cases where the connectivity between the consumer (eg NodeJS) app loses the connection. If the connection is down for long enough the MongoDB oplog overflows so you can never resume from that point again.\n\nWhat are some patterns you would use to handle this scenario?\n\nMy immediate thought is well, we log the time when the failure occurred. We then simply query Mongo directly for any documents updated from that point. Then resume streaming.\n\nI can\u2019t help but think there\u2019s a cleaner pattern\ud83e\udd14", "author_fullname": "t2_htptc13q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MongoDB ChangeStream Connection Failure Handling - ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ylkr1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667524293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious to know if anyone has worked with MongoDB in cases where the resume point it lost. &lt;/p&gt;\n\n&lt;p&gt;There are cases where the connectivity between the consumer (eg NodeJS) app loses the connection. If the connection is down for long enough the MongoDB oplog overflows so you can never resume from that point again.&lt;/p&gt;\n\n&lt;p&gt;What are some patterns you would use to handle this scenario?&lt;/p&gt;\n\n&lt;p&gt;My immediate thought is well, we log the time when the failure occurred. We then simply query Mongo directly for any documents updated from that point. Then resume streaming.&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t help but think there\u2019s a cleaner pattern\ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ylkr1a", "is_robot_indexable": true, "report_reasons": null, "author": "Main_Tap_1256", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ylkr1a/mongodb_changestream_connection_failure_handling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ylkr1a/mongodb_changestream_connection_failure_handling/", "subreddit_subscribers": 78914, "created_utc": 1667524293.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}