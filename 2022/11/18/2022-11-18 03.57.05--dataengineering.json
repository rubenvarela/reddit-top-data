{"kind": "Listing", "data": {"after": "t3_yxq1tz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022](https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022)\n\nhttps://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake syntax now supports EXCLUDE &amp; RENAME syntax", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2inizkec1l0a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=85d741105d8ef05ce7c42be9d2af06a5d179f45e"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ecb6f641cd7233c41845b4f71fb41be60c846b1"}, {"y": 220, "x": 320, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=57848927e730cd8d034eca8ccbba32b9c7debf6b"}, {"y": 441, "x": 640, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3b86381cf41be58dfcfcf05be1c76a56636521f"}, {"y": 662, "x": 960, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=053f1ce7e93e936e264c6a26473285d8679a733c"}, {"y": 745, "x": 1080, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=44c72166f2ea2a1d0ff634bcc062030f1fefa452"}], "s": {"y": 1122, "x": 1626, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140"}, "id": "2inizkec1l0a1"}}, "name": "t3_yy2qmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/EoS_04k_K4mUGKbAQjIfCamP4I8q4XHt2bNXAMErctA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1668721951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022\"&gt;https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140\"&gt;https://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?auto=webp&amp;s=6c4577b4b27b2f3cb213abccd9a9bc589d2418e8", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=71451e9c1cc16528fbc34507862665d8183081d3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8af2e536d48b791bafcedfbdb5728346e2109f22", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=92e856a3642fc42087b7e751258cdac62f23ffd2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dab18af7e3da9431e2dc8d67e6ec0260f7f47c35", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=69266347b991e43b5cc29f5d1bbc90260fa577e2", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7badca4ca72a246b97ad3a9eb03a5238751e16b1", "width": 1080, "height": 567}], "variants": {}, "id": "DZ6ZkB53QxWcONahOQnFN7Kkze2JZoFjE1YqqJfitLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy2qmg", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy2qmg/snowflake_syntax_now_supports_exclude_rename/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy2qmg/snowflake_syntax_now_supports_exclude_rename/", "subreddit_subscribers": 80264, "created_utc": 1668721951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Zach wilson on linkedin said that rust is going to have a great future in data engineering, what do you think about that?", "author_fullname": "t2_th46eirx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust in data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxj5fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668667723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Zach wilson on linkedin said that rust is going to have a great future in data engineering, what do you think about that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxj5fz", "is_robot_indexable": true, "report_reasons": null, "author": "PopTheTenYasha", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxj5fz/rust_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxj5fz/rust_in_data_engineering/", "subreddit_subscribers": 80264, "created_utc": 1668667723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I would like to propose an open-source metadata management and data governance tool in my company.\n\n   \nWe use Kubernetes as our deployment platform.   \nAny feedback on one of these open source data catalogs ?  \n  \\- [https://atlas.apache.org/#/](https://atlas.apache.org/#/)  \n  \\- [https://opendatadiscovery.org/](https://opendatadiscovery.org/)  \n  \\- [https://open-metadata.org/](https://open-metadata.org/)  \n  \\- [https://marquezproject.github.io/marquez/](https://marquezproject.github.io/marquez/)  \n  \\- [https://datahubproject.io/](https://datahubproject.io/)  \n  \\- [https://www.amundsen.io/](https://www.amundsen.io/)  \n  \\- [https://ckan.org/](https://ckan.org/)  \n  \\- [https://magda.io/](https://magda.io/)", "author_fullname": "t2_10vw8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metadata Store - Which one to Choose ? OpenMetadata vs Datahub ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxrh9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668694611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I would like to propose an open-source metadata management and data governance tool in my company.&lt;/p&gt;\n\n&lt;p&gt;We use Kubernetes as our deployment platform.&lt;br/&gt;\nAny feedback on one of these open source data catalogs ?&lt;br/&gt;\n  - &lt;a href=\"https://atlas.apache.org/#/\"&gt;https://atlas.apache.org/#/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://opendatadiscovery.org/\"&gt;https://opendatadiscovery.org/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://open-metadata.org/\"&gt;https://open-metadata.org/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://marquezproject.github.io/marquez/\"&gt;https://marquezproject.github.io/marquez/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://datahubproject.io/\"&gt;https://datahubproject.io/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://www.amundsen.io/\"&gt;https://www.amundsen.io/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://ckan.org/\"&gt;https://ckan.org/&lt;/a&gt;&lt;br/&gt;\n  - &lt;a href=\"https://magda.io/\"&gt;https://magda.io/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxrh9y", "is_robot_indexable": true, "report_reasons": null, "author": "MoiSanh", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxrh9y/metadata_store_which_one_to_choose_openmetadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxrh9y/metadata_store_which_one_to_choose_openmetadata/", "subreddit_subscribers": 80264, "created_utc": 1668694611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ez8d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MotherDuck scores $47.5m to prove scale-up databases are not quackers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_yxo09b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xDt98sOzCHeuymb3U-ihUEOVA7co6_K0D0fa9Ztn8eI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668685031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theregister.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theregister.com/2022/11/17/475_million_says_scaleup_databases/?utm_medium=share&amp;utm_content=article&amp;utm_source=reddit", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?auto=webp&amp;s=0dfa7d8b0152756a1773dc38b2ce42b98316c558", "width": 648, "height": 429}, "resolutions": [{"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8bafdd5d56d30718219f5dd49d8334eb00a881d0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04d45f0757d64120d60590dc6279ac82a04cfc9c", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=35f359e75f60d3e14dda780dbee0f3473056d3a5", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce6a0f7efba4a56836e229bd30394b60e4b8fb32", "width": 640, "height": 423}], "variants": {}, "id": "C4Zahor1I_MVU7Ugl_ADOspvaGrRqoIqcYaEHgflLTM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yxo09b", "is_robot_indexable": true, "report_reasons": null, "author": "Bazencourt", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxo09b/motherduck_scores_475m_to_prove_scaleup_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theregister.com/2022/11/17/475_million_says_scaleup_databases/?utm_medium=share&amp;utm_content=article&amp;utm_source=reddit", "subreddit_subscribers": 80264, "created_utc": 1668685031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you guys take care of timestamp columns during daylight savings off for streaming data pipelines ?, We had an issue where because of daylight savings off , timestamp difference between source and target is different as time will fall back. How do you solve this in your team/company ? TIA", "author_fullname": "t2_3ep37bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daylight savings off - Data Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxq8rl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668691663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you guys take care of timestamp columns during daylight savings off for streaming data pipelines ?, We had an issue where because of daylight savings off , timestamp difference between source and target is different as time will fall back. How do you solve this in your team/company ? TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxq8rl", "is_robot_indexable": true, "report_reasons": null, "author": "chanu4dincha", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxq8rl/daylight_savings_off_data_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxq8rl/daylight_savings_off_data_issue/", "subreddit_subscribers": 80264, "created_utc": 1668691663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all! I\u2019m currently a Data Engineering Manager at a big tech company (FAANG) and I find myself kind of done with management. I\u2019m wondering what it would take to switch to an IC role? I have a solid knowledge of SQL and good knowledge of python but not a whole lot of experience on the other modern tech stacks and generally a bit out of touch with coding with about 6 years of management experience. How much of a step down would I have to take to get familiar with things like real-time streaming data, API development etc. ? I don\u2019t mind taking a break to prepare myself but find it hard to figure out what would give me the best bang for my buck (certs? Projects?). Thoughts?", "author_fullname": "t2_3x1kych3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager to IC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy676j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668731044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! I\u2019m currently a Data Engineering Manager at a big tech company (FAANG) and I find myself kind of done with management. I\u2019m wondering what it would take to switch to an IC role? I have a solid knowledge of SQL and good knowledge of python but not a whole lot of experience on the other modern tech stacks and generally a bit out of touch with coding with about 6 years of management experience. How much of a step down would I have to take to get familiar with things like real-time streaming data, API development etc. ? I don\u2019t mind taking a break to prepare myself but find it hard to figure out what would give me the best bang for my buck (certs? Projects?). Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yy676j", "is_robot_indexable": true, "report_reasons": null, "author": "Alone-Investment", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy676j/manager_to_ic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy676j/manager_to_ic/", "subreddit_subscribers": 80264, "created_utc": 1668731044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is working with vibrations analytics. We are manually measure some component and got WAV file. In order to analysis it, we convert the content to numpy array. In the future we are going to receive this data from a sensor and need to convert the data to a unified schema.\n\nThis array might be really large ( &gt; 500K items) and we also need to record some metadata on each measurement. This additional data can be measured\\_time, component, site of the record...\n\nThe question is what will be the best way to store it to answer on queries like: give me all the measurements from 2020-01-01 for the component \"motor\"?\n\nWhat we tried so far:\n\n1. Store in relational DB with star schema where the facts table contains a file name. Later we download the relevant content. This can't work since we might get data in JSON array format without a compound file.\n2. Store the measurements in a large Parquet files in a Hive format in GCS. Create a BigQuery table with id and measurement content as binary data in Hive structure. Later, move the metadata to BigQuery as well and join it with the previous table.This is better since we don't use files anymore and can handle any format of data. However, we reach the BigQuery limit on the size of the data ( the data can be really large)\n\nError:\n\ngoogle.api\\_core.exceptions.BadRequest: 400 Resources exceeded during query execution: Out of memory. Failed to import values for column 'content' This might happen if the file contains a row that is too large, or if the total size of the pages loaded for the queried columns is too large.; Failed to read Parquet file /bigstore/vibrations-samples/date=2022-08-30/sample\\_2022-08-30.parquet. This might happen if the file contains a row that is too large, or if the total size of the pages loaded for the queried columns is too large.\n\nIs this modeling issue or I can just increase some BQ config?\n\nThanks", "author_fullname": "t2_ll7atfr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Store WAV files data into BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxrjhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668695285.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668694773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is working with vibrations analytics. We are manually measure some component and got WAV file. In order to analysis it, we convert the content to numpy array. In the future we are going to receive this data from a sensor and need to convert the data to a unified schema.&lt;/p&gt;\n\n&lt;p&gt;This array might be really large ( &amp;gt; 500K items) and we also need to record some metadata on each measurement. This additional data can be measured_time, component, site of the record...&lt;/p&gt;\n\n&lt;p&gt;The question is what will be the best way to store it to answer on queries like: give me all the measurements from 2020-01-01 for the component &amp;quot;motor&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;What we tried so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Store in relational DB with star schema where the facts table contains a file name. Later we download the relevant content. This can&amp;#39;t work since we might get data in JSON array format without a compound file.&lt;/li&gt;\n&lt;li&gt;Store the measurements in a large Parquet files in a Hive format in GCS. Create a BigQuery table with id and measurement content as binary data in Hive structure. Later, move the metadata to BigQuery as well and join it with the previous table.This is better since we don&amp;#39;t use files anymore and can handle any format of data. However, we reach the BigQuery limit on the size of the data ( the data can be really large)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Error:&lt;/p&gt;\n\n&lt;p&gt;google.api_core.exceptions.BadRequest: 400 Resources exceeded during query execution: Out of memory. Failed to import values for column &amp;#39;content&amp;#39; This might happen if the file contains a row that is too large, or if the total size of the pages loaded for the queried columns is too large.; Failed to read Parquet file /bigstore/vibrations-samples/date=2022-08-30/sample_2022-08-30.parquet. This might happen if the file contains a row that is too large, or if the total size of the pages loaded for the queried columns is too large.&lt;/p&gt;\n\n&lt;p&gt;Is this modeling issue or I can just increase some BQ config?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxrjhf", "is_robot_indexable": true, "report_reasons": null, "author": "Leon_Bam", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxrjhf/store_wav_files_data_into_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxrjhf/store_wav_files_data_into_bigquery/", "subreddit_subscribers": 80264, "created_utc": 1668694773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm not interested in the cert,  just in the Content in the course.\n\n&amp;#x200B;\n\nDoes anyone know which is better?", "author_fullname": "t2_a9icd9le", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM Data Engineering Professional Certificate Or Meta Data Engineer Cert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxnu68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668684490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not interested in the cert,  just in the Content in the course.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone know which is better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxnu68", "is_robot_indexable": true, "report_reasons": null, "author": "Then_Landscape6474", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxnu68/ibm_data_engineering_professional_certificate_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxnu68/ibm_data_engineering_professional_certificate_or/", "subreddit_subscribers": 80264, "created_utc": 1668684490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing YAML Data Modeling in Cube, the headless BI platform\u2014goodbye, JavaScript", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yxtm3z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dcZl0R8JbX0fLO3neSWrO3Co6MlStxvLSTnQZaDOR6o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668700100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-cube-support-for-yaml-data-modeling", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?auto=webp&amp;s=70f5d72a00d9591117dad065c302e8000bfae673", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=574bae08b02252c74b3eadf29a8e065c0b6da172", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6bef6a5f7c7a29634da9704d4078870a1add4b73", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1d0c1e1b94073d4b1016ef19d6e685fb442133bb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2d8f39ec54712b2476b09190de32484f2bba2ba", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e87f295629c5589636e83c4ae41cb2341e6a1b3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/NB2qyp82AET0ff_tvlpuH5r_9GPEqCHk7NyB-XM_3rg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e0f9cbe459cc97c6d9e0e75162490739ffef3996", "width": 1080, "height": 567}], "variants": {}, "id": "VtTqNdgZSXnTbk2mzaCyMvkS473GvRDuf-RnYWRn3JM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yxtm3z", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxtm3z/introducing_yaml_data_modeling_in_cube_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-cube-support-for-yaml-data-modeling", "subreddit_subscribers": 80264, "created_utc": 1668700100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_73sd7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using StarRocks DB instead of ClickHouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_yxo6hd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NcOQ8WSDZdQ_DEzTyqaMj2WlVRiwS881k2PBILrhIr8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668685584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/StarRocks/StarRocks", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?auto=webp&amp;s=154e9fa3405ff9149ccffc08b770363fd2302b70", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=56bc3a6e306285fab823bc833ece979a93645d69", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d397ea2b0dd2e2229b1178f4693a615c414b7075", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0159b401ff7e1333a3ad97dd115fe8abc5c3a29e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=543cc6f54952604b6aaa1f5061bbe26397758647", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffa8542f33ba8cc0bcfd97e537ecbd0ea83a1fc4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5bfd99f2987fbe60113e4099b6ad26eefb9e1e8", "width": 1080, "height": 540}], "variants": {}, "id": "BB_cFx1_beS1zbZZ7YrZr7olAiCnnZknb9WMiVbKkyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yxo6hd", "is_robot_indexable": true, "report_reasons": null, "author": "intellidumb", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxo6hd/anyone_using_starrocks_db_instead_of_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/StarRocks/StarRocks", "subreddit_subscribers": 80264, "created_utc": 1668685584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this pipeline that heavily relies on our database. Every transformation needs a piece of data from a different column and therefore, we do a lot of selects and joins. \n\nManagement is complaining that when ingestion is running, the database consumption is increasing, which makes our application slow to reach the final customer\n\nWhat if I create a replica database, perform all the calculations, and then sync back to the production database? Does this sound like a good solution?", "author_fullname": "t2_3p0fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does it make sense to have a replica database for a data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxypaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668712363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this pipeline that heavily relies on our database. Every transformation needs a piece of data from a different column and therefore, we do a lot of selects and joins. &lt;/p&gt;\n\n&lt;p&gt;Management is complaining that when ingestion is running, the database consumption is increasing, which makes our application slow to reach the final customer&lt;/p&gt;\n\n&lt;p&gt;What if I create a replica database, perform all the calculations, and then sync back to the production database? Does this sound like a good solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yxypaq", "is_robot_indexable": true, "report_reasons": null, "author": "Croves", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxypaq/does_it_make_sense_to_have_a_replica_database_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxypaq/does_it_make_sense_to_have_a_replica_database_for/", "subreddit_subscribers": 80264, "created_utc": 1668712363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe have an Airflow MWAA cluster and huge volume of Data in our Redshift data warehouse. We currently process the data directly in Redshift (w/ SQL) but given the amount of data, this puts a lot of pressure in the data warehouse and it is less and less resilient.\n\nA potential solution we found would be to decouple the data storage (Redshift) from the data processing (Spark), first of all, what do you think about this solution?\n\nTo do this, we would like to use Airflow MWAA and SparkSQL to:\n\n\\- Transfer data from Redshift to Spark\n\n\\- Process the SQL scripts that were previously done in Redshift\n\n\\- Transfer the newly created table from Spark to Redshift  \n\n\nIs it a use case that someone here has already put in production?\n\n  \nWhat would in your opinion be the best way to interact with the Spark Cluster ? EmrAddStepsOperator vs PythonOperator + PySpark?\n\nThank you!", "author_fullname": "t2_f1ixi4vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to process Redshift data on Spark (EMR) via Airflow MWAA ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxo2e1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668685220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We have an Airflow MWAA cluster and huge volume of Data in our Redshift data warehouse. We currently process the data directly in Redshift (w/ SQL) but given the amount of data, this puts a lot of pressure in the data warehouse and it is less and less resilient.&lt;/p&gt;\n\n&lt;p&gt;A potential solution we found would be to decouple the data storage (Redshift) from the data processing (Spark), first of all, what do you think about this solution?&lt;/p&gt;\n\n&lt;p&gt;To do this, we would like to use Airflow MWAA and SparkSQL to:&lt;/p&gt;\n\n&lt;p&gt;- Transfer data from Redshift to Spark&lt;/p&gt;\n\n&lt;p&gt;- Process the SQL scripts that were previously done in Redshift&lt;/p&gt;\n\n&lt;p&gt;- Transfer the newly created table from Spark to Redshift  &lt;/p&gt;\n\n&lt;p&gt;Is it a use case that someone here has already put in production?&lt;/p&gt;\n\n&lt;p&gt;What would in your opinion be the best way to interact with the Spark Cluster ? EmrAddStepsOperator vs PythonOperator + PySpark?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yxo2e1", "is_robot_indexable": true, "report_reasons": null, "author": "No_Fudge1060", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxo2e1/best_way_to_process_redshift_data_on_spark_emr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxo2e1/best_way_to_process_redshift_data_on_spark_emr/", "subreddit_subscribers": 80264, "created_utc": 1668685220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If anyone interested in azure Synapse analytics,this tutorial will help you, thanks in advance\n\n https://link.medium.com/sEunVJMy1ub", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synapse analytics Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxkntn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668673218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone interested in azure Synapse analytics,this tutorial will help you, thanks in advance&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://link.medium.com/sEunVJMy1ub\"&gt;https://link.medium.com/sEunVJMy1ub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?auto=webp&amp;s=f11dbc436c657ece1988f8a0696d30532e132605", "width": 1046, "height": 299}, "resolutions": [{"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7959609354bba23f902617c582da5965d3488ec5", "width": 108, "height": 30}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a489b5381f4513bafa288a0d123687509d4c31b", "width": 216, "height": 61}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=138c723f9a18485b0327662c489e61db4c372451", "width": 320, "height": 91}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=29ff8d270da4084f76dd28acf9741b6071f2704a", "width": 640, "height": 182}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97732932532733856da7f96d63f541e14cc71e20", "width": 960, "height": 274}], "variants": {}, "id": "dvGCojG4WDv9ttbAGYv6q4tpdoIRh-oYoL_pelyJocU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yxkntn", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxkntn/synapse_analytics_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxkntn/synapse_analytics_tutorial/", "subreddit_subscribers": 80264, "created_utc": 1668673218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have ELT job that has to loop through an API to extract all Invoice line items per invoice. I have made an API call for each invoice at a time  currently, the job can take up 3 hours to run. just needed suggestions and advice in improving the performance. I am thinking of using Spark to parallel processes against the API. If you have recommendations, please let me know.", "author_fullname": "t2_6mggwqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API pagination performance issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxh4hk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668661245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have ELT job that has to loop through an API to extract all Invoice line items per invoice. I have made an API call for each invoice at a time  currently, the job can take up 3 hours to run. just needed suggestions and advice in improving the performance. I am thinking of using Spark to parallel processes against the API. If you have recommendations, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yxh4hk", "is_robot_indexable": true, "report_reasons": null, "author": "Professional-Goal892", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxh4hk/api_pagination_performance_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxh4hk/api_pagination_performance_issues/", "subreddit_subscribers": 80264, "created_utc": 1668661245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm about to graduate with a DS bachelor's, and i've studied the fundamentals of programming and data structures/algorithm's. I want to expand my knowledge in the SE aspect of things. Is there a way to get there through courses/master's? Thank you.", "author_fullname": "t2_tqogom2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to get into DE/SE from a DS Bachelor's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy7gol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668734792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to graduate with a DS bachelor&amp;#39;s, and i&amp;#39;ve studied the fundamentals of programming and data structures/algorithm&amp;#39;s. I want to expand my knowledge in the SE aspect of things. Is there a way to get there through courses/master&amp;#39;s? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yy7gol", "is_robot_indexable": true, "report_reasons": null, "author": "subte_rancio", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy7gol/is_it_possible_to_get_into_dese_from_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy7gol/is_it_possible_to_get_into_dese_from_a_ds/", "subreddit_subscribers": 80264, "created_utc": 1668734792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my SE major, I put my focus on DS and ML. At the time I did this, I wasn't even aware of DE. Too bad there isn't even something directly relevant for Data Engineering to study in uni.\n\nThere are lots of Junior Data Science positions. There are barely any Junior Data Engineer positions. Hence, let's say I wouldn't be able to get into one after graduating.\n\n&amp;#x200B;\n\nWould 'Junior Data Scientist' be acceptable as career entry point for Data Engineering? I am quite aware of the overlap and the differences. I think I found out I enjoy 'real' software engineering more, and DE is much more real SE than DS is. But as a DS junior position will likely still heavily require skills such as Python, SQL, dashboards probably, it would still make a lot of sense to take it, right? Are there any other positions that would make sense as starting point, besides DS and DE obviously?", "author_fullname": "t2_136crg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science position acceptable as entry job for a road to a DE career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy19ir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668718361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my SE major, I put my focus on DS and ML. At the time I did this, I wasn&amp;#39;t even aware of DE. Too bad there isn&amp;#39;t even something directly relevant for Data Engineering to study in uni.&lt;/p&gt;\n\n&lt;p&gt;There are lots of Junior Data Science positions. There are barely any Junior Data Engineer positions. Hence, let&amp;#39;s say I wouldn&amp;#39;t be able to get into one after graduating.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would &amp;#39;Junior Data Scientist&amp;#39; be acceptable as career entry point for Data Engineering? I am quite aware of the overlap and the differences. I think I found out I enjoy &amp;#39;real&amp;#39; software engineering more, and DE is much more real SE than DS is. But as a DS junior position will likely still heavily require skills such as Python, SQL, dashboards probably, it would still make a lot of sense to take it, right? Are there any other positions that would make sense as starting point, besides DS and DE obviously?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yy19ir", "is_robot_indexable": true, "report_reasons": null, "author": "Boruroku", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy19ir/data_science_position_acceptable_as_entry_job_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy19ir/data_science_position_acceptable_as_entry_job_for/", "subreddit_subscribers": 80264, "created_utc": 1668718361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was applying for DA and DE positions over the summer the ones I prioritized applying for were the ones that clearly defined what responsibilities and task would be owned by the candidate chosen for the role.\n\nFor example at my previous Data Analyst positions I owned the SSRS and PowerBI reporting dashboards, the ETL processes to pull the data from the source systems onto our DW, the handling and prioritizing of report request tickets as they came in and integrating data from outside sources like legacy EHRs or flat CVS files into our DW.\n\nNow that I am working as a Data Engineer my ownership includes everything and anything to do with SSIS or Azure Data Factory, spinning up test environments via either Docker or HyperV Linux VMs, management of our Git Hub Organization (we are currently on the free tier but are thinking of upgrading to the \"teams\" one if anyone has any feedback on this that would be awesome), QA processes for the data being ETL. And everyone's favorite heavily documenting everything.\n\nThings I DONT own in this position are any DBA task aside from the test environments. A lot of our work is done on external clients databases so it's a constant game of tag asking their DBA for new permissions, creating specific DB roles, asking for more space etc. I also have nothing to do with the front end BI tool that our data warehouse connects to, and I don't orchestrate gaining access to outside data systems. Some of them have us use a Ctirix Desktop , others have a VPN set up so we can still work on our native desktop and connect to their DBs via our locally installed SSMS and Visual Studio. \n\nSo what do you own ?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the things you \"own\" in your job title.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxral1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668694131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was applying for DA and DE positions over the summer the ones I prioritized applying for were the ones that clearly defined what responsibilities and task would be owned by the candidate chosen for the role.&lt;/p&gt;\n\n&lt;p&gt;For example at my previous Data Analyst positions I owned the SSRS and PowerBI reporting dashboards, the ETL processes to pull the data from the source systems onto our DW, the handling and prioritizing of report request tickets as they came in and integrating data from outside sources like legacy EHRs or flat CVS files into our DW.&lt;/p&gt;\n\n&lt;p&gt;Now that I am working as a Data Engineer my ownership includes everything and anything to do with SSIS or Azure Data Factory, spinning up test environments via either Docker or HyperV Linux VMs, management of our Git Hub Organization (we are currently on the free tier but are thinking of upgrading to the &amp;quot;teams&amp;quot; one if anyone has any feedback on this that would be awesome), QA processes for the data being ETL. And everyone&amp;#39;s favorite heavily documenting everything.&lt;/p&gt;\n\n&lt;p&gt;Things I DONT own in this position are any DBA task aside from the test environments. A lot of our work is done on external clients databases so it&amp;#39;s a constant game of tag asking their DBA for new permissions, creating specific DB roles, asking for more space etc. I also have nothing to do with the front end BI tool that our data warehouse connects to, and I don&amp;#39;t orchestrate gaining access to outside data systems. Some of them have us use a Ctirix Desktop , others have a VPN set up so we can still work on our native desktop and connect to their DBs via our locally installed SSMS and Visual Studio. &lt;/p&gt;\n\n&lt;p&gt;So what do you own ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxral1", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxral1/what_are_some_of_the_things_you_own_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxral1/what_are_some_of_the_things_you_own_in_your_job/", "subreddit_subscribers": 80264, "created_utc": 1668694131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From reading through this sub for a few months it seems to have attracted the attention of people from all different realms of the data world. Many of us seem to have backgrounds in Data Analysis, Data Architecture,  Business Analyst , Data Scenic and of course what we are all aspiring to be which is Engineers in the Data Space.\n\nThe common denominator seems to be we all have lots of experience using databases in one way or another. Me personally I started as a reporting analyst , upgraded to a more Data Analyst role and then started orchestrating my own ETLs and spinning up my own database environments for testing using tools like Docker or Hyper V VMs. I also took an interest in Data Science and started pursuing a master's degree in it but only ended up getting their 15 credit certificate of advanced study because I didn't have the time or money to finish the whole 34 credit program.\n\nI started incorporating some classification and clustering models into some of the analytics I was working on but never took it too far, and sometimes I would make a sexy visualization or two in R or Python instead of using something like Excel.\n\nWhat I'm noticing is that there is just so much overlap in these titles and the job duties that you are expected to perform. Sometimes I feel like a jack of all trades but a master of none. Right now I am working my first formal Data Engineering role and I'm hitting the ground running trying to learn as much as I can about it because I think it's more future proof (and interesting) than Data Science. \n\nI feel like these companies dream is to find some unicornish Data Jedi Master that can just come in and solve any data problem on the spot.  What would that title be ? And what kind of requirements would you want from that person. 10+ years of working in the data realm where you had exposure to a little bit of everything ? Or a more itemized list of requirements like knowing x number of years of specific skill sets with the tail end being something that is modern and upcoming.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What will the new hybrid Data Centric Job Title Be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy6z1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668733311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From reading through this sub for a few months it seems to have attracted the attention of people from all different realms of the data world. Many of us seem to have backgrounds in Data Analysis, Data Architecture,  Business Analyst , Data Scenic and of course what we are all aspiring to be which is Engineers in the Data Space.&lt;/p&gt;\n\n&lt;p&gt;The common denominator seems to be we all have lots of experience using databases in one way or another. Me personally I started as a reporting analyst , upgraded to a more Data Analyst role and then started orchestrating my own ETLs and spinning up my own database environments for testing using tools like Docker or Hyper V VMs. I also took an interest in Data Science and started pursuing a master&amp;#39;s degree in it but only ended up getting their 15 credit certificate of advanced study because I didn&amp;#39;t have the time or money to finish the whole 34 credit program.&lt;/p&gt;\n\n&lt;p&gt;I started incorporating some classification and clustering models into some of the analytics I was working on but never took it too far, and sometimes I would make a sexy visualization or two in R or Python instead of using something like Excel.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m noticing is that there is just so much overlap in these titles and the job duties that you are expected to perform. Sometimes I feel like a jack of all trades but a master of none. Right now I am working my first formal Data Engineering role and I&amp;#39;m hitting the ground running trying to learn as much as I can about it because I think it&amp;#39;s more future proof (and interesting) than Data Science. &lt;/p&gt;\n\n&lt;p&gt;I feel like these companies dream is to find some unicornish Data Jedi Master that can just come in and solve any data problem on the spot.  What would that title be ? And what kind of requirements would you want from that person. 10+ years of working in the data realm where you had exposure to a little bit of everything ? Or a more itemized list of requirements like knowing x number of years of specific skill sets with the tail end being something that is modern and upcoming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy6z1p", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy6z1p/what_will_the_new_hybrid_data_centric_job_title_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy6z1p/what_will_the_new_hybrid_data_centric_job_title_be/", "subreddit_subscribers": 80264, "created_utc": 1668733311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, sorry for the noob question. Just looking for some insights on how to go about approaching this problem.\n\nOne of customers would like to have access to their data to run for analysis purposes. We haven't yet built a public API for them to extract this data, but want to support the use case of sending them their data in the meantime. We were thinking of doing something like snowflake sharing of db, but we don't use snowflake and atm don't want to migrate. So my question is there something similar to snowflake sharing of db, that works for most common database, that I can use to sync the data to my customers database? Want to minimize the amount of dev hours to do this. I might be completely on the wrong track with this approach, would love to hear different approaches for this! \n\nAlso, the data isn't static, it changes everyday, so need mechanism to keep it up-to-date.\n\nThanks!!", "author_fullname": "t2_k9bt2fal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syncing data between database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy5r02", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668729785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, sorry for the noob question. Just looking for some insights on how to go about approaching this problem.&lt;/p&gt;\n\n&lt;p&gt;One of customers would like to have access to their data to run for analysis purposes. We haven&amp;#39;t yet built a public API for them to extract this data, but want to support the use case of sending them their data in the meantime. We were thinking of doing something like snowflake sharing of db, but we don&amp;#39;t use snowflake and atm don&amp;#39;t want to migrate. So my question is there something similar to snowflake sharing of db, that works for most common database, that I can use to sync the data to my customers database? Want to minimize the amount of dev hours to do this. I might be completely on the wrong track with this approach, would love to hear different approaches for this! &lt;/p&gt;\n\n&lt;p&gt;Also, the data isn&amp;#39;t static, it changes everyday, so need mechanism to keep it up-to-date.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yy5r02", "is_robot_indexable": true, "report_reasons": null, "author": "coolbeansarelife", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy5r02/syncing_data_between_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy5r02/syncing_data_between_database/", "subreddit_subscribers": 80264, "created_utc": 1668729785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Virtualization *should be* a perfect fit for Customer 360. Or so you\u2019d think. But please add your input, if you are using another method...\n\n\nAfter all, Data Virtualization gives authorized users access to customer data \u2013 regardless of format, location, or protocol.\u00a0It also shields them from the underlying systems, and their complexities.\u00a0\n\n\u00a0\nBut traditional Data Virtualization fails to deliver on Customer 360 because it:\u00a0\n\u00a0\n\n\u274c Isn\u2019t designed for operational workloads (due its reliance on existing data source availability and response times)\u00a0\n\n\u00a0\n\u274c Can\u2019t handle complex data transformations, and therefore must rely on additional ETL tools\u00a0\n\n\u00a0\n\u274c Lacks data governance (data quality and compliance)\u00a0\n\n\nA DATA PRODUCT APPROACH, combined with Dynamic Data Virtualization, resolves these issues by enabling:\u00a0\n\n\n\u2611\ufe0f High-speed customer data delivery, regardless of source system performance\u00a0\n\u00a0\n\n\u2611\ufe0f Less stress on the source systems\u00a0\n\u00a0\n\n\u2611\ufe0f In-flight data transformation and enrichment, for real-time operational intelligence\u00a0\n\u00a0\n\n\u2611\ufe0f Embedded data governance\u00a0\n\u00a0\n\nAnd allowing you to:\u00a0\u00a0\n\n- Complete your Customer 360 program in weeks, and\u00a0\n\u00a0\n\n- Leverage your existing Customer 360 investments.\u00a0\n\n\n\nLearn more in our \u201cGuide to Customer 360 Success\u201d \u2013 https://www.k2view.com/what-is-customer-360\n\u00a0", "author_fullname": "t2_5dmr6nl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer 360: Why Data Virtualization Fails", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy58pk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668729649.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668728393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Virtualization &lt;em&gt;should be&lt;/em&gt; a perfect fit for Customer 360. Or so you\u2019d think. But please add your input, if you are using another method...&lt;/p&gt;\n\n&lt;p&gt;After all, Data Virtualization gives authorized users access to customer data \u2013 regardless of format, location, or protocol.\u00a0It also shields them from the underlying systems, and their complexities.\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0\nBut traditional Data Virtualization fails to deliver on Customer 360 because it:\u00a0\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u274c Isn\u2019t designed for operational workloads (due its reliance on existing data source availability and response times)\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0\n\u274c Can\u2019t handle complex data transformations, and therefore must rely on additional ETL tools\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0\n\u274c Lacks data governance (data quality and compliance)\u00a0&lt;/p&gt;\n\n&lt;p&gt;A DATA PRODUCT APPROACH, combined with Dynamic Data Virtualization, resolves these issues by enabling:\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u2611\ufe0f High-speed customer data delivery, regardless of source system performance\u00a0\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u2611\ufe0f Less stress on the source systems\u00a0\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u2611\ufe0f In-flight data transformation and enrichment, for real-time operational intelligence\u00a0\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u2611\ufe0f Embedded data governance\u00a0\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;And allowing you to:\u00a0\u00a0&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Complete your Customer 360 program in weeks, and\u00a0\n\u00a0&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Leverage your existing Customer 360 investments.\u00a0&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Learn more in our \u201cGuide to Customer 360 Success\u201d \u2013 &lt;a href=\"https://www.k2view.com/what-is-customer-360\"&gt;https://www.k2view.com/what-is-customer-360&lt;/a&gt;\n\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZJ6eUhCm5w_cpf_WC_iyN7pyrfmBovB_f_clRvqgdZ4.jpg?auto=webp&amp;s=5187104b6f67d2ea2041eb968b3aa3f026b2d03f", "width": 900, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/ZJ6eUhCm5w_cpf_WC_iyN7pyrfmBovB_f_clRvqgdZ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60e04248270bbff384b8a3cd7b669c9a2eb5a5a6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZJ6eUhCm5w_cpf_WC_iyN7pyrfmBovB_f_clRvqgdZ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6b2952cf1d12ccaa77d0a2bb0e6f18e2b5c430a1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZJ6eUhCm5w_cpf_WC_iyN7pyrfmBovB_f_clRvqgdZ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25a7bb9b8279c82989507c8af538e039018f7b52", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZJ6eUhCm5w_cpf_WC_iyN7pyrfmBovB_f_clRvqgdZ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d8f43f3d8905f1ab9e04fcf8b67e73f6ced8697", "width": 640, "height": 320}], "variants": {}, "id": "_0X_CmDzv-tqo73g36wrrY3I4-hfhP-Q0cJCi-morI8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yy58pk", "is_robot_indexable": true, "report_reasons": null, "author": "luckysonic2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy58pk/customer_360_why_data_virtualization_fails/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy58pk/customer_360_why_data_virtualization_fails/", "subreddit_subscribers": 80264, "created_utc": 1668728393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently reading Designing Data-Intensive Applications, the Data Warehouse Toolkit, and a system design interview book.\n\n\n\nDesigning Data-Intensive Applications is fascinating, but seems overly detailed at times.  Which makes me think I might be over-preparing.\n\n\n\n\nIn the new year, I'm preparing to interview for senior data engineering roles and more experienced mid-level roles.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I over-preparing for system design interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy4qq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668727027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently reading Designing Data-Intensive Applications, the Data Warehouse Toolkit, and a system design interview book.&lt;/p&gt;\n\n&lt;p&gt;Designing Data-Intensive Applications is fascinating, but seems overly detailed at times.  Which makes me think I might be over-preparing.&lt;/p&gt;\n\n&lt;p&gt;In the new year, I&amp;#39;m preparing to interview for senior data engineering roles and more experienced mid-level roles.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy4qq0", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy4qq0/am_i_overpreparing_for_system_design_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy4qq0/am_i_overpreparing_for_system_design_interviews/", "subreddit_subscribers": 80264, "created_utc": 1668727027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking for an easy move to the cloud but I can\u2019t find pricing info anywhere.", "author_fullname": "t2_dw6y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are you paying for Qlik Replicate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy343b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668722849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for an easy move to the cloud but I can\u2019t find pricing info anywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yy343b", "is_robot_indexable": true, "report_reasons": null, "author": "Squeebee007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy343b/what_are_you_paying_for_qlik_replicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy343b/what_are_you_paying_for_qlik_replicate/", "subreddit_subscribers": 80264, "created_utc": 1668722849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data teams use a lot of tools and understanding how access is configured across the growing stack is complex and exhausting. Jetty is a tiny peek at our broader vision of simplifying data privacy and we'd love you to give it a try and offer any feedback. It's free to use and available via \\`pip\\`!\n\nHere's our first blog post about why we're tackling this problem: [https://docs.get-jetty.com/blog/2022/11/17/hello-jetty](https://docs.get-jetty.com/blog/2022/11/17/hello-jetty)\n\nIf you want to jump straight in, here are the quickstart docs: [https://docs.get-jetty.com/getting-started/](https://docs.get-jetty.com/getting-started/)", "author_fullname": "t2_12c7ta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We just launched Jetty to help you understand permissions across Snowflake, dbt, and Tableau!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy2zq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668722543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data teams use a lot of tools and understanding how access is configured across the growing stack is complex and exhausting. Jetty is a tiny peek at our broader vision of simplifying data privacy and we&amp;#39;d love you to give it a try and offer any feedback. It&amp;#39;s free to use and available via `pip`!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s our first blog post about why we&amp;#39;re tackling this problem: &lt;a href=\"https://docs.get-jetty.com/blog/2022/11/17/hello-jetty\"&gt;https://docs.get-jetty.com/blog/2022/11/17/hello-jetty&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you want to jump straight in, here are the quickstart docs: &lt;a href=\"https://docs.get-jetty.com/getting-started/\"&gt;https://docs.get-jetty.com/getting-started/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?auto=webp&amp;s=b82066f4a0700f80d4671da79322ec36ef3642bf", "width": 390, "height": 100}, "resolutions": [{"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b407e0a2e8387f5ba5d0bc17b3366e520ccc7584", "width": 108, "height": 27}, {"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c103cfb8d8186a78bdf6d1f3dfd9d90aa55b9291", "width": 216, "height": 55}, {"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d6ed111359dd1e221170a94df59df176dc040f45", "width": 320, "height": 82}], "variants": {}, "id": "EdFQhio2xUgFD7h2xIFVJ4cxt8YCRUk9d_JB-s5xNAc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy2zq2", "is_robot_indexable": true, "report_reasons": null, "author": "azjkjensen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy2zq2/we_just_launched_jetty_to_help_you_understand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy2zq2/we_just_launched_jetty_to_help_you_understand/", "subreddit_subscribers": 80264, "created_utc": 1668722543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nMy company is looking to extract data from SQL Server and Oracle to Snowflake. What are some pros and cons of these tools?\n\n\\- Matillion\n\n\\- Fivetran\n\n\\- Wherescape\n\n\\- ADF\n\n\\- or any other?\n\nPreferably looking for one tool to fulfill the whole ELT process if possible.", "author_fullname": "t2_r0krk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT Stack to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxxrm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668712840.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668710152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;My company is looking to extract data from SQL Server and Oracle to Snowflake. What are some pros and cons of these tools?&lt;/p&gt;\n\n&lt;p&gt;- Matillion&lt;/p&gt;\n\n&lt;p&gt;- Fivetran&lt;/p&gt;\n\n&lt;p&gt;- Wherescape&lt;/p&gt;\n\n&lt;p&gt;- ADF&lt;/p&gt;\n\n&lt;p&gt;- or any other?&lt;/p&gt;\n\n&lt;p&gt;Preferably looking for one tool to fulfill the whole ELT process if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxxrm4", "is_robot_indexable": true, "report_reasons": null, "author": "sizzlepoop", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxxrm4/elt_stack_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxxrm4/elt_stack_to_snowflake/", "subreddit_subscribers": 80264, "created_utc": 1668710152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team has been put in charge of creating a process to move customers from one product DB to another. \n\nThis is currently done using SSIS packages that are pretty much a black box to anyone wondering what logic they're using to move data.\n\nWe're building out a new workflow, I'd like to take a step back and consider another option.\n\nAs a software engineer I'd really like to be able to write test cases, do version control, all that good stuff while also documenting business logic of DB values and how they relate across products?", "author_fullname": "t2_exqc18fi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool for creating a process to move customers from one product/DB to another", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxq1tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668691157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team has been put in charge of creating a process to move customers from one product DB to another. &lt;/p&gt;\n\n&lt;p&gt;This is currently done using SSIS packages that are pretty much a black box to anyone wondering what logic they&amp;#39;re using to move data.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re building out a new workflow, I&amp;#39;d like to take a step back and consider another option.&lt;/p&gt;\n\n&lt;p&gt;As a software engineer I&amp;#39;d really like to be able to write test cases, do version control, all that good stuff while also documenting business logic of DB values and how they relate across products?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxq1tz", "is_robot_indexable": true, "report_reasons": null, "author": "No-Swimming-3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxq1tz/best_tool_for_creating_a_process_to_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxq1tz/best_tool_for_creating_a_process_to_move/", "subreddit_subscribers": 80264, "created_utc": 1668691157.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}