{"kind": "Listing", "data": {"after": "t3_yy2zq2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to level up my skills and want to know what repos out there follow good data engineering practice.\n\nWhat accounts/repos stood out to you?\n\nWhich repos do you find yourself peeking at from time to time?\n\nWhich ones taught you something that you didn't already know?", "author_fullname": "t2_4gzaf8mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your favourite GitHub repos that shows how data engineering should be done?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyh6l9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 143, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 143, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668768618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to level up my skills and want to know what repos out there follow good data engineering practice.&lt;/p&gt;\n\n&lt;p&gt;What accounts/repos stood out to you?&lt;/p&gt;\n\n&lt;p&gt;Which repos do you find yourself peeking at from time to time?&lt;/p&gt;\n\n&lt;p&gt;Which ones taught you something that you didn&amp;#39;t already know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyh6l9", "is_robot_indexable": true, "report_reasons": null, "author": "theoriginalmantooth", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyh6l9/what_are_your_favourite_github_repos_that_shows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyh6l9/what_are_your_favourite_github_repos_that_shows/", "subreddit_subscribers": 80324, "created_utc": 1668768618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022](https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022)\n\nhttps://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake syntax now supports EXCLUDE &amp; RENAME syntax", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2inizkec1l0a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=85d741105d8ef05ce7c42be9d2af06a5d179f45e"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ecb6f641cd7233c41845b4f71fb41be60c846b1"}, {"y": 220, "x": 320, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=57848927e730cd8d034eca8ccbba32b9c7debf6b"}, {"y": 441, "x": 640, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3b86381cf41be58dfcfcf05be1c76a56636521f"}, {"y": 662, "x": 960, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=053f1ce7e93e936e264c6a26473285d8679a733c"}, {"y": 745, "x": 1080, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=44c72166f2ea2a1d0ff634bcc062030f1fefa452"}], "s": {"y": 1122, "x": 1626, "u": "https://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140"}, "id": "2inizkec1l0a1"}}, "name": "t3_yy2qmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 97, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 97, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/EoS_04k_K4mUGKbAQjIfCamP4I8q4XHt2bNXAMErctA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1668721951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022\"&gt;https://community.snowflake.com/s/article/6-37-Release-Notes-November-10-11-2022&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140\"&gt;https://preview.redd.it/2inizkec1l0a1.png?width=1626&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1513a820971b80f542a1a75b6a46d3ab9cefb140&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?auto=webp&amp;s=6c4577b4b27b2f3cb213abccd9a9bc589d2418e8", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=71451e9c1cc16528fbc34507862665d8183081d3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8af2e536d48b791bafcedfbdb5728346e2109f22", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=92e856a3642fc42087b7e751258cdac62f23ffd2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dab18af7e3da9431e2dc8d67e6ec0260f7f47c35", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=69266347b991e43b5cc29f5d1bbc90260fa577e2", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/DIDkJHFxJpQ200A6FqbC5-cJzOUmRW4a1G3tgvQJVvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7badca4ca72a246b97ad3a9eb03a5238751e16b1", "width": 1080, "height": 567}], "variants": {}, "id": "DZ6ZkB53QxWcONahOQnFN7Kkze2JZoFjE1YqqJfitLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy2qmg", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy2qmg/snowflake_syntax_now_supports_exclude_rename/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy2qmg/snowflake_syntax_now_supports_exclude_rename/", "subreddit_subscribers": 80324, "created_utc": 1668721951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all! I\u2019m currently a Data Engineering Manager at a big tech company (FAANG) and I find myself kind of done with management. I\u2019m wondering what it would take to switch to an IC role? I have a solid knowledge of SQL and good knowledge of python but not a whole lot of experience on the other modern tech stacks and generally a bit out of touch with coding with about 6 years of management experience. How much of a step down would I have to take to get familiar with things like real-time streaming data, API development etc. ? I don\u2019t mind taking a break to prepare myself but find it hard to figure out what would give me the best bang for my buck (certs? Projects?). Thoughts?", "author_fullname": "t2_3x1kych3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager to IC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy676j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668731044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! I\u2019m currently a Data Engineering Manager at a big tech company (FAANG) and I find myself kind of done with management. I\u2019m wondering what it would take to switch to an IC role? I have a solid knowledge of SQL and good knowledge of python but not a whole lot of experience on the other modern tech stacks and generally a bit out of touch with coding with about 6 years of management experience. How much of a step down would I have to take to get familiar with things like real-time streaming data, API development etc. ? I don\u2019t mind taking a break to prepare myself but find it hard to figure out what would give me the best bang for my buck (certs? Projects?). Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yy676j", "is_robot_indexable": true, "report_reasons": null, "author": "Alone-Investment", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy676j/manager_to_ic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy676j/manager_to_ic/", "subreddit_subscribers": 80324, "created_utc": 1668731044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I undestand that apache sparks benefit is to do distributed processing, but I am trouble figuring out the different ways this actually occurs. Is the goal to simply put all your data inside a dataframe, then create a UDF and run that function against the dataframe? \n\nExample:\n\nIf I have 1 master and 5 slave nodes:\n\n1. Dataframe with 1 column of URLs to S3 bucket to do image processing. Will a grey\\_filter UDF that turns the images grey be distributed to the 5 slave nodes and have 5 processes running simultaneously? If I create save\\_to\\_s3 UDF and run that after grey\\_filter UDF is done.. is it possible to chain UDFs and is this acceptable practice? \n2. Data frame with 1 column of revenue $. If I run the built in sum function, assuming this distributes the work to the 5 nodes and does some map reduce like process?\n3. Any other examples of showcasing the power of how spark is beneficial??", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the true power of Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyc1re", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668749106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I undestand that apache sparks benefit is to do distributed processing, but I am trouble figuring out the different ways this actually occurs. Is the goal to simply put all your data inside a dataframe, then create a UDF and run that function against the dataframe? &lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;p&gt;If I have 1 master and 5 slave nodes:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Dataframe with 1 column of URLs to S3 bucket to do image processing. Will a grey_filter UDF that turns the images grey be distributed to the 5 slave nodes and have 5 processes running simultaneously? If I create save_to_s3 UDF and run that after grey_filter UDF is done.. is it possible to chain UDFs and is this acceptable practice? &lt;/li&gt;\n&lt;li&gt;Data frame with 1 column of revenue $. If I run the built in sum function, assuming this distributes the work to the 5 nodes and does some map reduce like process?&lt;/li&gt;\n&lt;li&gt;Any other examples of showcasing the power of how spark is beneficial??&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyc1re", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyc1re/what_is_the_true_power_of_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyc1re/what_is_the_true_power_of_apache_spark/", "subreddit_subscribers": 80324, "created_utc": 1668749106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7oampu1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Architecture 101 | Concepts &amp; Application", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": false, "name": "t3_yygg77", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": "transparent", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Uop7DvCJ_pvmalkHAag7jOxIy7ArM6CUKX3ZsfwsSNI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668765781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/dev-genius/spark-architecture-101-concepts-application-f5260783ac9d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3739ilfseOfuTdoGgSZHV0PmE0uLEAwMbXTz9OL69DU.jpg?auto=webp&amp;s=36398a63c376e43266a4079627950fa49008e7b7", "width": 816, "height": 333}, "resolutions": [{"url": "https://external-preview.redd.it/3739ilfseOfuTdoGgSZHV0PmE0uLEAwMbXTz9OL69DU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c65392d71eee8d4f74f97d97446a47d1598414fd", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/3739ilfseOfuTdoGgSZHV0PmE0uLEAwMbXTz9OL69DU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db34928b42eea90bf9868f1598f346766401fd22", "width": 216, "height": 88}, {"url": "https://external-preview.redd.it/3739ilfseOfuTdoGgSZHV0PmE0uLEAwMbXTz9OL69DU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd2f7f7e370e2655a6726a9c214075af423ff419", "width": 320, "height": 130}, {"url": "https://external-preview.redd.it/3739ilfseOfuTdoGgSZHV0PmE0uLEAwMbXTz9OL69DU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e9ea2a11af572a4c3937665ae9d3728ebab0807", "width": 640, "height": 261}], "variants": {}, "id": "wd_6Z6dap2DCyGFU7dBLVOJruBOLUpnqgEsNI6cqlec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yygg77", "is_robot_indexable": true, "report_reasons": null, "author": "Sidharth_r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yygg77/spark_architecture_101_concepts_application/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/dev-genius/spark-architecture-101-concepts-application-f5260783ac9d", "subreddit_subscribers": 80324, "created_utc": 1668765781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4cc8quyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a Better GitHub Insight Tool in a Week? A True Story | OSS Insight", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "name": "t3_yydhsg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KrXRc48bgr4dJrPRlklyMsBHXv98z3eD5QMHoFvDLXw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668754251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ossinsight.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ossinsight.io/blog/why-we-choose-tidb-to-support-ossinsight", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?auto=webp&amp;s=8b0b2f4ee172a15773dee72b84ac35e520d74bbd", "width": 1743, "height": 1336}, "resolutions": [{"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0df3138f63bda86daacdd457f431bc5ae8a728fc", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1be8e1b98b05a72274da7a6c5085eada9bb99ff9", "width": 216, "height": 165}, {"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c710b7944f841e2e37249b908e6d600be26e013", "width": 320, "height": 245}, {"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=155582d044004fd05b4d06ada1e1b4b34a9a0c0a", "width": 640, "height": 490}, {"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=acf0f311cc7af9d9ac4680597c8021559af9dcfb", "width": 960, "height": 735}, {"url": "https://external-preview.redd.it/XYmV11eSixR6j5XM6jO8fkYVYIJQJwpcqQL-th91WGE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=880d38025b6132379fe537c4b466faba09b11614", "width": 1080, "height": 827}], "variants": {}, "id": "g-2lOqIhV-njJUwyMyo-77ZlaTAw-4SmAKiZdN9w3iI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yydhsg", "is_robot_indexable": true, "report_reasons": null, "author": "hooopo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yydhsg/build_a_better_github_insight_tool_in_a_week_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ossinsight.io/blog/why-we-choose-tidb-to-support-ossinsight", "subreddit_subscribers": 80324, "created_utc": 1668754251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my SE major, I put my focus on DS and ML. At the time I did this, I wasn't even aware of DE. Too bad there isn't even something directly relevant for Data Engineering to study in uni.\n\nThere are lots of Junior Data Science positions. There are barely any Junior Data Engineer positions. Hence, let's say I wouldn't be able to get into one after graduating.\n\n&amp;#x200B;\n\nWould 'Junior Data Scientist' be acceptable as career entry point for Data Engineering? I am quite aware of the overlap and the differences. I think I found out I enjoy 'real' software engineering more, and DE is much more real SE than DS is. But as a DS junior position will likely still heavily require skills such as Python, SQL, dashboards probably, it would still make a lot of sense to take it, right? Are there any other positions that would make sense as starting point, besides DS and DE obviously?", "author_fullname": "t2_136crg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science position acceptable as entry job for a road to a DE career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy19ir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668718361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my SE major, I put my focus on DS and ML. At the time I did this, I wasn&amp;#39;t even aware of DE. Too bad there isn&amp;#39;t even something directly relevant for Data Engineering to study in uni.&lt;/p&gt;\n\n&lt;p&gt;There are lots of Junior Data Science positions. There are barely any Junior Data Engineer positions. Hence, let&amp;#39;s say I wouldn&amp;#39;t be able to get into one after graduating.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would &amp;#39;Junior Data Scientist&amp;#39; be acceptable as career entry point for Data Engineering? I am quite aware of the overlap and the differences. I think I found out I enjoy &amp;#39;real&amp;#39; software engineering more, and DE is much more real SE than DS is. But as a DS junior position will likely still heavily require skills such as Python, SQL, dashboards probably, it would still make a lot of sense to take it, right? Are there any other positions that would make sense as starting point, besides DS and DE obviously?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yy19ir", "is_robot_indexable": true, "report_reasons": null, "author": "Boruroku", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy19ir/data_science_position_acceptable_as_entry_job_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy19ir/data_science_position_acceptable_as_entry_job_for/", "subreddit_subscribers": 80324, "created_utc": 1668718361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_20sul3l3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yybwga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VC04oAHnrxPHHD_ivI1peKUMpIzZoshL2eq2zeMRRn4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668748621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?auto=webp&amp;s=39cec4446675f2353a6250f0775b7f674c759b28", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0becbe2f4317ee42dc5d62208b8f6a277c5d59ee", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83d1bf1123e5e2af515328320df596482ca00ae5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a1007df76c8b2a9c315722614764df47ff22afa", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=67d4927464988a7e6b0c255a3151b0feb28ac483", "width": 640, "height": 336}], "variants": {}, "id": "JGhC9b9qhHNJ4eh7-qMHVcYJNdZfz1K-5VoSz-ZvhQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yybwga", "is_robot_indexable": true, "report_reasons": null, "author": "saik2363", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yybwga/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 80324, "created_utc": 1668748621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve read a lot of experiences of people talking about freelancing so I don\u2019t want to repeat the same question about switching from regular job to freelancing, actually I\u2019m talking about the opposite. How difficult is to come back to companies and get a fair salary? Do freelancing years count as normal \u201cyears of experience\u201d or company tend to not consider those years in salary negotiations?", "author_fullname": "t2_e4qv08k8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How difficult is to come back from freelancing to \u201cregular\u201d job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyewca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668760119.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668759645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve read a lot of experiences of people talking about freelancing so I don\u2019t want to repeat the same question about switching from regular job to freelancing, actually I\u2019m talking about the opposite. How difficult is to come back to companies and get a fair salary? Do freelancing years count as normal \u201cyears of experience\u201d or company tend to not consider those years in salary negotiations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yyewca", "is_robot_indexable": true, "report_reasons": null, "author": "Busy_Elderberry8650", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyewca/how_difficult_is_to_come_back_from_freelancing_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyewca/how_difficult_is_to_come_back_from_freelancing_to/", "subreddit_subscribers": 80324, "created_utc": 1668759645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, sorry for the noob question. Just looking for some insights on how to go about approaching this problem.\n\nOne of customers would like to have access to their data to run for analysis purposes. We haven't yet built a public API for them to extract this data, but want to support the use case of sending them their data in the meantime. We were thinking of doing something like snowflake sharing of db, but we don't use snowflake and atm don't want to migrate. So my question is there something similar to snowflake sharing of db, that works for most common database, that I can use to sync the data to my customers database? Want to minimize the amount of dev hours to do this. I might be completely on the wrong track with this approach, would love to hear different approaches for this! \n\nAlso, the data isn't static, it changes everyday, so need mechanism to keep it up-to-date.\n\nThanks!!", "author_fullname": "t2_k9bt2fal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syncing data between database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy5r02", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668729785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, sorry for the noob question. Just looking for some insights on how to go about approaching this problem.&lt;/p&gt;\n\n&lt;p&gt;One of customers would like to have access to their data to run for analysis purposes. We haven&amp;#39;t yet built a public API for them to extract this data, but want to support the use case of sending them their data in the meantime. We were thinking of doing something like snowflake sharing of db, but we don&amp;#39;t use snowflake and atm don&amp;#39;t want to migrate. So my question is there something similar to snowflake sharing of db, that works for most common database, that I can use to sync the data to my customers database? Want to minimize the amount of dev hours to do this. I might be completely on the wrong track with this approach, would love to hear different approaches for this! &lt;/p&gt;\n\n&lt;p&gt;Also, the data isn&amp;#39;t static, it changes everyday, so need mechanism to keep it up-to-date.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yy5r02", "is_robot_indexable": true, "report_reasons": null, "author": "coolbeansarelife", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy5r02/syncing_data_between_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy5r02/syncing_data_between_database/", "subreddit_subscribers": 80324, "created_utc": 1668729785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this pipeline that heavily relies on our database. Every transformation needs a piece of data from a different column and therefore, we do a lot of selects and joins. \n\nManagement is complaining that when ingestion is running, the database consumption is increasing, which makes our application slow to reach the final customer\n\nWhat if I create a replica database, perform all the calculations, and then sync back to the production database? Does this sound like a good solution?", "author_fullname": "t2_3p0fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does it make sense to have a replica database for a data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxypaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668712363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this pipeline that heavily relies on our database. Every transformation needs a piece of data from a different column and therefore, we do a lot of selects and joins. &lt;/p&gt;\n\n&lt;p&gt;Management is complaining that when ingestion is running, the database consumption is increasing, which makes our application slow to reach the final customer&lt;/p&gt;\n\n&lt;p&gt;What if I create a replica database, perform all the calculations, and then sync back to the production database? Does this sound like a good solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yxypaq", "is_robot_indexable": true, "report_reasons": null, "author": "Croves", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxypaq/does_it_make_sense_to_have_a_replica_database_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxypaq/does_it_make_sense_to_have_a_replica_database_for/", "subreddit_subscribers": 80324, "created_utc": 1668712363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone more intelligent than me help me understand the main differences and use cases between Snowflake and Databricks? \n\nWhen should I use one over the other as they look quite similar in terms of solutions?\n\nMuch appreciated!", "author_fullname": "t2_arqcenpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Vs Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yymz5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668785823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone more intelligent than me help me understand the main differences and use cases between Snowflake and Databricks? &lt;/p&gt;\n\n&lt;p&gt;When should I use one over the other as they look quite similar in terms of solutions?&lt;/p&gt;\n\n&lt;p&gt;Much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yymz5c", "is_robot_indexable": true, "report_reasons": null, "author": "AMadRam", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yymz5c/snowflake_vs_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yymz5c/snowflake_vs_databricks/", "subreddit_subscribers": 80324, "created_utc": 1668785823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This week we started a new project (Loan default prediction for car dealerships) and w\\\\in this video. We worked on cleaning the data and some bit of EDA. We majorly used pandas and wrote python functions in order not to repeat ourselves while keeping in mind the events that will take place when the model is pushed to production and how the model will be consumed. We also discovered pandas\\_profiling package that helps in profiling pandas data frames and giving several insights that are useful in machine learning model development and and exploratory data analysis. Here is the video, have fun. [https://www.youtube.com/watch?v=JHz5UV3N-YU&amp;ab\\_channel=DaliCodes](https://www.youtube.com/watch?v=JHz5UV3N-YU&amp;ab_channel=DaliCodes)", "author_fullname": "t2_ck47kwls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Loan default prediction data cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yympa0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668785099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This week we started a new project (Loan default prediction for car dealerships) and w\\in this video. We worked on cleaning the data and some bit of EDA. We majorly used pandas and wrote python functions in order not to repeat ourselves while keeping in mind the events that will take place when the model is pushed to production and how the model will be consumed. We also discovered pandas_profiling package that helps in profiling pandas data frames and giving several insights that are useful in machine learning model development and and exploratory data analysis. Here is the video, have fun. &lt;a href=\"https://www.youtube.com/watch?v=JHz5UV3N-YU&amp;amp;ab_channel=DaliCodes\"&gt;https://www.youtube.com/watch?v=JHz5UV3N-YU&amp;amp;ab_channel=DaliCodes&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HwzYwC2EU7OIAQpp4HacZCehUSO9NtDZ8tGwGNbTBGc.jpg?auto=webp&amp;s=c37c5c3e2742e2bde398dc5c67c561e8f22f1f44", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HwzYwC2EU7OIAQpp4HacZCehUSO9NtDZ8tGwGNbTBGc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1455a937326b7f9662ca697a9c30c55c291cb4b5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HwzYwC2EU7OIAQpp4HacZCehUSO9NtDZ8tGwGNbTBGc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46e412cfadbdf5ad6f42a6a0e614ebc4035f5106", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HwzYwC2EU7OIAQpp4HacZCehUSO9NtDZ8tGwGNbTBGc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34f76c3d1367677735f4cb256297259149f65b53", "width": 320, "height": 240}], "variants": {}, "id": "k__OjWG3xRAodSlH2Fpm-kcEVsBIT5Ck4IEj4zrv-tc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yympa0", "is_robot_indexable": true, "report_reasons": null, "author": "DaliCodes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yympa0/loan_default_prediction_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yympa0/loan_default_prediction_data_cleaning/", "subreddit_subscribers": 80324, "created_utc": 1668785099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple DE project with Airbyte, dbt, and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yykzuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/E6DDWZLkyLmaeZIPQYFu1azHo-DvIbPWSRy2NYlnlG8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668780585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/airbyte-monitoring-with-dbt-and-metabase", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?auto=webp&amp;s=30618cf4d8c898d07e70fe39de985931096a4147", "width": 3648, "height": 2736}, "resolutions": [{"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ecb7c74c7e3375b4a29252a3f6be57ca171db428", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b1c364436c62b5db71a98904030b2dd6e3dd7af", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2979e70d042d263953b3d9e9758e0641a26fe5d9", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b8bad82a0f8dad898ad6e6cc8a30b134d2ba5523", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8cc048a01410f195b8e2e33aabe1c7446233cc36", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/6mVHDzZ9Gf0-cBF5N8kLLiNwJVzyQ2b5So90KdEveMQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4615c45713b2b23c80a8c3e62bc9f7d3a3f907a5", "width": 1080, "height": 810}], "variants": {}, "id": "Bvvo36jh2LX5eZnzhmqX5VRT-ttyI1RIUIJ1Yx29Po0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yykzuc", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yykzuc/a_simple_de_project_with_airbyte_dbt_and_metabase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/airbyte-monitoring-with-dbt-and-metabase", "subreddit_subscribers": 80324, "created_utc": 1668780585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1- Saying yes, and building on top of existing business goal as a quick solution without taking the blame for the outcome which is usually a failure. After agreeing to the project once all the red flags are conveyed to business. \n\n2- Building from ground up for a proper DS project to solve a problem.", "author_fullname": "t2_3ftiaba8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science and Building a project on existing business solutions. I consider this to be a red flag or two pronged problem...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yyq13l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668793606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;1- Saying yes, and building on top of existing business goal as a quick solution without taking the blame for the outcome which is usually a failure. After agreeing to the project once all the red flags are conveyed to business. &lt;/p&gt;\n\n&lt;p&gt;2- Building from ground up for a proper DS project to solve a problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyq13l", "is_robot_indexable": true, "report_reasons": null, "author": "Zenith_N", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyq13l/data_science_and_building_a_project_on_existing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyq13l/data_science_and_building_a_project_on_existing/", "subreddit_subscribers": 80324, "created_utc": 1668793606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm trying to learn the delta architecture concept. I've got a problem understanding how to mange large incremental files. Delta concept assumes that bronze layer stores raw data, so if we have a bug in silver layer or we just want to make some adjustments,  we can always go back and recreate silver table (with unchanged bronze data).\n\nLet's say that we have a transactional table that grows 1 million rows per day. The business requirement is that the table should be refreshed daily. To fetch all the recent changes we need to go 3 days backwards every day and then insert/update data into production table.\n\nIn such case bronze daily extracts contain lots of overlapping data with other daily snapshots. Wouldn't it be better to load data incrementally into bronze layer right away (and save a lot of storage space)?", "author_fullname": "t2_33dfdmfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bronze layer (Delta Lake) data storage of incremental files.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyofae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668789569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m trying to learn the delta architecture concept. I&amp;#39;ve got a problem understanding how to mange large incremental files. Delta concept assumes that bronze layer stores raw data, so if we have a bug in silver layer or we just want to make some adjustments,  we can always go back and recreate silver table (with unchanged bronze data).&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say that we have a transactional table that grows 1 million rows per day. The business requirement is that the table should be refreshed daily. To fetch all the recent changes we need to go 3 days backwards every day and then insert/update data into production table.&lt;/p&gt;\n\n&lt;p&gt;In such case bronze daily extracts contain lots of overlapping data with other daily snapshots. Wouldn&amp;#39;t it be better to load data incrementally into bronze layer right away (and save a lot of storage space)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyofae", "is_robot_indexable": true, "report_reasons": null, "author": "bl_lato7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyofae/bronze_layer_delta_lake_data_storage_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyofae/bronze_layer_delta_lake_data_storage_of/", "subreddit_subscribers": 80324, "created_utc": 1668789569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which sites have good database benchmarks on them? I'm interested in SQL, NoSQL, Graph databases...", "author_fullname": "t2_tyl6qdc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database benchmarks - what are good sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yykwso", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668780359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which sites have good database benchmarks on them? I&amp;#39;m interested in SQL, NoSQL, Graph databases...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yykwso", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Plan591", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yykwso/database_benchmarks_what_are_good_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yykwso/database_benchmarks_what_are_good_sources/", "subreddit_subscribers": 80324, "created_utc": 1668780359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "so, interesting problem, and maybe im too used to doing things the old way, I need to update a hive table with new columns in source file in an automated way.. im allowed to connect to the db as well, so how would i go about updating the pipeline to accommodate new fields in a table, any tool/strategy that supports this?", "author_fullname": "t2_75uto0yh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to update hive tables with schema updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyk9dk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668778575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so, interesting problem, and maybe im too used to doing things the old way, I need to update a hive table with new columns in source file in an automated way.. im allowed to connect to the db as well, so how would i go about updating the pipeline to accommodate new fields in a table, any tool/strategy that supports this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyk9dk", "is_robot_indexable": true, "report_reasons": null, "author": "Impossible-Stop2243", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyk9dk/how_to_update_hive_tables_with_schema_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyk9dk/how_to_update_hive_tables_with_schema_updates/", "subreddit_subscribers": 80324, "created_utc": 1668778575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nI am trying to write a pyspark structured streaming program which reads  the changes from the  postgres log file in real time. I am not supposed to use Apache Kafka. Is there a way to do this?", "author_fullname": "t2_cb7rpz4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "read changes in log files in real time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyj98b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668775576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nI am trying to write a pyspark structured streaming program which reads  the changes from the  postgres log file in real time. I am not supposed to use Apache Kafka. Is there a way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yyj98b", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_marshmellow19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyj98b/read_changes_in_log_files_in_real_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyj98b/read_changes_in_log_files_in_real_time/", "subreddit_subscribers": 80324, "created_utc": 1668775576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If I have a feed of data / a data producer spitting out \\~100 items/second, are these stream processing services essentially just collecting all the data in a managed and controlled way and theoretically just sitting there? And then if I create additional services to analyze or process the data, do they talk to/consume the data.. essentially saying 'hey I'm ready to read you in, go?' Is that the main purpose of how stream data is dealt with?\n\nAlso how does one know/choose or figure out which of the services such as Kafka, event hubs, firehose, spark streaming, storm, link etc are all used for?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the purpose of stream processing engines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyc5sa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668749492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I have a feed of data / a data producer spitting out ~100 items/second, are these stream processing services essentially just collecting all the data in a managed and controlled way and theoretically just sitting there? And then if I create additional services to analyze or process the data, do they talk to/consume the data.. essentially saying &amp;#39;hey I&amp;#39;m ready to read you in, go?&amp;#39; Is that the main purpose of how stream data is dealt with?&lt;/p&gt;\n\n&lt;p&gt;Also how does one know/choose or figure out which of the services such as Kafka, event hubs, firehose, spark streaming, storm, link etc are all used for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yyc5sa", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yyc5sa/what_is_the_purpose_of_stream_processing_engines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yyc5sa/what_is_the_purpose_of_stream_processing_engines/", "subreddit_subscribers": 80324, "created_utc": 1668749492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm about to graduate with a DS bachelor's, and i've studied the fundamentals of programming and data structures/algorithm's. I want to expand my knowledge in the SE aspect of things. Is there a way to get there through courses/master's? Thank you.", "author_fullname": "t2_tqogom2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to get into DE/SE from a DS Bachelor's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy7gol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668734792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to graduate with a DS bachelor&amp;#39;s, and i&amp;#39;ve studied the fundamentals of programming and data structures/algorithm&amp;#39;s. I want to expand my knowledge in the SE aspect of things. Is there a way to get there through courses/master&amp;#39;s? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yy7gol", "is_robot_indexable": true, "report_reasons": null, "author": "subte_rancio", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy7gol/is_it_possible_to_get_into_dese_from_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy7gol/is_it_possible_to_get_into_dese_from_a_ds/", "subreddit_subscribers": 80324, "created_utc": 1668734792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From reading through this sub for a few months it seems to have attracted the attention of people from all different realms of the data world. Many of us seem to have backgrounds in Data Analysis, Data Architecture,  Business Analyst , Data Scenic and of course what we are all aspiring to be which is Engineers in the Data Space.\n\nThe common denominator seems to be we all have lots of experience using databases in one way or another. Me personally I started as a reporting analyst , upgraded to a more Data Analyst role and then started orchestrating my own ETLs and spinning up my own database environments for testing using tools like Docker or Hyper V VMs. I also took an interest in Data Science and started pursuing a master's degree in it but only ended up getting their 15 credit certificate of advanced study because I didn't have the time or money to finish the whole 34 credit program.\n\nI started incorporating some classification and clustering models into some of the analytics I was working on but never took it too far, and sometimes I would make a sexy visualization or two in R or Python instead of using something like Excel.\n\nWhat I'm noticing is that there is just so much overlap in these titles and the job duties that you are expected to perform. Sometimes I feel like a jack of all trades but a master of none. Right now I am working my first formal Data Engineering role and I'm hitting the ground running trying to learn as much as I can about it because I think it's more future proof (and interesting) than Data Science. \n\nI feel like these companies dream is to find some unicornish Data Jedi Master that can just come in and solve any data problem on the spot.  What would that title be ? And what kind of requirements would you want from that person. 10+ years of working in the data realm where you had exposure to a little bit of everything ? Or a more itemized list of requirements like knowing x number of years of specific skill sets with the tail end being something that is modern and upcoming.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What will the new hybrid Data Centric Job Title Be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy6z1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668733311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From reading through this sub for a few months it seems to have attracted the attention of people from all different realms of the data world. Many of us seem to have backgrounds in Data Analysis, Data Architecture,  Business Analyst , Data Scenic and of course what we are all aspiring to be which is Engineers in the Data Space.&lt;/p&gt;\n\n&lt;p&gt;The common denominator seems to be we all have lots of experience using databases in one way or another. Me personally I started as a reporting analyst , upgraded to a more Data Analyst role and then started orchestrating my own ETLs and spinning up my own database environments for testing using tools like Docker or Hyper V VMs. I also took an interest in Data Science and started pursuing a master&amp;#39;s degree in it but only ended up getting their 15 credit certificate of advanced study because I didn&amp;#39;t have the time or money to finish the whole 34 credit program.&lt;/p&gt;\n\n&lt;p&gt;I started incorporating some classification and clustering models into some of the analytics I was working on but never took it too far, and sometimes I would make a sexy visualization or two in R or Python instead of using something like Excel.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m noticing is that there is just so much overlap in these titles and the job duties that you are expected to perform. Sometimes I feel like a jack of all trades but a master of none. Right now I am working my first formal Data Engineering role and I&amp;#39;m hitting the ground running trying to learn as much as I can about it because I think it&amp;#39;s more future proof (and interesting) than Data Science. &lt;/p&gt;\n\n&lt;p&gt;I feel like these companies dream is to find some unicornish Data Jedi Master that can just come in and solve any data problem on the spot.  What would that title be ? And what kind of requirements would you want from that person. 10+ years of working in the data realm where you had exposure to a little bit of everything ? Or a more itemized list of requirements like knowing x number of years of specific skill sets with the tail end being something that is modern and upcoming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy6z1p", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy6z1p/what_will_the_new_hybrid_data_centric_job_title_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy6z1p/what_will_the_new_hybrid_data_centric_job_title_be/", "subreddit_subscribers": 80324, "created_utc": 1668733311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently reading Designing Data-Intensive Applications, the Data Warehouse Toolkit, and a system design interview book.\n\n\n\nDesigning Data-Intensive Applications is fascinating, but seems overly detailed at times.  Which makes me think I might be over-preparing.\n\n\n\n\nIn the new year, I'm preparing to interview for senior data engineering roles and more experienced mid-level roles.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I over-preparing for system design interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy4qq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668727027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently reading Designing Data-Intensive Applications, the Data Warehouse Toolkit, and a system design interview book.&lt;/p&gt;\n\n&lt;p&gt;Designing Data-Intensive Applications is fascinating, but seems overly detailed at times.  Which makes me think I might be over-preparing.&lt;/p&gt;\n\n&lt;p&gt;In the new year, I&amp;#39;m preparing to interview for senior data engineering roles and more experienced mid-level roles.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy4qq0", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy4qq0/am_i_overpreparing_for_system_design_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy4qq0/am_i_overpreparing_for_system_design_interviews/", "subreddit_subscribers": 80324, "created_utc": 1668727027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking for an easy move to the cloud but I can\u2019t find pricing info anywhere.", "author_fullname": "t2_dw6y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are you paying for Qlik Replicate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy343b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668722849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for an easy move to the cloud but I can\u2019t find pricing info anywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yy343b", "is_robot_indexable": true, "report_reasons": null, "author": "Squeebee007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy343b/what_are_you_paying_for_qlik_replicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy343b/what_are_you_paying_for_qlik_replicate/", "subreddit_subscribers": 80324, "created_utc": 1668722849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data teams use a lot of tools and understanding how access is configured across the growing stack is complex and exhausting. Jetty is a tiny peek at our broader vision of simplifying data privacy and we'd love you to give it a try and offer any feedback. It's free to use and available via \\`pip\\`!\n\nHere's our first blog post about why we're tackling this problem: [https://docs.get-jetty.com/blog/2022/11/17/hello-jetty](https://docs.get-jetty.com/blog/2022/11/17/hello-jetty)\n\nIf you want to jump straight in, here are the quickstart docs: [https://docs.get-jetty.com/getting-started/](https://docs.get-jetty.com/getting-started/)", "author_fullname": "t2_12c7ta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We just launched Jetty to help you understand permissions across Snowflake, dbt, and Tableau!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy2zq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668722543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data teams use a lot of tools and understanding how access is configured across the growing stack is complex and exhausting. Jetty is a tiny peek at our broader vision of simplifying data privacy and we&amp;#39;d love you to give it a try and offer any feedback. It&amp;#39;s free to use and available via `pip`!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s our first blog post about why we&amp;#39;re tackling this problem: &lt;a href=\"https://docs.get-jetty.com/blog/2022/11/17/hello-jetty\"&gt;https://docs.get-jetty.com/blog/2022/11/17/hello-jetty&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you want to jump straight in, here are the quickstart docs: &lt;a href=\"https://docs.get-jetty.com/getting-started/\"&gt;https://docs.get-jetty.com/getting-started/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?auto=webp&amp;s=b82066f4a0700f80d4671da79322ec36ef3642bf", "width": 390, "height": 100}, "resolutions": [{"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b407e0a2e8387f5ba5d0bc17b3366e520ccc7584", "width": 108, "height": 27}, {"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c103cfb8d8186a78bdf6d1f3dfd9d90aa55b9291", "width": 216, "height": 55}, {"url": "https://external-preview.redd.it/rWaNCe92wwS0idFN9IdsnW_jWropqmj36Jx3ft_VBMc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d6ed111359dd1e221170a94df59df176dc040f45", "width": 320, "height": 82}], "variants": {}, "id": "EdFQhio2xUgFD7h2xIFVJ4cxt8YCRUk9d_JB-s5xNAc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yy2zq2", "is_robot_indexable": true, "report_reasons": null, "author": "azjkjensen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yy2zq2/we_just_launched_jetty_to_help_you_understand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yy2zq2/we_just_launched_jetty_to_help_you_understand/", "subreddit_subscribers": 80324, "created_utc": 1668722543.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}