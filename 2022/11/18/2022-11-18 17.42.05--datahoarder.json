{"kind": "Listing", "data": {"after": "t3_yymt49", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&gt;Twitter has emailed staffers: \"Hi, Effective immediately, we are temporarily closing our office buildings and all badge access will be suspended. Offices will reopen on Monday, November 21st. .. We look forward to working with you on Twitter\u2019s exciting future.\"\n\n&amp;#x200B;\n\n&gt;Story to be updated soon with more: Am hearing that several \u201ccritical\u201d infra engineering teams at Twitter have completely resigned. \u201cYou cannot run Twitter without this team,\u201d one current engineer tells me of one such group. Also, Twitter has shut off badge access to its offices.\n\n&amp;#x200B;\n\n&gt;What I\u2019m hearing from Twitter employees; It looks like roughly 75% of the remaining 3,700ish Twitter employees have not opted to stay after the \u201chardcore\u201d email.  \n&gt;  \n&gt;Even though the deadline has passed, everyone still has access to their systems.\n\n&amp;#x200B;\n\n&gt;\u201cI know of six critical systems (like \u2018serving tweets\u2019 levels of critical) which no longer have any engineers,\" the former employee said. \"There is no longer even a skeleton crew manning the system. It will continue to coast until it runs into something, and then it will stop.\u201d  \n&gt;  \n&gt;Resignations and departures were already taking a toll on Twitter\u2019s service, employees said. \u201cBreakages are already happening slowly and accumulating,\u201d one said. \u201cIf you want to export your tweets, do it now.\u201d\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[Link 1](https://twitter.com/oliverdarcy/status/1593394621627138048)\n\n[Link 2](https://twitter.com/alexeheath/status/1593399683086327808)\n\n[Link 3](https://twitter.com/kyliebytes/status/1593391167718113280)\n\n[Link 4](https://www.washingtonpost.com/technology/2022/11/17/twitter-musk-easing-rto-order/)\n\n&amp;#x200B;\n\nEdit:\n\n[twitter-scraper (github no api-key needed)](https://github.com/n0madic/twitter-scraper)\n\n[twitter-media-downloader (github no api-key needed)](https://github.com/mmpx12/twitter-media-downloader)\n\n&amp;#x200B;\n\nEdit2:\n\n[https://github.com/markowanga/stweet](https://github.com/markowanga/stweet)\n\n&amp;#x200B;\n\nEdit3:\n\n[gallery-dl guide by /u/Scripter17](https://www.reddit.com/r/DataHoarder/comments/yy8o9w/for_everyone_using_gallerydl_to_backup_twitter/)\n\n&amp;#x200B;\n\nEdit4:\n\n[Twitter Media Downloader](https://chrome.google.com/webstore/detail/twitter-media-downloader/cblpjenafgeohmnjknfhpdbdljfkndig?hl=en)\n\n&amp;#x200B;\n\nEdit5:  \n[https://github.com/JustAnotherArchivist/snscrape](https://github.com/JustAnotherArchivist/snscrape)", "author_fullname": "t2_ioi0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup twitter now! Multiple critical infra teams have resigned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy7tig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 767, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 767, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668783041.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668735892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Twitter has emailed staffers: &amp;quot;Hi, Effective immediately, we are temporarily closing our office buildings and all badge access will be suspended. Offices will reopen on Monday, November 21st. .. We look forward to working with you on Twitter\u2019s exciting future.&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Story to be updated soon with more: Am hearing that several \u201ccritical\u201d infra engineering teams at Twitter have completely resigned. \u201cYou cannot run Twitter without this team,\u201d one current engineer tells me of one such group. Also, Twitter has shut off badge access to its offices.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;What I\u2019m hearing from Twitter employees; It looks like roughly 75% of the remaining 3,700ish Twitter employees have not opted to stay after the \u201chardcore\u201d email.  &lt;/p&gt;\n\n&lt;p&gt;Even though the deadline has passed, everyone still has access to their systems.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;\u201cI know of six critical systems (like \u2018serving tweets\u2019 levels of critical) which no longer have any engineers,&amp;quot; the former employee said. &amp;quot;There is no longer even a skeleton crew manning the system. It will continue to coast until it runs into something, and then it will stop.\u201d  &lt;/p&gt;\n\n&lt;p&gt;Resignations and departures were already taking a toll on Twitter\u2019s service, employees said. \u201cBreakages are already happening slowly and accumulating,\u201d one said. \u201cIf you want to export your tweets, do it now.\u201d&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/oliverdarcy/status/1593394621627138048\"&gt;Link 1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/alexeheath/status/1593399683086327808\"&gt;Link 2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/kyliebytes/status/1593391167718113280\"&gt;Link 3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.washingtonpost.com/technology/2022/11/17/twitter-musk-easing-rto-order/\"&gt;Link 4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/n0madic/twitter-scraper\"&gt;twitter-scraper (github no api-key needed)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mmpx12/twitter-media-downloader\"&gt;twitter-media-downloader (github no api-key needed)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit2:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/markowanga/stweet\"&gt;https://github.com/markowanga/stweet&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit3:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/yy8o9w/for_everyone_using_gallerydl_to_backup_twitter/\"&gt;gallery-dl guide by /u/Scripter17&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit4:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://chrome.google.com/webstore/detail/twitter-media-downloader/cblpjenafgeohmnjknfhpdbdljfkndig?hl=en\"&gt;Twitter Media Downloader&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit5:&lt;br/&gt;\n&lt;a href=\"https://github.com/JustAnotherArchivist/snscrape\"&gt;https://github.com/JustAnotherArchivist/snscrape&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yy7tig", "is_robot_indexable": true, "report_reasons": null, "author": "fourDnet", "discussion_type": null, "num_comments": 292, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy7tig/backup_twitter_now_multiple_critical_infra_teams/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/yy7tig/backup_twitter_now_multiple_critical_infra_teams/", "subreddit_subscribers": 654700, "created_utc": 1668735892.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_d48yz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google and Amazon Helped the FBI Identify Z-Library's Operators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyj1dc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 93, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 93, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1668774878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "torrentfreak.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://torrentfreak.com/how-google-and-amazon-helped-the-fbi-identify-z-librarys-operators-221117/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyj1dc", "is_robot_indexable": true, "report_reasons": null, "author": "Prometheus720", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyj1dc/google_and_amazon_helped_the_fbi_identify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://torrentfreak.com/how-google-and-amazon-helped-the-fbi-identify-z-librarys-operators-221117/", "subreddit_subscribers": 654700, "created_utc": 1668774878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Rewritten for clarity because speedrunning a post like this tends to leave questions\n\nHow to get started:\n\n1. Install [Python](https://www.python.org/). There is a standalone .exe but this just makes it easier to upgrade and all that\n\n2. Run `pip install gallery-dl` in command prompt (windows) or Bash (Linux)\n\n3. From there running `gallery-dl &lt;url&gt;` in the same command line should download the url's contents\n\n## config.json\n\nThe config.json is located at `%APPDATA%\\gallery-dl\\config.json` (windows) and `/etc/gallery-dl.conf` (Linux)\n\nIf the folder/file doesn't exist, just making it yourself should work\n\nThe basic config I recommend is this. If this is your first time with gallery-dl it's safe to just replace the entire file with this. If it's not your first time you should know how to transplant this into your existing config\n\n    {\n        \"extractor\":{\n            \"cookies\": [\"&lt;your browser (firefox, chromium, etc)&gt;\"],\n            \"twitter\":{\n                \"users\": \"https://twitter.com/{legacy[screen_name]}\",\n                \"text-tweets\":true,\n                \"retweets\":true,\n                \"quoted\":true,\n                \"logout\":true,\n                \"replies\":true,\n                \"postprocessors\":[\n                    {\"name\": \"metadata\", \"event\": \"post\", \"filename\": \"{tweet_id}_main.json\"}\n                ]\n            }\n        }\n    }\n\nThe documentation for the config.json is [here](https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst) and the specific part about getting cookies from your browser is [here](https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst#extractorcookies)\n\nCurrently supplying your login as a username/password combo seems to be broken. Idk if this is an issue with twitter or gallery-dl but using browser cookies is just easier in the long run\n\n## URLs:\n\n[The twitter API limits getting a user's page to the latest ~3200 tweets](https://github.com/mikf/gallery-dl/issues/2226). To get the as much as possible I recommend getting the main tab, the media tab, *and* the URL when you search for `from:&lt;user&gt;`\n\nTo make downloading the media tab not immediately exit when it sees a duplicate image, you'll want to add `-o skip=true` to the command you put in the command line. This can also be specified in the config. I have mine set to 20 when I'm just updating an existing download. If it sees 20 known images in a row then it moves on to the next one.\n\nThe 3 URLs I recommend downloading are:\n\n- `https://www.twitter.com/&lt;user&gt;`\n- `https://www.twitter.com/&lt;user&gt;/media`\n- `https://twitter.com/search?q=from:&lt;user&gt;`\n\nTo get someone's likes the URL is `https://www.twitter.com/&lt;user&gt;/likes`\n\nTo get your bookmarks the URL is `https://twitter.com/i/bookmarks`\n\n**Note**: Because twitter honestly just sucks and has for quite a while, you should run each download a few times (again with `-o skip=true`) to make sure you get everything\n\n## Commands:\n\nAnd the commands you're running should look like `gallery-dl &lt;url&gt; --write-metadata -o skip=true`\n\n`--write-metadata` saves `.json` files with metadata about each image. the `\"postprocessors\"` part of the config already writes the metadata for the tweet itself but the per-image metadata has some extra stuff\n\nIf you run `gallery-dl -g https://twitter.com/&lt;your handle&gt;/following` you can get a list of everyone you follow.\n\n### Windows:\n\nIf you have a text editor that supports regex replacement (CTRL+H in Sublime Text. Enable the button that looks like a .*), you can paste the list gallery-dl gave you and replace `(.+\\/)([^/\\r\\n]+)` with `gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{$2}\"\"]\"`\n\nYou should see something along the lines of\n\n    gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{test1}\"\"]\"\n    gallery-dl https://twitter.com/test2               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{test2}\"\"]\"\n    gallery-dl https://twitter.com/test3               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o \"directory=[\"\"twitter\"\",\"\"{test3}\"\"]\"\n\nThen put an `@echo off` at the top of the file and save it as a `.bat`\n\n### Linux:\n\nIf you have a text editor that supports regex replacement, you can paste the list gallery-dl gave you and replace `(.+\\/)([^/\\r\\n]+)` with `gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{$2}\\\"]\"`\n\nYou should see something along the lines of\n\n    gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{test1}\\\"]\"\n    gallery-dl https://twitter.com/test2               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{test2}\\\"]\"\n    gallery-dl https://twitter.com/test3               --write-metadata -o skip=true\n    gallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\n    gallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o \"directory=[\\\"twitter\\\",\\\"{test3}\\\"]\"\n\nThen save it as a `.sh` file\n\nIf, on either OS, the resulting commands has a bunch of `$1` and `$2` in it, replace the `$`s in the replacement string with `\\`s and do it again.\n\nAfter that, running the file should (assuming I got all the steps right) download everyone you follow\n\n.\n\nNow, if you excuse me, it's almost 6am and I need to sleep. I really hope I haven't made any catastrophic errors", "author_fullname": "t2_yj3jz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For everyone using gallery-dl to backup twitter: Make sure you do it right", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy8o9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668768882.0, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668738416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Rewritten for clarity because speedrunning a post like this tends to leave questions&lt;/p&gt;\n\n&lt;p&gt;How to get started:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Install &lt;a href=\"https://www.python.org/\"&gt;Python&lt;/a&gt;. There is a standalone .exe but this just makes it easier to upgrade and all that&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Run &lt;code&gt;pip install gallery-dl&lt;/code&gt; in command prompt (windows) or Bash (Linux)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;From there running &lt;code&gt;gallery-dl &amp;lt;url&amp;gt;&lt;/code&gt; in the same command line should download the url&amp;#39;s contents&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;config.json&lt;/h2&gt;\n\n&lt;p&gt;The config.json is located at &lt;code&gt;%APPDATA%\\gallery-dl\\config.json&lt;/code&gt; (windows) and &lt;code&gt;/etc/gallery-dl.conf&lt;/code&gt; (Linux)&lt;/p&gt;\n\n&lt;p&gt;If the folder/file doesn&amp;#39;t exist, just making it yourself should work&lt;/p&gt;\n\n&lt;p&gt;The basic config I recommend is this. If this is your first time with gallery-dl it&amp;#39;s safe to just replace the entire file with this. If it&amp;#39;s not your first time you should know how to transplant this into your existing config&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n    &amp;quot;extractor&amp;quot;:{\n        &amp;quot;cookies&amp;quot;: [&amp;quot;&amp;lt;your browser (firefox, chromium, etc)&amp;gt;&amp;quot;],\n        &amp;quot;twitter&amp;quot;:{\n            &amp;quot;users&amp;quot;: &amp;quot;https://twitter.com/{legacy[screen_name]}&amp;quot;,\n            &amp;quot;text-tweets&amp;quot;:true,\n            &amp;quot;retweets&amp;quot;:true,\n            &amp;quot;quoted&amp;quot;:true,\n            &amp;quot;logout&amp;quot;:true,\n            &amp;quot;replies&amp;quot;:true,\n            &amp;quot;postprocessors&amp;quot;:[\n                {&amp;quot;name&amp;quot;: &amp;quot;metadata&amp;quot;, &amp;quot;event&amp;quot;: &amp;quot;post&amp;quot;, &amp;quot;filename&amp;quot;: &amp;quot;{tweet_id}_main.json&amp;quot;}\n            ]\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The documentation for the config.json is &lt;a href=\"https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst\"&gt;here&lt;/a&gt; and the specific part about getting cookies from your browser is &lt;a href=\"https://github.com/mikf/gallery-dl/blob/master/docs/configuration.rst#extractorcookies\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently supplying your login as a username/password combo seems to be broken. Idk if this is an issue with twitter or gallery-dl but using browser cookies is just easier in the long run&lt;/p&gt;\n\n&lt;h2&gt;URLs:&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mikf/gallery-dl/issues/2226\"&gt;The twitter API limits getting a user&amp;#39;s page to the latest ~3200 tweets&lt;/a&gt;. To get the as much as possible I recommend getting the main tab, the media tab, &lt;em&gt;and&lt;/em&gt; the URL when you search for &lt;code&gt;from:&amp;lt;user&amp;gt;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;To make downloading the media tab not immediately exit when it sees a duplicate image, you&amp;#39;ll want to add &lt;code&gt;-o skip=true&lt;/code&gt; to the command you put in the command line. This can also be specified in the config. I have mine set to 20 when I&amp;#39;m just updating an existing download. If it sees 20 known images in a row then it moves on to the next one.&lt;/p&gt;\n\n&lt;p&gt;The 3 URLs I recommend downloading are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;https://www.twitter.com/&amp;lt;user&amp;gt;&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;https://www.twitter.com/&amp;lt;user&amp;gt;/media&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;https://twitter.com/search?q=from:&amp;lt;user&amp;gt;&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To get someone&amp;#39;s likes the URL is &lt;code&gt;https://www.twitter.com/&amp;lt;user&amp;gt;/likes&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;To get your bookmarks the URL is &lt;code&gt;https://twitter.com/i/bookmarks&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Because twitter honestly just sucks and has for quite a while, you should run each download a few times (again with &lt;code&gt;-o skip=true&lt;/code&gt;) to make sure you get everything&lt;/p&gt;\n\n&lt;h2&gt;Commands:&lt;/h2&gt;\n\n&lt;p&gt;And the commands you&amp;#39;re running should look like &lt;code&gt;gallery-dl &amp;lt;url&amp;gt; --write-metadata -o skip=true&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;--write-metadata&lt;/code&gt; saves &lt;code&gt;.json&lt;/code&gt; files with metadata about each image. the &lt;code&gt;&amp;quot;postprocessors&amp;quot;&lt;/code&gt; part of the config already writes the metadata for the tweet itself but the per-image metadata has some extra stuff&lt;/p&gt;\n\n&lt;p&gt;If you run &lt;code&gt;gallery-dl -g https://twitter.com/&amp;lt;your handle&amp;gt;/following&lt;/code&gt; you can get a list of everyone you follow.&lt;/p&gt;\n\n&lt;h3&gt;Windows:&lt;/h3&gt;\n\n&lt;p&gt;If you have a text editor that supports regex replacement (CTRL+H in Sublime Text. Enable the button that looks like a .*), you can paste the list gallery-dl gave you and replace &lt;code&gt;(.+\\/)([^/\\r\\n]+)&lt;/code&gt; with &lt;code&gt;gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{$2}&amp;quot;&amp;quot;]&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;You should see something along the lines of&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{test1}&amp;quot;&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test2               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{test2}&amp;quot;&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test3               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o &amp;quot;directory=[&amp;quot;&amp;quot;twitter&amp;quot;&amp;quot;,&amp;quot;&amp;quot;{test3}&amp;quot;&amp;quot;]&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then put an &lt;code&gt;@echo off&lt;/code&gt; at the top of the file and save it as a &lt;code&gt;.bat&lt;/code&gt;&lt;/p&gt;\n\n&lt;h3&gt;Linux:&lt;/h3&gt;\n\n&lt;p&gt;If you have a text editor that supports regex replacement, you can paste the list gallery-dl gave you and replace &lt;code&gt;(.+\\/)([^/\\r\\n]+)&lt;/code&gt; with &lt;code&gt;gallery-dl $1$2               --write-metadata -o skip=true\\ngallery-dl $1$2/media         --write-metadata -o skip=true\\ngallery-dl $1search?q=from:$2 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{$2}\\&amp;quot;]&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;You should see something along the lines of&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl https://twitter.com/test1               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test1/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test1 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{test1}\\&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test2               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test2/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test2 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{test2}\\&amp;quot;]&amp;quot;\ngallery-dl https://twitter.com/test3               --write-metadata -o skip=true\ngallery-dl https://twitter.com/test3/media         --write-metadata -o skip=true\ngallery-dl https://twitter.com/search?q=from:test3 --write-metadata -o skip=true -o &amp;quot;directory=[\\&amp;quot;twitter\\&amp;quot;,\\&amp;quot;{test3}\\&amp;quot;]&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then save it as a &lt;code&gt;.sh&lt;/code&gt; file&lt;/p&gt;\n\n&lt;p&gt;If, on either OS, the resulting commands has a bunch of &lt;code&gt;$1&lt;/code&gt; and &lt;code&gt;$2&lt;/code&gt; in it, replace the &lt;code&gt;$&lt;/code&gt;s in the replacement string with &lt;code&gt;\\&lt;/code&gt;s and do it again.&lt;/p&gt;\n\n&lt;p&gt;After that, running the file should (assuming I got all the steps right) download everyone you follow&lt;/p&gt;\n\n&lt;p&gt;.&lt;/p&gt;\n\n&lt;p&gt;Now, if you excuse me, it&amp;#39;s almost 6am and I need to sleep. I really hope I haven&amp;#39;t made any catastrophic errors&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XACIlvLRgD0CrsIsxO7yWQMICHPINiGesu3WjxQxeXs.jpg?auto=webp&amp;s=c7f0d77306cb94adced1c514958fdf68f575791c", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/XACIlvLRgD0CrsIsxO7yWQMICHPINiGesu3WjxQxeXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0a156ee41a904137a12d7727f03ba51aa2a31c7", "width": 108, "height": 108}], "variants": {}, "id": "_QTobzuJkr1Zm6t-xAciOuvRRUG3sFX1cl1tVTmHCMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "The sexiest data storage medium", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy8o9w", "is_robot_indexable": true, "report_reasons": null, "author": "Scripter17", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yy8o9w/for_everyone_using_gallerydl_to_backup_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy8o9w/for_everyone_using_gallerydl_to_backup_twitter/", "subreddit_subscribers": 654700, "created_utc": 1668738416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ihhqghp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just snagged this on Amazon UK Black Friday Sale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yyg9f3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/t0QdmbTBFOZAyjfowwNYjHzCO76zS6S9QCtIRXq5XQ8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668765062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/pulb0zra3q0a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?auto=webp&amp;s=064dc021967fba1f97f6a98730f8780fd59ddfe3", "width": 1290, "height": 2796}, "resolutions": [{"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5639047d72e19e25073a3f3c2140ebe8085bc153", "width": 108, "height": 216}, {"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f439f75a13da20d16c4960144dcfa67c229334e", "width": 216, "height": 432}, {"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec9910faafefbed4dc9af1f9d1082bce7f97db6e", "width": 320, "height": 640}, {"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=86142c4fecd9aae10ef5121d62b444b9c6e11f0d", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8285610e80820165e22f600f2f4f7b9a156a13e2", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/pulb0zra3q0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8aec81b4a6cd12f40e30865faf9c72aedee029ea", "width": 1080, "height": 2160}], "variants": {}, "id": "NpCU_UcXrABz_XqsWmyewmI77IdJg7pOzeHQxDQ3xOI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyg9f3", "is_robot_indexable": true, "report_reasons": null, "author": "arjan5", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyg9f3/just_snagged_this_on_amazon_uk_black_friday_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/pulb0zra3q0a1.jpg", "subreddit_subscribers": 654700, "created_utc": 1668765062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_tlgcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A database of paper airplanes with easy to follow folding instructions, video tutorials and printable folding plans. Find the best paper airplanes that fly the furthest and stay aloft the longest.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yyhavo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 78, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 78, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/prZ5H2m6FUcoXaVYAgI4mTKRMuTFDWbsdOBELddMgW8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668769050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "foldnfly.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.foldnfly.com/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?auto=webp&amp;s=2e319bc9673fc40f1aec8c70febd71b2f84b10cb", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d37c2a5e835ea4c51b538aef5cbbd90f4e401217", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4d339c5a12d9cf0b1cf1a15d74138abbb400754", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b622d929f9312bf9d0f6019c52870b890a6d4ad", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d65b5cd84e8524d5d83e756f6a19fffc433d5b12", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=69a20c6d882a8d34f6c8dea2fec83e9b577a5f29", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/WVp0m9OUTYQ0kDtjcDJDARG5lVeC4REtkVmsdLIvLJ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94570fce0f309e51fd4ca001f841c5a99f97f58d", "width": 1080, "height": 567}], "variants": {}, "id": "uZ2zDM2Hy1FLstbjMCzVaGvaO0jNdvizg4F-yPk7isI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB Synology DS1819+", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyhavo", "is_robot_indexable": true, "report_reasons": null, "author": "PaddleMonkey", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yyhavo/a_database_of_paper_airplanes_with_easy_to_follow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.foldnfly.com/", "subreddit_subscribers": 654700, "created_utc": 1668769050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I am probably way out of my depth here but r/Twitter redirected me here when I asked this question. In case Twitter actually does go away I am trying to download the entire Twitter feed of my best friend who passed away 5 years ago. I\u2019m currently just screenshotting favorites in a panic and googling returns old workarounds that don\u2019t work anymore. Any advice at all is appreciated, thank you.", "author_fullname": "t2_eo84n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download An Entire Twitter Feed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy8dii", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668737540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am probably way out of my depth here but &lt;a href=\"/r/Twitter\"&gt;r/Twitter&lt;/a&gt; redirected me here when I asked this question. In case Twitter actually does go away I am trying to download the entire Twitter feed of my best friend who passed away 5 years ago. I\u2019m currently just screenshotting favorites in a panic and googling returns old workarounds that don\u2019t work anymore. Any advice at all is appreciated, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy8dii", "is_robot_indexable": true, "report_reasons": null, "author": "plaidtuxedo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy8dii/download_an_entire_twitter_feed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy8dii/download_an_entire_twitter_feed/", "subreddit_subscribers": 654700, "created_utc": 1668737540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a thread for current blackfriday storage discounts like last year?", "author_fullname": "t2_4y7ra1ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black Friday thread", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyc1vh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668749117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a thread for current blackfriday storage discounts like last year?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyc1vh", "is_robot_indexable": true, "report_reasons": null, "author": "HolUp-", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyc1vh/black_friday_thread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyc1vh/black_friday_thread/", "subreddit_subscribers": 654700, "created_utc": 1668749117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there usually good deals for hard drives on these days? I'm finally building my first NAS and want to find good deals obviously.   Is it worth waiting for Black Friday / Cyber Monday deals or are they going to be just crap drives?\n\nThanks!", "author_fullname": "t2_140qwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black Friday/ Cyber Monday deals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxw0kh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668705932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there usually good deals for hard drives on these days? I&amp;#39;m finally building my first NAS and want to find good deals obviously.   Is it worth waiting for Black Friday / Cyber Monday deals or are they going to be just crap drives?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxw0kh", "is_robot_indexable": true, "report_reasons": null, "author": "Mastasmoker", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxw0kh/black_friday_cyber_monday_deals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxw0kh/black_friday_cyber_monday_deals/", "subreddit_subscribers": 654700, "created_utc": 1668705932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "About 5 months ago, arguably the largest database of doujinshi and manga (Doujinshi.org) seemingly went down over night. The site had thousands of contributors collecting information on even the most obscure and most niche indie works over nearly a DECADE. Most of which was untranslated, so you can imagine the treasure trove of information. A shit ton of stuff that not even hardcore weebs know exists.\n\nThe owner made [this](https://twitter.com/tenetan/status/1550839774969208833) tweet the day the site went offline. This is the only update they have given, ever. No tweets since, absolutely nothing. There isn't a discord or a subreddit or anything either where one would be able to contact them. They do however still seem to [like drawings of anime girls on twitter](https://i.imgur.com/b3jFx1K.png), unbothered by the countless of people asking for updates.\n\nFor all we know they could be in financial trouble or be sick or whatever. We simply do not know. But what is pissing me off to no end is the fact that they are radio silent. If you host a database that is almost entirely dependant on the community, you have the obligation and responsibility to inform them of what's become of their effort if you ask me. They \\*owe\\* communcation. Because at that point, the site isn't even the owners anymore.\n\nNow, I have a question to my fellow data hoarders, and it's the reason why I'm posting this in the first place. What the hell are we supposed to? There's no archives or backups anywhere; the site wasn't all too popular, evident by the fact that no one is even talking about this despite it being the biggest ressource for Japanese fan works.\n\nTo be honest, I really doubt it's going to come back. And I fear this might be another Library of Alexandria scenario...", "author_fullname": "t2_d5g3mn4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Largest Doujinshi and Manga Lexicon Went Down 5 Months Ago and No One Cares", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxwkd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668707282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About 5 months ago, arguably the largest database of doujinshi and manga (Doujinshi.org) seemingly went down over night. The site had thousands of contributors collecting information on even the most obscure and most niche indie works over nearly a DECADE. Most of which was untranslated, so you can imagine the treasure trove of information. A shit ton of stuff that not even hardcore weebs know exists.&lt;/p&gt;\n\n&lt;p&gt;The owner made &lt;a href=\"https://twitter.com/tenetan/status/1550839774969208833\"&gt;this&lt;/a&gt; tweet the day the site went offline. This is the only update they have given, ever. No tweets since, absolutely nothing. There isn&amp;#39;t a discord or a subreddit or anything either where one would be able to contact them. They do however still seem to &lt;a href=\"https://i.imgur.com/b3jFx1K.png\"&gt;like drawings of anime girls on twitter&lt;/a&gt;, unbothered by the countless of people asking for updates.&lt;/p&gt;\n\n&lt;p&gt;For all we know they could be in financial trouble or be sick or whatever. We simply do not know. But what is pissing me off to no end is the fact that they are radio silent. If you host a database that is almost entirely dependant on the community, you have the obligation and responsibility to inform them of what&amp;#39;s become of their effort if you ask me. They *owe* communcation. Because at that point, the site isn&amp;#39;t even the owners anymore.&lt;/p&gt;\n\n&lt;p&gt;Now, I have a question to my fellow data hoarders, and it&amp;#39;s the reason why I&amp;#39;m posting this in the first place. What the hell are we supposed to? There&amp;#39;s no archives or backups anywhere; the site wasn&amp;#39;t all too popular, evident by the fact that no one is even talking about this despite it being the biggest ressource for Japanese fan works.&lt;/p&gt;\n\n&lt;p&gt;To be honest, I really doubt it&amp;#39;s going to come back. And I fear this might be another Library of Alexandria scenario...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A39rPq03PqwgcbXWQppLdcN5AeSiXDvlH7tPcHsAh1Q.png?auto=webp&amp;s=879d33faecaf0361ff93445bf2f7bac5b4bcafc5", "width": 586, "height": 695}, "resolutions": [{"url": "https://external-preview.redd.it/A39rPq03PqwgcbXWQppLdcN5AeSiXDvlH7tPcHsAh1Q.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c2c17a640d7412041f27536106544263a54ead6", "width": 108, "height": 128}, {"url": "https://external-preview.redd.it/A39rPq03PqwgcbXWQppLdcN5AeSiXDvlH7tPcHsAh1Q.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=841ba32d3ece1119693ee620ffc6858977a5d73d", "width": 216, "height": 256}, {"url": "https://external-preview.redd.it/A39rPq03PqwgcbXWQppLdcN5AeSiXDvlH7tPcHsAh1Q.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1177f2e748708d2001e85c789d08ed532347397f", "width": 320, "height": 379}], "variants": {}, "id": "WFdf4X6f7FV-nDYfv84KJrMGtgaGBMHKgAzMvk6EscM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxwkd5", "is_robot_indexable": true, "report_reasons": null, "author": "scremixz566", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxwkd5/largest_doujinshi_and_manga_lexicon_went_down_5/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxwkd5/largest_doujinshi_and_manga_lexicon_went_down_5/", "subreddit_subscribers": 654700, "created_utc": 1668707282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Lots of options to scrape your tweets, but I have a lot of bookmarks I also wanna back up.\n\nI found a way to download all the tweet URLs into a csv ([Dewey](https://getdewey.co/)) and a way to download videos and gifs independently ([youtube-dl](https://youtube-dl-helper.github.io/)) but I can't find a way to do it all at the same time.\n\nEverything into a XML file would be ideal. Also if possible it would be nice for it to keep threads (which should be possible if not annoying)\n\nI found [this](https://gist.github.com/CJKinni/3063070) but it's very old code and has basically no chance to work", "author_fullname": "t2_ykkhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get all my Twitter bookmarks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy978v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668739972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of options to scrape your tweets, but I have a lot of bookmarks I also wanna back up.&lt;/p&gt;\n\n&lt;p&gt;I found a way to download all the tweet URLs into a csv (&lt;a href=\"https://getdewey.co/\"&gt;Dewey&lt;/a&gt;) and a way to download videos and gifs independently (&lt;a href=\"https://youtube-dl-helper.github.io/\"&gt;youtube-dl&lt;/a&gt;) but I can&amp;#39;t find a way to do it all at the same time.&lt;/p&gt;\n\n&lt;p&gt;Everything into a XML file would be ideal. Also if possible it would be nice for it to keep threads (which should be possible if not annoying)&lt;/p&gt;\n\n&lt;p&gt;I found &lt;a href=\"https://gist.github.com/CJKinni/3063070\"&gt;this&lt;/a&gt; but it&amp;#39;s very old code and has basically no chance to work&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?auto=webp&amp;s=e2d60ad36c7afe27744a4b4f63f20d3181954d4b", "width": 1015, "height": 494}, "resolutions": [{"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4de019e984fdeee8a89ce7e525e828568019fd28", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=06f53d6a2f1e4248b34fb2643cd2df9e85f63585", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=11aa0debd38927b0c86148157dd6fb2be3425330", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a008abc197d7c09c8a6d7c679a7a14dfeb6aff84", "width": 640, "height": 311}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8407e59962bf38175018cc891c88bea773d2b655", "width": 960, "height": 467}], "variants": {}, "id": "D83W6ubnaf9JIZcLbn0OsGoknMj1En17FJrGkylXYzs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy978v", "is_robot_indexable": true, "report_reasons": null, "author": "PowderPhysics", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy978v/how_to_get_all_my_twitter_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy978v/how_to_get_all_my_twitter_bookmarks/", "subreddit_subscribers": 654700, "created_utc": 1668739972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Should i get 5 of these for my NAS? Curious if its worth it to use these or bite the bullet and get the Reds for a but more money.  \n\n\nThey are currently $199.99 at BestBuy\n\nWD - easystore 14TB External USB 3.0 Hard Drive - Black\n\nModel:WDBAMA0140HBK-NESNSKU:6425303\n\n[https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303](https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303)", "author_fullname": "t2_8wu8x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD - easystore 14TB External USB 3.0 Hard Drive For NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyk7mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Shuckable NAS Drives", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668778440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should i get 5 of these for my NAS? Curious if its worth it to use these or bite the bullet and get the Reds for a but more money.  &lt;/p&gt;\n\n&lt;p&gt;They are currently $199.99 at BestBuy&lt;/p&gt;\n\n&lt;p&gt;WD - easystore 14TB External USB 3.0 Hard Drive - Black&lt;/p&gt;\n\n&lt;p&gt;Model:WDBAMA0140HBK-NESNSKU:6425303&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303\"&gt;https://www.bestbuy.com/site/wd-easystore-14tb-external-usb-3-0-hard-drive-black/6425303.p?skuId=6425303&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?auto=webp&amp;s=0d9dc09b0ad8bb581b3f12d19a61f850933bb13d", "width": 1452, "height": 5012}, "resolutions": [{"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f13038664e7cac7334520eb6f6219ebcaa06077d", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ced7daed466de03f936545afae108a381fbd5548", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99ce2e22c9b74024d7f6948409a3403bb9821faf", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a06827eb64f82327b663eeb4bcc50b34736b2469", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=959de205f67d48894b89a59f2999a355aea021a3", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/ZseKVRgX3jeJqr848TEUnFsXmb36I5tfKDi8Zy3BG-o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f171001b6b2b3e2579548bf4f45f34f0ee94f5cb", "width": 1080, "height": 2160}], "variants": {}, "id": "v3nUqdM-I-azEYHHZp7B5iu55trREQB_4lBrJlrXTo0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yyk7mz", "is_robot_indexable": true, "report_reasons": null, "author": "ironman52885", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyk7mz/wd_easystore_14tb_external_usb_30_hard_drive_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyk7mz/wd_easystore_14tb_external_usb_30_hard_drive_for/", "subreddit_subscribers": 654700, "created_utc": 1668778440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7w4k6ew8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Users urged to archive tweets amid rumors of Twitter implosion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yymkm3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/eALEhho84LazRxOlfZEM6k9800EAMqAzryV6fTLtZc8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668784757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theguardian.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theguardian.com/technology/2022/nov/17/twitter-archive-tweets-company-shuts", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?auto=webp&amp;s=1a1c0054b85a7f182043ecc83a24c61ed68b81da", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28e937736e790e72762917e976d26195cfe61fd0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5be5a1ef1f03e74076ada75bb970130fe7d027e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ae5b4b15e0e9348a170bccc6ee4291f4410491b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=774d8fc94fb5c43dea6ec1a6270926be8c2df19a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7384756fc81363733e6c438330eac0e52e25f5ae", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Ip5DRtw-aLUv8vdwCuNwFZx6-c4vgkuFjAhEUWk1x_I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5898eeaaa637f96d892c11a4b505afe236bc039", "width": 1080, "height": 567}], "variants": {}, "id": "e73AQNWJSsqrckdWSHBK6HJXAG6Ufrm3I_6DS13ZpN8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yymkm3", "is_robot_indexable": true, "report_reasons": null, "author": "Buddy_Deep", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yymkm3/users_urged_to_archive_tweets_amid_rumors_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theguardian.com/technology/2022/nov/17/twitter-archive-tweets-company-shuts", "subreddit_subscribers": 654700, "created_utc": 1668784757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Genuinely decent chance Twitter might pop in the near future.](https://twitter.com/alexeheath/status/1593399683086327808?s=20&amp;t=dfeufbahrPBgan8EqpYe1w) Does anyone know how to save tweets from an account en masse? Worried that some people might not archive their own things before it's too late. Sorry if this doesn't fit the sub?\n\nAll the tools I can find are pay-to-use which is wild, except archive.org which only saves the most recent page of tweets from an account? Like a few days' worth roughly.", "author_fullname": "t2_yeb0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I archive other people's twitter accounts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy7yvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668736340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://twitter.com/alexeheath/status/1593399683086327808?s=20&amp;amp;t=dfeufbahrPBgan8EqpYe1w\"&gt;Genuinely decent chance Twitter might pop in the near future.&lt;/a&gt; Does anyone know how to save tweets from an account en masse? Worried that some people might not archive their own things before it&amp;#39;s too late. Sorry if this doesn&amp;#39;t fit the sub?&lt;/p&gt;\n\n&lt;p&gt;All the tools I can find are pay-to-use which is wild, except archive.org which only saves the most recent page of tweets from an account? Like a few days&amp;#39; worth roughly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy7yvo", "is_robot_indexable": true, "report_reasons": null, "author": "SansFinalGuardian", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy7yvo/how_can_i_archive_other_peoples_twitter_accounts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy7yvo/how_can_i_archive_other_peoples_twitter_accounts/", "subreddit_subscribers": 654700, "created_utc": 1668736340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_bzjnaypn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Seagate 4tb Expansion drive with a 12V Power supply a good buy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_yynve8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aBeakvC6Vv0YkfO0S3gfpHCU70r4aPJA6fnenmEaAIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668788157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vnxtoanyzr0a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?auto=webp&amp;s=cd5addd911e381950d8d641e30abcb82260a33fa", "width": 4000, "height": 3000}, "resolutions": [{"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99227f737f30c31a1b351c2bbf70e37432de0bc5", "width": 108, "height": 81}, {"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db75fb5e53a21b2a4b1d446037e45edd86f090fd", "width": 216, "height": 162}, {"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b911ecb3f16521c0e19cd83634aefae060e07e", "width": 320, "height": 240}, {"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7bac5e1f2edd653465e75497352102569771ddd4", "width": 640, "height": 480}, {"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3bcea0191a40e8c48b644b8cbed118e7950882e", "width": 960, "height": 720}, {"url": "https://preview.redd.it/vnxtoanyzr0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e8df8a8eb80e8a23267cfafd135ebf50b44fffee", "width": 1080, "height": 810}], "variants": {}, "id": "0QZlluD0A4bT9g0d0GzYJD-yuQWi48bHK2ZGos64QIw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yynve8", "is_robot_indexable": true, "report_reasons": null, "author": "Small-Special-7735", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yynve8/is_seagate_4tb_expansion_drive_with_a_12v_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vnxtoanyzr0a1.jpg", "subreddit_subscribers": 654700, "created_utc": 1668788157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "*Note: I do have all the data I'm referring to backed up elsewhere*\n\nI'm on Windows 10 Pro and I've got two identical dynamic disks -- 3TB each with 2.4TB (or whatever) filled, each. I want to convert them to spanned or striped (haven't decided which, yet) but I don't seem to have the option -- it's greyed out in Disk Manager:\n\nhttps://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81\n\nDo I...need to shrink the disks to make room? I'm hesitant to try that without getting thoughts from others because it'll take the better part of a day, each disk. Do I...need to delete the volumes and create the array from scratch?\n\nI'd prefer a non-destructive option if possible. I'm willing to delete these because the data is backed up, but restoring it will be a PITA :)\n\nMuch appreciated.", "author_fullname": "t2_36jz3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows: Can dynamic disks not be converted to spanned/striped?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"b203wafbjm0a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=94b6126cadbbbb1376df665d6a170fc771860b95"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ea9718fef595c82c340ac3622c2b2a951e1052b"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2265f302a5ff338b74ebf4de0a9b17ebb80d3252"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7cd33c67ecfeec80a2ec3738e382e54eecd19144"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=063565c5bab55cb108d470c859daba852a0a356d"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7893f3501b0345bcf7d35fda3017a05d217bb596"}], "s": {"y": 900, "x": 1440, "u": "https://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81"}, "id": "b203wafbjm0a1"}}, "name": "t3_yy99ds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vMb3XlrxBTmOW43DaRSvG5q-XrdleZUhBeYHO6lSV00.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668740163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Note: I do have all the data I&amp;#39;m referring to backed up elsewhere&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on Windows 10 Pro and I&amp;#39;ve got two identical dynamic disks -- 3TB each with 2.4TB (or whatever) filled, each. I want to convert them to spanned or striped (haven&amp;#39;t decided which, yet) but I don&amp;#39;t seem to have the option -- it&amp;#39;s greyed out in Disk Manager:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81\"&gt;https://preview.redd.it/b203wafbjm0a1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b57714bbcb5fb9e4fdc5ca8832838a0716c36e81&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do I...need to shrink the disks to make room? I&amp;#39;m hesitant to try that without getting thoughts from others because it&amp;#39;ll take the better part of a day, each disk. Do I...need to delete the volumes and create the array from scratch?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefer a non-destructive option if possible. I&amp;#39;m willing to delete these because the data is backed up, but restoring it will be a PITA :)&lt;/p&gt;\n\n&lt;p&gt;Much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy99ds", "is_robot_indexable": true, "report_reasons": null, "author": "eriksrx", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy99ds/windows_can_dynamic_disks_not_be_converted_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy99ds/windows_can_dynamic_disks_not_be_converted_to/", "subreddit_subscribers": 654700, "created_utc": 1668740163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to have a reddit account years ago that I deleted. I regret deleting it and want to view my old posts but don't know how to access it.", "author_fullname": "t2_toe2sph2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find deleted posts from a reddit user?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yync9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668786804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to have a reddit account years ago that I deleted. I regret deleting it and want to view my old posts but don&amp;#39;t know how to access it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yync9m", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayaccount29_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yync9m/how_to_find_deleted_posts_from_a_reddit_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yync9m/how_to_find_deleted_posts_from_a_reddit_user/", "subreddit_subscribers": 654700, "created_utc": 1668786804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So recently I heard plenty of rumours saying twitter will shut down, and so I decided to secure all my bookmarks. I already have my bookmarks synced in [dewey](https://getdewey.co/how-to-use/export-bookmarks/) and [BirdBear](https://birdbear.app/) yet I'm not sure if I'm going to be able to access the content after god forbid Twitter is gone.\n\nIs there a way to download them or store them in a cloud storage or whatever (i'm not experienced in this data stuff..)?", "author_fullname": "t2_65e2rxyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to gain access to my twitter bookmarks forever even in case of Twitter shutdown?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyiot5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668774562.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668773746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So recently I heard plenty of rumours saying twitter will shut down, and so I decided to secure all my bookmarks. I already have my bookmarks synced in &lt;a href=\"https://getdewey.co/how-to-use/export-bookmarks/\"&gt;dewey&lt;/a&gt; and &lt;a href=\"https://birdbear.app/\"&gt;BirdBear&lt;/a&gt; yet I&amp;#39;m not sure if I&amp;#39;m going to be able to access the content after god forbid Twitter is gone.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to download them or store them in a cloud storage or whatever (i&amp;#39;m not experienced in this data stuff..)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?auto=webp&amp;s=e2d60ad36c7afe27744a4b4f63f20d3181954d4b", "width": 1015, "height": 494}, "resolutions": [{"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4de019e984fdeee8a89ce7e525e828568019fd28", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=06f53d6a2f1e4248b34fb2643cd2df9e85f63585", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=11aa0debd38927b0c86148157dd6fb2be3425330", "width": 320, "height": 155}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a008abc197d7c09c8a6d7c679a7a14dfeb6aff84", "width": 640, "height": 311}, {"url": "https://external-preview.redd.it/AEdc_3tJelQQvC6DWwF19CLav4eOuAbCnyD661amR-4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8407e59962bf38175018cc891c88bea773d2b655", "width": 960, "height": 467}], "variants": {}, "id": "D83W6ubnaf9JIZcLbn0OsGoknMj1En17FJrGkylXYzs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyiot5", "is_robot_indexable": true, "report_reasons": null, "author": "AYMAAAAAAAAAAAAAAAAN", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyiot5/is_there_a_way_to_gain_access_to_my_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyiot5/is_there_a_way_to_gain_access_to_my_twitter/", "subreddit_subscribers": 654700, "created_utc": 1668773746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hiya. I've bought an old 8 bay server that came with\n\n* 4x 1TB drives in it\n* Supermicro X9DRH-7TF/7F/iTF/iF motherboard\n* Xeon E5-2603 1.80 GHz\n* 8gb or DDR3 1333 Mhz ram\n* Areca Arc-1222 pcie raid controller\n* A proprietary modified debian 6 by a local it company\n\nIt was working fine but then I thought let's try adding more drives into the remaining bays and see how that works\n\nWell. It didn't. I managed to expand the raidset but the proprietary software that runs filesharing was pretty obfuscated and locked down with how and what it sees. I've contacted the company and they said 'sorry mate, that things been out of support for years. buy a new one'\n\nSo I jumped onto the next logical step. Let's wipe the whole thing and install something else on it. So I wiped it and tried installing openmediavault.\n\nBooted into installer, all looking good.Installer sees all my raidcard volumes, all good.\n\nInstalled it on a dedicated 10GB OS partition on the raidcard, all good.\n\nReboot\n\nSee the grub window\n\nThen black screen with the cursor for 10 minutes\n\nThen barrage of errors\n\nThought maybe faulty USB stick or smtn, tried reinstalling from another stick and a usb SSD drive. Same result.\n\nNext thing I had tried is installing mediavault not onto a RAID volume but onto USB stick instead and booting from that.\n\nSurprise, that booted in just fine!\n\nBUT\n\nOS doesn't see any of the RAID card volumes. Well it only sees them partially\n\nIn the OS raidcard volumes sda, sdb can\u2019t be accessed or mounted.\n\nThey appear listed with **lsblk** and **cat /proc/partitions** and are listed in **/dev/disk/by-path** (but not in by-id/by-partuuid/by-uuid).\n\nBut they don't appear when using **fdisk -l** and similar commands\n\nI could find messages like\n\n*I/O error, dev sda, sector 0 op 0x0:(READ) flags 0x0 phys\\_seg 1 prio class 0*\n\n*Nov 11 10:35:06 openmediavault kernel: Buffer I/O error on dev sda, logical block 0, async page read*\n\nI've tried installing raidcard driver I had found on the Areca website\n\n**arcmsr\\_1.50.0X.09-2-OMV6.0.24-k5.16.0-0.bpo.4-amd64.deb**\n\nRebooted, but still had same issue of raid volumes being only partially seen.\n\nI had also installed their raidcard monitoring tool which works fine but doesn't see any raid controllers in the web gui it comes with.\n\nI've had emailed Areca support a month ago about this but considering its a 10 year old legacy product I doubt they'll ever come back to me.\n\nI'm 90% leaning towards it being a raidcard driver issue. Anyone familiar with these older Areca cards? Do I need to use an older OS possibly for it to work?\n\nIdeally I'd like to just install any OS on a Raidcard volume that would let me share drives over SMB.\n\nI think motherboard itself might have 8 sata ports so i could potentially plug drives into that but I'd lose any hot swapping ability by doing that.\n\nIs it possible to save this at all? It was working fine for few weeks with the original 4 drives and software in place till I decided to 'upgrade'...\n\nHere's a link to journalctllog of when I boot into OS off USB\n\n[https://pastebin.com/A7pum7UW](https://pastebin.com/A7pum7UW)", "author_fullname": "t2_16yjgj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with a bargain server i got : /", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyeyvz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668761335.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668759924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hiya. I&amp;#39;ve bought an old 8 bay server that came with&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4x 1TB drives in it&lt;/li&gt;\n&lt;li&gt;Supermicro X9DRH-7TF/7F/iTF/iF motherboard&lt;/li&gt;\n&lt;li&gt;Xeon E5-2603 1.80 GHz&lt;/li&gt;\n&lt;li&gt;8gb or DDR3 1333 Mhz ram&lt;/li&gt;\n&lt;li&gt;Areca Arc-1222 pcie raid controller&lt;/li&gt;\n&lt;li&gt;A proprietary modified debian 6 by a local it company&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It was working fine but then I thought let&amp;#39;s try adding more drives into the remaining bays and see how that works&lt;/p&gt;\n\n&lt;p&gt;Well. It didn&amp;#39;t. I managed to expand the raidset but the proprietary software that runs filesharing was pretty obfuscated and locked down with how and what it sees. I&amp;#39;ve contacted the company and they said &amp;#39;sorry mate, that things been out of support for years. buy a new one&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;So I jumped onto the next logical step. Let&amp;#39;s wipe the whole thing and install something else on it. So I wiped it and tried installing openmediavault.&lt;/p&gt;\n\n&lt;p&gt;Booted into installer, all looking good.Installer sees all my raidcard volumes, all good.&lt;/p&gt;\n\n&lt;p&gt;Installed it on a dedicated 10GB OS partition on the raidcard, all good.&lt;/p&gt;\n\n&lt;p&gt;Reboot&lt;/p&gt;\n\n&lt;p&gt;See the grub window&lt;/p&gt;\n\n&lt;p&gt;Then black screen with the cursor for 10 minutes&lt;/p&gt;\n\n&lt;p&gt;Then barrage of errors&lt;/p&gt;\n\n&lt;p&gt;Thought maybe faulty USB stick or smtn, tried reinstalling from another stick and a usb SSD drive. Same result.&lt;/p&gt;\n\n&lt;p&gt;Next thing I had tried is installing mediavault not onto a RAID volume but onto USB stick instead and booting from that.&lt;/p&gt;\n\n&lt;p&gt;Surprise, that booted in just fine!&lt;/p&gt;\n\n&lt;p&gt;BUT&lt;/p&gt;\n\n&lt;p&gt;OS doesn&amp;#39;t see any of the RAID card volumes. Well it only sees them partially&lt;/p&gt;\n\n&lt;p&gt;In the OS raidcard volumes sda, sdb can\u2019t be accessed or mounted.&lt;/p&gt;\n\n&lt;p&gt;They appear listed with &lt;strong&gt;lsblk&lt;/strong&gt; and &lt;strong&gt;cat /proc/partitions&lt;/strong&gt; and are listed in &lt;strong&gt;/dev/disk/by-path&lt;/strong&gt; (but not in by-id/by-partuuid/by-uuid).&lt;/p&gt;\n\n&lt;p&gt;But they don&amp;#39;t appear when using &lt;strong&gt;fdisk -l&lt;/strong&gt; and similar commands&lt;/p&gt;\n\n&lt;p&gt;I could find messages like&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I/O error, dev sda, sector 0 op 0x0:(READ) flags 0x0 phys_seg 1 prio class 0&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Nov 11 10:35:06 openmediavault kernel: Buffer I/O error on dev sda, logical block 0, async page read&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried installing raidcard driver I had found on the Areca website&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;arcmsr_1.50.0X.09-2-OMV6.0.24-k5.16.0-0.bpo.4-amd64.deb&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Rebooted, but still had same issue of raid volumes being only partially seen.&lt;/p&gt;\n\n&lt;p&gt;I had also installed their raidcard monitoring tool which works fine but doesn&amp;#39;t see any raid controllers in the web gui it comes with.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had emailed Areca support a month ago about this but considering its a 10 year old legacy product I doubt they&amp;#39;ll ever come back to me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m 90% leaning towards it being a raidcard driver issue. Anyone familiar with these older Areca cards? Do I need to use an older OS possibly for it to work?&lt;/p&gt;\n\n&lt;p&gt;Ideally I&amp;#39;d like to just install any OS on a Raidcard volume that would let me share drives over SMB.&lt;/p&gt;\n\n&lt;p&gt;I think motherboard itself might have 8 sata ports so i could potentially plug drives into that but I&amp;#39;d lose any hot swapping ability by doing that.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to save this at all? It was working fine for few weeks with the original 4 drives and software in place till I decided to &amp;#39;upgrade&amp;#39;...&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a link to journalctllog of when I boot into OS off USB&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/A7pum7UW\"&gt;https://pastebin.com/A7pum7UW&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;s=07c121a0180003f7373863af66192b6ff6a937da", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df9c6a296446d05d873c629a30253398c4d29c1b", "width": 108, "height": 108}], "variants": {}, "id": "OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyeyvz", "is_robot_indexable": true, "report_reasons": null, "author": "poliver1988", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyeyvz/struggling_with_a_bargain_server_i_got/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyeyvz/struggling_with_a_bargain_server_i_got/", "subreddit_subscribers": 654700, "created_utc": 1668759924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all. So, I have here about 15 drives, with an eye toward getting a lot more. Currently they are stored in a full tower case, and a sans digital 5-bay rack. However, I would like to have them all consolidated into one case/rack. I want it to be just a plain storage unit, not an external raid controller; all that is handled by linux. Basically just a rack that provides power and slots. What should I be looking for?\r\n\r\nPS: totally unrelated, but why the hell is it so hard to find a full tower that doesn't have a bunch of stupid RGB with it? Grrr.", "author_fullname": "t2_nyaisr0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware suggestions for storing drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yyecpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668757761.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668757530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. So, I have here about 15 drives, with an eye toward getting a lot more. Currently they are stored in a full tower case, and a sans digital 5-bay rack. However, I would like to have them all consolidated into one case/rack. I want it to be just a plain storage unit, not an external raid controller; all that is handled by linux. Basically just a rack that provides power and slots. What should I be looking for?&lt;/p&gt;\n\n&lt;p&gt;PS: totally unrelated, but why the hell is it so hard to find a full tower that doesn&amp;#39;t have a bunch of stupid RGB with it? Grrr.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yyecpx", "is_robot_indexable": true, "report_reasons": null, "author": "the_purple_goat", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yyecpx/hardware_suggestions_for_storing_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yyecpx/hardware_suggestions_for_storing_drives/", "subreddit_subscribers": 654700, "created_utc": 1668757530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two needs:\n\n1. backup 1.5 TB of data on my main machine to an S3 bucket (B2, S3, etc...)\n2. sync a sub folder (of the 1.5 TB) between my laptop and main machine\n\nI've always used SyncThing to sync my two machines (#2). But then I came across GoodSync and see that it can do both: P2P syncing and backing up.\n\nI looked around for other products that do both but can't find any. I thought I would check here before I pull the trigger.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is GoodSync the only product that backup to S3 buckets AND P2P sync with another machine on the LAN?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy9y67", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668742248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two needs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;backup 1.5 TB of data on my main machine to an S3 bucket (B2, S3, etc...)&lt;/li&gt;\n&lt;li&gt;sync a sub folder (of the 1.5 TB) between my laptop and main machine&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve always used SyncThing to sync my two machines (#2). But then I came across GoodSync and see that it can do both: P2P syncing and backing up.&lt;/p&gt;\n\n&lt;p&gt;I looked around for other products that do both but can&amp;#39;t find any. I thought I would check here before I pull the trigger.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy9y67", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy9y67/is_goodsync_the_only_product_that_backup_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy9y67/is_goodsync_the_only_product_that_backup_to_s3/", "subreddit_subscribers": 654700, "created_utc": 1668742248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "is there a way to archive an email mailbox and make it searchable by a simple webinterface or even just a good export into text files + attachements.", "author_fullname": "t2_mdv6krfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "archive email mailbox and make it searchable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy3bio", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668723359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is there a way to archive an email mailbox and make it searchable by a simple webinterface or even just a good export into text files + attachements.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy3bio", "is_robot_indexable": true, "report_reasons": null, "author": "tillybowman", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy3bio/archive_email_mailbox_and_make_it_searchable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy3bio/archive_email_mailbox_and_make_it_searchable/", "subreddit_subscribers": 654700, "created_utc": 1668723359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've never done RAID/ZFS before, but now I need to keep files and have them with higher availability so not just backed up. Until now I was simply copying the data to 2 separate disks because the availability was not that important \n\nBut now I want to make sure that I can always access the files because I need to serve them from a web server\n\nWhat solution do I need? ZFS? RAID?\n\nI need to be able to access the files as if I would access regular disk on the system\n\nI was planning to install it on a separate VM on the network (It's a little private project I'm doing, nothing too important)", "author_fullname": "t2_58tud67t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need ZFS or RAID in this case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy2qb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668721930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve never done RAID/ZFS before, but now I need to keep files and have them with higher availability so not just backed up. Until now I was simply copying the data to 2 separate disks because the availability was not that important &lt;/p&gt;\n\n&lt;p&gt;But now I want to make sure that I can always access the files because I need to serve them from a web server&lt;/p&gt;\n\n&lt;p&gt;What solution do I need? ZFS? RAID?&lt;/p&gt;\n\n&lt;p&gt;I need to be able to access the files as if I would access regular disk on the system&lt;/p&gt;\n\n&lt;p&gt;I was planning to install it on a separate VM on the network (It&amp;#39;s a little private project I&amp;#39;m doing, nothing too important)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy2qb4", "is_robot_indexable": true, "report_reasons": null, "author": "ligonsker", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy2qb4/do_i_need_zfs_or_raid_in_this_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy2qb4/do_i_need_zfs_or_raid_in_this_case/", "subreddit_subscribers": 654700, "created_utc": 1668721930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let's say\n\n- you have different purpose data (archive + volatile data)\n- too much to fit totally on local disk (both kinds)\n- backup over multiple companies, in case an account would be banned (there are enough reasons, even accidents, like banned google account because of youtube violence).\n\nI thought about the following concept:\n\nCold-Storage:\n- Backblaze\n- GCloud\n- one more?\n\nLocal (virtual) file system:  \n\n```\n/coldstorage (let it mostly unmounted, because of expensive read costs)\n  /backblaze\n    /dropbox-full-backup (incl. gdrive-backup)\n  /gcloud (cold tier)\n\n/dropbox (quiet fast)\n  /gdrive-backup (readonly)\n\n/gdrive (slow.....)  \n  /dropbox-backup  (readonly)\n```\n\nYou can also create an EncFS encrypted folder within the /dropbox folder (only for specific folders).\n\nSo, in this case you have two different volatile cloud storages, and they backup them each self to the other. Plus one big backup to the backblaze cold storage.\n\nCold Storage is also used for non volatile data like big ZIPS, archives, Camera Videos and so on.\n\nWhat do you think about this concept? It seems to too price, and i think, it's still performant. By the way, the sync between the multiple storages, i would them do within an small cloud computing instance, just for speed/internet speed bottle neck.", "author_fullname": "t2_44jxdyfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redundant Cloud Storage Concept", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxwig0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668773499.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668707145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;you have different purpose data (archive + volatile data)&lt;/li&gt;\n&lt;li&gt;too much to fit totally on local disk (both kinds)&lt;/li&gt;\n&lt;li&gt;backup over multiple companies, in case an account would be banned (there are enough reasons, even accidents, like banned google account because of youtube violence).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I thought about the following concept:&lt;/p&gt;\n\n&lt;p&gt;Cold-Storage:\n- Backblaze\n- GCloud\n- one more?&lt;/p&gt;\n\n&lt;p&gt;Local (virtual) file system:  &lt;/p&gt;\n\n&lt;p&gt;```\n/coldstorage (let it mostly unmounted, because of expensive read costs)\n  /backblaze\n    /dropbox-full-backup (incl. gdrive-backup)\n  /gcloud (cold tier)&lt;/p&gt;\n\n&lt;p&gt;/dropbox (quiet fast)\n  /gdrive-backup (readonly)&lt;/p&gt;\n\n&lt;p&gt;/gdrive (slow.....)&lt;br/&gt;\n  /dropbox-backup  (readonly)\n```&lt;/p&gt;\n\n&lt;p&gt;You can also create an EncFS encrypted folder within the /dropbox folder (only for specific folders).&lt;/p&gt;\n\n&lt;p&gt;So, in this case you have two different volatile cloud storages, and they backup them each self to the other. Plus one big backup to the backblaze cold storage.&lt;/p&gt;\n\n&lt;p&gt;Cold Storage is also used for non volatile data like big ZIPS, archives, Camera Videos and so on.&lt;/p&gt;\n\n&lt;p&gt;What do you think about this concept? It seems to too price, and i think, it&amp;#39;s still performant. By the way, the sync between the multiple storages, i would them do within an small cloud computing instance, just for speed/internet speed bottle neck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxwig0", "is_robot_indexable": true, "report_reasons": null, "author": "sebastian-loncar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxwig0/redundant_cloud_storage_concept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxwig0/redundant_cloud_storage_concept/", "subreddit_subscribers": 654700, "created_utc": 1668707145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi !\n\nI currently own a raspberry pi 4b and I would like to extend the storage capacity with a 3.5\" hard drive of 4to (and be able to upgrade with by adding a new drive) to build a jellyfin (Plex) and backup server \n\nI found the argon eon case which looks great but is expensive (around 180$ in France with shipping).\n\nI also found this 2 bay docking station for around 50$:  https://www.amazon.fr/Sabrent-Ec-dflt-Drive-Dock-External/dp/B0759567JT/\n\nIs there major differences between what those can do in terms of specs ?\nI will probably buy an iron wolf 4to drive with CMR (for around 90$)", "author_fullname": "t2_4ytzqq2l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Raspberry pi docking station to choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yynwbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668788220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi !&lt;/p&gt;\n\n&lt;p&gt;I currently own a raspberry pi 4b and I would like to extend the storage capacity with a 3.5&amp;quot; hard drive of 4to (and be able to upgrade with by adding a new drive) to build a jellyfin (Plex) and backup server &lt;/p&gt;\n\n&lt;p&gt;I found the argon eon case which looks great but is expensive (around 180$ in France with shipping).&lt;/p&gt;\n\n&lt;p&gt;I also found this 2 bay docking station for around 50$:  &lt;a href=\"https://www.amazon.fr/Sabrent-Ec-dflt-Drive-Dock-External/dp/B0759567JT/\"&gt;https://www.amazon.fr/Sabrent-Ec-dflt-Drive-Dock-External/dp/B0759567JT/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there major differences between what those can do in terms of specs ?\nI will probably buy an iron wolf 4to drive with CMR (for around 90$)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yynwbg", "is_robot_indexable": true, "report_reasons": null, "author": "sarlaytos284", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yynwbg/which_raspberry_pi_docking_station_to_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yynwbg/which_raspberry_pi_docking_station_to_choose/", "subreddit_subscribers": 654700, "created_utc": 1668788220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16ljkt33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Well I guess there\u2019s a first time for everyone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yymt49", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZbfaJL2A04kigIvAfyli2o1vVNQh3VGu_QN4cP9SVsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668785375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jgn8k3cprr0a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?auto=webp&amp;s=9c7d9d7a0a06582b4e311f39efd681cadfb01e77", "width": 1105, "height": 1632}, "resolutions": [{"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f931b06fc41138c9b2c3f54645f061124f05666f", "width": 108, "height": 159}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b439c243abb4bd3fbb01a67d4ab5aa93ee90574f", "width": 216, "height": 319}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=837eccd77e3417c0ff37e6657b807dc9a33e0821", "width": 320, "height": 472}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eab28429ca47f669cebd02eefd7c2d67c9312fe6", "width": 640, "height": 945}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=179673b47e79d29e4b57f4c86e34cea65a58da30", "width": 960, "height": 1417}, {"url": "https://preview.redd.it/jgn8k3cprr0a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16fa7c62fd867b4d191341381b1da98ae39ac430", "width": 1080, "height": 1595}], "variants": {}, "id": "ZNagWy__7ZPBH4futKvhBx4Oid-stmGTw1lkVZWWw-4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yymt49", "is_robot_indexable": true, "report_reasons": null, "author": "ddrfraser1", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yymt49/well_i_guess_theres_a_first_time_for_everyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jgn8k3cprr0a1.jpg", "subreddit_subscribers": 654700, "created_utc": 1668785375.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}