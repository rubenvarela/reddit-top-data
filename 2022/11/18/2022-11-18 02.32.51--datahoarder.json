{"kind": "Listing", "data": {"after": "t3_yxtg1w", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.justice.gov/usao-edny/pr/two-russian-nationals-charged-running-massive-e-book-piracy-website", "author_fullname": "t2_7wwsf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The operators of Z-Library arrested in Argentina ti be extradited to the US", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxmtad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1090, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1090, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668680985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.justice.gov/usao-edny/pr/two-russian-nationals-charged-running-massive-e-book-piracy-website\"&gt;https://www.justice.gov/usao-edny/pr/two-russian-nationals-charged-running-massive-e-book-piracy-website&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/w93zRzaRJxd5t8UZ0qmwxNnQ42WUkGACAVu4F6kYt5s.jpg?auto=webp&amp;s=b79b5e4c727a2a33f42a03386f69f7f956238969", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/w93zRzaRJxd5t8UZ0qmwxNnQ42WUkGACAVu4F6kYt5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fc20e1aec4443077677bd4c317ecb1150b621862", "width": 108, "height": 108}], "variants": {}, "id": "Xl1_YVzU4YW2LwbKsSkm5qq8NUF5LNfXk_KIiT4bR6w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxmtad", "is_robot_indexable": true, "report_reasons": null, "author": "espero", "discussion_type": null, "num_comments": 311, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxmtad/the_operators_of_zlibrary_arrested_in_argentina/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxmtad/the_operators_of_zlibrary_arrested_in_argentina/", "subreddit_subscribers": 654483, "created_utc": 1668680985.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5s2jw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RIP unlimited Google workspace for education so sad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yxuyof", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZJzgS5JeIqSiM-S4S_ZMfo9x_ok42HTD7BQN1dBqruA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668703414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/WIq41oo.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?auto=webp&amp;s=0735b911b2f5092d8e3a6f537ab26c58dfdc480b", "width": 1440, "height": 3120}, "resolutions": [{"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f556e8d409447f35d120f43223d24293101359cd", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7b195ecb97e447e8fb122db7364de94d876fd94a", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b630ff166942e4ba407be4f0d2a3262dbc86c259", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5d9d5f1acf434fafac965e8287ab8c8f05f14959", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea00e99830f8772720df410dbc757afae117f6e7", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f3d8a3b27fc330b38d13e49555f63d6a1318a08", "width": 1080, "height": 2160}], "variants": {}, "id": "tXJO2nqpeXoWEfbeINadLiA5MRKOwAiwWes_Q_YJ3iM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxuyof", "is_robot_indexable": true, "report_reasons": null, "author": "UACEENGR", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxuyof/rip_unlimited_google_workspace_for_education_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/WIq41oo.jpg", "subreddit_subscribers": 654483, "created_utc": 1668703414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks, long time lurker here. I have a bunch of loose external drives that are frequently in use. I have plans to get cats soon and I'm worried they'll be attracted to the noise/heat and knock them all about / on to the ground. Does anybody have any good techniques / strategies / equipment to protect sensitive data from cat attacks?\n\nPS: I already tried \"man cat 1\" in the terminal but didn't find anything useful.", "author_fullname": "t2_3agoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Catproofing strategies for external drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxig2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668665424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, long time lurker here. I have a bunch of loose external drives that are frequently in use. I have plans to get cats soon and I&amp;#39;m worried they&amp;#39;ll be attracted to the noise/heat and knock them all about / on to the ground. Does anybody have any good techniques / strategies / equipment to protect sensitive data from cat attacks?&lt;/p&gt;\n\n&lt;p&gt;PS: I already tried &amp;quot;man cat 1&amp;quot; in the terminal but didn&amp;#39;t find anything useful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxig2y", "is_robot_indexable": true, "report_reasons": null, "author": "nzodd", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxig2y/catproofing_strategies_for_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxig2y/catproofing_strategies_for_external_drives/", "subreddit_subscribers": 654483, "created_utc": 1668665424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to figure out how I want to backup the data of my daily driver. It's about 1.5 TB worth of documents and family pictures/videos. I don't need to access the data daily. I'd only ever need it if I lost all my data and needed to restore/recover.\n\nI don't need or want to backup everything on my disk. I have specific folders I'd select and then would, ideally, want to exclude certain sub-folders like `.git` or `node_modules`.\n\nI've been researching this for days and ... I just need some outside perspective. Here are my thoughts:\n\n* BackBlaze Personal Backup is $7 a month for unlimited backups. But the backup client backups everything and you have to specify all the excludes. The UI is cumbersome as hell and I'll have to edit an XML file to get it to do what I want (like exclude any `.git` folder). I'd only have to edit the file once, probably, but it's still a PITA. \n* I could use something like Duplicati or Duplicacy with B2 or S3 Glacier. I don't have experience with either so I'm not sure.\n* S3 Glacier seems cheaper but I'm not sure if that's necessarily a good thing over B2.\n\nI'm pretty tech savvy but I want something as simple as possible here. Ideally I'd select the root level folders I want to back up, set some kind of encryption, and then have them auto back up, with versions.\n\nBeing able to remotely access files when I'm not at home is an added bonus but not  a must. If I really needed that I'd just install Nextcloud or something.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with my analysis paralysis: BackBlaze unlimited vs Duplicati or Duplicacy with B2 or S3 Glacier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxfwx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668657651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to figure out how I want to backup the data of my daily driver. It&amp;#39;s about 1.5 TB worth of documents and family pictures/videos. I don&amp;#39;t need to access the data daily. I&amp;#39;d only ever need it if I lost all my data and needed to restore/recover.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t need or want to backup everything on my disk. I have specific folders I&amp;#39;d select and then would, ideally, want to exclude certain sub-folders like &lt;code&gt;.git&lt;/code&gt; or &lt;code&gt;node_modules&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been researching this for days and ... I just need some outside perspective. Here are my thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;BackBlaze Personal Backup is $7 a month for unlimited backups. But the backup client backups everything and you have to specify all the excludes. The UI is cumbersome as hell and I&amp;#39;ll have to edit an XML file to get it to do what I want (like exclude any &lt;code&gt;.git&lt;/code&gt; folder). I&amp;#39;d only have to edit the file once, probably, but it&amp;#39;s still a PITA. &lt;/li&gt;\n&lt;li&gt;I could use something like Duplicati or Duplicacy with B2 or S3 Glacier. I don&amp;#39;t have experience with either so I&amp;#39;m not sure.&lt;/li&gt;\n&lt;li&gt;S3 Glacier seems cheaper but I&amp;#39;m not sure if that&amp;#39;s necessarily a good thing over B2.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m pretty tech savvy but I want something as simple as possible here. Ideally I&amp;#39;d select the root level folders I want to back up, set some kind of encryption, and then have them auto back up, with versions.&lt;/p&gt;\n\n&lt;p&gt;Being able to remotely access files when I&amp;#39;m not at home is an added bonus but not  a must. If I really needed that I&amp;#39;d just install Nextcloud or something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxfwx3", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxfwx3/i_need_help_with_my_analysis_paralysis_backblaze/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxfwx3/i_need_help_with_my_analysis_paralysis_backblaze/", "subreddit_subscribers": 654483, "created_utc": 1668657651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there usually good deals for hard drives on these days? I'm finally building my first NAS and want to find good deals obviously.   Is it worth waiting for Black Friday / Cyber Monday deals or are they going to be just crap drives?\n\nThanks!", "author_fullname": "t2_140qwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black Friday/ Cyber Monday deals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxw0kh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668705932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there usually good deals for hard drives on these days? I&amp;#39;m finally building my first NAS and want to find good deals obviously.   Is it worth waiting for Black Friday / Cyber Monday deals or are they going to be just crap drives?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxw0kh", "is_robot_indexable": true, "report_reasons": null, "author": "Mastasmoker", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxw0kh/black_friday_cyber_monday_deals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxw0kh/black_friday_cyber_monday_deals/", "subreddit_subscribers": 654483, "created_utc": 1668705932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello my gaming pc from 2016  has been very slow the past 2 years i was wondering if my HDD being at 100% in the task manager had anything to do with it so I've been researching and got to crystaldiskinfo. i am looking and it says i have 662 reallocated sectors and 712 current pending sectors i was wondering what any of this means.", "author_fullname": "t2_208j5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "reallocated sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxjjwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668669104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello my gaming pc from 2016  has been very slow the past 2 years i was wondering if my HDD being at 100% in the task manager had anything to do with it so I&amp;#39;ve been researching and got to crystaldiskinfo. i am looking and it says i have 662 reallocated sectors and 712 current pending sectors i was wondering what any of this means.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxjjwf", "is_robot_indexable": true, "report_reasons": null, "author": "IWILLREFORM", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxjjwf/reallocated_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxjjwf/reallocated_sector/", "subreddit_subscribers": 654483, "created_utc": 1668669104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Putting together a small NAS with 6 x 4TB HGST SAS drives, HUS724040ALS640s, and was lucky enough to snag two of them as unused spares for \u00a330 a pop. The next four I've just picked up, and the first couple have come back with roughly 25,000 hours on them.\n\nObviously any reports are going to be anecdotal and not a guarantee, but I'm curious as to if any of you have experience with used enterprise drives and reliability in that region of use.\n\nFrom my own personal experience, it seems that if a drive is destined to die it tends to die relatively quickly, and the ones I've had in the past that made it to 10,000 hours typically lasted another 50k+.\n\nUltimately I spent \u00a330 a pop on each of these, so I'm tempted to just consider it a good deal regardless and put it out of my mind. Am I crazy?", "author_fullname": "t2_7cqcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used Enterprise Drives and Power On Hours", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxsz7h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668698470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Putting together a small NAS with 6 x 4TB HGST SAS drives, HUS724040ALS640s, and was lucky enough to snag two of them as unused spares for \u00a330 a pop. The next four I&amp;#39;ve just picked up, and the first couple have come back with roughly 25,000 hours on them.&lt;/p&gt;\n\n&lt;p&gt;Obviously any reports are going to be anecdotal and not a guarantee, but I&amp;#39;m curious as to if any of you have experience with used enterprise drives and reliability in that region of use.&lt;/p&gt;\n\n&lt;p&gt;From my own personal experience, it seems that if a drive is destined to die it tends to die relatively quickly, and the ones I&amp;#39;ve had in the past that made it to 10,000 hours typically lasted another 50k+.&lt;/p&gt;\n\n&lt;p&gt;Ultimately I spent \u00a330 a pop on each of these, so I&amp;#39;m tempted to just consider it a good deal regardless and put it out of my mind. Am I crazy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxsz7h", "is_robot_indexable": true, "report_reasons": null, "author": "mdcdesign", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxsz7h/used_enterprise_drives_and_power_on_hours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxsz7h/used_enterprise_drives_and_power_on_hours/", "subreddit_subscribers": 654483, "created_utc": 1668698470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This cooking website that I have followed for years has a clean, printable version of every recipe on a very similar web address that all follow the same format.\n\n[https://www.halfbakedharvest.com/wprm\\_print/26284](https://www.halfbakedharvest.com/wprm_print/26284)\n\n[https://www.halfbakedharvest.com/wprm\\_print/108579](https://www.halfbakedharvest.com/wprm_print/108579)\n\n[https://www.halfbakedharvest.com/wprm\\_print/110135](https://www.halfbakedharvest.com/wprm_print/110135)\n\n[https://www.halfbakedharvest.com/wprm\\_print/118540](https://www.halfbakedharvest.com/wprm_print/118540)\n\nThere are hundreds of recipes, but the numbers at the end of the address jumps at random intervals (ex. 540, 588, 607, 690). Is there someway a scraper or something could go through and check every number to test if a page is there and then download the webpage?", "author_fullname": "t2_hd6cp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a way to save recipes webpages from similar web addresses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxx8pt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668708898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This cooking website that I have followed for years has a clean, printable version of every recipe on a very similar web address that all follow the same format.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.halfbakedharvest.com/wprm_print/26284\"&gt;https://www.halfbakedharvest.com/wprm_print/26284&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.halfbakedharvest.com/wprm_print/108579\"&gt;https://www.halfbakedharvest.com/wprm_print/108579&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.halfbakedharvest.com/wprm_print/110135\"&gt;https://www.halfbakedharvest.com/wprm_print/110135&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.halfbakedharvest.com/wprm_print/118540\"&gt;https://www.halfbakedharvest.com/wprm_print/118540&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There are hundreds of recipes, but the numbers at the end of the address jumps at random intervals (ex. 540, 588, 607, 690). Is there someway a scraper or something could go through and check every number to test if a page is there and then download the webpage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxx8pt", "is_robot_indexable": true, "report_reasons": null, "author": "1000yardstareslacker", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxx8pt/looking_for_a_way_to_save_recipes_webpages_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxx8pt/looking_for_a_way_to_save_recipes_webpages_from/", "subreddit_subscribers": 654483, "created_utc": 1668708898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A couple years ago i was really into old games and collected a lot of them from yard sales, ebay, traded them with friends. I knew what i already got for the most part, but i never really made a list/labeled them. In total i guess somewhere around 250 floppys &amp; 4-5000 cds.\n\nSince many of them are nearly 20 years some even older, i am looking for a way to digitalis them.\n\n**The first thing, is there an efficient way/program to convert them to isos?**\n\n**The second thing, are you familiar with any archive/collection management program thats selfhosted and where you could link the said isos?**   \n(Like Collectorz just Selfhosted, Browserbased &amp; OpenSource)\n\nThanks for any ideas", "author_fullname": "t2_8jnr5wv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficient Way to Backup/Archive many Gamedisks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxns42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668684298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A couple years ago i was really into old games and collected a lot of them from yard sales, ebay, traded them with friends. I knew what i already got for the most part, but i never really made a list/labeled them. In total i guess somewhere around 250 floppys &amp;amp; 4-5000 cds.&lt;/p&gt;\n\n&lt;p&gt;Since many of them are nearly 20 years some even older, i am looking for a way to digitalis them.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The first thing, is there an efficient way/program to convert them to isos?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The second thing, are you familiar with any archive/collection management program thats selfhosted and where you could link the said isos?&lt;/strong&gt;&lt;br/&gt;\n(Like Collectorz just Selfhosted, Browserbased &amp;amp; OpenSource)&lt;/p&gt;\n\n&lt;p&gt;Thanks for any ideas&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxns42", "is_robot_indexable": true, "report_reasons": null, "author": "Pommes254", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxns42/efficient_way_to_backuparchive_many_gamedisks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxns42/efficient_way_to_backuparchive_many_gamedisks/", "subreddit_subscribers": 654483, "created_utc": 1668684298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&gt;Twitter has emailed staffers: \"Hi, Effective immediately, we are temporarily closing our office buildings and all badge access will be suspended. Offices will reopen on Monday, November 21st. .. We look forward to working with you on Twitter\u2019s exciting future.\"\n\n&amp;#x200B;\n\n&gt;Story to be updated soon with more: Am hearing that several \u201ccritical\u201d infra engineering teams at Twitter have completely resigned. \u201cYou cannot run Twitter without this team,\u201d one current engineer tells me of one such group. Also, Twitter has shut off badge access to its offices.\n\n&amp;#x200B;\n\n&gt;What I\u2019m hearing from Twitter employees; It looks like roughly 75% of the remaining 3,700ish Twitter employees have not opted to stay after the \u201chardcore\u201d email.  \n&gt;  \n&gt;Even though the deadline has passed, everyone still has access to their systems.\n\n&amp;#x200B;\n\n&gt;\u201cI know of six critical systems (like \u2018serving tweets\u2019 levels of critical) which no longer have any engineers,\" the former employee said. \"There is no longer even a skeleton crew manning the system. It will continue to coast until it runs into something, and then it will stop.\u201d  \n&gt;  \n&gt;Resignations and departures were already taking a toll on Twitter\u2019s service, employees said. \u201cBreakages are already happening slowly and accumulating,\u201d one said. \u201cIf you want to export your tweets, do it now.\u201d\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[Link 1](https://twitter.com/oliverdarcy/status/1593394621627138048)\n\n[Link 2](https://twitter.com/alexeheath/status/1593399683086327808)\n\n[Link 3](https://twitter.com/kyliebytes/status/1593391167718113280)\n\n[Link 4](https://www.washingtonpost.com/technology/2022/11/17/twitter-musk-easing-rto-order/)\n\n&amp;#x200B;\n\nEdit:\n\n[twitter-scraper (github no api-key needed)](https://github.com/n0madic/twitter-scraper)\n\n[twitter-media-downloader (github no api-key needed)](https://github.com/mmpx12/twitter-media-downloader)\n\n&amp;#x200B;\n\nEdit2:\n\n[https://github.com/markowanga/stweet](https://github.com/markowanga/stweet)\n\n&amp;#x200B;", "author_fullname": "t2_ioi0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup twitter now! Multiple critical infra teams have resigned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yy7tig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668737805.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668735892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Twitter has emailed staffers: &amp;quot;Hi, Effective immediately, we are temporarily closing our office buildings and all badge access will be suspended. Offices will reopen on Monday, November 21st. .. We look forward to working with you on Twitter\u2019s exciting future.&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Story to be updated soon with more: Am hearing that several \u201ccritical\u201d infra engineering teams at Twitter have completely resigned. \u201cYou cannot run Twitter without this team,\u201d one current engineer tells me of one such group. Also, Twitter has shut off badge access to its offices.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;What I\u2019m hearing from Twitter employees; It looks like roughly 75% of the remaining 3,700ish Twitter employees have not opted to stay after the \u201chardcore\u201d email.  &lt;/p&gt;\n\n&lt;p&gt;Even though the deadline has passed, everyone still has access to their systems.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;\u201cI know of six critical systems (like \u2018serving tweets\u2019 levels of critical) which no longer have any engineers,&amp;quot; the former employee said. &amp;quot;There is no longer even a skeleton crew manning the system. It will continue to coast until it runs into something, and then it will stop.\u201d  &lt;/p&gt;\n\n&lt;p&gt;Resignations and departures were already taking a toll on Twitter\u2019s service, employees said. \u201cBreakages are already happening slowly and accumulating,\u201d one said. \u201cIf you want to export your tweets, do it now.\u201d&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/oliverdarcy/status/1593394621627138048\"&gt;Link 1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/alexeheath/status/1593399683086327808\"&gt;Link 2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/kyliebytes/status/1593391167718113280\"&gt;Link 3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.washingtonpost.com/technology/2022/11/17/twitter-musk-easing-rto-order/\"&gt;Link 4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/n0madic/twitter-scraper\"&gt;twitter-scraper (github no api-key needed)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mmpx12/twitter-media-downloader\"&gt;twitter-media-downloader (github no api-key needed)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit2:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/markowanga/stweet\"&gt;https://github.com/markowanga/stweet&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yy7tig", "is_robot_indexable": true, "report_reasons": null, "author": "fourDnet", "discussion_type": null, "num_comments": 22, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy7tig/backup_twitter_now_multiple_critical_infra_teams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy7tig/backup_twitter_now_multiple_critical_infra_teams/", "subreddit_subscribers": 654483, "created_utc": 1668735892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all.\n\nI am thinking of building a DIY DAS, with a SilverStone DS380 and 8xHDD, but I need something odd that maybe does not exist.\n\nI would need to connect my DAS through an USB interface (USB3.0 is enough for mechanical HDD), so I am looking for an interface that convert the SATA or MiniSAS connectors to an external USB connector, preferably with a PCI bracket to fit the PCI slots of the case.\n\nTo sum up, I need something like a SSF8087 to SSF8088 adapter (pic below) but SSF8087 to USB instead.\n\nhttps://tinypic.host/i/yhZkj\n\nI do not find anything similar to it, but thinking about all the commercial DAS (Yottamaster, IcyBox, Mediasonic...), they all have an external USB interface, that expose the SATA/SAS HDD in the interior, so the card must exist. \n\nThanks in advance.", "author_fullname": "t2_14jgu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SATA or MiniSAS (internal) to USB (external) adapter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy2qyi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668722266.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668721975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.&lt;/p&gt;\n\n&lt;p&gt;I am thinking of building a DIY DAS, with a SilverStone DS380 and 8xHDD, but I need something odd that maybe does not exist.&lt;/p&gt;\n\n&lt;p&gt;I would need to connect my DAS through an USB interface (USB3.0 is enough for mechanical HDD), so I am looking for an interface that convert the SATA or MiniSAS connectors to an external USB connector, preferably with a PCI bracket to fit the PCI slots of the case.&lt;/p&gt;\n\n&lt;p&gt;To sum up, I need something like a SSF8087 to SSF8088 adapter (pic below) but SSF8087 to USB instead.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://tinypic.host/i/yhZkj\"&gt;https://tinypic.host/i/yhZkj&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I do not find anything similar to it, but thinking about all the commercial DAS (Yottamaster, IcyBox, Mediasonic...), they all have an external USB interface, that expose the SATA/SAS HDD in the interior, so the card must exist. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?auto=webp&amp;s=9b207d0abedb366d4381989cda212ee9d7574de3", "width": 1080, "height": 653}, "resolutions": [{"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c756591550f48c6bce45456d7cb4acb5a8d804af", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63b9020eea214892cd1125b63e546c36bac2af0c", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4d2d4a0d43b5d9a6a877d265f8dca65ecbdf88b", "width": 320, "height": 193}, {"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6afe2d78de2ed2c55554560aea202cc6feb55873", "width": 640, "height": 386}, {"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=51e614fa4c38d2671d98e93289a003bd373a449f", "width": 960, "height": 580}, {"url": "https://external-preview.redd.it/rr7MNbCppznpfkih2duPrin_J0xv-DiwE8KMSvWtDjA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=10feb3bb48f86b851b6c59cde4d15e743f8df4ca", "width": 1080, "height": 653}], "variants": {}, "id": "DQVGuU-HCHY8fxeMmUx1dMx7UmiZDidB6gsy-HQmVRc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy2qyi", "is_robot_indexable": true, "report_reasons": null, "author": "jfromeo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy2qyi/sata_or_minisas_internal_to_usb_external_adapter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy2qyi/sata_or_minisas_internal_to_usb_external_adapter/", "subreddit_subscribers": 654483, "created_utc": 1668721975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've never done RAID/ZFS before, but now I need to keep files and have them with higher availability so not just backed up. Until now I was simply copying the data to 2 separate disks because the availability was not that important \n\nBut now I want to make sure that I can always access the files because I need to serve them from a web server\n\nWhat solution do I need? ZFS? RAID?\n\nI need to be able to access the files as if I would access regular disk on the system\n\nI was planning to install it on a separate VM on the network (It's a little private project I'm doing, nothing too important)", "author_fullname": "t2_58tud67t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need ZFS or RAID in this case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy2qb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668721930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve never done RAID/ZFS before, but now I need to keep files and have them with higher availability so not just backed up. Until now I was simply copying the data to 2 separate disks because the availability was not that important &lt;/p&gt;\n\n&lt;p&gt;But now I want to make sure that I can always access the files because I need to serve them from a web server&lt;/p&gt;\n\n&lt;p&gt;What solution do I need? ZFS? RAID?&lt;/p&gt;\n\n&lt;p&gt;I need to be able to access the files as if I would access regular disk on the system&lt;/p&gt;\n\n&lt;p&gt;I was planning to install it on a separate VM on the network (It&amp;#39;s a little private project I&amp;#39;m doing, nothing too important)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy2qb4", "is_robot_indexable": true, "report_reasons": null, "author": "ligonsker", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy2qb4/do_i_need_zfs_or_raid_in_this_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy2qb4/do_i_need_zfs_or_raid_in_this_case/", "subreddit_subscribers": 654483, "created_utc": 1668721930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As I started researching online backup solutions, I realized we all mostly talk about backing up, but **we rarely talking about restoring**. More specifically, we rarely talk about the process of restoring, if it works, how well it works, etc. I read many folks say they couldn't restore cause of a corrupted backup because of the backup tool they used -- *not cool*.\n\nSo, I'm wondering, for folks who have had to restore data **and it was successful**, what tool were you using to do the backup + restore? Comment with your thoughts/experience.\n\n[View Poll](https://www.reddit.com/poll/yxqwnz)", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What back tool did you use to backup **AND RESTORE** and how well did it work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxqwnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668693212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As I started researching online backup solutions, I realized we all mostly talk about backing up, but &lt;strong&gt;we rarely talking about restoring&lt;/strong&gt;. More specifically, we rarely talk about the process of restoring, if it works, how well it works, etc. I read many folks say they couldn&amp;#39;t restore cause of a corrupted backup because of the backup tool they used -- &lt;em&gt;not cool&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m wondering, for folks who have had to restore data &lt;strong&gt;and it was successful&lt;/strong&gt;, what tool were you using to do the backup + restore? Comment with your thoughts/experience.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yxqwnz\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxqwnz", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1669298012653, "options": [{"text": "Backblaze Personal", "id": "19865732"}, {"text": "rclone", "id": "19865733"}, {"text": "Duplicati", "id": "19865734"}, {"text": "Duplicacy", "id": "19865735"}, {"text": "ARQ", "id": "19865736"}, {"text": "Veeam", "id": "19865737"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 49, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxqwnz/what_back_tool_did_you_use_to_backup_and_restore/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/DataHoarder/comments/yxqwnz/what_back_tool_did_you_use_to_backup_and_restore/", "subreddit_subscribers": 654483, "created_utc": 1668693212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Perhaps I\u2019m just lucky and haven\u2019t lost a drive but I feel like between SMART monitoring and using single addressable drives my 24 bay media server using drives on their own is running well.\n\nI\u2019ve been considering some pooled sort of RAID like unraid or omv zfs for many years, and realize it means the loss of one drive for parity, but overall the bigger fear is that something will go wrong that will trash the entire pool of Files versus just one drives worth of content - tv and movie files which could be replaced. Anyone else have similar fears and how did you resolve? I just worry the implosion of say 100tb of a pool would be riskier than losing a regular 14tb drive. My drives are all of various size btw ranging from 5tb to 14tb all gutted from desktop cases so not bleeding edge. Also isn\u2019t raid going to run slower than jbod on my 4u Xeon rackmount?", "author_fullname": "t2_4jntazsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID Risks - Anyone left using only JBOD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxnrss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668684268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Perhaps I\u2019m just lucky and haven\u2019t lost a drive but I feel like between SMART monitoring and using single addressable drives my 24 bay media server using drives on their own is running well.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been considering some pooled sort of RAID like unraid or omv zfs for many years, and realize it means the loss of one drive for parity, but overall the bigger fear is that something will go wrong that will trash the entire pool of Files versus just one drives worth of content - tv and movie files which could be replaced. Anyone else have similar fears and how did you resolve? I just worry the implosion of say 100tb of a pool would be riskier than losing a regular 14tb drive. My drives are all of various size btw ranging from 5tb to 14tb all gutted from desktop cases so not bleeding edge. Also isn\u2019t raid going to run slower than jbod on my 4u Xeon rackmount?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxnrss", "is_robot_indexable": true, "report_reasons": null, "author": "ExcitingDegree", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxnrss/raid_risks_anyone_left_using_only_jbod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxnrss/raid_risks_anyone_left_using_only_jbod/", "subreddit_subscribers": 654483, "created_utc": 1668684268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is the standard recommendation basically Fractal Design Define 7 XL?\n\nI looked at the Hardware Wiki and it looks like it is in bad need for some love and updates since a lot of the links don't even work!\n\nI'd like to know what most people are running/recommending here for \\~12x 3.5\" and probably at least 2x 5.25\" and 2x 2.5\". Hot swap is a nice-to-have, but not required.\n\nNote that I'm not interested in server U cases. I'd rather it take more space vertically than horizontally. Plus in my experience of owning some enterprise gears, they tend to be loud and I'm trying to steer away from that.", "author_fullname": "t2_5xyrdccu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good tower case in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxk1ew", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668670897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the standard recommendation basically Fractal Design Define 7 XL?&lt;/p&gt;\n\n&lt;p&gt;I looked at the Hardware Wiki and it looks like it is in bad need for some love and updates since a lot of the links don&amp;#39;t even work!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to know what most people are running/recommending here for ~12x 3.5&amp;quot; and probably at least 2x 5.25&amp;quot; and 2x 2.5&amp;quot;. Hot swap is a nice-to-have, but not required.&lt;/p&gt;\n\n&lt;p&gt;Note that I&amp;#39;m not interested in server U cases. I&amp;#39;d rather it take more space vertically than horizontally. Plus in my experience of owning some enterprise gears, they tend to be loud and I&amp;#39;m trying to steer away from that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxk1ew", "is_robot_indexable": true, "report_reasons": null, "author": "whattteva", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxk1ew/good_tower_case_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxk1ew/good_tower_case_in_2022/", "subreddit_subscribers": 654483, "created_utc": 1668670897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So one of my clients at work has an iMac that is used as a Data Server. They are in the process of upgrading it to an actual Apple Server but it is a slow process due to cost. \n\nThe problem is, they have 4 external hard drives that are used for backup purposes. Two are used for Time Machine backups, and the other two are used for data backups for a program they use. The old solution was that they were just swapping them out every week, but then we ran into the problem of corrupt drives (due to a USB hub not having enough power and failing intermittently). I now want all 4 plugged into the device at once to prevent this nightmare of a situation. The problem is, the iMac only has 4 USB ports on the back, and 3 are occupied and cannot be moved. One is used by a personal scanner which cannot be connected to a USB hub, another is the USB hub mentioned earlier, and a third is the Ethernet adapter which cannot be moved due to the actual Ethernet port on the iMac being broken.\n\nI need some ideas, because currently only one backup can really work properly as there is only one USB port available. Open to any ideas, thank you.", "author_fullname": "t2_f53sz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some way to have 4 external hard drives running backups on an iMac with minimal USB hubs available.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yy6uf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668732946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So one of my clients at work has an iMac that is used as a Data Server. They are in the process of upgrading it to an actual Apple Server but it is a slow process due to cost. &lt;/p&gt;\n\n&lt;p&gt;The problem is, they have 4 external hard drives that are used for backup purposes. Two are used for Time Machine backups, and the other two are used for data backups for a program they use. The old solution was that they were just swapping them out every week, but then we ran into the problem of corrupt drives (due to a USB hub not having enough power and failing intermittently). I now want all 4 plugged into the device at once to prevent this nightmare of a situation. The problem is, the iMac only has 4 USB ports on the back, and 3 are occupied and cannot be moved. One is used by a personal scanner which cannot be connected to a USB hub, another is the USB hub mentioned earlier, and a third is the Ethernet adapter which cannot be moved due to the actual Ethernet port on the iMac being broken.&lt;/p&gt;\n\n&lt;p&gt;I need some ideas, because currently only one backup can really work properly as there is only one USB port available. Open to any ideas, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy6uf2", "is_robot_indexable": true, "report_reasons": null, "author": "AH_BareGarrett", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy6uf2/need_some_way_to_have_4_external_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy6uf2/need_some_way_to_have_4_external_hard_drives/", "subreddit_subscribers": 654483, "created_utc": 1668732946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Edit to answer FAQ: hardware choices are for cost and versatility, the whole budget for this build is under $350. Raid config is RAID 10 + 1 hot spare and four more drives on hand to swap in for failures. I am not afraid to cut holes in this case. \n\nI've also posted this over on homeserver, but the level of jank I'm striving for fits a lot better here I think. \n\nI'm currently working on building a home file server that could potentially host both Plex and Pi-Hole. I've already got the drives on the way but I have not ordered the rest of the hardware. Right now I am bidding on an auction for an Optiplex 7040 MT, i7-6700 with 8GB RAM. There will be a dedicated SSD for the OS. I know that the specs will be sufficient for any of the individual uses, but will they be enough for all three at once? Also, what would be the best way to install 11 drives? I'm not afraid of jank, so \"creative\" solutions are welcome. My array plans are for 11 2TB drives with 10 TB logical storage for full parity with 1 hot spare. I will also have 4 cold spares. \nHere are the solutions I'm looking for ideas on:\n1. software. Currently thinking about Samba but would be open to any other free options\n\n2. power. Will the 240w dell power supply be enough for 11 spinning platters or do I need another solution?\n\n3. connection. Do I need to use a specific PCIe expansion card to make sure my OS can see all the drives?\n\n4. physical mounting. How the heck can I get 11 drives connected to this thing?\n\nTIA!", "author_fullname": "t2_2vd74d5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for Optiplex Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxuv9c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668713641.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668703184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit to answer FAQ: hardware choices are for cost and versatility, the whole budget for this build is under $350. Raid config is RAID 10 + 1 hot spare and four more drives on hand to swap in for failures. I am not afraid to cut holes in this case. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also posted this over on homeserver, but the level of jank I&amp;#39;m striving for fits a lot better here I think. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on building a home file server that could potentially host both Plex and Pi-Hole. I&amp;#39;ve already got the drives on the way but I have not ordered the rest of the hardware. Right now I am bidding on an auction for an Optiplex 7040 MT, i7-6700 with 8GB RAM. There will be a dedicated SSD for the OS. I know that the specs will be sufficient for any of the individual uses, but will they be enough for all three at once? Also, what would be the best way to install 11 drives? I&amp;#39;m not afraid of jank, so &amp;quot;creative&amp;quot; solutions are welcome. My array plans are for 11 2TB drives with 10 TB logical storage for full parity with 1 hot spare. I will also have 4 cold spares. \nHere are the solutions I&amp;#39;m looking for ideas on:\n1. software. Currently thinking about Samba but would be open to any other free options&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;power. Will the 240w dell power supply be enough for 11 spinning platters or do I need another solution?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;connection. Do I need to use a specific PCIe expansion card to make sure my OS can see all the drives?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;physical mounting. How the heck can I get 11 drives connected to this thing?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxuv9c", "is_robot_indexable": true, "report_reasons": null, "author": "OutfoxHyperion", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxuv9c/advice_for_optiplex_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxuv9c/advice_for_optiplex_server/", "subreddit_subscribers": 654483, "created_utc": 1668703184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried Onedrive and Google Drive, but neither of them allows me to roll back a whole folder at once. Only a single file at a time. Backblaze costs money per-device, but I have multiple devices so that solution doesn't work for me either. I also don't need more than 1TB.\n\nI'd like it to be as streamlined as possible (so no manual pushing/pulling, and preferably no complicated setups).\n\nCan anyone help?", "author_fullname": "t2_m7d9qp32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a cloud storage that allows me to roll back entire folders at once?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxrgzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668694805.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668694590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried Onedrive and Google Drive, but neither of them allows me to roll back a whole folder at once. Only a single file at a time. Backblaze costs money per-device, but I have multiple devices so that solution doesn&amp;#39;t work for me either. I also don&amp;#39;t need more than 1TB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like it to be as streamlined as possible (so no manual pushing/pulling, and preferably no complicated setups).&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxrgzi", "is_robot_indexable": true, "report_reasons": null, "author": "CutiePatootieLootie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxrgzi/is_there_a_cloud_storage_that_allows_me_to_roll/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxrgzi/is_there_a_cloud_storage_that_allows_me_to_roll/", "subreddit_subscribers": 654483, "created_utc": 1668694590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wrote a little blog post about my journey of migrating all of my cloud files away from OneDrive! Eventually, I found a managed Nextcloud instance to be working really well for me, but I\u2019ve also compared some other cloud storage providers in the blog post. Maybe it helps some of you, or is at least an interesting read!\n\n[https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/](https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/)\n\nAnd please let me know if I missed anything!", "author_fullname": "t2_snlb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating 1 terabyte of files from OneDrive to Nextcloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxn81k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668682432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a little blog post about my journey of migrating all of my cloud files away from OneDrive! Eventually, I found a managed Nextcloud instance to be working really well for me, but I\u2019ve also compared some other cloud storage providers in the blog post. Maybe it helps some of you, or is at least an interesting read!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/\"&gt;https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And please let me know if I missed anything!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?auto=webp&amp;s=88a062633dedf9ccf452448d8fc2db2dad601c1f", "width": 1280, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98d55d59103bd7b567864dba6260fd09315eb9ed", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e34219664abdc1aa38d76b56c777f3772f425052", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec4b0f7ab74821b6ac125f46b3118523fbc8000b", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3401a41d681fdfc6b2ef8e92e6678d6312a20951", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d402ce1f8f6ebb81425114a6c8044a702a4ec2d", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d33df6ce715275bb50796c44663dec38ee80c099", "width": 1080, "height": 675}], "variants": {}, "id": "hSLDBk73_NSVA14RgE0rWWy7p2PyXnFjDL3BnIToUjA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxn81k", "is_robot_indexable": true, "report_reasons": null, "author": "herrherrmann", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxn81k/migrating_1_terabyte_of_files_from_onedrive_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxn81k/migrating_1_terabyte_of_files_from_onedrive_to/", "subreddit_subscribers": 654483, "created_utc": 1668682432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1egq3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding the UBI File System in Embedded Devices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yxm2v5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p2KwVnIXS5RIWyEbUk0K8spJZGi2P-R5tF-a9cMQObE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668678336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "serhack.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://serhack.me/articles/understanding-ubi-file-system-embedded-devices-reolink/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?auto=webp&amp;s=00078a38d692ba8754d89738ee89ea6e4b9e8c19", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49133ab284e90d376be0f0b56abc666023dcfeaa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=365be787bd7e64ffb8060bab75adadd2059c7267", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0192f4547be6c29445b1d2376d14a324d9cf0109", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38415530d6caba0e9880f6a29b456efdf0d969d6", "width": 640, "height": 360}], "variants": {}, "id": "HfVseBBMzCg0VO3uFfUhboKSYGovmAWqQX0RMkMeYVk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxm2v5", "is_robot_indexable": true, "report_reasons": null, "author": "serhack", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxm2v5/understanding_the_ubi_file_system_in_embedded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://serhack.me/articles/understanding-ubi-file-system-embedded-devices-reolink/", "subreddit_subscribers": 654483, "created_utc": 1668678336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys, \n\nI used poweriso to create a mountable image files from data because it can create image file from big directory (&gt;10GB, 20GB ...) with a good compress ratio compared to .tar .rar. zip file.\n\nHowever, it's not safe as my antivirus program says.\n\nI'm looking for alternatives. What do you use to archive a huge amount of data?\n\nThanks", "author_fullname": "t2_5fhmvk4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "poweriso alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yy80wf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668736513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;I used poweriso to create a mountable image files from data because it can create image file from big directory (&amp;gt;10GB, 20GB ...) with a good compress ratio compared to .tar .rar. zip file.&lt;/p&gt;\n\n&lt;p&gt;However, it&amp;#39;s not safe as my antivirus program says.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for alternatives. What do you use to archive a huge amount of data?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy80wf", "is_robot_indexable": true, "report_reasons": null, "author": "mitchneal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy80wf/poweriso_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy80wf/poweriso_alternative/", "subreddit_subscribers": 654483, "created_utc": 1668736513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Genuinely decent chance Twitter might pop in the near future.](https://twitter.com/alexeheath/status/1593399683086327808?s=20&amp;t=dfeufbahrPBgan8EqpYe1w) Does anyone know how to save tweets from an account en masse? Worried that some people might not archive their own things before it's too late. Sorry if this doesn't fit the sub?\n\nAll the tools I can find are pay-to-use which is wild, except archive.org which only saves the most recent page of tweets from an account? Like a few days' worth roughly.", "author_fullname": "t2_yeb0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I archive other people's twitter accounts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yy7yvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668736340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://twitter.com/alexeheath/status/1593399683086327808?s=20&amp;amp;t=dfeufbahrPBgan8EqpYe1w\"&gt;Genuinely decent chance Twitter might pop in the near future.&lt;/a&gt; Does anyone know how to save tweets from an account en masse? Worried that some people might not archive their own things before it&amp;#39;s too late. Sorry if this doesn&amp;#39;t fit the sub?&lt;/p&gt;\n\n&lt;p&gt;All the tools I can find are pay-to-use which is wild, except archive.org which only saves the most recent page of tweets from an account? Like a few days&amp;#39; worth roughly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy7yvo", "is_robot_indexable": true, "report_reasons": null, "author": "SansFinalGuardian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy7yvo/how_can_i_archive_other_peoples_twitter_accounts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy7yvo/how_can_i_archive_other_peoples_twitter_accounts/", "subreddit_subscribers": 654483, "created_utc": 1668736340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "is there a way to archive an email mailbox and make it searchable by a simple webinterface or even just a good export into text files + attachements.", "author_fullname": "t2_mdv6krfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "archive email mailbox and make it searchable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yy3bio", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668723359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is there a way to archive an email mailbox and make it searchable by a simple webinterface or even just a good export into text files + attachements.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yy3bio", "is_robot_indexable": true, "report_reasons": null, "author": "tillybowman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yy3bio/archive_email_mailbox_and_make_it_searchable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yy3bio/archive_email_mailbox_and_make_it_searchable/", "subreddit_subscribers": 654483, "created_utc": 1668723359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sorry if this is a stupid question, I'm completely clueless about this stuff.\n\nI have a huge collection of obscure gaming books and materials. Including scans of rare developer interviews.\n\nI was reading the ArchiveTeam wiki and I found out that you can upload to archive.org using a torrent.\n\nhttps://wiki.archiveteam.org/index.php/Internet_Archive#Uploading_to_archive.org\n\n\"Torrent upload, useful if you need resume (for huge files or because your bandwidth is insufficient for upload in one go)\"\n\nI don't have the best equipment so I want to use this method in case I have some sort of interruption.\n\nIs it recommended to use torrent upload? Is there any file size limits to it? Can it handle 10gb+ uploads?", "author_fullname": "t2_8rcmiabz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about using torrent upload for Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxzvvs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668715128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is a stupid question, I&amp;#39;m completely clueless about this stuff.&lt;/p&gt;\n\n&lt;p&gt;I have a huge collection of obscure gaming books and materials. Including scans of rare developer interviews.&lt;/p&gt;\n\n&lt;p&gt;I was reading the ArchiveTeam wiki and I found out that you can upload to archive.org using a torrent.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://wiki.archiveteam.org/index.php/Internet_Archive#Uploading_to_archive.org\"&gt;https://wiki.archiveteam.org/index.php/Internet_Archive#Uploading_to_archive.org&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Torrent upload, useful if you need resume (for huge files or because your bandwidth is insufficient for upload in one go)&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have the best equipment so I want to use this method in case I have some sort of interruption.&lt;/p&gt;\n\n&lt;p&gt;Is it recommended to use torrent upload? Is there any file size limits to it? Can it handle 10gb+ uploads?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxzvvs", "is_robot_indexable": true, "report_reasons": null, "author": "CitronDestroys", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxzvvs/question_about_using_torrent_upload_for_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxzvvs/question_about_using_torrent_upload_for_internet/", "subreddit_subscribers": 654483, "created_utc": 1668715128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently got a CRC check error on one of my drives, I follow the 3-2-1 rule, but the corruption was detected late, and the corrupted data seems to of replicated. \n\nI've held off getting a NAS for a long time but I am now thinking of getting something cheap. After some research, would a RAID5 or RAID-Z1 fit my needs? or would you recommend something else? Is there a script / command I should run on a weekly basis to detect disk errors early?\n\nMany thanks for your help in advance!", "author_fullname": "t2_g0xhb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preventing CRC check type errors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxtg1w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668699675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got a CRC check error on one of my drives, I follow the 3-2-1 rule, but the corruption was detected late, and the corrupted data seems to of replicated. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve held off getting a NAS for a long time but I am now thinking of getting something cheap. After some research, would a RAID5 or RAID-Z1 fit my needs? or would you recommend something else? Is there a script / command I should run on a weekly basis to detect disk errors early?&lt;/p&gt;\n\n&lt;p&gt;Many thanks for your help in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxtg1w", "is_robot_indexable": true, "report_reasons": null, "author": "this1seasy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxtg1w/preventing_crc_check_type_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxtg1w/preventing_crc_check_type_errors/", "subreddit_subscribers": 654483, "created_utc": 1668699675.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}