{"kind": "Listing", "data": {"after": "t3_z80bh1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m not talking about not getting back to candidates after the CV stage or even the HR stage. Why do not follow up after further stages? Those require decent prep especially if they are technical interviews or involve a take-home assignments. Not even an email after these stages is such an insult to the time spent.", "author_fullname": "t2_hxbkihpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hiring managers, why do you ghost the candidates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z82bry", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 301, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 301, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669747546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not talking about not getting back to candidates after the CV stage or even the HR stage. Why do not follow up after further stages? Those require decent prep especially if they are technical interviews or involve a take-home assignments. Not even an email after these stages is such an insult to the time spent.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "z82bry", "is_robot_indexable": true, "report_reasons": null, "author": "BlondeRaspberry", "discussion_type": null, "num_comments": 128, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z82bry/hiring_managers_why_do_you_ghost_the_candidates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z82bry/hiring_managers_why_do_you_ghost_the_candidates/", "subreddit_subscribers": 822641, "created_utc": 1669747546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have been running a GridSearch for the past 5 hours now, making my laptop unusable and I\u2019ve already cleaned my entire apartment. Just wondering what y\u2019all do while waiting? (Obviously, this doesn\u2019t apply if you\u2019re running models on a company server or something)", "author_fullname": "t2_h2af93ho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you all do while you\u2019re fitting models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8bwy0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669769237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have been running a GridSearch for the past 5 hours now, making my laptop unusable and I\u2019ve already cleaned my entire apartment. Just wondering what y\u2019all do while waiting? (Obviously, this doesn\u2019t apply if you\u2019re running models on a company server or something)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8bwy0", "is_robot_indexable": true, "report_reasons": null, "author": "Plusdebeurre", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8bwy0/what_do_you_all_do_while_youre_fitting_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8bwy0/what_do_you_all_do_while_youre_fitting_models/", "subreddit_subscribers": 822641, "created_utc": 1669769237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Learning Data Science is like finding out the exploits to a video game, except the game is the universe, and you're trying to figure out how it works and how to predict it. Every statistical theorem and trick feels like you're finding a new speedrunning \"hack\" related to predicting the outcome of some event. It almost feels like the devs to this simulation left a few bugs in our code and we are trying to exploit them to gain an advantage. \n\nEven something as fundamental as the central limit theorem feels \"gamebreaking\" to me. Data Science is like finding out the rules and strategies to a game that's infinitely complex. You'll never \"beat\" the game, but you can use your knowledge to make predictions and decisions that can help you and your team succeed. You can use data to optimize the decisions you make, and to make decisions that are better than those made without it.  \n\n**Like, \\*poof\\* most the text written here was written by AI. How cool is that?**  Data Science is a fascinating journey of exploration and discovery. It's a learning process that involves discovering patterns and relationships in data, and using that knowledge to make better decisions. It involves applying theories and techniques from mathematics, statistics, computing, and other related fields to create models and solutions to problems. \n\nIt's a challenging and rewarding field of study that can help provide insights into our world and help us make better decisions.", "author_fullname": "t2_i4k26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why I love this field", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8otqq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669806711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning Data Science is like finding out the exploits to a video game, except the game is the universe, and you&amp;#39;re trying to figure out how it works and how to predict it. Every statistical theorem and trick feels like you&amp;#39;re finding a new speedrunning &amp;quot;hack&amp;quot; related to predicting the outcome of some event. It almost feels like the devs to this simulation left a few bugs in our code and we are trying to exploit them to gain an advantage. &lt;/p&gt;\n\n&lt;p&gt;Even something as fundamental as the central limit theorem feels &amp;quot;gamebreaking&amp;quot; to me. Data Science is like finding out the rules and strategies to a game that&amp;#39;s infinitely complex. You&amp;#39;ll never &amp;quot;beat&amp;quot; the game, but you can use your knowledge to make predictions and decisions that can help you and your team succeed. You can use data to optimize the decisions you make, and to make decisions that are better than those made without it.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Like, *poof* most the text written here was written by AI. How cool is that?&lt;/strong&gt;  Data Science is a fascinating journey of exploration and discovery. It&amp;#39;s a learning process that involves discovering patterns and relationships in data, and using that knowledge to make better decisions. It involves applying theories and techniques from mathematics, statistics, computing, and other related fields to create models and solutions to problems. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a challenging and rewarding field of study that can help provide insights into our world and help us make better decisions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8otqq", "is_robot_indexable": true, "report_reasons": null, "author": "notspoon", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8otqq/why_i_love_this_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8otqq/why_i_love_this_field/", "subreddit_subscribers": 822641, "created_utc": 1669806711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4ws2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a transition to Data Engineering a year ago, and couldn't be happier. This post reflects my sentiment perfectly.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_z8mqzu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_cqeUpYC87pWCzEaiJri2tB-6V0e-ipzzBZXNeMDIfk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669799404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ryxcommar.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ryxcommar.com/2022/11/27/goodbye-data-science/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F6AGihc6sjMmnVLm-XWIe0jcP2vPZpBwjOqH2PhZX-c.jpg?auto=webp&amp;s=13353f39561ed11ccd79ec9880d3b36c19dcc81c", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/F6AGihc6sjMmnVLm-XWIe0jcP2vPZpBwjOqH2PhZX-c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0563ade4652d2408b81c0d4fd5f4ad1c26458007", "width": 108, "height": 108}], "variants": {}, "id": "sAYY86zgdT-GUuuQxQ55XhcVr4wy0uMIajd_UOBdg3Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8mqzu", "is_robot_indexable": true, "report_reasons": null, "author": "srkiboy83", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8mqzu/i_made_a_transition_to_data_engineering_a_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ryxcommar.com/2022/11/27/goodbye-data-science/", "subreddit_subscribers": 822641, "created_utc": 1669799404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was contacted by a recruiter of a staffing company where he asked if he was interested in signing a contract with them to work with one of the FAANG companies. \n\nI am a new grad having a hard time finding a full time DS job right now. I\u2019ve never thought about/heard things about working for a staffing company, so I wanted to hear some opinions. \n\nHave anyone worked for a staffing company or heard things about working for one? It'd be great if you guys could share what your thoughts are. Thank you.", "author_fullname": "t2_k66cdt9y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you guys think about working for a staffing company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8afn6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669765751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was contacted by a recruiter of a staffing company where he asked if he was interested in signing a contract with them to work with one of the FAANG companies. &lt;/p&gt;\n\n&lt;p&gt;I am a new grad having a hard time finding a full time DS job right now. I\u2019ve never thought about/heard things about working for a staffing company, so I wanted to hear some opinions. &lt;/p&gt;\n\n&lt;p&gt;Have anyone worked for a staffing company or heard things about working for one? It&amp;#39;d be great if you guys could share what your thoughts are. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8afn6", "is_robot_indexable": true, "report_reasons": null, "author": "According-Bar-7830", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8afn6/what_do_you_guys_think_about_working_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8afn6/what_do_you_guys_think_about_working_for_a/", "subreddit_subscribers": 822641, "created_utc": 1669765751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good afternoon people! I'm passing by to share our journal \"Knowledge Organization\". It is the official journal of ISKO (International Society for Knowledge Organization), which is a professional association for scholars of knowledge organization, knowledge structures, classification and organization studies and information and data structure. These are some of the themes of the scientific articles published in the journal in general, as well as some other themes such as thesauri, ontologies and studies of terminologies in the flow and organization of scientific data and information.\n\nThat's why I invite you to follow our social networks and take a look at the scientific works that we publish on them weekly. (:  \n\n\n Here are the official links of the journal to learn more about it:    \n[https://www.isko.org/ko.html](https://www.isko.org/ko.html)  \n[https://www.nomos-elibrary.de/zeitschrift/0943-7444](https://www.nomos-elibrary.de/zeitschrift/0943-7444)\n\nAnd the links to our networks are these:\n\nTwitter: [https://twitter.com/ko\\_isko\\_/](https://twitter.com/ko_isko_/)\n\nInstagram: [https://www.instagram.com/ko.isko/](https://www.instagram.com/ko.isko/)\n\nFacebook: [https://www.facebook.com/KnowledgeOrganizationISKO](https://www.facebook.com/KnowledgeOrganizationISKO)\n\nI hope you guys find cool and useful work for your studies!\n\nhttps://preview.redd.it/xzhn0uayhx2a1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=96b847f642e9ec680cd66a49258d1787bde37893", "author_fullname": "t2_k34drzns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scientific journal in the area of \u200b\u200bKnowledge Organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xzhn0uayhx2a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bd1e20be677b2e0a4c746576db63d45eadcc0ff9"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=65cec9c9b10b576393768e35cd181ebe824b9d23"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e467e56abe4417dae481721e23c802510e4a77d0"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=762a6a9856c1496d05db5bd3e47f22835e20f84d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=91a5f37e413c1d26f6bfdf224f1664ca4bdb4e13"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e659b9222d9ab5f666012bbb747c0519e3547170"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/xzhn0uayhx2a1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=96b847f642e9ec680cd66a49258d1787bde37893"}, "id": "xzhn0uayhx2a1"}}, "name": "t3_z8180z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gU8mU1YmKMgruPzfjxBDAgqioHnvDzZLqOoa4s4gbP8.jpg", "edited": 1669758102.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669745097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good afternoon people! I&amp;#39;m passing by to share our journal &amp;quot;Knowledge Organization&amp;quot;. It is the official journal of ISKO (International Society for Knowledge Organization), which is a professional association for scholars of knowledge organization, knowledge structures, classification and organization studies and information and data structure. These are some of the themes of the scientific articles published in the journal in general, as well as some other themes such as thesauri, ontologies and studies of terminologies in the flow and organization of scientific data and information.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why I invite you to follow our social networks and take a look at the scientific works that we publish on them weekly. (:  &lt;/p&gt;\n\n&lt;p&gt;Here are the official links of the journal to learn more about it:&lt;br/&gt;\n&lt;a href=\"https://www.isko.org/ko.html\"&gt;https://www.isko.org/ko.html&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://www.nomos-elibrary.de/zeitschrift/0943-7444\"&gt;https://www.nomos-elibrary.de/zeitschrift/0943-7444&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And the links to our networks are these:&lt;/p&gt;\n\n&lt;p&gt;Twitter: &lt;a href=\"https://twitter.com/ko_isko_/\"&gt;https://twitter.com/ko_isko_/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Instagram: &lt;a href=\"https://www.instagram.com/ko.isko/\"&gt;https://www.instagram.com/ko.isko/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Facebook: &lt;a href=\"https://www.facebook.com/KnowledgeOrganizationISKO\"&gt;https://www.facebook.com/KnowledgeOrganizationISKO&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope you guys find cool and useful work for your studies!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xzhn0uayhx2a1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=96b847f642e9ec680cd66a49258d1787bde37893\"&gt;https://preview.redd.it/xzhn0uayhx2a1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=96b847f642e9ec680cd66a49258d1787bde37893&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8180z", "is_robot_indexable": true, "report_reasons": null, "author": "badmatt2305", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8180z/scientific_journal_in_the_area_of_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8180z/scientific_journal_in_the_area_of_knowledge/", "subreddit_subscribers": 822641, "created_utc": 1669745097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys! Many of us in the data science and ML space work with **multi-label data**, where the image or text is tagged with multiple labels. Often these datasets contain **frequent label errors** and/or **missing tags** (check what we found below in the CelebA dataset) that make it hard to train highly accurate ML models. Support for multi-label data was one of the top features requested \u2014 so we [added it](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html), [benchmarked it](https://cleanlab.ai/blog/multilabel/), and published all of the [research](https://cleanlab.ai/blog/multilabel/).\n\n[Find errors and missing labels in multi-label datasets.](https://preview.redd.it/tn0m9lg8mx2a1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=80d4d09a24b6929894a5ce994042f491a6b8f544)\n\nWe are excited to share this newest research on algorithms to automatically find label errors in multi-label classification datasets. Image/document tagging represents important instances of\u00a0**multi-label classification**\u00a0tasks, where each example can belong to multiple (or none) of K possible classes. Because annotating such data requires many decisions for each example, often multi-label classification datasets contain tons of label errors, which harm the performance of ML models.\n\nWe\u2019ve open-sourced our algorithms in the [recent release of cleanlab v2.2](https://github.com/cleanlab/cleanlab/releases/tag/v2.2.0). All you need to do to use them is write one line of open-source code via [cleanlab.filter.find\\_label\\_issues](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html).\n\n    from cleanlab.filter import find_label_issues\n    \n    ranked_label_issues = find_label_issues(\n        labels=labels,\n        pred_probs=pred_probs,\n        multi_label=True,\n        return_indices_ranked_by=\"self_confidence\",\n    )\n    # labels: list of lists of (multiple) labels of each example\n    # pred_probs: predicted class probabilities from any trained classifier\n\nRunning the new `find_label_issues()`function on the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) image tagging dataset reveals around **30,000 mislabeled images**! Check out a few of them in the blog post!\n\nResources:\n\n* Blog post: [https://cleanlab.ai/blog/multilabel/](https://cleanlab.ai/blog/multilabel/)\n* Paper: [https://arxiv.org/abs/2211.13895](https://arxiv.org/abs/2211.13895)\n* Tutorial: [https://docs.cleanlab.ai/stable/tutorials/multilabel\\_classification.html](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html)\n* Benchmarks: [https://github.com/cleanlab/multilabel-error-detection-benchmarks](https://github.com/cleanlab/multilabel-error-detection-benchmarks)\n* Code: [https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)\n\nHope you find these practical tools useful in your real-world data science and ML applications!", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically Detect Annotation Errors in Image/Text Tagging Datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tn0m9lg8mx2a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ded0b70ace773d914022938b7f6111773083e63"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5297af1c66825939d6593864eaa66df1bd213576"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f29ee612abb6b36828e75e9e39c8fca58370236d"}, {"y": 358, "x": 640, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cc157981e74fb2d637e29b35525a2fed3e332245"}, {"y": 537, "x": 960, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c297bc35439a14766a5ad512e53b9fa51fb81aa3"}, {"y": 604, "x": 1080, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1f2e195f1bc4a38b7363b56f4941e25e60af7c4"}], "s": {"y": 700, "x": 1250, "u": "https://preview.redd.it/tn0m9lg8mx2a1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=80d4d09a24b6929894a5ce994042f491a6b8f544"}, "id": "tn0m9lg8mx2a1"}}, "name": "t3_z81m6m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NBR3-bZHhjkdKO9c2ZVeLFCwv0yliMxMF6bmuvldQgw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669745983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! Many of us in the data science and ML space work with &lt;strong&gt;multi-label data&lt;/strong&gt;, where the image or text is tagged with multiple labels. Often these datasets contain &lt;strong&gt;frequent label errors&lt;/strong&gt; and/or &lt;strong&gt;missing tags&lt;/strong&gt; (check what we found below in the CelebA dataset) that make it hard to train highly accurate ML models. Support for multi-label data was one of the top features requested \u2014 so we &lt;a href=\"https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html\"&gt;added it&lt;/a&gt;, &lt;a href=\"https://cleanlab.ai/blog/multilabel/\"&gt;benchmarked it&lt;/a&gt;, and published all of the &lt;a href=\"https://cleanlab.ai/blog/multilabel/\"&gt;research&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tn0m9lg8mx2a1.png?width=1250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d4d09a24b6929894a5ce994042f491a6b8f544\"&gt;Find errors and missing labels in multi-label datasets.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We are excited to share this newest research on algorithms to automatically find label errors in multi-label classification datasets. Image/document tagging represents important instances of\u00a0&lt;strong&gt;multi-label classification&lt;/strong&gt;\u00a0tasks, where each example can belong to multiple (or none) of K possible classes. Because annotating such data requires many decisions for each example, often multi-label classification datasets contain tons of label errors, which harm the performance of ML models.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve open-sourced our algorithms in the &lt;a href=\"https://github.com/cleanlab/cleanlab/releases/tag/v2.2.0\"&gt;recent release of cleanlab v2.2&lt;/a&gt;. All you need to do to use them is write one line of open-source code via &lt;a href=\"https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html\"&gt;cleanlab.filter.find_label_issues&lt;/a&gt;.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from cleanlab.filter import find_label_issues\n\nranked_label_issues = find_label_issues(\n    labels=labels,\n    pred_probs=pred_probs,\n    multi_label=True,\n    return_indices_ranked_by=&amp;quot;self_confidence&amp;quot;,\n)\n# labels: list of lists of (multiple) labels of each example\n# pred_probs: predicted class probabilities from any trained classifier\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Running the new &lt;code&gt;find_label_issues()&lt;/code&gt;function on the &lt;a href=\"https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\"&gt;CelebA&lt;/a&gt; image tagging dataset reveals around &lt;strong&gt;30,000 mislabeled images&lt;/strong&gt;! Check out a few of them in the blog post!&lt;/p&gt;\n\n&lt;p&gt;Resources:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Blog post: &lt;a href=\"https://cleanlab.ai/blog/multilabel/\"&gt;https://cleanlab.ai/blog/multilabel/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Paper: &lt;a href=\"https://arxiv.org/abs/2211.13895\"&gt;https://arxiv.org/abs/2211.13895&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Tutorial: &lt;a href=\"https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html\"&gt;https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Benchmarks: &lt;a href=\"https://github.com/cleanlab/multilabel-error-detection-benchmarks\"&gt;https://github.com/cleanlab/multilabel-error-detection-benchmarks&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Code: &lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;https://github.com/cleanlab/cleanlab&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hope you find these practical tools useful in your real-world data science and ML applications!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z81m6m", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z81m6m/automatically_detect_annotation_errors_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z81m6m/automatically_detect_annotation_errors_in/", "subreddit_subscribers": 822641, "created_utc": 1669745983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all! I am a Msc Data Science graduate but unfortunately the course didn't really teach me a lot and all I did was learn a whole lot of how to make assignments (kinda regret doing it).\n\nAs the title suggests, I am trying to learn IT skills to set my foot into data science/engineering jobs.\nWhat is a \"fail-proof\" IT skillset I would have that will almost guarantee that I will \"most probably\" land a job?\n\nCurrent IT skills I possess:\n1) Excel - intermediate to advanced \n2) PowerBI - intermediate to advanced\n3) Sql - intermediate to advanced\n4) Python - basic level. (Mentioned intermediate before but I don't believe I am anywhere near intermediate competency in python). All I can do is make stupid turtle games :)\n\nAlso I can never understand the difference between python and python for data science.\nIs modules/libs being used the only difference?\nI have started to learn coding and can do easy level questions on hacker rank with relative ease.\n\nI want to upskill myself with any skills that will be needed in next 2-3 months to go after a Junior DE/DS position.", "author_fullname": "t2_s2gn10bm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To working Data friends- How to upskill myself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8ndi5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669803149.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669801692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! I am a Msc Data Science graduate but unfortunately the course didn&amp;#39;t really teach me a lot and all I did was learn a whole lot of how to make assignments (kinda regret doing it).&lt;/p&gt;\n\n&lt;p&gt;As the title suggests, I am trying to learn IT skills to set my foot into data science/engineering jobs.\nWhat is a &amp;quot;fail-proof&amp;quot; IT skillset I would have that will almost guarantee that I will &amp;quot;most probably&amp;quot; land a job?&lt;/p&gt;\n\n&lt;p&gt;Current IT skills I possess:\n1) Excel - intermediate to advanced \n2) PowerBI - intermediate to advanced\n3) Sql - intermediate to advanced\n4) Python - basic level. (Mentioned intermediate before but I don&amp;#39;t believe I am anywhere near intermediate competency in python). All I can do is make stupid turtle games :)&lt;/p&gt;\n\n&lt;p&gt;Also I can never understand the difference between python and python for data science.\nIs modules/libs being used the only difference?\nI have started to learn coding and can do easy level questions on hacker rank with relative ease.&lt;/p&gt;\n\n&lt;p&gt;I want to upskill myself with any skills that will be needed in next 2-3 months to go after a Junior DE/DS position.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8ndi5", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent_Owl2797", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8ndi5/to_working_data_friends_how_to_upskill_myself/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8ndi5/to_working_data_friends_how_to_upskill_myself/", "subreddit_subscribers": 822641, "created_utc": 1669801692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have to forecast the headcount for a couple of business units across my org. \n\nNow I don\u2019t have a ton of experience in time series but took a few udemy courses and all and understand the basic principles.\n\nHowever since I have to create 50+ forecasts, I can\u2019t really go one by one and identify the best pdq values for each business unit.\n\nSo I created a function to just iterate through a bunch of SARIMAX parameters (p, q, seasonal pdq, trend) and just use the model with the lowest MAPE score. The function doesn\u2019t iterate through d but it tests for stationarity and proceeds accordingly.\n\nThe model results, for the most part, look good. I\u2019m just wondering if this is just inherently wrong or if there\u2019s a better way around it.\n\nThanks!", "author_fullname": "t2_1eoopt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a bad practice for time series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z80drh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669743235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to forecast the headcount for a couple of business units across my org. &lt;/p&gt;\n\n&lt;p&gt;Now I don\u2019t have a ton of experience in time series but took a few udemy courses and all and understand the basic principles.&lt;/p&gt;\n\n&lt;p&gt;However since I have to create 50+ forecasts, I can\u2019t really go one by one and identify the best pdq values for each business unit.&lt;/p&gt;\n\n&lt;p&gt;So I created a function to just iterate through a bunch of SARIMAX parameters (p, q, seasonal pdq, trend) and just use the model with the lowest MAPE score. The function doesn\u2019t iterate through d but it tests for stationarity and proceeds accordingly.&lt;/p&gt;\n\n&lt;p&gt;The model results, for the most part, look good. I\u2019m just wondering if this is just inherently wrong or if there\u2019s a better way around it.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z80drh", "is_robot_indexable": true, "report_reasons": null, "author": "scun1995", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z80drh/is_this_a_bad_practice_for_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z80drh/is_this_a_bad_practice_for_time_series/", "subreddit_subscribers": 822641, "created_utc": 1669743235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I made an RFM table from transaction data and plan to use clustering algorithm on it. However, the distribution of each R, F, and M is highly skewed. I suppose this is because there are a lot of outliers. I checked it using the IQR method.\n\nWhat should I do with the outliers data? I tried using sklearn's RobustScaler, but it does not make the distribution better. Tried using the log values too but it did not produce good enough result. \n\nOr, should I just:\n1. Remove the outliers\n2. Fit the transformation method (e.g., StandardScaler) on the remaining data\n3. Fit the scaled data to the clustering algorithm\n\nThank you!", "author_fullname": "t2_dnekp18a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I do if my RFM table contains outliers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z8rxw8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669816059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made an RFM table from transaction data and plan to use clustering algorithm on it. However, the distribution of each R, F, and M is highly skewed. I suppose this is because there are a lot of outliers. I checked it using the IQR method.&lt;/p&gt;\n\n&lt;p&gt;What should I do with the outliers data? I tried using sklearn&amp;#39;s RobustScaler, but it does not make the distribution better. Tried using the log values too but it did not produce good enough result. &lt;/p&gt;\n\n&lt;p&gt;Or, should I just:\n1. Remove the outliers\n2. Fit the transformation method (e.g., StandardScaler) on the remaining data\n3. Fit the scaled data to the clustering algorithm&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8rxw8", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Deer8805", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8rxw8/what_should_i_do_if_my_rfm_table_contains_outliers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8rxw8/what_should_i_do_if_my_rfm_table_contains_outliers/", "subreddit_subscribers": 822641, "created_utc": 1669816059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have trained a SARIMA model, and the best model is ARIMA(2,0,2)(2,0,1)\\[12\\]. Now, I have two questions:\n\n1. I understand that since D = 0, we don't perform seasonal differencing. Does this mean my data has something related to seasonality (because P = 2 and Q = 1) or not?\n2. What would be the best way to explain the orders and seasonal orders of the ARIMA parameters above in a way that non-technical managers can also understand?\n\nThank you!", "author_fullname": "t2_dnekp18a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I interpret SARIMA seasonal orders in a business language?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8ntug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669803208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have trained a SARIMA model, and the best model is ARIMA(2,0,2)(2,0,1)[12]. Now, I have two questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I understand that since D = 0, we don&amp;#39;t perform seasonal differencing. Does this mean my data has something related to seasonality (because P = 2 and Q = 1) or not?&lt;/li&gt;\n&lt;li&gt;What would be the best way to explain the orders and seasonal orders of the ARIMA parameters above in a way that non-technical managers can also understand?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8ntug", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Deer8805", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8ntug/how_do_i_interpret_sarima_seasonal_orders_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8ntug/how_do_i_interpret_sarima_seasonal_orders_in_a/", "subreddit_subscribers": 822641, "created_utc": 1669803208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have studied different variants of resnet and I'm aware that it is primarily used for image classification. I've even used pretrained resnet models for some projects.\n\nHowever I'm now very curious to know if there's any variant of resnet that can be used on typical tabular data, that too for a regression task.\n\nOr is there any convenient residual blocks (preferably tensorflow) available that I can plug and play?", "author_fullname": "t2_7pfh6trc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building ResNet for Tabular Data Regression Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z7z95e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669740671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have studied different variants of resnet and I&amp;#39;m aware that it is primarily used for image classification. I&amp;#39;ve even used pretrained resnet models for some projects.&lt;/p&gt;\n\n&lt;p&gt;However I&amp;#39;m now very curious to know if there&amp;#39;s any variant of resnet that can be used on typical tabular data, that too for a regression task.&lt;/p&gt;\n\n&lt;p&gt;Or is there any convenient residual blocks (preferably tensorflow) available that I can plug and play?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z7z95e", "is_robot_indexable": true, "report_reasons": null, "author": "eternalmathstudent", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z7z95e/building_resnet_for_tabular_data_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z7z95e/building_resnet_for_tabular_data_regression/", "subreddit_subscribers": 822641, "created_utc": 1669740671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know this sounds dumb but I want to figure out which among these should I get a masters in. Thank you", "author_fullname": "t2_85h2ri1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it easier for a data scientist to switch to an MLE role than it is for an MLE to become a data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8kbj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669791415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this sounds dumb but I want to figure out which among these should I get a masters in. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8kbj2", "is_robot_indexable": true, "report_reasons": null, "author": "bornwick", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8kbj2/is_it_easier_for_a_data_scientist_to_switch_to_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8kbj2/is_it_easier_for_a_data_scientist_to_switch_to_an/", "subreddit_subscribers": 822641, "created_utc": 1669791415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A flip question for all of us who seem to be on the other side of data so often but with scandals that have came out where firms use facial recognition technology to disproportionately misidentify people of color as criminals or social media platforms let advertisers exclude Black homebuyers from seeing real estate ads in particular neighborhoods, I wonder how many of us (Black, White, Man, Woman etc..) experience or even notice these type of exploitations on a personal or day to day level?\n\n\\-We are talking about race, technology and justice in my anthropology class and I would love to bring up unique perspectives", "author_fullname": "t2_rk081oia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do you think data is used against you based of your race or gender?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8eg3l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669775786.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669775399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A flip question for all of us who seem to be on the other side of data so often but with scandals that have came out where firms use facial recognition technology to disproportionately misidentify people of color as criminals or social media platforms let advertisers exclude Black homebuyers from seeing real estate ads in particular neighborhoods, I wonder how many of us (Black, White, Man, Woman etc..) experience or even notice these type of exploitations on a personal or day to day level?&lt;/p&gt;\n\n&lt;p&gt;-We are talking about race, technology and justice in my anthropology class and I would love to bring up unique perspectives&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8eg3l", "is_robot_indexable": true, "report_reasons": null, "author": "Supanovastar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8eg3l/how_often_do_you_think_data_is_used_against_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8eg3l/how_often_do_you_think_data_is_used_against_you/", "subreddit_subscribers": 822641, "created_utc": 1669775399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I'm assigned to build a dashboard to showcase time series data and models' predictions.I hate HTML.\n\nDivided between plotly dash, grafana, and metabase. What is your opinion?", "author_fullname": "t2_78hwwikp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real time dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8d3no", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669772134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m assigned to build a dashboard to showcase time series data and models&amp;#39; predictions.I hate HTML.&lt;/p&gt;\n\n&lt;p&gt;Divided between plotly dash, grafana, and metabase. What is your opinion?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8d3no", "is_robot_indexable": true, "report_reasons": null, "author": "quilograma", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8d3no/real_time_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8d3no/real_time_dashboard/", "subreddit_subscribers": 822641, "created_utc": 1669772134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, so I\u2019ve been learning data science through an live online course for almost 6 months. I feel quite comfortable using Python and SQL (although pretty much use Google search to find solutions to basically everything haha) Yesterday I had an interview for a entry data analytics position with hr and it went well, so today they invited me for a second round interview with the boss. Any tips or recommendations on what he might ask? (This is my first interview in this field)", "author_fullname": "t2_a24tjlxv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Typical interview questions for entry position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8bym6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669769769.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669769348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, so I\u2019ve been learning data science through an live online course for almost 6 months. I feel quite comfortable using Python and SQL (although pretty much use Google search to find solutions to basically everything haha) Yesterday I had an interview for a entry data analytics position with hr and it went well, so today they invited me for a second round interview with the boss. Any tips or recommendations on what he might ask? (This is my first interview in this field)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8bym6", "is_robot_indexable": true, "report_reasons": null, "author": "Minute_Associate3161", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8bym6/typical_interview_questions_for_entry_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8bym6/typical_interview_questions_for_entry_position/", "subreddit_subscribers": 822641, "created_utc": 1669769348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello friends. I am a trauma data analyst looking to see if anyone is familiar with this company. I was curious about the quality of their data for the trauma registry.", "author_fullname": "t2_dkv0iidt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Q-Centrix Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z81wq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669746640.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends. I am a trauma data analyst looking to see if anyone is familiar with this company. I was curious about the quality of their data for the trauma registry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z81wq4", "is_robot_indexable": true, "report_reasons": null, "author": "Xmegzyx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z81wq4/qcentrix_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z81wq4/qcentrix_data/", "subreddit_subscribers": 822641, "created_utc": 1669746640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4sd4akec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we use PCA (Principal Component analysis) to reduce dimension for a linear regression problem and at the same time control the multi-collinearity issue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8175q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669745044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8175q", "is_robot_indexable": true, "report_reasons": null, "author": "priyankandatta", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8175q/can_we_use_pca_principal_component_analysis_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8175q/can_we_use_pca_principal_component_analysis_to/", "subreddit_subscribers": 822641, "created_utc": 1669745044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not a data scientist. I'm just a programmer. I've had this question about the fundamentals of data modeling for a while though, hoping for clarification.\n\nConceptualizing the act of data modeling naively, I consider what happens when you learn new information. When you see more data about something you can make conservative updates to your existing model or you can make huge leaps.\n\nA conservative update would be the least assuming, I assume, almost akin to just recording the data like you would when performing K-nearest neighbors. Whereas, a huge leap is just that, a huge leap to making multiple assumptions from one observation, many of which may not be true.\n\nIt seems like every update to the model lies upon that spectrum. And to make things as simple as possible I'm assuming a truthful, or we should say, deterministic dataset. Most datasets are not deterministic. Their messy, real world stuff like the weather: it can snow in death valley even if it doesn't happen often. A deterministic environment would be something like a Rubik's cube, certain configurations or transitions are impossible.\n\nIt seems data modeling is the act of mapping the possibility space of the environment described by the dataset.\n\nMy question is, how do we do that in the most conservative way possible? And how do we know when we should get less conservative?\n\nI wish I had better concrete examples and I'm sorry this is so conceptual, but I'm trying to understand in my own way. Can you point me in the right direction?", "author_fullname": "t2_13e4kt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me understand the art.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8kj4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669792034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a data scientist. I&amp;#39;m just a programmer. I&amp;#39;ve had this question about the fundamentals of data modeling for a while though, hoping for clarification.&lt;/p&gt;\n\n&lt;p&gt;Conceptualizing the act of data modeling naively, I consider what happens when you learn new information. When you see more data about something you can make conservative updates to your existing model or you can make huge leaps.&lt;/p&gt;\n\n&lt;p&gt;A conservative update would be the least assuming, I assume, almost akin to just recording the data like you would when performing K-nearest neighbors. Whereas, a huge leap is just that, a huge leap to making multiple assumptions from one observation, many of which may not be true.&lt;/p&gt;\n\n&lt;p&gt;It seems like every update to the model lies upon that spectrum. And to make things as simple as possible I&amp;#39;m assuming a truthful, or we should say, deterministic dataset. Most datasets are not deterministic. Their messy, real world stuff like the weather: it can snow in death valley even if it doesn&amp;#39;t happen often. A deterministic environment would be something like a Rubik&amp;#39;s cube, certain configurations or transitions are impossible.&lt;/p&gt;\n\n&lt;p&gt;It seems data modeling is the act of mapping the possibility space of the environment described by the dataset.&lt;/p&gt;\n\n&lt;p&gt;My question is, how do we do that in the most conservative way possible? And how do we know when we should get less conservative?&lt;/p&gt;\n\n&lt;p&gt;I wish I had better concrete examples and I&amp;#39;m sorry this is so conceptual, but I&amp;#39;m trying to understand in my own way. Can you point me in the right direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8kj4t", "is_robot_indexable": true, "report_reasons": null, "author": "Stack3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8kj4t/help_me_understand_the_art/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8kj4t/help_me_understand_the_art/", "subreddit_subscribers": 822641, "created_utc": 1669792034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As an aspiring data scientist and current analyst, I notice sometimes I make small/careless mistakes and try to overcome it but I'm wondering how I can avoid it. For example, sometimes what I write vs. the number I have is different like a positive vs negative value. I'm trying to be as detail oriented as possible", "author_fullname": "t2_4707201x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Avoiding careless mistakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8g8wg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669779923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an aspiring data scientist and current analyst, I notice sometimes I make small/careless mistakes and try to overcome it but I&amp;#39;m wondering how I can avoid it. For example, sometimes what I write vs. the number I have is different like a positive vs negative value. I&amp;#39;m trying to be as detail oriented as possible&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8g8wg", "is_robot_indexable": true, "report_reasons": null, "author": "hello010101", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8g8wg/avoiding_careless_mistakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8g8wg/avoiding_careless_mistakes/", "subreddit_subscribers": 822641, "created_utc": 1669779923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I was recently promoted to manage a newly established data science team and need a solution that doesn\u2019t add more pain than it\u2019s worth.\n\nThis is a new team full of 15ish people who mostly have not worked together. I\u2019d like some way to display (to myself and the team) what people are working on and how each person\u2019s contributions intersect. Ideally this would look like some kind of Trello-meets-flowchart where I can see what\u2019s going on, what resources are in play and how it all relates.\n\nDoes this exist? What are best practices you guys have seen for getting a big picture overview of the mechanics/assets in play with your team?", "author_fullname": "t2_unnu5ob8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking management tools my (new) data team will not hate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8cbt5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669770255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I was recently promoted to manage a newly established data science team and need a solution that doesn\u2019t add more pain than it\u2019s worth.&lt;/p&gt;\n\n&lt;p&gt;This is a new team full of 15ish people who mostly have not worked together. I\u2019d like some way to display (to myself and the team) what people are working on and how each person\u2019s contributions intersect. Ideally this would look like some kind of Trello-meets-flowchart where I can see what\u2019s going on, what resources are in play and how it all relates.&lt;/p&gt;\n\n&lt;p&gt;Does this exist? What are best practices you guys have seen for getting a big picture overview of the mechanics/assets in play with your team?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8cbt5", "is_robot_indexable": true, "report_reasons": null, "author": "United-Albatros", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8cbt5/seeking_management_tools_my_new_data_team_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8cbt5/seeking_management_tools_my_new_data_team_will/", "subreddit_subscribers": 822641, "created_utc": 1669770255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_15fwz65h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Christmas Season Coming Earlier? A Statistical Analysis.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 118, "top_awarded_type": null, "hide_score": false, "name": "t3_z89o2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0k0bf7EELHyERPNTPF5S9cmaZ1P00x1v1FTlUMHGpcI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669764009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "statsignificant.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.statsignificant.com/p/is-christmas-season-coming-earlier", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dgfx7WF37oS0MJuC5DBBJGfamGnPjb06OMvxFLzTFo0.jpg?auto=webp&amp;s=fe7622099c5b4e1afe0b18597aa856502a54a274", "width": 711, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/dgfx7WF37oS0MJuC5DBBJGfamGnPjb06OMvxFLzTFo0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=36494d18e981ffb3cef594c0b0efa87c011ff9ba", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/dgfx7WF37oS0MJuC5DBBJGfamGnPjb06OMvxFLzTFo0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0046cb078822bfdf4acf0f0c60a4ee243743dde6", "width": 216, "height": 182}, {"url": "https://external-preview.redd.it/dgfx7WF37oS0MJuC5DBBJGfamGnPjb06OMvxFLzTFo0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d47ecadce7f62ee3f8feaeb21fea56dbcf5ee12e", "width": 320, "height": 270}, {"url": "https://external-preview.redd.it/dgfx7WF37oS0MJuC5DBBJGfamGnPjb06OMvxFLzTFo0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=001a3a17c6f1514dfb74bc5cd24b5eec473f8121", "width": 640, "height": 540}], "variants": {}, "id": "DKLxZn6jm2xA1w6sagiYoeJqeKXO9-T9hnIWulLShIE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "z89o2s", "is_robot_indexable": true, "report_reasons": null, "author": "dpee123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z89o2s/is_christmas_season_coming_earlier_a_statistical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.statsignificant.com/p/is-christmas-season-coming-earlier", "subreddit_subscribers": 822641, "created_utc": 1669764009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m currently enrolled in a data science bootcamp where we will be taken from the very basics all the way through to ML and AI work.\n\nThey\u2019ve recommended we use VS Code as our IDE.\n\nI\u2019m 21 [M] and need to purchase a laptop on which I can complete this work.\n\nI\u2019d be financing it, and wouldn\u2019t want to pay more than \u00a31.3k overall for it.\n\nWhat laptop would you guys recommend and why?\n\n(In the past I\u2019ve had both macs and windows).\n\nThanks in advance!", "author_fullname": "t2_9z23zma5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What laptop would you recommend for someone starting out with data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8noj6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669802730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently enrolled in a data science bootcamp where we will be taken from the very basics all the way through to ML and AI work.&lt;/p&gt;\n\n&lt;p&gt;They\u2019ve recommended we use VS Code as our IDE.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m 21 [M] and need to purchase a laptop on which I can complete this work.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d be financing it, and wouldn\u2019t want to pay more than \u00a31.3k overall for it.&lt;/p&gt;\n\n&lt;p&gt;What laptop would you guys recommend and why?&lt;/p&gt;\n\n&lt;p&gt;(In the past I\u2019ve had both macs and windows).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8noj6", "is_robot_indexable": true, "report_reasons": null, "author": "Any-Ad8016", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8noj6/what_laptop_would_you_recommend_for_someone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8noj6/what_laptop_would_you_recommend_for_someone/", "subreddit_subscribers": 822641, "created_utc": 1669802730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "One of best way to learn Technical skills is to write about it and read about it through Blogs. From Today, Daily i will share link to some Blogs published on Famous Platforms(not mine, credit goes to respective Platforms) in field of Data Science, Web 3.0, Azure, Cloud Computing, Blockchain, AWS etc.", "author_fullname": "t2_t17xnudl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn by reading !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z8lr8p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669795912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of best way to learn Technical skills is to write about it and read about it through Blogs. From Today, Daily i will share link to some Blogs published on Famous Platforms(not mine, credit goes to respective Platforms) in field of Data Science, Web 3.0, Azure, Cloud Computing, Blockchain, AWS etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z8lr8p", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Science_Novice", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z8lr8p/learn_by_reading/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z8lr8p/learn_by_reading/", "subreddit_subscribers": 822641, "created_utc": 1669795912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I'm picking between 5 universities to apply for my masters. Wondering what you think and anyone has any insight/ replace them. \n\n\nDS masters-\n-Minnesota (ds in public health)\n-Georgia tech ( cheapest DS) \n-Unt for data engineering\n-Arizona state university for bio Informatics \n- SMU (60k for it, but smu connections", "author_fullname": "t2_rntn75xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with these 5 masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z80bh1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669743093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m picking between 5 universities to apply for my masters. Wondering what you think and anyone has any insight/ replace them. &lt;/p&gt;\n\n&lt;p&gt;DS masters-\n-Minnesota (ds in public health)\n-Georgia tech ( cheapest DS) \n-Unt for data engineering\n-Arizona state university for bio Informatics \n- SMU (60k for it, but smu connections&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z80bh1", "is_robot_indexable": true, "report_reasons": null, "author": "Enough_Classroom_903", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z80bh1/help_with_these_5_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z80bh1/help_with_these_5_masters/", "subreddit_subscribers": 822641, "created_utc": 1669743093.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}