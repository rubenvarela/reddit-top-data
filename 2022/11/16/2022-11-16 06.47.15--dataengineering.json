{"kind": "Listing", "data": {"after": "t3_yw98q9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Airflow was released in\u00a0**2014**\u00a0by Maxime Beauchemin (of Airbnb). In those 8 years it\u2019s really dominated DE in the wild. However, many teams are putting out ideas to succeed Airflow.\n\nI\u2019d like to start a discussion:\n\nIs DE collectively moving on from Airflow, or \u2026 i***f it ain\u2019t broke, why fix it?!***\n\nWhat could be improved on Airflow (even v2):\n\n&amp;#x200B;\n\n* Lack of ability to test easily\n* Data sharing between tasks (TaskFlow API is a step in the right direction, but still limited by underlying design choices)\n* End up with NxM for sources and targets\n\n&amp;#x200B;\n\nHow might the market develop? (not 1 winner, for sure):\n\n* **Streaming, Kafka**\n   * Backbone of many of the large tech now\n   * Very advanced for many teams\n   * Will it completely replace batch?\n* **Fivetran and other tools that automate DE**\n   * Reduces reliance on hard to find DEs\n   * New pricing models based on credits make it more affordable\n* **Airbyte and DBT, Simple Airflow and DBT**\n   * simple model of commoditizing the \\[EL\\] and then DBT for the \\[T\\]\n   * makes \u2018analytics engineers\u2018 (analysts) much more productive but is limited for complex workloads perhaps (will adding python hooks change this)\n* **Dagster &amp; Prefect**\n   * Better composability\n   * Shared data between tasks\n   * Big enough feature improvements to move from Airflow?\n   * Is the community big enough yet?\n* **AWS Lambda (serverless)**\n   * Tooling underdeveloped\n   * 15 minute limit per lambda run\n* **Stick with Airflow 2**\n   * FOSS\n   * Move to Astronomer for managed services is growing somewhat\n   * Despite some productivity challenges, it is easy to support\n\n&amp;#x200B;\n\n**What do you think?**\n\n\\- What do you plan (concretely) on using in next 6 months?- What are you using now?\n\n&amp;#x200B;\n\n**Full disclosure:**  I hope this is an interesting discussion question! We are of course making [a new alternative (typhoondata.io)](https://typhoondata.io/)   but want to learn from the forum so I have not included our option directly in the list.", "author_fullname": "t2_crnoguki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After Airflow. Where next for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw3mk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668546144.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668532840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Airflow was released in\u00a0&lt;strong&gt;2014&lt;/strong&gt;\u00a0by Maxime Beauchemin (of Airbnb). In those 8 years it\u2019s really dominated DE in the wild. However, many teams are putting out ideas to succeed Airflow.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to start a discussion:&lt;/p&gt;\n\n&lt;p&gt;Is DE collectively moving on from Airflow, or \u2026 i&lt;strong&gt;&lt;em&gt;f it ain\u2019t broke, why fix it?!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;What could be improved on Airflow (even v2):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Lack of ability to test easily&lt;/li&gt;\n&lt;li&gt;Data sharing between tasks (TaskFlow API is a step in the right direction, but still limited by underlying design choices)&lt;/li&gt;\n&lt;li&gt;End up with NxM for sources and targets&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How might the market develop? (not 1 winner, for sure):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Streaming, Kafka&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Backbone of many of the large tech now&lt;/li&gt;\n&lt;li&gt;Very advanced for many teams&lt;/li&gt;\n&lt;li&gt;Will it completely replace batch?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fivetran and other tools that automate DE&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Reduces reliance on hard to find DEs&lt;/li&gt;\n&lt;li&gt;New pricing models based on credits make it more affordable&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Airbyte and DBT, Simple Airflow and DBT&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;simple model of commoditizing the [EL] and then DBT for the [T]&lt;/li&gt;\n&lt;li&gt;makes \u2018analytics engineers\u2018 (analysts) much more productive but is limited for complex workloads perhaps (will adding python hooks change this)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Dagster &amp;amp; Prefect&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Better composability&lt;/li&gt;\n&lt;li&gt;Shared data between tasks&lt;/li&gt;\n&lt;li&gt;Big enough feature improvements to move from Airflow?&lt;/li&gt;\n&lt;li&gt;Is the community big enough yet?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AWS Lambda (serverless)&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Tooling underdeveloped&lt;/li&gt;\n&lt;li&gt;15 minute limit per lambda run&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stick with Airflow 2&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;FOSS&lt;/li&gt;\n&lt;li&gt;Move to Astronomer for managed services is growing somewhat&lt;/li&gt;\n&lt;li&gt;Despite some productivity challenges, it is easy to support&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What do you think?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- What do you plan (concretely) on using in next 6 months?- What are you using now?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Full disclosure:&lt;/strong&gt;  I hope this is an interesting discussion question! We are of course making &lt;a href=\"https://typhoondata.io/\"&gt;a new alternative (typhoondata.io)&lt;/a&gt;   but want to learn from the forum so I have not included our option directly in the list.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?auto=webp&amp;s=0ccd7631658c9ca465afe7ddaada34d1598a8afc", "width": 600, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a794906fe1dc01d33c54746bf6f1d02726d5050", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b80f68957e3c9fdb3d6251a471eb8e8999fa837", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8k_zLc8WIktL7A7a0yuAsmHUdi2XgcrKemETVwo74EY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5996e2653640cef99d3c4d3a408ed9b270c6d9c7", "width": 320, "height": 160}], "variants": {}, "id": "mpduhDtughYqwqqQM2iBf4D_nFj2DW0HvTduyWYjmDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw3mk5", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful_Yam_8090", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw3mk5/after_airflow_where_next_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw3mk5/after_airflow_where_next_for_de/", "subreddit_subscribers": 80086, "created_utc": 1668532840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI recently faced a decision I had to make at work whether to use asyncio or concurrent.futures ThreadPoolExecutor in order to do some concurrent fetching from a database for a backend service. (~30 fetching jobs, small and quick queries).\n\nI did some research online and found some very different opinions about these two approaches and couldn't quite decide what's best for this use case. \n\nThat had me wondering which approach do other data engineers tend to use with such problems?", "author_fullname": "t2_bikhahe4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python concurrency for Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw06ry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668547387.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668525781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently faced a decision I had to make at work whether to use asyncio or concurrent.futures ThreadPoolExecutor in order to do some concurrent fetching from a database for a backend service. (~30 fetching jobs, small and quick queries).&lt;/p&gt;\n\n&lt;p&gt;I did some research online and found some very different opinions about these two approaches and couldn&amp;#39;t quite decide what&amp;#39;s best for this use case. &lt;/p&gt;\n\n&lt;p&gt;That had me wondering which approach do other data engineers tend to use with such problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw06ry", "is_robot_indexable": true, "report_reasons": null, "author": "ConsistentAd1477", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw06ry/python_concurrency_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw06ry/python_concurrency_for_data_engineers/", "subreddit_subscribers": 80086, "created_utc": 1668525781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a new graduate and I am working as a data scientist in a startup for a 8 months. I started as a intern and now I am working full time. Unfortunately, my responsibilities are not exactly data science tasks. I can define it as data analysis and finding data sources for dev team. These tasks doesn't help me to improve my resume I can not develop myself in data field.\n\nActually I am more interested in data engineering and I want to switch to this field. I know Python and SQL but I don't have an expertise on these languages. Everyday I am visiting this subreddit and try to find a path. Some of them says \"SQL and Python is enough for entry level, just start to apply\". Other one says \"you should also build pipeline, make a project\" and maybe sometimes \"you should know dbt, airflow etc.\" so I feel I am lost. I was thinking this path before:\n\n* Improve yourself on SQL and start to solve leetcode.\n* Then learn cloud (aws).\n* After that build a pipeline, ETL project.\n* Now you can start to apply jobs.\n\nWhat do you think, what should I do now? This subreddit is so valuable and your opinions are really helpful for me. Thank you.", "author_fullname": "t2_qmoxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I start applying for jobs? I am lost.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw0jg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668526547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new graduate and I am working as a data scientist in a startup for a 8 months. I started as a intern and now I am working full time. Unfortunately, my responsibilities are not exactly data science tasks. I can define it as data analysis and finding data sources for dev team. These tasks doesn&amp;#39;t help me to improve my resume I can not develop myself in data field.&lt;/p&gt;\n\n&lt;p&gt;Actually I am more interested in data engineering and I want to switch to this field. I know Python and SQL but I don&amp;#39;t have an expertise on these languages. Everyday I am visiting this subreddit and try to find a path. Some of them says &amp;quot;SQL and Python is enough for entry level, just start to apply&amp;quot;. Other one says &amp;quot;you should also build pipeline, make a project&amp;quot; and maybe sometimes &amp;quot;you should know dbt, airflow etc.&amp;quot; so I feel I am lost. I was thinking this path before:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Improve yourself on SQL and start to solve leetcode.&lt;/li&gt;\n&lt;li&gt;Then learn cloud (aws).&lt;/li&gt;\n&lt;li&gt;After that build a pipeline, ETL project.&lt;/li&gt;\n&lt;li&gt;Now you can start to apply jobs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think, what should I do now? This subreddit is so valuable and your opinions are really helpful for me. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw0jg3", "is_robot_indexable": true, "report_reasons": null, "author": "lost4line", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw0jg3/should_i_start_applying_for_jobs_i_am_lost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw0jg3/should_i_start_applying_for_jobs_i_am_lost/", "subreddit_subscribers": 80086, "created_utc": 1668526547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm confused as to what Airbyte exactly offers. I have more of a BI engineering background but also have plenty of experience developing data pipelines. I've tried watching a few videos of Airbyte but can't exactly figure out what it is. Is it a low-code solution? Does it include orchestration? What's it most comparable to?", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone explain Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw8pzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668544418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m confused as to what Airbyte exactly offers. I have more of a BI engineering background but also have plenty of experience developing data pipelines. I&amp;#39;ve tried watching a few videos of Airbyte but can&amp;#39;t exactly figure out what it is. Is it a low-code solution? Does it include orchestration? What&amp;#39;s it most comparable to?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw8pzx", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw8pzx/can_someone_explain_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw8pzx/can_someone_explain_airbyte/", "subreddit_subscribers": 80086, "created_utc": 1668544418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data mesh has been a really popular concept, but I've been surprised by how few pieces there are about how to operationalize a data mesh architecture. A  cool feature that a lot of companies use to get past the performance barrier to data federation is full query passthrough. To this end, I wrote a tutorial on how to use it below. Hope it helps you all out: [https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/](https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/)", "author_fullname": "t2_bd9mcb3k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Guide] Full query passthrough to enable the data mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw6j2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668539267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data mesh has been a really popular concept, but I&amp;#39;ve been surprised by how few pieces there are about how to operationalize a data mesh architecture. A  cool feature that a lot of companies use to get past the performance barrier to data federation is full query passthrough. To this end, I wrote a tutorial on how to use it below. Hope it helps you all out: &lt;a href=\"https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/\"&gt;https://www.starburst.io/blog/introducing-full-query-passthrough-for-faster-query-federation/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?auto=webp&amp;s=2aa1e5b0e2b22d524df1c9d9a934793b88ad6e31", "width": 1234, "height": 574}, "resolutions": [{"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c5062d0fcc3a1bd0739a2c78484343ca772ea075", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bce6e57d8071ac00fd40feebbb63b883d6413a41", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d3626e50ab90bb5519b5da3035e06e088d82269", "width": 320, "height": 148}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e2711ecc9d4fd5a93f36e52fafe3be94204feb15", "width": 640, "height": 297}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23d8b10f222f9f8a8d6dd61bf735c3277d740c1a", "width": 960, "height": 446}, {"url": "https://external-preview.redd.it/SAVzQrIMcZycGKzD7YQ-CL5jFd13aZRxF7ebIGS7RQs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a28c956ade73a6ac95d7d67ccbba4f144a91a920", "width": 1080, "height": 502}], "variants": {}, "id": "ijJ6Xa2IDLeCS5kKwH08WIF4KC76IYswMsiKoXbp5Bg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yw6j2t", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Week6114", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw6j2t/guide_full_query_passthrough_to_enable_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw6j2t/guide_full_query_passthrough_to_enable_the_data/", "subreddit_subscribers": 80086, "created_utc": 1668539267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm reading [*Fundamentals of Data Engineering*](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302)*.* Chapter 2 talks about metadata in depth.   \n\n\nI understand what metadata is in theory (data about data) but **I don't fully understand what it looks like in practice. If you have any example, let me know!**   \n\n\nHere's what I know so far about metadata in practice:\n\n* Documentation\n* Data dictionaries\n* Data models/ schema (example: documenting data models / schemas w/ dbt)\n* Data lineage (documenting the lifecycle of data from inception to its final state. Kinda like orchestration or DAGS)", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't wrap my head around \"metadata\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw5dya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668536586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reading &lt;a href=\"https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302\"&gt;&lt;em&gt;Fundamentals of Data Engineering&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt; Chapter 2 talks about metadata in depth.   &lt;/p&gt;\n\n&lt;p&gt;I understand what metadata is in theory (data about data) but &lt;strong&gt;I don&amp;#39;t fully understand what it looks like in practice. If you have any example, let me know!&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I know so far about metadata in practice:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Documentation&lt;/li&gt;\n&lt;li&gt;Data dictionaries&lt;/li&gt;\n&lt;li&gt;Data models/ schema (example: documenting data models / schemas w/ dbt)&lt;/li&gt;\n&lt;li&gt;Data lineage (documenting the lifecycle of data from inception to its final state. Kinda like orchestration or DAGS)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw5dya", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw5dya/cant_wrap_my_head_around_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw5dya/cant_wrap_my_head_around_metadata/", "subreddit_subscribers": 80086, "created_utc": 1668536586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have the task of replicating the data in from an Azure SQL DB and an AWS RDS SQL DB into a Snowflake data warehouse, and I am unsure the most cost effective way to do this.\n\n* Azure SQL DB has 25 GB of data, and grows at about 1 GB per month\n* AWS RDS SQL DB has 1.2 TB of data, and grows at about 5 GB per month\n\nMy task is to get both of these databases fully replicated into the Snowflake instance, and then keep the Snowflake instance updated on a daily cadence for our business intelligence reports.\n\nIs Azure Data Factory a good way to handle this? I don't need to transform the data during replication, but I am finding it difficult to estimate the cost of running the ADF replication pipelines each once per day.\n\nI am also a little confused on if ADF can support just replicating the delta from each source after the initial bulk loading is done into the Snowflake warehouse. I see conflicting information online about ADF's ability to just handle the delta with Snowflake as a sink, and that SnowPipe would need to be used for that instead.\n\nAre there better options out there for this use-case rather than ADF or SnowPipe? Thanks in advance for anyone that can give me some advice.", "author_fullname": "t2_tql2kvxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to set up replication pipelines from an Azure SQL DB + AWS RDS SQL DB into Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvw546", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668516253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have the task of replicating the data in from an Azure SQL DB and an AWS RDS SQL DB into a Snowflake data warehouse, and I am unsure the most cost effective way to do this.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure SQL DB has 25 GB of data, and grows at about 1 GB per month&lt;/li&gt;\n&lt;li&gt;AWS RDS SQL DB has 1.2 TB of data, and grows at about 5 GB per month&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My task is to get both of these databases fully replicated into the Snowflake instance, and then keep the Snowflake instance updated on a daily cadence for our business intelligence reports.&lt;/p&gt;\n\n&lt;p&gt;Is Azure Data Factory a good way to handle this? I don&amp;#39;t need to transform the data during replication, but I am finding it difficult to estimate the cost of running the ADF replication pipelines each once per day.&lt;/p&gt;\n\n&lt;p&gt;I am also a little confused on if ADF can support just replicating the delta from each source after the initial bulk loading is done into the Snowflake warehouse. I see conflicting information online about ADF&amp;#39;s ability to just handle the delta with Snowflake as a sink, and that SnowPipe would need to be used for that instead.&lt;/p&gt;\n\n&lt;p&gt;Are there better options out there for this use-case rather than ADF or SnowPipe? Thanks in advance for anyone that can give me some advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvw546", "is_robot_indexable": true, "report_reasons": null, "author": "AzureNoob1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvw546/best_way_to_set_up_replication_pipelines_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvw546/best_way_to_set_up_replication_pipelines_from_an/", "subreddit_subscribers": 80086, "created_utc": 1668516253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has any one written the DBT developer certificate exam?\n\nif so how did you prep?\n\n&amp;#x200B;\n\nto give some context, I have been using DBT now for a year at my work and my boss suggested that i write that exam, I booked it for the end of December and i found this [https://www.getdbt.com/assets/uploads/dbt\\_certificate\\_study\\_guide.pdf](https://www.getdbt.com/assets/uploads/dbt_certificate_study_guide.pdf)\n\n&amp;#x200B;\n\nbut I wasn't sure if going through it is enough to pass.", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Developer Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw3567", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668531833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has any one written the DBT developer certificate exam?&lt;/p&gt;\n\n&lt;p&gt;if so how did you prep?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;to give some context, I have been using DBT now for a year at my work and my boss suggested that i write that exam, I booked it for the end of December and i found this &lt;a href=\"https://www.getdbt.com/assets/uploads/dbt_certificate_study_guide.pdf\"&gt;https://www.getdbt.com/assets/uploads/dbt_certificate_study_guide.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;but I wasn&amp;#39;t sure if going through it is enough to pass.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw3567", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw3567/dbt_developer_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw3567/dbt_developer_certificate/", "subreddit_subscribers": 80086, "created_utc": 1668531833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We can't be the only ones facing this issue in Bigquery.\n\nPrinciple of least privilege. A user should not be able to read any sensitive data unless they need to, and if they need to read it the reason should be documented and the privilege should best case temporary. At least if we want to make the DPO happy. Managing that at scale seems to be a hassle, feels like we're missing something obvious.\n\nWhat we as a team require (among other things):\n\n1. Tagging columns with policy tags\n2. Defining policy tag taxonomies\n3. Efficient access requests to datasets/tables/columns\n4. Audit privileges (anyone have access that shouldn't?)\n5. Privilege expiration \n\nFor any individual part it's totally doable to create our own custom solutions, but putting it all together it becomes cumbersome.\n\nFor example policy tags. Creating those in GCP is ok, and we could even have a script that creates them from code. Tagging columns with them however I don't have many solutions for, Dbt is the only one that probably could work for us, but I'm not sure how the source tables (CSVs etc loaded into BQ with Airflow) would fit into that picture, probably requires some restructuring. Adding onto that we also need to have a system for requesting fine-grained reader privilege on the tags.\n\nA bit long-winded. Have I missed any go-to resources? How do you guys manage policy tags and such?", "author_fullname": "t2_svio3uio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage GDPR in Bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw8yrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668544994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We can&amp;#39;t be the only ones facing this issue in Bigquery.&lt;/p&gt;\n\n&lt;p&gt;Principle of least privilege. A user should not be able to read any sensitive data unless they need to, and if they need to read it the reason should be documented and the privilege should best case temporary. At least if we want to make the DPO happy. Managing that at scale seems to be a hassle, feels like we&amp;#39;re missing something obvious.&lt;/p&gt;\n\n&lt;p&gt;What we as a team require (among other things):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Tagging columns with policy tags&lt;/li&gt;\n&lt;li&gt;Defining policy tag taxonomies&lt;/li&gt;\n&lt;li&gt;Efficient access requests to datasets/tables/columns&lt;/li&gt;\n&lt;li&gt;Audit privileges (anyone have access that shouldn&amp;#39;t?)&lt;/li&gt;\n&lt;li&gt;Privilege expiration &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For any individual part it&amp;#39;s totally doable to create our own custom solutions, but putting it all together it becomes cumbersome.&lt;/p&gt;\n\n&lt;p&gt;For example policy tags. Creating those in GCP is ok, and we could even have a script that creates them from code. Tagging columns with them however I don&amp;#39;t have many solutions for, Dbt is the only one that probably could work for us, but I&amp;#39;m not sure how the source tables (CSVs etc loaded into BQ with Airflow) would fit into that picture, probably requires some restructuring. Adding onto that we also need to have a system for requesting fine-grained reader privilege on the tags.&lt;/p&gt;\n\n&lt;p&gt;A bit long-winded. Have I missed any go-to resources? How do you guys manage policy tags and such?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw8yrv", "is_robot_indexable": true, "report_reasons": null, "author": "Natural_Switch_8614", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw8yrv/how_do_you_manage_gdpr_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw8yrv/how_do_you_manage_gdpr_in_bigquery/", "subreddit_subscribers": 80086, "created_utc": 1668544994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nWe need to move data from Maria DB to Snowflake. We get the Maria table data periodically in to S3 bucket (snowflake external stage) through a vendor CDC replication app. Every changes happening in Maria table would be written to S3 bucket all day around as JSON files with tablename-01.json,tablename-02.json etc. File sizes are expected to be less than 100mb.\n\nWe use Python to load the data from the S3 bucket in to Snowflake and Airflow to schedule the data movement. We would use Python Operator to run the Python script that contains COPY/MERGE statements. \n\nMy question is around setting up Airflow DAGS. We are planning to have one DAG per table. Since all DAGs would have similar tasks, the plan is to generate the DAGs dynamically.  So if there are 10 tables, we would have 10 DAGs each moving data for the respective table in to Snowflake.\n\nIs this approach fine or is there any other better way to do this data movement? General suggestions in setting up this pipeline are also welcome.\n\nthanks.", "author_fullname": "t2_jfqnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DAG set up for moving data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw6mzp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668539509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;We need to move data from Maria DB to Snowflake. We get the Maria table data periodically in to S3 bucket (snowflake external stage) through a vendor CDC replication app. Every changes happening in Maria table would be written to S3 bucket all day around as JSON files with tablename-01.json,tablename-02.json etc. File sizes are expected to be less than 100mb.&lt;/p&gt;\n\n&lt;p&gt;We use Python to load the data from the S3 bucket in to Snowflake and Airflow to schedule the data movement. We would use Python Operator to run the Python script that contains COPY/MERGE statements. &lt;/p&gt;\n\n&lt;p&gt;My question is around setting up Airflow DAGS. We are planning to have one DAG per table. Since all DAGs would have similar tasks, the plan is to generate the DAGs dynamically.  So if there are 10 tables, we would have 10 DAGs each moving data for the respective table in to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Is this approach fine or is there any other better way to do this data movement? General suggestions in setting up this pipeline are also welcome.&lt;/p&gt;\n\n&lt;p&gt;thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw6mzp", "is_robot_indexable": true, "report_reasons": null, "author": "curidpostn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw6mzp/airflow_dag_set_up_for_moving_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw6mzp/airflow_dag_set_up_for_moving_data/", "subreddit_subscribers": 80086, "created_utc": 1668539509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you're a self-employed data engineer or have been paid to build out data pipelines for companies, I have questions for you!\n\n&amp;#x200B;\n\n* How did you get started? Did a company reach out to you or vice versa?\n* How do you scope out a projects timeline for a company? Do you break down the work into increments?\n* How many years of prior experience do you have?\n* What \"stack\" have you used? What is necessary and what is substitutable?\n* How have you created your pricing model?", "author_fullname": "t2_6ztum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self Employeed DE Contractors Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw2ood", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668530899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re a self-employed data engineer or have been paid to build out data pipelines for companies, I have questions for you!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How did you get started? Did a company reach out to you or vice versa?&lt;/li&gt;\n&lt;li&gt;How do you scope out a projects timeline for a company? Do you break down the work into increments?&lt;/li&gt;\n&lt;li&gt;How many years of prior experience do you have?&lt;/li&gt;\n&lt;li&gt;What &amp;quot;stack&amp;quot; have you used? What is necessary and what is substitutable?&lt;/li&gt;\n&lt;li&gt;How have you created your pricing model?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw2ood", "is_robot_indexable": true, "report_reasons": null, "author": "reidism", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw2ood/self_employeed_de_contractors_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw2ood/self_employeed_de_contractors_questions/", "subreddit_subscribers": 80086, "created_utc": 1668530899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State Management for Cloud Native Streaming: Getting to the Core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yw6g0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tCrJjRMOZqAd9beY4o3cb1ipq85NYf1SVRKQqt2XEvY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668539067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave-labs.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave-labs.com/blog/state-management-for-cloud-native-streaming/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?auto=webp&amp;s=35f49010d5ff8fb2e64563c9e22e7f30e3429954", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77c9ce8993b766b1d3c55c37eff0e17e621d1d63", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cd995fc23561c9e6d806ca2b6e99214378bf2af", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0bb21e91c3a40670781b97dbab03350f18a603e7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4259042dfb6f278b2cd95b13c13ad7ef1b22f61", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=48686911ad6edd9bc84fbb027e5da86fe1c833e6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/YIzK8Iua47OgJX6MrxXOQ19F_zKmHAxgT0PJndvv0yc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=933970c776740f42863ff83f4b20ed8e7ec682b5", "width": 1080, "height": 607}], "variants": {}, "id": "kZR2XqyHUc26qkWZUy5G4HdWSzR1DCliVsb8zkhmBEs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yw6g0s", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw6g0s/state_management_for_cloud_native_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave-labs.com/blog/state-management-for-cloud-native-streaming/", "subreddit_subscribers": 80086, "created_utc": 1668539067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nMy company is small, sub 10 mill revenue. We\u2019ve just created a data engineering team after years of bodging it. The first thing I want to do is catalogue the data, so I\u2019m researching the various choices online. I\u2019m getting frustrated with the inability to find ballpark costs. The only mention I can see of Alation\u2019s offering is $198k per annum which prices it so far beyond our budget that it\u2019s a waste of my time to even consider it.\n\nWhat are small companies using for data cataloguing? What other DE tools are small companies using? We currently have a wild mix of in-house built tools in at least 4 different languages and it\u2019s all getting a bit creaky\u2026 \n\nThanks for your advice.", "author_fullname": "t2_9od90rps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data cataloguing (and other tools) - pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw4bv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668534291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;My company is small, sub 10 mill revenue. We\u2019ve just created a data engineering team after years of bodging it. The first thing I want to do is catalogue the data, so I\u2019m researching the various choices online. I\u2019m getting frustrated with the inability to find ballpark costs. The only mention I can see of Alation\u2019s offering is $198k per annum which prices it so far beyond our budget that it\u2019s a waste of my time to even consider it.&lt;/p&gt;\n\n&lt;p&gt;What are small companies using for data cataloguing? What other DE tools are small companies using? We currently have a wild mix of in-house built tools in at least 4 different languages and it\u2019s all getting a bit creaky\u2026 &lt;/p&gt;\n\n&lt;p&gt;Thanks for your advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw4bv1", "is_robot_indexable": true, "report_reasons": null, "author": "Acidulated", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw4bv1/data_cataloguing_and_other_tools_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw4bv1/data_cataloguing_and_other_tools_pricing/", "subreddit_subscribers": 80086, "created_utc": 1668534291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_wxj1rz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How vectorization improves database performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yw0z51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1_9V4zWdYJ3f5OrlMGMsnDDtjSBVUY5oJRVULRe_Gxw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668527414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoworld.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoworld.com/article/3678300/how-vectorization-improves-database-performance.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?auto=webp&amp;s=2de46562324f1234705ff004863ac441380bac90", "width": 1200, "height": 1231}, "resolutions": [{"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1d895959685c3071284a787c1c65c1c9ad04f16", "width": 108, "height": 110}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=755bc79f8c465ef4017f8418baf23965dee9a37b", "width": 216, "height": 221}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=047c69df98d016ed9e54f397f810b87cadc54251", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e844915eea1f1cc02fed432baeeff3e39f59133d", "width": 640, "height": 656}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d7ae9ae66c7aaa01f6dd78eef1d6b05ac42461a", "width": 960, "height": 984}, {"url": "https://external-preview.redd.it/r-UvBJGka4fePEWCkcar0bpX3ehruSP-JFBJl1yMb0g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cfbb1d51a30e2591e2ba6f4f288afc00e729311", "width": 1080, "height": 1107}], "variants": {}, "id": "PSkYnX0bO_VeNWvfjdFzn2fYuF2JR9dne_Zc-Km4668"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yw0z51", "is_robot_indexable": true, "report_reasons": null, "author": "lkang5280", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw0z51/how_vectorization_improves_database_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoworld.com/article/3678300/how-vectorization-improves-database-performance.html", "subreddit_subscribers": 80086, "created_utc": 1668527414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi all,\n\nI'm a data engineering consultant so I start a project at a new customer regularly. I have the technical skills and tools down nicely so the biggest challenge when working with new data is figuring out and remembering what every database, schema, table and column means or is for. Is there a way or tool to document data for myself in a user-friendly manner? Like I can pull automatically or write down any of the objects (db, schema, table, column, column value, constraint, etc) and write my own notes by them, making everything easily findable etc.\n\nI thought about using trello boards per db and a ticket per table or something, writing down column descriptions and general info in there, but I feel like there must be a better way to go about it.\n\nAny tips, tricks and tools are greatly appreciated!", "author_fullname": "t2_5877uyxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Documenting data for personal reference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvry50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668504223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineering consultant so I start a project at a new customer regularly. I have the technical skills and tools down nicely so the biggest challenge when working with new data is figuring out and remembering what every database, schema, table and column means or is for. Is there a way or tool to document data for myself in a user-friendly manner? Like I can pull automatically or write down any of the objects (db, schema, table, column, column value, constraint, etc) and write my own notes by them, making everything easily findable etc.&lt;/p&gt;\n\n&lt;p&gt;I thought about using trello boards per db and a ticket per table or something, writing down column descriptions and general info in there, but I feel like there must be a better way to go about it.&lt;/p&gt;\n\n&lt;p&gt;Any tips, tricks and tools are greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvry50", "is_robot_indexable": true, "report_reasons": null, "author": "v0nm1ll3r", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvry50/documenting_data_for_personal_reference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvry50/documenting_data_for_personal_reference/", "subreddit_subscribers": 80086, "created_utc": 1668504223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would love to here from the community how you guys are designing your databricks DLT pipelines, as its pretty new and there isn\u2019t a whole lot of community documentation on it.\n\nFor us, our workspace consists of 3 DLT pipelines: dev , staging, and prod. Changes are tested on dev and then deployed to staging(runs once a day) and prod (continuous), where we can toggle between the two for a blue/green type deployment (data needs to always be accessible)\n\nData is read through SQS/SNS first to a raw table (entire table is read in a single json column with CDC), it is then written to a table with a defined schema (this is all in DLT pipeline)\n\nFrom here we define views to different catalogs and databases of varying degrees of sensitive/pii data (red, yellow, green). All databricks infrastructure, permissions, and users are managed with pulumi (like terraform).\n\nWould love to hear what others are doing to see how we could improve!", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your Databricks/DLT architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywi2en", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668568330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to here from the community how you guys are designing your databricks DLT pipelines, as its pretty new and there isn\u2019t a whole lot of community documentation on it.&lt;/p&gt;\n\n&lt;p&gt;For us, our workspace consists of 3 DLT pipelines: dev , staging, and prod. Changes are tested on dev and then deployed to staging(runs once a day) and prod (continuous), where we can toggle between the two for a blue/green type deployment (data needs to always be accessible)&lt;/p&gt;\n\n&lt;p&gt;Data is read through SQS/SNS first to a raw table (entire table is read in a single json column with CDC), it is then written to a table with a defined schema (this is all in DLT pipeline)&lt;/p&gt;\n\n&lt;p&gt;From here we define views to different catalogs and databases of varying degrees of sensitive/pii data (red, yellow, green). All databricks infrastructure, permissions, and users are managed with pulumi (like terraform).&lt;/p&gt;\n\n&lt;p&gt;Would love to hear what others are doing to see how we could improve!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywi2en", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywi2en/what_is_your_databricksdlt_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywi2en/what_is_your_databricksdlt_architecture/", "subreddit_subscribers": 80086, "created_utc": 1668568330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nNoob here trying to gather information and get grounded in all of this. My organization is deciding whether to go with Snowflake or Synapse for their data warehouse and deciding what ELT tools would be best.\n\nHere's some context:\n\n\\- 90% data on SQL Server, 10% Oracle &amp; others\n\n\\- All employees are SQL based, not well versed in spark or python\n\n\\- A lot of existing code and stored procedures in MS SQL already.\n\n\\- County-sized judicial data.\n\nWe have some experience with Azure Data Factory &amp; Purview. Considering options like Matillion, Fivetran, and Coalesce  (and open to any better ones) for Snowflake if it would be better overall.\n\nWe have no limitation on price and are mostly focused on finding what's easiest/best to transition to and maintain.\n\nLet me know if I can provide more info, thanks in advance!", "author_fullname": "t2_r0krk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Combination of Tools (Synapse or Snowflake)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywb63z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668550223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;Noob here trying to gather information and get grounded in all of this. My organization is deciding whether to go with Snowflake or Synapse for their data warehouse and deciding what ELT tools would be best.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s some context:&lt;/p&gt;\n\n&lt;p&gt;- 90% data on SQL Server, 10% Oracle &amp;amp; others&lt;/p&gt;\n\n&lt;p&gt;- All employees are SQL based, not well versed in spark or python&lt;/p&gt;\n\n&lt;p&gt;- A lot of existing code and stored procedures in MS SQL already.&lt;/p&gt;\n\n&lt;p&gt;- County-sized judicial data.&lt;/p&gt;\n\n&lt;p&gt;We have some experience with Azure Data Factory &amp;amp; Purview. Considering options like Matillion, Fivetran, and Coalesce  (and open to any better ones) for Snowflake if it would be better overall.&lt;/p&gt;\n\n&lt;p&gt;We have no limitation on price and are mostly focused on finding what&amp;#39;s easiest/best to transition to and maintain.&lt;/p&gt;\n\n&lt;p&gt;Let me know if I can provide more info, thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywb63z", "is_robot_indexable": true, "report_reasons": null, "author": "sizzlepoop", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywb63z/best_combination_of_tools_synapse_or_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywb63z/best_combination_of_tools_synapse_or_snowflake/", "subreddit_subscribers": 80086, "created_utc": 1668550223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am an experienced professional with around 16 years of experience. I have worked a lot on data pipelines \\[for micro services mainly, not for ML\\] and AWS. Have very strong database and analytics experience (RDBMS, NOSql , AWS DBs, KAfka, AWS services like Kinesis, etc). I am thinking DS degree would expand my horizon into the ML area. But I would probably stick to DE as I really enjoy my work.", "author_fullname": "t2_7p3dtj69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How relevant would be a Masters in Data Science for a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywaslt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668549301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an experienced professional with around 16 years of experience. I have worked a lot on data pipelines [for micro services mainly, not for ML] and AWS. Have very strong database and analytics experience (RDBMS, NOSql , AWS DBs, KAfka, AWS services like Kinesis, etc). I am thinking DS degree would expand my horizon into the ML area. But I would probably stick to DE as I really enjoy my work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywaslt", "is_robot_indexable": true, "report_reasons": null, "author": "Release-Helpful", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywaslt/how_relevant_would_be_a_masters_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywaslt/how_relevant_would_be_a_masters_in_data_science/", "subreddit_subscribers": 80086, "created_utc": 1668549301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Much like web development, embedded systems, DevOps, etc?\n\n[View Poll](https://www.reddit.com/poll/yw9gc6)", "author_fullname": "t2_et5pvnxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think Data Engineering is a specialization within Software Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw9gc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668546135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Much like web development, embedded systems, DevOps, etc?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yw9gc6\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yw9gc6", "is_robot_indexable": true, "report_reasons": null, "author": "yabbagabbamappa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1668805335878, "options": [{"text": "Yes, DE is a subfield / specialization within SWE.", "id": "19832574"}, {"text": "No.", "id": "19832575"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 428, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw9gc6/do_you_think_data_engineering_is_a_specialization/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/yw9gc6/do_you_think_data_engineering_is_a_specialization/", "subreddit_subscribers": 80086, "created_utc": 1668546135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, \n\nI am currently working on a project (personal but hoping to commercialize it at some point). The idea is a website allowing the user to upload data in the form of CSV/Excel and the website would basically generate a full dashboard containing several graphs analyzing the data. Eventually, I would want to export those dashboards as pdfs or emaemailsil. \n\nThe data extraction part I am ok with.  I am able to build the data parsing part easily with Pandas . I am looking now for the best way to generate dashboards on the web app (based on the result of the processing done in python ). \n\nI had a quick look at the possibilities and I found Streamlit and Dash as two options. They seemed however more adapted to a scenario of a company building its own BI system than a service website. My assumption is based on a quick research and gut feeling so please correct me if I am wrong \n\nAny suggestions for tools and libraries? \n\nThanks in advance", "author_fullname": "t2_kzkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help need to pick the most adapted dashboard-generating tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw1ap6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668528068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, &lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project (personal but hoping to commercialize it at some point). The idea is a website allowing the user to upload data in the form of CSV/Excel and the website would basically generate a full dashboard containing several graphs analyzing the data. Eventually, I would want to export those dashboards as pdfs or emaemailsil. &lt;/p&gt;\n\n&lt;p&gt;The data extraction part I am ok with.  I am able to build the data parsing part easily with Pandas . I am looking now for the best way to generate dashboards on the web app (based on the result of the processing done in python ). &lt;/p&gt;\n\n&lt;p&gt;I had a quick look at the possibilities and I found Streamlit and Dash as two options. They seemed however more adapted to a scenario of a company building its own BI system than a service website. My assumption is based on a quick research and gut feeling so please correct me if I am wrong &lt;/p&gt;\n\n&lt;p&gt;Any suggestions for tools and libraries? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yw1ap6", "is_robot_indexable": true, "report_reasons": null, "author": "mkhalil77", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw1ap6/help_need_to_pick_the_most_adapted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw1ap6/help_need_to_pick_the_most_adapted/", "subreddit_subscribers": 80086, "created_utc": 1668528068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an idea for a web application project that I want to build and I wanted to get peoples ideas on what the best approach should be. \n\nThe problem: A podcast I listen to doesn't name each podcast with a descriptive title. Each title is just a random phrase unrelated to description of the podcast. So it's difficult to go back and find a podcast or recommend an episode to a friend if you can't remember the title. \n\nSolution: I'd like to build a web application which consists of a search bar and has a list of episodes underneath the search bar. As you type into the search bar the list of episodes underneath gets filtered down. \n\nMy approach: I'm thinking that the first step would be to scrape the data and create a table with the title as one column and the episode description as the second column. Or potentially break the episode description into a number of tags and link the episode titles to their tags. \n\nHelp: After that I'm a bit lost. How should I best create these tables. How can I filter a list based on text in the search bar. Any ideas on this are appreciated. I'm sure this had also been done before so if there's a name for what I'm trying to do or specific learning resources please send them my way.", "author_fullname": "t2_303xrahc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to design a list which filters based on text in a search bar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yvyvat", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668522639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an idea for a web application project that I want to build and I wanted to get peoples ideas on what the best approach should be. &lt;/p&gt;\n\n&lt;p&gt;The problem: A podcast I listen to doesn&amp;#39;t name each podcast with a descriptive title. Each title is just a random phrase unrelated to description of the podcast. So it&amp;#39;s difficult to go back and find a podcast or recommend an episode to a friend if you can&amp;#39;t remember the title. &lt;/p&gt;\n\n&lt;p&gt;Solution: I&amp;#39;d like to build a web application which consists of a search bar and has a list of episodes underneath the search bar. As you type into the search bar the list of episodes underneath gets filtered down. &lt;/p&gt;\n\n&lt;p&gt;My approach: I&amp;#39;m thinking that the first step would be to scrape the data and create a table with the title as one column and the episode description as the second column. Or potentially break the episode description into a number of tags and link the episode titles to their tags. &lt;/p&gt;\n\n&lt;p&gt;Help: After that I&amp;#39;m a bit lost. How should I best create these tables. How can I filter a list based on text in the search bar. Any ideas on this are appreciated. I&amp;#39;m sure this had also been done before so if there&amp;#39;s a name for what I&amp;#39;m trying to do or specific learning resources please send them my way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yvyvat", "is_robot_indexable": true, "report_reasons": null, "author": "CorktoBoston2020", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yvyvat/how_to_design_a_list_which_filters_based_on_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yvyvat/how_to_design_a_list_which_filters_based_on_text/", "subreddit_subscribers": 80086, "created_utc": 1668522639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to understand if it's a viable option to use a sample of the data for faster delivery and/or to save the resources. We have a pretty complex sequence of  daily Spark jobs that results in a desirable dataset. Daily jobs process billions of events and consumes thousands of core-hours. Now we are asked to prepare it every few hours. The final goal is to see some counts and conversion rates of app's UI elements. I think we can use slow pipeline for daily but for hourly version we can use sampling. If the number of events is high enough we can just take  1/10(randomly picked users) of the data and then multiply the counts back by 10. If counts are pretty high we should get a relatively close estimation of the result and you still will be able to see the trends. \nDoes anyone use similar approach? Is there any drawbacks to this?", "author_fullname": "t2_bxh7hkhc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use sampling in your ETL pipelines for faster delivery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywhbsq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668566318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand if it&amp;#39;s a viable option to use a sample of the data for faster delivery and/or to save the resources. We have a pretty complex sequence of  daily Spark jobs that results in a desirable dataset. Daily jobs process billions of events and consumes thousands of core-hours. Now we are asked to prepare it every few hours. The final goal is to see some counts and conversion rates of app&amp;#39;s UI elements. I think we can use slow pipeline for daily but for hourly version we can use sampling. If the number of events is high enough we can just take  1/10(randomly picked users) of the data and then multiply the counts back by 10. If counts are pretty high we should get a relatively close estimation of the result and you still will be able to see the trends. \nDoes anyone use similar approach? Is there any drawbacks to this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywhbsq", "is_robot_indexable": true, "report_reasons": null, "author": "SunnyBay6", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywhbsq/do_you_use_sampling_in_your_etl_pipelines_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywhbsq/do_you_use_sampling_in_your_etl_pipelines_for/", "subreddit_subscribers": 80086, "created_utc": 1668566318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are trying to ingest Mongo into our data lake, but the problem is that being inherently unstructured, there\u2019s no east way to use the typical tools (Tableau, SQL engines) you would have in relational DBs. How do you make Mongo data available for analytics?\n\nSome of the things I\u2019ve seen but not sure how good of solutions they\u2019d be. \n\n* Store it as JSON and just use JSON functions in SQL. JSON functions in SQL seem like almost as much of a pain as MQL\n* Use the relationalize class in AWS Glue to automatically create tables. Leaning toward this, but not sure how reliable it will be\n* Manually write scripts to relationalize the data. This is what we have done in the past, but it requires a lot of maintenance for schema evolution\n* Atlas Data Lake seems interesting, but not quite ready yet", "author_fullname": "t2_15ii7n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What options are there for storing Mongo data in a data lake for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywh909", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668566105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are trying to ingest Mongo into our data lake, but the problem is that being inherently unstructured, there\u2019s no east way to use the typical tools (Tableau, SQL engines) you would have in relational DBs. How do you make Mongo data available for analytics?&lt;/p&gt;\n\n&lt;p&gt;Some of the things I\u2019ve seen but not sure how good of solutions they\u2019d be. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Store it as JSON and just use JSON functions in SQL. JSON functions in SQL seem like almost as much of a pain as MQL&lt;/li&gt;\n&lt;li&gt;Use the relationalize class in AWS Glue to automatically create tables. Leaning toward this, but not sure how reliable it will be&lt;/li&gt;\n&lt;li&gt;Manually write scripts to relationalize the data. This is what we have done in the past, but it requires a lot of maintenance for schema evolution&lt;/li&gt;\n&lt;li&gt;Atlas Data Lake seems interesting, but not quite ready yet&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ywh909", "is_robot_indexable": true, "report_reasons": null, "author": "draqor", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywh909/what_options_are_there_for_storing_mongo_data_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywh909/what_options_are_there_for_storing_mongo_data_in/", "subreddit_subscribers": 80086, "created_utc": 1668566105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI've been exploring gcp's data fusion product and not really liking it. Seems like its still got a ways to go. Am I missing something? What are all your thoughts on it? What kind of things do you guys use it for if you are using it?", "author_fullname": "t2_866f1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on google cloud data fusion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywexau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668559769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been exploring gcp&amp;#39;s data fusion product and not really liking it. Seems like its still got a ways to go. Am I missing something? What are all your thoughts on it? What kind of things do you guys use it for if you are using it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywexau", "is_robot_indexable": true, "report_reasons": null, "author": "LegacyTower", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywexau/thoughts_on_google_cloud_data_fusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywexau/thoughts_on_google_cloud_data_fusion/", "subreddit_subscribers": 80086, "created_utc": 1668559769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, what are possible tools for triggering job on Databricks via some event, for example data delivered to s3?", "author_fullname": "t2_sx1wry60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "event trigger jobs on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yw98q9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668545651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, what are possible tools for triggering job on Databricks via some event, for example data delivered to s3?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yw98q9", "is_robot_indexable": true, "report_reasons": null, "author": "AcceptableProcess772", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yw98q9/event_trigger_jobs_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yw98q9/event_trigger_jobs_on_databricks/", "subreddit_subscribers": 80086, "created_utc": 1668545651.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}