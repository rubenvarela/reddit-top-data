{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nI am fresh grad working at a startup with around 20 people. And basically, Im having a very hard time showing them how to do AB testing properly. They have definitely made a lot of progress over the past 6 months but I feel like it's not enough.\nFor example: When I came in, they used to carry out some AB tests without control groups, and when they did, the sample sizes were guessed completely at random,  \"ah let's have 100 in control and 55000 in the test group because we know that the treatment group is going to be positive anyways. \"\n\nThe problem is that I am not taking part in the experiment design and I am only learning about their experiment after it has ended. They only come to me when they need an analysis done. \"Hey we did this experiment 4 weeks ago. Can you tell us if A outperformed B?\"\n\nLogically I must be involved in these experiments from the very start, and no experiments should be run without my approval. But, being the stats nerd that I am, how can I convince a team of extroverted marketing people that I'm important for ab testing? \n\nAny thoughts?  \n\nThanks in advance.", "author_fullname": "t2_2lwypaad", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I enforce statistical rigor in a non-technical team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yrs7se", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 189, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 189, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668115415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am fresh grad working at a startup with around 20 people. And basically, Im having a very hard time showing them how to do AB testing properly. They have definitely made a lot of progress over the past 6 months but I feel like it&amp;#39;s not enough.\nFor example: When I came in, they used to carry out some AB tests without control groups, and when they did, the sample sizes were guessed completely at random,  &amp;quot;ah let&amp;#39;s have 100 in control and 55000 in the test group because we know that the treatment group is going to be positive anyways. &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The problem is that I am not taking part in the experiment design and I am only learning about their experiment after it has ended. They only come to me when they need an analysis done. &amp;quot;Hey we did this experiment 4 weeks ago. Can you tell us if A outperformed B?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Logically I must be involved in these experiments from the very start, and no experiments should be run without my approval. But, being the stats nerd that I am, how can I convince a team of extroverted marketing people that I&amp;#39;m important for ab testing? &lt;/p&gt;\n\n&lt;p&gt;Any thoughts?  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yrs7se", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Fan_283", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yrs7se/how_can_i_enforce_statistical_rigor_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yrs7se/how_can_i_enforce_statistical_rigor_in_a/", "subreddit_subscribers": 818845, "created_utc": 1668115415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My background is 100% NLP; i have 2 master's degrees in linguistics, applied and computational.  I have been at my current job at a startup for 3 years, mostly working classic classification on semi-structuered data. I'd say 25% of my time is doing analysis/visualizations, 25% building models and the rest of the time doing model productionizing/data pipeline work.\n\nI left on parental leave and when I came back my old manager was now gone and my old team had no work left for me so I was moved to the CV team.  This was way out of my domain experience but I was trying to make it work.  There were a few communication breakdowns between the new team lead and I, partly due to my own ADHD and sleep-deprived state (new baby y'all), and partly due to unclear expectations/communication.  Things like \"you should be looking at module X to develop our augmentation pipeline\", a day later \"why did start coding in module X, this isn't what I wanted\", a month later \"Code looks good but you should've used module X, looks like your code was developed in parallel.\" To another coworker \"Please switch these to relative imports.\" A week later \"Why are these relative imports? They should be absolute.\"\n\nIt's the end of the quarter and we are starting to wrap up some new models we've been developing.  I got pulled into a meeting two days ago to talk about Q4 project plans with my team lead and the engineering lead.  I was promptly told that I would be finishing my model development that day and switching to MLOps/Engineering starting the next day, complete with official org/desk move.  My work which was 95% python will now be done in Golang, a language I don't know (although I have experience with Java).  I was told this was 'entirely resource driven'.  This might be true as there's been a lot of attrition on our team (we lost 50% of our DS team in the last 3 years, and just had a small layoff on the engineering team that got rid of some architects/devops people).  But it's also certainly a possibility that the team is not working out but instead of moving me back to my old team they've just decided to offload me.\n\nThis is not at all what I wanted, especially after trying to adjust with life with a new baby.  I feel like I've been asked to learn Mandarin, when I only know French and was struggling to learn Italian.  I'm actively trying to leave this place but with the economic slowdown + holidays, I'm getting fewer and fewer responses back to applications.\n\nAnyone else get stuck in a role you didn't want? How'd you deal?\n\nOh, fun note: New engineering lead will be my *seventh* manager in 3 years.", "author_fullname": "t2_epvfp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm being forced into an engineering role, after 3 years of DS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ysb12p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668174567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My background is 100% NLP; i have 2 master&amp;#39;s degrees in linguistics, applied and computational.  I have been at my current job at a startup for 3 years, mostly working classic classification on semi-structuered data. I&amp;#39;d say 25% of my time is doing analysis/visualizations, 25% building models and the rest of the time doing model productionizing/data pipeline work.&lt;/p&gt;\n\n&lt;p&gt;I left on parental leave and when I came back my old manager was now gone and my old team had no work left for me so I was moved to the CV team.  This was way out of my domain experience but I was trying to make it work.  There were a few communication breakdowns between the new team lead and I, partly due to my own ADHD and sleep-deprived state (new baby y&amp;#39;all), and partly due to unclear expectations/communication.  Things like &amp;quot;you should be looking at module X to develop our augmentation pipeline&amp;quot;, a day later &amp;quot;why did start coding in module X, this isn&amp;#39;t what I wanted&amp;quot;, a month later &amp;quot;Code looks good but you should&amp;#39;ve used module X, looks like your code was developed in parallel.&amp;quot; To another coworker &amp;quot;Please switch these to relative imports.&amp;quot; A week later &amp;quot;Why are these relative imports? They should be absolute.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s the end of the quarter and we are starting to wrap up some new models we&amp;#39;ve been developing.  I got pulled into a meeting two days ago to talk about Q4 project plans with my team lead and the engineering lead.  I was promptly told that I would be finishing my model development that day and switching to MLOps/Engineering starting the next day, complete with official org/desk move.  My work which was 95% python will now be done in Golang, a language I don&amp;#39;t know (although I have experience with Java).  I was told this was &amp;#39;entirely resource driven&amp;#39;.  This might be true as there&amp;#39;s been a lot of attrition on our team (we lost 50% of our DS team in the last 3 years, and just had a small layoff on the engineering team that got rid of some architects/devops people).  But it&amp;#39;s also certainly a possibility that the team is not working out but instead of moving me back to my old team they&amp;#39;ve just decided to offload me.&lt;/p&gt;\n\n&lt;p&gt;This is not at all what I wanted, especially after trying to adjust with life with a new baby.  I feel like I&amp;#39;ve been asked to learn Mandarin, when I only know French and was struggling to learn Italian.  I&amp;#39;m actively trying to leave this place but with the economic slowdown + holidays, I&amp;#39;m getting fewer and fewer responses back to applications.&lt;/p&gt;\n\n&lt;p&gt;Anyone else get stuck in a role you didn&amp;#39;t want? How&amp;#39;d you deal?&lt;/p&gt;\n\n&lt;p&gt;Oh, fun note: New engineering lead will be my &lt;em&gt;seventh&lt;/em&gt; manager in 3 years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ysb12p", "is_robot_indexable": true, "report_reasons": null, "author": "GirlLunarExplorer", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ysb12p/im_being_forced_into_an_engineering_role_after_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ysb12p/im_being_forced_into_an_engineering_role_after_3/", "subreddit_subscribers": 818845, "created_utc": 1668174567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would also be interested in hearing about the sect(s) of Data Science you belong to.", "author_fullname": "t2_xyd63e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools or software have provided monumental assistance (i.e., time savers, simplified work processes, etc) for your work in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yrzy0t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668137152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would also be interested in hearing about the sect(s) of Data Science you belong to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yrzy0t", "is_robot_indexable": true, "report_reasons": null, "author": "thapasaan", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yrzy0t/what_tools_or_software_have_provided_monumental/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yrzy0t/what_tools_or_software_have_provided_monumental/", "subreddit_subscribers": 818845, "created_utc": 1668137152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have two binary variables, that I want to put in 4 different classes. Also, I have a small dataset (N=110) that is unbalanced (e.g., group 3 has only three observations) and I want to make predictions. Obviously the predictions that I did for the unbalanced dataset are pretty bad, because error rates for minority classes are 100%. However, I upsampled the dataset, and now I have the problem that minority classes get 0% error rate, but majority classes have almost 100% error. I am using random forest and SVM. Is it better to perform two binary classification problems than do one 4 level classification?\n\nThanks for any help!", "author_fullname": "t2_ebvaei9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 level classification with imbalance data - better to perform 2 binary predictions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yrwma0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668127051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two binary variables, that I want to put in 4 different classes. Also, I have a small dataset (N=110) that is unbalanced (e.g., group 3 has only three observations) and I want to make predictions. Obviously the predictions that I did for the unbalanced dataset are pretty bad, because error rates for minority classes are 100%. However, I upsampled the dataset, and now I have the problem that minority classes get 0% error rate, but majority classes have almost 100% error. I am using random forest and SVM. Is it better to perform two binary classification problems than do one 4 level classification?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yrwma0", "is_robot_indexable": true, "report_reasons": null, "author": "ArugulaOk1835", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yrwma0/4_level_classification_with_imbalance_data_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yrwma0/4_level_classification_with_imbalance_data_better/", "subreddit_subscribers": 818845, "created_utc": 1668127051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A network takes features as input.\n\nA solution to combinatorial optimization is a series of number is seemingly a random string of number\n\nIf I want to extract some features from the random string to put into network. What could I do?", "author_fullname": "t2_sonzi145", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A weird confusion: can I extract features from solution of combinatorial optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ys5n17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668158057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A network takes features as input.&lt;/p&gt;\n\n&lt;p&gt;A solution to combinatorial optimization is a series of number is seemingly a random string of number&lt;/p&gt;\n\n&lt;p&gt;If I want to extract some features from the random string to put into network. What could I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ys5n17", "is_robot_indexable": true, "report_reasons": null, "author": "JoPrimer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ys5n17/a_weird_confusion_can_i_extract_features_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ys5n17/a_weird_confusion_can_i_extract_features_from/", "subreddit_subscribers": 818845, "created_utc": 1668158057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TLDR**: There are a lot of resources online about [feature store](https://www.featurestore.org/) solutions but few best practice on how to handle common framework problems (a.k.a. Design Patterns).\n\nThere are a lot of resources online about [feature store](https://www.featurestore.org/) solutions and [comprehensive guides](https://www.databricks.com/p/ebook/the-comprehensive-guide-to-feature-stores).\n\nMany of them are valid but there are few best practice on how to actually build your feature store and handle common framework problems. In software there's the concept of \"Design Patterns\"; can be done something similar for implementing feature stores?\n\nExample: daily raw data but models you have in production mostly use monthly aggregated features (i.e. monthly totals, weekly totals, weekend totals, workday totals, ...). Do you compute and store all those features or try to find only 'elemental' features and let the model compute the rest? For example workday totals can be obtained by difference among monthly totals and weeekend totals, last month total can be obtained by querying the previous month monthly total instead of having the same feature replicated in the observation month, etc.\n\n What suggestions do you have? Do you have any resource on 'Feature Store Design Patterns' to share?", "author_fullname": "t2_11i284", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Store - Framework &amp; Best Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ys59w9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668156553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: There are a lot of resources online about &lt;a href=\"https://www.featurestore.org/\"&gt;feature store&lt;/a&gt; solutions but few best practice on how to handle common framework problems (a.k.a. Design Patterns).&lt;/p&gt;\n\n&lt;p&gt;There are a lot of resources online about &lt;a href=\"https://www.featurestore.org/\"&gt;feature store&lt;/a&gt; solutions and &lt;a href=\"https://www.databricks.com/p/ebook/the-comprehensive-guide-to-feature-stores\"&gt;comprehensive guides&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Many of them are valid but there are few best practice on how to actually build your feature store and handle common framework problems. In software there&amp;#39;s the concept of &amp;quot;Design Patterns&amp;quot;; can be done something similar for implementing feature stores?&lt;/p&gt;\n\n&lt;p&gt;Example: daily raw data but models you have in production mostly use monthly aggregated features (i.e. monthly totals, weekly totals, weekend totals, workday totals, ...). Do you compute and store all those features or try to find only &amp;#39;elemental&amp;#39; features and let the model compute the rest? For example workday totals can be obtained by difference among monthly totals and weeekend totals, last month total can be obtained by querying the previous month monthly total instead of having the same feature replicated in the observation month, etc.&lt;/p&gt;\n\n&lt;p&gt;What suggestions do you have? Do you have any resource on &amp;#39;Feature Store Design Patterns&amp;#39; to share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?auto=webp&amp;s=9a82f43e1e3452fe983fa0ab0964f78cd8b52222", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91b2d1357b430509bc1f9c6c25ce4cd983119ce9", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51b15ba2cd405bad5849290b666531c7add82003", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8669ad464e3294b51098555d5aab46fee277774b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4bc917402d937eae72809fa21358cc018ad8031", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c3116d7a241534e5b05416445e11397975b5e1c8", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/LwHAPIbymnRFe9lGZZ4d1WTPZegvBth9n4uyxcB93M8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f763d5a4a9bd78d4619bcf989268f87b990bfd5", "width": 1080, "height": 564}], "variants": {}, "id": "NXEI7Vixuycifnw6bOQljgr9f0bq5RIcsJj6wvaxzdI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ys59w9", "is_robot_indexable": true, "report_reasons": null, "author": "__kVz__", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ys59w9/feature_store_framework_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ys59w9/feature_store_framework_best_practice/", "subreddit_subscribers": 818845, "created_utc": 1668156553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nHi everyone,\n\nIm fairly new to data science and currently working on a project to test the effects that an economic shock has had.\n\n(to give more context, Im looking to prove that the mini-budget recently introduced in the UK caused adverse yield prices. I want to compare the real yield prices with a forecast of yield prices had that budget not been introduced. The other variables I have data for are EUR and USD exchange rates, SONIA interest rates, FTSE100 open prices and Conservative voting intention. All these variables interact with one another as well as the government bond yield)\n\nI am looking to create a model where I can forecast yield prices by taking into account the other variables mentioned, then use dummy variables to assess the impact of different shocks.\n\nIs this possible? How is best to go about doing this?\n\nEDIT: Is it viable to continue with VAR using the variables other than government bond yield as independent variables?\n\nThanks!", "author_fullname": "t2_pplvkuz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help choosing multivariate time series analysis model for forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ysj0p8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668192064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Im fairly new to data science and currently working on a project to test the effects that an economic shock has had.&lt;/p&gt;\n\n&lt;p&gt;(to give more context, Im looking to prove that the mini-budget recently introduced in the UK caused adverse yield prices. I want to compare the real yield prices with a forecast of yield prices had that budget not been introduced. The other variables I have data for are EUR and USD exchange rates, SONIA interest rates, FTSE100 open prices and Conservative voting intention. All these variables interact with one another as well as the government bond yield)&lt;/p&gt;\n\n&lt;p&gt;I am looking to create a model where I can forecast yield prices by taking into account the other variables mentioned, then use dummy variables to assess the impact of different shocks.&lt;/p&gt;\n\n&lt;p&gt;Is this possible? How is best to go about doing this?&lt;/p&gt;\n\n&lt;p&gt;EDIT: Is it viable to continue with VAR using the variables other than government bond yield as independent variables?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ysj0p8", "is_robot_indexable": true, "report_reasons": null, "author": "FunObligation4171", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ysj0p8/help_choosing_multivariate_time_series_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ysj0p8/help_choosing_multivariate_time_series_analysis/", "subreddit_subscribers": 818845, "created_utc": 1668192064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nWe could go for multiple paragraphs of backstory, but here's the TL;DR without all the trouble:\n\n1) 50% of my next sprint allocation is adhocs, probably because lately I've showcased that I can be highly detailed and provide fast turnaround on stakeholder and exec requests  \n2) My current workflow - juggling multiple jupyter kernels, juggling multiple terminal windows for authentication, juggling multiple environments, juggling ugly stuff like Excel - is not working out. I spend time looking for the \\*right\\* window or the \\*right\\* cell in a jupyter notebook, and it's frustrating.  \n3) I'm going to switch to an IDE just to reduce all the window clutter, and make work cleaner and leaner, but I'm not sure how to start. A lot of videos are only 9-10 minutes long, and I've got an entire holiday weekend to prep for next sprint.\n\nRight now I've installed VSCode but I'm open to other options. Really what I'm looking for is long-format material that talks about how to use an IDE, how to organize projects within an IDE, and how to implement the features I need like Python, Anaconda, and AWS access. \n\nIf you know of any, please send them my way.", "author_fullname": "t2_263lkv5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working in an IDE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ysgte5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668187235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;We could go for multiple paragraphs of backstory, but here&amp;#39;s the TL;DR without all the trouble:&lt;/p&gt;\n\n&lt;p&gt;1) 50% of my next sprint allocation is adhocs, probably because lately I&amp;#39;ve showcased that I can be highly detailed and provide fast turnaround on stakeholder and exec requests&lt;br/&gt;\n2) My current workflow - juggling multiple jupyter kernels, juggling multiple terminal windows for authentication, juggling multiple environments, juggling ugly stuff like Excel - is not working out. I spend time looking for the *right* window or the *right* cell in a jupyter notebook, and it&amp;#39;s frustrating.&lt;br/&gt;\n3) I&amp;#39;m going to switch to an IDE just to reduce all the window clutter, and make work cleaner and leaner, but I&amp;#39;m not sure how to start. A lot of videos are only 9-10 minutes long, and I&amp;#39;ve got an entire holiday weekend to prep for next sprint.&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;ve installed VSCode but I&amp;#39;m open to other options. Really what I&amp;#39;m looking for is long-format material that talks about how to use an IDE, how to organize projects within an IDE, and how to implement the features I need like Python, Anaconda, and AWS access. &lt;/p&gt;\n\n&lt;p&gt;If you know of any, please send them my way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ysgte5", "is_robot_indexable": true, "report_reasons": null, "author": "AresBou", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ysgte5/working_in_an_ide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ysgte5/working_in_an_ide/", "subreddit_subscribers": 818845, "created_utc": 1668187235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nSelf-service analytics: What would you recommend for learning more about self-service analytics? Sorry for a very broad and vague question, it's why I want to learn.\n\nIn general I understand it loosely means providing users with capabilities to perform queries and generate analysis of data on their own but I want to try and learn how to implement it in practice and what it means. The resources can be technical tools as well as books, learning resources on how to implement self-service (the how to bit does not need to be tool specific).", "author_fullname": "t2_6jsoipfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-service analytics: What would you recommend for learning more about self-service analytics? Sorry for a very broad and vague question, it's why I want to learn.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ysgg1t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668186454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Self-service analytics: What would you recommend for learning more about self-service analytics? Sorry for a very broad and vague question, it&amp;#39;s why I want to learn.&lt;/p&gt;\n\n&lt;p&gt;In general I understand it loosely means providing users with capabilities to perform queries and generate analysis of data on their own but I want to try and learn how to implement it in practice and what it means. The resources can be technical tools as well as books, learning resources on how to implement self-service (the how to bit does not need to be tool specific).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ysgg1t", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataGentleman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ysgg1t/selfservice_analytics_what_would_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ysgg1t/selfservice_analytics_what_would_you_recommend/", "subreddit_subscribers": 818845, "created_utc": 1668186454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2ujnok1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your best pro tips for managing the Product Manager?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ys1ss4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668143236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ys1ss4", "is_robot_indexable": true, "report_reasons": null, "author": "is_this_the_place", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ys1ss4/what_are_your_best_pro_tips_for_managing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ys1ss4/what_are_your_best_pro_tips_for_managing_the/", "subreddit_subscribers": 818845, "created_utc": 1668143236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I've been a data scientist for around 2 years now in an industry that's being hit hard by the current economy and will likely get worse over time. Talk around the office makes it pretty clear we should expect layoffs in tech. I'm not near the top of the headsman's list, but it's a possibility.\n\nI've received an offer for a 2-year contract (W2 through a staffing firm) working for a large company with good name recognition. It's a big pay bump even after accounting for the extra cost of buying into benefits, and this company is in an industry that will likely weather a recession very well. The only catch is that they apparently never convert to full time.\n\nHas anyone had experience with this kind of long term contract work in DS? How were you treated? How did it affect your career prospects long term? Were you able to get back into regular direct hire work after?", "author_fullname": "t2_82z4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience with (W2) contract positions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ysh0fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668187653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been a data scientist for around 2 years now in an industry that&amp;#39;s being hit hard by the current economy and will likely get worse over time. Talk around the office makes it pretty clear we should expect layoffs in tech. I&amp;#39;m not near the top of the headsman&amp;#39;s list, but it&amp;#39;s a possibility.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve received an offer for a 2-year contract (W2 through a staffing firm) working for a large company with good name recognition. It&amp;#39;s a big pay bump even after accounting for the extra cost of buying into benefits, and this company is in an industry that will likely weather a recession very well. The only catch is that they apparently never convert to full time.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had experience with this kind of long term contract work in DS? How were you treated? How did it affect your career prospects long term? Were you able to get back into regular direct hire work after?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ysh0fb", "is_robot_indexable": true, "report_reasons": null, "author": "tangentc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ysh0fb/any_experience_with_w2_contract_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ysh0fb/any_experience_with_w2_contract_positions/", "subreddit_subscribers": 818845, "created_utc": 1668187653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_u6mty1xg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi, I'm an aspiring data science, looking forward to gaining some experience by doing real-world data science projects, Can anyone share real-world business projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yrzohh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668136294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yrzohh", "is_robot_indexable": true, "report_reasons": null, "author": "Leading-Blood2744", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yrzohh/hi_im_an_aspiring_data_science_looking_forward_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yrzohh/hi_im_an_aspiring_data_science_looking_forward_to/", "subreddit_subscribers": 818845, "created_utc": 1668136294.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}