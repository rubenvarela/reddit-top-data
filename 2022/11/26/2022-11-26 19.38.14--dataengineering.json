{"kind": "Listing", "data": {"after": null, "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5j6v95ua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaled to 1M cores in EKS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": false, "name": "t3_z52hou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w56Vys1PdW3Y5YENkgDjT5vceoqoNGiN5JcCUrHYftE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669451668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/18sxhhpxsa2a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?auto=webp&amp;s=242eefb8697d6e0c9f67bb8f028d36744567f97f", "width": 1600, "height": 652}, "resolutions": [{"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e1b5521ff5b901ff4e443c10f8b4a7b606688d2d", "width": 108, "height": 44}, {"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a18c60112c72c91f1b3915a161ed5907285ac992", "width": 216, "height": 88}, {"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ccb3936c5b47f1b35fe9fa8bd106a7650f89830", "width": 320, "height": 130}, {"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8103178628f2054943323cab8d38f4e9bbc6c66b", "width": 640, "height": 260}, {"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5df38cda5a59c30fa02525f5cdcf1704e7a03b45", "width": 960, "height": 391}, {"url": "https://preview.redd.it/18sxhhpxsa2a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b367fe11ad54d6c7fa3b832792ccab2bdbbdb72d", "width": 1080, "height": 440}], "variants": {}, "id": "gjkycOOMIRn_i3K9NtxTPTeEzWvZ5aqbXa5HNPKpcOk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z52hou", "is_robot_indexable": true, "report_reasons": null, "author": "buachaill_beorach", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z52hou/scaled_to_1m_cores_in_eks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/18sxhhpxsa2a1.jpg", "subreddit_subscribers": 81010, "created_utc": 1669451668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview next week for an Analytics Engineering position at a SaaS company. The recruiter told me that the technical interview will be about data modeling. They expect SQL and Python skills.\n\nI don't have any work experience data modeling but I have a personal project (Zoomcamp) that did basic modeling and have read Fundamentals of Data Engineering and the first 3 chapters of The Data Warehouse Toolkit along with various youtube videos. I imagine that I would be tested on my knowledge of Dimensional Modeling.\n\nHow should I go about studying for this interview? Some commenters have mentioned modeling a real data set. What is a good data set or site to pull data from for my use case? Where in Leetcode should I go to learn data modeling? Any walkthrough videos going over how to create a dimensional model on a cloud data warehouse?\n\nThanks!", "author_fullname": "t2_ww0mp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to practice Data Modeling for an Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z4o8vj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669410771.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669410486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview next week for an Analytics Engineering position at a SaaS company. The recruiter told me that the technical interview will be about data modeling. They expect SQL and Python skills.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any work experience data modeling but I have a personal project (Zoomcamp) that did basic modeling and have read Fundamentals of Data Engineering and the first 3 chapters of The Data Warehouse Toolkit along with various youtube videos. I imagine that I would be tested on my knowledge of Dimensional Modeling.&lt;/p&gt;\n\n&lt;p&gt;How should I go about studying for this interview? Some commenters have mentioned modeling a real data set. What is a good data set or site to pull data from for my use case? Where in Leetcode should I go to learn data modeling? Any walkthrough videos going over how to create a dimensional model on a cloud data warehouse?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z4o8vj", "is_robot_indexable": true, "report_reasons": null, "author": "SilentSturm", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z4o8vj/how_to_practice_data_modeling_for_an_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z4o8vj/how_to_practice_data_modeling_for_an_interview/", "subreddit_subscribers": 81010, "created_utc": 1669410486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm attempting to build out a completely k8s native data platform for batch and streaming data, just to get better at k8s, and also to get more familiar with a handful of some data engineering tools. Here's a [diagram](https://i.imgur.com/byfSJUb.png) that hopefully shows what I'm trying to build. \n\nBut I'm stuck on where to store all this data (whatever it may be, I don't actually know yet). I'm familiar with BigQuery and Snowflake, but obviously neither of those are open source, but I suppose I'm not opposed to either one. Any suggestions on warehouse, or on the platform in general?", "author_fullname": "t2_iyhsf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building out my own homebrew Data Platform completely (so far) using open source applications.... Need some feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z4ulnz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669426912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m attempting to build out a completely k8s native data platform for batch and streaming data, just to get better at k8s, and also to get more familiar with a handful of some data engineering tools. Here&amp;#39;s a &lt;a href=\"https://i.imgur.com/byfSJUb.png\"&gt;diagram&lt;/a&gt; that hopefully shows what I&amp;#39;m trying to build. &lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m stuck on where to store all this data (whatever it may be, I don&amp;#39;t actually know yet). I&amp;#39;m familiar with BigQuery and Snowflake, but obviously neither of those are open source, but I suppose I&amp;#39;m not opposed to either one. Any suggestions on warehouse, or on the platform in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?auto=webp&amp;s=cfdeabd51e417d3c036fe014f3b5e809f94ab5ee", "width": 1252, "height": 789}, "resolutions": [{"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=822cd2d4b2ac2dc4875f4b3d3c54c56872199f62", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=55073338d5c400933bfc4ca4e69a7d3c1c3b027d", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dbf9aee4daebbe42db00e9562f8d079bed48e8cd", "width": 320, "height": 201}, {"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=eba0c5296fa9d7ef433e62ff0d6e78e34870c54e", "width": 640, "height": 403}, {"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4222c2c6688d97be0bfeb7381346302c6ce0cb84", "width": 960, "height": 604}, {"url": "https://external-preview.redd.it/Rm0U51pW5YUJfO2XW7l6vJ8fyy7J1HzFUavoIfbE7G4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b92bc5a419b48534412958b3d50531c8c12b147c", "width": 1080, "height": 680}], "variants": {}, "id": "LoELzeRC4vGaHc3PN5qjinzY9jfbzOtjhfldr-bfz6c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "z4ulnz", "is_robot_indexable": true, "report_reasons": null, "author": "rokd", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z4ulnz/building_out_my_own_homebrew_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z4ulnz/building_out_my_own_homebrew_data_platform/", "subreddit_subscribers": 81010, "created_utc": 1669426912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If 1,000 records per second are streamed to parquet files in, let's say, S3, how would one approach handling small files and partitioning? Every second, when a write occurs, a small file of 1,000 records is generated, and these small files will accumulate very quickly. Is there some mechanism for periodically combining the small files into one once they add up to a block size, e.g. 128 MB? And then, let's say this data consists of simple user data and the most common queries against it are filtering on last name. What would a partitioning strategy look like, again in light of the small file sizes?", "author_fullname": "t2_1evp2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDFS Streaming - Small Files and Partitioning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z4n1i5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669407400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If 1,000 records per second are streamed to parquet files in, let&amp;#39;s say, S3, how would one approach handling small files and partitioning? Every second, when a write occurs, a small file of 1,000 records is generated, and these small files will accumulate very quickly. Is there some mechanism for periodically combining the small files into one once they add up to a block size, e.g. 128 MB? And then, let&amp;#39;s say this data consists of simple user data and the most common queries against it are filtering on last name. What would a partitioning strategy look like, again in light of the small file sizes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z4n1i5", "is_robot_indexable": true, "report_reasons": null, "author": "LaminatedMisanthropy", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z4n1i5/hdfs_streaming_small_files_and_partitioning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z4n1i5/hdfs_streaming_small_files_and_partitioning/", "subreddit_subscribers": 81010, "created_utc": 1669407400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I was recently joined a new team and was tasked with helping to prototype an architecture design and the setup of airflow onto openshift - but I have certain reservations on the applicability of airflow for our team's use case.\n\nMy team wants to shift from using control-M to schedule our jobs and to use airflow to replace the current process. Most of our jobs and data sources will come from Snowflake tables in the future; And the team will be in-charge of transforming  the data from these tables to views for the user.\n\nHowever, I feel hesitant on pushing towards using airflow as the team does not want to rely on using stored procedures or most forms of SQL queries (save for joins) being used in airflow itself. The plan is to pull data from Snowflake and to process the data within the pythonoperator using pandas/snowpark, and to then finally write the data to a view. But as I understand it, airflow is not meant to be a data processing pipeline and the team doesn't want airflow to get too \"complex\" by integrating spark.\n\nShould we continue to migrate to airflow for our use case? Or are there other potential better solutions? Any help and advice is greatly appreciated!", "author_fullname": "t2_2ma0hvq1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should we shift from Control-M to Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z56ipf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669466081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I was recently joined a new team and was tasked with helping to prototype an architecture design and the setup of airflow onto openshift - but I have certain reservations on the applicability of airflow for our team&amp;#39;s use case.&lt;/p&gt;\n\n&lt;p&gt;My team wants to shift from using control-M to schedule our jobs and to use airflow to replace the current process. Most of our jobs and data sources will come from Snowflake tables in the future; And the team will be in-charge of transforming  the data from these tables to views for the user.&lt;/p&gt;\n\n&lt;p&gt;However, I feel hesitant on pushing towards using airflow as the team does not want to rely on using stored procedures or most forms of SQL queries (save for joins) being used in airflow itself. The plan is to pull data from Snowflake and to process the data within the pythonoperator using pandas/snowpark, and to then finally write the data to a view. But as I understand it, airflow is not meant to be a data processing pipeline and the team doesn&amp;#39;t want airflow to get too &amp;quot;complex&amp;quot; by integrating spark.&lt;/p&gt;\n\n&lt;p&gt;Should we continue to migrate to airflow for our use case? Or are there other potential better solutions? Any help and advice is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z56ipf", "is_robot_indexable": true, "report_reasons": null, "author": "pseudoduespp", "discussion_type": null, "num_comments": 9, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z56ipf/should_we_shift_from_controlm_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z56ipf/should_we_shift_from_controlm_to_airflow/", "subreddit_subscribers": 81010, "created_utc": 1669466081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to understand how pros think before deciding to use them (in a scenario you know for sure your application will need to be multi cloud)\n\nSuppose you're building a platform which needs ETL building in AWS for customer 1 and Azure for customer 2\n\nYou build ETL for 1 first and you end up using dynamic frame/bookmark etc glue specific features, now you get to 2 and see those vendor specific features aren't available\n\nshould 1 have used spark native features only? to save time resolving same mini problems across cloud vendors? even if the dynamic frame etc was best decision for that cloud?", "author_fullname": "t2_piwlmz4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To use vendor specific features or not? Dynamic frames for Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z542cd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669457385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to understand how pros think before deciding to use them (in a scenario you know for sure your application will need to be multi cloud)&lt;/p&gt;\n\n&lt;p&gt;Suppose you&amp;#39;re building a platform which needs ETL building in AWS for customer 1 and Azure for customer 2&lt;/p&gt;\n\n&lt;p&gt;You build ETL for 1 first and you end up using dynamic frame/bookmark etc glue specific features, now you get to 2 and see those vendor specific features aren&amp;#39;t available&lt;/p&gt;\n\n&lt;p&gt;should 1 have used spark native features only? to save time resolving same mini problems across cloud vendors? even if the dynamic frame etc was best decision for that cloud?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z542cd", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Story2003", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z542cd/to_use_vendor_specific_features_or_not_dynamic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z542cd/to_use_vendor_specific_features_or_not_dynamic/", "subreddit_subscribers": 81010, "created_utc": 1669457385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_invkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing Spark DataFrame to HBase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z57p70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669469662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ayoublabiad.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ayoublabiad.me/posts/spark-to-hbase/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z57p70", "is_robot_indexable": true, "report_reasons": null, "author": "T3Z0", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z57p70/writing_spark_dataframe_to_hbase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ayoublabiad.me/posts/spark-to-hbase/", "subreddit_subscribers": 81010, "created_utc": 1669469662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Goal: migrate a snowflake table (150 million records) to postgres (it is on prem postgres database)\n\n\nCurrent limitations/stack we are using:\n\n- Docker/ecs container (10gb container space)\n- managed aws airflow\n- python\n\nWhat I currently have in mind:\n\n- Export Snowflake table to csv\n- read csv as dataframe (csv export is required for archiving purposes)\n- insert dataframe into Postgres using some Python library ?", "author_fullname": "t2_k95rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best approach to migrate Snowflake table to Postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5agab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669477391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Goal: migrate a snowflake table (150 million records) to postgres (it is on prem postgres database)&lt;/p&gt;\n\n&lt;p&gt;Current limitations/stack we are using:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Docker/ecs container (10gb container space)&lt;/li&gt;\n&lt;li&gt;managed aws airflow&lt;/li&gt;\n&lt;li&gt;python&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I currently have in mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Export Snowflake table to csv&lt;/li&gt;\n&lt;li&gt;read csv as dataframe (csv export is required for archiving purposes)&lt;/li&gt;\n&lt;li&gt;insert dataframe into Postgres using some Python library ?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z5agab", "is_robot_indexable": true, "report_reasons": null, "author": "jaspar1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5agab/best_approach_to_migrate_snowflake_table_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5agab/best_approach_to_migrate_snowflake_table_to/", "subreddit_subscribers": 81010, "created_utc": 1669477391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have just been offered a TDP position as a data engineer, but when I applied it was as a data engineer/data scientist. My undergraduate degree is in Data Science. I was wondering if there was a significant difference between the 2, and what should I be expecting so that I can prepare for the role better.", "author_fullname": "t2_cauyq044", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Grad Job Question Regarding Title", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z54dss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669458555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just been offered a TDP position as a data engineer, but when I applied it was as a data engineer/data scientist. My undergraduate degree is in Data Science. I was wondering if there was a significant difference between the 2, and what should I be expecting so that I can prepare for the role better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z54dss", "is_robot_indexable": true, "report_reasons": null, "author": "honey1337", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z54dss/new_grad_job_question_regarding_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z54dss/new_grad_job_question_regarding_title/", "subreddit_subscribers": 81010, "created_utc": 1669458555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody else been turned down for a job on financial probity reasons? Had an offer for a Quant job at a hedge fund, but because I got hit by the covid financial crisis I fell behind on bills. Now I am being turned down for roles. Anybody else seeing this?", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z5brqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669480828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody else been turned down for a job on financial probity reasons? Had an offer for a Quant job at a hedge fund, but because I got hit by the covid financial crisis I fell behind on bills. Now I am being turned down for roles. Anybody else seeing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z5brqk", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z5brqk/curious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z5brqk/curious/", "subreddit_subscribers": 81010, "created_utc": 1669480828.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}