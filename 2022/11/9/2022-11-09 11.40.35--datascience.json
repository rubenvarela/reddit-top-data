{"kind": "Listing", "data": {"after": "t3_ypzgf2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "People are obsessed with pursuing data science roles for some reason. I guess it's interesting work with a high skill ceiling. Thats why I'm pursuing it. But nobody talks about the data analyst. The folks who write SQL for reporting, create dashboards, and provide insights. Data science does do all this in a more sophisticated way, but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth. If you're struggling to get into data science, consider analytics. The pay is still good (100k plus if you're doing product analytics) and a natural growth path from there can totally be data science. Don't rule it out, you have options. End \ud83d\ude0a", "author_fullname": "t2_8o0eldke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "hot take: forget data science, we need more analysts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypr93q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 835, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 835, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667924978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People are obsessed with pursuing data science roles for some reason. I guess it&amp;#39;s interesting work with a high skill ceiling. Thats why I&amp;#39;m pursuing it. But nobody talks about the data analyst. The folks who write SQL for reporting, create dashboards, and provide insights. Data science does do all this in a more sophisticated way, but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth. If you&amp;#39;re struggling to get into data science, consider analytics. The pay is still good (100k plus if you&amp;#39;re doing product analytics) and a natural growth path from there can totally be data science. Don&amp;#39;t rule it out, you have options. End \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 200, "id": "award_1703f934-cf44-40cc-a96d-3729d0b48262", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "My kindergarten teacher, my cat, my mom, and you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "I'd Like to Thank...", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypr93q", "is_robot_indexable": true, "report_reasons": null, "author": "djaycat", "discussion_type": null, "num_comments": 154, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypr93q/hot_take_forget_data_science_we_need_more_analysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypr93q/hot_take_forget_data_science_we_need_more_analysts/", "subreddit_subscribers": 818351, "created_utc": 1667924978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are there any people out there worth watching on youtube that make interesting DS projects? Preferably in a long video format.\n\nI tried to watch a few, but they all were painfully bad. Like starting feature engineering before checking data types and bumping head against the wall every time python  returns a types error, or saving cvs and starting excel to see unique values in columns manually instead of using .value\\_counts method etc.\n\nI am a data analyst sql power bi monkey and in no way a very advanced Python user, just know some and have a bit of practical experience. My knowledge isn\u2019t enough to be good myself, but enough to see a moron pretending being competent.\n\n I don\u2019t really want to watch some exoteric ML mamba jambo, just a competent person doing basic stuff really well, learn something and have fun. \n\nAre there people you can recommend?", "author_fullname": "t2_p9z8x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any COMPETENT youtubers making DS \u201clet\u2019s plays\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq6gkj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667962043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any people out there worth watching on youtube that make interesting DS projects? Preferably in a long video format.&lt;/p&gt;\n\n&lt;p&gt;I tried to watch a few, but they all were painfully bad. Like starting feature engineering before checking data types and bumping head against the wall every time python  returns a types error, or saving cvs and starting excel to see unique values in columns manually instead of using .value_counts method etc.&lt;/p&gt;\n\n&lt;p&gt;I am a data analyst sql power bi monkey and in no way a very advanced Python user, just know some and have a bit of practical experience. My knowledge isn\u2019t enough to be good myself, but enough to see a moron pretending being competent.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t really want to watch some exoteric ML mamba jambo, just a competent person doing basic stuff really well, learn something and have fun. &lt;/p&gt;\n\n&lt;p&gt;Are there people you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq6gkj", "is_robot_indexable": true, "report_reasons": null, "author": "Cpt_keaSar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq6gkj/are_there_any_competent_youtubers_making_ds_lets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq6gkj/are_there_any_competent_youtubers_making_ds_lets/", "subreddit_subscribers": 818351, "created_utc": 1667962043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Engineers for Ukraine** is an international team of volunteers working on a machine learning tool to identify Russian equipment in real time (with minimal human involvement) to increase the speed at which accurate information about Russian soldiers/equipment in the area passes from local civilians on the ground to the Ukrainian warfighter. \n\nEngineers for Ukraine has four teams: \n\n1. The Data Team, which builds the training datasets for the machine learning models. This is the easiest team to join since the tasks are straightforward and the training is short/easy thanks to the help of our beloved data scientists. \n2. The Machine Learning Team, which builds and trains machine learning models. This team needs a bit more experience and/or time to get through readings to get up to speed. If you are familiar with AWS, AWS SageMaker, AWS S3, AWS Rekognition, AWS Comprehend, Lambda, machine learning attacks, machine learning security, dedicated red team work, and/or data science, please join the machine learning team.\n3. The Development Team, which handles much of the project infrastructure and builds the relevant web pages, services, and user interfaces.  If you are familiar with AWS, Lambda, JavaScript, React.js, Node.js, API's, plug-ins, and/or devops/SRE/cloud engineering, please join the dev team.\n4. The Cybersecurity Team, which works heavily with the Development Team searching for and fixing vulnerabilities, but also creates threat models, does red team vs blue team work, penetration testing, and occasionally OSINT work. If you are interested in learning cool cybersecurity skills from a team of professionals who are just super busy and need more hands on deck to knock out tasks OR if you are also skilled in cybersecurity, please join the cybersecurity team.\n\nI\u2019ve talked about Engineers for Ukraine before in this Reddit post: [https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers\\_needed\\_for\\_proukraine\\_project/](https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers_needed_for_proukraine_project/)\n\nIf you are interested in either of these groups, please reach out to breaker25789@gmail.com with the project (AidSupply or Engineers for Ukraine) and team you are interested in.\n\nWe will reach out and schedule a video call in which you can verify that we aren\u2019t Russian bots and we can verify that you are not a Russian bot by both showing a government-issued photo ID and two social media accounts. As part of the recruitment process, each volunteer may be asked to complete an introductory assignment specific to the project/team they are applying to. This isn\u2019t meant as a barrier, just as a way to get people onboarded faster while giving the project leadership a sense of each volunteer\u2019s skill level.", "author_fullname": "t2_1323h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Volunteers Needed for Pro-Ukraine Machine Learning Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yptkvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667930260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Engineers for Ukraine&lt;/strong&gt; is an international team of volunteers working on a machine learning tool to identify Russian equipment in real time (with minimal human involvement) to increase the speed at which accurate information about Russian soldiers/equipment in the area passes from local civilians on the ground to the Ukrainian warfighter. &lt;/p&gt;\n\n&lt;p&gt;Engineers for Ukraine has four teams: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The Data Team, which builds the training datasets for the machine learning models. This is the easiest team to join since the tasks are straightforward and the training is short/easy thanks to the help of our beloved data scientists. &lt;/li&gt;\n&lt;li&gt;The Machine Learning Team, which builds and trains machine learning models. This team needs a bit more experience and/or time to get through readings to get up to speed. If you are familiar with AWS, AWS SageMaker, AWS S3, AWS Rekognition, AWS Comprehend, Lambda, machine learning attacks, machine learning security, dedicated red team work, and/or data science, please join the machine learning team.&lt;/li&gt;\n&lt;li&gt;The Development Team, which handles much of the project infrastructure and builds the relevant web pages, services, and user interfaces.  If you are familiar with AWS, Lambda, JavaScript, React.js, Node.js, API&amp;#39;s, plug-ins, and/or devops/SRE/cloud engineering, please join the dev team.&lt;/li&gt;\n&lt;li&gt;The Cybersecurity Team, which works heavily with the Development Team searching for and fixing vulnerabilities, but also creates threat models, does red team vs blue team work, penetration testing, and occasionally OSINT work. If you are interested in learning cool cybersecurity skills from a team of professionals who are just super busy and need more hands on deck to knock out tasks OR if you are also skilled in cybersecurity, please join the cybersecurity team.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I\u2019ve talked about Engineers for Ukraine before in this Reddit post: &lt;a href=\"https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers_needed_for_proukraine_project/\"&gt;https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers_needed_for_proukraine_project/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested in either of these groups, please reach out to &lt;a href=\"mailto:breaker25789@gmail.com\"&gt;breaker25789@gmail.com&lt;/a&gt; with the project (AidSupply or Engineers for Ukraine) and team you are interested in.&lt;/p&gt;\n\n&lt;p&gt;We will reach out and schedule a video call in which you can verify that we aren\u2019t Russian bots and we can verify that you are not a Russian bot by both showing a government-issued photo ID and two social media accounts. As part of the recruitment process, each volunteer may be asked to complete an introductory assignment specific to the project/team they are applying to. This isn\u2019t meant as a barrier, just as a way to get people onboarded faster while giving the project leadership a sense of each volunteer\u2019s skill level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yptkvg", "is_robot_indexable": true, "report_reasons": null, "author": "OttersAreDevilSpawn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yptkvg/volunteers_needed_for_proukraine_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yptkvg/volunteers_needed_for_proukraine_machine_learning/", "subreddit_subscribers": 818351, "created_utc": 1667930260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " In my work as a datascientist I use a lot of blackbox algoritms such as gradient boosting, random forrest and neural networks. One question I ALWAYS get from the business I'm making the models for is, what features are important? How does the model make descicions. So to answer that I do the usual feature analysis, correlation matrices, partial dependence plots, mdi, model extraction. But I still fill like I'm not entirely able to answer what variables are the most important for example.\n\nNow I was thinking of a new method to determine feature importance. First we need the trained model, and the feature distributions. If we take a feature, we look at the sorted values and take 11 values corresponding to 0% - 10% - .. - 100% of the feature distribution. Next we take for example 1000 random states of the other features and test per random state the 11 options for the selected feature. For this 11 values of the feature, we check the number of times the y-value (label) changes. After doing this for all features, we should have an order of feature importance, as a higer rate of changes indicates more influence on the labels outcome. Would als be applicable for discrete variables and continuous labels with some minor adjustments.\n\nI love to hear your experiences in this regard and what you think of the proposed method?", "author_fullname": "t2_k8jayuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demystify the blackbox, what do you think of my idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypn2rg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my work as a datascientist I use a lot of blackbox algoritms such as gradient boosting, random forrest and neural networks. One question I ALWAYS get from the business I&amp;#39;m making the models for is, what features are important? How does the model make descicions. So to answer that I do the usual feature analysis, correlation matrices, partial dependence plots, mdi, model extraction. But I still fill like I&amp;#39;m not entirely able to answer what variables are the most important for example.&lt;/p&gt;\n\n&lt;p&gt;Now I was thinking of a new method to determine feature importance. First we need the trained model, and the feature distributions. If we take a feature, we look at the sorted values and take 11 values corresponding to 0% - 10% - .. - 100% of the feature distribution. Next we take for example 1000 random states of the other features and test per random state the 11 options for the selected feature. For this 11 values of the feature, we check the number of times the y-value (label) changes. After doing this for all features, we should have an order of feature importance, as a higer rate of changes indicates more influence on the labels outcome. Would als be applicable for discrete variables and continuous labels with some minor adjustments.&lt;/p&gt;\n\n&lt;p&gt;I love to hear your experiences in this regard and what you think of the proposed method?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypn2rg", "is_robot_indexable": true, "report_reasons": null, "author": "localhoststream", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypn2rg/demystify_the_blackbox_what_do_you_think_of_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypn2rg/demystify_the_blackbox_what_do_you_think_of_my/", "subreddit_subscribers": 818351, "created_utc": 1667916038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just wanted to give a heads up that we\u2019ve got an upcoming course on Time Series &amp; Forecasting. The goal is to help you solve complex business problems by making more accurate predictions with modern forecasting techniques.\n\n\u00a0This course will be led by two industry leaders: Jan Gasthaus (AWS) and Tim Januschowski (ex-AWS, Zalando).\n\nIn the past, Tim and his team built multiple AI services for AWS such as SageMaker, Forecast, Lookout for Metrics, and DevOps Guru. Jan was part of the teams pushing these projects forward, and also co-created the open-source deep learning forecasting library Gluon TS.\n\nPlus, like all of our courses, Time Series &amp; Forecasting qualifies for coverage from your org\u2019s L&amp;D budget or personal learning stipend.\n\nCome join Tim and Jan live for 5-days of hands-on training. You can learn more about the course by clicking here: https://www.getsphere.com/cohorts/modern-forecasting-in-practice?source=Sphere-Communities-r-datascience", "author_fullname": "t2_2rh4tgqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Forecasting in Practice with Jan Gasthaus (AWS) and Tim Januschowski (Zalando)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3pdr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667954342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to give a heads up that we\u2019ve got an upcoming course on Time Series &amp;amp; Forecasting. The goal is to help you solve complex business problems by making more accurate predictions with modern forecasting techniques.&lt;/p&gt;\n\n&lt;p&gt;\u00a0This course will be led by two industry leaders: Jan Gasthaus (AWS) and Tim Januschowski (ex-AWS, Zalando).&lt;/p&gt;\n\n&lt;p&gt;In the past, Tim and his team built multiple AI services for AWS such as SageMaker, Forecast, Lookout for Metrics, and DevOps Guru. Jan was part of the teams pushing these projects forward, and also co-created the open-source deep learning forecasting library Gluon TS.&lt;/p&gt;\n\n&lt;p&gt;Plus, like all of our courses, Time Series &amp;amp; Forecasting qualifies for coverage from your org\u2019s L&amp;amp;D budget or personal learning stipend.&lt;/p&gt;\n\n&lt;p&gt;Come join Tim and Jan live for 5-days of hands-on training. You can learn more about the course by clicking here: &lt;a href=\"https://www.getsphere.com/cohorts/modern-forecasting-in-practice?source=Sphere-Communities-r-datascience\"&gt;https://www.getsphere.com/cohorts/modern-forecasting-in-practice?source=Sphere-Communities-r-datascience&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?auto=webp&amp;s=8b3e2fe08160bb2a53124e33340455fa98bc44fb", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63d45c89326e562fdb6f6094604071f95abe2dfa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e26e45f843a9033b53c53417d6cf10904605bdc", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d173d8e175559385460c0e1dc662f5da9b1ffa4f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03036dde2114ae1d143fcdd2249acc72b08bb4ef", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=01bc00472d2b14068c296bea5f83844805160e24", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2895a71d6477497431d3b1a729d21d7135547db8", "width": 1080, "height": 607}], "variants": {}, "id": "7NPxWGevlxuxdKhK4Hz8wx0_DLrtCK7AYwROIjbI3Kg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq3pdr", "is_robot_indexable": true, "report_reasons": null, "author": "lorenzo_1999", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq3pdr/modern_forecasting_in_practice_with_jan_gasthaus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq3pdr/modern_forecasting_in_practice_with_jan_gasthaus/", "subreddit_subscribers": 818351, "created_utc": 1667954342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently in graduate school in the US, and I am considering starting my career in data science in Canada. \n\nAs the title says, how is the data science scene in Canada?\n\n Are there more or less need for positions compared to the US?\n\n And how well does work experience in Canada carry over to the US?\n\n&amp;#x200B;\n\nThank you very much for any thoughts and insights!", "author_fullname": "t2_saxqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is the data science scene in Canada", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq6lp6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667962455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently in graduate school in the US, and I am considering starting my career in data science in Canada. &lt;/p&gt;\n\n&lt;p&gt;As the title says, how is the data science scene in Canada?&lt;/p&gt;\n\n&lt;p&gt;Are there more or less need for positions compared to the US?&lt;/p&gt;\n\n&lt;p&gt;And how well does work experience in Canada carry over to the US?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for any thoughts and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yq6lp6", "is_robot_indexable": true, "report_reasons": null, "author": "andrewYao", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq6lp6/how_is_the_data_science_scene_in_canada/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq6lp6/how_is_the_data_science_scene_in_canada/", "subreddit_subscribers": 818351, "created_utc": 1667962455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A couple of days ago I started thinking if I had to start learning #machinelearning and #datascience all over again where would I start?\n\nThe funny thing was that the learning path that I imagined was completely different from that one that I actually did when I was starting.\n\nSo, talking from my own perspective and knowing how I learn better, If I was to redesign my learning path, \ud835\udc30\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc2c\ud835\udc24\ud835\udc22\ud835\udc25\ud835\udc25\ud835\udc2c \ud835\udc30\ud835\udc28\ud835\udc2e\ud835\udc25\ud835\udc1d \ud835\udc08 \ud835\udc1f\ud835\udc28\ud835\udc1c\ud835\udc2e\ud835\udc2c \ud835\udc28\ud835\udc27?\n\n1. Learn how to gather, pipe, transform, handle and monitor data\n2. Learn how to visualize and clearly communicate the story of that data\n3. Gain familiarity with relational and non-relational databases. Ability to develop proper storage and indexing schemas for a given task.\n4. Learn mathematics for machine learning (Probability, Statistics, Calculus, and Linear Algebra)\n5. Learn programming, become efficient in that language, and adopt good software engineering practices\n6. Learn SQL, data modeling and evaluation skills\n7. Learn ethics in data science and machine learning\n8. Gain understanding of data quality, compliance and governance.\n9. Learn project management and how to deliver projects on time and on budget.\n10. Gain business acumen in a chosen domain area\n11. Learn machine learning fundamentals. (Machine Learning algorithms and methods)\n12. Improve the breadth of my knowledge of putting things into production. From Jupyter Notebooks to Production.\n13. Learn Git, Github and version control for data science\n14. Gain knowledge of web standards, REST APIs, ability to call an API, and web dashboards.\n15. Learn how to read, reproduce and implement deep learning literature, and case studies.\n16. Basic knowledge of the Unix command line. In my experience this was helpful when writing Spark jobs to create datasets for analytics/reporting purposes.\n17. Expose myself to the powers of parallel and distributed computing like Apache Spark\n\nThere are multiple ways to learn the \u2018right\u2019 data science skills. If you had to start learning data science again, how would you redesign your path?", "author_fullname": "t2_3m1kf60u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud835\udc08\ud835\udc1f \ud835\udc08 \ud835\udc21\ud835\udc1a\ud835\udc1d \ud835\udc2d\ud835\udc28 \ud835\udc2c\ud835\udc2d\ud835\udc1a\ud835\udc2b\ud835\udc2d \ud835\udc25\ud835\udc1e\ud835\udc1a\ud835\udc2b\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc12\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc1e \ud835\udc1a\ud835\udc20\ud835\udc1a\ud835\udc22\ud835\udc27, \ud835\udc21\ud835\udc28\ud835\udc30 \ud835\udc30\ud835\udc28\ud835\udc2e\ud835\udc25\ud835\udc1d \ud835\udc08 \ud835\udc1d\ud835\udc28 \ud835\udc22\ud835\udc2d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqcv2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667983067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A couple of days ago I started thinking if I had to start learning #machinelearning and #datascience all over again where would I start?&lt;/p&gt;\n\n&lt;p&gt;The funny thing was that the learning path that I imagined was completely different from that one that I actually did when I was starting.&lt;/p&gt;\n\n&lt;p&gt;So, talking from my own perspective and knowing how I learn better, If I was to redesign my learning path, \ud835\udc30\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc2c\ud835\udc24\ud835\udc22\ud835\udc25\ud835\udc25\ud835\udc2c \ud835\udc30\ud835\udc28\ud835\udc2e\ud835\udc25\ud835\udc1d \ud835\udc08 \ud835\udc1f\ud835\udc28\ud835\udc1c\ud835\udc2e\ud835\udc2c \ud835\udc28\ud835\udc27?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Learn how to gather, pipe, transform, handle and monitor data&lt;/li&gt;\n&lt;li&gt;Learn how to visualize and clearly communicate the story of that data&lt;/li&gt;\n&lt;li&gt;Gain familiarity with relational and non-relational databases. Ability to develop proper storage and indexing schemas for a given task.&lt;/li&gt;\n&lt;li&gt;Learn mathematics for machine learning (Probability, Statistics, Calculus, and Linear Algebra)&lt;/li&gt;\n&lt;li&gt;Learn programming, become efficient in that language, and adopt good software engineering practices&lt;/li&gt;\n&lt;li&gt;Learn SQL, data modeling and evaluation skills&lt;/li&gt;\n&lt;li&gt;Learn ethics in data science and machine learning&lt;/li&gt;\n&lt;li&gt;Gain understanding of data quality, compliance and governance.&lt;/li&gt;\n&lt;li&gt;Learn project management and how to deliver projects on time and on budget.&lt;/li&gt;\n&lt;li&gt;Gain business acumen in a chosen domain area&lt;/li&gt;\n&lt;li&gt;Learn machine learning fundamentals. (Machine Learning algorithms and methods)&lt;/li&gt;\n&lt;li&gt;Improve the breadth of my knowledge of putting things into production. From Jupyter Notebooks to Production.&lt;/li&gt;\n&lt;li&gt;Learn Git, Github and version control for data science&lt;/li&gt;\n&lt;li&gt;Gain knowledge of web standards, REST APIs, ability to call an API, and web dashboards.&lt;/li&gt;\n&lt;li&gt;Learn how to read, reproduce and implement deep learning literature, and case studies.&lt;/li&gt;\n&lt;li&gt;Basic knowledge of the Unix command line. In my experience this was helpful when writing Spark jobs to create datasets for analytics/reporting purposes.&lt;/li&gt;\n&lt;li&gt;Expose myself to the powers of parallel and distributed computing like Apache Spark&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There are multiple ways to learn the \u2018right\u2019 data science skills. If you had to start learning data science again, how would you redesign your path?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yqcv2a", "is_robot_indexable": true, "report_reasons": null, "author": "KennedyKWangari", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yqcv2a/\ud835\udc08\ud835\udc1f_\ud835\udc08_\ud835\udc21\ud835\udc1a\ud835\udc1d_\ud835\udc2d\ud835\udc28_\ud835\udc2c\ud835\udc2d\ud835\udc1a\ud835\udc2b\ud835\udc2d_\ud835\udc25\ud835\udc1e\ud835\udc1a\ud835\udc2b\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20_\ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a_\ud835\udc12\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc1e_\ud835\udc1a\ud835\udc20\ud835\udc1a\ud835\udc22\ud835\udc27_\ud835\udc21\ud835\udc28\ud835\udc30/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yqcv2a/\ud835\udc08\ud835\udc1f_\ud835\udc08_\ud835\udc21\ud835\udc1a\ud835\udc1d_\ud835\udc2d\ud835\udc28_\ud835\udc2c\ud835\udc2d\ud835\udc1a\ud835\udc2b\ud835\udc2d_\ud835\udc25\ud835\udc1e\ud835\udc1a\ud835\udc2b\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20_\ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a_\ud835\udc12\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc1e_\ud835\udc1a\ud835\udc20\ud835\udc1a\ud835\udc22\ud835\udc27_\ud835\udc21\ud835\udc28\ud835\udc30/", "subreddit_subscribers": 818351, "created_utc": 1667983067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello All, \n\nI am a host of a podcast that helps students and young professionals with all things personal and career development. \n\nI got a question about how to stand out for a data science internship. I know having a portfolio or github would help, but want to validate with the community.  \n\nThis is one of my favorite subreddits bc of the smart and realistic community ! \n\nAny other ways you would recommend to standout while on the job hunt (getting a job in data science)?", "author_fullname": "t2_29rf2ck4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on standing out during interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq4ns7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667956963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All, &lt;/p&gt;\n\n&lt;p&gt;I am a host of a podcast that helps students and young professionals with all things personal and career development. &lt;/p&gt;\n\n&lt;p&gt;I got a question about how to stand out for a data science internship. I know having a portfolio or github would help, but want to validate with the community.  &lt;/p&gt;\n\n&lt;p&gt;This is one of my favorite subreddits bc of the smart and realistic community ! &lt;/p&gt;\n\n&lt;p&gt;Any other ways you would recommend to standout while on the job hunt (getting a job in data science)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yq4ns7", "is_robot_indexable": true, "report_reasons": null, "author": "azatar19", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq4ns7/advice_on_standing_out_during_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq4ns7/advice_on_standing_out_during_interviews/", "subreddit_subscribers": 818351, "created_utc": 1667956963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just reading the news and saw these impressive interactive visualizations at the [Guardian](https://www.theguardian.com/us-news/ng-interactive/2022/nov/08/midterm-election-results-live-2022-map-us-midterms-latest-winners-seats-congress?CMP=Share_iOSApp_Other).\n\nJust wondering if anyone knows what programming language or software platform are used to build them?", "author_fullname": "t2_3j8mlt6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interactive Visualizations - How?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq299y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667950526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just reading the news and saw these impressive interactive visualizations at the &lt;a href=\"https://www.theguardian.com/us-news/ng-interactive/2022/nov/08/midterm-election-results-live-2022-map-us-midterms-latest-winners-seats-congress?CMP=Share_iOSApp_Other\"&gt;Guardian&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Just wondering if anyone knows what programming language or software platform are used to build them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq299y", "is_robot_indexable": true, "report_reasons": null, "author": "iamappleapple1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq299y/interactive_visualizations_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq299y/interactive_visualizations_how/", "subreddit_subscribers": 818351, "created_utc": 1667950526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a question regarding Textmining, I want to get information out of a semi-structured text like the highlighted price or the size of the property. The data is currently in a txt.file but I could also safe it somewhere else. What is the best way to get this information into a structured format? Thank you for your help! \n\nhttps://preview.redd.it/0pyrw00iupy91.png?width=747&amp;format=png&amp;auto=webp&amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116", "author_fullname": "t2_tyjml9b0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question Textscraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0pyrw00iupy91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=68153e297febf102f4ce35060ddfcc3cbf07f145"}, {"y": 233, "x": 216, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b031ddda885c56674026b02333ad7b06226ae3e"}, {"y": 345, "x": 320, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7355378c733c11254324605b7130ac17c264dc59"}, {"y": 691, "x": 640, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ffe6b08d69dabcd4d3cfd0e52ab6d0ad23dd1f84"}], "s": {"y": 807, "x": 747, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=747&amp;format=png&amp;auto=webp&amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116"}, "id": "0pyrw00iupy91"}}, "name": "t3_ypjwln", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KhYlSufCJURrtUn8CDQUesWnhSSXOr4U-NzYoziDysY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667908454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question regarding Textmining, I want to get information out of a semi-structured text like the highlighted price or the size of the property. The data is currently in a txt.file but I could also safe it somewhere else. What is the best way to get this information into a structured format? Thank you for your help! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0pyrw00iupy91.png?width=747&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116\"&gt;https://preview.redd.it/0pyrw00iupy91.png?width=747&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypjwln", "is_robot_indexable": true, "report_reasons": null, "author": "Ferry_Carondelet", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypjwln/question_textscraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypjwln/question_textscraping/", "subreddit_subscribers": 818351, "created_utc": 1667908454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been looking for some advice or general best practices when it comes to wrangling survey response data that consists mostly of \"click all that apply\" responses and then free text responses (for reference the survey was distributed through Survey Monkey). The data is structured in a wide format, wherein the possible responses for questions are distributed in the columns of the data. For example a question on race would have each of possible values for race as a column variable: \n\n    white &lt;- c(white, NA, NA, white) \n    black &lt;- c(NA, black, NA, black) \n    asian &lt;- c(asian, NA, asian, NA)\n    unique_id &lt;- x(1,2,3)\n    df &lt;- tibble(white, black, asian, unique_id) \n\nEach respondent's responses are captured in a single row and every respondent has a unique ID, so respondent 1 would have checked the boxes for White and Asian. My question is in regards to how best to go about formatting the data for analysis. Given that there are multiple of these \"check all that apply\" or dummy variable columns, is it best to leave this data in a wide format? Or is it better to gather all of these columns into a single variable and pivot the data longer? My only concern is that there are about 20 questions like this, so pivoting each of these variables would create a really long data frame. Additionally, I need to have the data formatted in a way that would require little to no preprocessing in Tableau. This is primarily due to work policies on formatting research publications and data visuals (I know it's not ideal but I can't change it). \n\nI have it currently set up in two way: the first is with each question separated out in different excel sheets that can be joined by their unique ID. The second is with all the questions combined into a single data frame. Both are formatted wide. Thanks in advance for any help or advice, I can also provide additional anonymous data if that would help you help me better :)", "author_fullname": "t2_9337qo7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cleaning Survey Response Data for Analysis in R | Best Practices or Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypveb6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking for some advice or general best practices when it comes to wrangling survey response data that consists mostly of &amp;quot;click all that apply&amp;quot; responses and then free text responses (for reference the survey was distributed through Survey Monkey). The data is structured in a wide format, wherein the possible responses for questions are distributed in the columns of the data. For example a question on race would have each of possible values for race as a column variable: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;white &amp;lt;- c(white, NA, NA, white) \nblack &amp;lt;- c(NA, black, NA, black) \nasian &amp;lt;- c(asian, NA, asian, NA)\nunique_id &amp;lt;- x(1,2,3)\ndf &amp;lt;- tibble(white, black, asian, unique_id) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Each respondent&amp;#39;s responses are captured in a single row and every respondent has a unique ID, so respondent 1 would have checked the boxes for White and Asian. My question is in regards to how best to go about formatting the data for analysis. Given that there are multiple of these &amp;quot;check all that apply&amp;quot; or dummy variable columns, is it best to leave this data in a wide format? Or is it better to gather all of these columns into a single variable and pivot the data longer? My only concern is that there are about 20 questions like this, so pivoting each of these variables would create a really long data frame. Additionally, I need to have the data formatted in a way that would require little to no preprocessing in Tableau. This is primarily due to work policies on formatting research publications and data visuals (I know it&amp;#39;s not ideal but I can&amp;#39;t change it). &lt;/p&gt;\n\n&lt;p&gt;I have it currently set up in two way: the first is with each question separated out in different excel sheets that can be joined by their unique ID. The second is with all the questions combined into a single data frame. Both are formatted wide. Thanks in advance for any help or advice, I can also provide additional anonymous data if that would help you help me better :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypveb6", "is_robot_indexable": true, "report_reasons": null, "author": "Legal_Television_944", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypveb6/cleaning_survey_response_data_for_analysis_in_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypveb6/cleaning_survey_response_data_for_analysis_in_r/", "subreddit_subscribers": 818351, "created_utc": 1667934361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm just a very beginnner, I don't know much about Data Science.   \nI was wondering if I should get desktop to get more VRam or is 6GB just fine?", "author_fullname": "t2_700mjkri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I get desktop with RTX 3060 (12GB) or Laptop with RTX 3060 (6GB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqdep4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667985123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just a very beginnner, I don&amp;#39;t know much about Data Science.&lt;br/&gt;\nI was wondering if I should get desktop to get more VRam or is 6GB just fine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yqdep4", "is_robot_indexable": true, "report_reasons": null, "author": "No_Bat9898", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yqdep4/should_i_get_desktop_with_rtx_3060_12gb_or_laptop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yqdep4/should_i_get_desktop_with_rtx_3060_12gb_or_laptop/", "subreddit_subscribers": 818351, "created_utc": 1667985123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\u2705 Leverage your experience, skills, and flexibility to understand where the needs of the client are before they articulate them.\n\nThis is developed more and more over time, but keeping this in mind can help you become an effective advisor from day 1.\n\n\u2705Having mastery over technology concepts helps a hell of a lot but it's only half the battle.\n\nThe other half is knowing how to explain them to business people and then relating that concept to a business problem they are having.\n\n\u2705 Consulting is built on trust, and trust is developed in a number of different ways.\n\nBecoming a trusted advisor to a client is a key step, that means walking them through the good and bad, and making sure honesty is present in the relationship.\n\nHaving your team become known for providing this, as well as an open and thoughtful approach helps future clients consider what you are offering.\n\n\u2705 Regular feedback and communication is critical\n\nThere is this saying in consulting, \u201cas long as you're 5 minutes ahead of the client\u201d which I find to be an interesting thing.\n\n\u2705 Developing an agile and project management mindset greatly helps to ensure that your projects stay on target and ultimately address the problem statement.\n\nThere are new challenges, learning challenges, thinking challenges, planning challenges.  There is success, there is failure but at the end of the day, it\u2019s fun.", "author_fullname": "t2_3m1kf60u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What consulting taught me about data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqcuj4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667983009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\u2705 Leverage your experience, skills, and flexibility to understand where the needs of the client are before they articulate them.&lt;/p&gt;\n\n&lt;p&gt;This is developed more and more over time, but keeping this in mind can help you become an effective advisor from day 1.&lt;/p&gt;\n\n&lt;p&gt;\u2705Having mastery over technology concepts helps a hell of a lot but it&amp;#39;s only half the battle.&lt;/p&gt;\n\n&lt;p&gt;The other half is knowing how to explain them to business people and then relating that concept to a business problem they are having.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Consulting is built on trust, and trust is developed in a number of different ways.&lt;/p&gt;\n\n&lt;p&gt;Becoming a trusted advisor to a client is a key step, that means walking them through the good and bad, and making sure honesty is present in the relationship.&lt;/p&gt;\n\n&lt;p&gt;Having your team become known for providing this, as well as an open and thoughtful approach helps future clients consider what you are offering.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Regular feedback and communication is critical&lt;/p&gt;\n\n&lt;p&gt;There is this saying in consulting, \u201cas long as you&amp;#39;re 5 minutes ahead of the client\u201d which I find to be an interesting thing.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Developing an agile and project management mindset greatly helps to ensure that your projects stay on target and ultimately address the problem statement.&lt;/p&gt;\n\n&lt;p&gt;There are new challenges, learning challenges, thinking challenges, planning challenges.  There is success, there is failure but at the end of the day, it\u2019s fun.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yqcuj4", "is_robot_indexable": true, "report_reasons": null, "author": "KennedyKWangari", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yqcuj4/what_consulting_taught_me_about_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yqcuj4/what_consulting_taught_me_about_data_science/", "subreddit_subscribers": 818351, "created_utc": 1667983009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm pursuing MS in Data Science and I have decided to take my Data Science Capstone Project in the next semester. \n\nI had a discussion with my advisor and he wants me to contribute to open Source as my capstone project. \n\nI don't have any problem in that but I just don't know how and where I can contribute in a Data Science domain. \n\nIt would be great if you guys can give some ideas.", "author_fullname": "t2_780hr7d6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My advisor want me to Contribute to Open Source as a capstone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqaonc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667975055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m pursuing MS in Data Science and I have decided to take my Data Science Capstone Project in the next semester. &lt;/p&gt;\n\n&lt;p&gt;I had a discussion with my advisor and he wants me to contribute to open Source as my capstone project. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any problem in that but I just don&amp;#39;t know how and where I can contribute in a Data Science domain. &lt;/p&gt;\n\n&lt;p&gt;It would be great if you guys can give some ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yqaonc", "is_robot_indexable": true, "report_reasons": null, "author": "zxcvbnmlkjhgfdsaq19", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yqaonc/my_advisor_want_me_to_contribute_to_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yqaonc/my_advisor_want_me_to_contribute_to_open_source/", "subreddit_subscribers": 818351, "created_utc": 1667975055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_tyl6qdc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Personas - Who\u2019s Who in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_yqalo3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SsBC5yj01DYkXXqrmPbcwZryy5CIX1i_mzRJfip5IHA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667974796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arangodb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.arangodb.com/2022/04/whos-who-in-data-science/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?auto=webp&amp;s=54001d6b668ebf81ac60c27d1ca48e96c2600a0b", "width": 1169, "height": 536}, "resolutions": [{"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a7cd775dec9d5f38f5a0087cc56be0fcabf078d", "width": 108, "height": 49}, {"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=39499125b7f3bdbf09d40d5da7e7d365a0b6ac35", "width": 216, "height": 99}, {"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ee7bd43d332a4b44ec3bbf951c0eaff0e33afdb", "width": 320, "height": 146}, {"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cc4afbffb84268b43f2e1c857e3dae488fd9fefa", "width": 640, "height": 293}, {"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b879f3fc35b8096d4e4b98f8568c19cd6c1d43a6", "width": 960, "height": 440}, {"url": "https://external-preview.redd.it/zFXHonNQ8i2AhCHKFegQPrD4lH0llP0bY_tHfvju3yc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ad742d9eb4c28af722ef9df7dc73f59b0195c85", "width": 1080, "height": 495}], "variants": {}, "id": "sgemabpR_jc6Eb_WzBdtHM3xka5k2kSTMXdcmZwxQZM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yqalo3", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Plan591", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yqalo3/data_science_personas_whos_who_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arangodb.com/2022/04/whos-who-in-data-science/", "subreddit_subscribers": 818351, "created_utc": 1667974796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking for a book/website/ebook to learn high level statistics along with Python. \n\nI would like to be able to learn how to import data sources, how to perform anova, multiple linear regression, hypothesis testing, etc etc. \n\nIn an ideal world, I'd like a physical book. However, if the online sources provide higher quality content, i'll gladly use those. \n\nThank you", "author_fullname": "t2_oyqxw0r6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resource to learn Python along with statistics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq7qww", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667965794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a book/website/ebook to learn high level statistics along with Python. &lt;/p&gt;\n\n&lt;p&gt;I would like to be able to learn how to import data sources, how to perform anova, multiple linear regression, hypothesis testing, etc etc. &lt;/p&gt;\n\n&lt;p&gt;In an ideal world, I&amp;#39;d like a physical book. However, if the online sources provide higher quality content, i&amp;#39;ll gladly use those. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq7qww", "is_robot_indexable": true, "report_reasons": null, "author": "GrantTheGreat15", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq7qww/good_resource_to_learn_python_along_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq7qww/good_resource_to_learn_python_along_with/", "subreddit_subscribers": 818351, "created_utc": 1667965794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hello,\n\nI am working on curve's peaks and valleys detections.\n\n**Peak detection function**  \nIn Python there is no shortage of nice functions to do it like with scipy.signal.find\\_peaks.  \nAnd most functions have many parameters (distance, height, prominence, etc.) which have for objective to detect more or less peaks, which mean ignoring the minor ones, considered as noise.\n\n**Curve smoothing**  \nThen comes smoothing the curve before peak detecting.  \nI often see it done in blogs and examples.  \nThe savgol\\_filter is quite often used.  \nBasically it smooths the curves, so noise is removed and then you detect only major peaks.\n\n**Here are my questions**:\n\n**1/ Is curve smoothing before peak detection of any use ?**  \nI have the intuition that it's overlapping, and basically doing twice the same thing via different means.  \nAnd that if you fine tune your peak detection function parameters (distance, height, prominence, etc.) enough, smoothing before will never provide any upside.\n\n**2/ If curve smoothing is useful how to optimize it with peak detection?**  \nSay you want to detect only visually major peaks (I know it's subjective, but let's say you want only a limited number of peaks, while maximizing the gap between peaks and valleys).   \nIs there a way to find the correct mix of smoothing and parameters?  \nOr do you bruteforce millions of combinaisons until you have minimized the number of peaks while maximized the average gaps between peaks and valleys? \n\nWhat are your thoughts?  \nthx", "author_fullname": "t2_5559lwqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curve peak finding: isn't curve smoothing overlapping with peak detection functions parameters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypqxuf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667924311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am working on curve&amp;#39;s peaks and valleys detections.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Peak detection function&lt;/strong&gt;&lt;br/&gt;\nIn Python there is no shortage of nice functions to do it like with scipy.signal.find_peaks.&lt;br/&gt;\nAnd most functions have many parameters (distance, height, prominence, etc.) which have for objective to detect more or less peaks, which mean ignoring the minor ones, considered as noise.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Curve smoothing&lt;/strong&gt;&lt;br/&gt;\nThen comes smoothing the curve before peak detecting.&lt;br/&gt;\nI often see it done in blogs and examples.&lt;br/&gt;\nThe savgol_filter is quite often used.&lt;br/&gt;\nBasically it smooths the curves, so noise is removed and then you detect only major peaks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are my questions&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1/ Is curve smoothing before peak detection of any use ?&lt;/strong&gt;&lt;br/&gt;\nI have the intuition that it&amp;#39;s overlapping, and basically doing twice the same thing via different means.&lt;br/&gt;\nAnd that if you fine tune your peak detection function parameters (distance, height, prominence, etc.) enough, smoothing before will never provide any upside.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2/ If curve smoothing is useful how to optimize it with peak detection?&lt;/strong&gt;&lt;br/&gt;\nSay you want to detect only visually major peaks (I know it&amp;#39;s subjective, but let&amp;#39;s say you want only a limited number of peaks, while maximizing the gap between peaks and valleys).&lt;br/&gt;\nIs there a way to find the correct mix of smoothing and parameters?&lt;br/&gt;\nOr do you bruteforce millions of combinaisons until you have minimized the number of peaks while maximized the average gaps between peaks and valleys? &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts?&lt;br/&gt;\nthx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypqxuf", "is_robot_indexable": true, "report_reasons": null, "author": "Vince_peak", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypqxuf/curve_peak_finding_isnt_curve_smoothing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypqxuf/curve_peak_finding_isnt_curve_smoothing/", "subreddit_subscribers": 818351, "created_utc": 1667924311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_u4a425tc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Top &amp; Most used Machine Learning Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5qqb61yqnvy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 132, "x": 108, "u": "https://preview.redd.it/5qqb61yqnvy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=983f2f674a093d85c0fb7ac0d9ee721047d9078a"}, {"y": 264, "x": 216, "u": "https://preview.redd.it/5qqb61yqnvy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=179e0387e3aba6853d8d4b53584f17baca1201dd"}, {"y": 391, "x": 320, "u": "https://preview.redd.it/5qqb61yqnvy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=553a7fa59dee447ad302a715722a6aad0ae789f4"}, {"y": 783, "x": 640, "u": "https://preview.redd.it/5qqb61yqnvy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c674bcea084ddac77eaeb65aed19d869f1b4c3b5"}], "s": {"y": 960, "x": 784, "u": "https://preview.redd.it/5qqb61yqnvy91.jpg?width=784&amp;format=pjpg&amp;auto=webp&amp;s=5539fe87a24f4b5623adf5355b4cad00eacbf69f"}, "id": "5qqb61yqnvy91"}, "d0uua2yqnvy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 120, "x": 108, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2aed76ec321d0b8aec67b75bf91c75cea43e07c3"}, {"y": 240, "x": 216, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c6283e9f3374ec7432243550bb54c56c169f668"}, {"y": 356, "x": 320, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d184e2ccc8c4f6a4f26a0d03cb1e9d098ce66f87"}, {"y": 713, "x": 640, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d24efc5971e4226c69c0fba13191e6f2294ec2d3"}, {"y": 1070, "x": 960, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b117ad95d856e1f26faf898b1a12d31d53ed390d"}, {"y": 1204, "x": 1080, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c61f991c1e0afcb0e95b5c9d6e30fed0e8a5efd"}], "s": {"y": 1432, "x": 1284, "u": "https://preview.redd.it/d0uua2yqnvy91.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;s=448b7f53041b49b3617550aa25ee2f25ea07591a"}, "id": "d0uua2yqnvy91"}, "puk5f1yqnvy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 123, "x": 108, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d7cf52a5f449a3d8daace28da95894123b85fbe"}, {"y": 246, "x": 216, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8ef2e89240cb4aef7a245484d430fb6a419f4524"}, {"y": 364, "x": 320, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=75d5d879a628be9c5ce6d6611895370169d54d0b"}, {"y": 729, "x": 640, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=78def771e43e6937dd48db09e6c1601786aad2eb"}, {"y": 1093, "x": 960, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c17dd3e47494391c3a9bb580987ee7bb19c8df97"}, {"y": 1230, "x": 1080, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=03973717ad43bf18e045fa67a4853c9614e5b0a3"}], "s": {"y": 1463, "x": 1284, "u": "https://preview.redd.it/puk5f1yqnvy91.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;s=3fe64ea42277a25b22327aad9ace3b8316b02310"}, "id": "puk5f1yqnvy91"}, "5exyo1yqnvy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 120, "x": 108, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c13ef6042d03e4e8b1a807cb690a019457d44be"}, {"y": 241, "x": 216, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d53d74202d8ea415096ab602401f01a47a861113"}, {"y": 358, "x": 320, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7be4253390d023f9006989b7ab17e23a8e0a87d2"}, {"y": 716, "x": 640, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6bd921816773ffde9e365bd376387e2d3e0dfb13"}, {"y": 1075, "x": 960, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7496bd6989310f007d6d23eaf582ea0227a52deb"}, {"y": 1209, "x": 1080, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1c1c014f69430452b93bf48edc368893f85eb9f"}], "s": {"y": 1438, "x": 1284, "u": "https://preview.redd.it/5exyo1yqnvy91.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;s=853ec72c903b766d2e210e6df6bfa817d0276655"}, "id": "5exyo1yqnvy91"}, "9f3401yqnvy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 121, "x": 108, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8adf0d470ca514d6a1bc181e7aa28764647b24c"}, {"y": 242, "x": 216, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f5b5b41a7697c6b813cc2dfa718081b0818aa5aa"}, {"y": 358, "x": 320, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=524c497737723ffe6aa6073a1eff9b437f2f2999"}, {"y": 717, "x": 640, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc859f2383ae5a0d427895747a5d91373f012b31"}, {"y": 1076, "x": 960, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4cfd1707cdab5a38cef4d44f5dd93288d493d863"}, {"y": 1211, "x": 1080, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1fc5aa3d8504fd4b63d1afa5b3b37659610552b7"}], "s": {"y": 1440, "x": 1284, "u": "https://preview.redd.it/9f3401yqnvy91.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;s=d7b787d9b0aa97a2b500d164d3fd58ff36c825ca"}, "id": "9f3401yqnvy91"}, "hk16f3yqnvy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 121, "x": 108, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b836da1dacac65d31c0632fb4c5deae02fd0aa5d"}, {"y": 242, "x": 216, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c8a092c3b3fe645f380ac583f9ca83053d6a544"}, {"y": 359, "x": 320, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b0b2ee885d8ad91152aa5b5732e68581402e3261"}, {"y": 718, "x": 640, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=77acf5e3b7bef6c726bea3ec4559136e9a72dd53"}, {"y": 1078, "x": 960, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=75850d0159f1b74b6a6410b4e263562fd0905a0c"}, {"y": 1212, "x": 1080, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1c61117ea1e954e1464779881d8ff58814b1fd33"}], "s": {"y": 1442, "x": 1284, "u": "https://preview.redd.it/hk16f3yqnvy91.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;s=aeacac383c4051be26986f701c0a692bc25ff452"}, "id": "hk16f3yqnvy91"}}, "name": "t3_yqbqse", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "5qqb61yqnvy91", "id": 207111824}, {"media_id": "puk5f1yqnvy91", "id": 207111825}, {"media_id": "9f3401yqnvy91", "id": 207111826}, {"media_id": "5exyo1yqnvy91", "id": 207111827}, {"media_id": "d0uua2yqnvy91", "id": 207111828}, {"media_id": "hk16f3yqnvy91", "id": 207111829}]}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hYz01u5v9ZIgNdHMyLWbi915pxbeLTQm0Yz00GnF25w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667978786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yqbqse", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "yqbqse", "is_robot_indexable": true, "report_reasons": null, "author": "wadeedmadni", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yqbqse/top_most_used_machine_learning_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yqbqse", "subreddit_subscribers": 818351, "created_utc": 1667978786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For some states, with only 1% of data, there was a confident projection. Then for some other states, with much more data in, still no projection could be made.  This made me think maybe for some states priors were a determinant factor.  But i have doubts. \n\nWhat is the model used here? How is the inference made? I want to be able to do a similar analysis and predict the next elections myself and then compare my results with Nate Silver\u2019s.  Please provide some good sources to learn this. I have good foundation in both classical and bayesian statistics, and probability theory.", "author_fullname": "t2_4h24gybm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does the election projections made?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq9eko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667970901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For some states, with only 1% of data, there was a confident projection. Then for some other states, with much more data in, still no projection could be made.  This made me think maybe for some states priors were a determinant factor.  But i have doubts. &lt;/p&gt;\n\n&lt;p&gt;What is the model used here? How is the inference made? I want to be able to do a similar analysis and predict the next elections myself and then compare my results with Nate Silver\u2019s.  Please provide some good sources to learn this. I have good foundation in both classical and bayesian statistics, and probability theory.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq9eko", "is_robot_indexable": true, "report_reasons": null, "author": "maibees", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq9eko/how_does_the_election_projections_made/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq9eko/how_does_the_election_projections_made/", "subreddit_subscribers": 818351, "created_utc": 1667970901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working with a data set that needs to remain strictly confidential (though not due to HIPAA or any such legal requirements, just out of respect to the source). I also need to protype a web dashboard for visualizing and manipulating the data to demonstrate possible ways of communicating the data and the \"story\" within if they made the data publicly accessible.\n\nI have two questions (which may have different answers):\n\n1. How would you minimally secure (i.e. password protect, but perhaps not with a full-on authentication system) a basic (probably static, HTML/CSS/Javascript) web app in 2022?\n2. How do you deal with confidential/proprietary data when developing prototypes?\n3. (Bonus) Happen to have an example of how you tackled a similar scenario?\n\nI'll edit this post as needed if clarifying questions are asked below. Thanks in advance!", "author_fullname": "t2_f260834", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Securing a Data Science Project in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvho0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with a data set that needs to remain strictly confidential (though not due to HIPAA or any such legal requirements, just out of respect to the source). I also need to protype a web dashboard for visualizing and manipulating the data to demonstrate possible ways of communicating the data and the &amp;quot;story&amp;quot; within if they made the data publicly accessible.&lt;/p&gt;\n\n&lt;p&gt;I have two questions (which may have different answers):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How would you minimally secure (i.e. password protect, but perhaps not with a full-on authentication system) a basic (probably static, HTML/CSS/Javascript) web app in 2022?&lt;/li&gt;\n&lt;li&gt;How do you deal with confidential/proprietary data when developing prototypes?&lt;/li&gt;\n&lt;li&gt;(Bonus) Happen to have an example of how you tackled a similar scenario?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ll edit this post as needed if clarifying questions are asked below. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypvho0", "is_robot_indexable": true, "report_reasons": null, "author": "BoxBeatMan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypvho0/securing_a_data_science_project_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypvho0/securing_a_data_science_project_in_2022/", "subreddit_subscribers": 818351, "created_utc": 1667934580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For example, this one:\nhttps://careers.google.com/jobs/results/137295691429880518-business-and-marketing-data-scientist-applied-machine-learning/ for a Business and Marketing Data Scientist, Applied Machine Learning, says: \"US base salary range for this full-time position is $141,000-$219,000 + bonus + equity + benefits\"\n\nThis one: https://careers.google.com/jobs/results/106912103970808518-business-and-marketing-data-scientist-gtech/ for a Business and Marketing Data Scientist, gTech says \"The US base salary range for this full-time position is $119,000-$181,000 + bonus + equity + benefits.\"\n\nDo you think other employers will do this, and what effect will it have?", "author_fullname": "t2_5vr57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google now posting salary ranges (on all jobs, inc DS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3l4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667954022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, this one:\n&lt;a href=\"https://careers.google.com/jobs/results/137295691429880518-business-and-marketing-data-scientist-applied-machine-learning/\"&gt;https://careers.google.com/jobs/results/137295691429880518-business-and-marketing-data-scientist-applied-machine-learning/&lt;/a&gt; for a Business and Marketing Data Scientist, Applied Machine Learning, says: &amp;quot;US base salary range for this full-time position is $141,000-$219,000 + bonus + equity + benefits&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;This one: &lt;a href=\"https://careers.google.com/jobs/results/106912103970808518-business-and-marketing-data-scientist-gtech/\"&gt;https://careers.google.com/jobs/results/106912103970808518-business-and-marketing-data-scientist-gtech/&lt;/a&gt; for a Business and Marketing Data Scientist, gTech says &amp;quot;The US base salary range for this full-time position is $119,000-$181,000 + bonus + equity + benefits.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Do you think other employers will do this, and what effect will it have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?auto=webp&amp;s=860a20668c97a679bf12f760a9822ae6e573573d", "width": 1060, "height": 707}, "resolutions": [{"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=708bd1a06cf10c57e470f18c364e2ba7f2260140", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4501174b90d76b237a507bd06e37d9f41aeba74", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe440a35e675b92d83dc0d75ec6805b4ba51e7be", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18fc68b0a58d5ff200dca570b0b60fcb22b13e44", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1db86297e8fc27bc3c255873fe3d7536a123efc", "width": 960, "height": 640}], "variants": {}, "id": "6H24UlQQqZU8MhF1DciG4g8Xl9ju1x2f0n7OjLDCQss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq3l4p", "is_robot_indexable": true, "report_reasons": null, "author": "FlyMyPretty", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq3l4p/google_now_posting_salary_ranges_on_all_jobs_inc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq3l4p/google_now_posting_salary_ranges_on_all_jobs_inc/", "subreddit_subscribers": 818351, "created_utc": 1667954022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If this is the wrong forum, please direct me.\n\nI'm more of a BI analyst, but I've been challenged to broaden my skillset with some data science tasks. I've got some exposure to data science concepts, but nothing I've utilized in any full time role. \n\nMy task is to take some transactional data thats been categorized. Think something like credit card transactions, and how vendors get categorized (fast food, medical etc). If I'm trying to identify someone who might use a particular product based on their past spending history, what type of an analysis am I using to tease that out. \n\nSo if in this complete dataset I have users who've purchased product A. How would you go about doing a look-alike to find users who spend the same way as those who have product A but don't currently subscribe?\n\nI don't expect to be spoon fed, but more so to give me some key word search terms to help me get on the right path. \n\nI appreciate the assistance!", "author_fullname": "t2_b8zce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analysis Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq078w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667945489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If this is the wrong forum, please direct me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m more of a BI analyst, but I&amp;#39;ve been challenged to broaden my skillset with some data science tasks. I&amp;#39;ve got some exposure to data science concepts, but nothing I&amp;#39;ve utilized in any full time role. &lt;/p&gt;\n\n&lt;p&gt;My task is to take some transactional data thats been categorized. Think something like credit card transactions, and how vendors get categorized (fast food, medical etc). If I&amp;#39;m trying to identify someone who might use a particular product based on their past spending history, what type of an analysis am I using to tease that out. &lt;/p&gt;\n\n&lt;p&gt;So if in this complete dataset I have users who&amp;#39;ve purchased product A. How would you go about doing a look-alike to find users who spend the same way as those who have product A but don&amp;#39;t currently subscribe?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t expect to be spoon fed, but more so to give me some key word search terms to help me get on the right path. &lt;/p&gt;\n\n&lt;p&gt;I appreciate the assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq078w", "is_robot_indexable": true, "report_reasons": null, "author": "justfordickjoke", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq078w/data_analysis_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq078w/data_analysis_advice/", "subreddit_subscribers": 818351, "created_utc": 1667945489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my two previous roles we were just using Python scripts orchestrated with Airflow. At my current job, we use databricks. I think mostly because there\u2019s a lot of junior DS and they like cramming stuff into notebooks. I can\u2019t find a good workflow. The fact that the databricks environment is so bad compared to a nice IDE like PyCharm is really limiting for me. Ideally I want to do most of the development locally and use databricks to run the code when I need a lot or resources but I can\u2019t find a way that seems reasonably user friendly and end up going back and forth between local and cloud/db env using git. \n\nDoes anyone have a good flow to recommend?", "author_fullname": "t2_fqwkw26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your workflow when using databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypz7zw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667943190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my two previous roles we were just using Python scripts orchestrated with Airflow. At my current job, we use databricks. I think mostly because there\u2019s a lot of junior DS and they like cramming stuff into notebooks. I can\u2019t find a good workflow. The fact that the databricks environment is so bad compared to a nice IDE like PyCharm is really limiting for me. Ideally I want to do most of the development locally and use databricks to run the code when I need a lot or resources but I can\u2019t find a way that seems reasonably user friendly and end up going back and forth between local and cloud/db env using git. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good flow to recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypz7zw", "is_robot_indexable": true, "report_reasons": null, "author": "jobeta", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypz7zw/whats_your_workflow_when_using_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypz7zw/whats_your_workflow_when_using_databricks/", "subreddit_subscribers": 818351, "created_utc": 1667943190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was thinking about the actual updating of the weights and biases for the past couple of days, and i realized something that i havent been able to get off my mind.. if your learning rate is less than one (which i dont see how it couldnt be. Anything greater than one converges to infinite error as far as i can tell, and using a number less than one is the only way to actually use the information about the sensitivity of the cost function), anywhere you find a derivative less than one is going to make your change huge and probably change your weight too much\u2026 what\u2026 what am i missing here?\n\n(Btw sorry if this question seems inappropriate but i dont really know where else to ask r/askdatascience is dead)", "author_fullname": "t2_3hk48w5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back Propagation Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypv4jy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667945065.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking about the actual updating of the weights and biases for the past couple of days, and i realized something that i havent been able to get off my mind.. if your learning rate is less than one (which i dont see how it couldnt be. Anything greater than one converges to infinite error as far as i can tell, and using a number less than one is the only way to actually use the information about the sensitivity of the cost function), anywhere you find a derivative less than one is going to make your change huge and probably change your weight too much\u2026 what\u2026 what am i missing here?&lt;/p&gt;\n\n&lt;p&gt;(Btw sorry if this question seems inappropriate but i dont really know where else to ask &lt;a href=\"/r/askdatascience\"&gt;r/askdatascience&lt;/a&gt; is dead)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypv4jy", "is_robot_indexable": true, "report_reasons": null, "author": "Sharpeye1994", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypv4jy/back_propagation_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypv4jy/back_propagation_question/", "subreddit_subscribers": 818351, "created_utc": 1667933756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dkjfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cyber criminals: Data \u201ctoo dirty\u201d for dark web.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ypzgf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/e3LfSkgo3-W6ANFXPGuKhTP5wwO6JQS0FIr6OWyOGpk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667943732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5fu6mrcjrsy91.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?auto=webp&amp;s=05128d7c4a0ef3d3e9663d3a0f40b7178bf612ea", "width": 1124, "height": 1541}, "resolutions": [{"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a046400361b0ac0fa11b1552273639be0e77939", "width": 108, "height": 148}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a5a6be9e8af41a511ac0e8f3985c1e4318541e8", "width": 216, "height": 296}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1f65ecfd5e4b74e2d33e4dcf74c0037a454eaa3", "width": 320, "height": 438}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14767a3820718b756061f8016eed6301cc23463a", "width": 640, "height": 877}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d3fadbfbaa4dd61472e403f18bbd8ae0fea0d68", "width": 960, "height": 1316}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=187e19effd58d509e6fbc6e53c8c62456e9ad30b", "width": 1080, "height": 1480}], "variants": {}, "id": "XsBoj2TNTQ3mlna6p7Ubws8jtHmRG-ni-fxhsepQLIQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypzgf2", "is_robot_indexable": true, "report_reasons": null, "author": "bpalmerau", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypzgf2/cyber_criminals_data_too_dirty_for_dark_web/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/5fu6mrcjrsy91.jpg", "subreddit_subscribers": 818351, "created_utc": 1667943732.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}