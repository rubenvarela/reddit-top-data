{"kind": "Listing", "data": {"after": "t3_ypuz8r", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2sx99h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I built a 4 hard drive NAS in a storage box. Designed to be easy to transport. I use it mostly to store photos and videos but want to dedicate part to a \"vault\" that has survival guides and significant works (eg movies, art and others). Any suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"w448hzxhbwy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54295cce9e5a0d95ca50a8ed080f7c75e7ec2804"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d240a7b60e9682b20bfd3a36f89937ce6791acb"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea6e575e4d71672f9c0d880b4b245d31568b89e1"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60caff007e4eda154b88a13ea5e0ecfddf3c427a"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cc28810d5ec58c10f17ef6870a3db90210c03d72"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=60492f211e76f3e115a2cfb3526003f9d2212b98"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/w448hzxhbwy91.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=b7b5d4f0fa111788464e08b69dda39fd570cdfe3"}, "id": "w448hzxhbwy91"}, "0oadabmhbwy91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=141ffa64175277e127ef9923e38a5134f9e4953a"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5dd41eec4ef7af9191dd1244f2934686a5d62bb6"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=913f128c65b7595b990c85c0eccd68003369733c"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a5d6247a9e5c8bfbb76d8db5cb80837715500e1"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa6656bd8dcd61301bce3cc24cf2ec8e60ffeb5d"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=438b7f5d4fdfe153bee18b08c18a5b2a6b4423e5"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/0oadabmhbwy91.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=fdd0c1eb91c56650fa9e3b7438e5fb8662f7d1b0"}, "id": "0oadabmhbwy91"}}, "name": "t3_yqdufy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 177, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Completed, has been running for 3 months now without much issue (one hard drive is dieing)", "media_id": "0oadabmhbwy91", "id": 207133333}, {"caption": "Lots of spaghetti. This is before I realised how hot it gets and cut holes in the side for fans and exhaust", "media_id": "w448hzxhbwy91", "id": 207133334}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 177, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XMhl2GgtH1E8sSO7Mc991pPqwqOHipWQS9cW-UModms.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667986764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 1, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/yqdufy", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yqdufy", "is_robot_indexable": true, "report_reasons": null, "author": "Xididit", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqdufy/i_built_a_4_hard_drive_nas_in_a_storage_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/yqdufy", "subreddit_subscribers": 652632, "created_utc": 1667986764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "They're either about $140 or $20. I know the $20 ones have to be a scam. I just don't understand what their angle is. When I start writing 1 TB of data to it and it doesn't read it all back, it's going to be obvious it's a lower capacity device hacked to claim it's higher capacity. Or, if it actually will store the full 1 TB, it's some flaky off-brand tech that has the shelf life of unrefrigerated milk.\n\nFor durable, on-person backup, what's a line of microSD cards this community likes?", "author_fullname": "t2_5bccnsml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the deal with 1 TB microSD cards?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq5mkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667959684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They&amp;#39;re either about $140 or $20. I know the $20 ones have to be a scam. I just don&amp;#39;t understand what their angle is. When I start writing 1 TB of data to it and it doesn&amp;#39;t read it all back, it&amp;#39;s going to be obvious it&amp;#39;s a lower capacity device hacked to claim it&amp;#39;s higher capacity. Or, if it actually will store the full 1 TB, it&amp;#39;s some flaky off-brand tech that has the shelf life of unrefrigerated milk.&lt;/p&gt;\n\n&lt;p&gt;For durable, on-person backup, what&amp;#39;s a line of microSD cards this community likes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq5mkq", "is_robot_indexable": true, "report_reasons": null, "author": "GunzAndCamo", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq5mkq/whats_the_deal_with_1_tb_microsd_cards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq5mkq/whats_the_deal_with_1_tb_microsd_cards/", "subreddit_subscribers": 652632, "created_utc": 1667959684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Assuming none of us have hardened facilities/homes/shops to store computers in, Most servers are one home burglary away from being stolen. In linux, how would you implement remote offsite backups?\n\nYou cant just encrypt the offsite server's drive because they would require to be decrypted every time the server is rebooted.  \nPlease correct me if im wrong, but I think the way to do it is to temporarily encrypt my important data on my local nas to an empty SSD, where I would then rsync it to my remote server.\n\nremote server can stay wide open and so long as my host OS drive is ecrypted, my sata hdd's can remain in the clear because all they would hold is encrypted files that only I have the key for.\n\nHow do you guys do it?", "author_fullname": "t2_5xx2c0t2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I implement offsite backups where my offsite server sits insecurely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq2kca", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667951319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming none of us have hardened facilities/homes/shops to store computers in, Most servers are one home burglary away from being stolen. In linux, how would you implement remote offsite backups?&lt;/p&gt;\n\n&lt;p&gt;You cant just encrypt the offsite server&amp;#39;s drive because they would require to be decrypted every time the server is rebooted.&lt;br/&gt;\nPlease correct me if im wrong, but I think the way to do it is to temporarily encrypt my important data on my local nas to an empty SSD, where I would then rsync it to my remote server.&lt;/p&gt;\n\n&lt;p&gt;remote server can stay wide open and so long as my host OS drive is ecrypted, my sata hdd&amp;#39;s can remain in the clear because all they would hold is encrypted files that only I have the key for.&lt;/p&gt;\n\n&lt;p&gt;How do you guys do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq2kca", "is_robot_indexable": true, "report_reasons": null, "author": "CertainlyBright", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq2kca/how_can_i_implement_offsite_backups_where_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq2kca/how_can_i_implement_offsite_backups_where_my/", "subreddit_subscribers": 652632, "created_utc": 1667951319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_66bhu061", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thunderbolt 22-in-1 Dock with High Security SSD + HDD RAID", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yqdeor", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yjvidUg1PXzkteUxaAkT2bVJB3tZkyJSxWsAQqdsoqQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667985122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kickstarter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.kickstarter.com/projects/hyperaid/thunderbolt-22-in-1-dock-with-high-security-ssd-hdd-raid", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?auto=webp&amp;s=1871dd4fa38a5888f678a52726d6cea62251fd3a", "width": 1552, "height": 873}, "resolutions": [{"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=61363a7207bb35feac945563830258a716d05afc", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d416dc519a73dc495cd3265ed284a88dfca672ae", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad717c67037b10efefd2b95844186f7defc14bce", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f084a69338f2cfd0dd8bc7d15431cb9fb3cbaebd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cdddd32e368a3c215c20335d8d090a4be96b031b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/cLpDfonxMnFrnzsCaqSu8Bo3yjfFUY2GeVXb9F2SKfk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e72835a866de3a4618d7e27432a41782867591", "width": 1080, "height": 607}], "variants": {}, "id": "7kQmS4X0arDT16tMuITQhm2LKUiRsVfSZ3IrRqgxAxA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqdeor", "is_robot_indexable": true, "report_reasons": null, "author": "domanpanda", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqdeor/thunderbolt_22in1_dock_with_high_security_ssd_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.kickstarter.com/projects/hyperaid/thunderbolt-22-in-1-dock-with-high-security-ssd-hdd-raid", "subreddit_subscribers": 652632, "created_utc": 1667985122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I looked around on google and the sub, but I would like an up to date answer. \n\nI have a lot of hobby projects (Not very sensitive data) that I work on. I keep them backed up and synced to a cloud, so I can 1) revert files back to earlier versions, and 2) if my house burns down I can still retrieve my files. \n\nMy free OneDrive just filled up, so I am looking for a paid cloud storage now, where I can continue to keep my projects backed up.\n\nI would like to avoid a learning curve, and I would like everything to be as automated/easy as possible. I also don't want to be spending too much money, as I will probably just keep my subscription for the next 20+ years.\n\nCan anyone help?", "author_fullname": "t2_m7d9qp32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best casual cloud storage per TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypwfqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667936764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I looked around on google and the sub, but I would like an up to date answer. &lt;/p&gt;\n\n&lt;p&gt;I have a lot of hobby projects (Not very sensitive data) that I work on. I keep them backed up and synced to a cloud, so I can 1) revert files back to earlier versions, and 2) if my house burns down I can still retrieve my files. &lt;/p&gt;\n\n&lt;p&gt;My free OneDrive just filled up, so I am looking for a paid cloud storage now, where I can continue to keep my projects backed up.&lt;/p&gt;\n\n&lt;p&gt;I would like to avoid a learning curve, and I would like everything to be as automated/easy as possible. I also don&amp;#39;t want to be spending too much money, as I will probably just keep my subscription for the next 20+ years.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypwfqm", "is_robot_indexable": true, "report_reasons": null, "author": "CutiePatootieLootie", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypwfqm/best_casual_cloud_storage_per_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypwfqm/best_casual_cloud_storage_per_tb/", "subreddit_subscribers": 652632, "created_utc": 1667936764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Source code: https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py\n\nWindows executable: https://github.com/n0x5/scripts/releases/tag/google_vision_v2\n\nThis script uploads an image to the Google Cloud Vision AI and then saves the entire result in a .json file in the same folder as the image. The downside is you need a google account and billing enabled in Google Cloud dashboard, but there are 1000 requests / month for free which is pretty usable IMO.\n\nThe resulting .json file looks like this: https://i.imgur.com/lCQBYH5.png\n\nYou can pass 2 parameters:\n\n--file &lt;filepath&gt; - for single image recognition\n\n--folder &lt;folderpath&gt; for recursive scan of an entire folder.\n\nI also created an .exe that doesn't need Python or the libraries installed. It is compiled with pyinstaller. \n\nSetup guide:\n\n1) Go to https://console.developers.google.com/\n\n2) Click 'Credentials' in left side menu\n\n3) Create \"create credentials\" - &gt; \"OAuth client ID\"\n\n4) Select \"Desktop app\" in \"Application type\". Use any name you want, mine is \"Desktop client 1\"\n\n5) Go back to the Credentials main page and click the Download OAuth client link to the left of the \"Desktop client 1\" in the list.\n\n6) The .json file downloads in browser, so just rename it to \"credentials.json\" and place it in the same folder as Vision_API_V2.py/exe and then run it with --file to a single file to initiate.\n\n7) The browser will open to a Google page to authorize the app to access the account, click accept etc. Finished.\n\nSetup guide for python:\n\nIf you don't want to use the executable and you don't have Python you have to go to www.python.org, download the latest version, then run the following command:\n\n    pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nAfter this you should follow the earlier guide to setup Google OAuth.\n\nAlso some extra info:\n\nI wasn't sure what format or database to save it to, so I thought it's better to just save the .json as it is from google because no matter what the format, you need some sort of program to parse it anyway (although the .json is just a text file you can open in text editor). I did think about creating some kind of browser/UI but open to any suggestions for how to store it or how to parse it or any other things. Thanks", "author_fullname": "t2_378xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a script to recursively scan an image folder to Google Vision AI for image recognition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yppphp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667921706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Source code: &lt;a href=\"https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py\"&gt;https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Windows executable: &lt;a href=\"https://github.com/n0x5/scripts/releases/tag/google_vision_v2\"&gt;https://github.com/n0x5/scripts/releases/tag/google_vision_v2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This script uploads an image to the Google Cloud Vision AI and then saves the entire result in a .json file in the same folder as the image. The downside is you need a google account and billing enabled in Google Cloud dashboard, but there are 1000 requests / month for free which is pretty usable IMO.&lt;/p&gt;\n\n&lt;p&gt;The resulting .json file looks like this: &lt;a href=\"https://i.imgur.com/lCQBYH5.png\"&gt;https://i.imgur.com/lCQBYH5.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can pass 2 parameters:&lt;/p&gt;\n\n&lt;p&gt;--file &amp;lt;filepath&amp;gt; - for single image recognition&lt;/p&gt;\n\n&lt;p&gt;--folder &amp;lt;folderpath&amp;gt; for recursive scan of an entire folder.&lt;/p&gt;\n\n&lt;p&gt;I also created an .exe that doesn&amp;#39;t need Python or the libraries installed. It is compiled with pyinstaller. &lt;/p&gt;\n\n&lt;p&gt;Setup guide:&lt;/p&gt;\n\n&lt;p&gt;1) Go to &lt;a href=\"https://console.developers.google.com/\"&gt;https://console.developers.google.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2) Click &amp;#39;Credentials&amp;#39; in left side menu&lt;/p&gt;\n\n&lt;p&gt;3) Create &amp;quot;create credentials&amp;quot; - &amp;gt; &amp;quot;OAuth client ID&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;4) Select &amp;quot;Desktop app&amp;quot; in &amp;quot;Application type&amp;quot;. Use any name you want, mine is &amp;quot;Desktop client 1&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;5) Go back to the Credentials main page and click the Download OAuth client link to the left of the &amp;quot;Desktop client 1&amp;quot; in the list.&lt;/p&gt;\n\n&lt;p&gt;6) The .json file downloads in browser, so just rename it to &amp;quot;credentials.json&amp;quot; and place it in the same folder as Vision_API_V2.py/exe and then run it with --file to a single file to initiate.&lt;/p&gt;\n\n&lt;p&gt;7) The browser will open to a Google page to authorize the app to access the account, click accept etc. Finished.&lt;/p&gt;\n\n&lt;p&gt;Setup guide for python:&lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t want to use the executable and you don&amp;#39;t have Python you have to go to &lt;a href=\"http://www.python.org\"&gt;www.python.org&lt;/a&gt;, download the latest version, then run the following command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;After this you should follow the earlier guide to setup Google OAuth.&lt;/p&gt;\n\n&lt;p&gt;Also some extra info:&lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t sure what format or database to save it to, so I thought it&amp;#39;s better to just save the .json as it is from google because no matter what the format, you need some sort of program to parse it anyway (although the .json is just a text file you can open in text editor). I did think about creating some kind of browser/UI but open to any suggestions for how to store it or how to parse it or any other things. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?auto=webp&amp;s=c01c055b663941fe246888572be1bf8be8a7a520", "width": 681, "height": 771}, "resolutions": [{"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=099014c1e935a6ae87abe7dd725cde5ca5b4fc68", "width": 108, "height": 122}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e199c542005f3799ad9cf24eb0a0f437acd7a67", "width": 216, "height": 244}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=420a13a82cbd157af63aa8d94d15e65220611697", "width": 320, "height": 362}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2bbe4578b3feb1d6d8b1a80a9f1892bd1f56027", "width": 640, "height": 724}], "variants": {}, "id": "Ch5PxhWuk4icRlGEXHG3CoUrcSxfmnWtCOcXnvvSr3I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yppphp", "is_robot_indexable": true, "report_reasons": null, "author": "ouija", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yppphp/i_created_a_script_to_recursively_scan_an_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yppphp/i_created_a_script_to_recursively_scan_an_image/", "subreddit_subscribers": 652632, "created_utc": 1667921706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It was disappointing that I was struggling to find well seeded or existing classic release Linux distros that were so easy to find when they were first released.\n\nThen I discovered Usenet. My eyes have been opened.", "author_fullname": "t2_b8r6aj5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After years of hoarding, and then several years without, I felt like I missed out on the golden age.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypnmbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Editable Flair", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667917216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It was disappointing that I was struggling to find well seeded or existing classic release Linux distros that were so easy to find when they were first released.&lt;/p&gt;\n\n&lt;p&gt;Then I discovered Usenet. My eyes have been opened.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ypnmbt", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Professional3832", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypnmbt/after_years_of_hoarding_and_then_several_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypnmbt/after_years_of_hoarding_and_then_several_years/", "subreddit_subscribers": 652632, "created_utc": 1667917216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\\-Thanks.", "author_fullname": "t2_nvkg0kma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much bit rot do Hard drives get if left on a shelf for a long time compared to SSD's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqfdoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667991056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;-Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqfdoc", "is_robot_indexable": true, "report_reasons": null, "author": "FuckReddit442", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqfdoc/how_much_bit_rot_do_hard_drives_get_if_left_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqfdoc/how_much_bit_rot_do_hard_drives_get_if_left_on_a/", "subreddit_subscribers": 652632, "created_utc": 1667991056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The only method I know of is where you borrow the book, zoom in, open up Developer Tools **\u2192** Network **\u2192** Img, flip through the book and download the JPGs one by one. Is there an easy method where I could download them in a batch? I don't know code or anything like that so I'm at a lost.", "author_fullname": "t2_3z0vqk63", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way of downloading picture books in the HIGHEST quality on Internet Archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypzh74", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667943781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The only method I know of is where you borrow the book, zoom in, open up Developer Tools &lt;strong&gt;\u2192&lt;/strong&gt; Network &lt;strong&gt;\u2192&lt;/strong&gt; Img, flip through the book and download the JPGs one by one. Is there an easy method where I could download them in a batch? I don&amp;#39;t know code or anything like that so I&amp;#39;m at a lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypzh74", "is_robot_indexable": true, "report_reasons": null, "author": "jeruthemaster", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypzh74/best_way_of_downloading_picture_books_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypzh74/best_way_of_downloading_picture_books_in_the/", "subreddit_subscribers": 652632, "created_utc": 1667943781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to expand my hoard with a lot of ebooks, as I recently got an older iPad and want to get back into reading. I know Kaggle has a WikiBooks dataset but I was thinking more like sci-fi/fantasy stuff. Anyone know of good sources to start a digital library?", "author_fullname": "t2_mr4t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good place to find large collections of ebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypn5m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to expand my hoard with a lot of ebooks, as I recently got an older iPad and want to get back into reading. I know Kaggle has a WikiBooks dataset but I was thinking more like sci-fi/fantasy stuff. Anyone know of good sources to start a digital library?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1PB goal", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypn5m3", "is_robot_indexable": true, "report_reasons": null, "author": "grabmyrooster", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypn5m3/good_place_to_find_large_collections_of_ebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypn5m3/good_place_to_find_large_collections_of_ebooks/", "subreddit_subscribers": 652632, "created_utc": 1667916203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to figure out which high capacity drives to purchase. Thanks!", "author_fullname": "t2_dahbpb7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a NAS\u2014I am building in an itx case due to space constraints and because I don\u2019t need anything bigger right now. Noise is a concern for me\u2026are all drives the same loudness or are some louder than others?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yqie0f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667998920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to figure out which high capacity drives to purchase. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yqie0f", "is_robot_indexable": true, "report_reasons": null, "author": "v-a-g", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqie0f/setting_up_a_nasi_am_building_in_an_itx_case_due/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqie0f/setting_up_a_nasi_am_building_in_an_itx_case_due/", "subreddit_subscribers": 652632, "created_utc": 1667998920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What can I use to dock or otherwise connect an old IDE drive to my desktop to pull data from it? \n\nI saw docks some on Amazon but the reviews make me want to get good opinions before I buy something.", "author_fullname": "t2_c0vd3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IDE drive question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yqhx2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667997707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What can I use to dock or otherwise connect an old IDE drive to my desktop to pull data from it? &lt;/p&gt;\n\n&lt;p&gt;I saw docks some on Amazon but the reviews make me want to get good opinions before I buy something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqhx2o", "is_robot_indexable": true, "report_reasons": null, "author": "Subliminal87", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqhx2o/ide_drive_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqhx2o/ide_drive_question/", "subreddit_subscribers": 652632, "created_utc": 1667997707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bought 14Tb external hdd, but I can't mount it to my current case. I Will change the case in the future but I don't want to have to \"collect\" all the data again if i will be forced to reformat it.", "author_fullname": "t2_7t04smq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can i shuck my External HDD in the future and connect to Sata without needing to format it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yqhwo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667997682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bought 14Tb external hdd, but I can&amp;#39;t mount it to my current case. I Will change the case in the future but I don&amp;#39;t want to have to &amp;quot;collect&amp;quot; all the data again if i will be forced to reformat it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqhwo0", "is_robot_indexable": true, "report_reasons": null, "author": "yezitoc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqhwo0/can_i_shuck_my_external_hdd_in_the_future_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqhwo0/can_i_shuck_my_external_hdd_in_the_future_and/", "subreddit_subscribers": 652632, "created_utc": 1667997682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sorry for the weird title, I wasn't sure how to condense it in a way that still makes it obvious what I want. \n\nI'm thinking of getting a TR-004 to expand my QNAP TS453Bmini. I have a APC Back-UPS that detects power outage and tells my NAS to shut down within a certain amount of time. I was not able to find out if this functionality would extend to a connected TR-004 as well. Can anyone here answer this for me?", "author_fullname": "t2_160alx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "QNAP TS453bmini+TR-004 - UPS power loss prevention supported on NAS and extension?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqfygt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667992589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for the weird title, I wasn&amp;#39;t sure how to condense it in a way that still makes it obvious what I want. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of getting a TR-004 to expand my QNAP TS453Bmini. I have a APC Back-UPS that detects power outage and tells my NAS to shut down within a certain amount of time. I was not able to find out if this functionality would extend to a connected TR-004 as well. Can anyone here answer this for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqfygt", "is_robot_indexable": true, "report_reasons": null, "author": "FeastForCows", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqfygt/qnap_ts453bminitr004_ups_power_loss_prevention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqfygt/qnap_ts453bminitr004_ups_power_loss_prevention/", "subreddit_subscribers": 652632, "created_utc": 1667992589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI'm looking for the **biggest possible** external drive, which uses USB-3.0 and does not need an additional power adapter.\n\nAs far as I know that limits me to 2.5\" SSD drives like the Samsung 870 8TB SSD in an external enclosure. The issue is that this one draws 5.5W while USB-3.0 only provides 4.5W.\n\nWhich would be the biggest drive that can run on only 4.5W USB-3.0? Thanks\n\n(I hope this kind of post is allowed here. If not, I'm sorry)", "author_fullname": "t2_f1pw4w03", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big external USB-3.0 Drive without power adapter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqd43u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667984039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for the &lt;strong&gt;biggest possible&lt;/strong&gt; external drive, which uses USB-3.0 and does not need an additional power adapter.&lt;/p&gt;\n\n&lt;p&gt;As far as I know that limits me to 2.5&amp;quot; SSD drives like the Samsung 870 8TB SSD in an external enclosure. The issue is that this one draws 5.5W while USB-3.0 only provides 4.5W.&lt;/p&gt;\n\n&lt;p&gt;Which would be the biggest drive that can run on only 4.5W USB-3.0? Thanks&lt;/p&gt;\n\n&lt;p&gt;(I hope this kind of post is allowed here. If not, I&amp;#39;m sorry)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqd43u", "is_robot_indexable": true, "report_reasons": null, "author": "don-dante", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqd43u/big_external_usb30_drive_without_power_adapter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqd43u/big_external_usb30_drive_without_power_adapter/", "subreddit_subscribers": 652632, "created_utc": 1667984039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im sorry for potentially stupid question, but i could not google stright answer for that.\n\nLet's say we have RAID1 (mdadm, zfs, whatever) with 3 or more drives. Let's say one of them fails.\n \n~~Question1: Since (AFAIK) reading speeds for RAID1 are multiplied according to number of the disks, then rebuilding such pool should be also faster right? Because resilvering/rebuilding goes from 2+ disks remaining in the pool?~~\nAlready answered: speed will be limited mainly by writing speeds of replaced drive \n\nQuestion2: If previous statement is true, then also remaining disks should be less stressed during rebuilding/resilvering because load is spread on 2+ right? (lets say i mainly ask about mdadm)", "author_fullname": "t2_66bhu061", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID1 with 3+ drives - is rebuilding/resilvering it faster than 2-drive RAID1?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqcn0m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667993389.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667982196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im sorry for potentially stupid question, but i could not google stright answer for that.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we have RAID1 (mdadm, zfs, whatever) with 3 or more drives. Let&amp;#39;s say one of them fails.&lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;Question1: Since (AFAIK) reading speeds for RAID1 are multiplied according to number of the disks, then rebuilding such pool should be also faster right? Because resilvering/rebuilding goes from 2+ disks remaining in the pool?&lt;/del&gt;\nAlready answered: speed will be limited mainly by writing speeds of replaced drive &lt;/p&gt;\n\n&lt;p&gt;Question2: If previous statement is true, then also remaining disks should be less stressed during rebuilding/resilvering because load is spread on 2+ right? (lets say i mainly ask about mdadm)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqcn0m", "is_robot_indexable": true, "report_reasons": null, "author": "domanpanda", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqcn0m/raid1_with_3_drives_is_rebuildingresilvering_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqcn0m/raid1_with_3_drives_is_rebuildingresilvering_it/", "subreddit_subscribers": 652632, "created_utc": 1667982196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was told to crosspost this here: Getting storage error when moving mods despite having more than enough space on hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3xtf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5xg6l51", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "skyrimmods", "selftext": "Hi folks, I'm trying to move my MO2 mods from a 500 GB drive to my 1 TB drive, and I keep getting this error ([https://imgur.com/a/Iqh79rn](https://imgur.com/a/Iqh79rn)). I have checked and have a LOT of room on this drive, so I don't understand why it won't let me move them. There's also the additional confusion of saying that there \"isn't enough space on X\" where X is the name of a folder within the mod. I'm at a loss and any info would be greatly appreciated. Thanks!", "author_fullname": "t2_5xg6l51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting storage error when moving mods despite having more than enough space on hard drive", "link_flair_richtext": [{"e": "text", "t": "PC SSE - Help"}], "subreddit_name_prefixed": "r/skyrimmods", "hidden": false, "pwls": 6, "link_flair_css_class": "pc help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3cuk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "PC SSE - Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667953394.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.skyrimmods", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I&amp;#39;m trying to move my MO2 mods from a 500 GB drive to my 1 TB drive, and I keep getting this error (&lt;a href=\"https://imgur.com/a/Iqh79rn\"&gt;https://imgur.com/a/Iqh79rn&lt;/a&gt;). I have checked and have a LOT of room on this drive, so I don&amp;#39;t understand why it won&amp;#39;t let me move them. There&amp;#39;s also the additional confusion of saying that there &amp;quot;isn&amp;#39;t enough space on X&amp;quot; where X is the name of a folder within the mod. I&amp;#39;m at a loss and any info would be greatly appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?auto=webp&amp;s=582e8c916e2ba72f81def226bae5d7d2d4c4f266", "width": 788, "height": 497}, "resolutions": [{"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1205cf84f08dcab61057b4881b1fa609ec70662c", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f6de7c2850c303338319c5869ffa46cfc433e75", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e0b0f951039bf92802a4be34b8ae98b7fbeade6", "width": 320, "height": 201}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1288ff7abb4f9941fd525573e5010fa48f59cb4", "width": 640, "height": 403}], "variants": {}, "id": "s8zk_JESvU1TJolUPHXZdfpR9Ek1VJbTNKTX-Sus-Zo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bdae4814-a9d9-11e4-a87a-22000bb26ab4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sqqh", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yq3cuk", "is_robot_indexable": true, "report_reasons": null, "author": "moss_back", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "subreddit_subscribers": 384220, "created_utc": 1667953394.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1667954984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.skyrimmods", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?auto=webp&amp;s=582e8c916e2ba72f81def226bae5d7d2d4c4f266", "width": 788, "height": 497}, "resolutions": [{"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1205cf84f08dcab61057b4881b1fa609ec70662c", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f6de7c2850c303338319c5869ffa46cfc433e75", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e0b0f951039bf92802a4be34b8ae98b7fbeade6", "width": 320, "height": 201}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1288ff7abb4f9941fd525573e5010fa48f59cb4", "width": 640, "height": 403}], "variants": {}, "id": "s8zk_JESvU1TJolUPHXZdfpR9Ek1VJbTNKTX-Sus-Zo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq3xtf", "is_robot_indexable": true, "report_reasons": null, "author": "moss_back", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yq3cuk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq3xtf/was_told_to_crosspost_this_here_getting_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "subreddit_subscribers": 652632, "created_utc": 1667954984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I finally hit that point that everyone told me would happen - I've outgrown my 2-bay Synology, and I want something bigger. I would just get a bigger Synology, but...I really want something rack-mounted. I'm OK paying the rack tax just for the convenience factor, but I am struggling to make the right choice for it. For reference, I LOVE my Synology, and use it for a bunch of different things (media serving, backups for other devices, Docker containers).\n\nOption 1 - Synology RS822+. Literally exactly what I need. 4-bays with higher-capacity drives will suffice unless/until my data storage needs fundamentally change, and there is the RX418 available in that case. As mentioned before, I love my Synology. I would look at the RS422+, but not having expandable memory is a deal-breaker. The cost though is making me hesitant - $1k is a lot of money for a closed-source appliance that I can't repair/reuse for different purposes.\n\nOption 2 - Custom Unraid box. I am totally fine with messing around with something that requires more setup or is less user-friendly than normal consumer products, but I don't want it to become a chore. That said...I can build one of these for a few hundred bucks cheaper than a Synology that will provide me more flexibility and easier repair/upgrades in the future.  My biggest issues is finding a case that will give me at least 4 3.5\" bays and is less than 19\" long - preferably in a 2u form factor.\n\n&amp;#x200B;\n\nAny thoughts either way? And if an Unraid box is my best bet, has anyone tried these cases out before, or have suggestions?\n\nThis looks perfect, but seems to be some sort of custom item....[http://www.plinkusa.net/webITX-S2082](http://www.plinkusa.net/webITX-S2082)\n\nThis Silverstone case also looks good, but is $$$: [https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/](https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/)\n\nThis Rosewill case is cheaper, but only supports 6 drives and doesn't have front-access drives (not a huge deal TBH): [https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179](https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179)", "author_fullname": "t2_16irvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing DS220+ with another Synology, custom box, or ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq2bqv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667950970.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667950698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally hit that point that everyone told me would happen - I&amp;#39;ve outgrown my 2-bay Synology, and I want something bigger. I would just get a bigger Synology, but...I really want something rack-mounted. I&amp;#39;m OK paying the rack tax just for the convenience factor, but I am struggling to make the right choice for it. For reference, I LOVE my Synology, and use it for a bunch of different things (media serving, backups for other devices, Docker containers).&lt;/p&gt;\n\n&lt;p&gt;Option 1 - Synology RS822+. Literally exactly what I need. 4-bays with higher-capacity drives will suffice unless/until my data storage needs fundamentally change, and there is the RX418 available in that case. As mentioned before, I love my Synology. I would look at the RS422+, but not having expandable memory is a deal-breaker. The cost though is making me hesitant - $1k is a lot of money for a closed-source appliance that I can&amp;#39;t repair/reuse for different purposes.&lt;/p&gt;\n\n&lt;p&gt;Option 2 - Custom Unraid box. I am totally fine with messing around with something that requires more setup or is less user-friendly than normal consumer products, but I don&amp;#39;t want it to become a chore. That said...I can build one of these for a few hundred bucks cheaper than a Synology that will provide me more flexibility and easier repair/upgrades in the future.  My biggest issues is finding a case that will give me at least 4 3.5&amp;quot; bays and is less than 19&amp;quot; long - preferably in a 2u form factor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts either way? And if an Unraid box is my best bet, has anyone tried these cases out before, or have suggestions?&lt;/p&gt;\n\n&lt;p&gt;This looks perfect, but seems to be some sort of custom item....&lt;a href=\"http://www.plinkusa.net/webITX-S2082\"&gt;http://www.plinkusa.net/webITX-S2082&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This Silverstone case also looks good, but is $$$: &lt;a href=\"https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/\"&gt;https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This Rosewill case is cheaper, but only supports 6 drives and doesn&amp;#39;t have front-access drives (not a huge deal TBH): &lt;a href=\"https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179\"&gt;https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq2bqv", "is_robot_indexable": true, "report_reasons": null, "author": "icelandismine", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq2bqv/replacing_ds220_with_another_synology_custom_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq2bqv/replacing_ds220_with_another_synology_custom_box/", "subreddit_subscribers": 652632, "created_utc": 1667950698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just received my first \"returned\" WD drive from Amazon.  As soon as I opened the box, which was still sealed, on the top anyway, I could tell what was up.  Both sides of the case were broken open.  For giggles I went ahead and connected it to the PC.  It was recognized as 500GB (should be 16TB) , and still contained a Windows install, complete with user name (Mr Dan Hoffman).", "author_fullname": "t2_3wf6rrz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"New\" WD external drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvkx5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just received my first &amp;quot;returned&amp;quot; WD drive from Amazon.  As soon as I opened the box, which was still sealed, on the top anyway, I could tell what was up.  Both sides of the case were broken open.  For giggles I went ahead and connected it to the PC.  It was recognized as 500GB (should be 16TB) , and still contained a Windows install, complete with user name (Mr Dan Hoffman).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "60TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ypvkx5", "is_robot_indexable": true, "report_reasons": null, "author": "joe-dirt-1001", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypvkx5/new_wd_external_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypvkx5/new_wd_external_drive/", "subreddit_subscribers": 652632, "created_utc": 1667934786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Noob here. I have been sorting through all these files from my past, and I thankfully have already been keeping a log of checksums for all of the files. Every time I save a new file in my 3-2-1 system, I log the checksum. That way, any time I encounter some file on an old drive I find, or someone sends me something from long ago, I can search the log for the checksum, and I'll know if I already have it or not, regardless of what we named the file. I also just like having the checksums in general, so I know the data is always good from when I received it.\n\nThis has worked for me, and helped me avoid saving many many duplicates. I use a custom script to log everything to a single .tsv file, and I use bash to parse through it when needed. It's not pretty (nor ugly), but I figured I'd ask if I'm reinventing the wheel here, and if there is any software that does this, or if there are any better methods out there? I'd also like to know if this is extremely inefficient (say, if I wanted to do it for an entire drive at once). Also, I currently use the SHA256 algo, even though I know faster algos have very low chance of collision anyway.\n\nI would appreciate any critiques/input on this workflow. TIA!", "author_fullname": "t2_445vu7eo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Criticism please: Is there a better way to log checksums of all my files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypv7ew", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Noob here. I have been sorting through all these files from my past, and I thankfully have already been keeping a log of checksums for all of the files. Every time I save a new file in my 3-2-1 system, I log the checksum. That way, any time I encounter some file on an old drive I find, or someone sends me something from long ago, I can search the log for the checksum, and I&amp;#39;ll know if I already have it or not, regardless of what we named the file. I also just like having the checksums in general, so I know the data is always good from when I received it.&lt;/p&gt;\n\n&lt;p&gt;This has worked for me, and helped me avoid saving many many duplicates. I use a custom script to log everything to a single .tsv file, and I use bash to parse through it when needed. It&amp;#39;s not pretty (nor ugly), but I figured I&amp;#39;d ask if I&amp;#39;m reinventing the wheel here, and if there is any software that does this, or if there are any better methods out there? I&amp;#39;d also like to know if this is extremely inefficient (say, if I wanted to do it for an entire drive at once). Also, I currently use the SHA256 algo, even though I know faster algos have very low chance of collision anyway.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any critiques/input on this workflow. TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypv7ew", "is_robot_indexable": true, "report_reasons": null, "author": "Hooked__On__Chronics", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypv7ew/criticism_please_is_there_a_better_way_to_log/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypv7ew/criticism_please_is_there_a_better_way_to_log/", "subreddit_subscribers": 652632, "created_utc": 1667933940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know buying an internal hard drive + enclosure is almost always better but I'm looking for 4 or 5TB of storage in a small form factor for traveling. \n\nIs there a list of smaller capacity external HDDs that don't have the sata connector soldered onto the USB adapter? [https://shucks.top/](https://shucks.top/) only has WD drives and they start at 8TB.", "author_fullname": "t2_2xo37qk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which external HDDs don't have the sata connector soldered onto the USB adapter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypu4ob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667931490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know buying an internal hard drive + enclosure is almost always better but I&amp;#39;m looking for 4 or 5TB of storage in a small form factor for traveling. &lt;/p&gt;\n\n&lt;p&gt;Is there a list of smaller capacity external HDDs that don&amp;#39;t have the sata connector soldered onto the USB adapter? &lt;a href=\"https://shucks.top/\"&gt;https://shucks.top/&lt;/a&gt; only has WD drives and they start at 8TB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?auto=webp&amp;s=4305af1baddc4e2ce299670a6b101ab1b7117895", "width": 512, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=262b84cd4e22f5efb49272c5faff423c8e19100c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c8e6634d0f9c8deea9e61cb2b4ed3a1186d0c1b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6321c8f7388444b25dfc26f9b70396d92b51363", "width": 320, "height": 160}], "variants": {}, "id": "mXTY-ElzykgJ9hWy66sBlD2xbZ60EVow9UyVqQ-TUEU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypu4ob", "is_robot_indexable": true, "report_reasons": null, "author": "owta150", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypu4ob/which_external_hdds_dont_have_the_sata_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypu4ob/which_external_hdds_dont_have_the_sata_connector/", "subreddit_subscribers": 652632, "created_utc": 1667931490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am thinking about building a very simple Pi NAS. Like, one 1 or 2TB external SSD hooked into my home network via ethernet. I am a total noob at this stuff. For redundancy maybe pay google $2 a month for cloud storage or something.\n\nRight now this is honestly more of a solution in search of a problem; I just like to tinker mainly. Thinking it'll just be a place to stick important files without too much trouble. Here is what I would like to be able to do:\n\n&amp;#x200B;\n\n* Stick family photos and videos on, from any source (Windows, macOS, iOS)\n* Stick important docs on (old tax turbo tax PDFs, etc)\n* Maybe stick some music files on\n\nImportantly, be able to VIEW and edit the files if needed. Specifically I am thinking about our pics, which are incredibly disorganized, duplicated, etc. Would like to be able to open up the iPad and go through the NAS and be like \"that one sucks, DELETE... that one is upside down, FIX.... Create a \"wedding pictures\" folder and move all these pics over there.... etc\\*\"\n\nIs all that possible?\n\n*\\*One thing that I am not clear on... let's say I go to a folder full of pics on the NAS and start editing them on an iPAD (or whatever device, PC, MAC, etc). Am I using whatever photo viewing / editing SW to view and edit the file residing on the NAS (i.e. the SW is acting like a \"window\" to look at the file still residing on another computer).... or am I pulling the file ONTO the device, making changes, and then when I hit \"save\" it overwrites (uploads) the new file to the NAS?*\n\n*I am not sure there is a fundamental difference in outcome but just wondering.*", "author_fullname": "t2_ltj899zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about potential Pi NAS - dumb question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypsvwg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1667928873.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667928671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking about building a very simple Pi NAS. Like, one 1 or 2TB external SSD hooked into my home network via ethernet. I am a total noob at this stuff. For redundancy maybe pay google $2 a month for cloud storage or something.&lt;/p&gt;\n\n&lt;p&gt;Right now this is honestly more of a solution in search of a problem; I just like to tinker mainly. Thinking it&amp;#39;ll just be a place to stick important files without too much trouble. Here is what I would like to be able to do:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Stick family photos and videos on, from any source (Windows, macOS, iOS)&lt;/li&gt;\n&lt;li&gt;Stick important docs on (old tax turbo tax PDFs, etc)&lt;/li&gt;\n&lt;li&gt;Maybe stick some music files on&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Importantly, be able to VIEW and edit the files if needed. Specifically I am thinking about our pics, which are incredibly disorganized, duplicated, etc. Would like to be able to open up the iPad and go through the NAS and be like &amp;quot;that one sucks, DELETE... that one is upside down, FIX.... Create a &amp;quot;wedding pictures&amp;quot; folder and move all these pics over there.... etc*&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Is all that possible?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;\\&lt;/em&gt;One thing that I am not clear on... let&amp;#39;s say I go to a folder full of pics on the NAS and start editing them on an iPAD (or whatever device, PC, MAC, etc). Am I using whatever photo viewing / editing SW to view and edit the file residing on the NAS (i.e. the SW is acting like a &amp;quot;window&amp;quot; to look at the file still residing on another computer).... or am I pulling the file ONTO the device, making changes, and then when I hit &amp;quot;save&amp;quot; it overwrites (uploads) the new file to the NAS?*&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I am not sure there is a fundamental difference in outcome but just wondering.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypsvwg", "is_robot_indexable": true, "report_reasons": null, "author": "_How_Can_She_Slap_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypsvwg/question_about_potential_pi_nas_dumb_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypsvwg/question_about_potential_pi_nas_dumb_question/", "subreddit_subscribers": 652632, "created_utc": 1667928671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had an issue and I fee like there are too many brilliant people on this sub for there to not be some kind of solution or recommendation for it.    \n\n\nI'm looking to setup a tagging and indexing system for my documents collection and was wondering if anyone could recommend the best software approach. I have several TB worth of documents (PDF, Doc, txt, and Epub etc.) as well as video (avi, mp4, m4v), images (png, jpg, tif), and audio files and I want away to \n\n* Filter by file type(s)\n* Manually assign tags to them and filter by those tags\n* Have a way to index specific files (mostly the document files), so that their contents are also searchable. \n\nHas anyone created a system that could do this? Was this a custom solution or is there existing software?", "author_fullname": "t2_9dk8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a tagging and search system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypopme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had an issue and I fee like there are too many brilliant people on this sub for there to not be some kind of solution or recommendation for it.    &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to setup a tagging and indexing system for my documents collection and was wondering if anyone could recommend the best software approach. I have several TB worth of documents (PDF, Doc, txt, and Epub etc.) as well as video (avi, mp4, m4v), images (png, jpg, tif), and audio files and I want away to &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Filter by file type(s)&lt;/li&gt;\n&lt;li&gt;Manually assign tags to them and filter by those tags&lt;/li&gt;\n&lt;li&gt;Have a way to index specific files (mostly the document files), so that their contents are also searchable. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Has anyone created a system that could do this? Was this a custom solution or is there existing software?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypopme", "is_robot_indexable": true, "report_reasons": null, "author": "funke75", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypopme/setting_up_a_tagging_and_search_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypopme/setting_up_a_tagging_and_search_system/", "subreddit_subscribers": 652632, "created_utc": 1667919613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I suspect it has been asked and answered, and a reference to a post would be great. \n\n&amp;#x200B;\n\n**What does everyone use to make their own collections available from their own NAS to the internet so you can access your own material securely and easily to either stream or download what you want at will?** \n\n&amp;#x200B;\n\nI usually travel with an ipad or a laptop, so something that is compatible across platforms and easily usable would be ideal.\n\n&amp;#x200B;\n\n**Many thanks!**", "author_fullname": "t2_27akqj9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to stream or self server your own NAS as cloud storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvmwb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I suspect it has been asked and answered, and a reference to a post would be great. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What does everyone use to make their own collections available from their own NAS to the internet so you can access your own material securely and easily to either stream or download what you want at will?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I usually travel with an ipad or a laptop, so something that is compatible across platforms and easily usable would be ideal.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Many thanks!&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypvmwb", "is_robot_indexable": true, "report_reasons": null, "author": "Chance-Pie6495", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypvmwb/best_way_to_stream_or_self_server_your_own_nas_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypvmwb/best_way_to_stream_or_self_server_your_own_nas_as/", "subreddit_subscribers": 652632, "created_utc": 1667934910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow hoarders, \n\nI am a nut about pro wrestling and have an 8 TB drive that has many subfolders including one called Matches. This folder has just over 7,000 video files in folders like this:\n\n **Decade** \n\nYear\n\nYYYY.MM.DD Compay X vs X\n\n&amp;#x200B;\n\nWhat I am looking to do is to be able to A) Export the file names to Excel to better track them. B) Be able to easily find duplicates that I may have.\n\nHoping for some guidance from the sub, thanks in advance!!", "author_fullname": "t2_qtmcicrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organize and list/look for dups in excel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypuz8r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow hoarders, &lt;/p&gt;\n\n&lt;p&gt;I am a nut about pro wrestling and have an 8 TB drive that has many subfolders including one called Matches. This folder has just over 7,000 video files in folders like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Decade&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Year&lt;/p&gt;\n\n&lt;p&gt;YYYY.MM.DD Compay X vs X&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What I am looking to do is to be able to A) Export the file names to Excel to better track them. B) Be able to easily find duplicates that I may have.&lt;/p&gt;\n\n&lt;p&gt;Hoping for some guidance from the sub, thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypuz8r", "is_robot_indexable": true, "report_reasons": null, "author": "gargamels_right_boot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypuz8r/organize_and_listlook_for_dups_in_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypuz8r/organize_and_listlook_for_dups_in_excel/", "subreddit_subscribers": 652632, "created_utc": 1667933422.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}