{"kind": "Listing", "data": {"after": null, "dist": 16, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've noticed with most big Data Engineering projects that a whole multitude of things can go wrong in the development phase. Data types don't match, tables get renamed or disappear all together , new columns get added so the bad Data Engineers before you who used SELECT * instead of listing out every column explicitly inadvertently break your pipelines months later. And many many other things.\n\nThe QA processes for data work seem a bit more tedious than other types of development I've done before. Right now we are in the process of fine tubing our QA methods , I've made quite a few helpful views and stored procedures that print out key information on certain tables but it's still very much a manual process. I'm trying to use dynamic SQL with input parameters to automate as much of it as I can but in general I try to avoid dynamic SQL due to performance issues particularly with large data sets.\n\nHow does everyone else feel about the QA process ? Love it, hate it, equate it to the 7th circle of hell?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hot Take : QA is the most tedious part of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3nwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667954230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed with most big Data Engineering projects that a whole multitude of things can go wrong in the development phase. Data types don&amp;#39;t match, tables get renamed or disappear all together , new columns get added so the bad Data Engineers before you who used SELECT * instead of listing out every column explicitly inadvertently break your pipelines months later. And many many other things.&lt;/p&gt;\n\n&lt;p&gt;The QA processes for data work seem a bit more tedious than other types of development I&amp;#39;ve done before. Right now we are in the process of fine tubing our QA methods , I&amp;#39;ve made quite a few helpful views and stored procedures that print out key information on certain tables but it&amp;#39;s still very much a manual process. I&amp;#39;m trying to use dynamic SQL with input parameters to automate as much of it as I can but in general I try to avoid dynamic SQL due to performance issues particularly with large data sets.&lt;/p&gt;\n\n&lt;p&gt;How does everyone else feel about the QA process ? Love it, hate it, equate it to the 7th circle of hell?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yq3nwa", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yq3nwa/hot_take_qa_is_the_most_tedious_part_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yq3nwa/hot_take_qa_is_the_most_tedious_part_of_data/", "subreddit_subscribers": 79402, "created_utc": 1667954230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Introduction to Snowflake's Micro-Partitions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yq0t6l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 80, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/tjfy5yap2pVUNFEH6hKLCqXkKDk2jSAmn-MNUlKoako.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667946912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/introduction-to-snowflake-micro-partitions", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?auto=webp&amp;s=6f25f1b0e93e7e74f553b5aa4c07400d15fcc3ce", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=359ad947553a9db5d9f74797e0137d682fa9c303", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eafe7d8b430b140f35b22d67ed33b04c32529abd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3681e70642ccd160072f1d3552aae6ba4b6f1117", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62ebfcf39d626aabc6a34b402bea37d52cc4447b", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4e73f161d8a206f1b0913c901cf54564e670522", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/dJJhj_hcs_fmPpW79MMNQmj5kRcgYAAlHtHUjuCmJ3g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eba69146c31335436e100301c826ff6688b125ca", "width": 1080, "height": 565}], "variants": {}, "id": "4J5fFrX1rcNyzxhdFfIME8Sm9Tq7yZzTDn1wriMxncs"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yq0t6l", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yq0t6l/introduction_to_snowflakes_micropartitions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/introduction-to-snowflake-micro-partitions", "subreddit_subscribers": 79402, "created_utc": 1667946912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "11,000 is a big number. I just wonder if any DE's are being let go. If so, whats your plan moving forward? Looks like the severance package is good though.", "author_fullname": "t2_1afmkbx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here being let go by Meta?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqohhm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668012826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;11,000 is a big number. I just wonder if any DE&amp;#39;s are being let go. If so, whats your plan moving forward? Looks like the severance package is good though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yqohhm", "is_robot_indexable": true, "report_reasons": null, "author": "w_savage", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqohhm/anyone_here_being_let_go_by_meta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yqohhm/anyone_here_being_let_go_by_meta/", "subreddit_subscribers": 79402, "created_utc": 1668012826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I until now have had the great pleasure of not having to learn Spark. But with great responsibility comes\u2026no idea how that quote goes.\n\nIt\u2019s seems impossible to get an answer to this or my Googling skills which afford me a nice salary are totally rubbish.\n\nIf I run spark locally to experiment and learn do you still get distributed processing? I would assume that locally it\u2019ll just use threads instead?", "author_fullname": "t2_htptc13q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you run spark locally do you still get parallel processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq4yst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667957828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I until now have had the great pleasure of not having to learn Spark. But with great responsibility comes\u2026no idea how that quote goes.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s seems impossible to get an answer to this or my Googling skills which afford me a nice salary are totally rubbish.&lt;/p&gt;\n\n&lt;p&gt;If I run spark locally to experiment and learn do you still get distributed processing? I would assume that locally it\u2019ll just use threads instead?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yq4yst", "is_robot_indexable": true, "report_reasons": null, "author": "Main_Tap_1256", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yq4yst/if_you_run_spark_locally_do_you_still_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yq4yst/if_you_run_spark_locally_do_you_still_get/", "subreddit_subscribers": 79402, "created_utc": 1667957828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Specific niche, I guess, so I'm looking for advice from anyone in this same situation. I am full-time employed, but also going to do a temporary side gig for a past co-worker/friend's company doing some turnkey data integration/data warehouse building work (ETL hookup with Stitch, dbt integration, possibly BI setup).\n\nWhat I would like is some advice on is how to determine what I should ask for as an hourly rate. I did some basic BI freelancing during COVID and just asked for my employer's hourly rate ($50/hr at the time). It was low for freelancing work, but I offered it because I didn't need to make up for any insurance costs and overhead like a 100% freelancer might. I thought at the time, in reality a freelancer might be asking for double that hourly rate at the least, and I should have asked for much more. So at this point, I am almost thinking of a flat $100-120/hr. I'm in a Low COL area and $100/hr is bank, but this is a remote gig, so maybe that's irrelevant.\n\nIs there anyone else in this situation who can walk me through the thought process on arriving at a sound number? For reference, I'm making around $70/hr doing this same work for my employer.", "author_fullname": "t2_12aazb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Freelancers who are also FT employed--How do you determine your hourly rate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq0v6z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667947052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Specific niche, I guess, so I&amp;#39;m looking for advice from anyone in this same situation. I am full-time employed, but also going to do a temporary side gig for a past co-worker/friend&amp;#39;s company doing some turnkey data integration/data warehouse building work (ETL hookup with Stitch, dbt integration, possibly BI setup).&lt;/p&gt;\n\n&lt;p&gt;What I would like is some advice on is how to determine what I should ask for as an hourly rate. I did some basic BI freelancing during COVID and just asked for my employer&amp;#39;s hourly rate ($50/hr at the time). It was low for freelancing work, but I offered it because I didn&amp;#39;t need to make up for any insurance costs and overhead like a 100% freelancer might. I thought at the time, in reality a freelancer might be asking for double that hourly rate at the least, and I should have asked for much more. So at this point, I am almost thinking of a flat $100-120/hr. I&amp;#39;m in a Low COL area and $100/hr is bank, but this is a remote gig, so maybe that&amp;#39;s irrelevant.&lt;/p&gt;\n\n&lt;p&gt;Is there anyone else in this situation who can walk me through the thought process on arriving at a sound number? For reference, I&amp;#39;m making around $70/hr doing this same work for my employer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yq0v6z", "is_robot_indexable": true, "report_reasons": null, "author": "ntdoyfanboy", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yq0v6z/freelancers_who_are_also_ft_employedhow_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yq0v6z/freelancers_who_are_also_ft_employedhow_do_you/", "subreddit_subscribers": 79402, "created_utc": 1667947052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hhdac8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Memphis.dev - Data Engineering Trends for 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yqi2tm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u8qqWbP4KwLY8sp4U_Ut5v5XCP1GXm0bgXdmcAVOb7E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667998138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memphis.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memphis.dev/blog/data-engineering-trends-for-2023/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?auto=webp&amp;s=a4b38595d8a4b65dd18c2551a542363d4ad37a27", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12a2a3835b79090fbfef12448e4d92ff9760308c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7314fc665d2a12457649e8379c046e2400789f5e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c4c206516a85795674f9643e2cb6e777edb9eba", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62629913094942563f14961cfab040fc78ca1850", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=750bdd5719ad03ac48a47f67beca7df6001951ea", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/VxCr7WFGtiHGvvty2-KkWiVu-4hdn-xFR5hm7_M45NU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9384cf3a7e35df4b401bb8b0f7009769633cab06", "width": 1080, "height": 607}], "variants": {}, "id": "SXWz10wCIyP7aVAiBp-6kHw53y20Ru30XuS9HDO0ALI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yqi2tm", "is_robot_indexable": true, "report_reasons": null, "author": "yanivbh1", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqi2tm/memphisdev_data_engineering_trends_for_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memphis.dev/blog/data-engineering-trends-for-2023/", "subreddit_subscribers": 79402, "created_utc": 1667998138.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are two tables of size 2 Tb and 10 Tb respectively. How would you join these two tables in databricks?\nI was asked this question in an interview, would really appreciate if anyone could provide an answer. Thanks.", "author_fullname": "t2_e8k9c3l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which method to use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqlris", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668006995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are two tables of size 2 Tb and 10 Tb respectively. How would you join these two tables in databricks?\nI was asked this question in an interview, would really appreciate if anyone could provide an answer. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yqlris", "is_robot_indexable": true, "report_reasons": null, "author": "SignalCrew739", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqlris/which_method_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yqlris/which_method_to_use/", "subreddit_subscribers": 79402, "created_utc": 1668006995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a research project where I\u2019m the data engineer for the project. This is my first DE experience so I feel really overwhelmed with all the options, would really appreciate any advice. I couldn't find anything when I searched.\n\nWe are analyzing a dataset, and will likely have to train a model using it later on. About the dataset:\n\n- 7.5B rows\n- Strong schema\n- 400GB of Apache Parquet files / ~2TB of JSON files(?)\n- Static, it\u2019s never written to\n\nWe\u2019ve been using BigQuery for our analysis so far, but our GCP free trial is about to run out and we don\u2019t wanna pay for any cloud bills. Requirements for new system:\n\n- Must be on premise, we have acess to a cluster of up to 5 decently powerful machines with plenty of disk space\n- SQL syntax\n\nWhat are some options? What I can think off the top my head:\n\n- Apache Drill seems to be like an open source version of BigQuery (both based off the Dremel paper). Have already used it, works for querying but it doesn\u2019t seem that popular and documentation is not great either. Running on just one machine, it\u2019s somewhat slow to query. Would take a lot more work to get it distributed across multiple machines.\n\n- Put all the data into a RDBMS like Postgres. Is this a terrible idea?\n\n\nAgain, I know it would be much easier to do using cloud but the professor I'm working with requires it to be on-premise using the hardware he already has.", "author_fullname": "t2_an12ed5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building BigQuery on-premise alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq08xv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667945601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a research project where I\u2019m the data engineer for the project. This is my first DE experience so I feel really overwhelmed with all the options, would really appreciate any advice. I couldn&amp;#39;t find anything when I searched.&lt;/p&gt;\n\n&lt;p&gt;We are analyzing a dataset, and will likely have to train a model using it later on. About the dataset:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;7.5B rows&lt;/li&gt;\n&lt;li&gt;Strong schema&lt;/li&gt;\n&lt;li&gt;400GB of Apache Parquet files / ~2TB of JSON files(?)&lt;/li&gt;\n&lt;li&gt;Static, it\u2019s never written to&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We\u2019ve been using BigQuery for our analysis so far, but our GCP free trial is about to run out and we don\u2019t wanna pay for any cloud bills. Requirements for new system:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Must be on premise, we have acess to a cluster of up to 5 decently powerful machines with plenty of disk space&lt;/li&gt;\n&lt;li&gt;SQL syntax&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are some options? What I can think off the top my head:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Apache Drill seems to be like an open source version of BigQuery (both based off the Dremel paper). Have already used it, works for querying but it doesn\u2019t seem that popular and documentation is not great either. Running on just one machine, it\u2019s somewhat slow to query. Would take a lot more work to get it distributed across multiple machines.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Put all the data into a RDBMS like Postgres. Is this a terrible idea?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Again, I know it would be much easier to do using cloud but the professor I&amp;#39;m working with requires it to be on-premise using the hardware he already has.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yq08xv", "is_robot_indexable": true, "report_reasons": null, "author": "FollowingWonderful28", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yq08xv/building_bigquery_onpremise_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yq08xv/building_bigquery_onpremise_alternative/", "subreddit_subscribers": 79402, "created_utc": 1667945601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yqb31f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_Ce-b6Dz1Wg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_Ce-b6Dz1Wg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/_Ce-b6Dz1Wg/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/SoftWizCircle"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_Ce-b6Dz1Wg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yqb31f", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tvpQ4h9W4BkUfMvKSYDVzsGEhBbuGLzxjK0owH-0E5Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667976451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/_Ce-b6Dz1Wg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DDw8uv8x2v8zORRmUh4t6pedR91wmtDB1VFCJDKC_ZA.jpg?auto=webp&amp;s=65033003ff6ece649f32f8a3a8f5352295719d27", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/DDw8uv8x2v8zORRmUh4t6pedR91wmtDB1VFCJDKC_ZA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da91e7d1943d8e5167633b405866cd24bd4862dd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DDw8uv8x2v8zORRmUh4t6pedR91wmtDB1VFCJDKC_ZA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0169a83128eebb01e065ac280c06357b76f04b10", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/DDw8uv8x2v8zORRmUh4t6pedR91wmtDB1VFCJDKC_ZA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15a26b1021696e2e4460da4aa8de8ecab5f9b52a", "width": 320, "height": 240}], "variants": {}, "id": "_fswxaLkMY8_1hjGIW_QlUF0U0kl9bYXO5p1PC0rRwU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yqb31f", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqb31f/azure_data_factory_incrementally_load_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/_Ce-b6Dz1Wg", "subreddit_subscribers": 79402, "created_utc": 1667976451.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_Ce-b6Dz1Wg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Azure Data Factory - Incrementally load data from Azure SQL to Azure Data Lake using Watermark\"&gt;&lt;/iframe&gt;", "author_name": "SoftWiz Circle", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/_Ce-b6Dz1Wg/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/SoftWizCircle"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone here have DE experience working at Amazon they would be willing to share? Work-life balance, compensation, flexibility, etc.\n\nThey get a pretty bad rep over in r/cscareerquestions for being overworked and  aggressively stack ranking employees, but they seem to be hiring a lot of DEs right now and a year or two there would probably open a lot of doors so I'm considering interview prepping and applying.\n\nI have heard the culture is highly dependent on your team-- are there any specific teams/products to avoid?", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience at Amazon?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqrm4m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668019429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here have DE experience working at Amazon they would be willing to share? Work-life balance, compensation, flexibility, etc.&lt;/p&gt;\n\n&lt;p&gt;They get a pretty bad rep over in &lt;a href=\"/r/cscareerquestions\"&gt;r/cscareerquestions&lt;/a&gt; for being overworked and  aggressively stack ranking employees, but they seem to be hiring a lot of DEs right now and a year or two there would probably open a lot of doors so I&amp;#39;m considering interview prepping and applying.&lt;/p&gt;\n\n&lt;p&gt;I have heard the culture is highly dependent on your team-- are there any specific teams/products to avoid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yqrm4m", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqrm4m/experience_at_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yqrm4m/experience_at_amazon/", "subreddit_subscribers": 79402, "created_utc": 1668019429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_86rkib21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adapting to Change: How Machine Intelligences Adapt to a Changing World with Robert Crowe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yqj1yc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/rnn2lAbIz5g?list=PLEx5khR4g7PKuDrMVDkHvItDxCsB0msAs\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Adapting to Change: How Machine Intelligences Adapt to a Changing World \u2022 Robert Crowe \u2022 GOTO 2022", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/rnn2lAbIz5g?list=PLEx5khR4g7PKuDrMVDkHvItDxCsB0msAs\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/rnn2lAbIz5g/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/GotoConferences"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/rnn2lAbIz5g?list=PLEx5khR4g7PKuDrMVDkHvItDxCsB0msAs\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yqj1yc", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/MQ6aS2ry95uOmGg4MBA6scUf8i4_hLnTkInWKkkrEI8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668000599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/rnn2lAbIz5g?list=PLEx5khR4g7PKuDrMVDkHvItDxCsB0msAs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LJGkN0_OHb6H_1BoFlsseWbf4viWgYOYKNm8hFJzVLY.jpg?auto=webp&amp;s=36a160ec947c3981a95fa5e311938b8d4154ff1e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/LJGkN0_OHb6H_1BoFlsseWbf4viWgYOYKNm8hFJzVLY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98fd3781a2fcad758ad3b318009287fa6787e6cd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/LJGkN0_OHb6H_1BoFlsseWbf4viWgYOYKNm8hFJzVLY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03ad4a53da688712b66e00d26a1747adc0678ff8", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/LJGkN0_OHb6H_1BoFlsseWbf4viWgYOYKNm8hFJzVLY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb5cf99f996ac2b6d7fb3ba0d43e399f067696f7", "width": 320, "height": 240}], "variants": {}, "id": "rQvgq0MGDrdACRC4BvdDkdB1s_DXr381EbjYM23tYLE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yqj1yc", "is_robot_indexable": true, "report_reasons": null, "author": "asc2450", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqj1yc/adapting_to_change_how_machine_intelligences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/rnn2lAbIz5g?list=PLEx5khR4g7PKuDrMVDkHvItDxCsB0msAs", "subreddit_subscribers": 79402, "created_utc": 1668000599.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Adapting to Change: How Machine Intelligences Adapt to a Changing World \u2022 Robert Crowe \u2022 GOTO 2022", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/rnn2lAbIz5g?list=PLEx5khR4g7PKuDrMVDkHvItDxCsB0msAs\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/rnn2lAbIz5g/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/c/GotoConferences"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to version control Airbyte configurations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_yqo9mk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/O_iM3HkUG7XRplnY5dYg4z9cvWMsB48_V_VTZTCa1A0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668012335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/tutorials/version-control-airbyte-configurations", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?auto=webp&amp;s=269d82fb17d4f47dd9e8de75e39367d346979bcb", "width": 1201, "height": 625}, "resolutions": [{"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=677b064a82bdb2f2b8504143a09da1afb8ba9511", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=601eac42c0a7c0e8e627619c420e73e846333293", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c25ea361fb9763097c2ef8ede254cca614b0d08", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab6623da6aab0cced34278178b150cf3a0c72d12", "width": 640, "height": 333}, {"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5777b8162d79e6bcbbbc84b4337a4daf8d143bcc", "width": 960, "height": 499}, {"url": "https://external-preview.redd.it/cEOuVIQPgYWx6OreL723TaAKnqG1UnZge57ZxEOo3HQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfec198ee150688d0d1b10b38f0dd4bad77cfbc7", "width": 1080, "height": 562}], "variants": {}, "id": "0mj0Wxr40wKsHPro6VCu-hIIckkFVw8IeI2K8tX_gWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yqo9mk", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqo9mk/how_to_version_control_airbyte_configurations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/tutorials/version-control-airbyte-configurations", "subreddit_subscribers": 79402, "created_utc": 1668012335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for a better setup for pulling in streaming data.  Not sure if is really considered streaming data since we are pulling it it.  The scenario is a google pub/sub subscription that we pull in with Databricks and process it.  One big issue is scaling up.  We can get rather large spikes in activity that can last hours so it would be nice to have something that can auto scale to handle the increased activity then scale back down when not needed.", "author_fullname": "t2_h6zwd9zl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure pulling streaming data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yqwi56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668030272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a better setup for pulling in streaming data.  Not sure if is really considered streaming data since we are pulling it it.  The scenario is a google pub/sub subscription that we pull in with Databricks and process it.  One big issue is scaling up.  We can get rather large spikes in activity that can last hours so it would be nice to have something that can auto scale to handle the increased activity then scale back down when not needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yqwi56", "is_robot_indexable": true, "report_reasons": null, "author": "the_data_is_wrong", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqwi56/azure_pulling_streaming_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yqwi56/azure_pulling_streaming_data/", "subreddit_subscribers": 79402, "created_utc": 1668030272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nI'm an analyst turned self taught engineer and I was recently informed that I'll be moving into a management role next year.  Our organization does not have a very mature data ops structure and I'm being tasked with maturing our pipeline.  I'm looking for resources for developing the necessary foundation to succeed in the management roll.  I read lot of articles, listen to various podcasts, and watch plenty of online video content.  I'm looking to supplement this with an in-person intensive learning.  \n\nDo any of you have recommendations?  Employer is going to pay for whatever I find.  Week long in-person training, conference, whatever.  I would love to hear your recommendations.  I found a couple threads with people sharing conferences they are aware of, but not a ton of people indicating they had attended and would recommend the conference.\n\nThanks!", "author_fullname": "t2_e8m84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Ops Conferences &amp; In-Person Trainings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqm4i2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668007769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an analyst turned self taught engineer and I was recently informed that I&amp;#39;ll be moving into a management role next year.  Our organization does not have a very mature data ops structure and I&amp;#39;m being tasked with maturing our pipeline.  I&amp;#39;m looking for resources for developing the necessary foundation to succeed in the management roll.  I read lot of articles, listen to various podcasts, and watch plenty of online video content.  I&amp;#39;m looking to supplement this with an in-person intensive learning.  &lt;/p&gt;\n\n&lt;p&gt;Do any of you have recommendations?  Employer is going to pay for whatever I find.  Week long in-person training, conference, whatever.  I would love to hear your recommendations.  I found a couple threads with people sharing conferences they are aware of, but not a ton of people indicating they had attended and would recommend the conference.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yqm4i2", "is_robot_indexable": true, "report_reasons": null, "author": "davidjaymartin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqm4i2/data_ops_conferences_inperson_trainings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yqm4i2/data_ops_conferences_inperson_trainings/", "subreddit_subscribers": 79402, "created_utc": 1668007769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cqao8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Developer Experience - how important is it for data engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yqc33c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l5JXdfxztKZwlj-5TiE3RicPnau95f4rrd3XToRh4rA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667980068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arecadata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arecadata.com/the-developer-experience-formula/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wXeIfE2OO90j_2c4hd5yuIvG6DA_eYsIa7gzMDBbwVM.jpg?auto=webp&amp;s=a34fa99e2b07f3178f4547d0b70e3748e518be09", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/wXeIfE2OO90j_2c4hd5yuIvG6DA_eYsIa7gzMDBbwVM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f602ed9ee80ce3b7bb90d1bf88034805dbaff59", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/wXeIfE2OO90j_2c4hd5yuIvG6DA_eYsIa7gzMDBbwVM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec1005d2a6b7afa5f0398e99ab9eb5e216f20fa4", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/wXeIfE2OO90j_2c4hd5yuIvG6DA_eYsIa7gzMDBbwVM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=affb1b5bf846843758ed0a1f10f5e3aa371caff5", "width": 320, "height": 320}], "variants": {}, "id": "S3OyZ58H3lbM8Jv8qkhdgxkDdAuws-u49g8BC8s4NEs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yqc33c", "is_robot_indexable": true, "report_reasons": null, "author": "dan_the_lion", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqc33c/developer_experience_how_important_is_it_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arecadata.com/the-developer-experience-formula/", "subreddit_subscribers": 79402, "created_utc": 1667980068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fuypuqcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Containers are chroot with a Marketing Budget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yqo0yg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1668011804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "earthly.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://earthly.dev/blog/chroot/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yqo0yg", "is_robot_indexable": true, "report_reasons": null, "author": "towtoo893", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yqo0yg/containers_are_chroot_with_a_marketing_budget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://earthly.dev/blog/chroot/", "subreddit_subscribers": 79402, "created_utc": 1668011804.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}