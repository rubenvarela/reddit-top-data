{"kind": "Listing", "data": {"after": "t3_ypperd", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_c9yytte1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After 4 months of researching my first 50TB NAS is running. Thank you.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ypeuey", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 431, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 431, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RQhSJXNR-Y_ln3KTEEJEW31qAMKhfOBddnVCr5VG438.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667893977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/58ufyeclnoy91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?auto=webp&amp;s=2c0be2afe7c17805c8031208d7630ecd2bb03495", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38cc627fb9c7be01951be9bff943071442a71b8e", "width": 108, "height": 144}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3f577150474a042253908a9aaf1c6ce95c77d94", "width": 216, "height": 288}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6ad278aec414805e39b8a61277021ddef593acd", "width": 320, "height": 426}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=76d74ee42102ae02f02df3713cde29de231e4e7c", "width": 640, "height": 853}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0043c8103b700c1308fb4dd82b07574a50f5ff11", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=152a18dee29c28875fa8481c054f13cef1d27016", "width": 1080, "height": 1440}], "variants": {}, "id": "QzfTHmHU1fPnXtElQTxW0lCMyit-GMN_ZtGOzsE-jGs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypeuey", "is_robot_indexable": true, "report_reasons": null, "author": "slavsetup", "discussion_type": null, "num_comments": 113, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypeuey/after_4_months_of_researching_my_first_50tb_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/58ufyeclnoy91.jpg", "subreddit_subscribers": 652591, "created_utc": 1667893977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Assuming none of us have hardened facilities/homes/shops to store computers in, Most servers are one home burglary away from being stolen. In linux, how would you implement remote offsite backups?\n\nYou cant just encrypt the offsite server's drive because they would require to be decrypted every time the server is rebooted.  \nPlease correct me if im wrong, but I think the way to do it is to temporarily encrypt my important data on my local nas to an empty SSD, where I would then rsync it to my remote server.\n\nremote server can stay wide open and so long as my host OS drive is ecrypted, my sata hdd's can remain in the clear because all they would hold is encrypted files that only I have the key for.\n\nHow do you guys do it?", "author_fullname": "t2_5xx2c0t2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I implement offsite backups where my offsite server sits insecurely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq2kca", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667951319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming none of us have hardened facilities/homes/shops to store computers in, Most servers are one home burglary away from being stolen. In linux, how would you implement remote offsite backups?&lt;/p&gt;\n\n&lt;p&gt;You cant just encrypt the offsite server&amp;#39;s drive because they would require to be decrypted every time the server is rebooted.&lt;br/&gt;\nPlease correct me if im wrong, but I think the way to do it is to temporarily encrypt my important data on my local nas to an empty SSD, where I would then rsync it to my remote server.&lt;/p&gt;\n\n&lt;p&gt;remote server can stay wide open and so long as my host OS drive is ecrypted, my sata hdd&amp;#39;s can remain in the clear because all they would hold is encrypted files that only I have the key for.&lt;/p&gt;\n\n&lt;p&gt;How do you guys do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq2kca", "is_robot_indexable": true, "report_reasons": null, "author": "CertainlyBright", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq2kca/how_can_i_implement_offsite_backups_where_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq2kca/how_can_i_implement_offsite_backups_where_my/", "subreddit_subscribers": 652591, "created_utc": 1667951319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My question is essentially the title and mostly comes from idle curiosity. Do they not make 2.5\" CMR drives anymore? I know seagate has one in their EXOS lineup ($600 for 2TB here... Sheesh) and a couple models from 2015~2017 seem to be CMR but that's about it. I knew 4TB+ was all SMR but I thought a few 1TB or 2TB models would still be CMR.\n\nThe reason I'm asking (which makes less sense the more I think about it) is because I was looking for some cheap local storage for an SFF secondary build. The drive is expected to write 300~500GB and read ~1.5x that amount per day. If the drive was SMR and randomly kept dropping to 15MBps, I'd be better of just accessing the data from the network instead.\n\nTBW is where I ran into my first issue. Regular laptop HDDs (the one's I was expecting to find) are only rated for 55TB/Y. My estimated usage blows that out of the water meaning I should be looking at the EXOS lineup with 550TB/Y. But those are so expensive I'd be better off getting a decent SSD instead.\n\nNow I have to figure out if I want to save $100, forgo the SSD and just read the data from my server instead of buying an SSD and caching data locally...", "author_fullname": "t2_q6dz0zvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do 2.5\" CMR drives just not exist anymore?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypik0j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667904745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My question is essentially the title and mostly comes from idle curiosity. Do they not make 2.5&amp;quot; CMR drives anymore? I know seagate has one in their EXOS lineup ($600 for 2TB here... Sheesh) and a couple models from 2015~2017 seem to be CMR but that&amp;#39;s about it. I knew 4TB+ was all SMR but I thought a few 1TB or 2TB models would still be CMR.&lt;/p&gt;\n\n&lt;p&gt;The reason I&amp;#39;m asking (which makes less sense the more I think about it) is because I was looking for some cheap local storage for an SFF secondary build. The drive is expected to write 300~500GB and read ~1.5x that amount per day. If the drive was SMR and randomly kept dropping to 15MBps, I&amp;#39;d be better of just accessing the data from the network instead.&lt;/p&gt;\n\n&lt;p&gt;TBW is where I ran into my first issue. Regular laptop HDDs (the one&amp;#39;s I was expecting to find) are only rated for 55TB/Y. My estimated usage blows that out of the water meaning I should be looking at the EXOS lineup with 550TB/Y. But those are so expensive I&amp;#39;d be better off getting a decent SSD instead.&lt;/p&gt;\n\n&lt;p&gt;Now I have to figure out if I want to save $100, forgo the SSD and just read the data from my server instead of buying an SSD and caching data locally...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "vTrueNAS 72TB ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypik0j", "is_robot_indexable": true, "report_reasons": null, "author": "KRS_88", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypik0j/do_25_cmr_drives_just_not_exist_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypik0j/do_25_cmr_drives_just_not_exist_anymore/", "subreddit_subscribers": 652591, "created_utc": 1667904745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "They're either about $140 or $20. I know the $20 ones have to be a scam. I just don't understand what their angle is. When I start writing 1 TB of data to it and it doesn't read it all back, it's going to be obvious it's a lower capacity device hacked to claim it's higher capacity. Or, if it actually will store the full 1 TB, it's some flaky off-brand tech that has the shelf life of unrefrigerated milk.\n\nFor durable, on-person backup, what's a line of microSD cards this community likes?", "author_fullname": "t2_5bccnsml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the deal with 1 TB microSD cards?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq5mkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667959684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They&amp;#39;re either about $140 or $20. I know the $20 ones have to be a scam. I just don&amp;#39;t understand what their angle is. When I start writing 1 TB of data to it and it doesn&amp;#39;t read it all back, it&amp;#39;s going to be obvious it&amp;#39;s a lower capacity device hacked to claim it&amp;#39;s higher capacity. Or, if it actually will store the full 1 TB, it&amp;#39;s some flaky off-brand tech that has the shelf life of unrefrigerated milk.&lt;/p&gt;\n\n&lt;p&gt;For durable, on-person backup, what&amp;#39;s a line of microSD cards this community likes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq5mkq", "is_robot_indexable": true, "report_reasons": null, "author": "GunzAndCamo", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq5mkq/whats_the_deal_with_1_tb_microsd_cards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq5mkq/whats_the_deal_with_1_tb_microsd_cards/", "subreddit_subscribers": 652591, "created_utc": 1667959684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Source code: https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py\n\nWindows executable: https://github.com/n0x5/scripts/releases/tag/google_vision_v2\n\nThis script uploads an image to the Google Cloud Vision AI and then saves the entire result in a .json file in the same folder as the image. The downside is you need a google account and billing enabled in Google Cloud dashboard, but there are 1000 requests / month for free which is pretty usable IMO.\n\nThe resulting .json file looks like this: https://i.imgur.com/lCQBYH5.png\n\nYou can pass 2 parameters:\n\n--file &lt;filepath&gt; - for single image recognition\n\n--folder &lt;folderpath&gt; for recursive scan of an entire folder.\n\nI also created an .exe that doesn't need Python or the libraries installed. It is compiled with pyinstaller. \n\nSetup guide:\n\n1) Go to https://console.developers.google.com/\n\n2) Click 'Credentials' in left side menu\n\n3) Create \"create credentials\" - &gt; \"OAuth client ID\"\n\n4) Select \"Desktop app\" in \"Application type\". Use any name you want, mine is \"Desktop client 1\"\n\n5) Go back to the Credentials main page and click the Download OAuth client link to the left of the \"Desktop client 1\" in the list.\n\n6) The .json file downloads in browser, so just rename it to \"credentials.json\" and place it in the same folder as Vision_API_V2.py/exe and then run it with --file to a single file to initiate.\n\n7) The browser will open to a Google page to authorize the app to access the account, click accept etc. Finished.\n\nSetup guide for python:\n\nIf you don't want to use the executable and you don't have Python you have to go to www.python.org, download the latest version, then run the following command:\n\n    pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nAfter this you should follow the earlier guide to setup Google OAuth.\n\nAlso some extra info:\n\nI wasn't sure what format or database to save it to, so I thought it's better to just save the .json as it is from google because no matter what the format, you need some sort of program to parse it anyway (although the .json is just a text file you can open in text editor). I did think about creating some kind of browser/UI but open to any suggestions for how to store it or how to parse it or any other things. Thanks", "author_fullname": "t2_378xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a script to recursively scan an image folder to Google Vision AI for image recognition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yppphp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667921706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Source code: &lt;a href=\"https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py\"&gt;https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Windows executable: &lt;a href=\"https://github.com/n0x5/scripts/releases/tag/google_vision_v2\"&gt;https://github.com/n0x5/scripts/releases/tag/google_vision_v2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This script uploads an image to the Google Cloud Vision AI and then saves the entire result in a .json file in the same folder as the image. The downside is you need a google account and billing enabled in Google Cloud dashboard, but there are 1000 requests / month for free which is pretty usable IMO.&lt;/p&gt;\n\n&lt;p&gt;The resulting .json file looks like this: &lt;a href=\"https://i.imgur.com/lCQBYH5.png\"&gt;https://i.imgur.com/lCQBYH5.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can pass 2 parameters:&lt;/p&gt;\n\n&lt;p&gt;--file &amp;lt;filepath&amp;gt; - for single image recognition&lt;/p&gt;\n\n&lt;p&gt;--folder &amp;lt;folderpath&amp;gt; for recursive scan of an entire folder.&lt;/p&gt;\n\n&lt;p&gt;I also created an .exe that doesn&amp;#39;t need Python or the libraries installed. It is compiled with pyinstaller. &lt;/p&gt;\n\n&lt;p&gt;Setup guide:&lt;/p&gt;\n\n&lt;p&gt;1) Go to &lt;a href=\"https://console.developers.google.com/\"&gt;https://console.developers.google.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2) Click &amp;#39;Credentials&amp;#39; in left side menu&lt;/p&gt;\n\n&lt;p&gt;3) Create &amp;quot;create credentials&amp;quot; - &amp;gt; &amp;quot;OAuth client ID&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;4) Select &amp;quot;Desktop app&amp;quot; in &amp;quot;Application type&amp;quot;. Use any name you want, mine is &amp;quot;Desktop client 1&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;5) Go back to the Credentials main page and click the Download OAuth client link to the left of the &amp;quot;Desktop client 1&amp;quot; in the list.&lt;/p&gt;\n\n&lt;p&gt;6) The .json file downloads in browser, so just rename it to &amp;quot;credentials.json&amp;quot; and place it in the same folder as Vision_API_V2.py/exe and then run it with --file to a single file to initiate.&lt;/p&gt;\n\n&lt;p&gt;7) The browser will open to a Google page to authorize the app to access the account, click accept etc. Finished.&lt;/p&gt;\n\n&lt;p&gt;Setup guide for python:&lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t want to use the executable and you don&amp;#39;t have Python you have to go to &lt;a href=\"http://www.python.org\"&gt;www.python.org&lt;/a&gt;, download the latest version, then run the following command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;After this you should follow the earlier guide to setup Google OAuth.&lt;/p&gt;\n\n&lt;p&gt;Also some extra info:&lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t sure what format or database to save it to, so I thought it&amp;#39;s better to just save the .json as it is from google because no matter what the format, you need some sort of program to parse it anyway (although the .json is just a text file you can open in text editor). I did think about creating some kind of browser/UI but open to any suggestions for how to store it or how to parse it or any other things. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?auto=webp&amp;s=c01c055b663941fe246888572be1bf8be8a7a520", "width": 681, "height": 771}, "resolutions": [{"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=099014c1e935a6ae87abe7dd725cde5ca5b4fc68", "width": 108, "height": 122}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e199c542005f3799ad9cf24eb0a0f437acd7a67", "width": 216, "height": 244}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=420a13a82cbd157af63aa8d94d15e65220611697", "width": 320, "height": 362}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2bbe4578b3feb1d6d8b1a80a9f1892bd1f56027", "width": 640, "height": 724}], "variants": {}, "id": "Ch5PxhWuk4icRlGEXHG3CoUrcSxfmnWtCOcXnvvSr3I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yppphp", "is_robot_indexable": true, "report_reasons": null, "author": "ouija", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yppphp/i_created_a_script_to_recursively_scan_an_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yppphp/i_created_a_script_to_recursively_scan_an_image/", "subreddit_subscribers": 652591, "created_utc": 1667921706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It was disappointing that I was struggling to find well seeded or existing classic release Linux distros that were so easy to find when they were first released.\n\nThen I discovered Usenet. My eyes have been opened.", "author_fullname": "t2_b8r6aj5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After years of hoarding, and then several years without, I felt like I missed out on the golden age.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypnmbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Editable Flair", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667917216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It was disappointing that I was struggling to find well seeded or existing classic release Linux distros that were so easy to find when they were first released.&lt;/p&gt;\n\n&lt;p&gt;Then I discovered Usenet. My eyes have been opened.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ypnmbt", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Professional3832", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypnmbt/after_years_of_hoarding_and_then_several_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypnmbt/after_years_of_hoarding_and_then_several_years/", "subreddit_subscribers": 652591, "created_utc": 1667917216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I looked around on google and the sub, but I would like an up to date answer. \n\nI have a lot of hobby projects (Not very sensitive data) that I work on. I keep them backed up and synced to a cloud, so I can 1) revert files back to earlier versions, and 2) if my house burns down I can still retrieve my files. \n\nMy free OneDrive just filled up, so I am looking for a paid cloud storage now, where I can continue to keep my projects backed up.\n\nI would like to avoid a learning curve, and I would like everything to be as automated/easy as possible. I also don't want to be spending too much money, as I will probably just keep my subscription for the next 20+ years.\n\nCan anyone help?", "author_fullname": "t2_m7d9qp32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best casual cloud storage per TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypwfqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667936764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I looked around on google and the sub, but I would like an up to date answer. &lt;/p&gt;\n\n&lt;p&gt;I have a lot of hobby projects (Not very sensitive data) that I work on. I keep them backed up and synced to a cloud, so I can 1) revert files back to earlier versions, and 2) if my house burns down I can still retrieve my files. &lt;/p&gt;\n\n&lt;p&gt;My free OneDrive just filled up, so I am looking for a paid cloud storage now, where I can continue to keep my projects backed up.&lt;/p&gt;\n\n&lt;p&gt;I would like to avoid a learning curve, and I would like everything to be as automated/easy as possible. I also don&amp;#39;t want to be spending too much money, as I will probably just keep my subscription for the next 20+ years.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypwfqm", "is_robot_indexable": true, "report_reasons": null, "author": "CutiePatootieLootie", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypwfqm/best_casual_cloud_storage_per_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypwfqm/best_casual_cloud_storage_per_tb/", "subreddit_subscribers": 652591, "created_utc": 1667936764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to expand my hoard with a lot of ebooks, as I recently got an older iPad and want to get back into reading. I know Kaggle has a WikiBooks dataset but I was thinking more like sci-fi/fantasy stuff. Anyone know of good sources to start a digital library?", "author_fullname": "t2_mr4t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good place to find large collections of ebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypn5m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to expand my hoard with a lot of ebooks, as I recently got an older iPad and want to get back into reading. I know Kaggle has a WikiBooks dataset but I was thinking more like sci-fi/fantasy stuff. Anyone know of good sources to start a digital library?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1PB goal", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypn5m3", "is_robot_indexable": true, "report_reasons": null, "author": "grabmyrooster", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypn5m3/good_place_to_find_large_collections_of_ebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypn5m3/good_place_to_find_large_collections_of_ebooks/", "subreddit_subscribers": 652591, "created_utc": 1667916203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about four 1tb and two 500gig hdds just taking up space. Is it worth keeping them and setting up zfs partition? I\u2019d probably get like 4tb of usable space. I can take them apart and extract the magnets but I have a ton of those already \ud83d\ude02", "author_fullname": "t2_ggeqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with spare 1tb and 500gig hdds?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yqa3d4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667973127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about four 1tb and two 500gig hdds just taking up space. Is it worth keeping them and setting up zfs partition? I\u2019d probably get like 4tb of usable space. I can take them apart and extract the magnets but I have a ton of those already \ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yqa3d4", "is_robot_indexable": true, "report_reasons": null, "author": "accent2012", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yqa3d4/what_to_do_with_spare_1tb_and_500gig_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yqa3d4/what_to_do_with_spare_1tb_and_500gig_hdds/", "subreddit_subscribers": 652591, "created_utc": 1667973127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was told to crosspost this here: Getting storage error when moving mods despite having more than enough space on hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3xtf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5xg6l51", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "skyrimmods", "selftext": "Hi folks, I'm trying to move my MO2 mods from a 500 GB drive to my 1 TB drive, and I keep getting this error ([https://imgur.com/a/Iqh79rn](https://imgur.com/a/Iqh79rn)). I have checked and have a LOT of room on this drive, so I don't understand why it won't let me move them. There's also the additional confusion of saying that there \"isn't enough space on X\" where X is the name of a folder within the mod. I'm at a loss and any info would be greatly appreciated. Thanks!", "author_fullname": "t2_5xg6l51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting storage error when moving mods despite having more than enough space on hard drive", "link_flair_richtext": [{"e": "text", "t": "PC SSE - Help"}], "subreddit_name_prefixed": "r/skyrimmods", "hidden": false, "pwls": 6, "link_flair_css_class": "pc help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3cuk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "PC SSE - Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667953394.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.skyrimmods", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I&amp;#39;m trying to move my MO2 mods from a 500 GB drive to my 1 TB drive, and I keep getting this error (&lt;a href=\"https://imgur.com/a/Iqh79rn\"&gt;https://imgur.com/a/Iqh79rn&lt;/a&gt;). I have checked and have a LOT of room on this drive, so I don&amp;#39;t understand why it won&amp;#39;t let me move them. There&amp;#39;s also the additional confusion of saying that there &amp;quot;isn&amp;#39;t enough space on X&amp;quot; where X is the name of a folder within the mod. I&amp;#39;m at a loss and any info would be greatly appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?auto=webp&amp;s=582e8c916e2ba72f81def226bae5d7d2d4c4f266", "width": 788, "height": 497}, "resolutions": [{"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1205cf84f08dcab61057b4881b1fa609ec70662c", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f6de7c2850c303338319c5869ffa46cfc433e75", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e0b0f951039bf92802a4be34b8ae98b7fbeade6", "width": 320, "height": 201}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1288ff7abb4f9941fd525573e5010fa48f59cb4", "width": 640, "height": 403}], "variants": {}, "id": "s8zk_JESvU1TJolUPHXZdfpR9Ek1VJbTNKTX-Sus-Zo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bdae4814-a9d9-11e4-a87a-22000bb26ab4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sqqh", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yq3cuk", "is_robot_indexable": true, "report_reasons": null, "author": "moss_back", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "subreddit_subscribers": 384200, "created_utc": 1667953394.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1667954984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.skyrimmods", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?auto=webp&amp;s=582e8c916e2ba72f81def226bae5d7d2d4c4f266", "width": 788, "height": 497}, "resolutions": [{"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1205cf84f08dcab61057b4881b1fa609ec70662c", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f6de7c2850c303338319c5869ffa46cfc433e75", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e0b0f951039bf92802a4be34b8ae98b7fbeade6", "width": 320, "height": 201}, {"url": "https://external-preview.redd.it/RQWc207ww-6CtxlDDTnlrsw8x8VOpg0YOC0F22jqydU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1288ff7abb4f9941fd525573e5010fa48f59cb4", "width": 640, "height": 403}], "variants": {}, "id": "s8zk_JESvU1TJolUPHXZdfpR9Ek1VJbTNKTX-Sus-Zo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq3xtf", "is_robot_indexable": true, "report_reasons": null, "author": "moss_back", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_yq3cuk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq3xtf/was_told_to_crosspost_this_here_getting_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/skyrimmods/comments/yq3cuk/getting_storage_error_when_moving_mods_despite/", "subreddit_subscribers": 652591, "created_utc": 1667954984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The only method I know of is where you borrow the book, zoom in, open up Developer Tools **\u2192** Network **\u2192** Img, flip through the book and download the JPGs one by one. Is there an easy method where I could download them in a batch? I don't know code or anything like that so I'm at a lost.", "author_fullname": "t2_3z0vqk63", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way of downloading picture books in the HIGHEST quality on Internet Archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypzh74", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667943781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The only method I know of is where you borrow the book, zoom in, open up Developer Tools &lt;strong&gt;\u2192&lt;/strong&gt; Network &lt;strong&gt;\u2192&lt;/strong&gt; Img, flip through the book and download the JPGs one by one. Is there an easy method where I could download them in a batch? I don&amp;#39;t know code or anything like that so I&amp;#39;m at a lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypzh74", "is_robot_indexable": true, "report_reasons": null, "author": "jeruthemaster", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypzh74/best_way_of_downloading_picture_books_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypzh74/best_way_of_downloading_picture_books_in_the/", "subreddit_subscribers": 652591, "created_utc": 1667943781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I suspect it has been asked and answered, and a reference to a post would be great. \n\n&amp;#x200B;\n\n**What does everyone use to make their own collections available from their own NAS to the internet so you can access your own material securely and easily to either stream or download what you want at will?** \n\n&amp;#x200B;\n\nI usually travel with an ipad or a laptop, so something that is compatible across platforms and easily usable would be ideal.\n\n&amp;#x200B;\n\n**Many thanks!**", "author_fullname": "t2_27akqj9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to stream or self server your own NAS as cloud storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvmwb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I suspect it has been asked and answered, and a reference to a post would be great. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What does everyone use to make their own collections available from their own NAS to the internet so you can access your own material securely and easily to either stream or download what you want at will?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I usually travel with an ipad or a laptop, so something that is compatible across platforms and easily usable would be ideal.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Many thanks!&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypvmwb", "is_robot_indexable": true, "report_reasons": null, "author": "Chance-Pie6495", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypvmwb/best_way_to_stream_or_self_server_your_own_nas_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypvmwb/best_way_to_stream_or_self_server_your_own_nas_as/", "subreddit_subscribers": 652591, "created_utc": 1667934910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just received my first \"returned\" WD drive from Amazon.  As soon as I opened the box, which was still sealed, on the top anyway, I could tell what was up.  Both sides of the case were broken open.  For giggles I went ahead and connected it to the PC.  It was recognized as 500GB (should be 16TB) , and still contained a Windows install, complete with user name (Mr Dan Hoffman).", "author_fullname": "t2_3wf6rrz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"New\" WD external drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvkx5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just received my first &amp;quot;returned&amp;quot; WD drive from Amazon.  As soon as I opened the box, which was still sealed, on the top anyway, I could tell what was up.  Both sides of the case were broken open.  For giggles I went ahead and connected it to the PC.  It was recognized as 500GB (should be 16TB) , and still contained a Windows install, complete with user name (Mr Dan Hoffman).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "60TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ypvkx5", "is_robot_indexable": true, "report_reasons": null, "author": "joe-dirt-1001", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypvkx5/new_wd_external_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypvkx5/new_wd_external_drive/", "subreddit_subscribers": 652591, "created_utc": 1667934786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Noob here. I have been sorting through all these files from my past, and I thankfully have already been keeping a log of checksums for all of the files. Every time I save a new file in my 3-2-1 system, I log the checksum. That way, any time I encounter some file on an old drive I find, or someone sends me something from long ago, I can search the log for the checksum, and I'll know if I already have it or not, regardless of what we named the file. I also just like having the checksums in general, so I know the data is always good from when I received it.\n\nThis has worked for me, and helped me avoid saving many many duplicates. I use a custom script to log everything to a single .tsv file, and I use bash to parse through it when needed. It's not pretty (nor ugly), but I figured I'd ask if I'm reinventing the wheel here, and if there is any software that does this, or if there are any better methods out there? I'd also like to know if this is extremely inefficient (say, if I wanted to do it for an entire drive at once). Also, I currently use the SHA256 algo, even though I know faster algos have very low chance of collision anyway.\n\nI would appreciate any critiques/input on this workflow. TIA!", "author_fullname": "t2_445vu7eo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Criticism please: Is there a better way to log checksums of all my files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypv7ew", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Noob here. I have been sorting through all these files from my past, and I thankfully have already been keeping a log of checksums for all of the files. Every time I save a new file in my 3-2-1 system, I log the checksum. That way, any time I encounter some file on an old drive I find, or someone sends me something from long ago, I can search the log for the checksum, and I&amp;#39;ll know if I already have it or not, regardless of what we named the file. I also just like having the checksums in general, so I know the data is always good from when I received it.&lt;/p&gt;\n\n&lt;p&gt;This has worked for me, and helped me avoid saving many many duplicates. I use a custom script to log everything to a single .tsv file, and I use bash to parse through it when needed. It&amp;#39;s not pretty (nor ugly), but I figured I&amp;#39;d ask if I&amp;#39;m reinventing the wheel here, and if there is any software that does this, or if there are any better methods out there? I&amp;#39;d also like to know if this is extremely inefficient (say, if I wanted to do it for an entire drive at once). Also, I currently use the SHA256 algo, even though I know faster algos have very low chance of collision anyway.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any critiques/input on this workflow. TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypv7ew", "is_robot_indexable": true, "report_reasons": null, "author": "Hooked__On__Chronics", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypv7ew/criticism_please_is_there_a_better_way_to_log/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypv7ew/criticism_please_is_there_a_better_way_to_log/", "subreddit_subscribers": 652591, "created_utc": 1667933940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow hoarders, \n\nI am a nut about pro wrestling and have an 8 TB drive that has many subfolders including one called Matches. This folder has just over 7,000 video files in folders like this:\n\n **Decade** \n\nYear\n\nYYYY.MM.DD Compay X vs X\n\n&amp;#x200B;\n\nWhat I am looking to do is to be able to A) Export the file names to Excel to better track them. B) Be able to easily find duplicates that I may have.\n\nHoping for some guidance from the sub, thanks in advance!!", "author_fullname": "t2_qtmcicrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organize and list/look for dups in excel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypuz8r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow hoarders, &lt;/p&gt;\n\n&lt;p&gt;I am a nut about pro wrestling and have an 8 TB drive that has many subfolders including one called Matches. This folder has just over 7,000 video files in folders like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Decade&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Year&lt;/p&gt;\n\n&lt;p&gt;YYYY.MM.DD Compay X vs X&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What I am looking to do is to be able to A) Export the file names to Excel to better track them. B) Be able to easily find duplicates that I may have.&lt;/p&gt;\n\n&lt;p&gt;Hoping for some guidance from the sub, thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypuz8r", "is_robot_indexable": true, "report_reasons": null, "author": "gargamels_right_boot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypuz8r/organize_and_listlook_for_dups_in_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypuz8r/organize_and_listlook_for_dups_in_excel/", "subreddit_subscribers": 652591, "created_utc": 1667933422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know buying an internal hard drive + enclosure is almost always better but I'm looking for 4 or 5TB of storage in a small form factor for traveling. \n\nIs there a list of smaller capacity external HDDs that don't have the sata connector soldered onto the USB adapter? [https://shucks.top/](https://shucks.top/) only has WD drives and they start at 8TB.", "author_fullname": "t2_2xo37qk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which external HDDs don't have the sata connector soldered onto the USB adapter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypu4ob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667931490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know buying an internal hard drive + enclosure is almost always better but I&amp;#39;m looking for 4 or 5TB of storage in a small form factor for traveling. &lt;/p&gt;\n\n&lt;p&gt;Is there a list of smaller capacity external HDDs that don&amp;#39;t have the sata connector soldered onto the USB adapter? &lt;a href=\"https://shucks.top/\"&gt;https://shucks.top/&lt;/a&gt; only has WD drives and they start at 8TB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?auto=webp&amp;s=4305af1baddc4e2ce299670a6b101ab1b7117895", "width": 512, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=262b84cd4e22f5efb49272c5faff423c8e19100c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c8e6634d0f9c8deea9e61cb2b4ed3a1186d0c1b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jTe2BiFHTYoveMp07wA0QW8J-O8gPJVXV8opK8G_jhg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6321c8f7388444b25dfc26f9b70396d92b51363", "width": 320, "height": 160}], "variants": {}, "id": "mXTY-ElzykgJ9hWy66sBlD2xbZ60EVow9UyVqQ-TUEU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypu4ob", "is_robot_indexable": true, "report_reasons": null, "author": "owta150", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypu4ob/which_external_hdds_dont_have_the_sata_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypu4ob/which_external_hdds_dont_have_the_sata_connector/", "subreddit_subscribers": 652591, "created_utc": 1667931490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am thinking about building a very simple Pi NAS. Like, one 1 or 2TB external SSD hooked into my home network via ethernet. I am a total noob at this stuff. For redundancy maybe pay google $2 a month for cloud storage or something.\n\nRight now this is honestly more of a solution in search of a problem; I just like to tinker mainly. Thinking it'll just be a place to stick important files without too much trouble. Here is what I would like to be able to do:\n\n&amp;#x200B;\n\n* Stick family photos and videos on, from any source (Windows, macOS, iOS)\n* Stick important docs on (old tax turbo tax PDFs, etc)\n* Maybe stick some music files on\n\nImportantly, be able to VIEW and edit the files if needed. Specifically I am thinking about our pics, which are incredibly disorganized, duplicated, etc. Would like to be able to open up the iPad and go through the NAS and be like \"that one sucks, DELETE... that one is upside down, FIX.... Create a \"wedding pictures\" folder and move all these pics over there.... etc\\*\"\n\nIs all that possible?\n\n*\\*One thing that I am not clear on... let's say I go to a folder full of pics on the NAS and start editing them on an iPAD (or whatever device, PC, MAC, etc). Am I using whatever photo viewing / editing SW to view and edit the file residing on the NAS (i.e. the SW is acting like a \"window\" to look at the file still residing on another computer).... or am I pulling the file ONTO the device, making changes, and then when I hit \"save\" it overwrites (uploads) the new file to the NAS?*\n\n*I am not sure there is a fundamental difference in outcome but just wondering.*", "author_fullname": "t2_ltj899zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about potential Pi NAS - dumb question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypsvwg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1667928873.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667928671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking about building a very simple Pi NAS. Like, one 1 or 2TB external SSD hooked into my home network via ethernet. I am a total noob at this stuff. For redundancy maybe pay google $2 a month for cloud storage or something.&lt;/p&gt;\n\n&lt;p&gt;Right now this is honestly more of a solution in search of a problem; I just like to tinker mainly. Thinking it&amp;#39;ll just be a place to stick important files without too much trouble. Here is what I would like to be able to do:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Stick family photos and videos on, from any source (Windows, macOS, iOS)&lt;/li&gt;\n&lt;li&gt;Stick important docs on (old tax turbo tax PDFs, etc)&lt;/li&gt;\n&lt;li&gt;Maybe stick some music files on&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Importantly, be able to VIEW and edit the files if needed. Specifically I am thinking about our pics, which are incredibly disorganized, duplicated, etc. Would like to be able to open up the iPad and go through the NAS and be like &amp;quot;that one sucks, DELETE... that one is upside down, FIX.... Create a &amp;quot;wedding pictures&amp;quot; folder and move all these pics over there.... etc*&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Is all that possible?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;\\&lt;/em&gt;One thing that I am not clear on... let&amp;#39;s say I go to a folder full of pics on the NAS and start editing them on an iPAD (or whatever device, PC, MAC, etc). Am I using whatever photo viewing / editing SW to view and edit the file residing on the NAS (i.e. the SW is acting like a &amp;quot;window&amp;quot; to look at the file still residing on another computer).... or am I pulling the file ONTO the device, making changes, and then when I hit &amp;quot;save&amp;quot; it overwrites (uploads) the new file to the NAS?*&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I am not sure there is a fundamental difference in outcome but just wondering.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypsvwg", "is_robot_indexable": true, "report_reasons": null, "author": "_How_Can_She_Slap_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypsvwg/question_about_potential_pi_nas_dumb_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypsvwg/question_about_potential_pi_nas_dumb_question/", "subreddit_subscribers": 652591, "created_utc": 1667928671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had an issue and I fee like there are too many brilliant people on this sub for there to not be some kind of solution or recommendation for it.    \n\n\nI'm looking to setup a tagging and indexing system for my documents collection and was wondering if anyone could recommend the best software approach. I have several TB worth of documents (PDF, Doc, txt, and Epub etc.) as well as video (avi, mp4, m4v), images (png, jpg, tif), and audio files and I want away to \n\n* Filter by file type(s)\n* Manually assign tags to them and filter by those tags\n* Have a way to index specific files (mostly the document files), so that their contents are also searchable. \n\nHas anyone created a system that could do this? Was this a custom solution or is there existing software?", "author_fullname": "t2_9dk8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a tagging and search system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypopme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had an issue and I fee like there are too many brilliant people on this sub for there to not be some kind of solution or recommendation for it.    &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to setup a tagging and indexing system for my documents collection and was wondering if anyone could recommend the best software approach. I have several TB worth of documents (PDF, Doc, txt, and Epub etc.) as well as video (avi, mp4, m4v), images (png, jpg, tif), and audio files and I want away to &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Filter by file type(s)&lt;/li&gt;\n&lt;li&gt;Manually assign tags to them and filter by those tags&lt;/li&gt;\n&lt;li&gt;Have a way to index specific files (mostly the document files), so that their contents are also searchable. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Has anyone created a system that could do this? Was this a custom solution or is there existing software?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypopme", "is_robot_indexable": true, "report_reasons": null, "author": "funke75", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypopme/setting_up_a_tagging_and_search_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypopme/setting_up_a_tagging_and_search_system/", "subreddit_subscribers": 652591, "created_utc": 1667919613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nFirst time posting here and just wanted some opinions.  \n\nSo I'm cleaning out my IT closet and found a perfectly good old PC.  Nothing special just the unit I used to get thru college.\n\nI'm thinking of implementing TruNAS on it.  It is a i3 2gen intel with 16gigs ram.  I figured I'd throw a couple SSD in it and just use it as a NAS. No GPU and plane jane heat sync.\n\nDo you guys think it will work? What type of performance do you think I can get out of it? (i'll be storing movies, music on it)  What CPU works best for it?", "author_fullname": "t2_6g3iru0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old PC into a NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypmhyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667914731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;First time posting here and just wanted some opinions.  &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m cleaning out my IT closet and found a perfectly good old PC.  Nothing special just the unit I used to get thru college.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of implementing TruNAS on it.  It is a i3 2gen intel with 16gigs ram.  I figured I&amp;#39;d throw a couple SSD in it and just use it as a NAS. No GPU and plane jane heat sync.&lt;/p&gt;\n\n&lt;p&gt;Do you guys think it will work? What type of performance do you think I can get out of it? (i&amp;#39;ll be storing movies, music on it)  What CPU works best for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypmhyk", "is_robot_indexable": true, "report_reasons": null, "author": "KaiSimple", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypmhyk/old_pc_into_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypmhyk/old_pc_into_a_nas/", "subreddit_subscribers": 652591, "created_utc": 1667914731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I finally hit that point that everyone told me would happen - I've outgrown my 2-bay Synology, and I want something bigger. I would just get a bigger Synology, but...I really want something rack-mounted. I'm OK paying the rack tax just for the convenience factor, but I am struggling to make the right choice for it. For reference, I LOVE my Synology, and use it for a bunch of different things (media serving, backups for other devices, Docker containers).\n\nOption 1 - Synology RS822+. Literally exactly what I need. 4-bays with higher-capacity drives will suffice unless/until my data storage needs fundamentally change, and there is the RX418 available in that case. As mentioned before, I love my Synology. I would look at the RS422+, but not having expandable memory is a deal-breaker. The cost though is making me hesitant - $1k is a lot of money for a closed-source appliance that I can't repair/reuse for different purposes.\n\nOption 2 - Custom Unraid box. I am totally fine with messing around with something that requires more setup or is less user-friendly than normal consumer products, but I don't want it to become a chore. That said...I can build one of these for a few hundred bucks cheaper than a Synology that will provide me more flexibility and easier repair/upgrades in the future.  My biggest issues is finding a case that will give me at least 4 3.5\" bays and is less than 19\" long - preferably in a 2u form factor.\n\n&amp;#x200B;\n\nAny thoughts either way? And if an Unraid box is my best bet, has anyone tried these cases out before, or have suggestions?\n\nThis looks perfect, but seems to be some sort of custom item....[http://www.plinkusa.net/webITX-S2082](http://www.plinkusa.net/webITX-S2082)\n\nThis Silverstone case also looks good, but is $$$: [https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/](https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/)\n\nThis Rosewill case is cheaper, but only supports 6 drives and doesn't have front-access drives (not a huge deal TBH): [https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179](https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179)", "author_fullname": "t2_16irvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing DS220+ with another Synology, custom box, or ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq2bqv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667950970.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667950698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally hit that point that everyone told me would happen - I&amp;#39;ve outgrown my 2-bay Synology, and I want something bigger. I would just get a bigger Synology, but...I really want something rack-mounted. I&amp;#39;m OK paying the rack tax just for the convenience factor, but I am struggling to make the right choice for it. For reference, I LOVE my Synology, and use it for a bunch of different things (media serving, backups for other devices, Docker containers).&lt;/p&gt;\n\n&lt;p&gt;Option 1 - Synology RS822+. Literally exactly what I need. 4-bays with higher-capacity drives will suffice unless/until my data storage needs fundamentally change, and there is the RX418 available in that case. As mentioned before, I love my Synology. I would look at the RS422+, but not having expandable memory is a deal-breaker. The cost though is making me hesitant - $1k is a lot of money for a closed-source appliance that I can&amp;#39;t repair/reuse for different purposes.&lt;/p&gt;\n\n&lt;p&gt;Option 2 - Custom Unraid box. I am totally fine with messing around with something that requires more setup or is less user-friendly than normal consumer products, but I don&amp;#39;t want it to become a chore. That said...I can build one of these for a few hundred bucks cheaper than a Synology that will provide me more flexibility and easier repair/upgrades in the future.  My biggest issues is finding a case that will give me at least 4 3.5&amp;quot; bays and is less than 19&amp;quot; long - preferably in a 2u form factor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts either way? And if an Unraid box is my best bet, has anyone tried these cases out before, or have suggestions?&lt;/p&gt;\n\n&lt;p&gt;This looks perfect, but seems to be some sort of custom item....&lt;a href=\"http://www.plinkusa.net/webITX-S2082\"&gt;http://www.plinkusa.net/webITX-S2082&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This Silverstone case also looks good, but is $$$: &lt;a href=\"https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/\"&gt;https://www.silverstonetek.com/en/product/info/computer-chassis/RM21-308/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This Rosewill case is cheaper, but only supports 6 drives and doesn&amp;#39;t have front-access drives (not a huge deal TBH): &lt;a href=\"https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179\"&gt;https://www.rosewill.com/rosewill-rsv-z2800u-silver/p/9SIA072J2Y5179&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq2bqv", "is_robot_indexable": true, "report_reasons": null, "author": "icelandismine", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq2bqv/replacing_ds220_with_another_synology_custom_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq2bqv/replacing_ds220_with_another_synology_custom_box/", "subreddit_subscribers": 652591, "created_utc": 1667950698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For context - have to make a video for school, so I\u2019m making a \u201ccommentary\u201d style video where I will talk about the subject while showing clips of the situation taking place. \n\nI found the show I\u2019m looking to do my video on, on Prime Video. How do I save clips from movies/videos on Prime and upload them to a platform such as iMovie? \n\nI have a 2018 MacBook Air if that matters.\n\nEdit: looking for a way to do this for free. If not possible - looking to pay the smallest amount possible :)", "author_fullname": "t2_6mmit6l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I save clips from shows/movies on Prime Video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq23r2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667950152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context - have to make a video for school, so I\u2019m making a \u201ccommentary\u201d style video where I will talk about the subject while showing clips of the situation taking place. &lt;/p&gt;\n\n&lt;p&gt;I found the show I\u2019m looking to do my video on, on Prime Video. How do I save clips from movies/videos on Prime and upload them to a platform such as iMovie? &lt;/p&gt;\n\n&lt;p&gt;I have a 2018 MacBook Air if that matters.&lt;/p&gt;\n\n&lt;p&gt;Edit: looking for a way to do this for free. If not possible - looking to pay the smallest amount possible :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yq23r2", "is_robot_indexable": true, "report_reasons": null, "author": "n0tebook6", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yq23r2/how_do_i_save_clips_from_showsmovies_on_prime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yq23r2/how_do_i_save_clips_from_showsmovies_on_prime/", "subreddit_subscribers": 652591, "created_utc": 1667950152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone find a corkboard selfhost tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypz7tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_9qz1zwov", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I want to organize a bunch of notes in corkboard style however anything would be useful I suppose. Some in which, yes will be connected to one another therefore needing a proper way to be sorted and categorized to each other in one screen.  \n\n\n I would greatly appreciate whoever gives me a solution for this.", "author_fullname": "t2_9qz1zwov", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone find a corkboard selfhost tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypyy8q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667942594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to organize a bunch of notes in corkboard style however anything would be useful I suppose. Some in which, yes will be connected to one another therefore needing a proper way to be sorted and categorized to each other in one screen.  &lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate whoever gives me a solution for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypyy8q", "is_robot_indexable": true, "report_reasons": null, "author": "RisingFire2", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/ypyy8q/anyone_find_a_corkboard_selfhost_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/ypyy8q/anyone_find_a_corkboard_selfhost_tool/", "subreddit_subscribers": 209021, "created_utc": 1667942594.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1667943181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/selfhosted/comments/ypyy8q/anyone_find_a_corkboard_selfhost_tool/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypz7tn", "is_robot_indexable": true, "report_reasons": null, "author": "RisingFire2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ypyy8q", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypz7tn/anyone_find_a_corkboard_selfhost_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/selfhosted/comments/ypyy8q/anyone_find_a_corkboard_selfhost_tool/", "subreddit_subscribers": 652591, "created_utc": 1667943181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello -Disclaimer-  I'm going to ask this question across a few subreddits. So anyone who complains about topic relevance can suck it.\n\nWe purchased a new NetApp FAS 8300, and the engine part of it is too long to fit into our racks that we rent at our hosting provider. (flexential)\n\nAt my office, we have another identical FAS 8300 and yes, it's huge but our rack has a door that was slightly 'popped' out, which allowed it to close. My hosting provider is trying to charge me for a new oversized rack, but we cannot be their only customer with NetApp.\n\nCurious if anyone out there has encountered this and found a way around it. (yes, the doors must close and lock, it's part of our SLA)", "author_fullname": "t2_4qohg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for ideas on oversized storage array", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvwzt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667935558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello -Disclaimer-  I&amp;#39;m going to ask this question across a few subreddits. So anyone who complains about topic relevance can suck it.&lt;/p&gt;\n\n&lt;p&gt;We purchased a new NetApp FAS 8300, and the engine part of it is too long to fit into our racks that we rent at our hosting provider. (flexential)&lt;/p&gt;\n\n&lt;p&gt;At my office, we have another identical FAS 8300 and yes, it&amp;#39;s huge but our rack has a door that was slightly &amp;#39;popped&amp;#39; out, which allowed it to close. My hosting provider is trying to charge me for a new oversized rack, but we cannot be their only customer with NetApp.&lt;/p&gt;\n\n&lt;p&gt;Curious if anyone out there has encountered this and found a way around it. (yes, the doors must close and lock, it&amp;#39;s part of our SLA)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypvwzt", "is_robot_indexable": true, "report_reasons": null, "author": "DustinAgain", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypvwzt/looking_for_ideas_on_oversized_storage_array/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypvwzt/looking_for_ideas_on_oversized_storage_array/", "subreddit_subscribers": 652591, "created_utc": 1667935558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Could I buy a bunch of random hard drives off of market place and get them to work together or is best practices to have the same drives?", "author_fullname": "t2_8a7rdp5f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Random Hard drives for a RAID system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypuv0z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could I buy a bunch of random hard drives off of market place and get them to work together or is best practices to have the same drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypuv0z", "is_robot_indexable": true, "report_reasons": null, "author": "AdEnvironmental7198", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypuv0z/random_hard_drives_for_a_raid_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypuv0z/random_hard_drives_for_a_raid_system/", "subreddit_subscribers": 652591, "created_utc": 1667933149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Had a drive fail in my 6x4TB raidz1 pool today and wondering the best way to insure I save my data. There is no other backup of the data (I know, shame me) and the drives are old and some are smr so another failure during resilver is possible.\n\nNow the data is a mix of music, movies and photos. The photos account for around 1 TB, music a few hundred gigs and movies about 13TB. The photos are most important as I can't replace those of I lose them but the music and movies could be replaced tho it would be a pain.\n\nMy thought is to copy the photos to another pool while this one is still degraded and then resilver the pool. If i lose a drive while copying it wasn't going to survive the resilver anyways and I get some of my data, if the copy completes and then a drive dies in resilver I save my photos which is what I care most about.\n\nAny flaws with this plan? Is there a better way to go about this?", "author_fullname": "t2_fpuhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Degraded Z1 zpool and copying data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypperd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667921071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had a drive fail in my 6x4TB raidz1 pool today and wondering the best way to insure I save my data. There is no other backup of the data (I know, shame me) and the drives are old and some are smr so another failure during resilver is possible.&lt;/p&gt;\n\n&lt;p&gt;Now the data is a mix of music, movies and photos. The photos account for around 1 TB, music a few hundred gigs and movies about 13TB. The photos are most important as I can&amp;#39;t replace those of I lose them but the music and movies could be replaced tho it would be a pain.&lt;/p&gt;\n\n&lt;p&gt;My thought is to copy the photos to another pool while this one is still degraded and then resilver the pool. If i lose a drive while copying it wasn&amp;#39;t going to survive the resilver anyways and I get some of my data, if the copy completes and then a drive dies in resilver I save my photos which is what I care most about.&lt;/p&gt;\n\n&lt;p&gt;Any flaws with this plan? Is there a better way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypperd", "is_robot_indexable": true, "report_reasons": null, "author": "TKFT_ExTr3m3", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypperd/degraded_z1_zpool_and_copying_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypperd/degraded_z1_zpool_and_copying_data/", "subreddit_subscribers": 652591, "created_utc": 1667921071.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}