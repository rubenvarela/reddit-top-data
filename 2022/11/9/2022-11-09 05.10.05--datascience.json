{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "People are obsessed with pursuing data science roles for some reason. I guess it's interesting work with a high skill ceiling. Thats why I'm pursuing it. But nobody talks about the data analyst. The folks who write SQL for reporting, create dashboards, and provide insights. Data science does do all this in a more sophisticated way, but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth. If you're struggling to get into data science, consider analytics. The pay is still good (100k plus if you're doing product analytics) and a natural growth path from there can totally be data science. Don't rule it out, you have options. End \ud83d\ude0a", "author_fullname": "t2_8o0eldke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "hot take: forget data science, we need more analysts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypr93q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 677, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 677, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667924978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People are obsessed with pursuing data science roles for some reason. I guess it&amp;#39;s interesting work with a high skill ceiling. Thats why I&amp;#39;m pursuing it. But nobody talks about the data analyst. The folks who write SQL for reporting, create dashboards, and provide insights. Data science does do all this in a more sophisticated way, but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth. If you&amp;#39;re struggling to get into data science, consider analytics. The pay is still good (100k plus if you&amp;#39;re doing product analytics) and a natural growth path from there can totally be data science. Don&amp;#39;t rule it out, you have options. End \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 200, "id": "award_1703f934-cf44-40cc-a96d-3729d0b48262", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "My kindergarten teacher, my cat, my mom, and you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "I'd Like to Thank...", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypr93q", "is_robot_indexable": true, "report_reasons": null, "author": "djaycat", "discussion_type": null, "num_comments": 145, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypr93q/hot_take_forget_data_science_we_need_more_analysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypr93q/hot_take_forget_data_science_we_need_more_analysts/", "subreddit_subscribers": 818306, "created_utc": 1667924978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I came across a recent post highlighting that one of the main points that bring others to hate DS people is their crappy code that they hand over to production, and it got me wondering:\n\nWhat is a \"clean\" or \"good\" code that you expect a good DS professional to hand you for production so that you don't hate him/her for it? It'd be good to get some pointers to avoid these mistakes in the future and be hated for them.\n\nAnd please don't reply \"depends on the situation\"; please give good generalisable advice.", "author_fullname": "t2_71lk6sl4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pointers to write \"clean\" code for production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yphayx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667901095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across a recent post highlighting that one of the main points that bring others to hate DS people is their crappy code that they hand over to production, and it got me wondering:&lt;/p&gt;\n\n&lt;p&gt;What is a &amp;quot;clean&amp;quot; or &amp;quot;good&amp;quot; code that you expect a good DS professional to hand you for production so that you don&amp;#39;t hate him/her for it? It&amp;#39;d be good to get some pointers to avoid these mistakes in the future and be hated for them.&lt;/p&gt;\n\n&lt;p&gt;And please don&amp;#39;t reply &amp;quot;depends on the situation&amp;quot;; please give good generalisable advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yphayx", "is_robot_indexable": true, "report_reasons": null, "author": "William_Rosebud", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yphayx/pointers_to_write_clean_code_for_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yphayx/pointers_to_write_clean_code_for_production/", "subreddit_subscribers": 818306, "created_utc": 1667901095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " In my work as a datascientist I use a lot of blackbox algoritms such as gradient boosting, random forrest and neural networks. One question I ALWAYS get from the business I'm making the models for is, what features are important? How does the model make descicions. So to answer that I do the usual feature analysis, correlation matrices, partial dependence plots, mdi, model extraction. But I still fill like I'm not entirely able to answer what variables are the most important for example.\n\nNow I was thinking of a new method to determine feature importance. First we need the trained model, and the feature distributions. If we take a feature, we look at the sorted values and take 11 values corresponding to 0% - 10% - .. - 100% of the feature distribution. Next we take for example 1000 random states of the other features and test per random state the 11 options for the selected feature. For this 11 values of the feature, we check the number of times the y-value (label) changes. After doing this for all features, we should have an order of feature importance, as a higer rate of changes indicates more influence on the labels outcome. Would als be applicable for discrete variables and continuous labels with some minor adjustments.\n\nI love to hear your experiences in this regard and what you think of the proposed method?", "author_fullname": "t2_k8jayuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demystify the blackbox, what do you think of my idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypn2rg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my work as a datascientist I use a lot of blackbox algoritms such as gradient boosting, random forrest and neural networks. One question I ALWAYS get from the business I&amp;#39;m making the models for is, what features are important? How does the model make descicions. So to answer that I do the usual feature analysis, correlation matrices, partial dependence plots, mdi, model extraction. But I still fill like I&amp;#39;m not entirely able to answer what variables are the most important for example.&lt;/p&gt;\n\n&lt;p&gt;Now I was thinking of a new method to determine feature importance. First we need the trained model, and the feature distributions. If we take a feature, we look at the sorted values and take 11 values corresponding to 0% - 10% - .. - 100% of the feature distribution. Next we take for example 1000 random states of the other features and test per random state the 11 options for the selected feature. For this 11 values of the feature, we check the number of times the y-value (label) changes. After doing this for all features, we should have an order of feature importance, as a higer rate of changes indicates more influence on the labels outcome. Would als be applicable for discrete variables and continuous labels with some minor adjustments.&lt;/p&gt;\n\n&lt;p&gt;I love to hear your experiences in this regard and what you think of the proposed method?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypn2rg", "is_robot_indexable": true, "report_reasons": null, "author": "localhoststream", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypn2rg/demystify_the_blackbox_what_do_you_think_of_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypn2rg/demystify_the_blackbox_what_do_you_think_of_my/", "subreddit_subscribers": 818306, "created_utc": 1667916038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Engineers for Ukraine** is an international team of volunteers working on a machine learning tool to identify Russian equipment in real time (with minimal human involvement) to increase the speed at which accurate information about Russian soldiers/equipment in the area passes from local civilians on the ground to the Ukrainian warfighter. \n\nEngineers for Ukraine has four teams: \n\n1. The Data Team, which builds the training datasets for the machine learning models. This is the easiest team to join since the tasks are straightforward and the training is short/easy thanks to the help of our beloved data scientists. \n2. The Machine Learning Team, which builds and trains machine learning models. This team needs a bit more experience and/or time to get through readings to get up to speed. If you are familiar with AWS, AWS SageMaker, AWS S3, AWS Rekognition, AWS Comprehend, Lambda, machine learning attacks, machine learning security, dedicated red team work, and/or data science, please join the machine learning team.\n3. The Development Team, which handles much of the project infrastructure and builds the relevant web pages, services, and user interfaces.  If you are familiar with AWS, Lambda, JavaScript, React.js, Node.js, API's, plug-ins, and/or devops/SRE/cloud engineering, please join the dev team.\n4. The Cybersecurity Team, which works heavily with the Development Team searching for and fixing vulnerabilities, but also creates threat models, does red team vs blue team work, penetration testing, and occasionally OSINT work. If you are interested in learning cool cybersecurity skills from a team of professionals who are just super busy and need more hands on deck to knock out tasks OR if you are also skilled in cybersecurity, please join the cybersecurity team.\n\nI\u2019ve talked about Engineers for Ukraine before in this Reddit post: [https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers\\_needed\\_for\\_proukraine\\_project/](https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers_needed_for_proukraine_project/)\n\nIf you are interested in either of these groups, please reach out to breaker25789@gmail.com with the project (AidSupply or Engineers for Ukraine) and team you are interested in.\n\nWe will reach out and schedule a video call in which you can verify that we aren\u2019t Russian bots and we can verify that you are not a Russian bot by both showing a government-issued photo ID and two social media accounts. As part of the recruitment process, each volunteer may be asked to complete an introductory assignment specific to the project/team they are applying to. This isn\u2019t meant as a barrier, just as a way to get people onboarded faster while giving the project leadership a sense of each volunteer\u2019s skill level.", "author_fullname": "t2_1323h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Volunteers Needed for Pro-Ukraine Machine Learning Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yptkvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667930260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Engineers for Ukraine&lt;/strong&gt; is an international team of volunteers working on a machine learning tool to identify Russian equipment in real time (with minimal human involvement) to increase the speed at which accurate information about Russian soldiers/equipment in the area passes from local civilians on the ground to the Ukrainian warfighter. &lt;/p&gt;\n\n&lt;p&gt;Engineers for Ukraine has four teams: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The Data Team, which builds the training datasets for the machine learning models. This is the easiest team to join since the tasks are straightforward and the training is short/easy thanks to the help of our beloved data scientists. &lt;/li&gt;\n&lt;li&gt;The Machine Learning Team, which builds and trains machine learning models. This team needs a bit more experience and/or time to get through readings to get up to speed. If you are familiar with AWS, AWS SageMaker, AWS S3, AWS Rekognition, AWS Comprehend, Lambda, machine learning attacks, machine learning security, dedicated red team work, and/or data science, please join the machine learning team.&lt;/li&gt;\n&lt;li&gt;The Development Team, which handles much of the project infrastructure and builds the relevant web pages, services, and user interfaces.  If you are familiar with AWS, Lambda, JavaScript, React.js, Node.js, API&amp;#39;s, plug-ins, and/or devops/SRE/cloud engineering, please join the dev team.&lt;/li&gt;\n&lt;li&gt;The Cybersecurity Team, which works heavily with the Development Team searching for and fixing vulnerabilities, but also creates threat models, does red team vs blue team work, penetration testing, and occasionally OSINT work. If you are interested in learning cool cybersecurity skills from a team of professionals who are just super busy and need more hands on deck to knock out tasks OR if you are also skilled in cybersecurity, please join the cybersecurity team.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I\u2019ve talked about Engineers for Ukraine before in this Reddit post: &lt;a href=\"https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers_needed_for_proukraine_project/\"&gt;https://www.reddit.com/r/ukraine/comments/vlsaka/volunteers_needed_for_proukraine_project/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested in either of these groups, please reach out to &lt;a href=\"mailto:breaker25789@gmail.com\"&gt;breaker25789@gmail.com&lt;/a&gt; with the project (AidSupply or Engineers for Ukraine) and team you are interested in.&lt;/p&gt;\n\n&lt;p&gt;We will reach out and schedule a video call in which you can verify that we aren\u2019t Russian bots and we can verify that you are not a Russian bot by both showing a government-issued photo ID and two social media accounts. As part of the recruitment process, each volunteer may be asked to complete an introductory assignment specific to the project/team they are applying to. This isn\u2019t meant as a barrier, just as a way to get people onboarded faster while giving the project leadership a sense of each volunteer\u2019s skill level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yptkvg", "is_robot_indexable": true, "report_reasons": null, "author": "OttersAreDevilSpawn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yptkvg/volunteers_needed_for_proukraine_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yptkvg/volunteers_needed_for_proukraine_machine_learning/", "subreddit_subscribers": 818306, "created_utc": 1667930260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just wanted to give a heads up that we\u2019ve got an upcoming course on Time Series &amp; Forecasting. The goal is to help you solve complex business problems by making more accurate predictions with modern forecasting techniques.\n\n\u00a0This course will be led by two industry leaders: Jan Gasthaus (AWS) and Tim Januschowski (ex-AWS, Zalando).\n\nIn the past, Tim and his team built multiple AI services for AWS such as SageMaker, Forecast, Lookout for Metrics, and DevOps Guru. Jan was part of the teams pushing these projects forward, and also co-created the open-source deep learning forecasting library Gluon TS.\n\nPlus, like all of our courses, Time Series &amp; Forecasting qualifies for coverage from your org\u2019s L&amp;D budget or personal learning stipend.\n\nCome join Tim and Jan live for 5-days of hands-on training. You can learn more about the course by clicking here: https://www.getsphere.com/cohorts/modern-forecasting-in-practice?source=Sphere-Communities-r-datascience", "author_fullname": "t2_2rh4tgqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Forecasting in Practice with Jan Gasthaus (AWS) and Tim Januschowski (Zalando)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3pdr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667954342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to give a heads up that we\u2019ve got an upcoming course on Time Series &amp;amp; Forecasting. The goal is to help you solve complex business problems by making more accurate predictions with modern forecasting techniques.&lt;/p&gt;\n\n&lt;p&gt;\u00a0This course will be led by two industry leaders: Jan Gasthaus (AWS) and Tim Januschowski (ex-AWS, Zalando).&lt;/p&gt;\n\n&lt;p&gt;In the past, Tim and his team built multiple AI services for AWS such as SageMaker, Forecast, Lookout for Metrics, and DevOps Guru. Jan was part of the teams pushing these projects forward, and also co-created the open-source deep learning forecasting library Gluon TS.&lt;/p&gt;\n\n&lt;p&gt;Plus, like all of our courses, Time Series &amp;amp; Forecasting qualifies for coverage from your org\u2019s L&amp;amp;D budget or personal learning stipend.&lt;/p&gt;\n\n&lt;p&gt;Come join Tim and Jan live for 5-days of hands-on training. You can learn more about the course by clicking here: &lt;a href=\"https://www.getsphere.com/cohorts/modern-forecasting-in-practice?source=Sphere-Communities-r-datascience\"&gt;https://www.getsphere.com/cohorts/modern-forecasting-in-practice?source=Sphere-Communities-r-datascience&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?auto=webp&amp;s=8b3e2fe08160bb2a53124e33340455fa98bc44fb", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63d45c89326e562fdb6f6094604071f95abe2dfa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e26e45f843a9033b53c53417d6cf10904605bdc", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d173d8e175559385460c0e1dc662f5da9b1ffa4f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03036dde2114ae1d143fcdd2249acc72b08bb4ef", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=01bc00472d2b14068c296bea5f83844805160e24", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/MkO286z_LHoPdjBty3uN3l-_WCVwuWEX1QJzNj58u1g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2895a71d6477497431d3b1a729d21d7135547db8", "width": 1080, "height": 607}], "variants": {}, "id": "7NPxWGevlxuxdKhK4Hz8wx0_DLrtCK7AYwROIjbI3Kg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq3pdr", "is_robot_indexable": true, "report_reasons": null, "author": "lorenzo_1999", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq3pdr/modern_forecasting_in_practice_with_jan_gasthaus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq3pdr/modern_forecasting_in_practice_with_jan_gasthaus/", "subreddit_subscribers": 818306, "created_utc": 1667954342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently in graduate school in the US, and I am considering starting my career in data science in Canada. \n\nAs the title says, how is the data science scene in Canada?\n\n Are there more or less need for positions compared to the US?\n\n And how well does work experience in Canada carry over to the US?\n\n&amp;#x200B;\n\nThank you very much for any thoughts and insights!", "author_fullname": "t2_saxqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is the data science scene in Canada", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq6lp6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667962455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently in graduate school in the US, and I am considering starting my career in data science in Canada. &lt;/p&gt;\n\n&lt;p&gt;As the title says, how is the data science scene in Canada?&lt;/p&gt;\n\n&lt;p&gt;Are there more or less need for positions compared to the US?&lt;/p&gt;\n\n&lt;p&gt;And how well does work experience in Canada carry over to the US?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for any thoughts and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yq6lp6", "is_robot_indexable": true, "report_reasons": null, "author": "andrewYao", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq6lp6/how_is_the_data_science_scene_in_canada/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq6lp6/how_is_the_data_science_scene_in_canada/", "subreddit_subscribers": 818306, "created_utc": 1667962455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just reading the news and saw these impressive interactive visualizations at the [Guardian](https://www.theguardian.com/us-news/ng-interactive/2022/nov/08/midterm-election-results-live-2022-map-us-midterms-latest-winners-seats-congress?CMP=Share_iOSApp_Other).\n\nJust wondering if anyone knows what programming language or software platform are used to build them?", "author_fullname": "t2_3j8mlt6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interactive Visualizations - How?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq299y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667950526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just reading the news and saw these impressive interactive visualizations at the &lt;a href=\"https://www.theguardian.com/us-news/ng-interactive/2022/nov/08/midterm-election-results-live-2022-map-us-midterms-latest-winners-seats-congress?CMP=Share_iOSApp_Other\"&gt;Guardian&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Just wondering if anyone knows what programming language or software platform are used to build them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq299y", "is_robot_indexable": true, "report_reasons": null, "author": "iamappleapple1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq299y/interactive_visualizations_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq299y/interactive_visualizations_how/", "subreddit_subscribers": 818306, "created_utc": 1667950526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a question regarding Textmining, I want to get information out of a semi-structured text like the highlighted price or the size of the property. The data is currently in a txt.file but I could also safe it somewhere else. What is the best way to get this information into a structured format? Thank you for your help! \n\nhttps://preview.redd.it/0pyrw00iupy91.png?width=747&amp;format=png&amp;auto=webp&amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116", "author_fullname": "t2_tyjml9b0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question Textscraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0pyrw00iupy91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=68153e297febf102f4ce35060ddfcc3cbf07f145"}, {"y": 233, "x": 216, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b031ddda885c56674026b02333ad7b06226ae3e"}, {"y": 345, "x": 320, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7355378c733c11254324605b7130ac17c264dc59"}, {"y": 691, "x": 640, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ffe6b08d69dabcd4d3cfd0e52ab6d0ad23dd1f84"}], "s": {"y": 807, "x": 747, "u": "https://preview.redd.it/0pyrw00iupy91.png?width=747&amp;format=png&amp;auto=webp&amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116"}, "id": "0pyrw00iupy91"}}, "name": "t3_ypjwln", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KhYlSufCJURrtUn8CDQUesWnhSSXOr4U-NzYoziDysY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667908454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question regarding Textmining, I want to get information out of a semi-structured text like the highlighted price or the size of the property. The data is currently in a txt.file but I could also safe it somewhere else. What is the best way to get this information into a structured format? Thank you for your help! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0pyrw00iupy91.png?width=747&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116\"&gt;https://preview.redd.it/0pyrw00iupy91.png?width=747&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c413dee0771dd7071907d4ff3b519e4f8cbf9116&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypjwln", "is_robot_indexable": true, "report_reasons": null, "author": "Ferry_Carondelet", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypjwln/question_textscraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypjwln/question_textscraping/", "subreddit_subscribers": 818306, "created_utc": 1667908454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The EDA and data cleaning part of the project is always a messy phase for me. I was wondering what practices people are doing to standardize it and make things more automated and streamlined?\n\nI've also been trying to make my code more extensible to avoid having to code refactor every time new things comes into play. Since its easy to go in one direction, but harder to go in the other. Keeping things more modular and abstract. I know data science is particularly not fit for some parts of these, since data cleaning is very order based, and EDA is very unplanned and prone to rabbit-holes, but i try to put up with it anyways.\n\nFor example, I no longer do df.groupby(X), but put the key into a list like df.groupby(\\[X\\]), and maybe take out that and keep it as a list variable for data abstraction. Or do things like df\\[df\\[\"col\"\\].isin(\\[X\\])\\] instead of df\\[df\\[\"col\"\\]==X\\].\n\nSure, these create awkward one-element lists at the start, but the point is that they might not end up being one-element anymore in the future. The main con is slower readability with these oxbow lake code. Sometimes my team mate tries to revert and \"de-abstract\" the code back and I have to explain to them why extensibility is good.", "author_fullname": "t2_b7eh4ujn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organization in EDA and data cleaning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypg2yb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667897500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The EDA and data cleaning part of the project is always a messy phase for me. I was wondering what practices people are doing to standardize it and make things more automated and streamlined?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been trying to make my code more extensible to avoid having to code refactor every time new things comes into play. Since its easy to go in one direction, but harder to go in the other. Keeping things more modular and abstract. I know data science is particularly not fit for some parts of these, since data cleaning is very order based, and EDA is very unplanned and prone to rabbit-holes, but i try to put up with it anyways.&lt;/p&gt;\n\n&lt;p&gt;For example, I no longer do df.groupby(X), but put the key into a list like df.groupby([X]), and maybe take out that and keep it as a list variable for data abstraction. Or do things like df[df[&amp;quot;col&amp;quot;].isin([X])] instead of df[df[&amp;quot;col&amp;quot;]==X].&lt;/p&gt;\n\n&lt;p&gt;Sure, these create awkward one-element lists at the start, but the point is that they might not end up being one-element anymore in the future. The main con is slower readability with these oxbow lake code. Sometimes my team mate tries to revert and &amp;quot;de-abstract&amp;quot; the code back and I have to explain to them why extensibility is good.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypg2yb", "is_robot_indexable": true, "report_reasons": null, "author": "countlinard", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypg2yb/organization_in_eda_and_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypg2yb/organization_in_eda_and_data_cleaning/", "subreddit_subscribers": 818306, "created_utc": 1667897500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are there any people out there worth watching on youtube that make interesting DS projects? Preferably in a long video format.\n\nI tried to watch a few, but they all were painfully bad. Like starting feature engineering before checking data types and bumping head against the wall every time python  returns a types error, or saving cvs and starting excel to see unique values in columns manually instead of using .value\\_counts method etc.\n\nI am a data analyst sql power bi monkey and in no way a very advanced Python user, just know some and have a bit of practical experience. My knowledge isn\u2019t enough to be good myself, but enough to see a moron pretending being competent.\n\n I don\u2019t really want to watch some exoteric ML mamba jambo, just a competent person doing basic stuff really well, learn something and have fun. \n\nAre there people you can recommend?", "author_fullname": "t2_p9z8x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any COMPETENT youtubers making DS \u201clet\u2019s plays\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq6gkj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667962043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any people out there worth watching on youtube that make interesting DS projects? Preferably in a long video format.&lt;/p&gt;\n\n&lt;p&gt;I tried to watch a few, but they all were painfully bad. Like starting feature engineering before checking data types and bumping head against the wall every time python  returns a types error, or saving cvs and starting excel to see unique values in columns manually instead of using .value_counts method etc.&lt;/p&gt;\n\n&lt;p&gt;I am a data analyst sql power bi monkey and in no way a very advanced Python user, just know some and have a bit of practical experience. My knowledge isn\u2019t enough to be good myself, but enough to see a moron pretending being competent.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t really want to watch some exoteric ML mamba jambo, just a competent person doing basic stuff really well, learn something and have fun. &lt;/p&gt;\n\n&lt;p&gt;Are there people you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq6gkj", "is_robot_indexable": true, "report_reasons": null, "author": "Cpt_keaSar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq6gkj/are_there_any_competent_youtubers_making_ds_lets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq6gkj/are_there_any_competent_youtubers_making_ds_lets/", "subreddit_subscribers": 818306, "created_utc": 1667962043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking for a book/website/ebook to learn high level statistics along with Python. \n\nI would like to be able to learn how to import data sources, how to perform anova, multiple linear regression, hypothesis testing, etc etc. \n\nIn an ideal world, I'd like a physical book. However, if the online sources provide higher quality content, i'll gladly use those. \n\nThank you", "author_fullname": "t2_oyqxw0r6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resource to learn Python along with statistics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yq7qww", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667965794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a book/website/ebook to learn high level statistics along with Python. &lt;/p&gt;\n\n&lt;p&gt;I would like to be able to learn how to import data sources, how to perform anova, multiple linear regression, hypothesis testing, etc etc. &lt;/p&gt;\n\n&lt;p&gt;In an ideal world, I&amp;#39;d like a physical book. However, if the online sources provide higher quality content, i&amp;#39;ll gladly use those. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq7qww", "is_robot_indexable": true, "report_reasons": null, "author": "GrantTheGreat15", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq7qww/good_resource_to_learn_python_along_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq7qww/good_resource_to_learn_python_along_with/", "subreddit_subscribers": 818306, "created_utc": 1667965794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello All, \n\nI am a host of a podcast that helps students and young professionals with all things personal and career development. \n\nI got a question about how to stand out for a data science internship. I know having a portfolio or github would help, but want to validate with the community.  \n\nThis is one of my favorite subreddits bc of the smart and realistic community ! \n\nAny other ways you would recommend to standout while on the job hunt (getting a job in data science)?", "author_fullname": "t2_29rf2ck4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on standing out during interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq4ns7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667956963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All, &lt;/p&gt;\n\n&lt;p&gt;I am a host of a podcast that helps students and young professionals with all things personal and career development. &lt;/p&gt;\n\n&lt;p&gt;I got a question about how to stand out for a data science internship. I know having a portfolio or github would help, but want to validate with the community.  &lt;/p&gt;\n\n&lt;p&gt;This is one of my favorite subreddits bc of the smart and realistic community ! &lt;/p&gt;\n\n&lt;p&gt;Any other ways you would recommend to standout while on the job hunt (getting a job in data science)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yq4ns7", "is_robot_indexable": true, "report_reasons": null, "author": "azatar19", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq4ns7/advice_on_standing_out_during_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq4ns7/advice_on_standing_out_during_interviews/", "subreddit_subscribers": 818306, "created_utc": 1667956963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If this is the wrong forum, please direct me.\n\nI'm more of a BI analyst, but I've been challenged to broaden my skillset with some data science tasks. I've got some exposure to data science concepts, but nothing I've utilized in any full time role. \n\nMy task is to take some transactional data thats been categorized. Think something like credit card transactions, and how vendors get categorized (fast food, medical etc). If I'm trying to identify someone who might use a particular product based on their past spending history, what type of an analysis am I using to tease that out. \n\nSo if in this complete dataset I have users who've purchased product A. How would you go about doing a look-alike to find users who spend the same way as those who have product A but don't currently subscribe?\n\nI don't expect to be spoon fed, but more so to give me some key word search terms to help me get on the right path. \n\nI appreciate the assistance!", "author_fullname": "t2_b8zce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analysis Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq078w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667945489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If this is the wrong forum, please direct me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m more of a BI analyst, but I&amp;#39;ve been challenged to broaden my skillset with some data science tasks. I&amp;#39;ve got some exposure to data science concepts, but nothing I&amp;#39;ve utilized in any full time role. &lt;/p&gt;\n\n&lt;p&gt;My task is to take some transactional data thats been categorized. Think something like credit card transactions, and how vendors get categorized (fast food, medical etc). If I&amp;#39;m trying to identify someone who might use a particular product based on their past spending history, what type of an analysis am I using to tease that out. &lt;/p&gt;\n\n&lt;p&gt;So if in this complete dataset I have users who&amp;#39;ve purchased product A. How would you go about doing a look-alike to find users who spend the same way as those who have product A but don&amp;#39;t currently subscribe?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t expect to be spoon fed, but more so to give me some key word search terms to help me get on the right path. &lt;/p&gt;\n\n&lt;p&gt;I appreciate the assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq078w", "is_robot_indexable": true, "report_reasons": null, "author": "justfordickjoke", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq078w/data_analysis_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq078w/data_analysis_advice/", "subreddit_subscribers": 818306, "created_utc": 1667945489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been looking for some advice or general best practices when it comes to wrangling survey response data that consists mostly of \"click all that apply\" responses and then free text responses (for reference the survey was distributed through Survey Monkey). The data is structured in a wide format, wherein the possible responses for questions are distributed in the columns of the data. For example a question on race would have each of possible values for race as a column variable: \n\n    white &lt;- c(white, NA, NA, white) \n    black &lt;- c(NA, black, NA, black) \n    asian &lt;- c(asian, NA, asian, NA)\n    unique_id &lt;- x(1,2,3)\n    df &lt;- tibble(white, black, asian, unique_id) \n\nEach respondent's responses are captured in a single row and every respondent has a unique ID, so respondent 1 would have checked the boxes for White and Asian. My question is in regards to how best to go about formatting the data for analysis. Given that there are multiple of these \"check all that apply\" or dummy variable columns, is it best to leave this data in a wide format? Or is it better to gather all of these columns into a single variable and pivot the data longer? My only concern is that there are about 20 questions like this, so pivoting each of these variables would create a really long data frame. Additionally, I need to have the data formatted in a way that would require little to no preprocessing in Tableau. This is primarily due to work policies on formatting research publications and data visuals (I know it's not ideal but I can't change it). \n\nI have it currently set up in two way: the first is with each question separated out in different excel sheets that can be joined by their unique ID. The second is with all the questions combined into a single data frame. Both are formatted wide. Thanks in advance for any help or advice, I can also provide additional anonymous data if that would help you help me better :)", "author_fullname": "t2_9337qo7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cleaning Survey Response Data for Analysis in R | Best Practices or Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypveb6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking for some advice or general best practices when it comes to wrangling survey response data that consists mostly of &amp;quot;click all that apply&amp;quot; responses and then free text responses (for reference the survey was distributed through Survey Monkey). The data is structured in a wide format, wherein the possible responses for questions are distributed in the columns of the data. For example a question on race would have each of possible values for race as a column variable: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;white &amp;lt;- c(white, NA, NA, white) \nblack &amp;lt;- c(NA, black, NA, black) \nasian &amp;lt;- c(asian, NA, asian, NA)\nunique_id &amp;lt;- x(1,2,3)\ndf &amp;lt;- tibble(white, black, asian, unique_id) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Each respondent&amp;#39;s responses are captured in a single row and every respondent has a unique ID, so respondent 1 would have checked the boxes for White and Asian. My question is in regards to how best to go about formatting the data for analysis. Given that there are multiple of these &amp;quot;check all that apply&amp;quot; or dummy variable columns, is it best to leave this data in a wide format? Or is it better to gather all of these columns into a single variable and pivot the data longer? My only concern is that there are about 20 questions like this, so pivoting each of these variables would create a really long data frame. Additionally, I need to have the data formatted in a way that would require little to no preprocessing in Tableau. This is primarily due to work policies on formatting research publications and data visuals (I know it&amp;#39;s not ideal but I can&amp;#39;t change it). &lt;/p&gt;\n\n&lt;p&gt;I have it currently set up in two way: the first is with each question separated out in different excel sheets that can be joined by their unique ID. The second is with all the questions combined into a single data frame. Both are formatted wide. Thanks in advance for any help or advice, I can also provide additional anonymous data if that would help you help me better :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypveb6", "is_robot_indexable": true, "report_reasons": null, "author": "Legal_Television_944", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypveb6/cleaning_survey_response_data_for_analysis_in_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypveb6/cleaning_survey_response_data_for_analysis_in_r/", "subreddit_subscribers": 818306, "created_utc": 1667934361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hello,\n\nI am working on curve's peaks and valleys detections.\n\n**Peak detection function**  \nIn Python there is no shortage of nice functions to do it like with scipy.signal.find\\_peaks.  \nAnd most functions have many parameters (distance, height, prominence, etc.) which have for objective to detect more or less peaks, which mean ignoring the minor ones, considered as noise.\n\n**Curve smoothing**  \nThen comes smoothing the curve before peak detecting.  \nI often see it done in blogs and examples.  \nThe savgol\\_filter is quite often used.  \nBasically it smooths the curves, so noise is removed and then you detect only major peaks.\n\n**Here are my questions**:\n\n**1/ Is curve smoothing before peak detection of any use ?**  \nI have the intuition that it's overlapping, and basically doing twice the same thing via different means.  \nAnd that if you fine tune your peak detection function parameters (distance, height, prominence, etc.) enough, smoothing before will never provide any upside.\n\n**2/ If curve smoothing is useful how to optimize it with peak detection?**  \nSay you want to detect only visually major peaks (I know it's subjective, but let's say you want only a limited number of peaks, while maximizing the gap between peaks and valleys).   \nIs there a way to find the correct mix of smoothing and parameters?  \nOr do you bruteforce millions of combinaisons until you have minimized the number of peaks while maximized the average gaps between peaks and valleys? \n\nWhat are your thoughts?  \nthx", "author_fullname": "t2_5559lwqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curve peak finding: isn't curve smoothing overlapping with peak detection functions parameters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypqxuf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667924311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am working on curve&amp;#39;s peaks and valleys detections.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Peak detection function&lt;/strong&gt;&lt;br/&gt;\nIn Python there is no shortage of nice functions to do it like with scipy.signal.find_peaks.&lt;br/&gt;\nAnd most functions have many parameters (distance, height, prominence, etc.) which have for objective to detect more or less peaks, which mean ignoring the minor ones, considered as noise.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Curve smoothing&lt;/strong&gt;&lt;br/&gt;\nThen comes smoothing the curve before peak detecting.&lt;br/&gt;\nI often see it done in blogs and examples.&lt;br/&gt;\nThe savgol_filter is quite often used.&lt;br/&gt;\nBasically it smooths the curves, so noise is removed and then you detect only major peaks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are my questions&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1/ Is curve smoothing before peak detection of any use ?&lt;/strong&gt;&lt;br/&gt;\nI have the intuition that it&amp;#39;s overlapping, and basically doing twice the same thing via different means.&lt;br/&gt;\nAnd that if you fine tune your peak detection function parameters (distance, height, prominence, etc.) enough, smoothing before will never provide any upside.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2/ If curve smoothing is useful how to optimize it with peak detection?&lt;/strong&gt;&lt;br/&gt;\nSay you want to detect only visually major peaks (I know it&amp;#39;s subjective, but let&amp;#39;s say you want only a limited number of peaks, while maximizing the gap between peaks and valleys).&lt;br/&gt;\nIs there a way to find the correct mix of smoothing and parameters?&lt;br/&gt;\nOr do you bruteforce millions of combinaisons until you have minimized the number of peaks while maximized the average gaps between peaks and valleys? &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts?&lt;br/&gt;\nthx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypqxuf", "is_robot_indexable": true, "report_reasons": null, "author": "Vince_peak", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypqxuf/curve_peak_finding_isnt_curve_smoothing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypqxuf/curve_peak_finding_isnt_curve_smoothing/", "subreddit_subscribers": 818306, "created_utc": 1667924311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For example, this one:\nhttps://careers.google.com/jobs/results/137295691429880518-business-and-marketing-data-scientist-applied-machine-learning/ for a Business and Marketing Data Scientist, Applied Machine Learning, says: \"US base salary range for this full-time position is $141,000-$219,000 + bonus + equity + benefits\"\n\nThis one: https://careers.google.com/jobs/results/106912103970808518-business-and-marketing-data-scientist-gtech/ for a Business and Marketing Data Scientist, gTech says \"The US base salary range for this full-time position is $119,000-$181,000 + bonus + equity + benefits.\"\n\nDo you think other employers will do this, and what effect will it have?", "author_fullname": "t2_5vr57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google now posting salary ranges (on all jobs, inc DS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yq3l4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667954022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, this one:\n&lt;a href=\"https://careers.google.com/jobs/results/137295691429880518-business-and-marketing-data-scientist-applied-machine-learning/\"&gt;https://careers.google.com/jobs/results/137295691429880518-business-and-marketing-data-scientist-applied-machine-learning/&lt;/a&gt; for a Business and Marketing Data Scientist, Applied Machine Learning, says: &amp;quot;US base salary range for this full-time position is $141,000-$219,000 + bonus + equity + benefits&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;This one: &lt;a href=\"https://careers.google.com/jobs/results/106912103970808518-business-and-marketing-data-scientist-gtech/\"&gt;https://careers.google.com/jobs/results/106912103970808518-business-and-marketing-data-scientist-gtech/&lt;/a&gt; for a Business and Marketing Data Scientist, gTech says &amp;quot;The US base salary range for this full-time position is $119,000-$181,000 + bonus + equity + benefits.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Do you think other employers will do this, and what effect will it have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?auto=webp&amp;s=860a20668c97a679bf12f760a9822ae6e573573d", "width": 1060, "height": 707}, "resolutions": [{"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=708bd1a06cf10c57e470f18c364e2ba7f2260140", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4501174b90d76b237a507bd06e37d9f41aeba74", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe440a35e675b92d83dc0d75ec6805b4ba51e7be", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=18fc68b0a58d5ff200dca570b0b60fcb22b13e44", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/9ezcKlnr8A81En8Xi_IjXu-5QfdidB34761d47AT-7U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1db86297e8fc27bc3c255873fe3d7536a123efc", "width": 960, "height": 640}], "variants": {}, "id": "6H24UlQQqZU8MhF1DciG4g8Xl9ju1x2f0n7OjLDCQss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yq3l4p", "is_robot_indexable": true, "report_reasons": null, "author": "FlyMyPretty", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yq3l4p/google_now_posting_salary_ranges_on_all_jobs_inc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yq3l4p/google_now_posting_salary_ranges_on_all_jobs_inc/", "subreddit_subscribers": 818306, "created_utc": 1667954022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dkjfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cyber criminals: Data \u201ctoo dirty\u201d for dark web.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ypzgf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/e3LfSkgo3-W6ANFXPGuKhTP5wwO6JQS0FIr6OWyOGpk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667943732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5fu6mrcjrsy91.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?auto=webp&amp;s=05128d7c4a0ef3d3e9663d3a0f40b7178bf612ea", "width": 1124, "height": 1541}, "resolutions": [{"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a046400361b0ac0fa11b1552273639be0e77939", "width": 108, "height": 148}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a5a6be9e8af41a511ac0e8f3985c1e4318541e8", "width": 216, "height": 296}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1f65ecfd5e4b74e2d33e4dcf74c0037a454eaa3", "width": 320, "height": 438}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14767a3820718b756061f8016eed6301cc23463a", "width": 640, "height": 877}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d3fadbfbaa4dd61472e403f18bbd8ae0fea0d68", "width": 960, "height": 1316}, {"url": "https://preview.redd.it/5fu6mrcjrsy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=187e19effd58d509e6fbc6e53c8c62456e9ad30b", "width": 1080, "height": 1480}], "variants": {}, "id": "XsBoj2TNTQ3mlna6p7Ubws8jtHmRG-ni-fxhsepQLIQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypzgf2", "is_robot_indexable": true, "report_reasons": null, "author": "bpalmerau", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypzgf2/cyber_criminals_data_too_dirty_for_dark_web/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/5fu6mrcjrsy91.jpg", "subreddit_subscribers": 818306, "created_utc": 1667943732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my two previous roles we were just using Python scripts orchestrated with Airflow. At my current job, we use databricks. I think mostly because there\u2019s a lot of junior DS and they like cramming stuff into notebooks. I can\u2019t find a good workflow. The fact that the databricks environment is so bad compared to a nice IDE like PyCharm is really limiting for me. Ideally I want to do most of the development locally and use databricks to run the code when I need a lot or resources but I can\u2019t find a way that seems reasonably user friendly and end up going back and forth between local and cloud/db env using git. \n\nDoes anyone have a good flow to recommend?", "author_fullname": "t2_fqwkw26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your workflow when using databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypz7zw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667943190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my two previous roles we were just using Python scripts orchestrated with Airflow. At my current job, we use databricks. I think mostly because there\u2019s a lot of junior DS and they like cramming stuff into notebooks. I can\u2019t find a good workflow. The fact that the databricks environment is so bad compared to a nice IDE like PyCharm is really limiting for me. Ideally I want to do most of the development locally and use databricks to run the code when I need a lot or resources but I can\u2019t find a way that seems reasonably user friendly and end up going back and forth between local and cloud/db env using git. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good flow to recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypz7zw", "is_robot_indexable": true, "report_reasons": null, "author": "jobeta", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypz7zw/whats_your_workflow_when_using_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypz7zw/whats_your_workflow_when_using_databricks/", "subreddit_subscribers": 818306, "created_utc": 1667943190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working with a data set that needs to remain strictly confidential (though not due to HIPAA or any such legal requirements, just out of respect to the source). I also need to protype a web dashboard for visualizing and manipulating the data to demonstrate possible ways of communicating the data and the \"story\" within if they made the data publicly accessible.\n\nI have two questions (which may have different answers):\n\n1. How would you minimally secure (i.e. password protect, but perhaps not with a full-on authentication system) a basic (probably static, HTML/CSS/Javascript) web app in 2022?\n2. How do you deal with confidential/proprietary data when developing prototypes?\n3. (Bonus) Happen to have an example of how you tackled a similar scenario?\n\nI'll edit this post as needed if clarifying questions are asked below. Thanks in advance!", "author_fullname": "t2_f260834", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Securing a Data Science Project in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypvho0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667934580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with a data set that needs to remain strictly confidential (though not due to HIPAA or any such legal requirements, just out of respect to the source). I also need to protype a web dashboard for visualizing and manipulating the data to demonstrate possible ways of communicating the data and the &amp;quot;story&amp;quot; within if they made the data publicly accessible.&lt;/p&gt;\n\n&lt;p&gt;I have two questions (which may have different answers):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How would you minimally secure (i.e. password protect, but perhaps not with a full-on authentication system) a basic (probably static, HTML/CSS/Javascript) web app in 2022?&lt;/li&gt;\n&lt;li&gt;How do you deal with confidential/proprietary data when developing prototypes?&lt;/li&gt;\n&lt;li&gt;(Bonus) Happen to have an example of how you tackled a similar scenario?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ll edit this post as needed if clarifying questions are asked below. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypvho0", "is_robot_indexable": true, "report_reasons": null, "author": "BoxBeatMan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypvho0/securing_a_data_science_project_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypvho0/securing_a_data_science_project_in_2022/", "subreddit_subscribers": 818306, "created_utc": 1667934580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does a multiple regression model contain combination of predictor variables (eg. x1x2, x2x4, etc. where x1, x2, x3, x4, etc. are the predictor variables) or only separate multiple predictor variables?", "author_fullname": "t2_pwif3is8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does multiple regression model contain combination of predictor variables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypd1uv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667887879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does a multiple regression model contain combination of predictor variables (eg. x1x2, x2x4, etc. where x1, x2, x3, x4, etc. are the predictor variables) or only separate multiple predictor variables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypd1uv", "is_robot_indexable": true, "report_reasons": null, "author": "random5842786439", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypd1uv/does_multiple_regression_model_contain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypd1uv/does_multiple_regression_model_contain/", "subreddit_subscribers": 818306, "created_utc": 1667887879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was thinking about the actual updating of the weights and biases for the past couple of days, and i realized something that i havent been able to get off my mind.. if your learning rate is less than one (which i dont see how it couldnt be. Anything greater than one converges to infinite error as far as i can tell, and using a number less than one is the only way to actually use the information about the sensitivity of the cost function), anywhere you find a derivative less than one is going to make your change huge and probably change your weight too much\u2026 what\u2026 what am i missing here?\n\n(Btw sorry if this question seems inappropriate but i dont really know where else to ask r/askdatascience is dead)", "author_fullname": "t2_3hk48w5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back Propagation Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypv4jy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667945065.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667933756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking about the actual updating of the weights and biases for the past couple of days, and i realized something that i havent been able to get off my mind.. if your learning rate is less than one (which i dont see how it couldnt be. Anything greater than one converges to infinite error as far as i can tell, and using a number less than one is the only way to actually use the information about the sensitivity of the cost function), anywhere you find a derivative less than one is going to make your change huge and probably change your weight too much\u2026 what\u2026 what am i missing here?&lt;/p&gt;\n\n&lt;p&gt;(Btw sorry if this question seems inappropriate but i dont really know where else to ask &lt;a href=\"/r/askdatascience\"&gt;r/askdatascience&lt;/a&gt; is dead)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypv4jy", "is_robot_indexable": true, "report_reasons": null, "author": "Sharpeye1994", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypv4jy/back_propagation_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypv4jy/back_propagation_question/", "subreddit_subscribers": 818306, "created_utc": 1667933756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hearing from today's real-life data leaders on the Customer Insight Leader podcast (episode 58, Olivia Gambelin, founder of Ethical Associates)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ypr2ph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 456, "scrolling": false, "height": 152}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_x3vk1", "secure_media": {"type": "open.spotify.com", "oembed": {"provider_url": "https://spotify.com", "description": "Listen to this episode from Customer Insight Leader podcast on Spotify. For episode 58, I am in conversation with Olivia Gambelin, who joins us from Brussels. Olivia has the exciting job title of being an AI Ethicist and is the founder &amp; CEO of Ethical Intelligence.", "title": "Episode 58 - Olivia Gambelin (Ethical Associates)", "type": "rich", "thumbnail_width": 300, "height": 152, "width": 456, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Spotify", "thumbnail_url": "https://i.scdn.co/image/ab67656300005f1f4ff0d1ef2c05ba7d265e5f4f", "thumbnail_height": 300}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 456, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ypr2ph", "height": 152}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RWH8pICvv7NDhLx5sbV0Aa1cq0f2YsitYApFJi9s39w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Leadership", "selftext": "", "author_fullname": "t2_x3vk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hearing from today's real-life data leaders on the Customer Insight Leader podcast (episode 58, Olivia Gambelin, founder of Ethical Associates)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Leadership", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ypr26s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 456, "scrolling": false, "height": 152}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "open.spotify.com", "oembed": {"provider_url": "https://spotify.com", "description": "Listen to this episode from Customer Insight Leader podcast on Spotify. For episode 58, I am in conversation with Olivia Gambelin, who joins us from Brussels. Olivia has the exciting job title of being an AI Ethicist and is the founder &amp; CEO of Ethical Intelligence.", "title": "Episode 58 - Olivia Gambelin (Ethical Associates)", "type": "rich", "thumbnail_width": 300, "height": 152, "width": 456, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Spotify", "thumbnail_url": "https://i.scdn.co/image/ab67656300005f1f4ff0d1ef2c05ba7d265e5f4f", "thumbnail_height": 300}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 456, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ypr26s", "height": 152}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1667924568.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.spotify.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.spotify.com/episode/3DohlbDgAzi70uAndfoR4u", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ifdTymPAzu-kpVxBdeeXnnD3rcbWKbGr777sRQk47oM.jpg?auto=webp&amp;s=9d4047ccd9f4e29da026c82ffa2f45d459dd8d1b", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/ifdTymPAzu-kpVxBdeeXnnD3rcbWKbGr777sRQk47oM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c0cee7cd1ff0ca2bf92105d6865e46fa8236b54", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ifdTymPAzu-kpVxBdeeXnnD3rcbWKbGr777sRQk47oM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=58fdad66b2a4d68337f5cd3caa2284ca5a5865ea", "width": 216, "height": 216}], "variants": {}, "id": "fen4KphRVEK7hAjmH__71xK1oXG8c5eLoJwiUxVTHXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r7ks", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypr26s", "is_robot_indexable": true, "report_reasons": null, "author": "PaulLaughlin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Leadership/comments/ypr26s/hearing_from_todays_reallife_data_leaders_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.spotify.com/episode/3DohlbDgAzi70uAndfoR4u", "subreddit_subscribers": 29844, "created_utc": 1667924568.0, "num_crossposts": 1, "media": {"type": "open.spotify.com", "oembed": {"provider_url": "https://spotify.com", "description": "Listen to this episode from Customer Insight Leader podcast on Spotify. For episode 58, I am in conversation with Olivia Gambelin, who joins us from Brussels. Olivia has the exciting job title of being an AI Ethicist and is the founder &amp; CEO of Ethical Intelligence.", "title": "Episode 58 - Olivia Gambelin (Ethical Associates)", "type": "rich", "thumbnail_width": 300, "height": 152, "width": 456, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Spotify", "thumbnail_url": "https://i.scdn.co/image/ab67656300005f1f4ff0d1ef2c05ba7d265e5f4f", "thumbnail_height": 300}}, "is_video": false}], "created": 1667924599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.spotify.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://open.spotify.com/episode/3DohlbDgAzi70uAndfoR4u", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ifdTymPAzu-kpVxBdeeXnnD3rcbWKbGr777sRQk47oM.jpg?auto=webp&amp;s=9d4047ccd9f4e29da026c82ffa2f45d459dd8d1b", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/ifdTymPAzu-kpVxBdeeXnnD3rcbWKbGr777sRQk47oM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c0cee7cd1ff0ca2bf92105d6865e46fa8236b54", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ifdTymPAzu-kpVxBdeeXnnD3rcbWKbGr777sRQk47oM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=58fdad66b2a4d68337f5cd3caa2284ca5a5865ea", "width": 216, "height": 216}], "variants": {}, "id": "fen4KphRVEK7hAjmH__71xK1oXG8c5eLoJwiUxVTHXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypr2ph", "is_robot_indexable": true, "report_reasons": null, "author": "PaulLaughlin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ypr26s", "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypr2ph/hearing_from_todays_reallife_data_leaders_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.spotify.com/episode/3DohlbDgAzi70uAndfoR4u", "subreddit_subscribers": 818306, "created_utc": 1667924599.0, "num_crossposts": 0, "media": {"type": "open.spotify.com", "oembed": {"provider_url": "https://spotify.com", "description": "Listen to this episode from Customer Insight Leader podcast on Spotify. For episode 58, I am in conversation with Olivia Gambelin, who joins us from Brussels. Olivia has the exciting job title of being an AI Ethicist and is the founder &amp; CEO of Ethical Intelligence.", "title": "Episode 58 - Olivia Gambelin (Ethical Associates)", "type": "rich", "thumbnail_width": 300, "height": 152, "width": 456, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fopen.spotify.com%2Fembed%2Fepisode%2F3DohlbDgAzi70uAndfoR4u%3Futm_source%3Doembed&amp;display_name=Spotify&amp;url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F3DohlbDgAzi70uAndfoR4u&amp;image=https%3A%2F%2Fi.scdn.co%2Fimage%2Fab67656300005f1f4ff0d1ef2c05ba7d265e5f4f&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=spotify\" width=\"456\" height=\"152\" scrolling=\"no\" title=\"Spotify embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Spotify", "thumbnail_url": "https://i.scdn.co/image/ab67656300005f1f4ff0d1ef2c05ba7d265e5f4f", "thumbnail_height": 300}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's a boss I know that wants to get a Data Scientist, and the budget is $100,000. I told them that won't be enough for a decent data scientist, I also said what do you need it for they answered \"I don't know... They will do machine learning I think\".\nWhat do you guys think?", "author_fullname": "t2_7i9shveb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is $100,000 a year bad for a DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypebfp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667892321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a boss I know that wants to get a Data Scientist, and the budget is $100,000. I told them that won&amp;#39;t be enough for a decent data scientist, I also said what do you need it for they answered &amp;quot;I don&amp;#39;t know... They will do machine learning I think&amp;quot;.\nWhat do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypebfp", "is_robot_indexable": true, "report_reasons": null, "author": "byggmesterPRO", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypebfp/is_100000_a_year_bad_for_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypebfp/is_100000_a_year_bad_for_a_ds/", "subreddit_subscribers": 818306, "created_utc": 1667892321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Companies right now are flush with wannabe data scientists and, worse yet, underpaid, overlooked \"data\" analysts that put \"Microsoft Office Suite\" on their resumes still. Everyday I see people who want to break into the field of data science by posting shitty juPyter notebooks chock-full of violets or lillies or whatever that stupid floral data set is. What would really get them hired? A well-formatted PowerBI dashboard showing how many failed attempts to switch from marketing to data science involved predicting the survival rate of a hypothetical person on the USS Titanic. Bonus points if the person who made the dashboard could spell Git.\n\nListen, I know you doubt me, but please understand the following: companies don't know anything about anything ever and never will. Stakeholders currently make decisions by flipping a coin and whether or not there's a tingling in their elbows. They don't want data scientist, data analysts, data engineers, data product managers, data project managers, machine-learning engineers, machine-learning analysts, machine-learning scientists, research scientists, or machine-learning research scientists analysts. If you take the set of \\[\"data\", \"machine-learning\", \"research\"\\] and the set of \\['scientist', 'engineer', 'manager', 'analyst', 'intern'\\] and took ever combination of them\\*, then you'd arrive at a complete list of dogshit jobs that no one is hiring for, and will never hire for. Why? Because data is stupid. The whole thing is stupid. No one is doing anything. How do I know? Because I looked at the data the same way a stakeholder would: I read the headlines on this reddit and went with my gut-feeling to make decisions.\n\nSpeaking of gut feelings, you know what companies need more of? Anal.\n\n&amp;#x200B;\n\n\\*Only those combinations with \"engineer\" at the end will know how to import itertools, fools.\n\nEdit: now that we're done jerking off talking about how data science is a top-tier C-suite level job that only people with 15,000 years of experience and a doctorate from Oxford or Yale can hold, can we discuss the actual content, news, methodologies, and developments within the field of data science? ", "author_fullname": "t2_lwmkqytr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "hot take: the \"yst\" is not needed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypyhfj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.22, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": 1667941801.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667941527.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Companies right now are flush with wannabe data scientists and, worse yet, underpaid, overlooked &amp;quot;data&amp;quot; analysts that put &amp;quot;Microsoft Office Suite&amp;quot; on their resumes still. Everyday I see people who want to break into the field of data science by posting shitty juPyter notebooks chock-full of violets or lillies or whatever that stupid floral data set is. What would really get them hired? A well-formatted PowerBI dashboard showing how many failed attempts to switch from marketing to data science involved predicting the survival rate of a hypothetical person on the USS Titanic. Bonus points if the person who made the dashboard could spell Git.&lt;/p&gt;\n\n&lt;p&gt;Listen, I know you doubt me, but please understand the following: companies don&amp;#39;t know anything about anything ever and never will. Stakeholders currently make decisions by flipping a coin and whether or not there&amp;#39;s a tingling in their elbows. They don&amp;#39;t want data scientist, data analysts, data engineers, data product managers, data project managers, machine-learning engineers, machine-learning analysts, machine-learning scientists, research scientists, or machine-learning research scientists analysts. If you take the set of [&amp;quot;data&amp;quot;, &amp;quot;machine-learning&amp;quot;, &amp;quot;research&amp;quot;] and the set of [&amp;#39;scientist&amp;#39;, &amp;#39;engineer&amp;#39;, &amp;#39;manager&amp;#39;, &amp;#39;analyst&amp;#39;, &amp;#39;intern&amp;#39;] and took ever combination of them*, then you&amp;#39;d arrive at a complete list of dogshit jobs that no one is hiring for, and will never hire for. Why? Because data is stupid. The whole thing is stupid. No one is doing anything. How do I know? Because I looked at the data the same way a stakeholder would: I read the headlines on this reddit and went with my gut-feeling to make decisions.&lt;/p&gt;\n\n&lt;p&gt;Speaking of gut feelings, you know what companies need more of? Anal.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;*Only those combinations with &amp;quot;engineer&amp;quot; at the end will know how to import itertools, fools.&lt;/p&gt;\n\n&lt;p&gt;Edit: now that we&amp;#39;re done jerking off talking about how data science is a top-tier C-suite level job that only people with 15,000 years of experience and a doctorate from Oxford or Yale can hold, can we discuss the actual content, news, methodologies, and developments within the field of data science? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ypyhfj", "is_robot_indexable": true, "report_reasons": null, "author": "c0ntrap0sitive", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ypyhfj/hot_take_the_yst_is_not_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ypyhfj/hot_take_the_yst_is_not_needed/", "subreddit_subscribers": 818306, "created_utc": 1667941527.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}