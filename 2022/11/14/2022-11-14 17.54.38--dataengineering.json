{"kind": "Listing", "data": {"after": "t3_yux1v4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know the best way to find part time work (\\~20 hrs/wk as freelance/independent contractor) as a data engineer?\n\nRecruiters? Job sites? I\u2019ve thought about toptal/upwork but figured going out on my own is better", "author_fullname": "t2_gnj3pgpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Part Time Job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yui8kn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668381751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know the best way to find part time work (~20 hrs/wk as freelance/independent contractor) as a data engineer?&lt;/p&gt;\n\n&lt;p&gt;Recruiters? Job sites? I\u2019ve thought about toptal/upwork but figured going out on my own is better&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yui8kn", "is_robot_indexable": true, "report_reasons": null, "author": "Kini_J", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yui8kn/data_engineer_part_time_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yui8kn/data_engineer_part_time_job/", "subreddit_subscribers": 79948, "created_utc": 1668381751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best practices to load large data into a cloud datawarehouse like snowflake? Lets say I have 10 tables (each table size is &gt; 50gb) in a source database and I am using s3 as a intermediate storage layer. What is the best approach to load this data? Should I split the data in each source table into smaller files and load it? If splitting the data into smaller files is recommended, please explain me the reason to follow this approach.", "author_fullname": "t2_sde7upnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices to load large data file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuudwe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668419371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best practices to load large data into a cloud datawarehouse like snowflake? Lets say I have 10 tables (each table size is &amp;gt; 50gb) in a source database and I am using s3 as a intermediate storage layer. What is the best approach to load this data? Should I split the data in each source table into smaller files and load it? If splitting the data into smaller files is recommended, please explain me the reason to follow this approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yuudwe", "is_robot_indexable": true, "report_reasons": null, "author": "bharath-t", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuudwe/best_practices_to_load_large_data_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuudwe/best_practices_to_load_large_data_file/", "subreddit_subscribers": 79948, "created_utc": 1668419371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i'm creating a pipeline that is ingesting from 2 sources, both API's and want to transform, and load them into a single table in an external database. The table does not exist.\n\nSo far I have taken both json responses and put them into seperate source .json files (should I? as a best practice?) and then also used pandas to create 2 additional csv files (for no particular reason?) from the json files.   \nDoes this even make sense?   \n\n\nNow I want to create a table and populate it with some of the fields (not all).\n\nIve learned about sqlalchemy to use stuff like declarative base, creating tables for both the raw and the clean models, where raw holds the current data types, and clean the new actual database types. But I'm a bit confused as to why I would create a raw model when I can just transform the data I need and put them straight into the clean model. What Am I missing here?   \n\n\nAlso, is this even the desired solution for what I want to accomplish?   \n\n\nTHank you!", "author_fullname": "t2_6kipsr88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL question (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yujevd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668384702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;m creating a pipeline that is ingesting from 2 sources, both API&amp;#39;s and want to transform, and load them into a single table in an external database. The table does not exist.&lt;/p&gt;\n\n&lt;p&gt;So far I have taken both json responses and put them into seperate source .json files (should I? as a best practice?) and then also used pandas to create 2 additional csv files (for no particular reason?) from the json files.&lt;br/&gt;\nDoes this even make sense?   &lt;/p&gt;\n\n&lt;p&gt;Now I want to create a table and populate it with some of the fields (not all).&lt;/p&gt;\n\n&lt;p&gt;Ive learned about sqlalchemy to use stuff like declarative base, creating tables for both the raw and the clean models, where raw holds the current data types, and clean the new actual database types. But I&amp;#39;m a bit confused as to why I would create a raw model when I can just transform the data I need and put them straight into the clean model. What Am I missing here?   &lt;/p&gt;\n\n&lt;p&gt;Also, is this even the desired solution for what I want to accomplish?   &lt;/p&gt;\n\n&lt;p&gt;THank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yujevd", "is_robot_indexable": true, "report_reasons": null, "author": "Brontonomo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yujevd/etl_question_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yujevd/etl_question_noob/", "subreddit_subscribers": 79948, "created_utc": 1668384702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I work daily with spark, aws and python in my current role and have 2years of DE experience. My employer has offered to pay for a certification of my choice and I was wondering if anyone had a recommend. \n\nBased upon questions like how valuable the certification feels/was the content interesting/does it help with employability. Thank you.", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommend for valuable certifications? (aws/spark/python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuil1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668382581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I work daily with spark, aws and python in my current role and have 2years of DE experience. My employer has offered to pay for a certification of my choice and I was wondering if anyone had a recommend. &lt;/p&gt;\n\n&lt;p&gt;Based upon questions like how valuable the certification feels/was the content interesting/does it help with employability. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yuil1m", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuil1m/any_recommend_for_valuable_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuil1m/any_recommend_for_valuable_certifications/", "subreddit_subscribers": 79948, "created_utc": 1668382581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a project at my university, I have to create a scalable platform for real-time video analytics.\n\nI am searching for a way to create a data pipeline that will capture one or multiple video streams and process them accordingly. After searching, I am thinking of creating a pipeline as follows:\n\n1. Capture video stream with something like Kafka/Akka streams and send frames to a topic/actor.\n2. Load the data to spark streaming and using OpenCV perform video analysis (motion detection, etc.)\n3. Store results to S3.\n\nHas anyone worked with similar data? Some feedback would be greatly appreciated.\n\nI have no limitations to the technologies that I can use. However, I am mostly familiar with python/scala.", "author_fullname": "t2_3msw9pp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about video stream pipeline - University project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufp19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668376513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a project at my university, I have to create a scalable platform for real-time video analytics.&lt;/p&gt;\n\n&lt;p&gt;I am searching for a way to create a data pipeline that will capture one or multiple video streams and process them accordingly. After searching, I am thinking of creating a pipeline as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Capture video stream with something like Kafka/Akka streams and send frames to a topic/actor.&lt;/li&gt;\n&lt;li&gt;Load the data to spark streaming and using OpenCV perform video analysis (motion detection, etc.)&lt;/li&gt;\n&lt;li&gt;Store results to S3.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Has anyone worked with similar data? Some feedback would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;I have no limitations to the technologies that I can use. However, I am mostly familiar with python/scala.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufp19", "is_robot_indexable": true, "report_reasons": null, "author": "andreas_9898", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufp19/question_about_video_stream_pipeline_university/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufp19/question_about_video_stream_pipeline_university/", "subreddit_subscribers": 79948, "created_utc": 1668376513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the best graph database usage scenario that you have encountered? I mean, something that made you say \"Wow, I didn't know that I could do that with graph databases\".", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best graph database usage scenario that you have encountered?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv1y0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668438108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best graph database usage scenario that you have encountered? I mean, something that made you say &amp;quot;Wow, I didn&amp;#39;t know that I could do that with graph databases&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yv1y0d", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv1y0d/what_is_the_best_graph_database_usage_scenario/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv1y0d/what_is_the_best_graph_database_usage_scenario/", "subreddit_subscribers": 79948, "created_utc": 1668438108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I am interested to share with you my article about Terraform and its configuration on azure . I'll be happy if you share with me your thoughts and comments.\n https://link.medium.com/e6uKq8jUWub", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "get started with Terraform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv0u1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668435739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I am interested to share with you my article about Terraform and its configuration on azure . I&amp;#39;ll be happy if you share with me your thoughts and comments.\n &lt;a href=\"https://link.medium.com/e6uKq8jUWub\"&gt;https://link.medium.com/e6uKq8jUWub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?auto=webp&amp;s=b794eed6f59ce00534ff32164c84d6cc6a71d519", "width": 1200, "height": 624}, "resolutions": [{"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d986dd432f37582c06604fc3e452d3f024e380d7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=43b262d9de75a90e3d62fab593a2d2af57f8520d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59fe33412aa44ef6c1a6192990d54ea8e7dfef83", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ead6af24f208c6803f0710013c7c83768fa8efe1", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee6e5f62e1187b836ee558df3f7ae0d3c14587ff", "width": 960, "height": 499}, {"url": "https://external-preview.redd.it/UMF5Mo2jN-tMdnLzKSBYHfLAEyxaX9SO40FjubO9e5M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba2875d61f55ebb2c49c97de6b14ac17e01c1f75", "width": 1080, "height": 561}], "variants": {}, "id": "cHfT9jHacbTASq0gkcdy0nSLJDpzTh9DUF8H5O6wT6M"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 125, "id": "award_5f123e3d-4f48-42f4-9c11-e98b566d5897", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "When you come across a feel-good thing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Wholesome", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yv0u1t", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv0u1t/get_started_with_terraform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv0u1t/get_started_with_terraform/", "subreddit_subscribers": 79948, "created_utc": 1668435739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer having 12 years of experience in various tools and technologies ranging from Oracle, Teradata, bigdata, Hadoop, spark, python mostly in the financial industry, what's the way forward someone like me going forward should I pursue data architect role or consulting? Or keep doing what I am doing?", "author_fullname": "t2_76w8juxu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data engineering job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yutut4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668417785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer having 12 years of experience in various tools and technologies ranging from Oracle, Teradata, bigdata, Hadoop, spark, python mostly in the financial industry, what&amp;#39;s the way forward someone like me going forward should I pursue data architect role or consulting? Or keep doing what I am doing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yutut4", "is_robot_indexable": true, "report_reasons": null, "author": "Separate-Boat8195", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yutut4/data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yutut4/data_engineering_job/", "subreddit_subscribers": 79948, "created_utc": 1668417785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I would like  to start a consultancy, to do some side projects on the side in the field of data analytics/ data engineering and maybe turn that into a full time job. I am currently working a senior data engineer/ consultant. \n\n\nHow do you approach new clients? \n\nHow would charge for the projects ? \n\nLike subscription model or one time off fees ?", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Land clients to starting consultancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yutl48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668416989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I would like  to start a consultancy, to do some side projects on the side in the field of data analytics/ data engineering and maybe turn that into a full time job. I am currently working a senior data engineer/ consultant. &lt;/p&gt;\n\n&lt;p&gt;How do you approach new clients? &lt;/p&gt;\n\n&lt;p&gt;How would charge for the projects ? &lt;/p&gt;\n\n&lt;p&gt;Like subscription model or one time off fees ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yutl48", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yutl48/how_land_clients_to_starting_consultancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yutl48/how_land_clients_to_starting_consultancy/", "subreddit_subscribers": 79948, "created_utc": 1668416989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you ever heard of infrastructure as code? This will tell you what it is about and why it is so useful:\n\n[https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2](https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2)", "author_fullname": "t2_3di0zmcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS CloudFormation Introduction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuths5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668416714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you ever heard of infrastructure as code? This will tell you what it is about and why it is so useful:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2\"&gt;https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?auto=webp&amp;s=76157e72d5fa325f969674de8d937b707e82a9c9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a81d0bbd7684d987ee985f2fd56ba142393be51c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e98e7a07131f09ec2fa4d2ea5ab203c33b013c5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c57778b500a5ce0ced8df1fd086cc428aae77747", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c21c14ab1c3ca06899bf28e0b3fd293d8dd689ab", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a8b34c649db8a185db2eb0ca6c02a272deed349", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1eb2653c7e920f3261387f50c014eb834b27d4fb", "width": 1080, "height": 1080}], "variants": {}, "id": "14PTcHLZhsWzPYIRL1KFxfSWbZxysOVvupddjIWQQfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yuths5", "is_robot_indexable": true, "report_reasons": null, "author": "EdgarHuber", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuths5/aws_cloudformation_introduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuths5/aws_cloudformation_introduction/", "subreddit_subscribers": 79948, "created_utc": 1668416714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n\nI'm currently dealing with a client that uses media files for ML (videos and high def pictures). Using ADLS gen2 the loading and training is pretty easy.\n\nOf course the drawbacks are mainly the costs associated, as we constantly load data into Azure and we move the models off-cloud and into my client' production environment. \n\nBecause of all the transfers in and out, our rising bandwidth costs are going to surpass the actual storage budget.\n\nDo you guys have any best practices we could implement to reduce associated costs or at least curb it ? \n\nThe first on our checklist was to verify that every services were on the same region which is pretty easy to manage. \nThank you guys \ud83e\udd16", "author_fullname": "t2_2jzoy43k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing bandwidth costs on Azure, any tips or best practices ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yut4jj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668415336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently dealing with a client that uses media files for ML (videos and high def pictures). Using ADLS gen2 the loading and training is pretty easy.&lt;/p&gt;\n\n&lt;p&gt;Of course the drawbacks are mainly the costs associated, as we constantly load data into Azure and we move the models off-cloud and into my client&amp;#39; production environment. &lt;/p&gt;\n\n&lt;p&gt;Because of all the transfers in and out, our rising bandwidth costs are going to surpass the actual storage budget.&lt;/p&gt;\n\n&lt;p&gt;Do you guys have any best practices we could implement to reduce associated costs or at least curb it ? &lt;/p&gt;\n\n&lt;p&gt;The first on our checklist was to verify that every services were on the same region which is pretty easy to manage. \nThank you guys \ud83e\udd16&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yut4jj", "is_robot_indexable": true, "report_reasons": null, "author": "FromageDangereux", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yut4jj/managing_bandwidth_costs_on_azure_any_tips_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yut4jj/managing_bandwidth_costs_on_azure_any_tips_or/", "subreddit_subscribers": 79948, "created_utc": 1668415336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.", "author_fullname": "t2_116kc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instant data model from 1000s of unique files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufzlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668377110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufzlk", "is_robot_indexable": true, "report_reasons": null, "author": "daeisfresh", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufzlk/instant_data_model_from_1000s_of_unique_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufzlk/instant_data_model_from_1000s_of_unique_files/", "subreddit_subscribers": 79948, "created_utc": 1668377110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dremio Contributes the Arrow Flight SQL JDBC Driver to the Apache Arrow Community \u2013 The Latest of Many Contributions | Dremio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_yv4z3z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VzybhJXLFA8l35ZZiFK_kRskUhsSQIe6puq46uqnwxk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668444257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/blog/dremio-contributes-the-arrow-flight-sql-jdbc-driver-to-the-apache-arrow-community-the-latest-of-many-contributions/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?auto=webp&amp;s=6e6cd51218e5daa44fda46e871254d67b4f0b028", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3ff4e8f3ca79122c80a3edca5e76f391dbe6bdfe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=33960553c96829ccee2547f8ab406130247c7384", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df3787d2c0c0fd87c0515f59c003c36736a729ec", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f2078e40e00eed2276fcc88816b7ba1fc0b1e1f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3ce6f95c31b9473961006a3d143d79d7513af6c5", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/UjPgQ6jvcKO9etGms391DZ5QsStmI1Zik2a3kQwEJ5s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=511268e51ae4130135da26f6139fe780805c37b2", "width": 1080, "height": 565}], "variants": {}, "id": "dwgv-bjmtKMXlgmwTW_CSzpXGhwr6pO9hwIr945P_3g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yv4z3z", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv4z3z/dremio_contributes_the_arrow_flight_sql_jdbc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/blog/dremio-contributes-the-arrow-flight-sql-jdbc-driver-to-the-apache-arrow-community-the-latest-of-many-contributions/", "subreddit_subscribers": 79948, "created_utc": 1668444257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will soon start my first internship as DE, and most companies told me that they want from me to tell them what I want to work on, which could orientate my internship. Because I'm a complete begginner, I have very few ideas about which software or framework I should ask to work on. My goal would be to get knowledge on the most used frameworks so that I can have a high value on the market and be able to change position easely. With your experience, what do you think I should ask ? For the \"fixed part\" of the internships, I'm supposed to work on pySpark / Scala / databricks / AWS and build API, from what i've been told.", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which software / framework to work on during my first internship ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv360n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668440645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will soon start my first internship as DE, and most companies told me that they want from me to tell them what I want to work on, which could orientate my internship. Because I&amp;#39;m a complete begginner, I have very few ideas about which software or framework I should ask to work on. My goal would be to get knowledge on the most used frameworks so that I can have a high value on the market and be able to change position easely. With your experience, what do you think I should ask ? For the &amp;quot;fixed part&amp;quot; of the internships, I&amp;#39;m supposed to work on pySpark / Scala / databricks / AWS and build API, from what i&amp;#39;ve been told.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yv360n", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv360n/which_software_framework_to_work_on_during_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv360n/which_software_framework_to_work_on_during_my/", "subreddit_subscribers": 79948, "created_utc": 1668440645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an Azure engineer, and a majority of my end users are data scientists/engineers.  One of them is looking at using Airflow to trigger Azure Databricks jobs, and I'm doing a bare bones POC of Airflow based on an [Azure quickstart template](https://azure.microsoft.com/en-us/blog/deploying-apache-airflow-in-azure-to-build-and-run-data-pipelines/) using [Puckel's dockerhub Airflow image](https://hub.docker.com/r/puckel/docker-airflow/) (yes, it's gone 3 years since updating; I'm only using it for a POC, not production)  The deployment is working fine, I'm just poking through Airflow's interface, and had a few questions that I can't quite seem to find answers to in my research so far:\n\n* Are the users created via Admin -&gt; Users created as local users on the Postgres DB?  If so, does creating them as a superuser grant them rights to the DB or is it just superuser for Airflow?\n* If an Airflow pool is defined, does it impact the number of worker nodes that Databricks spawns to run the jobs in that pool?  Or is there no relationship between them?\n* Where do I specify the parameters called out in [this site covering connections to Azure service principals](https://airflow.apache.org/docs/apache-airflow-providers-microsoft-azure/stable/connections/azure.html)?", "author_fullname": "t2_6syo2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got a few questions on Airflow administration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv1uee", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668437919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an Azure engineer, and a majority of my end users are data scientists/engineers.  One of them is looking at using Airflow to trigger Azure Databricks jobs, and I&amp;#39;m doing a bare bones POC of Airflow based on an &lt;a href=\"https://azure.microsoft.com/en-us/blog/deploying-apache-airflow-in-azure-to-build-and-run-data-pipelines/\"&gt;Azure quickstart template&lt;/a&gt; using &lt;a href=\"https://hub.docker.com/r/puckel/docker-airflow/\"&gt;Puckel&amp;#39;s dockerhub Airflow image&lt;/a&gt; (yes, it&amp;#39;s gone 3 years since updating; I&amp;#39;m only using it for a POC, not production)  The deployment is working fine, I&amp;#39;m just poking through Airflow&amp;#39;s interface, and had a few questions that I can&amp;#39;t quite seem to find answers to in my research so far:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are the users created via Admin -&amp;gt; Users created as local users on the Postgres DB?  If so, does creating them as a superuser grant them rights to the DB or is it just superuser for Airflow?&lt;/li&gt;\n&lt;li&gt;If an Airflow pool is defined, does it impact the number of worker nodes that Databricks spawns to run the jobs in that pool?  Or is there no relationship between them?&lt;/li&gt;\n&lt;li&gt;Where do I specify the parameters called out in &lt;a href=\"https://airflow.apache.org/docs/apache-airflow-providers-microsoft-azure/stable/connections/azure.html\"&gt;this site covering connections to Azure service principals&lt;/a&gt;?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?auto=webp&amp;s=e3a3a19cf9b697e7dcb28ae5b14cc74cf9acd8c9", "width": 250, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=39e43cac4fbf358f8c0a5159c6c8bd2b60cc3cf0", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c452c2a15536677a4f16f14f69109d2fd7dc239a", "width": 216, "height": 216}], "variants": {}, "id": "Ln1lNDqLGYB-op_KKWkMJ3CIwoutiembrNZnyFULkZ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv1uee", "is_robot_indexable": true, "report_reasons": null, "author": "MohnJaddenPowers", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv1uee/got_a_few_questions_on_airflow_administration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv1uee/got_a_few_questions_on_airflow_administration/", "subreddit_subscribers": 79948, "created_utc": 1668437919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a web developer for 7 years and truly dread doing it now. I want to focus more on databases or cloud. It gets me excited when im working on databases. For some background, i never finished my college degree i got hired by a start up company before I could graduate I\u2019m now working for the government making 100k. I feel extremely lucky to land this job even without a degree but how hard would it be to transition to data engineering? Would certifications be enough? What path should i take? \n\nMy skills rn:\nNode.js typescript angular \nC# asp.net mvc\nBlazor \nSSMS SSRS SSIS \nPower Bi, dax\nAzure devops", "author_fullname": "t2_9bawc33i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Path to becoming Data Engineer 2022?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv1dof", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668436916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a web developer for 7 years and truly dread doing it now. I want to focus more on databases or cloud. It gets me excited when im working on databases. For some background, i never finished my college degree i got hired by a start up company before I could graduate I\u2019m now working for the government making 100k. I feel extremely lucky to land this job even without a degree but how hard would it be to transition to data engineering? Would certifications be enough? What path should i take? &lt;/p&gt;\n\n&lt;p&gt;My skills rn:\nNode.js typescript angular \nC# asp.net mvc\nBlazor \nSSMS SSRS SSIS \nPower Bi, dax\nAzure devops&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yv1dof", "is_robot_indexable": true, "report_reasons": null, "author": "Possible_Original326", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv1dof/path_to_becoming_data_engineer_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv1dof/path_to_becoming_data_engineer_2022/", "subreddit_subscribers": 79948, "created_utc": 1668436916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings, \nI would like to hear your experiences with using Datavault and maybe suggestions on how to proceed. \nBackground infromation: I've been managing a 20+ internal application datavault in my organisation for 2+ years. The goal was to replace Dashboards directly connected to the applications with a Datawarehouse using the data vault model. \nSo, the problem: the longer the datavault is being used the further data quality is being degraded. Its easy to blame other's, duing the interviews they claimed that the business keys were unique, but after a while i observe that that is not the case. Or records being deleted while they specifically stated that that is not the case ( and the application even has a row closed column). The result is that dashboards based on the datawarehouse show incorrect numbers and we are to blame. \n\nExamples: \n1)Process explained to me: Sale records must be unique and have at least one product. If sale is annulled the record gets a sign that its annulled. \n1)Reality: If a product is no longer sold all sale records are purged from the system because reasons.... \n\n2)Process explained to me:An employee ID is unique and identifies a  single natural person\n2)Reality: A temp worker is replacing another temp worker, HR is lazy and just changes an existing ID persons name,age, ets. \n The challenge is that the data is not faulty at  any one point in time: Its just that processes are not adhered to and thus the only way to get correct data is to purge the data vault.", "author_fullname": "t2_ippbo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those who have worked with Datavault, do you have any suggestions on how to proceed ( story inside)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv0hcm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668434965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, \nI would like to hear your experiences with using Datavault and maybe suggestions on how to proceed. \nBackground infromation: I&amp;#39;ve been managing a 20+ internal application datavault in my organisation for 2+ years. The goal was to replace Dashboards directly connected to the applications with a Datawarehouse using the data vault model. \nSo, the problem: the longer the datavault is being used the further data quality is being degraded. Its easy to blame other&amp;#39;s, duing the interviews they claimed that the business keys were unique, but after a while i observe that that is not the case. Or records being deleted while they specifically stated that that is not the case ( and the application even has a row closed column). The result is that dashboards based on the datawarehouse show incorrect numbers and we are to blame. &lt;/p&gt;\n\n&lt;p&gt;Examples: \n1)Process explained to me: Sale records must be unique and have at least one product. If sale is annulled the record gets a sign that its annulled. \n1)Reality: If a product is no longer sold all sale records are purged from the system because reasons.... &lt;/p&gt;\n\n&lt;p&gt;2)Process explained to me:An employee ID is unique and identifies a  single natural person\n2)Reality: A temp worker is replacing another temp worker, HR is lazy and just changes an existing ID persons name,age, ets. \n The challenge is that the data is not faulty at  any one point in time: Its just that processes are not adhered to and thus the only way to get correct data is to purge the data vault.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv0hcm", "is_robot_indexable": true, "report_reasons": null, "author": "roadrussian", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv0hcm/to_those_who_have_worked_with_datavault_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv0hcm/to_those_who_have_worked_with_datavault_do_you/", "subreddit_subscribers": 79948, "created_utc": 1668434965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2 instances (and 2 databases) that I would like to merge into 1 instance . The issue is that though schema is same for both database I would need to merge data and insert it in the dependency order.  Hence I would need to build custom script that programmatically pulls the data dump (based on some condition) and inserts it into destination. Is there any tool/sample that does the similar functionality or maybe an easier way I am not seeing. \n\nAlso is there anyway to perform the same keeping the original database online (without downtime).", "author_fullname": "t2_iywxzldm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merge 2 databases programatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuxwj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668428956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 instances (and 2 databases) that I would like to merge into 1 instance . The issue is that though schema is same for both database I would need to merge data and insert it in the dependency order.  Hence I would need to build custom script that programmatically pulls the data dump (based on some condition) and inserts it into destination. Is there any tool/sample that does the similar functionality or maybe an easier way I am not seeing. &lt;/p&gt;\n\n&lt;p&gt;Also is there anyway to perform the same keeping the original database online (without downtime).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yuxwj8", "is_robot_indexable": true, "report_reasons": null, "author": "Aztreix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuxwj8/merge_2_databases_programatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuxwj8/merge_2_databases_programatically/", "subreddit_subscribers": 79948, "created_utc": 1668428956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ugjew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tulip: Schematizing Meta\u2019s data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yuxqor", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b8z_zdQvvuMArj5NFKjCmuYof4eSXcfNPz69X7FLX7g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668428550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "engineering.fb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://engineering.fb.com/2022/11/09/developer-tools/tulip-schematizing-metas-data-platform/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?auto=webp&amp;s=985d9e86a60cd42c7c5961832c39f69ed8c48fe3", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220d8d5f11385f3fe6570b772aeea4bbace3099a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=08170c62a860a68e2eecc7f37b0fea26567ddb35", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15e9b80a4c44d3b89ab20b5985f6eec284ea0ee1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aad16a28dc7cec8a06ac005a9fb6b186cb06ae21", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60a7dd1ce23d82dd958b95473c659ff4a03785b5", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=79e4e12be1474061277a14f00e22094ed77d7a57", "width": 1080, "height": 607}], "variants": {}, "id": "8UfhOBudgsBvsTzSSr5lnkSwwiBO5L0NuKwtFuEAhjI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yuxqor", "is_robot_indexable": true, "report_reasons": null, "author": "marcosluis2186", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuxqor/tulip_schematizing_metas_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://engineering.fb.com/2022/11/09/developer-tools/tulip-schematizing-metas-data-platform/", "subreddit_subscribers": 79948, "created_utc": 1668428550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This might be a dumb question, but I need help please. \n\n\nI am an Intern who collaborated with one other engineer to build the entire end to end data system for a funded private equity firm, between the two of us. How could I word this on my resume without coming off like I am bragging?", "author_fullname": "t2_9ghl0zs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yujpxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668387089.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668385538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a dumb question, but I need help please. &lt;/p&gt;\n\n&lt;p&gt;I am an Intern who collaborated with one other engineer to build the entire end to end data system for a funded private equity firm, between the two of us. How could I word this on my resume without coming off like I am bragging?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yujpxs", "is_robot_indexable": true, "report_reasons": null, "author": "Perfect_Kangaroo6233", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yujpxs/help_with_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yujpxs/help_with_resume/", "subreddit_subscribers": 79948, "created_utc": 1668385538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you Guys Dealing with Ransomware.My Company is hit by this monster very much every Now and Then. How you guys are Securing the Environment ? Keep in mind our half of the Employees are Remote. They ask us to Open Sql defualt Port. Which we Think is cause of this problem..\n\nIf Someone have a Remedy please share.looking Forward to receive your Suggestions.Thank you", "author_fullname": "t2_4aa2ruvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Probably Irrelevant Question here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuafy9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668365690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you Guys Dealing with Ransomware.My Company is hit by this monster very much every Now and Then. How you guys are Securing the Environment ? Keep in mind our half of the Employees are Remote. They ask us to Open Sql defualt Port. Which we Think is cause of this problem..&lt;/p&gt;\n\n&lt;p&gt;If Someone have a Remedy please share.looking Forward to receive your Suggestions.Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yuafy9", "is_robot_indexable": true, "report_reasons": null, "author": "IKhalidAwan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuafy9/probably_irrelevant_question_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuafy9/probably_irrelevant_question_here/", "subreddit_subscribers": 79948, "created_utc": 1668365690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am a data engineer on my third year. I need perspective about my career progression, because I feel like I am not making any.\n\nMy experience: \n\n- 1st company ( 2 years 4months ) : building ETLs in Python and developing dashboards in Power Bi \n\n- 2nd company ( 5months and still ): Talend ETLs and Power Bi dashboards \n\nThe tech stack I covered is very basic and still at the surface of DE imo. I don't even think dashboard development is DE related. \n\n\nI am now looking up job offers on the market and I feel like all the high paying jobs are out of my reach. I am constantly trying to learn new tech on my own but it can hardly be as relevant. Unlike software dev, DE requires a bit of existing context and infrastructure.\n\nAt work, they really don't ask for much innovation or problem solving, it's just the same tasks all the time. And everyone around me is content with this so I feel kinda overqualified for what I am asked to do.\n\nWhat I want :\n- become a very good data engineer in the next two years, industry wise.\n\nWhat's on my mind :\n- find another job somewhere else\n- be patient and wait\n- work on a side project\n- freelance\n\n\nAny suggestions?", "author_fullname": "t2_gr70g2z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I switch jobs / be patient / work a side project ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu86mc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668360765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a data engineer on my third year. I need perspective about my career progression, because I feel like I am not making any.&lt;/p&gt;\n\n&lt;p&gt;My experience: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;1st company ( 2 years 4months ) : building ETLs in Python and developing dashboards in Power Bi &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2nd company ( 5months and still ): Talend ETLs and Power Bi dashboards &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The tech stack I covered is very basic and still at the surface of DE imo. I don&amp;#39;t even think dashboard development is DE related. &lt;/p&gt;\n\n&lt;p&gt;I am now looking up job offers on the market and I feel like all the high paying jobs are out of my reach. I am constantly trying to learn new tech on my own but it can hardly be as relevant. Unlike software dev, DE requires a bit of existing context and infrastructure.&lt;/p&gt;\n\n&lt;p&gt;At work, they really don&amp;#39;t ask for much innovation or problem solving, it&amp;#39;s just the same tasks all the time. And everyone around me is content with this so I feel kinda overqualified for what I am asked to do.&lt;/p&gt;\n\n&lt;p&gt;What I want :\n- become a very good data engineer in the next two years, industry wise.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s on my mind :\n- find another job somewhere else\n- be patient and wait\n- work on a side project\n- freelance&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yu86mc", "is_robot_indexable": true, "report_reasons": null, "author": "pursuuer", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yu86mc/should_i_switch_jobs_be_patient_work_a_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yu86mc/should_i_switch_jobs_be_patient_work_a_side/", "subreddit_subscribers": 79948, "created_utc": 1668360765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\nI'll be in a take-home assessment which will take 5 hours for data engineer role in a remote company \n\nDo you have any advice on how to deal with this?", "author_fullname": "t2_59165ick", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data engineer assessment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yv2ddc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668439006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello\nI&amp;#39;ll be in a take-home assessment which will take 5 hours for data engineer role in a remote company &lt;/p&gt;\n\n&lt;p&gt;Do you have any advice on how to deal with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yv2ddc", "is_robot_indexable": true, "report_reasons": null, "author": "1Hesham", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yv2ddc/data_engineer_assessment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yv2ddc/data_engineer_assessment/", "subreddit_subscribers": 79948, "created_utc": 1668439006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My Stats:\n\nCareer progression (in academia adjacent org):\nData Analytics Intern (7months)-&gt;\nSoftware Engineer (all data related stuff, 1.5 years)-&gt;\nData Scientist (2 months)\n\n\nEducation: \n\n-MS Data Science (in progress)\n-BS in Information Science, minor CS\n\n\nThings I know: \n- Python + common data libs, C/C++, SQL\n\n-PySpark, Dask\n\n-Tensorflow, scikit \n\n-Docker\n\n\nMy weaknesses:\n\n-little experience in the cloud, no way to get on job experience in my current role (dysfunctional legacy organization)\n\n-not an expert in SQL, we don\u2019t use SQL databases in my org very much (mostly parquet files and other alternatives) \n\n\n\nWhat is my path to become DE? Should I get an AWS certification, or a Spark, Docker, or Kubernetes certification? What is my path to transition to DE?  Will my current experience help me?", "author_fullname": "t2_b7eqz4bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my path to becoming a DE from a SWE/DS background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yub8zq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668367751.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668367531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Stats:&lt;/p&gt;\n\n&lt;p&gt;Career progression (in academia adjacent org):\nData Analytics Intern (7months)-&amp;gt;\nSoftware Engineer (all data related stuff, 1.5 years)-&amp;gt;\nData Scientist (2 months)&lt;/p&gt;\n\n&lt;p&gt;Education: &lt;/p&gt;\n\n&lt;p&gt;-MS Data Science (in progress)\n-BS in Information Science, minor CS&lt;/p&gt;\n\n&lt;p&gt;Things I know: \n- Python + common data libs, C/C++, SQL&lt;/p&gt;\n\n&lt;p&gt;-PySpark, Dask&lt;/p&gt;\n\n&lt;p&gt;-Tensorflow, scikit &lt;/p&gt;\n\n&lt;p&gt;-Docker&lt;/p&gt;\n\n&lt;p&gt;My weaknesses:&lt;/p&gt;\n\n&lt;p&gt;-little experience in the cloud, no way to get on job experience in my current role (dysfunctional legacy organization)&lt;/p&gt;\n\n&lt;p&gt;-not an expert in SQL, we don\u2019t use SQL databases in my org very much (mostly parquet files and other alternatives) &lt;/p&gt;\n\n&lt;p&gt;What is my path to become DE? Should I get an AWS certification, or a Spark, Docker, or Kubernetes certification? What is my path to transition to DE?  Will my current experience help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yub8zq", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Box228", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yub8zq/what_is_my_path_to_becoming_a_de_from_a_sweds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yub8zq/what_is_my_path_to_becoming_a_de_from_a_sweds/", "subreddit_subscribers": 79948, "created_utc": 1668367531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data hygiene implements the essential framework to keep your data in the right form, thereby helping you to operate your data-driven strategies immaculately. Understand how data hygiene creates a long-term impact by improving your business in various ways.\n\nhttps://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;format=pjpg&amp;auto=webp&amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5", "author_fullname": "t2_3ataz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Is Data Hygiene So Important For B2B Companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "media_metadata": {"diwn3kjtnwz91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=482c9e29ec2804d477dbe65e701ce5f08e07ce8b"}, {"y": 106, "x": 216, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=423c157af793432d7190f2e86cdbd9f0cfe1793b"}, {"y": 158, "x": 320, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=93c46f9c7579ff5def24290a0297e58436419ed0"}, {"y": 316, "x": 640, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8836bf608db7463fe50b1358f6555983f0755ed1"}, {"y": 474, "x": 960, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d99ca9cf5cf73e5a768fee190fce96548013cf4a"}], "s": {"y": 494, "x": 1000, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;format=pjpg&amp;auto=webp&amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5"}, "id": "diwn3kjtnwz91"}}, "name": "t3_yux1v4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/HvAWRaZzCbzoLB7Tj5XukmvrsRasluHysTjRmfr9yG8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668426776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data hygiene implements the essential framework to keep your data in the right form, thereby helping you to operate your data-driven strategies immaculately. Understand how data hygiene creates a long-term impact by improving your business in various ways.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5\"&gt;https://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yux1v4", "is_robot_indexable": true, "report_reasons": null, "author": "hitechbpo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yux1v4/why_is_data_hygiene_so_important_for_b2b_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yux1v4/why_is_data_hygiene_so_important_for_b2b_companies/", "subreddit_subscribers": 79948, "created_utc": 1668426776.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}