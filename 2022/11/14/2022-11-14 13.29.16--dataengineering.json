{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know the best way to find part time work (\\~20 hrs/wk as freelance/independent contractor) as a data engineer?\n\nRecruiters? Job sites? I\u2019ve thought about toptal/upwork but figured going out on my own is better", "author_fullname": "t2_gnj3pgpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Part Time Job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yui8kn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668381751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know the best way to find part time work (~20 hrs/wk as freelance/independent contractor) as a data engineer?&lt;/p&gt;\n\n&lt;p&gt;Recruiters? Job sites? I\u2019ve thought about toptal/upwork but figured going out on my own is better&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yui8kn", "is_robot_indexable": true, "report_reasons": null, "author": "Kini_J", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yui8kn/data_engineer_part_time_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yui8kn/data_engineer_part_time_job/", "subreddit_subscribers": 79930, "created_utc": 1668381751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e35wa210", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ways to Reduce Cloud Data Storage Costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_yu1y7w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BR7Ydd3yS_qMJvwjYquoKWc6eRRq6O_Ou10O84e8mtI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668346758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/reduce-cloud-data-storage-costs/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?auto=webp&amp;s=684f4aac33ad5fe9070a30f22295f326b7942005", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9861811e3825801fc6fed566677322d8c8578897", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40f02af6d93a490ed00b39fa8fe1a751c7eb9348", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eefb32db73650128169e38522554b2739f498b86", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3171ac42e695efc917141b9a1d122cf02d469b2", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6621dd4b26a31181a1237291e9118c8750d972e1", "width": 960, "height": 640}], "variants": {}, "id": "kINy1ajoFKyLTXfkoosJqlXODMAMyjqHwSZDTm3gJ7k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yu1y7w", "is_robot_indexable": true, "report_reasons": null, "author": "pinpepnet", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu1y7w/ways_to_reduce_cloud_data_storage_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/reduce-cloud-data-storage-costs/", "subreddit_subscribers": 79930, "created_utc": 1668346758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best practices to load large data into a cloud datawarehouse like snowflake? Lets say I have 10 tables (each table size is &gt; 50gb) in a source database and I am using s3 as a intermediate storage layer. What is the best approach to load this data? Should I split the data in each source table into smaller files and load it? If splitting the data into smaller files is recommended, please explain me the reason to follow this approach.", "author_fullname": "t2_sde7upnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices to load large data file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuudwe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668419371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best practices to load large data into a cloud datawarehouse like snowflake? Lets say I have 10 tables (each table size is &amp;gt; 50gb) in a source database and I am using s3 as a intermediate storage layer. What is the best approach to load this data? Should I split the data in each source table into smaller files and load it? If splitting the data into smaller files is recommended, please explain me the reason to follow this approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yuudwe", "is_robot_indexable": true, "report_reasons": null, "author": "bharath-t", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuudwe/best_practices_to_load_large_data_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuudwe/best_practices_to_load_large_data_file/", "subreddit_subscribers": 79930, "created_utc": 1668419371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_le8pcuu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SCC. Kubernetes: Orchestration Close to Decentralization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yu7dj7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fVKAXjW3uaLQzGNAX-_bFR-5I2uybeAcRJgX7UF5-TI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668358827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "superprotocol.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://superprotocol.medium.com/scc-kubernetes-orchestration-close-to-decentralization-9c7047026c71", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?auto=webp&amp;s=7ce63f504d38ee3b7f1ae262673c101e26972fdc", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=00101b2318e2a983c2201c2d58f120d026c3b28d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2bf7a45402cb2142829660f799995bdd24772d65", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d896ddb634177f122889c724604e13f6faf121b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4ab1f9901785f17a93a528b99394c5cd566aa5b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5fc5eb51ea143c7576a86de05d9a2c980a241ec4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e7f18fc12e303bee93797cc88c5ea4e4ceca324e", "width": 1080, "height": 607}], "variants": {}, "id": "KZ6x_Bx0E-g_2s7HZaRLSO1uEeVx7geH40O5eZHpjZI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yu7dj7", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional-Instance82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu7dj7/scc_kubernetes_orchestration_close_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://superprotocol.medium.com/scc-kubernetes-orchestration-close-to-decentralization-9c7047026c71", "subreddit_subscribers": 79930, "created_utc": 1668358827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer having 12 years of experience in various tools and technologies ranging from Oracle, Teradata, bigdata, Hadoop, spark, python mostly in the financial industry, what's the way forward someone like me going forward should I pursue data architect role or consulting? Or keep doing what I am doing?", "author_fullname": "t2_76w8juxu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data engineering job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yutut4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668417785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer having 12 years of experience in various tools and technologies ranging from Oracle, Teradata, bigdata, Hadoop, spark, python mostly in the financial industry, what&amp;#39;s the way forward someone like me going forward should I pursue data architect role or consulting? Or keep doing what I am doing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yutut4", "is_robot_indexable": true, "report_reasons": null, "author": "Separate-Boat8195", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yutut4/data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yutut4/data_engineering_job/", "subreddit_subscribers": 79930, "created_utc": 1668417785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i'm creating a pipeline that is ingesting from 2 sources, both API's and want to transform, and load them into a single table in an external database. The table does not exist.\n\nSo far I have taken both json responses and put them into seperate source .json files (should I? as a best practice?) and then also used pandas to create 2 additional csv files (for no particular reason?) from the json files.   \nDoes this even make sense?   \n\n\nNow I want to create a table and populate it with some of the fields (not all).\n\nIve learned about sqlalchemy to use stuff like declarative base, creating tables for both the raw and the clean models, where raw holds the current data types, and clean the new actual database types. But I'm a bit confused as to why I would create a raw model when I can just transform the data I need and put them straight into the clean model. What Am I missing here?   \n\n\nAlso, is this even the desired solution for what I want to accomplish?   \n\n\nTHank you!", "author_fullname": "t2_6kipsr88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL question (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yujevd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668384702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;m creating a pipeline that is ingesting from 2 sources, both API&amp;#39;s and want to transform, and load them into a single table in an external database. The table does not exist.&lt;/p&gt;\n\n&lt;p&gt;So far I have taken both json responses and put them into seperate source .json files (should I? as a best practice?) and then also used pandas to create 2 additional csv files (for no particular reason?) from the json files.&lt;br/&gt;\nDoes this even make sense?   &lt;/p&gt;\n\n&lt;p&gt;Now I want to create a table and populate it with some of the fields (not all).&lt;/p&gt;\n\n&lt;p&gt;Ive learned about sqlalchemy to use stuff like declarative base, creating tables for both the raw and the clean models, where raw holds the current data types, and clean the new actual database types. But I&amp;#39;m a bit confused as to why I would create a raw model when I can just transform the data I need and put them straight into the clean model. What Am I missing here?   &lt;/p&gt;\n\n&lt;p&gt;Also, is this even the desired solution for what I want to accomplish?   &lt;/p&gt;\n\n&lt;p&gt;THank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yujevd", "is_robot_indexable": true, "report_reasons": null, "author": "Brontonomo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yujevd/etl_question_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yujevd/etl_question_noob/", "subreddit_subscribers": 79930, "created_utc": 1668384702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I work daily with spark, aws and python in my current role and have 2years of DE experience. My employer has offered to pay for a certification of my choice and I was wondering if anyone had a recommend. \n\nBased upon questions like how valuable the certification feels/was the content interesting/does it help with employability. Thank you.", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommend for valuable certifications? (aws/spark/python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuil1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668382581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I work daily with spark, aws and python in my current role and have 2years of DE experience. My employer has offered to pay for a certification of my choice and I was wondering if anyone had a recommend. &lt;/p&gt;\n\n&lt;p&gt;Based upon questions like how valuable the certification feels/was the content interesting/does it help with employability. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yuil1m", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuil1m/any_recommend_for_valuable_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuil1m/any_recommend_for_valuable_certifications/", "subreddit_subscribers": 79930, "created_utc": 1668382581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any one working on any open source contribution for data engineering tools/technologies? I would like to join", "author_fullname": "t2_4f1ts4ru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Open Source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu3m38", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668350640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any one working on any open source contribution for data engineering tools/technologies? I would like to join&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yu3m38", "is_robot_indexable": true, "report_reasons": null, "author": "Subramaniam_DataEngr", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu3m38/de_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yu3m38/de_open_source/", "subreddit_subscribers": 79930, "created_utc": 1668350640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you ever heard of infrastructure as code? This will tell you what it is about and why it is so useful:\n\n[https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2](https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2)", "author_fullname": "t2_3di0zmcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS CloudFormation Introduction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuths5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668416714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you ever heard of infrastructure as code? This will tell you what it is about and why it is so useful:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2\"&gt;https://erwinschleier.medium.com/aws-cloudformation-introduction-e6d6f3fe89d2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?auto=webp&amp;s=76157e72d5fa325f969674de8d937b707e82a9c9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a81d0bbd7684d987ee985f2fd56ba142393be51c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e98e7a07131f09ec2fa4d2ea5ab203c33b013c5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c57778b500a5ce0ced8df1fd086cc428aae77747", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c21c14ab1c3ca06899bf28e0b3fd293d8dd689ab", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a8b34c649db8a185db2eb0ca6c02a272deed349", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1eb2653c7e920f3261387f50c014eb834b27d4fb", "width": 1080, "height": 1080}], "variants": {}, "id": "14PTcHLZhsWzPYIRL1KFxfSWbZxysOVvupddjIWQQfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yuths5", "is_robot_indexable": true, "report_reasons": null, "author": "EdgarHuber", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuths5/aws_cloudformation_introduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuths5/aws_cloudformation_introduction/", "subreddit_subscribers": 79930, "created_utc": 1668416714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a project at my university, I have to create a scalable platform for real-time video analytics.\n\nI am searching for a way to create a data pipeline that will capture one or multiple video streams and process them accordingly. After searching, I am thinking of creating a pipeline as follows:\n\n1. Capture video stream with something like Kafka/Akka streams and send frames to a topic/actor.\n2. Load the data to spark streaming and using OpenCV perform video analysis (motion detection, etc.)\n3. Store results to S3.\n\nHas anyone worked with similar data? Some feedback would be greatly appreciated.\n\nI have no limitations to the technologies that I can use. However, I am mostly familiar with python/scala.", "author_fullname": "t2_3msw9pp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about video stream pipeline - University project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufp19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668376513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a project at my university, I have to create a scalable platform for real-time video analytics.&lt;/p&gt;\n\n&lt;p&gt;I am searching for a way to create a data pipeline that will capture one or multiple video streams and process them accordingly. After searching, I am thinking of creating a pipeline as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Capture video stream with something like Kafka/Akka streams and send frames to a topic/actor.&lt;/li&gt;\n&lt;li&gt;Load the data to spark streaming and using OpenCV perform video analysis (motion detection, etc.)&lt;/li&gt;\n&lt;li&gt;Store results to S3.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Has anyone worked with similar data? Some feedback would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;I have no limitations to the technologies that I can use. However, I am mostly familiar with python/scala.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufp19", "is_robot_indexable": true, "report_reasons": null, "author": "andreas_9898", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufp19/question_about_video_stream_pipeline_university/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufp19/question_about_video_stream_pipeline_university/", "subreddit_subscribers": 79930, "created_utc": 1668376513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I would like  to start a consultancy, to do some side projects on the side in the field of data analytics/ data engineering and maybe turn that into a full time job. I am currently working a senior data engineer/ consultant. \n\n\nHow do you approach new clients? \n\nHow would charge for the projects ? \n\nLike subscription model or one time off fees ?", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Land clients to starting consultancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yutl48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668416989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I would like  to start a consultancy, to do some side projects on the side in the field of data analytics/ data engineering and maybe turn that into a full time job. I am currently working a senior data engineer/ consultant. &lt;/p&gt;\n\n&lt;p&gt;How do you approach new clients? &lt;/p&gt;\n\n&lt;p&gt;How would charge for the projects ? &lt;/p&gt;\n\n&lt;p&gt;Like subscription model or one time off fees ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yutl48", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yutl48/how_land_clients_to_starting_consultancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yutl48/how_land_clients_to_starting_consultancy/", "subreddit_subscribers": 79930, "created_utc": 1668416989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n\nI'm currently dealing with a client that uses media files for ML (videos and high def pictures). Using ADLS gen2 the loading and training is pretty easy.\n\nOf course the drawbacks are mainly the costs associated, as we constantly load data into Azure and we move the models off-cloud and into my client' production environment. \n\nBecause of all the transfers in and out, our rising bandwidth costs are going to surpass the actual storage budget.\n\nDo you guys have any best practices we could implement to reduce associated costs or at least curb it ? \n\nThe first on our checklist was to verify that every services were on the same region which is pretty easy to manage. \nThank you guys \ud83e\udd16", "author_fullname": "t2_2jzoy43k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing bandwidth costs on Azure, any tips or best practices ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yut4jj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668415336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently dealing with a client that uses media files for ML (videos and high def pictures). Using ADLS gen2 the loading and training is pretty easy.&lt;/p&gt;\n\n&lt;p&gt;Of course the drawbacks are mainly the costs associated, as we constantly load data into Azure and we move the models off-cloud and into my client&amp;#39; production environment. &lt;/p&gt;\n\n&lt;p&gt;Because of all the transfers in and out, our rising bandwidth costs are going to surpass the actual storage budget.&lt;/p&gt;\n\n&lt;p&gt;Do you guys have any best practices we could implement to reduce associated costs or at least curb it ? &lt;/p&gt;\n\n&lt;p&gt;The first on our checklist was to verify that every services were on the same region which is pretty easy to manage. \nThank you guys \ud83e\udd16&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yut4jj", "is_robot_indexable": true, "report_reasons": null, "author": "FromageDangereux", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yut4jj/managing_bandwidth_costs_on_azure_any_tips_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yut4jj/managing_bandwidth_costs_on_azure_any_tips_or/", "subreddit_subscribers": 79930, "created_utc": 1668415336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This might be a dumb question, but I need help please. \n\n\nI am an Intern who collaborated with one other engineer to build the entire end to end data system for a funded private equity firm, between the two of us. How could I word this on my resume without coming off like I am bragging?", "author_fullname": "t2_9ghl0zs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yujpxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668387089.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668385538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a dumb question, but I need help please. &lt;/p&gt;\n\n&lt;p&gt;I am an Intern who collaborated with one other engineer to build the entire end to end data system for a funded private equity firm, between the two of us. How could I word this on my resume without coming off like I am bragging?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yujpxs", "is_robot_indexable": true, "report_reasons": null, "author": "Perfect_Kangaroo6233", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yujpxs/help_with_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yujpxs/help_with_resume/", "subreddit_subscribers": 79930, "created_utc": 1668385538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.", "author_fullname": "t2_116kc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instant data model from 1000s of unique files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufzlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668377110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufzlk", "is_robot_indexable": true, "report_reasons": null, "author": "daeisfresh", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufzlk/instant_data_model_from_1000s_of_unique_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufzlk/instant_data_model_from_1000s_of_unique_files/", "subreddit_subscribers": 79930, "created_utc": 1668377110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2 instances (and 2 databases) that I would like to merge into 1 instance . The issue is that though schema is same for both database I would need to merge data and insert it in the dependency order.  Hence I would need to build custom script that programmatically pulls the data dump (based on some condition) and inserts it into destination. Is there any tool/sample that does the similar functionality or maybe an easier way I am not seeing. \n\nAlso is there anyway to perform the same keeping the original database online (without downtime).", "author_fullname": "t2_iywxzldm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merge 2 databases programatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yuxwj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668428956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 instances (and 2 databases) that I would like to merge into 1 instance . The issue is that though schema is same for both database I would need to merge data and insert it in the dependency order.  Hence I would need to build custom script that programmatically pulls the data dump (based on some condition) and inserts it into destination. Is there any tool/sample that does the similar functionality or maybe an easier way I am not seeing. &lt;/p&gt;\n\n&lt;p&gt;Also is there anyway to perform the same keeping the original database online (without downtime).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yuxwj8", "is_robot_indexable": true, "report_reasons": null, "author": "Aztreix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuxwj8/merge_2_databases_programatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuxwj8/merge_2_databases_programatically/", "subreddit_subscribers": 79930, "created_utc": 1668428956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": ".", "author_fullname": "t2_a031mtnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What accreditation is required for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuw07u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668423975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yuw07u", "is_robot_indexable": true, "report_reasons": null, "author": "Parking-Age-6974", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuw07u/what_accreditation_is_required_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuw07u/what_accreditation_is_required_for_data/", "subreddit_subscribers": 79930, "created_utc": 1668423975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you Guys Dealing with Ransomware.My Company is hit by this monster very much every Now and Then. How you guys are Securing the Environment ? Keep in mind our half of the Employees are Remote. They ask us to Open Sql defualt Port. Which we Think is cause of this problem..\n\nIf Someone have a Remedy please share.looking Forward to receive your Suggestions.Thank you", "author_fullname": "t2_4aa2ruvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Probably Irrelevant Question here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuafy9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668365690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you Guys Dealing with Ransomware.My Company is hit by this monster very much every Now and Then. How you guys are Securing the Environment ? Keep in mind our half of the Employees are Remote. They ask us to Open Sql defualt Port. Which we Think is cause of this problem..&lt;/p&gt;\n\n&lt;p&gt;If Someone have a Remedy please share.looking Forward to receive your Suggestions.Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yuafy9", "is_robot_indexable": true, "report_reasons": null, "author": "IKhalidAwan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuafy9/probably_irrelevant_question_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuafy9/probably_irrelevant_question_here/", "subreddit_subscribers": 79930, "created_utc": 1668365690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am a data engineer on my third year. I need perspective about my career progression, because I feel like I am not making any.\n\nMy experience: \n\n- 1st company ( 2 years 4months ) : building ETLs in Python and developing dashboards in Power Bi \n\n- 2nd company ( 5months and still ): Talend ETLs and Power Bi dashboards \n\nThe tech stack I covered is very basic and still at the surface of DE imo. I don't even think dashboard development is DE related. \n\n\nI am now looking up job offers on the market and I feel like all the high paying jobs are out of my reach. I am constantly trying to learn new tech on my own but it can hardly be as relevant. Unlike software dev, DE requires a bit of existing context and infrastructure.\n\nAt work, they really don't ask for much innovation or problem solving, it's just the same tasks all the time. And everyone around me is content with this so I feel kinda overqualified for what I am asked to do.\n\nWhat I want :\n- become a very good data engineer in the next two years, industry wise.\n\nWhat's on my mind :\n- find another job somewhere else\n- be patient and wait\n- work on a side project\n- freelance\n\n\nAny suggestions?", "author_fullname": "t2_gr70g2z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I switch jobs / be patient / work a side project ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu86mc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668360765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a data engineer on my third year. I need perspective about my career progression, because I feel like I am not making any.&lt;/p&gt;\n\n&lt;p&gt;My experience: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;1st company ( 2 years 4months ) : building ETLs in Python and developing dashboards in Power Bi &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2nd company ( 5months and still ): Talend ETLs and Power Bi dashboards &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The tech stack I covered is very basic and still at the surface of DE imo. I don&amp;#39;t even think dashboard development is DE related. &lt;/p&gt;\n\n&lt;p&gt;I am now looking up job offers on the market and I feel like all the high paying jobs are out of my reach. I am constantly trying to learn new tech on my own but it can hardly be as relevant. Unlike software dev, DE requires a bit of existing context and infrastructure.&lt;/p&gt;\n\n&lt;p&gt;At work, they really don&amp;#39;t ask for much innovation or problem solving, it&amp;#39;s just the same tasks all the time. And everyone around me is content with this so I feel kinda overqualified for what I am asked to do.&lt;/p&gt;\n\n&lt;p&gt;What I want :\n- become a very good data engineer in the next two years, industry wise.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s on my mind :\n- find another job somewhere else\n- be patient and wait\n- work on a side project\n- freelance&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yu86mc", "is_robot_indexable": true, "report_reasons": null, "author": "pursuuer", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yu86mc/should_i_switch_jobs_be_patient_work_a_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yu86mc/should_i_switch_jobs_be_patient_work_a_side/", "subreddit_subscribers": 79930, "created_utc": 1668360765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ugjew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tulip: Schematizing Meta\u2019s data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_yuxqor", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b8z_zdQvvuMArj5NFKjCmuYof4eSXcfNPz69X7FLX7g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668428550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "engineering.fb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://engineering.fb.com/2022/11/09/developer-tools/tulip-schematizing-metas-data-platform/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?auto=webp&amp;s=985d9e86a60cd42c7c5961832c39f69ed8c48fe3", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220d8d5f11385f3fe6570b772aeea4bbace3099a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=08170c62a860a68e2eecc7f37b0fea26567ddb35", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15e9b80a4c44d3b89ab20b5985f6eec284ea0ee1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aad16a28dc7cec8a06ac005a9fb6b186cb06ae21", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60a7dd1ce23d82dd958b95473c659ff4a03785b5", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q33Xy0jiK981QN4H96G7QxWZDqytUJkU3KQs62JLlws.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=79e4e12be1474061277a14f00e22094ed77d7a57", "width": 1080, "height": 607}], "variants": {}, "id": "8UfhOBudgsBvsTzSSr5lnkSwwiBO5L0NuKwtFuEAhjI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yuxqor", "is_robot_indexable": true, "report_reasons": null, "author": "marcosluis2186", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuxqor/tulip_schematizing_metas_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://engineering.fb.com/2022/11/09/developer-tools/tulip-schematizing-metas-data-platform/", "subreddit_subscribers": 79930, "created_utc": 1668428550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data hygiene implements the essential framework to keep your data in the right form, thereby helping you to operate your data-driven strategies immaculately. Understand how data hygiene creates a long-term impact by improving your business in various ways.\n\nhttps://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;format=pjpg&amp;auto=webp&amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5", "author_fullname": "t2_3ataz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Is Data Hygiene So Important For B2B Companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": true, "media_metadata": {"diwn3kjtnwz91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=482c9e29ec2804d477dbe65e701ce5f08e07ce8b"}, {"y": 106, "x": 216, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=423c157af793432d7190f2e86cdbd9f0cfe1793b"}, {"y": 158, "x": 320, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=93c46f9c7579ff5def24290a0297e58436419ed0"}, {"y": 316, "x": 640, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8836bf608db7463fe50b1358f6555983f0755ed1"}, {"y": 474, "x": 960, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d99ca9cf5cf73e5a768fee190fce96548013cf4a"}], "s": {"y": 494, "x": 1000, "u": "https://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;format=pjpg&amp;auto=webp&amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5"}, "id": "diwn3kjtnwz91"}}, "name": "t3_yux1v4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/HvAWRaZzCbzoLB7Tj5XukmvrsRasluHysTjRmfr9yG8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668426776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data hygiene implements the essential framework to keep your data in the right form, thereby helping you to operate your data-driven strategies immaculately. Understand how data hygiene creates a long-term impact by improving your business in various ways.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5\"&gt;https://preview.redd.it/diwn3kjtnwz91.jpg?width=1000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d79a667819371d5e8d043255b1ceaad7ff8557a5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yux1v4", "is_robot_indexable": true, "report_reasons": null, "author": "hitechbpo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yux1v4/why_is_data_hygiene_so_important_for_b2b_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yux1v4/why_is_data_hygiene_so_important_for_b2b_companies/", "subreddit_subscribers": 79930, "created_utc": 1668426776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My Stats:\n\nCareer progression (in academia adjacent org):\nData Analytics Intern (7months)-&gt;\nSoftware Engineer (all data related stuff, 1.5 years)-&gt;\nData Scientist (2 months)\n\n\nEducation: \n\n-MS Data Science (in progress)\n-BS in Information Science, minor CS\n\n\nThings I know: \n- Python + common data libs, C/C++, SQL\n\n-PySpark, Dask\n\n-Tensorflow, scikit \n\n-Docker\n\n\nMy weaknesses:\n\n-little experience in the cloud, no way to get on job experience in my current role (dysfunctional legacy organization)\n\n-not an expert in SQL, we don\u2019t use SQL databases in my org very much (mostly parquet files and other alternatives) \n\n\n\nWhat is my path to become DE? Should I get an AWS certification, or a Spark, Docker, or Kubernetes certification? What is my path to transition to DE?  Will my current experience help me?", "author_fullname": "t2_b7eqz4bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my path to becoming a DE from a SWE/DS background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yub8zq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668367751.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668367531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Stats:&lt;/p&gt;\n\n&lt;p&gt;Career progression (in academia adjacent org):\nData Analytics Intern (7months)-&amp;gt;\nSoftware Engineer (all data related stuff, 1.5 years)-&amp;gt;\nData Scientist (2 months)&lt;/p&gt;\n\n&lt;p&gt;Education: &lt;/p&gt;\n\n&lt;p&gt;-MS Data Science (in progress)\n-BS in Information Science, minor CS&lt;/p&gt;\n\n&lt;p&gt;Things I know: \n- Python + common data libs, C/C++, SQL&lt;/p&gt;\n\n&lt;p&gt;-PySpark, Dask&lt;/p&gt;\n\n&lt;p&gt;-Tensorflow, scikit &lt;/p&gt;\n\n&lt;p&gt;-Docker&lt;/p&gt;\n\n&lt;p&gt;My weaknesses:&lt;/p&gt;\n\n&lt;p&gt;-little experience in the cloud, no way to get on job experience in my current role (dysfunctional legacy organization)&lt;/p&gt;\n\n&lt;p&gt;-not an expert in SQL, we don\u2019t use SQL databases in my org very much (mostly parquet files and other alternatives) &lt;/p&gt;\n\n&lt;p&gt;What is my path to become DE? Should I get an AWS certification, or a Spark, Docker, or Kubernetes certification? What is my path to transition to DE?  Will my current experience help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yub8zq", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Box228", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yub8zq/what_is_my_path_to_becoming_a_de_from_a_sweds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yub8zq/what_is_my_path_to_becoming_a_de_from_a_sweds/", "subreddit_subscribers": 79930, "created_utc": 1668367531.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}