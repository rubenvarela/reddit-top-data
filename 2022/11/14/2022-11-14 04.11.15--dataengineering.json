{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e35wa210", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ways to Reduce Cloud Data Storage Costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_yu1y7w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BR7Ydd3yS_qMJvwjYquoKWc6eRRq6O_Ou10O84e8mtI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668346758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/reduce-cloud-data-storage-costs/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?auto=webp&amp;s=684f4aac33ad5fe9070a30f22295f326b7942005", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9861811e3825801fc6fed566677322d8c8578897", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40f02af6d93a490ed00b39fa8fe1a751c7eb9348", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eefb32db73650128169e38522554b2739f498b86", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3171ac42e695efc917141b9a1d122cf02d469b2", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/W8YRYFITU_hbVLCm-ArcEzT2ZmMQjQy4niAGzL3zGCc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6621dd4b26a31181a1237291e9118c8750d972e1", "width": 960, "height": 640}], "variants": {}, "id": "kINy1ajoFKyLTXfkoosJqlXODMAMyjqHwSZDTm3gJ7k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yu1y7w", "is_robot_indexable": true, "report_reasons": null, "author": "pinpepnet", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu1y7w/ways_to_reduce_cloud_data_storage_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/reduce-cloud-data-storage-costs/", "subreddit_subscribers": 79896, "created_utc": 1668346758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been seen more people saying that Working remotely from outside the US in an American company is becoming impossible. I currently living in Europe and would like to look for a job in the US remotely due to the difference in salaries which is huge. \n\nIs it still possible to hire full time / contractors from outside the US ? \n\nIs there any reasons why companies don\u2019t want to do that ? \n\nI work as a data engineer", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting a remote job in the USA from Europe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ytuy1e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668324995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been seen more people saying that Working remotely from outside the US in an American company is becoming impossible. I currently living in Europe and would like to look for a job in the US remotely due to the difference in salaries which is huge. &lt;/p&gt;\n\n&lt;p&gt;Is it still possible to hire full time / contractors from outside the US ? &lt;/p&gt;\n\n&lt;p&gt;Is there any reasons why companies don\u2019t want to do that ? &lt;/p&gt;\n\n&lt;p&gt;I work as a data engineer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ytuy1e", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ytuy1e/getting_a_remote_job_in_the_usa_from_europe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ytuy1e/getting_a_remote_job_in_the_usa_from_europe/", "subreddit_subscribers": 79896, "created_utc": 1668324995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know the best way to find part time work (\\~20 hrs/wk as freelance/independent contractor) as a data engineer?\n\nRecruiters? Job sites? I\u2019ve thought about toptal/upwork but figured going out on my own is better", "author_fullname": "t2_gnj3pgpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Part Time Job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yui8kn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668381751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know the best way to find part time work (~20 hrs/wk as freelance/independent contractor) as a data engineer?&lt;/p&gt;\n\n&lt;p&gt;Recruiters? Job sites? I\u2019ve thought about toptal/upwork but figured going out on my own is better&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yui8kn", "is_robot_indexable": true, "report_reasons": null, "author": "Kini_J", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yui8kn/data_engineer_part_time_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yui8kn/data_engineer_part_time_job/", "subreddit_subscribers": 79896, "created_utc": 1668381751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! \n\nI have been working with dbt + snowflake with Docker at work. But I only know how to work in dbt/ snowflake for data modeling. But I don't know how to set it up from scratch. I don't know how to write (what syntax) docker file. Where can I learn this? Every where I looked, they already have a eg repo to clone which already has docker written. \n\nThanks!", "author_fullname": "t2_7kdleomd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to setup dbt + postgres with Docker?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yts95d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668315406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;I have been working with dbt + snowflake with Docker at work. But I only know how to work in dbt/ snowflake for data modeling. But I don&amp;#39;t know how to set it up from scratch. I don&amp;#39;t know how to write (what syntax) docker file. Where can I learn this? Every where I looked, they already have a eg repo to clone which already has docker written. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yts95d", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded-Cod2051", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yts95d/how_to_setup_dbt_postgres_with_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yts95d/how_to_setup_dbt_postgres_with_docker/", "subreddit_subscribers": 79896, "created_utc": 1668315406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_le8pcuu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SCC. Kubernetes: Orchestration Close to Decentralization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yu7dj7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fVKAXjW3uaLQzGNAX-_bFR-5I2uybeAcRJgX7UF5-TI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668358827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "superprotocol.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://superprotocol.medium.com/scc-kubernetes-orchestration-close-to-decentralization-9c7047026c71", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?auto=webp&amp;s=7ce63f504d38ee3b7f1ae262673c101e26972fdc", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=00101b2318e2a983c2201c2d58f120d026c3b28d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2bf7a45402cb2142829660f799995bdd24772d65", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d896ddb634177f122889c724604e13f6faf121b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4ab1f9901785f17a93a528b99394c5cd566aa5b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5fc5eb51ea143c7576a86de05d9a2c980a241ec4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/as40sK3wtkQLjnEuGU-hYlv4X_y244WToqym_QRhgfY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e7f18fc12e303bee93797cc88c5ea4e4ceca324e", "width": 1080, "height": 607}], "variants": {}, "id": "KZ6x_Bx0E-g_2s7HZaRLSO1uEeVx7geH40O5eZHpjZI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yu7dj7", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional-Instance82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu7dj7/scc_kubernetes_orchestration_close_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://superprotocol.medium.com/scc-kubernetes-orchestration-close-to-decentralization-9c7047026c71", "subreddit_subscribers": 79896, "created_utc": 1668358827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any one working on any open source contribution for data engineering tools/technologies? I would like to join", "author_fullname": "t2_4f1ts4ru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Open Source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu3m38", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668350640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any one working on any open source contribution for data engineering tools/technologies? I would like to join&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yu3m38", "is_robot_indexable": true, "report_reasons": null, "author": "Subramaniam_DataEngr", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu3m38/de_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yu3m38/de_open_source/", "subreddit_subscribers": 79896, "created_utc": 1668350640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I work daily with spark, aws and python in my current role and have 2years of DE experience. My employer has offered to pay for a certification of my choice and I was wondering if anyone had a recommend. \n\nBased upon questions like how valuable the certification feels/was the content interesting/does it help with employability. Thank you.", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommend for valuable certifications? (aws/spark/python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuil1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668382581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I work daily with spark, aws and python in my current role and have 2years of DE experience. My employer has offered to pay for a certification of my choice and I was wondering if anyone had a recommend. &lt;/p&gt;\n\n&lt;p&gt;Based upon questions like how valuable the certification feels/was the content interesting/does it help with employability. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yuil1m", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuil1m/any_recommend_for_valuable_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuil1m/any_recommend_for_valuable_certifications/", "subreddit_subscribers": 79896, "created_utc": 1668382581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a project at my university, I have to create a scalable platform for real-time video analytics.\n\nI am searching for a way to create a data pipeline that will capture one or multiple video streams and process them accordingly. After searching, I am thinking of creating a pipeline as follows:\n\n1. Capture video stream with something like Kafka/Akka streams and send frames to a topic/actor.\n2. Load the data to spark streaming and using OpenCV perform video analysis (motion detection, etc.)\n3. Store results to S3.\n\nHas anyone worked with similar data? Some feedback would be greatly appreciated.\n\nI have no limitations to the technologies that I can use. However, I am mostly familiar with python/scala.", "author_fullname": "t2_3msw9pp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about video stream pipeline - University project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufp19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668376513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a project at my university, I have to create a scalable platform for real-time video analytics.&lt;/p&gt;\n\n&lt;p&gt;I am searching for a way to create a data pipeline that will capture one or multiple video streams and process them accordingly. After searching, I am thinking of creating a pipeline as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Capture video stream with something like Kafka/Akka streams and send frames to a topic/actor.&lt;/li&gt;\n&lt;li&gt;Load the data to spark streaming and using OpenCV perform video analysis (motion detection, etc.)&lt;/li&gt;\n&lt;li&gt;Store results to S3.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Has anyone worked with similar data? Some feedback would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;I have no limitations to the technologies that I can use. However, I am mostly familiar with python/scala.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufp19", "is_robot_indexable": true, "report_reasons": null, "author": "andreas_9898", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufp19/question_about_video_stream_pipeline_university/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufp19/question_about_video_stream_pipeline_university/", "subreddit_subscribers": 79896, "created_utc": 1668376513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i'm creating a pipeline that is ingesting from 2 sources, both API's and want to transform, and load them into a single table in an external database. The table does not exist.\n\nSo far I have taken both json responses and put them into seperate source .json files (should I? as a best practice?) and then also used pandas to create 2 additional csv files (for no particular reason?) from the json files.   \nDoes this even make sense?   \n\n\nNow I want to create a table and populate it with some of the fields (not all).\n\nIve learned about sqlalchemy to use stuff like declarative base, creating tables for both the raw and the clean models, where raw holds the current data types, and clean the new actual database types. But I'm a bit confused as to why I would create a raw model when I can just transform the data I need and put them straight into the clean model. What Am I missing here?   \n\n\nAlso, is this even the desired solution for what I want to accomplish?   \n\n\nTHank you!", "author_fullname": "t2_6kipsr88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL question (noob)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yujevd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668384702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;m creating a pipeline that is ingesting from 2 sources, both API&amp;#39;s and want to transform, and load them into a single table in an external database. The table does not exist.&lt;/p&gt;\n\n&lt;p&gt;So far I have taken both json responses and put them into seperate source .json files (should I? as a best practice?) and then also used pandas to create 2 additional csv files (for no particular reason?) from the json files.&lt;br/&gt;\nDoes this even make sense?   &lt;/p&gt;\n\n&lt;p&gt;Now I want to create a table and populate it with some of the fields (not all).&lt;/p&gt;\n\n&lt;p&gt;Ive learned about sqlalchemy to use stuff like declarative base, creating tables for both the raw and the clean models, where raw holds the current data types, and clean the new actual database types. But I&amp;#39;m a bit confused as to why I would create a raw model when I can just transform the data I need and put them straight into the clean model. What Am I missing here?   &lt;/p&gt;\n\n&lt;p&gt;Also, is this even the desired solution for what I want to accomplish?   &lt;/p&gt;\n\n&lt;p&gt;THank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yujevd", "is_robot_indexable": true, "report_reasons": null, "author": "Brontonomo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yujevd/etl_question_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yujevd/etl_question_noob/", "subreddit_subscribers": 79896, "created_utc": 1668384702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This might be a dumb question, but I need help please. \n\n\nI am an Intern who collaborated with one other engineer to build the entire end to end data system for a funded private equity firm, between the two of us. How could I word this on my resume without coming off like I am bragging?", "author_fullname": "t2_9ghl0zs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yujpxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668387089.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668385538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a dumb question, but I need help please. &lt;/p&gt;\n\n&lt;p&gt;I am an Intern who collaborated with one other engineer to build the entire end to end data system for a funded private equity firm, between the two of us. How could I word this on my resume without coming off like I am bragging?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yujpxs", "is_robot_indexable": true, "report_reasons": null, "author": "Perfect_Kangaroo6233", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yujpxs/help_with_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yujpxs/help_with_resume/", "subreddit_subscribers": 79896, "created_utc": 1668385538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.", "author_fullname": "t2_116kc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instant data model from 1000s of unique files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufzlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668377110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufzlk", "is_robot_indexable": true, "report_reasons": null, "author": "daeisfresh", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufzlk/instant_data_model_from_1000s_of_unique_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufzlk/instant_data_model_from_1000s_of_unique_files/", "subreddit_subscribers": 79896, "created_utc": 1668377110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello everyone, can I ask a question about creating a custom SQL data source Tableau?  \n\n&amp;#x200B;\n\nMy customer is storing a bunch of sensor data for an entire building (electricity, water, gas, etc. ) on Amazon Athena, I can not access their Amazon environment due to their privacy policy. They just gave me the access credential key for me to connect to Athena via Tableau. The thing is, the data is very raw, like, they don't have any data pre-processing step at all.    \n\n\nBack to the problem, I was given the sensor data and my task is to visualize one building energy usage on Tableau, here is the problem begins: the record I query is the sensor values for each measured time (mostly hourly), to calculate the usage I need to subtract the current value with the previous (one hour before) value, Tableau can do that with Calculation field, but then to calculate daily usage and monthly usage I have to Window\\_sum on the previous one (for example, Window\\_sum on hourly to get daily, Window\\_sum on daily to get monthly), however, when I do this, the Dashboard performance is horrible since it must calculate many things before visualizing the calculated data   \n\n\n I want to ask if there is a more elegant way to solve this problem on Tableau only. I personally thought it would be nice if they let me make a script to preprocess the raw data but sadly I can not access their cloud platform.", "author_fullname": "t2_2lg0sga7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question for creating a custom SQL data source in Tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu0syq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668343875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, can I ask a question about creating a custom SQL data source Tableau?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My customer is storing a bunch of sensor data for an entire building (electricity, water, gas, etc. ) on Amazon Athena, I can not access their Amazon environment due to their privacy policy. They just gave me the access credential key for me to connect to Athena via Tableau. The thing is, the data is very raw, like, they don&amp;#39;t have any data pre-processing step at all.    &lt;/p&gt;\n\n&lt;p&gt;Back to the problem, I was given the sensor data and my task is to visualize one building energy usage on Tableau, here is the problem begins: the record I query is the sensor values for each measured time (mostly hourly), to calculate the usage I need to subtract the current value with the previous (one hour before) value, Tableau can do that with Calculation field, but then to calculate daily usage and monthly usage I have to Window_sum on the previous one (for example, Window_sum on hourly to get daily, Window_sum on daily to get monthly), however, when I do this, the Dashboard performance is horrible since it must calculate many things before visualizing the calculated data   &lt;/p&gt;\n\n&lt;p&gt;I want to ask if there is a more elegant way to solve this problem on Tableau only. I personally thought it would be nice if they let me make a script to preprocess the raw data but sadly I can not access their cloud platform.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yu0syq", "is_robot_indexable": true, "report_reasons": null, "author": "Q_H_Chu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yu0syq/question_for_creating_a_custom_sql_data_source_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yu0syq/question_for_creating_a_custom_sql_data_source_in/", "subreddit_subscribers": 79896, "created_utc": 1668343875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am a data engineer on my third year. I need perspective about my career progression, because I feel like I am not making any.\n\nMy experience: \n\n- 1st company ( 2 years 4months ) : building ETLs in Python and developing dashboards in Power Bi \n\n- 2nd company ( 5months and still ): Talend ETLs and Power Bi dashboards \n\nThe tech stack I covered is very basic and still at the surface of DE imo. I don't even think dashboard development is DE related. \n\n\nI am now looking up job offers on the market and I feel like all the high paying jobs are out of my reach. I am constantly trying to learn new tech on my own but it can hardly be as relevant. Unlike software dev, DE requires a bit of existing context and infrastructure.\n\nAt work, they really don't ask for much innovation or problem solving, it's just the same tasks all the time. And everyone around me is content with this so I feel kinda overqualified for what I am asked to do.\n\nWhat I want :\n- become a very good data engineer in the next two years, industry wise.\n\nWhat's on my mind :\n- find another job somewhere else\n- be patient and wait\n- work on a side project\n- freelance\n\n\nAny suggestions?", "author_fullname": "t2_gr70g2z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I switch jobs / be patient / work a side project ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu86mc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668360765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a data engineer on my third year. I need perspective about my career progression, because I feel like I am not making any.&lt;/p&gt;\n\n&lt;p&gt;My experience: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;1st company ( 2 years 4months ) : building ETLs in Python and developing dashboards in Power Bi &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2nd company ( 5months and still ): Talend ETLs and Power Bi dashboards &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The tech stack I covered is very basic and still at the surface of DE imo. I don&amp;#39;t even think dashboard development is DE related. &lt;/p&gt;\n\n&lt;p&gt;I am now looking up job offers on the market and I feel like all the high paying jobs are out of my reach. I am constantly trying to learn new tech on my own but it can hardly be as relevant. Unlike software dev, DE requires a bit of existing context and infrastructure.&lt;/p&gt;\n\n&lt;p&gt;At work, they really don&amp;#39;t ask for much innovation or problem solving, it&amp;#39;s just the same tasks all the time. And everyone around me is content with this so I feel kinda overqualified for what I am asked to do.&lt;/p&gt;\n\n&lt;p&gt;What I want :\n- become a very good data engineer in the next two years, industry wise.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s on my mind :\n- find another job somewhere else\n- be patient and wait\n- work on a side project\n- freelance&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yu86mc", "is_robot_indexable": true, "report_reasons": null, "author": "pursuuer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/yu86mc/should_i_switch_jobs_be_patient_work_a_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yu86mc/should_i_switch_jobs_be_patient_work_a_side/", "subreddit_subscribers": 79896, "created_utc": 1668360765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you Guys Dealing with Ransomware.My Company is hit by this monster very much every Now and Then. How you guys are Securing the Environment ? Keep in mind our half of the Employees are Remote. They ask us to Open Sql defualt Port. Which we Think is cause of this problem..\n\nIf Someone have a Remedy please share.looking Forward to receive your Suggestions.Thank you", "author_fullname": "t2_4aa2ruvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Probably Irrelevant Question here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yuafy9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668365690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you Guys Dealing with Ransomware.My Company is hit by this monster very much every Now and Then. How you guys are Securing the Environment ? Keep in mind our half of the Employees are Remote. They ask us to Open Sql defualt Port. Which we Think is cause of this problem..&lt;/p&gt;\n\n&lt;p&gt;If Someone have a Remedy please share.looking Forward to receive your Suggestions.Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yuafy9", "is_robot_indexable": true, "report_reasons": null, "author": "IKhalidAwan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yuafy9/probably_irrelevant_question_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yuafy9/probably_irrelevant_question_here/", "subreddit_subscribers": 79896, "created_utc": 1668365690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My Stats:\n\nCareer progression (in academia adjacent org):\nData Analytics Intern (7months)-&gt;\nSoftware Engineer (all data related stuff, 1.5 years)-&gt;\nData Scientist (2 months)\n\n\nEducation: \n\n-MS Data Science (in progress)\n-BS in Information Science, minor CS\n\n\nThings I know: \n- Python + common data libs, C/C++, SQL\n\n-PySpark, Dask\n\n-Tensorflow, scikit \n\n-Docker\n\n\nMy weaknesses:\n\n-little experience in the cloud, no way to get on job experience in my current role (dysfunctional legacy organization)\n\n-not an expert in SQL, we don\u2019t use SQL databases in my org very much (mostly parquet files and other alternatives) \n\n\n\nWhat is my path to become DE? Should I get an AWS certification, or a Spark, Docker, or Kubernetes certification? What is my path to transition to DE?  Will my current experience help me?", "author_fullname": "t2_b7eqz4bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my path to becoming a DE from a SWE/DS background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yub8zq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668367751.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668367531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Stats:&lt;/p&gt;\n\n&lt;p&gt;Career progression (in academia adjacent org):\nData Analytics Intern (7months)-&amp;gt;\nSoftware Engineer (all data related stuff, 1.5 years)-&amp;gt;\nData Scientist (2 months)&lt;/p&gt;\n\n&lt;p&gt;Education: &lt;/p&gt;\n\n&lt;p&gt;-MS Data Science (in progress)\n-BS in Information Science, minor CS&lt;/p&gt;\n\n&lt;p&gt;Things I know: \n- Python + common data libs, C/C++, SQL&lt;/p&gt;\n\n&lt;p&gt;-PySpark, Dask&lt;/p&gt;\n\n&lt;p&gt;-Tensorflow, scikit &lt;/p&gt;\n\n&lt;p&gt;-Docker&lt;/p&gt;\n\n&lt;p&gt;My weaknesses:&lt;/p&gt;\n\n&lt;p&gt;-little experience in the cloud, no way to get on job experience in my current role (dysfunctional legacy organization)&lt;/p&gt;\n\n&lt;p&gt;-not an expert in SQL, we don\u2019t use SQL databases in my org very much (mostly parquet files and other alternatives) &lt;/p&gt;\n\n&lt;p&gt;What is my path to become DE? Should I get an AWS certification, or a Spark, Docker, or Kubernetes certification? What is my path to transition to DE?  Will my current experience help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yub8zq", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Box228", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yub8zq/what_is_my_path_to_becoming_a_de_from_a_sweds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yub8zq/what_is_my_path_to_becoming_a_de_from_a_sweds/", "subreddit_subscribers": 79896, "created_utc": 1668367531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.", "author_fullname": "t2_116kc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instant data model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufz48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668377082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yufz48", "is_robot_indexable": true, "report_reasons": null, "author": "daeisfresh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufz48/instant_data_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufz48/instant_data_model/", "subreddit_subscribers": 79896, "created_utc": 1668377082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.", "author_fullname": "t2_116kc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instant data model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yufyxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668377071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have collected thousands of unique files with slightly varying data structures in each file, most of them have a header but can be oddly shaped, is there any utility that can scan all of this in and suggest a data model a across all of them? I particular use case features a lot of financial data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yufyxk", "is_robot_indexable": true, "report_reasons": null, "author": "daeisfresh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yufyxk/instant_data_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yufyxk/instant_data_model/", "subreddit_subscribers": 79896, "created_utc": 1668377071.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}