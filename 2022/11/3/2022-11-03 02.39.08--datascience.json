{"kind": "Listing", "data": {"after": "t3_yklbzf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As of July 1st this year all health insurers in the US were required to publish files on their websites of all their negotiated prices they have for every possible medical procedure with every doctor in the country. In totality this data set equates to trillions of rows and hundreds of TB of data.\n\nI'm interested in building out a collaborative effort to aggregate all this data, but the cost of hosting seems to be a huge problem. What's the cheapest, effective way to host all this data in such a way that it's publicly accessible?", "author_fullname": "t2_457f1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help hosting trillions of rows of new health insurance public price data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk9gye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 105, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 105, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667405767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of July 1st this year all health insurers in the US were required to publish files on their websites of all their negotiated prices they have for every possible medical procedure with every doctor in the country. In totality this data set equates to trillions of rows and hundreds of TB of data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in building out a collaborative effort to aggregate all this data, but the cost of hosting seems to be a huge problem. What&amp;#39;s the cheapest, effective way to host all this data in such a way that it&amp;#39;s publicly accessible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk9gye", "is_robot_indexable": true, "report_reasons": null, "author": "invisiblelemur88", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk9gye/help_hosting_trillions_of_rows_of_new_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk9gye/help_hosting_trillions_of_rows_of_new_health/", "subreddit_subscribers": 816904, "created_utc": 1667405767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3im2k46f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In what ways is abstract algebra related to machine learning and data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjtx83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667358771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjtx83", "is_robot_indexable": true, "report_reasons": null, "author": "bc_951", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjtx83/in_what_ways_is_abstract_algebra_related_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjtx83/in_what_ways_is_abstract_algebra_related_to/", "subreddit_subscribers": 816904, "created_utc": 1667358771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a junior in college, looking to get a master's in data science. I am curious if any jobs allow you to travel for data science. I feel that most opportunities are stationary as most work deals with internal company data, but I would love to know if there are any industries or positions that allow more travel opportunities.", "author_fullname": "t2_5fdiktrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any data science jobs that require travel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjtox5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667358087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a junior in college, looking to get a master&amp;#39;s in data science. I am curious if any jobs allow you to travel for data science. I feel that most opportunities are stationary as most work deals with internal company data, but I would love to know if there are any industries or positions that allow more travel opportunities.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjtox5", "is_robot_indexable": true, "report_reasons": null, "author": "waddupbigpimps_", "discussion_type": null, "num_comments": 73, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjtox5/are_there_any_data_science_jobs_that_require/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjtox5/are_there_any_data_science_jobs_that_require/", "subreddit_subscribers": 816904, "created_utc": 1667358087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been doing data sci for 4 years, but actually, I think that I'm pretty crap at it... I program really well in R, but no one wants it, my Python is intermediate. I'm pretty good at stats from my PhD days, but that doesn't really come in handy in practice. When I do am ML project it's always regression based and seems to do the trick.... I did some deep learning courses, but I'm not sure if there are really any use cases out there for that... I basically feel like I'm not particularly well specialized. What thing could i really work on to start doing more exciting work and improve my job outlook? For example, really killing it with the deep learning is my first intuition, but it seems that in practice this skill is not all that sought after or needed.... What do you think?", "author_fullname": "t2_lrovl6pi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skills do I need to really work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykaxuh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667409178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been doing data sci for 4 years, but actually, I think that I&amp;#39;m pretty crap at it... I program really well in R, but no one wants it, my Python is intermediate. I&amp;#39;m pretty good at stats from my PhD days, but that doesn&amp;#39;t really come in handy in practice. When I do am ML project it&amp;#39;s always regression based and seems to do the trick.... I did some deep learning courses, but I&amp;#39;m not sure if there are really any use cases out there for that... I basically feel like I&amp;#39;m not particularly well specialized. What thing could i really work on to start doing more exciting work and improve my job outlook? For example, really killing it with the deep learning is my first intuition, but it seems that in practice this skill is not all that sought after or needed.... What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykaxuh", "is_robot_indexable": true, "report_reasons": null, "author": "likeamanyfacedgod", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykaxuh/what_skills_do_i_need_to_really_work_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykaxuh/what_skills_do_i_need_to_really_work_on/", "subreddit_subscribers": 816904, "created_utc": 1667409178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in the UK for a utility contractor, mostly automating reports, building ML algorithms and leading a team of new data scientists. My question is, if strong domain knowledge is a fundamental component of being a data scientist, how does someone with 5+ years' experience in one industry change to another? Do they need to start again as a junior?   \n\n\nI'd love to hear your experiences of this situation.", "author_fullname": "t2_thyuhojz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does a Data Scientist change domains?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk62ve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667397725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in the UK for a utility contractor, mostly automating reports, building ML algorithms and leading a team of new data scientists. My question is, if strong domain knowledge is a fundamental component of being a data scientist, how does someone with 5+ years&amp;#39; experience in one industry change to another? Do they need to start again as a junior?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your experiences of this situation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk62ve", "is_robot_indexable": true, "report_reasons": null, "author": "StereotypicalIrish1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk62ve/how_does_a_data_scientist_change_domains/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk62ve/how_does_a_data_scientist_change_domains/", "subreddit_subscribers": 816904, "created_utc": 1667397725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks\n\nI was wondering if there are any free sentiment analysis tools that are pre-trained (on typical customer support quer), so that I can run some text through it to get a general idea of positivity negativity? It\u2019s not a whole lot of text, maybe several thousand paragraphs.\n\nThanks.", "author_fullname": "t2_4zxcnppv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentiment analysis of customer support tickets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykmpgt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667434158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there are any free sentiment analysis tools that are pre-trained (on typical customer support quer), so that I can run some text through it to get a general idea of positivity negativity? It\u2019s not a whole lot of text, maybe several thousand paragraphs.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykmpgt", "is_robot_indexable": true, "report_reasons": null, "author": "enigmapaulns", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykmpgt/sentiment_analysis_of_customer_support_tickets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykmpgt/sentiment_analysis_of_customer_support_tickets/", "subreddit_subscribers": 816904, "created_utc": 1667434158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a classification model trained to predict 3 classes of labels. I want to know what feature combinations reliably predict each class. Is there an implementation in python which allows for this insight?", "author_fullname": "t2_kr695uqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to understand what features reliably predict my labels?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk3ex0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667390701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a classification model trained to predict 3 classes of labels. I want to know what feature combinations reliably predict each class. Is there an implementation in python which allows for this insight?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk3ex0", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Skin-3889", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk3ex0/how_to_understand_what_features_reliably_predict/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk3ex0/how_to_understand_what_features_reliably_predict/", "subreddit_subscribers": 816904, "created_utc": 1667390701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to load some data and do the following tasks:\n\n1. load data from csv\n2. encode data types\n3. normalize data\n4. .... more to come...\n5. split data into two\n\nIs there a common Python design pattern approach for this type of pipeline data analysis?\n\nNot sure exactly what I need but it reminds me a little of a ***Builder*** pattern.\n\n    var myObject = myBuilder.addName(\"John Doe\").addAge(15).build()\n\nI've seen some packages that look to support it using decorators, but not sure if that's overcomplicating things or even a common approach.", "author_fullname": "t2_293ojlay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Data Analysis Patterns - A pipeline design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8ski", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667404214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to load some data and do the following tasks:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;load data from csv&lt;/li&gt;\n&lt;li&gt;encode data types&lt;/li&gt;\n&lt;li&gt;normalize data&lt;/li&gt;\n&lt;li&gt;.... more to come...&lt;/li&gt;\n&lt;li&gt;split data into two&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there a common Python design pattern approach for this type of pipeline data analysis?&lt;/p&gt;\n\n&lt;p&gt;Not sure exactly what I need but it reminds me a little of a &lt;strong&gt;&lt;em&gt;Builder&lt;/em&gt;&lt;/strong&gt; pattern.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;var myObject = myBuilder.addName(&amp;quot;John Doe&amp;quot;).addAge(15).build()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ve seen some packages that look to support it using decorators, but not sure if that&amp;#39;s overcomplicating things or even a common approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8ski", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_buttons", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8ski/python_data_analysis_patterns_a_pipeline_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8ski/python_data_analysis_patterns_a_pipeline_design/", "subreddit_subscribers": 816904, "created_utc": 1667404214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm not a data scientist, but I've been assigned a project somewhat in this category and I'm trying to improve my programs performance.\n\nI'm scanning through a 10TB file system with 800,000 directories and a ton of files in python. I'm storing some file meta data like: size, mtime, and user id in a pandas dataframe, and it's taking 20+ hours to complete. What's odd about this is if I just go through the file system and only record file paths, it only takes about 6 hours. Which I would say is pretty fair. \n\nI feel that my problem is a memory problem. The more data is store the slower the program gets. Im sure people in this field have to work through datasets this large or larger very frequently, and there are developed methods for doing so efficiently. \n\nIs there a better means to record file meta data than to just save it in a structure in memory?", "author_fullname": "t2_l8wunj9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for storing Large Datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8yoi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667404614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m not a data scientist, but I&amp;#39;ve been assigned a project somewhat in this category and I&amp;#39;m trying to improve my programs performance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m scanning through a 10TB file system with 800,000 directories and a ton of files in python. I&amp;#39;m storing some file meta data like: size, mtime, and user id in a pandas dataframe, and it&amp;#39;s taking 20+ hours to complete. What&amp;#39;s odd about this is if I just go through the file system and only record file paths, it only takes about 6 hours. Which I would say is pretty fair. &lt;/p&gt;\n\n&lt;p&gt;I feel that my problem is a memory problem. The more data is store the slower the program gets. Im sure people in this field have to work through datasets this large or larger very frequently, and there are developed methods for doing so efficiently. &lt;/p&gt;\n\n&lt;p&gt;Is there a better means to record file meta data than to just save it in a structure in memory?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8yoi", "is_robot_indexable": true, "report_reasons": null, "author": "CruderMermaid6", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8yoi/best_practices_for_storing_large_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8yoi/best_practices_for_storing_large_datasets/", "subreddit_subscribers": 816904, "created_utc": 1667404614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been tasked with creating a production grade scalable distribution network routing optimization model with some additional nuances. I'm using Rust as it will use very large datasets and has many constraints. I presume using python computation will be very slow and can't take that risk. I'm quite adept in Rust FYI but didn't develop any AI/ML projects with it.\n\nSince I'm developing such a large scale project for the first time, I'm unsure as to how to arrive at a reasonable implementation timeframe since I may have to write the entire custom AI/ML model from scratch to accommodate for the uncommon nuances.\n\nSuggestions on how to make my work a bit easier from all of you experienced peeps are also welcome.", "author_fullname": "t2_ra4tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to report timelines to the management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk8i01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667403508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been tasked with creating a production grade scalable distribution network routing optimization model with some additional nuances. I&amp;#39;m using Rust as it will use very large datasets and has many constraints. I presume using python computation will be very slow and can&amp;#39;t take that risk. I&amp;#39;m quite adept in Rust FYI but didn&amp;#39;t develop any AI/ML projects with it.&lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m developing such a large scale project for the first time, I&amp;#39;m unsure as to how to arrive at a reasonable implementation timeframe since I may have to write the entire custom AI/ML model from scratch to accommodate for the uncommon nuances.&lt;/p&gt;\n\n&lt;p&gt;Suggestions on how to make my work a bit easier from all of you experienced peeps are also welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk8i01", "is_robot_indexable": true, "report_reasons": null, "author": "a_aniq", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk8i01/how_to_report_timelines_to_the_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk8i01/how_to_report_timelines_to_the_management/", "subreddit_subscribers": 816904, "created_utc": 1667403508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working on building up my data science knowledge for a few months now. Started actually building and testing models a bit over a month ago and now I'm fairly at a comfortable place. Not winning Kaggle competitions but the scores are something I'm happy with...for now.\n\nI've realised that my Achilles' Heel at this point is feature engineering, which is one of the most important tasks to build a good model. Before beginning work, I do look at similar datasets and see how others have treated that data but somehow my lack of knowledge in that domain fails me.\n\nI think I have very good interpretability skills from a business perspective but I'm unable to translate that understanding into features.\n\nHow much time do you all spend researching the related industry/domain of the data before building models? Any tips/tricks that you think could work for me?\n\nRight now I'm reading [http://www.feat.engineering/](http://www.feat.engineering/) which I found on this sub", "author_fullname": "t2_55cjp0l4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Engineering without domain knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykk7j9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667428781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on building up my data science knowledge for a few months now. Started actually building and testing models a bit over a month ago and now I&amp;#39;m fairly at a comfortable place. Not winning Kaggle competitions but the scores are something I&amp;#39;m happy with...for now.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve realised that my Achilles&amp;#39; Heel at this point is feature engineering, which is one of the most important tasks to build a good model. Before beginning work, I do look at similar datasets and see how others have treated that data but somehow my lack of knowledge in that domain fails me.&lt;/p&gt;\n\n&lt;p&gt;I think I have very good interpretability skills from a business perspective but I&amp;#39;m unable to translate that understanding into features.&lt;/p&gt;\n\n&lt;p&gt;How much time do you all spend researching the related industry/domain of the data before building models? Any tips/tricks that you think could work for me?&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;m reading &lt;a href=\"http://www.feat.engineering/\"&gt;http://www.feat.engineering/&lt;/a&gt; which I found on this sub&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykk7j9", "is_robot_indexable": true, "report_reasons": null, "author": "_Triggernometry_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykk7j9/feature_engineering_without_domain_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykk7j9/feature_engineering_without_domain_knowledge/", "subreddit_subscribers": 816904, "created_utc": 1667428781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, guys how would you approach the following problem?\n\n&amp;#x200B;\n\nI'm currently using an simple AutoRegressive model with the last N days to predit a sales outcome for the next day. I want to improve the model by using the first hours of the day that I'm trying to predict. \n\nThe problem is that the number of hours that I'll have available are note fixed. Maybe someone will use the prediction service at 8am and then at 4pm.  How would you add this feature if you want to use all the data available at the time?", "author_fullname": "t2_kguah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Timeseries help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykesdc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667417883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, guys how would you approach the following problem?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using an simple AutoRegressive model with the last N days to predit a sales outcome for the next day. I want to improve the model by using the first hours of the day that I&amp;#39;m trying to predict. &lt;/p&gt;\n\n&lt;p&gt;The problem is that the number of hours that I&amp;#39;ll have available are note fixed. Maybe someone will use the prediction service at 8am and then at 4pm.  How would you add this feature if you want to use all the data available at the time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykesdc", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_dealer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykesdc/timeseries_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykesdc/timeseries_help/", "subreddit_subscribers": 816904, "created_utc": 1667417883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have a dataset that a client sent me. They are a furniture manufacturer company, specialized in making Dressers. Their \"added value\" are how economical their products are.\n\nThe dataset's rows are individual ordered products, which can repeat for a single customer depending on how many products they ordered in a single transaction/day (if they bought 10 dressers, a single customer has 10 rows, each row being 1 product bought). **I'm tasked with gathering actionable insights for the client based on the dataset; the issue is that the dataset is very limited in terms of columns/variables, and I think/feel I'm out of ideas already**. I'm part of a digital marketing business, but this is exercise is actually not directly related to exclusively/mandatorily generating digital marketing recommendations.\n\nThe dataset columns are:\n\n1. Order Date (dd/mm/yyy), only with data from January 2021 to October 2022\n2. Product Name\n3. Customer Name (mostly useless)\n4. Customer Gender (M or F)\n5. City (needs A LOT of cleaning to standardize. This was a manual input from whoever filled it out)\n6. State (from the United States)\n7. Zip Code\n8. Channel (whether they sell through Amazon, Walmart or other marketplaces, or directly through their website. This is only available for 2021 and not for 2022)\n\nI already looked at things like:\n\n1. Top/bottom states in terms of orders by 100k population (based on each state's population). \\[Bar charts\\]\n2. Total orders (Y axis) by month (X axis) by state to detect outliers/patterns (nothing to highlight here, they mostly follow the national, aggregated total orders). \\[Line charts\\]\n3. Most popular products by state and their avg. order share (from each state) \\[Bar charts\\]\n4. Top/bottom products just based on total orders \\[Bar charts\\]\n5. Top/bottom states just based on total orders \\[Bar charts\\]\n6. Reach by product (whether they are sold in all states: 100%, just in one (1/51), etc.) \\[Bar charts\\]\n7. How much of the total orders do Dressers represent specifically \\[Area chart\\]\n8. Top 5 products by month \\[Ribbon chart\\]\n9. Top 5 products by gender \\[Bar chart\\]\n10. Top/bottom products by their male-to-female ratio in terms of orders \\[Bar chart\\]\n11. Repurchases based on a \"composite key\" of customer name + zip code for a single day \\[Bar chart, but almost useless. Almost no repurchases with less than 0.5% of all transactions\\]\n\nThat's about it. I think having columns like \"revenue\" and data for more years could really bring a whole new world of insights and creativity to get real actionable insights. So far the client (for any reason) has been reluctant to provide this or more data apart from 2021 and 2022. **Any ideas? I would enormously appreciate your input on this**\n\n**TL;DR: I have a very limited dataset on orders for furniture, mostly Dressers. I need to gather actionable insights and the data is extremely limited in terms of date range (2021-2022) and variables (up to 8 variables, with just 4 or 5 being truly useful). Ideas on actionable insights?**\n\nThank you!", "author_fullname": "t2_ie26w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to add more creativity to this EDA to gather useful, actionable insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ykp0fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667440266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a dataset that a client sent me. They are a furniture manufacturer company, specialized in making Dressers. Their &amp;quot;added value&amp;quot; are how economical their products are.&lt;/p&gt;\n\n&lt;p&gt;The dataset&amp;#39;s rows are individual ordered products, which can repeat for a single customer depending on how many products they ordered in a single transaction/day (if they bought 10 dressers, a single customer has 10 rows, each row being 1 product bought). &lt;strong&gt;I&amp;#39;m tasked with gathering actionable insights for the client based on the dataset; the issue is that the dataset is very limited in terms of columns/variables, and I think/feel I&amp;#39;m out of ideas already&lt;/strong&gt;. I&amp;#39;m part of a digital marketing business, but this is exercise is actually not directly related to exclusively/mandatorily generating digital marketing recommendations.&lt;/p&gt;\n\n&lt;p&gt;The dataset columns are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Order Date (dd/mm/yyy), only with data from January 2021 to October 2022&lt;/li&gt;\n&lt;li&gt;Product Name&lt;/li&gt;\n&lt;li&gt;Customer Name (mostly useless)&lt;/li&gt;\n&lt;li&gt;Customer Gender (M or F)&lt;/li&gt;\n&lt;li&gt;City (needs A LOT of cleaning to standardize. This was a manual input from whoever filled it out)&lt;/li&gt;\n&lt;li&gt;State (from the United States)&lt;/li&gt;\n&lt;li&gt;Zip Code&lt;/li&gt;\n&lt;li&gt;Channel (whether they sell through Amazon, Walmart or other marketplaces, or directly through their website. This is only available for 2021 and not for 2022)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I already looked at things like:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Top/bottom states in terms of orders by 100k population (based on each state&amp;#39;s population). [Bar charts]&lt;/li&gt;\n&lt;li&gt;Total orders (Y axis) by month (X axis) by state to detect outliers/patterns (nothing to highlight here, they mostly follow the national, aggregated total orders). [Line charts]&lt;/li&gt;\n&lt;li&gt;Most popular products by state and their avg. order share (from each state) [Bar charts]&lt;/li&gt;\n&lt;li&gt;Top/bottom products just based on total orders [Bar charts]&lt;/li&gt;\n&lt;li&gt;Top/bottom states just based on total orders [Bar charts]&lt;/li&gt;\n&lt;li&gt;Reach by product (whether they are sold in all states: 100%, just in one (1/51), etc.) [Bar charts]&lt;/li&gt;\n&lt;li&gt;How much of the total orders do Dressers represent specifically [Area chart]&lt;/li&gt;\n&lt;li&gt;Top 5 products by month [Ribbon chart]&lt;/li&gt;\n&lt;li&gt;Top 5 products by gender [Bar chart]&lt;/li&gt;\n&lt;li&gt;Top/bottom products by their male-to-female ratio in terms of orders [Bar chart]&lt;/li&gt;\n&lt;li&gt;Repurchases based on a &amp;quot;composite key&amp;quot; of customer name + zip code for a single day [Bar chart, but almost useless. Almost no repurchases with less than 0.5% of all transactions]&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;That&amp;#39;s about it. I think having columns like &amp;quot;revenue&amp;quot; and data for more years could really bring a whole new world of insights and creativity to get real actionable insights. So far the client (for any reason) has been reluctant to provide this or more data apart from 2021 and 2022. &lt;strong&gt;Any ideas? I would enormously appreciate your input on this&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR: I have a very limited dataset on orders for furniture, mostly Dressers. I need to gather actionable insights and the data is extremely limited in terms of date range (2021-2022) and variables (up to 8 variables, with just 4 or 5 being truly useful). Ideas on actionable insights?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykp0fb", "is_robot_indexable": true, "report_reasons": null, "author": "MadGlobin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykp0fb/how_to_add_more_creativity_to_this_eda_to_gather/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykp0fb/how_to_add_more_creativity_to_this_eda_to_gather/", "subreddit_subscribers": 816904, "created_utc": 1667440266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m open to any recommendations about data science talks/conferences/events worth going to (preferably on the west coast)!", "author_fullname": "t2_m0419", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which data science talks/conferences are worth going to?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykbm3q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667410695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m open to any recommendations about data science talks/conferences/events worth going to (preferably on the west coast)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykbm3q", "is_robot_indexable": true, "report_reasons": null, "author": "jzasdf1212", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykbm3q/which_data_science_talksconferences_are_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykbm3q/which_data_science_talksconferences_are_worth/", "subreddit_subscribers": 816904, "created_utc": 1667410695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If I have applied to a role as head of a department, how bad would it be to also apply for a senior scientist role in that department at the same company. I like doing hands on work, the money is probably more than I need either way, but the management role fits what I actually do now, so I would be a good fit for either, in my opinion. I feel like it\u2019s just kind of dumb to deny the reality that I would like either job and it\u2019s a numbers game to me anyway because there are so many positions, but would this be sketchy, looks desperate? Is it unattractive to desperately want a job? I feel like I\u2019d want to hire someone who did.", "author_fullname": "t2_7nkszese", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this look sketchy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk5xva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667397379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I have applied to a role as head of a department, how bad would it be to also apply for a senior scientist role in that department at the same company. I like doing hands on work, the money is probably more than I need either way, but the management role fits what I actually do now, so I would be a good fit for either, in my opinion. I feel like it\u2019s just kind of dumb to deny the reality that I would like either job and it\u2019s a numbers game to me anyway because there are so many positions, but would this be sketchy, looks desperate? Is it unattractive to desperately want a job? I feel like I\u2019d want to hire someone who did.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yk5xva", "is_robot_indexable": true, "report_reasons": null, "author": "BestUCanIsGoodEnough", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk5xva/does_this_look_sketchy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk5xva/does_this_look_sketchy/", "subreddit_subscribers": 816904, "created_utc": 1667397379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9ple7b7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What topics in multivariable calculus do I need for ml?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjztvu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667378902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjztvu", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping_Ad_7053", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjztvu/what_topics_in_multivariable_calculus_do_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjztvu/what_topics_in_multivariable_calculus_do_i_need/", "subreddit_subscribers": 816904, "created_utc": 1667378902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are there any implementations of DeepBlur algorithm for face obfuscation? (DeepBlur: A Simple and Effective Method for Natural Image Obfuscation)\n\nI found a very interesting article - [https://arxiv.org/abs/2104.02655](https://arxiv.org/abs/2104.02655)\n\nBut there is no implementation for this. \n\nDoes anyone happen to find a ready to use implementation of this or similar algorithm?", "author_fullname": "t2_8m2azun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any implementations of DeepBlur algorithm for face obfuscation? (DeepBlur: A Simple and Effective Method for Natural Image Obfuscation)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjxygb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667372004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any implementations of DeepBlur algorithm for face obfuscation? (DeepBlur: A Simple and Effective Method for Natural Image Obfuscation)&lt;/p&gt;\n\n&lt;p&gt;I found a very interesting article - &lt;a href=\"https://arxiv.org/abs/2104.02655\"&gt;https://arxiv.org/abs/2104.02655&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But there is no implementation for this. &lt;/p&gt;\n\n&lt;p&gt;Does anyone happen to find a ready to use implementation of this or similar algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjxygb", "is_robot_indexable": true, "report_reasons": null, "author": "glorsh66", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjxygb/are_there_any_implementations_of_deepblur/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjxygb/are_there_any_implementations_of_deepblur/", "subreddit_subscribers": 816904, "created_utc": 1667372004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Please check it out and let me know if it was helpful! (It is my second blogpost on medium!) \n\nhttps://link.medium.com/4b4DHsuuCub", "author_fullname": "t2_4uejp986", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Made a blog to help you do efficient and quick EDA and data preprocessing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjwnot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667367355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please check it out and let me know if it was helpful! (It is my second blogpost on medium!) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://link.medium.com/4b4DHsuuCub\"&gt;https://link.medium.com/4b4DHsuuCub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?auto=webp&amp;s=fc7caec44b6027249a3ea45f65f02204e3486889", "width": 1200, "height": 635}, "resolutions": [{"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c00bae51902824e1cab0485953b754fd51481f0", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb5628c83b5d5d56d41ab81cd11ae909845d7868", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f085524b848efef8d520ff37c144251743473d68", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=79637d5f2dd4eb8f7bb65f7d890dca5ab8883432", "width": 640, "height": 338}, {"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54b6ff31d9b69ebf2ceaa8af595c0455b98d08a7", "width": 960, "height": 508}, {"url": "https://external-preview.redd.it/62JATOdyieochBgZFl0I_Y_VQGvrEg3x8KG5qhcjOdk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d6aece8f66d57641bc5d6f0fa3eb4a98792a6756", "width": 1080, "height": 571}], "variants": {}, "id": "yLo0VdsLPYGp2xYvtPOa4iCQ1JIQtdb1j7Ivh2WDlVk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjwnot", "is_robot_indexable": true, "report_reasons": null, "author": "thetimeis_notnow", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjwnot/made_a_blog_to_help_you_do_efficient_and_quick/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjwnot/made_a_blog_to_help_you_do_efficient_and_quick/", "subreddit_subscribers": 816904, "created_utc": 1667367355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2qp4bbiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Data Analyst looking to transition to Data Scientist after I finish my undergrad. Any tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zly81vwzqmx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=607cb9b722e074f75dba2bb17f8989b9513cdcfc"}, {"y": 278, "x": 216, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2903d584528d9ee64ddc4deb997762b60e42d67d"}, {"y": 411, "x": 320, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fed11764dc4995eb1290bd4b2784b170daeb17a5"}, {"y": 823, "x": 640, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=360c499b83f4739d9973aea2a58f67b9c5906458"}, {"y": 1235, "x": 960, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6478855580c0475dfb06355ee0f5b26370e35d90"}, {"y": 1390, "x": 1080, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6871e11c57a167f9ea88ba1373ea60c9e4e9b839"}], "s": {"y": 1506, "x": 1170, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=3028fdc1fd65df157da93178373d3ab6565ed228"}, "id": "zly81vwzqmx91"}, "ai4hsuwzqmx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 138, "x": 108, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=148bb6cd952e5825dcc7a62223804cb7222b0fd0"}, {"y": 277, "x": 216, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4233a1a87b9666fcd41ad76f6424d0b99f121b1"}, {"y": 411, "x": 320, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a99f72d0d6332336ed6df6ac6efc71aeaa55ce18"}, {"y": 823, "x": 640, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce6cfa5f0fe5f9b03e3b384c04f3829a0e49aad9"}, {"y": 1234, "x": 960, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e31afbdc88eec2f7baad4a6e21ed1d4d68c0d79"}, {"y": 1389, "x": 1080, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f26b619fad82ac39a61da2f5a4c33f623da676ea"}], "s": {"y": 1505, "x": 1170, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=34790eac3971584fbcf3fd0ef2eb49da54889187"}, "id": "ai4hsuwzqmx91"}}, "name": "t3_ykn277", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "ai4hsuwzqmx91", "id": 204891057}, {"media_id": "zly81vwzqmx91", "id": 204891058}]}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Y4vC0HMhl0goDdnP4g4nQATGjVuRQYk39OWhDZvkbmA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667435058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/ykn277", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "ykn277", "is_robot_indexable": true, "report_reasons": null, "author": "Dont_know_wa_im_doin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykn277/data_analyst_looking_to_transition_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/ykn277", "subreddit_subscribers": 816904, "created_utc": 1667435058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm interested in learning a new \"spoken language\" (idk how to call it), I tried to look it up but only got answers about programming languages.\n\nI already speak Spanish (native) and English (not perfectly) but don't have any idea where should I continue.", "author_fullname": "t2_5oj654vi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most useful spoken languages for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykkupe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667430075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in learning a new &amp;quot;spoken language&amp;quot; (idk how to call it), I tried to look it up but only got answers about programming languages.&lt;/p&gt;\n\n&lt;p&gt;I already speak Spanish (native) and English (not perfectly) but don&amp;#39;t have any idea where should I continue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykkupe", "is_robot_indexable": true, "report_reasons": null, "author": "Pepe_Alpa", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykkupe/what_are_the_most_useful_spoken_languages_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykkupe/what_are_the_most_useful_spoken_languages_for/", "subreddit_subscribers": 816904, "created_utc": 1667430075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good jobs that involve Data Science and Environmentalism? (Ideally with Good pay and hours, work-life balance, etc.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk51kk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667395064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yk51kk", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk51kk/what_are_some_good_jobs_that_involve_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk51kk/what_are_some_good_jobs_that_involve_data_science/", "subreddit_subscribers": 816904, "created_utc": 1667395064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have dataset of videos of street in snowing day I want to detect if snow is covering traffic light &amp; classifying if the traffic light visibility (good, bad, very goodI read about YOLO &amp; worked with CNN before \n\nI was thinking of applying CNN to see if an object is visible or not then apply YOLO to the video \nIs applying CNN for an image the same as in video?\nIs there any better approach I can solve this?", "author_fullname": "t2_22mtojjh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "deep learning detect and classify object", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjvbzw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667363039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have dataset of videos of street in snowing day I want to detect if snow is covering traffic light &amp;amp; classifying if the traffic light visibility (good, bad, very goodI read about YOLO &amp;amp; worked with CNN before &lt;/p&gt;\n\n&lt;p&gt;I was thinking of applying CNN to see if an object is visible or not then apply YOLO to the video \nIs applying CNN for an image the same as in video?\nIs there any better approach I can solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjvbzw", "is_robot_indexable": true, "report_reasons": null, "author": "sk8er_girl90", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjvbzw/deep_learning_detect_and_classify_object/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjvbzw/deep_learning_detect_and_classify_object/", "subreddit_subscribers": 816904, "created_utc": 1667363039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I have been thinking about an idea which involves artists being able to stream their music via my app. I wanted resources on streaming services, can a few paid parts of it be built inhouse for testing etc.", "author_fullname": "t2_bmbzd7qm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendations for designs/books/git om audio streaming.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yk040u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667379978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I have been thinking about an idea which involves artists being able to stream their music via my app. I wanted resources on streaming services, can a few paid parts of it be built inhouse for testing etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yk040u", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive_Bad_818", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yk040u/looking_for_recommendations_for_designsbooksgit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yk040u/looking_for_recommendations_for_designsbooksgit/", "subreddit_subscribers": 816904, "created_utc": 1667379978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellow learners, I'm a data enthusiast currently working on data from James Webb Telescope. I generally work on gcp and thought it'd be fun if anyone wants to work together, remotely ofc. Dm me if you do", "author_fullname": "t2_9xw62nbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a project buddy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yjy1qb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667372329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow learners, I&amp;#39;m a data enthusiast currently working on data from James Webb Telescope. I generally work on gcp and thought it&amp;#39;d be fun if anyone wants to work together, remotely ofc. Dm me if you do&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yjy1qb", "is_robot_indexable": true, "report_reasons": null, "author": "PsychoAwkGirl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yjy1qb/looking_for_a_project_buddy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yjy1qb/looking_for_a_project_buddy/", "subreddit_subscribers": 816904, "created_utc": 1667372329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8c13n8vj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Pandas Functions That Help You Understand a Dataset Completely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_yklbzf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I88ZyqdGZLdUZ9jRYjNMqU1z2vwFIJakxsSGTxGrJdI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667431047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/b7de7e7e14ab", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?auto=webp&amp;s=a7cb64a1167a1a4517d6c0646e0d42d86d6c9002", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bab686777db435ff29d6b80b47f7e49f2eb63b0", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98b03ee58005d02b067bf6f2dbf2e13ea231fed0", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b65026aa876f83b83419f635bff0ae7e64ba241", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9f7dab2817ff400f9fcbe7efcaba57f45f0b4fcd", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc1fc64115c345320d8a157bad9d55ca7b985f4f", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d84077ad712c6dfe401df4cd3d8f9bb38bda57e", "width": 1080, "height": 720}], "variants": {}, "id": "7wBi4n5WKWMEkMStw6hzcfzdIhpwvwBWmosCaE4JK94"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yklbzf", "is_robot_indexable": true, "report_reasons": null, "author": "yangzhou1993", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yklbzf/10_pandas_functions_that_help_you_understand_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/b7de7e7e14ab", "subreddit_subscribers": 816904, "created_utc": 1667431047.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}