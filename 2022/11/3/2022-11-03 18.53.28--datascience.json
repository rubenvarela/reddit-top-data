{"kind": "Listing", "data": {"after": "t3_yksr9u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it just me or are the vast majority of job adverts on linked in right now for senior/lead/principal data scientists? (UK btw)\n\nI only saw a single advert for a junior role and this had over 200 applications in just a few a hours of being released.", "author_fullname": "t2_1rp1btfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No one is hiring juniors/ mid-level data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykyte6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 210, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 210, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667471938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just me or are the vast majority of job adverts on linked in right now for senior/lead/principal data scientists? (UK btw)&lt;/p&gt;\n\n&lt;p&gt;I only saw a single advert for a junior role and this had over 200 applications in just a few a hours of being released.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykyte6", "is_robot_indexable": true, "report_reasons": null, "author": "nullspace1729", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykyte6/no_one_is_hiring_juniors_midlevel_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykyte6/no_one_is_hiring_juniors_midlevel_data_scientists/", "subreddit_subscribers": 817043, "created_utc": 1667471938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_bb4m08u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing OpenAI GPT3 in Airtable. Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work pretty well. Any interesting use cases that you'd recommend testing with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ykybpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/igornefedovi/status/1588032734315704320", "author_name": "Igor Nefedov", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/igornefedovi", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/ykybpj", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/H5M11fv0b8Wy11cjAmYQFWbHB-Y653u0jbpFjTdc5o4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667470649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/igornefedovi/status/1588032734315704320", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q3_cAr_0AWvl2doPMq2oGYGlBrKQB6CXdpzOFQmnUBk.jpg?auto=webp&amp;s=438a341ce2e08c3d99c58319f7ff907ff8f90806", "width": 140, "height": 78}, "resolutions": [{"url": "https://external-preview.redd.it/Q3_cAr_0AWvl2doPMq2oGYGlBrKQB6CXdpzOFQmnUBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cf5cae1ce8dfd29d83b91454d5da4ef40e8288b", "width": 108, "height": 60}], "variants": {}, "id": "HYnQ8FaO96_yByBsMJgxlZn_e9b7QzNp8IGJjv5tEac"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykybpj", "is_robot_indexable": true, "report_reasons": null, "author": "igornefedovi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykybpj/testing_openai_gpt3_in_airtable_finetuning_gpt3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/igornefedovi/status/1588032734315704320", "subreddit_subscribers": 817043, "created_utc": 1667470649.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/igornefedovi/status/1588032734315704320", "author_name": "Igor Nefedov", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Running OpenAI in Airtable. Extracting structured JSON data from unstructured resume text.&lt;br&gt;&lt;br&gt;Fine-tuning gpt3 even with a very small dataset (50 in this case) appears to work extremely well.&lt;br&gt;&lt;br&gt;Also tested converting/extracting data from bank transactions, logs, emails &amp;amp; other data &lt;a href=\"https://t.co/k2596TLvFc\"&gt;pic.twitter.com/k2596TLvFc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Igor Nefedov (@igornefedovi) &lt;a href=\"https://twitter.com/igornefedovi/status/1588032734315704320?ref_src=twsrc%5Etfw\"&gt;November 3, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/igornefedovi", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks\n\nI was wondering if there are any free sentiment analysis tools that are pre-trained (on typical customer support quer), so that I can run some text through it to get a general idea of positivity negativity? It\u2019s not a whole lot of text, maybe several thousand paragraphs.\n\nThanks.", "author_fullname": "t2_4zxcnppv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentiment analysis of customer support tickets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykmpgt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667434158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there are any free sentiment analysis tools that are pre-trained (on typical customer support quer), so that I can run some text through it to get a general idea of positivity negativity? It\u2019s not a whole lot of text, maybe several thousand paragraphs.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykmpgt", "is_robot_indexable": true, "report_reasons": null, "author": "enigmapaulns", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykmpgt/sentiment_analysis_of_customer_support_tickets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykmpgt/sentiment_analysis_of_customer_support_tickets/", "subreddit_subscribers": 817043, "created_utc": 1667434158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it not almost always better to use probability output? So the business had a view of the model confidence for each prediction and can act on this information rather than a more black box output?", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In a business context, why would you ever use a binary output for a binary classifier? Its it almost always better to output class probability so the business can set their own threshold?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykytgo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667471944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it not almost always better to use probability output? So the business had a view of the model confidence for each prediction and can act on this information rather than a more black box output?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykytgo", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykytgo/in_a_business_context_why_would_you_ever_use_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykytgo/in_a_business_context_why_would_you_ever_use_a/", "subreddit_subscribers": 817043, "created_utc": 1667471944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! Recent BSc Biology grad here.\n\nI was thinking of doing an MDS to help train me how to work with big data. Would like to use the skills acquired to do bioinformatics or something related to analysis of healthcare data (I've been told by r/bioinformatics to go for an MDS instead of MSc Bioinf because you are taught similar skills but MDS will give broader job prospects). However, many of the MDS programs in my country are considered professional programs and thus funding is not provided by the university. This is a pretty significant downside for me. Would a masters in statistics provide me with similar skills? Thanks :)", "author_fullname": "t2_v7ofz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to Data Science Masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykrj8n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667447641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Recent BSc Biology grad here.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of doing an MDS to help train me how to work with big data. Would like to use the skills acquired to do bioinformatics or something related to analysis of healthcare data (I&amp;#39;ve been told by &lt;a href=\"/r/bioinformatics\"&gt;r/bioinformatics&lt;/a&gt; to go for an MDS instead of MSc Bioinf because you are taught similar skills but MDS will give broader job prospects). However, many of the MDS programs in my country are considered professional programs and thus funding is not provided by the university. This is a pretty significant downside for me. Would a masters in statistics provide me with similar skills? Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykrj8n", "is_robot_indexable": true, "report_reasons": null, "author": "KwallahT", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykrj8n/alternative_to_data_science_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykrj8n/alternative_to_data_science_masters/", "subreddit_subscribers": 817043, "created_utc": 1667447641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2qp4bbiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Data Analyst looking to transition to Data Scientist after I finish my undergrad. Any tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zly81vwzqmx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=607cb9b722e074f75dba2bb17f8989b9513cdcfc"}, {"y": 278, "x": 216, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2903d584528d9ee64ddc4deb997762b60e42d67d"}, {"y": 411, "x": 320, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fed11764dc4995eb1290bd4b2784b170daeb17a5"}, {"y": 823, "x": 640, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=360c499b83f4739d9973aea2a58f67b9c5906458"}, {"y": 1235, "x": 960, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6478855580c0475dfb06355ee0f5b26370e35d90"}, {"y": 1390, "x": 1080, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6871e11c57a167f9ea88ba1373ea60c9e4e9b839"}], "s": {"y": 1506, "x": 1170, "u": "https://preview.redd.it/zly81vwzqmx91.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=3028fdc1fd65df157da93178373d3ab6565ed228"}, "id": "zly81vwzqmx91"}, "ai4hsuwzqmx91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 138, "x": 108, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=148bb6cd952e5825dcc7a62223804cb7222b0fd0"}, {"y": 277, "x": 216, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4233a1a87b9666fcd41ad76f6424d0b99f121b1"}, {"y": 411, "x": 320, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a99f72d0d6332336ed6df6ac6efc71aeaa55ce18"}, {"y": 823, "x": 640, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce6cfa5f0fe5f9b03e3b384c04f3829a0e49aad9"}, {"y": 1234, "x": 960, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e31afbdc88eec2f7baad4a6e21ed1d4d68c0d79"}, {"y": 1389, "x": 1080, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f26b619fad82ac39a61da2f5a4c33f623da676ea"}], "s": {"y": 1505, "x": 1170, "u": "https://preview.redd.it/ai4hsuwzqmx91.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=34790eac3971584fbcf3fd0ef2eb49da54889187"}, "id": "ai4hsuwzqmx91"}}, "name": "t3_ykn277", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "ups": 5, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "ai4hsuwzqmx91", "id": 204891057}, {"media_id": "zly81vwzqmx91", "id": 204891058}]}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Y4vC0HMhl0goDdnP4g4nQATGjVuRQYk39OWhDZvkbmA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667435058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/ykn277", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "ykn277", "is_robot_indexable": true, "report_reasons": null, "author": "Dont_know_wa_im_doin", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykn277/data_analyst_looking_to_transition_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/ykn277", "subreddit_subscribers": 817043, "created_utc": 1667435058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6ntqfru4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow, Poetry and Docker: Anyone get them to work together?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yksvjr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667451938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yksvjr", "is_robot_indexable": true, "report_reasons": null, "author": "Entire_Ambassador349", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yksvjr/airflow_poetry_and_docker_anyone_get_them_to_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yksvjr/airflow_poetry_and_docker_anyone_get_them_to_work/", "subreddit_subscribers": 817043, "created_utc": 1667451938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working on building up my data science knowledge for a few months now. Started actually building and testing models a bit over a month ago and now I'm fairly at a comfortable place. Not winning Kaggle competitions but the scores are something I'm happy with...for now.\n\nI've realised that my Achilles' Heel at this point is feature engineering, which is one of the most important tasks to build a good model. Before beginning work, I do look at similar datasets and see how others have treated that data but somehow my lack of knowledge in that domain fails me.\n\nI think I have very good interpretability skills from a business perspective but I'm unable to translate that understanding into features.\n\nHow much time do you all spend researching the related industry/domain of the data before building models? Any tips/tricks that you think could work for me?\n\nRight now I'm reading [http://www.feat.engineering/](http://www.feat.engineering/) which I found on this sub", "author_fullname": "t2_55cjp0l4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Engineering without domain knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykk7j9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667428781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on building up my data science knowledge for a few months now. Started actually building and testing models a bit over a month ago and now I&amp;#39;m fairly at a comfortable place. Not winning Kaggle competitions but the scores are something I&amp;#39;m happy with...for now.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve realised that my Achilles&amp;#39; Heel at this point is feature engineering, which is one of the most important tasks to build a good model. Before beginning work, I do look at similar datasets and see how others have treated that data but somehow my lack of knowledge in that domain fails me.&lt;/p&gt;\n\n&lt;p&gt;I think I have very good interpretability skills from a business perspective but I&amp;#39;m unable to translate that understanding into features.&lt;/p&gt;\n\n&lt;p&gt;How much time do you all spend researching the related industry/domain of the data before building models? Any tips/tricks that you think could work for me?&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;m reading &lt;a href=\"http://www.feat.engineering/\"&gt;http://www.feat.engineering/&lt;/a&gt; which I found on this sub&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykk7j9", "is_robot_indexable": true, "report_reasons": null, "author": "_Triggernometry_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykk7j9/feature_engineering_without_domain_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykk7j9/feature_engineering_without_domain_knowledge/", "subreddit_subscribers": 817043, "created_utc": 1667428781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_d7ung", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone ELI5 nested cross validation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "name": "t3_yksloq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a5my7OPO1jSh0YZfIOUAcwuTB1HxBwyhagXb-lR_xIE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667451058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "scikit-learn.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "http://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p8UWe7P-YBJbKgqnfC_c6CCnbN_dt6MaKfe8oBmQpYo.jpg?auto=webp&amp;s=b27948a66bfc7b1fcce0868f365679abefd2dcb6", "width": 160, "height": 58}, "resolutions": [{"url": "https://external-preview.redd.it/p8UWe7P-YBJbKgqnfC_c6CCnbN_dt6MaKfe8oBmQpYo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea009a13d87d058093cb4117dad12bf8f3d5e5ff", "width": 108, "height": 39}], "variants": {}, "id": "aRDTtkw0_GBCGb9E7JLBzDXeEp2pWa53pBC0AILtbPw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yksloq", "is_robot_indexable": true, "report_reasons": null, "author": "o-rka", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yksloq/can_someone_eli5_nested_cross_validation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html", "subreddit_subscribers": 817043, "created_utc": 1667451058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, guys how would you approach the following problem?\n\n&amp;#x200B;\n\nI'm currently using an simple AutoRegressive model with the last N days to predit a sales outcome for the next day. I want to improve the model by using the first hours of the day that I'm trying to predict. \n\nThe problem is that the number of hours that I'll have available are note fixed. Maybe someone will use the prediction service at 8am and then at 4pm.  How would you add this feature if you want to use all the data available at the time?", "author_fullname": "t2_kguah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Timeseries help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykesdc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667417883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, guys how would you approach the following problem?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using an simple AutoRegressive model with the last N days to predit a sales outcome for the next day. I want to improve the model by using the first hours of the day that I&amp;#39;m trying to predict. &lt;/p&gt;\n\n&lt;p&gt;The problem is that the number of hours that I&amp;#39;ll have available are note fixed. Maybe someone will use the prediction service at 8am and then at 4pm.  How would you add this feature if you want to use all the data available at the time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykesdc", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_dealer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykesdc/timeseries_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykesdc/timeseries_help/", "subreddit_subscribers": 817043, "created_utc": 1667417883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The key components in an EDA are the main steps undertaken to perform the EDA. These are as follows:  \n\n\n1. Data Collection  \n\n\nNowadays, data is generated in huge volumes and various forms belonging to every sector of human life, like healthcare, sports, manufacturing, tourism, and so on. Every business knows the importance of using data beneficially by properly analyzing it. However, this depends on collecting the required data from various sources through surveys, social media, and customer reviews, to name a few. Without collecting sufficient and relevant data, further activities cannot begin.  \n\n\n2. Finding all Variables and Understanding Them  \n\n\nWhen the analysis process starts, the first focus is on the available data that gives a lot of information. This information contains changing values about various features or characteristics, which helps to understand and get valuable insights from them. It requires first identifying the important variables which affect the outcome and their possible impact. This step is crucial for the final result expected from any analysis.  \n\n\n3. Cleaning the Dataset  \n\n\nThe next step is to clean the data set, which may contain null values and irrelevant information. These are to be removed so that data contains only those values that are relevant and important from the target point of view. This will not only reduce time but also reduces the computational power from an estimation point of view. Preprocessing takes care of all issues, such as identifying null values, outliers, anomaly detection, etc.  \n\n\n4. Identify Correlated Variables  \n\n\nFinding a correlation between variables helps to know how a particular variable is related to another. The correlation matrix method gives a clear picture of how different variables correlate, which further helps in understanding vital relationships among them.  \n\n\n5. Choosing the Right Statistical Methods  \n\n\nAs will be seen in later sections, depending on the data, categorical or numerical, the size, type of variables, and the purpose of analysis, different statistical tools are employed. Statistical formulae applied for numerical outputs give fair information, but graphical visuals are more appealing and easier to interpret.  \n\n\n6. Visualizing and Analyzing Results  \n\n\nOnce the analysis is over, the findings are to be observed cautiously and carefully so that proper interpretation can be made. The trends in the spread of data and correlation between variables give good insights for making suitable changes in the data parameters. The data analyst should have the requisite capability to analyze and be well-versed in all analysis techniques. The results obtained will be appropriate to data of that particular domain and are suitable for use in retail, healthcare, and agriculture.", "author_fullname": "t2_ikvv2nbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Steps Involved in Exploratory Data Analysis (EDA)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yl9aza", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667497676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The key components in an EDA are the main steps undertaken to perform the EDA. These are as follows:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Collection&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Nowadays, data is generated in huge volumes and various forms belonging to every sector of human life, like healthcare, sports, manufacturing, tourism, and so on. Every business knows the importance of using data beneficially by properly analyzing it. However, this depends on collecting the required data from various sources through surveys, social media, and customer reviews, to name a few. Without collecting sufficient and relevant data, further activities cannot begin.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Finding all Variables and Understanding Them&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;When the analysis process starts, the first focus is on the available data that gives a lot of information. This information contains changing values about various features or characteristics, which helps to understand and get valuable insights from them. It requires first identifying the important variables which affect the outcome and their possible impact. This step is crucial for the final result expected from any analysis.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Cleaning the Dataset&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The next step is to clean the data set, which may contain null values and irrelevant information. These are to be removed so that data contains only those values that are relevant and important from the target point of view. This will not only reduce time but also reduces the computational power from an estimation point of view. Preprocessing takes care of all issues, such as identifying null values, outliers, anomaly detection, etc.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Identify Correlated Variables&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Finding a correlation between variables helps to know how a particular variable is related to another. The correlation matrix method gives a clear picture of how different variables correlate, which further helps in understanding vital relationships among them.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Choosing the Right Statistical Methods&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As will be seen in later sections, depending on the data, categorical or numerical, the size, type of variables, and the purpose of analysis, different statistical tools are employed. Statistical formulae applied for numerical outputs give fair information, but graphical visuals are more appealing and easier to interpret.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Visualizing and Analyzing Results&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Once the analysis is over, the findings are to be observed cautiously and carefully so that proper interpretation can be made. The trends in the spread of data and correlation between variables give good insights for making suitable changes in the data parameters. The data analyst should have the requisite capability to analyze and be well-versed in all analysis techniques. The results obtained will be appropriate to data of that particular domain and are suitable for use in retail, healthcare, and agriculture.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl9aza", "is_robot_indexable": true, "report_reasons": null, "author": "onlineeducation22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl9aza/steps_involved_in_exploratory_data_analysis_eda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl9aza/steps_involved_in_exploratory_data_analysis_eda/", "subreddit_subscribers": 817043, "created_utc": 1667497676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m not sure exactly how to phrase this. Professional DS with 15 years experience. I have no problems doing everything locally or on a web server if someone sets one up for me. For example, my company has a process to deploy Python scripts via restful API. The engineer taught me how to deploy what in need but when something breaks I am lost. How would I learn to fix bugs or setup my own type of service? Another issue. Someone is sending me a huge data file across a subnet at 5MB per second. Often the job fails. I would like to try to fix this. How do I learn about this. I don\u2019t even know what it\u2019s called. I\u2019m tired of waiting on other people to solve my problems.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources for architecture and networks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1w7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667479497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not sure exactly how to phrase this. Professional DS with 15 years experience. I have no problems doing everything locally or on a web server if someone sets one up for me. For example, my company has a process to deploy Python scripts via restful API. The engineer taught me how to deploy what in need but when something breaks I am lost. How would I learn to fix bugs or setup my own type of service? Another issue. Someone is sending me a huge data file across a subnet at 5MB per second. Often the job fails. I would like to try to fix this. How do I learn about this. I don\u2019t even know what it\u2019s called. I\u2019m tired of waiting on other people to solve my problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl1w7d", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl1w7d/good_resources_for_architecture_and_networks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl1w7d/good_resources_for_architecture_and_networks/", "subreddit_subscribers": 817043, "created_utc": 1667479497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been a ds for a number of years now on a decent size team and have worked on and lead handful of cool projects but I have zero formal education in the field.  I\u2019m self taught enough that I can keep up with anyone at this point.  Actually I help interns with problems frequently that come straight out of a masters program. I\u2019m surprised how little you know after graduating.\n\nI\u2019ve kinda worry about how many job posting require a masters/phd if I wanted to explore other opportunities.\n\nDo you think with the current state of the industry that it will be hard to get a position without the formal education backing me?", "author_fullname": "t2_hwogh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current DS without credentials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl1jbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667478493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a ds for a number of years now on a decent size team and have worked on and lead handful of cool projects but I have zero formal education in the field.  I\u2019m self taught enough that I can keep up with anyone at this point.  Actually I help interns with problems frequently that come straight out of a masters program. I\u2019m surprised how little you know after graduating.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve kinda worry about how many job posting require a masters/phd if I wanted to explore other opportunities.&lt;/p&gt;\n\n&lt;p&gt;Do you think with the current state of the industry that it will be hard to get a position without the formal education backing me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl1jbo", "is_robot_indexable": true, "report_reasons": null, "author": "tkpk5280", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl1jbo/current_ds_without_credentials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl1jbo/current_ds_without_credentials/", "subreddit_subscribers": 817043, "created_utc": 1667478493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm finding parallelising an r task (which basically means assigning work to a separate r session) requires all data in my environment to be copied over to the cache of the new core. If I'm working with just 10gb of data, my machine is losing more time copying data than it's saving by parallelising. This means I can't even split up CV tasks on windows, which should be trivial to parallelise.\n\nIs there an obvious alternative to this approach? And am I right in saying running on Linux would avoid this bottleneck?", "author_fullname": "t2_1rwftqt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does lack of fork parallelisation make windows an impractical OS for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl10to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667477285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finding parallelising an r task (which basically means assigning work to a separate r session) requires all data in my environment to be copied over to the cache of the new core. If I&amp;#39;m working with just 10gb of data, my machine is losing more time copying data than it&amp;#39;s saving by parallelising. This means I can&amp;#39;t even split up CV tasks on windows, which should be trivial to parallelise.&lt;/p&gt;\n\n&lt;p&gt;Is there an obvious alternative to this approach? And am I right in saying running on Linux would avoid this bottleneck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl10to", "is_robot_indexable": true, "report_reasons": null, "author": "theAbominablySlowMan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl10to/does_lack_of_fork_parallelisation_make_windows_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl10to/does_lack_of_fork_parallelisation_make_windows_an/", "subreddit_subscribers": 817043, "created_utc": 1667477285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\n&amp;#x200B;\n\nForgive me if this is not the right place to do this but I am studying data science myself and part of an assignment we have is to interview Data Scientist in the field regarding Data Ethics and create a summary of the results.\n\n&amp;#x200B;\n\nWould a few of you mind answering the following questions for me? I have tried getting in contact directly with people at banks, other universities and so forth but I am struggling to find people willing to conduct the \"Interview\". We need to attach proof that we conducted the interview, hence I need actual real data and am not about the business of \"fudging\" results.\n\nAssignment questions are as follows:\n\n\\--------\n\nDuring the interview, discuss the person\u2019s professional experience with ethics issues in their professional career on both the technical and personnel/workplace sides. This should include issues they directly experienced, and if they want, can include issues they heard about, as well. Pick two or three of the most memorable issues brought up by your interview, and ask some follow-up questions:\n\n* Do they feel the issue was handled well or not?\n* Were there situations that made it difficult to take the most ethical path?\n\n\\--------\n\nAny feedback would really be appreciated.\n\nThanks :)", "author_fullname": "t2_ntnaxuu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykysox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667471888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Forgive me if this is not the right place to do this but I am studying data science myself and part of an assignment we have is to interview Data Scientist in the field regarding Data Ethics and create a summary of the results.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would a few of you mind answering the following questions for me? I have tried getting in contact directly with people at banks, other universities and so forth but I am struggling to find people willing to conduct the &amp;quot;Interview&amp;quot;. We need to attach proof that we conducted the interview, hence I need actual real data and am not about the business of &amp;quot;fudging&amp;quot; results.&lt;/p&gt;\n\n&lt;p&gt;Assignment questions are as follows:&lt;/p&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;During the interview, discuss the person\u2019s professional experience with ethics issues in their professional career on both the technical and personnel/workplace sides. This should include issues they directly experienced, and if they want, can include issues they heard about, as well. Pick two or three of the most memorable issues brought up by your interview, and ask some follow-up questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do they feel the issue was handled well or not?&lt;/li&gt;\n&lt;li&gt;Were there situations that made it difficult to take the most ethical path?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;Any feedback would really be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykysox", "is_robot_indexable": true, "report_reasons": null, "author": "Eat-More-Brains", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykysox/data_science_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykysox/data_science_interview/", "subreddit_subscribers": 817043, "created_utc": 1667471888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A friend and I recently participated in a local datathon here in Australia and we're looking for further challenges either here or anywhere in the world (if it's open to international teams), however we're having a hard time finding websites or communities that are centered in promoting/advertising these events. We have something similar in Australia [for hackathons in general](https://www.hackathonsaustralia.com/), but they ceased comms over a year ago.\n\nAny suggestions about where to look for more data-driven challenges and competitions for international datathons or (ideally) in Australia? (Yes I *am* googling please don't send me there).", "author_fullname": "t2_71lk6sl4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any suggestions on communities (here on Reddit) or websites that announce/promote datathons?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykrt71", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667448496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A friend and I recently participated in a local datathon here in Australia and we&amp;#39;re looking for further challenges either here or anywhere in the world (if it&amp;#39;s open to international teams), however we&amp;#39;re having a hard time finding websites or communities that are centered in promoting/advertising these events. We have something similar in Australia &lt;a href=\"https://www.hackathonsaustralia.com/\"&gt;for hackathons in general&lt;/a&gt;, but they ceased comms over a year ago.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions about where to look for more data-driven challenges and competitions for international datathons or (ideally) in Australia? (Yes I &lt;em&gt;am&lt;/em&gt; googling please don&amp;#39;t send me there).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?auto=webp&amp;s=11eea8bc1fb810dc41c39d03eb1ea8d9c1977777", "width": 2460, "height": 1403}, "resolutions": [{"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6ef608d492647f3667beab7bfa9ab39f2e9d5dcc", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=abde207855145f367f630b2ee21b426c780c27be", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=327fcb10a130b311dbfd0b7defec642d8f3030d7", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d9a13d21b8d35521dd4ea5faacf7b598eff8fd4", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f93546129811ed8d4043fe3b38fcbf0b42e988d", "width": 960, "height": 547}, {"url": "https://external-preview.redd.it/IXtgRs6Zobbj_lavvAd9PHWaZRdv_ASW5PMi7ACWVL0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8670867e42d602b1d0e593ca46be3d885ac8511f", "width": 1080, "height": 615}], "variants": {}, "id": "vM8d3m2aOfl5VOI6_MUCLK00ddGCAj8Fgsy5VTpH0Sw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykrt71", "is_robot_indexable": true, "report_reasons": null, "author": "William_Rosebud", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykrt71/any_suggestions_on_communities_here_on_reddit_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykrt71/any_suggestions_on_communities_here_on_reddit_or/", "subreddit_subscribers": 817043, "created_utc": 1667448496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have a dataset that a client sent me. They are a furniture manufacturer company, specialized in making Dressers. Their \"added value\" are how economical their products are.\n\nThe dataset's rows are individual ordered products, which can repeat for a single customer depending on how many products they ordered in a single transaction/day (if they bought 10 dressers, a single customer has 10 rows, each row being 1 product bought). **I'm tasked with gathering actionable insights for the client based on the dataset; the issue is that the dataset is very limited in terms of columns/variables, and I think/feel I'm out of ideas already**. I'm part of a digital marketing business, but this is exercise is actually not directly related to exclusively/mandatorily generating digital marketing recommendations.\n\nThe dataset columns are:\n\n1. Order Date (dd/mm/yyy), only with data from January 2021 to October 2022\n2. Product Name\n3. Customer Name (mostly useless)\n4. Customer Gender (M or F)\n5. City (needs A LOT of cleaning to standardize. This was a manual input from whoever filled it out)\n6. State (from the United States)\n7. Zip Code\n8. Channel (whether they sell through Amazon, Walmart or other marketplaces, or directly through their website. This is only available for 2021 and not for 2022)\n\nI already looked at things like:\n\n1. Top/bottom states in terms of orders by 100k population (based on each state's population). \\[Bar charts\\]\n2. Total orders (Y axis) by month (X axis) by state to detect outliers/patterns (nothing to highlight here, they mostly follow the national, aggregated total orders). \\[Line charts\\]\n3. Most popular products by state and their avg. order share (from each state) \\[Bar charts\\]\n4. Top/bottom products just based on total orders \\[Bar charts\\]\n5. Top/bottom states just based on total orders \\[Bar charts\\]\n6. Reach by product (whether they are sold in all states: 100%, just in one (1/51), etc.) \\[Bar charts\\]\n7. How much of the total orders do Dressers represent specifically \\[Area chart\\]\n8. Top 5 products by month \\[Ribbon chart\\]\n9. Top 5 products by gender \\[Bar chart\\]\n10. Top/bottom products by their male-to-female ratio in terms of orders \\[Bar chart\\]\n11. Repurchases based on a \"composite key\" of customer name + zip code for a single day \\[Bar chart, but almost useless. Almost no repurchases with less than 0.5% of all transactions\\]\n\nThat's about it. I think having columns like \"revenue\" and data for more years could really bring a whole new world of insights and creativity to get real actionable insights. So far the client (for any reason) has been reluctant to provide this or more data apart from 2021 and 2022. **Any ideas? I would enormously appreciate your input on this**\n\n**TL;DR: I have a very limited dataset on orders for furniture, mostly Dressers. I need to gather actionable insights and the data is extremely limited in terms of date range (2021-2022) and variables (up to 8 variables, with just 4 or 5 being truly useful). Ideas on actionable insights?**\n\nThank you!", "author_fullname": "t2_ie26w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to add more creativity to this EDA to gather useful, actionable insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykp0fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667440266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a dataset that a client sent me. They are a furniture manufacturer company, specialized in making Dressers. Their &amp;quot;added value&amp;quot; are how economical their products are.&lt;/p&gt;\n\n&lt;p&gt;The dataset&amp;#39;s rows are individual ordered products, which can repeat for a single customer depending on how many products they ordered in a single transaction/day (if they bought 10 dressers, a single customer has 10 rows, each row being 1 product bought). &lt;strong&gt;I&amp;#39;m tasked with gathering actionable insights for the client based on the dataset; the issue is that the dataset is very limited in terms of columns/variables, and I think/feel I&amp;#39;m out of ideas already&lt;/strong&gt;. I&amp;#39;m part of a digital marketing business, but this is exercise is actually not directly related to exclusively/mandatorily generating digital marketing recommendations.&lt;/p&gt;\n\n&lt;p&gt;The dataset columns are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Order Date (dd/mm/yyy), only with data from January 2021 to October 2022&lt;/li&gt;\n&lt;li&gt;Product Name&lt;/li&gt;\n&lt;li&gt;Customer Name (mostly useless)&lt;/li&gt;\n&lt;li&gt;Customer Gender (M or F)&lt;/li&gt;\n&lt;li&gt;City (needs A LOT of cleaning to standardize. This was a manual input from whoever filled it out)&lt;/li&gt;\n&lt;li&gt;State (from the United States)&lt;/li&gt;\n&lt;li&gt;Zip Code&lt;/li&gt;\n&lt;li&gt;Channel (whether they sell through Amazon, Walmart or other marketplaces, or directly through their website. This is only available for 2021 and not for 2022)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I already looked at things like:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Top/bottom states in terms of orders by 100k population (based on each state&amp;#39;s population). [Bar charts]&lt;/li&gt;\n&lt;li&gt;Total orders (Y axis) by month (X axis) by state to detect outliers/patterns (nothing to highlight here, they mostly follow the national, aggregated total orders). [Line charts]&lt;/li&gt;\n&lt;li&gt;Most popular products by state and their avg. order share (from each state) [Bar charts]&lt;/li&gt;\n&lt;li&gt;Top/bottom products just based on total orders [Bar charts]&lt;/li&gt;\n&lt;li&gt;Top/bottom states just based on total orders [Bar charts]&lt;/li&gt;\n&lt;li&gt;Reach by product (whether they are sold in all states: 100%, just in one (1/51), etc.) [Bar charts]&lt;/li&gt;\n&lt;li&gt;How much of the total orders do Dressers represent specifically [Area chart]&lt;/li&gt;\n&lt;li&gt;Top 5 products by month [Ribbon chart]&lt;/li&gt;\n&lt;li&gt;Top 5 products by gender [Bar chart]&lt;/li&gt;\n&lt;li&gt;Top/bottom products by their male-to-female ratio in terms of orders [Bar chart]&lt;/li&gt;\n&lt;li&gt;Repurchases based on a &amp;quot;composite key&amp;quot; of customer name + zip code for a single day [Bar chart, but almost useless. Almost no repurchases with less than 0.5% of all transactions]&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;That&amp;#39;s about it. I think having columns like &amp;quot;revenue&amp;quot; and data for more years could really bring a whole new world of insights and creativity to get real actionable insights. So far the client (for any reason) has been reluctant to provide this or more data apart from 2021 and 2022. &lt;strong&gt;Any ideas? I would enormously appreciate your input on this&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR: I have a very limited dataset on orders for furniture, mostly Dressers. I need to gather actionable insights and the data is extremely limited in terms of date range (2021-2022) and variables (up to 8 variables, with just 4 or 5 being truly useful). Ideas on actionable insights?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykp0fb", "is_robot_indexable": true, "report_reasons": null, "author": "MadGlobin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykp0fb/how_to_add_more_creativity_to_this_eda_to_gather/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykp0fb/how_to_add_more_creativity_to_this_eda_to_gather/", "subreddit_subscribers": 817043, "created_utc": 1667440266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm interested in learning a new \"spoken language\" (idk how to call it), I tried to look it up but only got answers about programming languages.\n\nI already speak Spanish (native) and English (not perfectly) but don't have any idea where should I continue.", "author_fullname": "t2_5oj654vi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most useful spoken languages for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykkupe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667430075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in learning a new &amp;quot;spoken language&amp;quot; (idk how to call it), I tried to look it up but only got answers about programming languages.&lt;/p&gt;\n\n&lt;p&gt;I already speak Spanish (native) and English (not perfectly) but don&amp;#39;t have any idea where should I continue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykkupe", "is_robot_indexable": true, "report_reasons": null, "author": "Pepe_Alpa", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ykkupe/what_are_the_most_useful_spoken_languages_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ykkupe/what_are_the_most_useful_spoken_languages_for/", "subreddit_subscribers": 817043, "created_utc": 1667430075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I worked on the project and practically built everything from ground up however after a few months the team needs me to help answer questions on a portion  my teammates worked on. I am familiar with the whole process so I am the only one who knows time-series since the other than a DS is on maternity leave.\n\nI asked for part time during my studies and full time but they didn\u2019t give me anything and half assed any attempted to give me a job. However now that they are struggling they are asking for free consultations. \n\nthey put a new kid on the project but still do not have people qualified or knowledgeable enough to maintain and uphold the quality. So i am worried they would expect me to train their employees for free without them offering anything in return.\n\nNote: i put everything properly on documentation as well as how to trouble shoot potential problems.", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project manager reached out to me for help to answer questions on deployment after the end of my internship.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yl8gmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667495827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I worked on the project and practically built everything from ground up however after a few months the team needs me to help answer questions on a portion  my teammates worked on. I am familiar with the whole process so I am the only one who knows time-series since the other than a DS is on maternity leave.&lt;/p&gt;\n\n&lt;p&gt;I asked for part time during my studies and full time but they didn\u2019t give me anything and half assed any attempted to give me a job. However now that they are struggling they are asking for free consultations. &lt;/p&gt;\n\n&lt;p&gt;they put a new kid on the project but still do not have people qualified or knowledgeable enough to maintain and uphold the quality. So i am worried they would expect me to train their employees for free without them offering anything in return.&lt;/p&gt;\n\n&lt;p&gt;Note: i put everything properly on documentation as well as how to trouble shoot potential problems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl8gmi", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl8gmi/project_manager_reached_out_to_me_for_help_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl8gmi/project_manager_reached_out_to_me_for_help_to/", "subreddit_subscribers": 817043, "created_utc": 1667495827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Fundamentals of Data Engineering by Joe Reis and Matthew Housley.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl6qnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mh2cfxap", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Fundamentals of Data Engineering](https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302) has received a lot of good reviews in the data world, and I\u2019ve been meaning to read it.Turns out lots of folks have been meaning to read it too, so I put together a book club!\n\nI'm not being paid to promote this book in any way, shape, or form. I have no business affiliation with the authors. I just want to read it in a book club.**Here\u2019s a brief overview of the book club:**\\- All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.**Schedule:**\n\n* [**November 18th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-11&amp;date=2022-11-18)**:** Discuss Chapters 1-3\n* [**December 2nd**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-02)**:** Discuss Chapters 4-7\n* [**December 8th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-08)**:** Live AMA with Joe Reis, the author\n* [**December 16th**](https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;date=2022-12-16)**:** Discuss Chapters 8-11\n\nWe currently have 20+ people participating!If this sounds interesting to you, find additional details and schedule [here](https://calendly.com/jparkerrogers/oa-book-club?month=2022-11).", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Fundamentals of Data Engineering by Joe Reis and Matthew Housley.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ykbcfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 160, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 160, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667434000.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667410085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/Fundamentals-Data-Engineering-Robust-Systems/dp/1098108302\"&gt;Fundamentals of Data Engineering&lt;/a&gt; has received a lot of good reviews in the data world, and I\u2019ve been meaning to read it.Turns out lots of folks have been meaning to read it too, so I put together a book club!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not being paid to promote this book in any way, shape, or form. I have no business affiliation with the authors. I just want to read it in a book club.&lt;strong&gt;Here\u2019s a brief overview of the book club:&lt;/strong&gt;- All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.&lt;strong&gt;Schedule:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-11&amp;amp;date=2022-11-18\"&gt;&lt;strong&gt;November 18th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 1-3&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-02\"&gt;&lt;strong&gt;December 2nd&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 4-7&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-08\"&gt;&lt;strong&gt;December 8th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Live AMA with Joe Reis, the author&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-12&amp;amp;date=2022-12-16\"&gt;&lt;strong&gt;December 16th&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt; Discuss Chapters 8-11&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We currently have 20+ people participating!If this sounds interesting to you, find additional details and schedule &lt;a href=\"https://calendly.com/jparkerrogers/oa-book-club?month=2022-11\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ykbcfo", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "subreddit_subscribers": 78818, "created_utc": 1667410085.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1667491606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl6qnq", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ykbcfo", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl6qnq/book_club_fundamentals_of_data_engineering_by_joe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/ykbcfo/book_club_fundamentals_of_data_engineering_by_joe/", "subreddit_subscribers": 817043, "created_utc": 1667491606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As stated above, I work in Child Fatality Review. Every state in the US for the most part has a review team that draws conclusions from the data collected. I did not go to school for data analysis but I would like to be trained in graphing statistics as it would make the most impact on our annual reports.  Does anybody have any tips on how to develop this skill without going back to school for it?", "author_fullname": "t2_oxgbf5nq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Child Fatality Review - How can I develop this career further without going to school?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl5rrp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667489374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As stated above, I work in Child Fatality Review. Every state in the US for the most part has a review team that draws conclusions from the data collected. I did not go to school for data analysis but I would like to be trained in graphing statistics as it would make the most impact on our annual reports.  Does anybody have any tips on how to develop this skill without going back to school for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl5rrp", "is_robot_indexable": true, "report_reasons": null, "author": "truecrimeavocado", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl5rrp/child_fatality_review_how_can_i_develop_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl5rrp/child_fatality_review_how_can_i_develop_this/", "subreddit_subscribers": 817043, "created_utc": 1667489374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear all,\n\nSuppose yo want to do a parametric analysis, what I mean is that you want to obtain an estimate of some parameter P, from a given dataset A. \nFor some reason, a college was doing the same exact thing, but in a different dataset. He is measuring P from dataset B.\nNow both colleagues want to obtain the most of both that datasets, they meet and they find that A and B are not independent, and the intersection C is not negligible. \n\nDo you know some references to deal with this kind of situation? Or do you know a procedure to get the most information of both datasets without discarding the intersection? How would you proceed?\n\nSorry in advance if this is not the right place to ask\nHace a nice day!", "author_fullname": "t2_a50rr8cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analysis in intersected data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl4bur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667485815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all,&lt;/p&gt;\n\n&lt;p&gt;Suppose yo want to do a parametric analysis, what I mean is that you want to obtain an estimate of some parameter P, from a given dataset A. \nFor some reason, a college was doing the same exact thing, but in a different dataset. He is measuring P from dataset B.\nNow both colleagues want to obtain the most of both that datasets, they meet and they find that A and B are not independent, and the intersection C is not negligible. &lt;/p&gt;\n\n&lt;p&gt;Do you know some references to deal with this kind of situation? Or do you know a procedure to get the most information of both datasets without discarding the intersection? How would you proceed?&lt;/p&gt;\n\n&lt;p&gt;Sorry in advance if this is not the right place to ask\nHace a nice day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl4bur", "is_robot_indexable": true, "report_reasons": null, "author": "SpiritedEagle7948", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl4bur/analysis_in_intersected_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl4bur/analysis_in_intersected_data/", "subreddit_subscribers": 817043, "created_utc": 1667485815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all - apologies if this has been asked but I haven\u2019t found a great answer. What do you all recommend to learn to translate datasets (and the concept behind the visuals) into something I can host on a website? I know there\u2019s a ton of tools/languages (Plotly dash, d3js, tableau, RShiny) out there, but not sure where to spend my time learning.\n\nMy aim is to be able to compare two athletes in a given sport (take American football for example) and provide a head to head analysis on certain talents. I know this kind of stuff already exists, but I\u2019d like to learn by doing.\n\nFor reference, I primarily work in Python but happy to learn a new language for this. Thanks!", "author_fullname": "t2_5tmeg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best interactive web-interface to show data/viz?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yl0kxk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667476259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - apologies if this has been asked but I haven\u2019t found a great answer. What do you all recommend to learn to translate datasets (and the concept behind the visuals) into something I can host on a website? I know there\u2019s a ton of tools/languages (Plotly dash, d3js, tableau, RShiny) out there, but not sure where to spend my time learning.&lt;/p&gt;\n\n&lt;p&gt;My aim is to be able to compare two athletes in a given sport (take American football for example) and provide a head to head analysis on certain talents. I know this kind of stuff already exists, but I\u2019d like to learn by doing.&lt;/p&gt;\n\n&lt;p&gt;For reference, I primarily work in Python but happy to learn a new language for this. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yl0kxk", "is_robot_indexable": true, "report_reasons": null, "author": "dumper514", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yl0kxk/best_interactive_webinterface_to_show_dataviz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yl0kxk/best_interactive_webinterface_to_show_dataviz/", "subreddit_subscribers": 817043, "created_utc": 1667476259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A-Z of Data Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_yktx4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_dt6ya2pz", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c9rjQ2GkKna0FMW1qyxH7bdbD6DSkaE9GlhZqgIzVVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_addlerkuhn", "selftext": "**E for ETL (Extract, Transform, Load).** \n\nhttps://preview.redd.it/6urf8grleox91.jpg?width=5001&amp;format=pjpg&amp;auto=webp&amp;s=c8a2c240c5e723fa08f29159ee9b2dd1f3519176\n\nIt is the data cleaning process used to collect raw data (extract), convert it into the correct format so that it can be entered into another database (transform), and write data into the target database (load). Data warehouses rely heavily on this procedure to collect and sort raw datasets from different sources into a single warehouse.\n\nTo read more about ETL, click here: [ETL (Extract, Transform, Load): Definition, How It Works, and Comparison](https://www.linkedin.com/pulse/etl-extract-transform-load-definition-how-works-comparison-/)\n\nTo read more about Data Warehousing, click here: [Data Warehousing: Definition, Examples, and Comparison](https://www.linkedin.com/pulse/data-warehousing-definition-examples-comparison-cubeware-gmbh/)", "author_fullname": "t2_dt6ya2pz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A-Z of Data Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "u/addlerkuhn", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6urf8grleox91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=372463b84c63dcf41512655dcf747012336a0516"}, {"y": 114, "x": 216, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac64984f581342ae664bd4e2ad2130d3717d8d57"}, {"y": 169, "x": 320, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4b0aebfe1660431e733293f5f7ec776caa612f5"}, {"y": 339, "x": 640, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcf39af63de772225265119b32b453427350382d"}, {"y": 509, "x": 960, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e0ae576df61df57755998058f37c920eed96560d"}, {"y": 573, "x": 1080, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9becc0dacb56aeea8a274fd2c2870555580920ca"}], "s": {"y": 2655, "x": 5001, "u": "https://preview.redd.it/6urf8grleox91.jpg?width=5001&amp;format=pjpg&amp;auto=webp&amp;s=c8a2c240c5e723fa08f29159ee9b2dd1f3519176"}, "id": "6urf8grleox91"}}, "name": "t3_ykts9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "user", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c9rjQ2GkKna0FMW1qyxH7bdbD6DSkaE9GlhZqgIzVVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667455124.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.addlerkuhn", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;E for ETL (Extract, Transform, Load).&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6urf8grleox91.jpg?width=5001&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c8a2c240c5e723fa08f29159ee9b2dd1f3519176\"&gt;https://preview.redd.it/6urf8grleox91.jpg?width=5001&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c8a2c240c5e723fa08f29159ee9b2dd1f3519176&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It is the data cleaning process used to collect raw data (extract), convert it into the correct format so that it can be entered into another database (transform), and write data into the target database (load). Data warehouses rely heavily on this procedure to collect and sort raw datasets from different sources into a single warehouse.&lt;/p&gt;\n\n&lt;p&gt;To read more about ETL, click here: &lt;a href=\"https://www.linkedin.com/pulse/etl-extract-transform-load-definition-how-works-comparison-/\"&gt;ETL (Extract, Transform, Load): Definition, How It Works, and Comparison&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;To read more about Data Warehousing, click here: &lt;a href=\"https://www.linkedin.com/pulse/data-warehousing-definition-examples-comparison-cubeware-gmbh/\"&gt;Data Warehousing: Definition, Examples, and Comparison&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?auto=webp&amp;s=89c5bc72631da2314866a19292259a955c337d72", "width": 1280, "height": 679}, "resolutions": [{"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=916d080c07ddb482b0b4a89f693e36c89d6dae02", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61061b5bcbb9cef65814f43408c9f408ad1a971c", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bca5ecdc9900b3363723f7890210e7306205cbc2", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bfbaabaf3bce669f1f284e02fec8c90fd2c7a66b", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b45ebd56db5f273bde969ec854886143ee551a4b", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3f119e0be19d74d108523ffcafcc4ada119fbd24", "width": 1080, "height": 572}], "variants": {}, "id": "X13p816u_eoSFuYTCeDw4QPwxJbOxmW1PLUHBIcPyLc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_6uqcib", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ykts9m", "is_robot_indexable": true, "report_reasons": null, "author": "addlerkuhn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_addlerkuhn/comments/ykts9m/az_of_data_analytics/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_addlerkuhn/comments/ykts9m/az_of_data_analytics/", "subreddit_subscribers": 0, "created_utc": 1667455124.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1667455560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.addlerkuhn", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/user/addlerkuhn/comments/ykts9m/az_of_data_analytics/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?auto=webp&amp;s=89c5bc72631da2314866a19292259a955c337d72", "width": 1280, "height": 679}, "resolutions": [{"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=916d080c07ddb482b0b4a89f693e36c89d6dae02", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=61061b5bcbb9cef65814f43408c9f408ad1a971c", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bca5ecdc9900b3363723f7890210e7306205cbc2", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bfbaabaf3bce669f1f284e02fec8c90fd2c7a66b", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b45ebd56db5f273bde969ec854886143ee551a4b", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/i8wy79mg0tVAxy-K8yxTBhaF7x9R2K-ooCZrepto28U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3f119e0be19d74d108523ffcafcc4ada119fbd24", "width": 1080, "height": 572}], "variants": {}, "id": "X13p816u_eoSFuYTCeDw4QPwxJbOxmW1PLUHBIcPyLc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yktx4k", "is_robot_indexable": true, "report_reasons": null, "author": "addlerkuhn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ykts9m", "author_flair_text_color": null, "permalink": "/r/datascience/comments/yktx4k/az_of_data_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/user/addlerkuhn/comments/ykts9m/az_of_data_analytics/", "subreddit_subscribers": 817043, "created_utc": 1667455560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to pursue a MS Data Science degree from the UK and will try to find employment there post graduation. As the fees are really high I would have to sell off my assets to fund my education. However, what concerns me is that will I be able to find a job there provided I know my stuff and I will probably get an MS from a top ranked institution? How difficult would that be?\n\n[View Poll](https://www.reddit.com/poll/yksr9u)", "author_fullname": "t2_ywgj6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it advisable to get a MS DS degree keeping in mind the current recession?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yksr9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667451578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to pursue a MS Data Science degree from the UK and will try to find employment there post graduation. As the fees are really high I would have to sell off my assets to fund my education. However, what concerns me is that will I be able to find a job there provided I know my stuff and I will probably get an MS from a top ranked institution? How difficult would that be?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yksr9u\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "yksr9u", "is_robot_indexable": true, "report_reasons": null, "author": "musmas", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1667624378440, "options": [{"text": "Yes", "id": "19566071"}, {"text": "No", "id": "19566072"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 135, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yksr9u/is_it_advisable_to_get_a_ms_ds_degree_keeping_in/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/yksr9u/is_it_advisable_to_get_a_ms_ds_degree_keeping_in/", "subreddit_subscribers": 817043, "created_utc": 1667451578.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}