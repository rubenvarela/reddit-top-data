{"kind": "Listing", "data": {"after": "t3_yx9vf4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.justice.gov/usao-edny/pr/two-russian-nationals-charged-running-massive-e-book-piracy-website", "author_fullname": "t2_7wwsf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The operators of Z-Library arrested in Argentina ti be extradited to the US", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxmtad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 656, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 656, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668680985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.justice.gov/usao-edny/pr/two-russian-nationals-charged-running-massive-e-book-piracy-website\"&gt;https://www.justice.gov/usao-edny/pr/two-russian-nationals-charged-running-massive-e-book-piracy-website&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/w93zRzaRJxd5t8UZ0qmwxNnQ42WUkGACAVu4F6kYt5s.jpg?auto=webp&amp;s=b79b5e4c727a2a33f42a03386f69f7f956238969", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/w93zRzaRJxd5t8UZ0qmwxNnQ42WUkGACAVu4F6kYt5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fc20e1aec4443077677bd4c317ecb1150b621862", "width": 108, "height": 108}], "variants": {}, "id": "Xl1_YVzU4YW2LwbKsSkm5qq8NUF5LNfXk_KIiT4bR6w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxmtad", "is_robot_indexable": true, "report_reasons": null, "author": "espero", "discussion_type": null, "num_comments": 196, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxmtad/the_operators_of_zlibrary_arrested_in_argentina/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxmtad/the_operators_of_zlibrary_arrested_in_argentina/", "subreddit_subscribers": 654391, "created_utc": 1668680985.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks, long time lurker here. I have a bunch of loose external drives that are frequently in use. I have plans to get cats soon and I'm worried they'll be attracted to the noise/heat and knock them all about / on to the ground. Does anybody have any good techniques / strategies / equipment to protect sensitive data from cat attacks?\n\nPS: I already tried \"man cat 1\" in the terminal but didn't find anything useful.", "author_fullname": "t2_3agoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Catproofing strategies for external drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxig2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668665424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, long time lurker here. I have a bunch of loose external drives that are frequently in use. I have plans to get cats soon and I&amp;#39;m worried they&amp;#39;ll be attracted to the noise/heat and knock them all about / on to the ground. Does anybody have any good techniques / strategies / equipment to protect sensitive data from cat attacks?&lt;/p&gt;\n\n&lt;p&gt;PS: I already tried &amp;quot;man cat 1&amp;quot; in the terminal but didn&amp;#39;t find anything useful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxig2y", "is_robot_indexable": true, "report_reasons": null, "author": "nzodd", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxig2y/catproofing_strategies_for_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxig2y/catproofing_strategies_for_external_drives/", "subreddit_subscribers": 654391, "created_utc": 1668665424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_95l1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Picked this up for next to nothing. Could I make a PLEX server out of it?? (details in comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_yx8iqx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z6TkknwAqlhNp4dHIVTm8yhOVgHcvpDMye63Pz1c7oc.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668638068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgur.com/a/Nv9n17H", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?auto=webp&amp;s=072ff5139529f25b4c79236e9a7c5493d24ac00c", "width": 4656, "height": 3496}, "resolutions": [{"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa848b301f6f14cfb9c4bcfa02324ea8a0e71eec", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=02751e28fe4fe7bad49edf4c84d17ced838607bc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e637aecd629dead59300065b106c5857f42bc10c", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=11cb0b6eac62ac959d33b99051026f9f095a6e31", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=27513035f3b744de917cedbe9e7154b162896b4d", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/F9eQ6FjPfeGQ4pcNDoLKkDMq7T7WVyBHz9lEgBjMwLM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=64d9c64a8f93616b8e3b56fcbe91817d5ac7c213", "width": 1080, "height": 810}], "variants": {}, "id": "0jewuXscY0Cd64ldyeodbdkCqeLkmqMkaE5slNVuR2s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6.5TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yx8iqx", "is_robot_indexable": true, "report_reasons": null, "author": "noelgoo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/yx8iqx/picked_this_up_for_next_to_nothing_could_i_make_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgur.com/a/Nv9n17H", "subreddit_subscribers": 654391, "created_utc": 1668638068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5s2jw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RIP unlimited Google workspace for education so sad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_yxuyof", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZJzgS5JeIqSiM-S4S_ZMfo9x_ok42HTD7BQN1dBqruA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668703414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/WIq41oo.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?auto=webp&amp;s=0735b911b2f5092d8e3a6f537ab26c58dfdc480b", "width": 1440, "height": 3120}, "resolutions": [{"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f556e8d409447f35d120f43223d24293101359cd", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7b195ecb97e447e8fb122db7364de94d876fd94a", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b630ff166942e4ba407be4f0d2a3262dbc86c259", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5d9d5f1acf434fafac965e8287ab8c8f05f14959", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea00e99830f8772720df410dbc757afae117f6e7", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/yX6To4rdytjMfe6or_usFNmQ_HIdy3vH0xhkqoRGm-U.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f3d8a3b27fc330b38d13e49555f63d6a1318a08", "width": 1080, "height": 2160}], "variants": {}, "id": "tXJO2nqpeXoWEfbeINadLiA5MRKOwAiwWes_Q_YJ3iM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxuyof", "is_robot_indexable": true, "report_reasons": null, "author": "UACEENGR", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxuyof/rip_unlimited_google_workspace_for_education_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/WIq41oo.jpg", "subreddit_subscribers": 654391, "created_utc": 1668703414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to figure out how I want to backup the data of my daily driver. It's about 1.5 TB worth of documents and family pictures/videos. I don't need to access the data daily. I'd only ever need it if I lost all my data and needed to restore/recover.\n\nI don't need or want to backup everything on my disk. I have specific folders I'd select and then would, ideally, want to exclude certain sub-folders like `.git` or `node_modules`.\n\nI've been researching this for days and ... I just need some outside perspective. Here are my thoughts:\n\n* BackBlaze Personal Backup is $7 a month for unlimited backups. But the backup client backups everything and you have to specify all the excludes. The UI is cumbersome as hell and I'll have to edit an XML file to get it to do what I want (like exclude any `.git` folder). I'd only have to edit the file once, probably, but it's still a PITA. \n* I could use something like Duplicati or Duplicacy with B2 or S3 Glacier. I don't have experience with either so I'm not sure.\n* S3 Glacier seems cheaper but I'm not sure if that's necessarily a good thing over B2.\n\nI'm pretty tech savvy but I want something as simple as possible here. Ideally I'd select the root level folders I want to back up, set some kind of encryption, and then have them auto back up, with versions.\n\nBeing able to remotely access files when I'm not at home is an added bonus but not  a must. If I really needed that I'd just install Nextcloud or something.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with my analysis paralysis: BackBlaze unlimited vs Duplicati or Duplicacy with B2 or S3 Glacier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxfwx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668657651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to figure out how I want to backup the data of my daily driver. It&amp;#39;s about 1.5 TB worth of documents and family pictures/videos. I don&amp;#39;t need to access the data daily. I&amp;#39;d only ever need it if I lost all my data and needed to restore/recover.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t need or want to backup everything on my disk. I have specific folders I&amp;#39;d select and then would, ideally, want to exclude certain sub-folders like &lt;code&gt;.git&lt;/code&gt; or &lt;code&gt;node_modules&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been researching this for days and ... I just need some outside perspective. Here are my thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;BackBlaze Personal Backup is $7 a month for unlimited backups. But the backup client backups everything and you have to specify all the excludes. The UI is cumbersome as hell and I&amp;#39;ll have to edit an XML file to get it to do what I want (like exclude any &lt;code&gt;.git&lt;/code&gt; folder). I&amp;#39;d only have to edit the file once, probably, but it&amp;#39;s still a PITA. &lt;/li&gt;\n&lt;li&gt;I could use something like Duplicati or Duplicacy with B2 or S3 Glacier. I don&amp;#39;t have experience with either so I&amp;#39;m not sure.&lt;/li&gt;\n&lt;li&gt;S3 Glacier seems cheaper but I&amp;#39;m not sure if that&amp;#39;s necessarily a good thing over B2.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m pretty tech savvy but I want something as simple as possible here. Ideally I&amp;#39;d select the root level folders I want to back up, set some kind of encryption, and then have them auto back up, with versions.&lt;/p&gt;\n\n&lt;p&gt;Being able to remotely access files when I&amp;#39;m not at home is an added bonus but not  a must. If I really needed that I&amp;#39;d just install Nextcloud or something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxfwx3", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxfwx3/i_need_help_with_my_analysis_paralysis_backblaze/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxfwx3/i_need_help_with_my_analysis_paralysis_backblaze/", "subreddit_subscribers": 654391, "created_utc": 1668657651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello my gaming pc from 2016  has been very slow the past 2 years i was wondering if my HDD being at 100% in the task manager had anything to do with it so I've been researching and got to crystaldiskinfo. i am looking and it says i have 662 reallocated sectors and 712 current pending sectors i was wondering what any of this means.", "author_fullname": "t2_208j5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "reallocated sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxjjwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668669104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello my gaming pc from 2016  has been very slow the past 2 years i was wondering if my HDD being at 100% in the task manager had anything to do with it so I&amp;#39;ve been researching and got to crystaldiskinfo. i am looking and it says i have 662 reallocated sectors and 712 current pending sectors i was wondering what any of this means.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxjjwf", "is_robot_indexable": true, "report_reasons": null, "author": "IWILLREFORM", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxjjwf/reallocated_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxjjwf/reallocated_sector/", "subreddit_subscribers": 654391, "created_utc": 1668669104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A couple years ago i was really into old games and collected a lot of them from yard sales, ebay, traded them with friends. I knew what i already got for the most part, but i never really made a list/labeled them. In total i guess somewhere around 250 floppys &amp; 4-5000 cds.\n\nSince many of them are nearly 20 years some even older, i am looking for a way to digitalis them.\n\n**The first thing, is there an efficient way/program to convert them to isos?**\n\n**The second thing, are you familiar with any archive/collection management program thats selfhosted and where you could link the said isos?**   \n(Like Collectorz just Selfhosted, Browserbased &amp; OpenSource)\n\nThanks for any ideas", "author_fullname": "t2_8jnr5wv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficient Way to Backup/Archive many Gamedisks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxns42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668684298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A couple years ago i was really into old games and collected a lot of them from yard sales, ebay, traded them with friends. I knew what i already got for the most part, but i never really made a list/labeled them. In total i guess somewhere around 250 floppys &amp;amp; 4-5000 cds.&lt;/p&gt;\n\n&lt;p&gt;Since many of them are nearly 20 years some even older, i am looking for a way to digitalis them.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The first thing, is there an efficient way/program to convert them to isos?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The second thing, are you familiar with any archive/collection management program thats selfhosted and where you could link the said isos?&lt;/strong&gt;&lt;br/&gt;\n(Like Collectorz just Selfhosted, Browserbased &amp;amp; OpenSource)&lt;/p&gt;\n\n&lt;p&gt;Thanks for any ideas&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxns42", "is_robot_indexable": true, "report_reasons": null, "author": "Pommes254", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxns42/efficient_way_to_backuparchive_many_gamedisks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxns42/efficient_way_to_backuparchive_many_gamedisks/", "subreddit_subscribers": 654391, "created_utc": 1668684298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was using Tiny Media, but discovered that it is rentalware.  I don't mind buying a tool, but abhor subscriptions.  Anyone have a good suggestion?\n\nThe hoard is on a Synology serving Nvidia Shields and Kodi.  I was using Tiny to scrape the metadata and had Kodi pulling it locally instead of searching the net (faster and organized/renamed the files).  \n\nI'm open to other ways of doing this that do not involve Plex.", "author_fullname": "t2_2ztygbcz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a Video Metadata Scraper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx5hm0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668631131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was using Tiny Media, but discovered that it is rentalware.  I don&amp;#39;t mind buying a tool, but abhor subscriptions.  Anyone have a good suggestion?&lt;/p&gt;\n\n&lt;p&gt;The hoard is on a Synology serving Nvidia Shields and Kodi.  I was using Tiny to scrape the metadata and had Kodi pulling it locally instead of searching the net (faster and organized/renamed the files).  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m open to other ways of doing this that do not involve Plex.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yx5hm0", "is_robot_indexable": true, "report_reasons": null, "author": "Bushpylot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yx5hm0/looking_for_a_video_metadata_scraper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yx5hm0/looking_for_a_video_metadata_scraper/", "subreddit_subscribers": 654391, "created_utc": 1668631131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "# utzoo-mongo-db-converter\n\nI wrote some scripts for converting the UTZOO Usenet archive to a Mongo Database.\n\n## Background\n\nI recently found out about the [UTZOO Usenet Archive](https://archive.org/details/utzoo-wiseman-usenet-archive), a collection of something like two million [Usenet](https://en.wikipedia.org/wiki/Usenet) posts archived by [Henry Spencer](https://en.wikipedia.org/wiki/Henry_Spencer) from 1981 to 1991. I wanted to play around with the data, so I wrote some Node script to convert the files to a Mongo database. It's a little bit hacky, but it works.\n\n## Getting the data:\n\nThe data was available on the Internet Archive. You could download the data from the [UTZOO Usenet Archive](https://archive.org/details/utzoo-wiseman-usenet-archive) page. After legal demands were placed requesting the internet archive to remove the data, the data was removed and replaced with its checksum. Fortunately, some [friendly folks on Reddit](https://www.reddit.com/r/DataHoarder/comments/i2btuu/utzoo_archives_have_been_removed_from_archiveorg/) have preserved the data. You can download the UTZOO archive from a torrent linked in that post.\n\n## The files\n\nThe UTZOO archive has individual Usenet post saved individual files. This makes searching its contents pretty slow, especially running a search using in Windows. [GREP](https://man7.org/linux/man-pages/man1/grep.1.html) was faster, but still doesn't take advantage of search indexing. Seeking through the contents of files this way is always dead slow. I thought about a few ways of being able to quickly search the data. [Maybe a RAM disk?](https://en.wikipedia.org/wiki/RAM_drive). Faster storage? The drive I'm working from is already pretty fast (Gen 3 NVMe). Maybe I could use a database? I decided try using a database.\n\n## Why Mongo?\n\nI've been playing around with Mongo for a bit. Other implementations of database of the UTZOO archives are [SQL based](https://www.reddit.com/r/java/comments/bkm5h5/how_i_converted_utzoo_usenet_archive_from/) and I thought it might be interesting to try something different, NoSQL. What I would like to test is the ability to quickly search the data. I'm not sure if Mongo is the best choice for this, but I thought UTZOO could be a good test case for [Mongo's search indexing](https://www.mongodb.com/basics/search-index) features.\n\n## Decompressing the data:\n\nRather than decompress the data in Node, I decompressed it using 7zip, so once you retrieve the archive, you'll also need to do so.\n\n## How to run:\n\nYou must have the contents of the UTZOO Usenet archive extracted in a directory named UTZOO, in the same directory as the server and\n\n(If you are using [MongoDB.com](http://mongodb.com/) and) open the serverfolder and:\n\n* Create a file called credentials.js. In it, include:\n\n&amp;#x200B;\n\n    const clusterURL = `your_cluster_url`; \n    const credentials = {username : \"your_username\", password : \"your_password\" }  module.exports = {credentials: credentials, clusterURL: clusterURL }\n\n* Modify server.js:\n\n&amp;#x200B;\n\n    var { credentials, clusterURL } = require('./credentials'); \n    var dbURI = `mongodb+srv://${credentials.username}:${credentials.password}@${clusterURL}`;\n\n* Run \"node server\" to start the server.\n\nOr, if you are using a local database:\n\n* Install [MongoDB](https://www.mongodb.com/) and start a server\n* Open the serverfolder and modify server.js:\n\n&amp;#x200B;\n\n    var {clusterURL } = require('./credentials'); var dbURI = `${clusterURL}`;\n\n* Or, change clusterURLin credentials.jsto the URL of your local database, or replace the string with your database url, ex:\n\n&amp;#x200B;\n\n    var dbURI = \"mongodb://localhost:27017\";\n\nRun \"node server\" to start the server.\n\nImport:\n\nTo start adding data to the database, leave the server running and open the folder named \"importer\" and run \"node listworker.js\"\n\nThis will start inserting the data into the database. It will take a while.\n\n## Problems:\n\nI am still working on parsing the data, so the importer is not complete. I will update this when it is. There is a wide variety of header formats in the UTZOO archive. This includes a variety of different date codes. Later headers include a key to the header's value, early headers lack this. I still need to fix some of the date parsing. There's also a few headers that I haven't accounted for yet. I'm working on it.\n\n## Using the data:\n\nYou can use either [MongoDB.com](http://mongodb.com/)'s dashboard (if you host a remote database) or Mongo Compass to run queries on the data or you can modify the express middleware with your own queries. I'm still working on the API, so it's not very robust yet. I will update this when it is.\n\n## Performance\n\nThis script recursively crawls through the UTZOO directory and adds the files to the Mongo database using fetch calls to the expressbased API. Saving the data to the database took about 12 hours on my machine to a local MongoDB server.\n\nThere's definitely faster ways of doing this  \u00af\\_(\u30c4)\\_/\u00af. Ditching the middleware library (Express) would probably help.\n\n## Code:\n\nThe code is available on [Github](https://github.com/LiamOsler/utzoo-mongo-db-converter).\n\n## Going Forward:\n\nOnce I have the Database built up, I'm going to try and build a small front-end that will allow you to search the contents of the Usenet posts, something along the lines of [www.usenetarchives.com/](https://file+.vscode-resource.vscode-cdn.net/c:/Users/Magenta/Desktop/www.usenetarchives.com) but built with a MERN stack. Feel free to copy and modify the code.", "author_fullname": "t2_74ub1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote some scripts for converting the UTZOO Usenet archive to a Mongo Database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx44mx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668630289.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668628305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;utzoo-mongo-db-converter&lt;/h1&gt;\n\n&lt;p&gt;I wrote some scripts for converting the UTZOO Usenet archive to a Mongo Database.&lt;/p&gt;\n\n&lt;h2&gt;Background&lt;/h2&gt;\n\n&lt;p&gt;I recently found out about the &lt;a href=\"https://archive.org/details/utzoo-wiseman-usenet-archive\"&gt;UTZOO Usenet Archive&lt;/a&gt;, a collection of something like two million &lt;a href=\"https://en.wikipedia.org/wiki/Usenet\"&gt;Usenet&lt;/a&gt; posts archived by &lt;a href=\"https://en.wikipedia.org/wiki/Henry_Spencer\"&gt;Henry Spencer&lt;/a&gt; from 1981 to 1991. I wanted to play around with the data, so I wrote some Node script to convert the files to a Mongo database. It&amp;#39;s a little bit hacky, but it works.&lt;/p&gt;\n\n&lt;h2&gt;Getting the data:&lt;/h2&gt;\n\n&lt;p&gt;The data was available on the Internet Archive. You could download the data from the &lt;a href=\"https://archive.org/details/utzoo-wiseman-usenet-archive\"&gt;UTZOO Usenet Archive&lt;/a&gt; page. After legal demands were placed requesting the internet archive to remove the data, the data was removed and replaced with its checksum. Fortunately, some &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/i2btuu/utzoo_archives_have_been_removed_from_archiveorg/\"&gt;friendly folks on Reddit&lt;/a&gt; have preserved the data. You can download the UTZOO archive from a torrent linked in that post.&lt;/p&gt;\n\n&lt;h2&gt;The files&lt;/h2&gt;\n\n&lt;p&gt;The UTZOO archive has individual Usenet post saved individual files. This makes searching its contents pretty slow, especially running a search using in Windows. &lt;a href=\"https://man7.org/linux/man-pages/man1/grep.1.html\"&gt;GREP&lt;/a&gt; was faster, but still doesn&amp;#39;t take advantage of search indexing. Seeking through the contents of files this way is always dead slow. I thought about a few ways of being able to quickly search the data. &lt;a href=\"https://en.wikipedia.org/wiki/RAM_drive\"&gt;Maybe a RAM disk?&lt;/a&gt;. Faster storage? The drive I&amp;#39;m working from is already pretty fast (Gen 3 NVMe). Maybe I could use a database? I decided try using a database.&lt;/p&gt;\n\n&lt;h2&gt;Why Mongo?&lt;/h2&gt;\n\n&lt;p&gt;I&amp;#39;ve been playing around with Mongo for a bit. Other implementations of database of the UTZOO archives are &lt;a href=\"https://www.reddit.com/r/java/comments/bkm5h5/how_i_converted_utzoo_usenet_archive_from/\"&gt;SQL based&lt;/a&gt; and I thought it might be interesting to try something different, NoSQL. What I would like to test is the ability to quickly search the data. I&amp;#39;m not sure if Mongo is the best choice for this, but I thought UTZOO could be a good test case for &lt;a href=\"https://www.mongodb.com/basics/search-index\"&gt;Mongo&amp;#39;s search indexing&lt;/a&gt; features.&lt;/p&gt;\n\n&lt;h2&gt;Decompressing the data:&lt;/h2&gt;\n\n&lt;p&gt;Rather than decompress the data in Node, I decompressed it using 7zip, so once you retrieve the archive, you&amp;#39;ll also need to do so.&lt;/p&gt;\n\n&lt;h2&gt;How to run:&lt;/h2&gt;\n\n&lt;p&gt;You must have the contents of the UTZOO Usenet archive extracted in a directory named UTZOO, in the same directory as the server and&lt;/p&gt;\n\n&lt;p&gt;(If you are using &lt;a href=\"http://mongodb.com/\"&gt;MongoDB.com&lt;/a&gt; and) open the serverfolder and:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create a file called credentials.js. In it, include:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;const clusterURL = `your_cluster_url`; \nconst credentials = {username : &amp;quot;your_username&amp;quot;, password : &amp;quot;your_password&amp;quot; }  module.exports = {credentials: credentials, clusterURL: clusterURL }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Modify server.js:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;var { credentials, clusterURL } = require(&amp;#39;./credentials&amp;#39;); \nvar dbURI = `mongodb+srv://${credentials.username}:${credentials.password}@${clusterURL}`;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Run &amp;quot;node server&amp;quot; to start the server.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or, if you are using a local database:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Install &lt;a href=\"https://www.mongodb.com/\"&gt;MongoDB&lt;/a&gt; and start a server&lt;/li&gt;\n&lt;li&gt;Open the serverfolder and modify server.js:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;var {clusterURL } = require(&amp;#39;./credentials&amp;#39;); var dbURI = `${clusterURL}`;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Or, change clusterURLin credentials.jsto the URL of your local database, or replace the string with your database url, ex:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;var dbURI = &amp;quot;mongodb://localhost:27017&amp;quot;;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Run &amp;quot;node server&amp;quot; to start the server.&lt;/p&gt;\n\n&lt;p&gt;Import:&lt;/p&gt;\n\n&lt;p&gt;To start adding data to the database, leave the server running and open the folder named &amp;quot;importer&amp;quot; and run &amp;quot;node listworker.js&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;This will start inserting the data into the database. It will take a while.&lt;/p&gt;\n\n&lt;h2&gt;Problems:&lt;/h2&gt;\n\n&lt;p&gt;I am still working on parsing the data, so the importer is not complete. I will update this when it is. There is a wide variety of header formats in the UTZOO archive. This includes a variety of different date codes. Later headers include a key to the header&amp;#39;s value, early headers lack this. I still need to fix some of the date parsing. There&amp;#39;s also a few headers that I haven&amp;#39;t accounted for yet. I&amp;#39;m working on it.&lt;/p&gt;\n\n&lt;h2&gt;Using the data:&lt;/h2&gt;\n\n&lt;p&gt;You can use either &lt;a href=\"http://mongodb.com/\"&gt;MongoDB.com&lt;/a&gt;&amp;#39;s dashboard (if you host a remote database) or Mongo Compass to run queries on the data or you can modify the express middleware with your own queries. I&amp;#39;m still working on the API, so it&amp;#39;s not very robust yet. I will update this when it is.&lt;/p&gt;\n\n&lt;h2&gt;Performance&lt;/h2&gt;\n\n&lt;p&gt;This script recursively crawls through the UTZOO directory and adds the files to the Mongo database using fetch calls to the expressbased API. Saving the data to the database took about 12 hours on my machine to a local MongoDB server.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s definitely faster ways of doing this  \u00af_(\u30c4)_/\u00af. Ditching the middleware library (Express) would probably help.&lt;/p&gt;\n\n&lt;h2&gt;Code:&lt;/h2&gt;\n\n&lt;p&gt;The code is available on &lt;a href=\"https://github.com/LiamOsler/utzoo-mongo-db-converter\"&gt;Github&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2&gt;Going Forward:&lt;/h2&gt;\n\n&lt;p&gt;Once I have the Database built up, I&amp;#39;m going to try and build a small front-end that will allow you to search the contents of the Usenet posts, something along the lines of &lt;a href=\"https://file+.vscode-resource.vscode-cdn.net/c:/Users/Magenta/Desktop/www.usenetarchives.com\"&gt;www.usenetarchives.com/&lt;/a&gt; but built with a MERN stack. Feel free to copy and modify the code.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EjEbcSRhInDbL38pGa6AqM8eZoVgo3z49ki35Fj7_zg.jpg?auto=webp&amp;s=e98b6b090958ed73451630b5d6218dab2dd87f96", "width": 180, "height": 144}, "resolutions": [{"url": "https://external-preview.redd.it/EjEbcSRhInDbL38pGa6AqM8eZoVgo3z49ki35Fj7_zg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91ff2761db12355841a21002593f06f933362fe7", "width": 108, "height": 86}], "variants": {}, "id": "L618DVNfFyrYa22IPEcRYVxjn8GGPvNgDb1EWYQsaNo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yx44mx", "is_robot_indexable": true, "report_reasons": null, "author": "Democedes", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yx44mx/i_wrote_some_scripts_for_converting_the_utzoo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yx44mx/i_wrote_some_scripts_for_converting_the_utzoo/", "subreddit_subscribers": 654391, "created_utc": 1668628305.0, "num_crossposts": 4, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Putting together a small NAS with 6 x 4TB HGST SAS drives, HUS724040ALS640s, and was lucky enough to snag two of them as unused spares for \u00a330 a pop. The next four I've just picked up, and the first couple have come back with roughly 25,000 hours on them.\n\nObviously any reports are going to be anecdotal and not a guarantee, but I'm curious as to if any of you have experience with used enterprise drives and reliability in that region of use.\n\nFrom my own personal experience, it seems that if a drive is destined to die it tends to die relatively quickly, and the ones I've had in the past that made it to 10,000 hours typically lasted another 50k+.\n\nUltimately I spent \u00a330 a pop on each of these, so I'm tempted to just consider it a good deal regardless and put it out of my mind. Am I crazy?", "author_fullname": "t2_7cqcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used Enterprise Drives and Power On Hours", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxsz7h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668698470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Putting together a small NAS with 6 x 4TB HGST SAS drives, HUS724040ALS640s, and was lucky enough to snag two of them as unused spares for \u00a330 a pop. The next four I&amp;#39;ve just picked up, and the first couple have come back with roughly 25,000 hours on them.&lt;/p&gt;\n\n&lt;p&gt;Obviously any reports are going to be anecdotal and not a guarantee, but I&amp;#39;m curious as to if any of you have experience with used enterprise drives and reliability in that region of use.&lt;/p&gt;\n\n&lt;p&gt;From my own personal experience, it seems that if a drive is destined to die it tends to die relatively quickly, and the ones I&amp;#39;ve had in the past that made it to 10,000 hours typically lasted another 50k+.&lt;/p&gt;\n\n&lt;p&gt;Ultimately I spent \u00a330 a pop on each of these, so I&amp;#39;m tempted to just consider it a good deal regardless and put it out of my mind. Am I crazy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxsz7h", "is_robot_indexable": true, "report_reasons": null, "author": "mdcdesign", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxsz7h/used_enterprise_drives_and_power_on_hours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxsz7h/used_enterprise_drives_and_power_on_hours/", "subreddit_subscribers": 654391, "created_utc": 1668698470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there usually good deals for hard drives on these days? I'm finally building my first NAS and want to find good deals obviously.   Is it worth waiting for Black Friday / Cyber Monday deals or are they going to be just crap drives?\n\nThanks!", "author_fullname": "t2_140qwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black Friday/ Cyber Monday deals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yxw0kh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668705932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there usually good deals for hard drives on these days? I&amp;#39;m finally building my first NAS and want to find good deals obviously.   Is it worth waiting for Black Friday / Cyber Monday deals or are they going to be just crap drives?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxw0kh", "is_robot_indexable": true, "report_reasons": null, "author": "Mastasmoker", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxw0kh/black_friday_cyber_monday_deals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxw0kh/black_friday_cyber_monday_deals/", "subreddit_subscribers": 654391, "created_utc": 1668705932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried Onedrive and Google Drive, but neither of them allows me to roll back a whole folder at once. Only a single file at a time. Backblaze costs money per-device, but I have multiple devices so that solution doesn't work for me either. I also don't need more than 1TB.\n\nI'd like it to be as streamlined as possible (so no manual pushing/pulling, and preferably no complicated setups).\n\nCan anyone help?", "author_fullname": "t2_m7d9qp32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a cloud storage that allows me to roll back entire folders at once?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxrgzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668694805.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668694590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried Onedrive and Google Drive, but neither of them allows me to roll back a whole folder at once. Only a single file at a time. Backblaze costs money per-device, but I have multiple devices so that solution doesn&amp;#39;t work for me either. I also don&amp;#39;t need more than 1TB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like it to be as streamlined as possible (so no manual pushing/pulling, and preferably no complicated setups).&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxrgzi", "is_robot_indexable": true, "report_reasons": null, "author": "CutiePatootieLootie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxrgzi/is_there_a_cloud_storage_that_allows_me_to_roll/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxrgzi/is_there_a_cloud_storage_that_allows_me_to_roll/", "subreddit_subscribers": 654391, "created_utc": 1668694590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As I started researching online backup solutions, I realized we all mostly talk about backing up, but **we rarely talking about restoring**. More specifically, we rarely talk about the process of restoring, if it works, how well it works, etc. I read many folks say they couldn't restore cause of a corrupted backup because of the backup tool they used -- *not cool*.\n\nSo, I'm wondering, for folks who have had to restore data **and it was successful**, what tool were you using to do the backup + restore? Comment with your thoughts/experience.\n\n[View Poll](https://www.reddit.com/poll/yxqwnz)", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What back tool did you use to backup **AND RESTORE** and how well did it work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxqwnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668693212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As I started researching online backup solutions, I realized we all mostly talk about backing up, but &lt;strong&gt;we rarely talking about restoring&lt;/strong&gt;. More specifically, we rarely talk about the process of restoring, if it works, how well it works, etc. I read many folks say they couldn&amp;#39;t restore cause of a corrupted backup because of the backup tool they used -- &lt;em&gt;not cool&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m wondering, for folks who have had to restore data &lt;strong&gt;and it was successful&lt;/strong&gt;, what tool were you using to do the backup + restore? Comment with your thoughts/experience.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yxqwnz\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxqwnz", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1669298012653, "options": [{"text": "Backblaze Personal", "id": "19865732"}, {"text": "rclone", "id": "19865733"}, {"text": "Duplicati", "id": "19865734"}, {"text": "Duplicacy", "id": "19865735"}, {"text": "ARQ", "id": "19865736"}, {"text": "Veeam", "id": "19865737"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 29, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxqwnz/what_back_tool_did_you_use_to_backup_and_restore/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/DataHoarder/comments/yxqwnz/what_back_tool_did_you_use_to_backup_and_restore/", "subreddit_subscribers": 654391, "created_utc": 1668693212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Perhaps I\u2019m just lucky and haven\u2019t lost a drive but I feel like between SMART monitoring and using single addressable drives my 24 bay media server using drives on their own is running well.\n\nI\u2019ve been considering some pooled sort of RAID like unraid or omv zfs for many years, and realize it means the loss of one drive for parity, but overall the bigger fear is that something will go wrong that will trash the entire pool of Files versus just one drives worth of content - tv and movie files which could be replaced. Anyone else have similar fears and how did you resolve? I just worry the implosion of say 100tb of a pool would be riskier than losing a regular 14tb drive. My drives are all of various size btw ranging from 5tb to 14tb all gutted from desktop cases so not bleeding edge. Also isn\u2019t raid going to run slower than jbod on my 4u Xeon rackmount?", "author_fullname": "t2_4jntazsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID Risks - Anyone left using only JBOD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxnrss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668684268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Perhaps I\u2019m just lucky and haven\u2019t lost a drive but I feel like between SMART monitoring and using single addressable drives my 24 bay media server using drives on their own is running well.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been considering some pooled sort of RAID like unraid or omv zfs for many years, and realize it means the loss of one drive for parity, but overall the bigger fear is that something will go wrong that will trash the entire pool of Files versus just one drives worth of content - tv and movie files which could be replaced. Anyone else have similar fears and how did you resolve? I just worry the implosion of say 100tb of a pool would be riskier than losing a regular 14tb drive. My drives are all of various size btw ranging from 5tb to 14tb all gutted from desktop cases so not bleeding edge. Also isn\u2019t raid going to run slower than jbod on my 4u Xeon rackmount?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxnrss", "is_robot_indexable": true, "report_reasons": null, "author": "ExcitingDegree", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxnrss/raid_risks_anyone_left_using_only_jbod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxnrss/raid_risks_anyone_left_using_only_jbod/", "subreddit_subscribers": 654391, "created_utc": 1668684268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is the standard recommendation basically Fractal Design Define 7 XL?\n\nI looked at the Hardware Wiki and it looks like it is in bad need for some love and updates since a lot of the links don't even work!\n\nI'd like to know what most people are running/recommending here for \\~12x 3.5\" and probably at least 2x 5.25\" and 2x 2.5\". Hot swap is a nice-to-have, but not required.\n\nNote that I'm not interested in server U cases. I'd rather it take more space vertically than horizontally. Plus in my experience of owning some enterprise gears, they tend to be loud and I'm trying to steer away from that.", "author_fullname": "t2_5xyrdccu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good tower case in 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxk1ew", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668670897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the standard recommendation basically Fractal Design Define 7 XL?&lt;/p&gt;\n\n&lt;p&gt;I looked at the Hardware Wiki and it looks like it is in bad need for some love and updates since a lot of the links don&amp;#39;t even work!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to know what most people are running/recommending here for ~12x 3.5&amp;quot; and probably at least 2x 5.25&amp;quot; and 2x 2.5&amp;quot;. Hot swap is a nice-to-have, but not required.&lt;/p&gt;\n\n&lt;p&gt;Note that I&amp;#39;m not interested in server U cases. I&amp;#39;d rather it take more space vertically than horizontally. Plus in my experience of owning some enterprise gears, they tend to be loud and I&amp;#39;m trying to steer away from that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxk1ew", "is_robot_indexable": true, "report_reasons": null, "author": "whattteva", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxk1ew/good_tower_case_in_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxk1ew/good_tower_case_in_2022/", "subreddit_subscribers": 654391, "created_utc": 1668670897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "title explains most of it. i have ~1k+ songs liked on youtube music and even more videos liked on youtube. i want to download them just in case anything gets taken down or region banned (happened several times)\n\nis there a way to automate this? and i'm worried that if i do this i get flagged for suspicious activity and risk my account getting banned. so how can i minimize the risk of account issues? (e.g. batching them?)\n\nmainly interested in archiving my youtube music likes", "author_fullname": "t2_b0ac2pk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to download my liked music and videos from youtube is there a way to do automate this and not risk getting my account banned?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx3t5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668627616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title explains most of it. i have ~1k+ songs liked on youtube music and even more videos liked on youtube. i want to download them just in case anything gets taken down or region banned (happened several times)&lt;/p&gt;\n\n&lt;p&gt;is there a way to automate this? and i&amp;#39;m worried that if i do this i get flagged for suspicious activity and risk my account getting banned. so how can i minimize the risk of account issues? (e.g. batching them?)&lt;/p&gt;\n\n&lt;p&gt;mainly interested in archiving my youtube music likes&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yx3t5k", "is_robot_indexable": true, "report_reasons": null, "author": "ChaosFairyMagic", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yx3t5k/i_want_to_download_my_liked_music_and_videos_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yx3t5k/i_want_to_download_my_liked_music_and_videos_from/", "subreddit_subscribers": 654391, "created_utc": 1668627616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning to buy either [https://www.amazon.com/Western-Digital-Enterprise-Class-Internal/dp/B0B5W2ZM58/?th=1](https://www.amazon.com/Western-Digital-Enterprise-Class-Internal/dp/B0B5W2ZM58/?th=1) or [https://www.seagate.com/gb/en/products/nas-drives/ironwolf-hard-drive/](https://www.seagate.com/gb/en/products/nas-drives/ironwolf-hard-drive/) to make it into a External HDD. Which enclosure should I use?", "author_fullname": "t2_ipbf10dq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I convert 20/22 tb HDD to external drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yxwb37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668706643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to buy either &lt;a href=\"https://www.amazon.com/Western-Digital-Enterprise-Class-Internal/dp/B0B5W2ZM58/?th=1\"&gt;https://www.amazon.com/Western-Digital-Enterprise-Class-Internal/dp/B0B5W2ZM58/?th=1&lt;/a&gt; or &lt;a href=\"https://www.seagate.com/gb/en/products/nas-drives/ironwolf-hard-drive/\"&gt;https://www.seagate.com/gb/en/products/nas-drives/ironwolf-hard-drive/&lt;/a&gt; to make it into a External HDD. Which enclosure should I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxwb37", "is_robot_indexable": true, "report_reasons": null, "author": "Notalabel_4566", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxwb37/how_do_i_convert_2022_tb_hdd_to_external_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxwb37/how_do_i_convert_2022_tb_hdd_to_external_drive/", "subreddit_subscribers": 654391, "created_utc": 1668706643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was just wondering if anyone has found a way to download reddit discussions to an offline format like pdf or rtf?\n\nI have tried and everything I've tried I end up not getting the full discussion page more junk then actual good posts.\n\nIf anyone has some good advice let me know thx", "author_fullname": "t2_138xee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "downloading reddit threads for offline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yxw59f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668706251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just wondering if anyone has found a way to download reddit discussions to an offline format like pdf or rtf?&lt;/p&gt;\n\n&lt;p&gt;I have tried and everything I&amp;#39;ve tried I end up not getting the full discussion page more junk then actual good posts.&lt;/p&gt;\n\n&lt;p&gt;If anyone has some good advice let me know thx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxw59f", "is_robot_indexable": true, "report_reasons": null, "author": "callie8926", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxw59f/downloading_reddit_threads_for_offline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxw59f/downloading_reddit_threads_for_offline/", "subreddit_subscribers": 654391, "created_utc": 1668706251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've also posted this over on homeserver, but the level of jank I'm striving for fits a lot better here I think. \n\nI'm currently working on building a home file server that could potentially host both Plex and Pi-Hole. I've already got the drives on the way but I have not ordered the rest of the hardware. Right now I am bidding on an auction for an Optiplex 7040 MT, i7-6700 with 8GB RAM. There will be a dedicated SSD for the OS. I know that the specs will be sufficient for any of the individual uses, but will they be enough for all three at once? Also, what would be the best way to install 11 drives? I'm not afraid of jank, so \"creative\" solutions are welcome. My array plans are for 11 2TB drives with 10 TB logical storage for full parity with 1 hot spare. I will also have 4 cold spares. \nHere are the solutions I'm looking for ideas on:\n1. software. Currently thinking about Samba but would be open to any other free options\n\n2. power. Will the 240w dell power supply be enough for 11 spinning platters or do I need another solution?\n\n3. connection. Do I need to use a specific PCIe expansion card to make sure my OS can see all the drives?\n\n4. physical mounting. How the heck can I get 11 drives connected to this thing?\n\nTIA!", "author_fullname": "t2_2vd74d5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for Optiplex Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxuv9c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668703184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve also posted this over on homeserver, but the level of jank I&amp;#39;m striving for fits a lot better here I think. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on building a home file server that could potentially host both Plex and Pi-Hole. I&amp;#39;ve already got the drives on the way but I have not ordered the rest of the hardware. Right now I am bidding on an auction for an Optiplex 7040 MT, i7-6700 with 8GB RAM. There will be a dedicated SSD for the OS. I know that the specs will be sufficient for any of the individual uses, but will they be enough for all three at once? Also, what would be the best way to install 11 drives? I&amp;#39;m not afraid of jank, so &amp;quot;creative&amp;quot; solutions are welcome. My array plans are for 11 2TB drives with 10 TB logical storage for full parity with 1 hot spare. I will also have 4 cold spares. \nHere are the solutions I&amp;#39;m looking for ideas on:\n1. software. Currently thinking about Samba but would be open to any other free options&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;power. Will the 240w dell power supply be enough for 11 spinning platters or do I need another solution?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;connection. Do I need to use a specific PCIe expansion card to make sure my OS can see all the drives?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;physical mounting. How the heck can I get 11 drives connected to this thing?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxuv9c", "is_robot_indexable": true, "report_reasons": null, "author": "OutfoxHyperion", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxuv9c/advice_for_optiplex_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxuv9c/advice_for_optiplex_server/", "subreddit_subscribers": 654391, "created_utc": 1668703184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently got a CRC check error on one of my drives, I follow the 3-2-1 rule, but the corruption was detected late, and the corrupted data seems to of replicated. \n\nI've held off getting a NAS for a long time but I am now thinking of getting something cheap. After some research, would a RAID5 or RAID-Z1 fit my needs? or would you recommend something else? Is there a script / command I should run on a weekly basis to detect disk errors early?\n\nMany thanks for your help in advance!", "author_fullname": "t2_g0xhb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preventing CRC check type errors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxtg1w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668699675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got a CRC check error on one of my drives, I follow the 3-2-1 rule, but the corruption was detected late, and the corrupted data seems to of replicated. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve held off getting a NAS for a long time but I am now thinking of getting something cheap. After some research, would a RAID5 or RAID-Z1 fit my needs? or would you recommend something else? Is there a script / command I should run on a weekly basis to detect disk errors early?&lt;/p&gt;\n\n&lt;p&gt;Many thanks for your help in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxtg1w", "is_robot_indexable": true, "report_reasons": null, "author": "this1seasy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxtg1w/preventing_crc_check_type_errors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxtg1w/preventing_crc_check_type_errors/", "subreddit_subscribers": 654391, "created_utc": 1668699675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wrote a little blog post about my journey of migrating all of my cloud files away from OneDrive! Eventually, I found a managed Nextcloud instance to be working really well for me, but I\u2019ve also compared some other cloud storage providers in the blog post. Maybe it helps some of you, or is at least an interesting read!\n\n[https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/](https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/)\n\nAnd please let me know if I missed anything!", "author_fullname": "t2_snlb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating 1 terabyte of files from OneDrive to Nextcloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxn81k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668682432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a little blog post about my journey of migrating all of my cloud files away from OneDrive! Eventually, I found a managed Nextcloud instance to be working really well for me, but I\u2019ve also compared some other cloud storage providers in the blog post. Maybe it helps some of you, or is at least an interesting read!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/\"&gt;https://herrherrmann.net/migrating-1-terabyte-of-files-from-onedrive-to-nextcloud/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And please let me know if I missed anything!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?auto=webp&amp;s=88a062633dedf9ccf452448d8fc2db2dad601c1f", "width": 1280, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98d55d59103bd7b567864dba6260fd09315eb9ed", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e34219664abdc1aa38d76b56c777f3772f425052", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec4b0f7ab74821b6ac125f46b3118523fbc8000b", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3401a41d681fdfc6b2ef8e92e6678d6312a20951", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d402ce1f8f6ebb81425114a6c8044a702a4ec2d", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/ssxpdJV9WRYM88wr_Db_-DOFs6riFnJxrqjMBr1VAO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d33df6ce715275bb50796c44663dec38ee80c099", "width": 1080, "height": 675}], "variants": {}, "id": "hSLDBk73_NSVA14RgE0rWWy7p2PyXnFjDL3BnIToUjA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxn81k", "is_robot_indexable": true, "report_reasons": null, "author": "herrherrmann", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxn81k/migrating_1_terabyte_of_files_from_onedrive_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxn81k/migrating_1_terabyte_of_files_from_onedrive_to/", "subreddit_subscribers": 654391, "created_utc": 1668682432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1egq3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding the UBI File System in Embedded Devices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_yxm2v5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p2KwVnIXS5RIWyEbUk0K8spJZGi2P-R5tF-a9cMQObE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668678336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "serhack.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://serhack.me/articles/understanding-ubi-file-system-embedded-devices-reolink/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?auto=webp&amp;s=00078a38d692ba8754d89738ee89ea6e4b9e8c19", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49133ab284e90d376be0f0b56abc666023dcfeaa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=365be787bd7e64ffb8060bab75adadd2059c7267", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0192f4547be6c29445b1d2376d14a324d9cf0109", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Na7cLVk3-hR2SoZo2UIPnR0MXEW43mRO_x09p4aHf74.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38415530d6caba0e9880f6a29b456efdf0d969d6", "width": 640, "height": 360}], "variants": {}, "id": "HfVseBBMzCg0VO3uFfUhboKSYGovmAWqQX0RMkMeYVk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "yxm2v5", "is_robot_indexable": true, "report_reasons": null, "author": "serhack", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxm2v5/understanding_the_ubi_file_system_in_embedded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://serhack.me/articles/understanding-ubi-file-system-embedded-devices-reolink/", "subreddit_subscribers": 654391, "created_utc": 1668678336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Forgive me if this is a stupid question, I just do this casually. In your opinion, is Toshiba a trustworthy brand for external hard drives? I got a 2 TB drive earlier this year to store things, the majority videos and VODs that I think were at risk of being deleted, that I wanted to save just in case. ([This](https://a.co/d/9UY9XI4) is the specific product). I just want to make sure that it\u2019ll last me at least a good few years, I\u2019ll look at more long term solutions with time, but I just want to be sure it\u2019ll be okay for a little while. Thank you so much for your help if you can let me know or point me in the right direction &lt;3", "author_fullname": "t2_8dwcyjkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba Brand", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxd68p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668650108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Forgive me if this is a stupid question, I just do this casually. In your opinion, is Toshiba a trustworthy brand for external hard drives? I got a 2 TB drive earlier this year to store things, the majority videos and VODs that I think were at risk of being deleted, that I wanted to save just in case. (&lt;a href=\"https://a.co/d/9UY9XI4\"&gt;This&lt;/a&gt; is the specific product). I just want to make sure that it\u2019ll last me at least a good few years, I\u2019ll look at more long term solutions with time, but I just want to be sure it\u2019ll be okay for a little while. Thank you so much for your help if you can let me know or point me in the right direction &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxd68p", "is_robot_indexable": true, "report_reasons": null, "author": "StrawberryBubbleTea7", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxd68p/toshiba_brand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxd68p/toshiba_brand/", "subreddit_subscribers": 654391, "created_utc": 1668650108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings to the datahoarder community,\n\n  \n\n\nThank you for being one out your has knowledge or experience regarding the failure rates of the aforementioned hard drives. Sadly I don't see any third-party failure statistics from cool people like backblaze, but I really wanna buy a few of these and increase the resolution of my library :-)\n\nThese ones:\n\n[https://www.westerndigital.com/products/outlet/internal-drives/data-center-drives/ultrastar-dc-hc560-hdd#0F38755](https://www.westerndigital.com/products/outlet/internal-drives/data-center-drives/ultrastar-dc-hc560-hdd#0F38755)\n\n  \n\n\n[https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc570-hdd#0F48155](https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc570-hdd#0F48155)\n\n  \n\n\n  \n\n\nI really appreciate any input. These discs will be used very heavily. For me the most important factor is reliability. Premier failed disc has resulted in loss of happiness.\n\n  \n\n\nThe price is also dropped and for the first time, these seem like they can fit into the budget.", "author_fullname": "t2_1mgual0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any thoughts on reliability of Ultrastar DC HC560 / HC570", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxa06s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668641742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings to the datahoarder community,&lt;/p&gt;\n\n&lt;p&gt;Thank you for being one out your has knowledge or experience regarding the failure rates of the aforementioned hard drives. Sadly I don&amp;#39;t see any third-party failure statistics from cool people like backblaze, but I really wanna buy a few of these and increase the resolution of my library :-)&lt;/p&gt;\n\n&lt;p&gt;These ones:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.westerndigital.com/products/outlet/internal-drives/data-center-drives/ultrastar-dc-hc560-hdd#0F38755\"&gt;https://www.westerndigital.com/products/outlet/internal-drives/data-center-drives/ultrastar-dc-hc560-hdd#0F38755&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc570-hdd#0F48155\"&gt;https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc570-hdd#0F48155&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I really appreciate any input. These discs will be used very heavily. For me the most important factor is reliability. Premier failed disc has resulted in loss of happiness.&lt;/p&gt;\n\n&lt;p&gt;The price is also dropped and for the first time, these seem like they can fit into the budget.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?auto=webp&amp;s=8d2e158c0c72f5397b842fe547bacac2d450cfc2", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81cf745324646f70b3ec0a5f3ffc19d1330834fe", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ca8e27280e1b67121880fda68e1772301ae8d99a", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d0e82b4c84f6e9c1dd749fc7f183a65802c386b", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1431f4d533515ff82fd0455bcdea2a72e18c5976", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d4973466e690d44e3fab8b43159da5314b8e1b0", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/LP3csfUmVh2Scl8w8IA5GRCG36fK4aAhMni75IxwgdI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73f21b349418238bdb1bc0219aa01a2c1d6ce07b", "width": 1080, "height": 1080}], "variants": {}, "id": "LDh5lfWRphhbTLF86U9gEL3TXcmdlJmv8cLbkOrwZoI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yxa06s", "is_robot_indexable": true, "report_reasons": null, "author": "skunkytuna", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yxa06s/any_thoughts_on_reliability_of_ultrastar_dc_hc560/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yxa06s/any_thoughts_on_reliability_of_ultrastar_dc_hc560/", "subreddit_subscribers": 654391, "created_utc": 1668641742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all! Hard for me to summarize this, so apologies for block of text. I'll try to bold the more important bits. Thanks in advance.\n\nI have a **12U Gator rack** I won't be using now that I'm selling my DJ equipment, and I want to build a *reasonably* quiet gaming desktop that's rackmounted. It'll fit nicely with the Furman power conditioner and shelf.\n\nIn case it helps, here's my current [PC Part Picker list](https://pcpartpicker.com/list/4CBjC6).\n\nMy problems begin with the **rack's depth** only being **16.5\"**.\n\nThat makes finding a rackmount chassis that fits difficult enough. So far the best one I've found (15\" deep, reasonable price) looks to be here:\n\n[Sliger CX4150a](https://www.sliger.com/products/rackmount/4u/cx4150a/)\n\nI'd love to find some 6U or 8U unit so I could get loads of fans running at low speed to keep it quiet *and* a bunch of 5.25\" bays, but north of 4U appears to be either unicorns, or priced as unicorns. The two other variants of that linked one above (\"i\" and \"e\" suffixes) have one or two 5.25\" bays, but can't fit a deep power supply like that \"a\" variant.\n\nI don't intend to have dozens of drives hooked up daily or anything. **I just want three to four 5.25\" bays available for 1) a Blu-Ray drive, 2) at least one 3.5\" hot-swap bay, and 3) at least one 2.5\" hot-swap bay.**\n\nSo I'm wondering if it's possible to have a separate case mounted directly above or below the linked one, and run the SATA and power cables to it (plus extra fans, I assume) for these drives?\n\nThis subreddit just introduced me to \"JBOD\" (funniest acronym ever?), but even with that hint, most of what I'm finding is still into four figures. I'm literally just looking for a 1-2U piece with a handful of 5.25\" bays that wouldn't be too difficult to link into from the other piece.\n\nAnyone have ideas?", "author_fullname": "t2_tdogbn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rackmount 5.25\" bays? buildapc x datahoarder crossover", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx9vf4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668641408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! Hard for me to summarize this, so apologies for block of text. I&amp;#39;ll try to bold the more important bits. Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;I have a &lt;strong&gt;12U Gator rack&lt;/strong&gt; I won&amp;#39;t be using now that I&amp;#39;m selling my DJ equipment, and I want to build a &lt;em&gt;reasonably&lt;/em&gt; quiet gaming desktop that&amp;#39;s rackmounted. It&amp;#39;ll fit nicely with the Furman power conditioner and shelf.&lt;/p&gt;\n\n&lt;p&gt;In case it helps, here&amp;#39;s my current &lt;a href=\"https://pcpartpicker.com/list/4CBjC6\"&gt;PC Part Picker list&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;My problems begin with the &lt;strong&gt;rack&amp;#39;s depth&lt;/strong&gt; only being &lt;strong&gt;16.5&amp;quot;&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;That makes finding a rackmount chassis that fits difficult enough. So far the best one I&amp;#39;ve found (15&amp;quot; deep, reasonable price) looks to be here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.sliger.com/products/rackmount/4u/cx4150a/\"&gt;Sliger CX4150a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to find some 6U or 8U unit so I could get loads of fans running at low speed to keep it quiet &lt;em&gt;and&lt;/em&gt; a bunch of 5.25&amp;quot; bays, but north of 4U appears to be either unicorns, or priced as unicorns. The two other variants of that linked one above (&amp;quot;i&amp;quot; and &amp;quot;e&amp;quot; suffixes) have one or two 5.25&amp;quot; bays, but can&amp;#39;t fit a deep power supply like that &amp;quot;a&amp;quot; variant.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t intend to have dozens of drives hooked up daily or anything. &lt;strong&gt;I just want three to four 5.25&amp;quot; bays available for 1) a Blu-Ray drive, 2) at least one 3.5&amp;quot; hot-swap bay, and 3) at least one 2.5&amp;quot; hot-swap bay.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m wondering if it&amp;#39;s possible to have a separate case mounted directly above or below the linked one, and run the SATA and power cables to it (plus extra fans, I assume) for these drives?&lt;/p&gt;\n\n&lt;p&gt;This subreddit just introduced me to &amp;quot;JBOD&amp;quot; (funniest acronym ever?), but even with that hint, most of what I&amp;#39;m finding is still into four figures. I&amp;#39;m literally just looking for a 1-2U piece with a handful of 5.25&amp;quot; bays that wouldn&amp;#39;t be too difficult to link into from the other piece.&lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yx9vf4", "is_robot_indexable": true, "report_reasons": null, "author": "Weirderal1337", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yx9vf4/rackmount_525_bays_buildapc_x_datahoarder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yx9vf4/rackmount_525_bays_buildapc_x_datahoarder/", "subreddit_subscribers": 654391, "created_utc": 1668641408.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}