{"kind": "Listing", "data": {"after": "t3_ywx7bz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_anyz9dbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you monitoring your data pipelines and what are you using to debug production issues?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 138, "top_awarded_type": null, "hide_score": false, "name": "t3_yx2qsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 239, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 239, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ulVxDHwoPgs7grvN4OIvTtcDZNo9k1144eMQGmlFs2c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668625393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/f9dmcrn92d0a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?auto=webp&amp;s=2daf4589a1ae35f6708494339d746c84cc96b175", "width": 503, "height": 496}, "resolutions": [{"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95f2e5138517caaabf9f1ca4abd0980785be139b", "width": 108, "height": 106}, {"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83783f49cdf096944a13f92067e7508d9156029e", "width": 216, "height": 212}, {"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6525e84673dfe733708686931d685be35a2dd6b", "width": 320, "height": 315}], "variants": {}, "id": "ZpHlfqAkDfnHSNk-gcsYdmv5sqzzy9iMPkIgicZJAGc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yx2qsb", "is_robot_indexable": true, "report_reasons": null, "author": "tchungry", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx2qsb/how_are_you_monitoring_your_data_pipelines_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/f9dmcrn92d0a1.jpg", "subreddit_subscribers": 80195, "created_utc": 1668625393.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake announces Alerts in private preview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "name": "t3_yxbgcd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/select_dev/status/1593029267700723712", "author_name": "SELECT", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/select_dev", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yxbgcd", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/h-EKhX84KuPV-JEav9G5IkZ2LGidrionX03Q2i1uyfQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668645509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/select_dev/status/1593029267700723712", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p7R-c37C3OglF6slv6i60wsm8BxwO4fIiQaGjDTkwTU.jpg?auto=webp&amp;s=9c66b26fb8147f42fb5fe588afd4724a70861c56", "width": 140, "height": 88}, "resolutions": [{"url": "https://external-preview.redd.it/p7R-c37C3OglF6slv6i60wsm8BxwO4fIiQaGjDTkwTU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d6c48a84e4d3ae0bf7852508419ab98a7e09214", "width": 108, "height": 67}], "variants": {}, "id": "RDb0ZIEZiY5QRmP6koPKGj5NByF3KV1F3PLEhIxT-GQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxbgcd", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxbgcd/snowflake_announces_alerts_in_private_preview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/select_dev/status/1593029267700723712", "subreddit_subscribers": 80195, "created_utc": 1668645509.0, "num_crossposts": 1, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/select_dev/status/1593029267700723712", "author_name": "SELECT", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/select_dev", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Zach wilson on linkedin said that rust is going to have a great future in data engineering, what do you think about that?", "author_fullname": "t2_th46eirx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust in data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxj5fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668667723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Zach wilson on linkedin said that rust is going to have a great future in data engineering, what do you think about that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxj5fz", "is_robot_indexable": true, "report_reasons": null, "author": "PopTheTenYasha", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxj5fz/rust_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxj5fz/rust_in_data_engineering/", "subreddit_subscribers": 80195, "created_utc": 1668667723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently use python operator and have a bunch of processes that would run at same time. We don't want the processes to contend for resources and one high memory process bringing down the entire airflow server. How can this be handled in Airflow? \n\nIs kubernates operator right solution for managing resources effectively? How are things handled in Airflow in your organization? Thanks.", "author_fullname": "t2_jfqnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is your Airflow architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxe8au", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668652943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently use python operator and have a bunch of processes that would run at same time. We don&amp;#39;t want the processes to contend for resources and one high memory process bringing down the entire airflow server. How can this be handled in Airflow? &lt;/p&gt;\n\n&lt;p&gt;Is kubernates operator right solution for managing resources effectively? How are things handled in Airflow in your organization? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxe8au", "is_robot_indexable": true, "report_reasons": null, "author": "curidpostn", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxe8au/what_is_your_airflow_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxe8au/what_is_your_airflow_architecture/", "subreddit_subscribers": 80195, "created_utc": 1668652943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am transferring GA data from big query to snowflake. I am using DBT to flatten each of the JSON columns. I am stuck on custom dimensions. I can parse through each element but how can I loop through them using DBT? Given that they may have n array elements.", "author_fullname": "t2_5d6daxht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone worked on data transfer from GC Bq to snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx7m4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668635989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am transferring GA data from big query to snowflake. I am using DBT to flatten each of the JSON columns. I am stuck on custom dimensions. I can parse through each element but how can I loop through them using DBT? Given that they may have n array elements.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yx7m4s", "is_robot_indexable": true, "report_reasons": null, "author": "sankalpthakur2610", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx7m4s/has_anyone_worked_on_data_transfer_from_gc_bq_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx7m4s/has_anyone_worked_on_data_transfer_from_gc_bq_to/", "subreddit_subscribers": 80195, "created_utc": 1668635989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the case that you are ingesting data from a data source you do not control (3rd party vendor, silo'd team, etc), what do you do when the schema of the data changes? This could be a new column, a type change, enum update, or any other change like this. \n\n[View Poll](https://www.reddit.com/poll/ywxcn7)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle upstream schema changes in your pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywxcn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668614409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the case that you are ingesting data from a data source you do not control (3rd party vendor, silo&amp;#39;d team, etc), what do you do when the schema of the data changes? This could be a new column, a type change, enum update, or any other change like this. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/ywxcn7\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywxcn7", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 20, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1668873609694, "options": [{"text": "Versioned Tables with Different Schemas", "id": "19848159"}, {"text": "Migrate Existing Table Schema", "id": "19848160"}, {"text": "Something Else", "id": "19848161"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 179, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ywxcn7/how_do_you_handle_upstream_schema_changes_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/ywxcn7/how_do_you_handle_upstream_schema_changes_in_your/", "subreddit_subscribers": 80195, "created_utc": 1668614409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If anyone interested in azure Synapse analytics,this tutorial will help you, thanks in advance\n\n https://link.medium.com/sEunVJMy1ub", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synapse analytics Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxkntn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668673218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone interested in azure Synapse analytics,this tutorial will help you, thanks in advance&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://link.medium.com/sEunVJMy1ub\"&gt;https://link.medium.com/sEunVJMy1ub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?auto=webp&amp;s=f11dbc436c657ece1988f8a0696d30532e132605", "width": 1046, "height": 299}, "resolutions": [{"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7959609354bba23f902617c582da5965d3488ec5", "width": 108, "height": 30}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a489b5381f4513bafa288a0d123687509d4c31b", "width": 216, "height": 61}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=138c723f9a18485b0327662c489e61db4c372451", "width": 320, "height": 91}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=29ff8d270da4084f76dd28acf9741b6071f2704a", "width": 640, "height": 182}, {"url": "https://external-preview.redd.it/mwId_ZxwFXvY_WJrYEPl1b9DC_WbXdk_7zImch2WV6M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97732932532733856da7f96d63f541e14cc71e20", "width": 960, "height": 274}], "variants": {}, "id": "dvGCojG4WDv9ttbAGYv6q4tpdoIRh-oYoL_pelyJocU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yxkntn", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxkntn/synapse_analytics_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxkntn/synapse_analytics_tutorial/", "subreddit_subscribers": 80195, "created_utc": 1668673218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m thinking of majoring in data engineering, but I don\u2019t really get what data engineers do. Mainly the work-life balance, and the outlook. Because I don\u2019t want to major in something that\u2019ll just whittle away.", "author_fullname": "t2_6nkzxmrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is data engineering like", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywylfk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668616898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m thinking of majoring in data engineering, but I don\u2019t really get what data engineers do. Mainly the work-life balance, and the outlook. Because I don\u2019t want to major in something that\u2019ll just whittle away.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ywylfk", "is_robot_indexable": true, "report_reasons": null, "author": "davudbro", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywylfk/what_is_data_engineering_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywylfk/what_is_data_engineering_like/", "subreddit_subscribers": 80195, "created_utc": 1668616898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ez8d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MotherDuck scores $47.5m to prove scale-up databases are not quackers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_yxo09b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xDt98sOzCHeuymb3U-ihUEOVA7co6_K0D0fa9Ztn8eI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668685031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theregister.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theregister.com/2022/11/17/475_million_says_scaleup_databases/?utm_medium=share&amp;utm_content=article&amp;utm_source=reddit", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?auto=webp&amp;s=0dfa7d8b0152756a1773dc38b2ce42b98316c558", "width": 648, "height": 429}, "resolutions": [{"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8bafdd5d56d30718219f5dd49d8334eb00a881d0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04d45f0757d64120d60590dc6279ac82a04cfc9c", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=35f359e75f60d3e14dda780dbee0f3473056d3a5", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/KMt0zuiV34OZe0m-dQtNN6jf029X6W3nWej8bLwCUsc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce6a0f7efba4a56836e229bd30394b60e4b8fb32", "width": 640, "height": 423}], "variants": {}, "id": "C4Zahor1I_MVU7Ugl_ADOspvaGrRqoIqcYaEHgflLTM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yxo09b", "is_robot_indexable": true, "report_reasons": null, "author": "Bazencourt", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxo09b/motherduck_scores_475m_to_prove_scaleup_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theregister.com/2022/11/17/475_million_says_scaleup_databases/?utm_medium=share&amp;utm_content=article&amp;utm_source=reddit", "subreddit_subscribers": 80195, "created_utc": 1668685031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have ELT job that has to loop through an API to extract all Invoice line items per invoice. I have made an API call for each invoice at a time  currently, the job can take up 3 hours to run. just needed suggestions and advice in improving the performance. I am thinking of using Spark to parallel processes against the API. If you have recommendations, please let me know.", "author_fullname": "t2_6mggwqyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API pagination performance issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxh4hk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668661245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have ELT job that has to loop through an API to extract all Invoice line items per invoice. I have made an API call for each invoice at a time  currently, the job can take up 3 hours to run. just needed suggestions and advice in improving the performance. I am thinking of using Spark to parallel processes against the API. If you have recommendations, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yxh4hk", "is_robot_indexable": true, "report_reasons": null, "author": "Professional-Goal892", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxh4hk/api_pagination_performance_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxh4hk/api_pagination_performance_issues/", "subreddit_subscribers": 80195, "created_utc": 1668661245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I would like to gather important nuances in copying hdfs files to bigquery Or GCS. \n\nThere are 100 hive tables and it's data from Hdfs locations are needed to be pushed to GCP either BQ or GCS on a daily basis. What are the all points to be noted or challenges while copying via gsutil commands? Please advise.\n\nFlow would be from on prem to GCP only. \n\nNote : I need to perform gpg encryption before copy.", "author_fullname": "t2_4cullil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copy Hdfs files to Big query/GCS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx5d9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668630883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I would like to gather important nuances in copying hdfs files to bigquery Or GCS. &lt;/p&gt;\n\n&lt;p&gt;There are 100 hive tables and it&amp;#39;s data from Hdfs locations are needed to be pushed to GCP either BQ or GCS on a daily basis. What are the all points to be noted or challenges while copying via gsutil commands? Please advise.&lt;/p&gt;\n\n&lt;p&gt;Flow would be from on prem to GCP only. &lt;/p&gt;\n\n&lt;p&gt;Note : I need to perform gpg encryption before copy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yx5d9o", "is_robot_indexable": true, "report_reasons": null, "author": "tmanipra", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx5d9o/copy_hdfs_files_to_big_querygcs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx5d9o/copy_hdfs_files_to_big_querygcs/", "subreddit_subscribers": 80195, "created_utc": 1668630883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently an analytics engineer working on a side project to help break into a data engineering role. I\u2019m dockerizing my pipeline while developing on my local machine, but I was curious to see what best practices are when deploying a pipeline to cloud? In the case with AWS, would you take your dockerized app and install it on an EC2 instance (seems like this would be redundant), or would you manually install all dependencies directly on an EC2 instance and ditch docker altogether in a prod environment?\n\nI\u2019m still figuring everything out so please let me know if I am butchering any common sense logic.", "author_fullname": "t2_bwp6e1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it best practice to use Docker with cloud VMs, or only during development on local machine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywz6fs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668618070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently an analytics engineer working on a side project to help break into a data engineering role. I\u2019m dockerizing my pipeline while developing on my local machine, but I was curious to see what best practices are when deploying a pipeline to cloud? In the case with AWS, would you take your dockerized app and install it on an EC2 instance (seems like this would be redundant), or would you manually install all dependencies directly on an EC2 instance and ditch docker altogether in a prod environment?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m still figuring everything out so please let me know if I am butchering any common sense logic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywz6fs", "is_robot_indexable": true, "report_reasons": null, "author": "wild_bill34", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywz6fs/is_it_best_practice_to_use_docker_with_cloud_vms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywz6fs/is_it_best_practice_to_use_docker_with_cloud_vms/", "subreddit_subscribers": 80195, "created_utc": 1668618070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improve your first Airflow DAG for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_yxqu3h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/PbxI0Jyvlx0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Airflow DAG: Improving your first DAG for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow DAG: Improving your first DAG for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/PbxI0Jyvlx0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Airflow DAG: Improving your first DAG for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/PbxI0Jyvlx0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/PbxI0Jyvlx0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Airflow DAG: Improving your first DAG for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yxqu3h", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Xn3WbAxnw799tDd9ijigLXGMdkE66MXWIr5Fn_WeJes.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668693043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/PbxI0Jyvlx0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yLANk1T7rlyJ7SbNQWzMk5-TgMZUNaK55gIIyxg5_9g.jpg?auto=webp&amp;s=80cc9e1b851516520e19278f3f1ca46d85ee3cb5", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yLANk1T7rlyJ7SbNQWzMk5-TgMZUNaK55gIIyxg5_9g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37e4add9e698dfa4373452351ec8529b3f749208", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yLANk1T7rlyJ7SbNQWzMk5-TgMZUNaK55gIIyxg5_9g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2700b9139284bbda6d9a3ae75e59fca2fefdbc7b", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yLANk1T7rlyJ7SbNQWzMk5-TgMZUNaK55gIIyxg5_9g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6e9f99bb280b7704c11ae4c9598f792d354f0ba6", "width": 320, "height": 240}], "variants": {}, "id": "3dfk3R-YGk3OQRrlA7g6DrrWa8GPsDh_-v1ao8Hj8x0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yxqu3h", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxqu3h/improve_your_first_airflow_dag_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/PbxI0Jyvlx0", "subreddit_subscribers": 80195, "created_utc": 1668693043.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow DAG: Improving your first DAG for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/PbxI0Jyvlx0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Airflow DAG: Improving your first DAG for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/PbxI0Jyvlx0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you guys take care of timestamp columns during daylight savings off for streaming data pipelines ?, We had an issue where because of daylight savings off , timestamp difference between source and target is different as time will fall back. How do you solve this in your team/company ? TIA", "author_fullname": "t2_3ep37bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daylight savings off - Data Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yxq8rl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668691663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you guys take care of timestamp columns during daylight savings off for streaming data pipelines ?, We had an issue where because of daylight savings off , timestamp difference between source and target is different as time will fall back. How do you solve this in your team/company ? TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxq8rl", "is_robot_indexable": true, "report_reasons": null, "author": "chanu4dincha", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxq8rl/daylight_savings_off_data_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxq8rl/daylight_savings_off_data_issue/", "subreddit_subscribers": 80195, "created_utc": 1668691663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team has been put in charge of creating a process to move customers from one product DB to another. \n\nThis is currently done using SSIS packages that are pretty much a black box to anyone wondering what logic they're using to move data.\n\nWe're building out a new workflow, I'd like to take a step back and consider another option.\n\nAs a software engineer I'd really like to be able to write test cases, do version control, all that good stuff while also documenting business logic of DB values and how they relate across products?", "author_fullname": "t2_exqc18fi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool for creating a process to move customers from one product/DB to another", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yxq1tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668691157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team has been put in charge of creating a process to move customers from one product DB to another. &lt;/p&gt;\n\n&lt;p&gt;This is currently done using SSIS packages that are pretty much a black box to anyone wondering what logic they&amp;#39;re using to move data.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re building out a new workflow, I&amp;#39;d like to take a step back and consider another option.&lt;/p&gt;\n\n&lt;p&gt;As a software engineer I&amp;#39;d really like to be able to write test cases, do version control, all that good stuff while also documenting business logic of DB values and how they relate across products?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxq1tz", "is_robot_indexable": true, "report_reasons": null, "author": "No-Swimming-3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxq1tz/best_tool_for_creating_a_process_to_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxq1tz/best_tool_for_creating_a_process_to_move/", "subreddit_subscribers": 80195, "created_utc": 1668691157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_73sd7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using StarRocks DB instead of ClickHouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_yxo6hd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NcOQ8WSDZdQ_DEzTyqaMj2WlVRiwS881k2PBILrhIr8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668685584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/StarRocks/StarRocks", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?auto=webp&amp;s=154e9fa3405ff9149ccffc08b770363fd2302b70", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=56bc3a6e306285fab823bc833ece979a93645d69", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d397ea2b0dd2e2229b1178f4693a615c414b7075", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0159b401ff7e1333a3ad97dd115fe8abc5c3a29e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=543cc6f54952604b6aaa1f5061bbe26397758647", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffa8542f33ba8cc0bcfd97e537ecbd0ea83a1fc4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cIND3gDBPY7foVBGQaDVwtHzSBhHgHf781MjGiBpVpQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5bfd99f2987fbe60113e4099b6ad26eefb9e1e8", "width": 1080, "height": 540}], "variants": {}, "id": "BB_cFx1_beS1zbZZ7YrZr7olAiCnnZknb9WMiVbKkyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yxo6hd", "is_robot_indexable": true, "report_reasons": null, "author": "intellidumb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxo6hd/anyone_using_starrocks_db_instead_of_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/StarRocks/StarRocks", "subreddit_subscribers": 80195, "created_utc": 1668685584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe have an Airflow MWAA cluster and huge volume of Data in our Redshift data warehouse. We currently process the data directly in Redshift (w/ SQL) but given the amount of data, this puts a lot of pressure in the data warehouse and it is less and less resilient.\n\nA potential solution we found would be to decouple the data storage (Redshift) from the data processing (Spark), first of all, what do you think about this solution?\n\nTo do this, we would like to use Airflow MWAA and SparkSQL to:\n\n\\- Transfer data from Redshift to Spark\n\n\\- Process the SQL scripts that were previously done in Redshift\n\n\\- Transfer the newly created table from Spark to Redshift  \n\n\nIs it a use case that someone here has already put in production?\n\n  \nWhat would in your opinion be the best way to interact with the Spark Cluster ? EmrAddStepsOperator vs PythonOperator + PySpark?\n\nThank you!", "author_fullname": "t2_f1ixi4vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to process Redshift data on Spark (EMR) via Airflow MWAA ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxo2e1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668685220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We have an Airflow MWAA cluster and huge volume of Data in our Redshift data warehouse. We currently process the data directly in Redshift (w/ SQL) but given the amount of data, this puts a lot of pressure in the data warehouse and it is less and less resilient.&lt;/p&gt;\n\n&lt;p&gt;A potential solution we found would be to decouple the data storage (Redshift) from the data processing (Spark), first of all, what do you think about this solution?&lt;/p&gt;\n\n&lt;p&gt;To do this, we would like to use Airflow MWAA and SparkSQL to:&lt;/p&gt;\n\n&lt;p&gt;- Transfer data from Redshift to Spark&lt;/p&gt;\n\n&lt;p&gt;- Process the SQL scripts that were previously done in Redshift&lt;/p&gt;\n\n&lt;p&gt;- Transfer the newly created table from Spark to Redshift  &lt;/p&gt;\n\n&lt;p&gt;Is it a use case that someone here has already put in production?&lt;/p&gt;\n\n&lt;p&gt;What would in your opinion be the best way to interact with the Spark Cluster ? EmrAddStepsOperator vs PythonOperator + PySpark?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yxo2e1", "is_robot_indexable": true, "report_reasons": null, "author": "No_Fudge1060", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxo2e1/best_way_to_process_redshift_data_on_spark_emr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxo2e1/best_way_to_process_redshift_data_on_spark_emr/", "subreddit_subscribers": 80195, "created_utc": 1668685220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm not interested in the cert,  just in the Content in the course.\n\n&amp;#x200B;\n\nDoes anyone know which is better?", "author_fullname": "t2_a9icd9le", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM Data Engineering Professional Certificate Or Meta Data Engineer Cert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxnu68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668684490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not interested in the cert,  just in the Content in the course.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone know which is better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxnu68", "is_robot_indexable": true, "report_reasons": null, "author": "Then_Landscape6474", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxnu68/ibm_data_engineering_professional_certificate_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxnu68/ibm_data_engineering_professional_certificate_or/", "subreddit_subscribers": 80195, "created_utc": 1668684490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tomorrow I'm hosting [Ergest Xheblati](https://www.linkedin.com/in/ergestxheblati/) (Data Architect &amp; Author of [*Minimum Viable SQL Patterns*](https://ergestx.gumroad.com/l/sqlpatterns)) for a data modeling workshop - [How to Design a Lasting Business Blueprint](https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;utm_source=reddit&amp;utm_medium=social&amp;utm_content=ergest-workshop-data-modeling)  \n\n\nIt's a workshop. Not a webinar. There's no SaaS tool being sold. It's an honest, educational opportunity hosted by a data architect with 15+ years experience.   \n\n\nIn this workshop, Ergest will teach:  \n\ud83c\udfaf How to conceptually model a fictional SaaS business (Create a conceptual model BEFORE the physical implementation)\n\n\ud83c\udfaf How the modeling approaches above will effect said SaaS business (One Big Table, Start Schema, Activity Schema, Data Vault, etc.)\n\n\ud83c\udfaf Why you might choose one approach or another (and the tradeoffs between them)\n\n\ud83c\udfaf How to move from one approach to the next if circumstances change  \n\n\nIf this interests you, sign up [here](https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;utm_source=reddit&amp;utm_medium=social&amp;utm_content=ergest-workshop-data-modeling).", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Workshop (A workshop, not a webinar w/ subjective hot takes \ud83e\udd23)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx10ab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668621819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tomorrow I&amp;#39;m hosting &lt;a href=\"https://www.linkedin.com/in/ergestxheblati/\"&gt;Ergest Xheblati&lt;/a&gt; (Data Architect &amp;amp; Author of &lt;a href=\"https://ergestx.gumroad.com/l/sqlpatterns\"&gt;&lt;em&gt;Minimum Viable SQL Patterns&lt;/em&gt;&lt;/a&gt;) for a data modeling workshop - &lt;a href=\"https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;amp;utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_content=ergest-workshop-data-modeling\"&gt;How to Design a Lasting Business Blueprint&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a workshop. Not a webinar. There&amp;#39;s no SaaS tool being sold. It&amp;#39;s an honest, educational opportunity hosted by a data architect with 15+ years experience.   &lt;/p&gt;\n\n&lt;p&gt;In this workshop, Ergest will teach:&lt;br/&gt;\n\ud83c\udfaf How to conceptually model a fictional SaaS business (Create a conceptual model BEFORE the physical implementation)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfaf How the modeling approaches above will effect said SaaS business (One Big Table, Start Schema, Activity Schema, Data Vault, etc.)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfaf Why you might choose one approach or another (and the tradeoffs between them)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfaf How to move from one approach to the next if circumstances change  &lt;/p&gt;\n\n&lt;p&gt;If this interests you, sign up &lt;a href=\"https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;amp;utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_content=ergest-workshop-data-modeling\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yx10ab", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx10ab/data_modeling_workshop_a_workshop_not_a_webinar_w/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx10ab/data_modeling_workshop_a_workshop_not_a_webinar_w/", "subreddit_subscribers": 80195, "created_utc": 1668621819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "HI all,\n\n&amp;#x200B;\n\nI'm getting to the point where I'm starting to apply for data engineer roles. I am currently an application engineer that utilizes SQL in order to perform necessary tasks. In terms of SQL, we utilize basic queries such as select, update, delete, joins, cases, creating SQL scripts, etc. in a Microsoft SQL Server. Unfortunately, this does not give me any experience that translates to data engineering other than utilizing SQL.\n\nI also obtained a Bachelor's in Computer Science degree where Python was our main language. \n\nSo far, I've learned about Power Bi, DBT, ETL, etc. through udemy courses or YouTube videos. Obviously, I don't have real-world experience with this yet. \n\nI just wanted to know if there is anything else I can do to make myself a better candidate. Are there any courses that will steer me in the right direction? How much more studying do I need to do? I've seen people go straight into the field out of college and learned these skillsets on the job. \n\nthank you!", "author_fullname": "t2_7gkhxmgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I prepare for job interviews especially those that require to take home challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx086z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668620189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m getting to the point where I&amp;#39;m starting to apply for data engineer roles. I am currently an application engineer that utilizes SQL in order to perform necessary tasks. In terms of SQL, we utilize basic queries such as select, update, delete, joins, cases, creating SQL scripts, etc. in a Microsoft SQL Server. Unfortunately, this does not give me any experience that translates to data engineering other than utilizing SQL.&lt;/p&gt;\n\n&lt;p&gt;I also obtained a Bachelor&amp;#39;s in Computer Science degree where Python was our main language. &lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve learned about Power Bi, DBT, ETL, etc. through udemy courses or YouTube videos. Obviously, I don&amp;#39;t have real-world experience with this yet. &lt;/p&gt;\n\n&lt;p&gt;I just wanted to know if there is anything else I can do to make myself a better candidate. Are there any courses that will steer me in the right direction? How much more studying do I need to do? I&amp;#39;ve seen people go straight into the field out of college and learned these skillsets on the job. &lt;/p&gt;\n\n&lt;p&gt;thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yx086z", "is_robot_indexable": true, "report_reasons": null, "author": "SnooWalruses7164", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx086z/how_can_i_prepare_for_job_interviews_especially/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx086z/how_can_i_prepare_for_job_interviews_especially/", "subreddit_subscribers": 80195, "created_utc": 1668620189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently interviewing for a DE position and was invited to the next stage which is a live coding session with some members in the existing team. From the sounds of it it's going to be very casual, just doing some coding problems in Java and observing my coding practices and cooperation skills and i will be allowed to use the internet or ask question.\n\nI am very new to this with only just under 2 years of experience and currently working for a company without any real supervision - so nobody has ever been there to assess my work and nobody really cared how I did it as soon as it performed the way it has to. And also I had never had experience coding together with someone.\n\nSo my question really is what would be the best way to prepare for it? And what do you think they be assessing/ paying attention to? It all just sounds too easy to be true and I am scared Im gonna make a full of myself.\n\nThank you so much in advance!", "author_fullname": "t2_588bawm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach a live coding session during an interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywz8x6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668618209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently interviewing for a DE position and was invited to the next stage which is a live coding session with some members in the existing team. From the sounds of it it&amp;#39;s going to be very casual, just doing some coding problems in Java and observing my coding practices and cooperation skills and i will be allowed to use the internet or ask question.&lt;/p&gt;\n\n&lt;p&gt;I am very new to this with only just under 2 years of experience and currently working for a company without any real supervision - so nobody has ever been there to assess my work and nobody really cared how I did it as soon as it performed the way it has to. And also I had never had experience coding together with someone.&lt;/p&gt;\n\n&lt;p&gt;So my question really is what would be the best way to prepare for it? And what do you think they be assessing/ paying attention to? It all just sounds too easy to be true and I am scared Im gonna make a full of myself.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ywz8x6", "is_robot_indexable": true, "report_reasons": null, "author": "nastya_stark", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywz8x6/how_to_approach_a_live_coding_session_during_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywz8x6/how_to_approach_a_live_coding_session_during_an/", "subreddit_subscribers": 80195, "created_utc": 1668618209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8](https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Introduction to Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywxzq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668615674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8\"&gt;https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?auto=webp&amp;s=5df084b961ca67ef4b875bdafe05ee0dc02a529a", "width": 1200, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2932d9ca5538cf9e7987ea5defc90d8db21d9d4", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3108462afb44d08064dc1c7716950f90afa8d552", "width": 216, "height": 184}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=033b10566bc1c68678dda368a4e9693f89672e67", "width": 320, "height": 273}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6677cbcdfbd6611efac4705cf67d0877a7b19cb1", "width": 640, "height": 546}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ba9cba3302d93d040da6cae3f4fe55b64ab54a5", "width": 960, "height": 819}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8284f1945c08155cd1e9b6b260685063ec0f901a", "width": 1080, "height": 921}], "variants": {}, "id": "eaYixETYqrtg_QSgOGZ9uK-0oKhDzDSheNCmQpS0PRk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ywxzq6", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywxzq6/an_introduction_to_data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywxzq6/an_introduction_to_data_mesh/", "subreddit_subscribers": 80195, "created_utc": 1668615674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. My company after two years of pandemic want to switch back to hybrid work (1-2 days in a week in office). \nFor my all team this change do not make sense. Tomorrow we have a call with boss of my boss. \n\nDo you have any ideas of how to argument that we want to work remotely?\n\nDid any of you have similar situation?", "author_fullname": "t2_50lq8gs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching from remote to hybrid", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yxm64i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668678681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. My company after two years of pandemic want to switch back to hybrid work (1-2 days in a week in office). \nFor my all team this change do not make sense. Tomorrow we have a call with boss of my boss. &lt;/p&gt;\n\n&lt;p&gt;Do you have any ideas of how to argument that we want to work remotely?&lt;/p&gt;\n\n&lt;p&gt;Did any of you have similar situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxm64i", "is_robot_indexable": true, "report_reasons": null, "author": "truverol", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxm64i/switching_from_remote_to_hybrid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxm64i/switching_from_remote_to_hybrid/", "subreddit_subscribers": 80195, "created_utc": 1668678681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nCurrently I have 2+ yoe, a master\u2019s degree in engineering ( non-CS) and have been working in a F500 modern data stack company for 2 years. I started as a data analyst ( Covid lack of options), and have been a data engineer ( promoted from junior to mid level recently).  I currently make 93k. \n\nI was searching for new jobs and I have been interviewing pretty well with leetcode for sql/ python. I received one offer for 121k which was immediately revoked because the team decided \u201cto go in a different direction\u201d this week. I received a second offer for a tax preparation small firm for 132k, but I found our they are being  acquired by a Private Equity firm. The offer is great and I would learn a lot, but I feel conflicted as the PE firm was fined multiple times for medication theft/fraud by the NHS. I think I will reject the offer and wait for a less ethical fraught \noffer? Thoughts", "author_fullname": "t2_tsrtqcem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ethical Concerns with Offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx1r12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668623344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Currently I have 2+ yoe, a master\u2019s degree in engineering ( non-CS) and have been working in a F500 modern data stack company for 2 years. I started as a data analyst ( Covid lack of options), and have been a data engineer ( promoted from junior to mid level recently).  I currently make 93k. &lt;/p&gt;\n\n&lt;p&gt;I was searching for new jobs and I have been interviewing pretty well with leetcode for sql/ python. I received one offer for 121k which was immediately revoked because the team decided \u201cto go in a different direction\u201d this week. I received a second offer for a tax preparation small firm for 132k, but I found our they are being  acquired by a Private Equity firm. The offer is great and I would learn a lot, but I feel conflicted as the PE firm was fined multiple times for medication theft/fraud by the NHS. I think I will reject the offer and wait for a less ethical fraught \noffer? Thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yx1r12", "is_robot_indexable": true, "report_reasons": null, "author": "CookingGoBlue", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx1r12/ethical_concerns_with_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx1r12/ethical_concerns_with_offer/", "subreddit_subscribers": 80195, "created_utc": 1668623344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For on ongoing blog series about AWS cloud computing, a new post just got published! This time you will learn about the Simple Storage Service S3. It's an object store and one of the most essential services of AWS. \n\n[https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373](https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373)", "author_fullname": "t2_3di0zmcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Simple Storage Service - S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywx7bz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668614108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For on ongoing blog series about AWS cloud computing, a new post just got published! This time you will learn about the Simple Storage Service S3. It&amp;#39;s an object store and one of the most essential services of AWS. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373\"&gt;https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?auto=webp&amp;s=76157e72d5fa325f969674de8d937b707e82a9c9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a81d0bbd7684d987ee985f2fd56ba142393be51c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e98e7a07131f09ec2fa4d2ea5ab203c33b013c5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c57778b500a5ce0ced8df1fd086cc428aae77747", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c21c14ab1c3ca06899bf28e0b3fd293d8dd689ab", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a8b34c649db8a185db2eb0ca6c02a272deed349", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1eb2653c7e920f3261387f50c014eb834b27d4fb", "width": 1080, "height": 1080}], "variants": {}, "id": "14PTcHLZhsWzPYIRL1KFxfSWbZxysOVvupddjIWQQfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ywx7bz", "is_robot_indexable": true, "report_reasons": null, "author": "EdgarHuber", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywx7bz/aws_simple_storage_service_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywx7bz/aws_simple_storage_service_s3/", "subreddit_subscribers": 80195, "created_utc": 1668614108.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}