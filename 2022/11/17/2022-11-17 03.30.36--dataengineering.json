{"kind": "Listing", "data": {"after": "t3_ywx7bz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_anyz9dbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you monitoring your data pipelines and what are you using to debug production issues?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 138, "top_awarded_type": null, "hide_score": false, "name": "t3_yx2qsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 123, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 123, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ulVxDHwoPgs7grvN4OIvTtcDZNo9k1144eMQGmlFs2c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668625393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/f9dmcrn92d0a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?auto=webp&amp;s=2daf4589a1ae35f6708494339d746c84cc96b175", "width": 503, "height": 496}, "resolutions": [{"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95f2e5138517caaabf9f1ca4abd0980785be139b", "width": 108, "height": 106}, {"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83783f49cdf096944a13f92067e7508d9156029e", "width": 216, "height": 212}, {"url": "https://preview.redd.it/f9dmcrn92d0a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6525e84673dfe733708686931d685be35a2dd6b", "width": 320, "height": 315}], "variants": {}, "id": "ZpHlfqAkDfnHSNk-gcsYdmv5sqzzy9iMPkIgicZJAGc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "yx2qsb", "is_robot_indexable": true, "report_reasons": null, "author": "tchungry", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx2qsb/how_are_you_monitoring_your_data_pipelines_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/f9dmcrn92d0a1.jpg", "subreddit_subscribers": 80138, "created_utc": 1668625393.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious on what you guys' use cases for using Go in the data engineering world", "author_fullname": "t2_230kdua8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Go as a data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yws9hu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668602330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious on what you guys&amp;#39; use cases for using Go in the data engineering world&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yws9hu", "is_robot_indexable": true, "report_reasons": null, "author": "enginerd298", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yws9hu/using_go_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yws9hu/using_go_as_a_data_engineer/", "subreddit_subscribers": 80138, "created_utc": 1668602330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would love to here from the community how you guys are designing your databricks DLT pipelines, as its pretty new and there isn\u2019t a whole lot of community documentation on it.\n\nFor us, our workspace consists of 3 DLT pipelines: dev , staging, and prod. Changes are tested on dev and then deployed to staging(runs once a day) and prod (continuous), where we can toggle between the two for a blue/green type deployment (data needs to always be accessible)\n\nData is read through SQS/SNS first to a raw table (entire table is read in a single json column with CDC), it is then written to a table with a defined schema (this is all in DLT pipeline)\n\nFrom here we define views to different catalogs and databases of varying degrees of sensitive/pii data (red, yellow, green). All databricks infrastructure, permissions, and users are managed with pulumi (like terraform).\n\nWould love to hear what others are doing to see how we could improve!", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your Databricks/DLT architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywi2en", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668568330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to here from the community how you guys are designing your databricks DLT pipelines, as its pretty new and there isn\u2019t a whole lot of community documentation on it.&lt;/p&gt;\n\n&lt;p&gt;For us, our workspace consists of 3 DLT pipelines: dev , staging, and prod. Changes are tested on dev and then deployed to staging(runs once a day) and prod (continuous), where we can toggle between the two for a blue/green type deployment (data needs to always be accessible)&lt;/p&gt;\n\n&lt;p&gt;Data is read through SQS/SNS first to a raw table (entire table is read in a single json column with CDC), it is then written to a table with a defined schema (this is all in DLT pipeline)&lt;/p&gt;\n\n&lt;p&gt;From here we define views to different catalogs and databases of varying degrees of sensitive/pii data (red, yellow, green). All databricks infrastructure, permissions, and users are managed with pulumi (like terraform).&lt;/p&gt;\n\n&lt;p&gt;Would love to hear what others are doing to see how we could improve!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywi2en", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywi2en/what_is_your_databricksdlt_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywi2en/what_is_your_databricksdlt_architecture/", "subreddit_subscribers": 80138, "created_utc": 1668568330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have multiple pipelines I\u2019ve developed, in different languages / frameworks. I have one on-prem Windows 10 vm to deploy these. I can do whatever I want on this VM, but they have to run on it (can\u2019t use any cloud tools / etc).\n\nRight now, I plan on moving the repos to the vm and using windows task scheduler to schedule them to run on whatever cadence I need.\n\nIs this sufficient? Is there anything else I should be doing up front that is better practice / will be more robust?\n\nI am a Data Scientist, have never truly productionized things before at this scale, and there isn\u2019t a Data Engineering function nor IT resources in my org to help me. \n\nThanks", "author_fullname": "t2_lfd04s6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deploy my pipelines\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yworr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668590117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have multiple pipelines I\u2019ve developed, in different languages / frameworks. I have one on-prem Windows 10 vm to deploy these. I can do whatever I want on this VM, but they have to run on it (can\u2019t use any cloud tools / etc).&lt;/p&gt;\n\n&lt;p&gt;Right now, I plan on moving the repos to the vm and using windows task scheduler to schedule them to run on whatever cadence I need.&lt;/p&gt;\n\n&lt;p&gt;Is this sufficient? Is there anything else I should be doing up front that is better practice / will be more robust?&lt;/p&gt;\n\n&lt;p&gt;I am a Data Scientist, have never truly productionized things before at this scale, and there isn\u2019t a Data Engineering function nor IT resources in my org to help me. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yworr4", "is_robot_indexable": true, "report_reasons": null, "author": "No_Caterpillar_7258", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yworr4/how_to_deploy_my_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yworr4/how_to_deploy_my_pipelines/", "subreddit_subscribers": 80138, "created_utc": 1668590117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake announces Alerts in private preview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "name": "t3_yxbgcd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/select_dev/status/1593029267700723712", "author_name": "SELECT", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/select_dev", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/yxbgcd", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/h-EKhX84KuPV-JEav9G5IkZ2LGidrionX03Q2i1uyfQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668645509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/select_dev/status/1593029267700723712", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p7R-c37C3OglF6slv6i60wsm8BxwO4fIiQaGjDTkwTU.jpg?auto=webp&amp;s=9c66b26fb8147f42fb5fe588afd4724a70861c56", "width": 140, "height": 88}, "resolutions": [{"url": "https://external-preview.redd.it/p7R-c37C3OglF6slv6i60wsm8BxwO4fIiQaGjDTkwTU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d6c48a84e4d3ae0bf7852508419ab98a7e09214", "width": 108, "height": 67}], "variants": {}, "id": "RDb0ZIEZiY5QRmP6koPKGj5NByF3KV1F3PLEhIxT-GQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxbgcd", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxbgcd/snowflake_announces_alerts_in_private_preview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/select_dev/status/1593029267700723712", "subreddit_subscribers": 80138, "created_utc": 1668645509.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/select_dev/status/1593029267700723712", "author_name": "SELECT", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Now in private preview on &lt;a href=\"https://twitter.com/SnowflakeDB?ref_src=twsrc%5Etfw\"&gt;@SnowflakeDB&lt;/a&gt;, you can set up an alert that periodically performs an action under specific conditions, based on data within Snowflake. &lt;a href=\"https://t.co/R2wBkvZK7N\"&gt;pic.twitter.com/R2wBkvZK7N&lt;/a&gt;&lt;/p&gt;&amp;mdash; SELECT (@select_dev) &lt;a href=\"https://twitter.com/select_dev/status/1593029267700723712?ref_src=twsrc%5Etfw\"&gt;November 16, 2022&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/select_dev", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a little out of the loop on cloud products and offerings. I was pretty knowledgeable on AWS about 4-5 years ago but haven't needed to use cloud services since then, and have not really kept up with new offerings.\n\nIf I have a locally developed Python script that I want to automate, to just run on a daily basis, how would you all suggest doing so? I have a GCP account available to use products there, a Github repo, and potentially access to AWS and Azure. I've heard good things about Github actions - is that somewhat easy to setup? I don't need to or want to develop a fancy pipeline with orchestration, just a quick and easy script to run", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the easiest way to automate scripts these days?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywtqir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668606276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a little out of the loop on cloud products and offerings. I was pretty knowledgeable on AWS about 4-5 years ago but haven&amp;#39;t needed to use cloud services since then, and have not really kept up with new offerings.&lt;/p&gt;\n\n&lt;p&gt;If I have a locally developed Python script that I want to automate, to just run on a daily basis, how would you all suggest doing so? I have a GCP account available to use products there, a Github repo, and potentially access to AWS and Azure. I&amp;#39;ve heard good things about Github actions - is that somewhat easy to setup? I don&amp;#39;t need to or want to develop a fancy pipeline with orchestration, just a quick and easy script to run&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ywtqir", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywtqir/whats_the_easiest_way_to_automate_scripts_these/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywtqir/whats_the_easiest_way_to_automate_scripts_these/", "subreddit_subscribers": 80138, "created_utc": 1668606276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m thinking of majoring in data engineering, but I don\u2019t really get what data engineers do. Mainly the work-life balance, and the outlook. Because I don\u2019t want to major in something that\u2019ll just whittle away.", "author_fullname": "t2_6nkzxmrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is data engineering like", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywylfk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668616898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m thinking of majoring in data engineering, but I don\u2019t really get what data engineers do. Mainly the work-life balance, and the outlook. Because I don\u2019t want to major in something that\u2019ll just whittle away.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ywylfk", "is_robot_indexable": true, "report_reasons": null, "author": "davudbro", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywylfk/what_is_data_engineering_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywylfk/what_is_data_engineering_like/", "subreddit_subscribers": 80138, "created_utc": 1668616898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am transferring GA data from big query to snowflake. I am using DBT to flatten each of the JSON columns. I am stuck on custom dimensions. I can parse through each element but how can I loop through them using DBT? Given that they may have n array elements.", "author_fullname": "t2_5d6daxht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone worked on data transfer from GC Bq to snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx7m4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668635989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am transferring GA data from big query to snowflake. I am using DBT to flatten each of the JSON columns. I am stuck on custom dimensions. I can parse through each element but how can I loop through them using DBT? Given that they may have n array elements.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yx7m4s", "is_robot_indexable": true, "report_reasons": null, "author": "sankalpthakur2610", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx7m4s/has_anyone_worked_on_data_transfer_from_gc_bq_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx7m4s/has_anyone_worked_on_data_transfer_from_gc_bq_to/", "subreddit_subscribers": 80138, "created_utc": 1668635989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the case that you are ingesting data from a data source you do not control (3rd party vendor, silo'd team, etc), what do you do when the schema of the data changes? This could be a new column, a type change, enum update, or any other change like this. \n\n[View Poll](https://www.reddit.com/poll/ywxcn7)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle upstream schema changes in your pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywxcn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668614409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the case that you are ingesting data from a data source you do not control (3rd party vendor, silo&amp;#39;d team, etc), what do you do when the schema of the data changes? This could be a new column, a type change, enum update, or any other change like this. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/ywxcn7\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywxcn7", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1668873609694, "options": [{"text": "Versioned Tables with Different Schemas", "id": "19848159"}, {"text": "Migrate Existing Table Schema", "id": "19848160"}, {"text": "Something Else", "id": "19848161"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 131, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/ywxcn7/how_do_you_handle_upstream_schema_changes_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/ywxcn7/how_do_you_handle_upstream_schema_changes_in_your/", "subreddit_subscribers": 80138, "created_utc": 1668614409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a junior swe in a small team focused on taking care of our data. Part of our jobs require building pipelines and creating reports but for the most of it we're working on code to maintain the data services. The tickets I've been getting so far are require testing changes to the services setup, and sounds simple when explained by the team's senior dev during our sprint planning session - \"just point it to a different URL\" or \"just change the version of the docker image pulled\". As a result the tasks points estimations are low, but no one wants to take it up so I volunteer because I want the exposure to different problems. \n\nThen comes the issue where most of these services are setup in a secure way. Every change I make a change and deploy, it throws an SSL related error and the entire service is down in the dev environment. Even my senior dev is astounded and turns to the DevOps team that is in charge of generating and maintaining those certs. I feel pretty useless because it's like someone from another team is doing the work at this point. I'm trying to learn on my own by emulating the setup in my home lab and figuring out how all the pieces work together but one service involves so many DevOps tools that I have no experience with and it's a nightmare and can't be covered in one weekend. If anyone has been through this situation and has any advice, I'm all ears.", "author_fullname": "t2_s5w2bngt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Junior SWE] Some of my tasks fall into DevOps territory and I'm stuck", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywjy3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668573686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a junior swe in a small team focused on taking care of our data. Part of our jobs require building pipelines and creating reports but for the most of it we&amp;#39;re working on code to maintain the data services. The tickets I&amp;#39;ve been getting so far are require testing changes to the services setup, and sounds simple when explained by the team&amp;#39;s senior dev during our sprint planning session - &amp;quot;just point it to a different URL&amp;quot; or &amp;quot;just change the version of the docker image pulled&amp;quot;. As a result the tasks points estimations are low, but no one wants to take it up so I volunteer because I want the exposure to different problems. &lt;/p&gt;\n\n&lt;p&gt;Then comes the issue where most of these services are setup in a secure way. Every change I make a change and deploy, it throws an SSL related error and the entire service is down in the dev environment. Even my senior dev is astounded and turns to the DevOps team that is in charge of generating and maintaining those certs. I feel pretty useless because it&amp;#39;s like someone from another team is doing the work at this point. I&amp;#39;m trying to learn on my own by emulating the setup in my home lab and figuring out how all the pieces work together but one service involves so many DevOps tools that I have no experience with and it&amp;#39;s a nightmare and can&amp;#39;t be covered in one weekend. If anyone has been through this situation and has any advice, I&amp;#39;m all ears.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ywjy3m", "is_robot_indexable": true, "report_reasons": null, "author": "Global_Service_1094", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywjy3m/junior_swe_some_of_my_tasks_fall_into_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywjy3m/junior_swe_some_of_my_tasks_fall_into_devops/", "subreddit_subscribers": 80138, "created_utc": 1668573686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious if there are other folks who exclusively work on prem. What does your stack look like?\n\nThis is what we have so far.\n\nBunch of DB replica -&gt; Python -&gt; SQL Server as a Data warehouse.\n\nWe are currently working with a 3rd party vendor moving to a Cloudera stack, which is  too expensive, no CDC support and I don\u2019t think is worth it.\n\nWhat is the right way to scale? I used to use spark from a previous job (using the then opensource ambari) if that\u2019s worth anything.", "author_fullname": "t2_b59xmddf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On premise stack for a mid size company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywtsd3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668606382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if there are other folks who exclusively work on prem. What does your stack look like?&lt;/p&gt;\n\n&lt;p&gt;This is what we have so far.&lt;/p&gt;\n\n&lt;p&gt;Bunch of DB replica -&amp;gt; Python -&amp;gt; SQL Server as a Data warehouse.&lt;/p&gt;\n\n&lt;p&gt;We are currently working with a 3rd party vendor moving to a Cloudera stack, which is  too expensive, no CDC support and I don\u2019t think is worth it.&lt;/p&gt;\n\n&lt;p&gt;What is the right way to scale? I used to use spark from a previous job (using the then opensource ambari) if that\u2019s worth anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywtsd3", "is_robot_indexable": true, "report_reasons": null, "author": "Turbulent-Bell9500", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywtsd3/on_premise_stack_for_a_mid_size_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywtsd3/on_premise_stack_for_a_mid_size_company/", "subreddit_subscribers": 80138, "created_utc": 1668606382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I would like to gather important nuances in copying hdfs files to bigquery Or GCS. \n\nThere are 100 hive tables and it's data from Hdfs locations are needed to be pushed to GCP either BQ or GCS on a daily basis. What are the all points to be noted or challenges while copying via gsutil commands? Please advise.\n\nFlow would be from on prem to GCP only. \n\nNote : I need to perform gpg encryption before copy.", "author_fullname": "t2_4cullil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copy Hdfs files to Big query/GCS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx5d9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668630883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I would like to gather important nuances in copying hdfs files to bigquery Or GCS. &lt;/p&gt;\n\n&lt;p&gt;There are 100 hive tables and it&amp;#39;s data from Hdfs locations are needed to be pushed to GCP either BQ or GCS on a daily basis. What are the all points to be noted or challenges while copying via gsutil commands? Please advise.&lt;/p&gt;\n\n&lt;p&gt;Flow would be from on prem to GCP only. &lt;/p&gt;\n\n&lt;p&gt;Note : I need to perform gpg encryption before copy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yx5d9o", "is_robot_indexable": true, "report_reasons": null, "author": "tmanipra", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx5d9o/copy_hdfs_files_to_big_querygcs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx5d9o/copy_hdfs_files_to_big_querygcs/", "subreddit_subscribers": 80138, "created_utc": 1668630883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am new to Airflow, and I am wanting to write a simple DAG to insert data into a table, but not using BigQuery.\n\nIs there an example on how to do this using Python operators?", "author_fullname": "t2_13ussz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Example on how to write a simple DAG to insert data into table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywu1mm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668606967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am new to Airflow, and I am wanting to write a simple DAG to insert data into a table, but not using BigQuery.&lt;/p&gt;\n\n&lt;p&gt;Is there an example on how to do this using Python operators?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ywu1mm", "is_robot_indexable": true, "report_reasons": null, "author": "saucyhambon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywu1mm/example_on_how_to_write_a_simple_dag_to_insert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywu1mm/example_on_how_to_write_a_simple_dag_to_insert/", "subreddit_subscribers": 80138, "created_utc": 1668606967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm new at creating data pipeline. My techstack is kafka + ksqlDB (ETL) -&gt; ClickHouse (DW). \\\\  \nBoth ksqlDB and ClickHouse provide Materialized View so I cannot decide which is better: \\\\\n\n\\- ksqlDB: Maybe when reboot, replaying changelog to get newest data take times ? [Animated blog](https://www.confluent.io/blog/how-real-time-materialized-views-work-with-ksqldb/#replaying-from-changelogs) . It need populates data to ClickHouse DW too.\n\n\\- ClickHouse: Hmmm I dont know. Seem compaction better. [ClickHouse doc](https://clickhouse.com/docs/en/sql-reference/statements/create/view#materialized-view)  \n\n\nI appreciate any comments. Tks.", "author_fullname": "t2_3hg7xsy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to place Materialized View?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywnnb1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668585912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new at creating data pipeline. My techstack is kafka + ksqlDB (ETL) -&amp;gt; ClickHouse (DW). \\&lt;br/&gt;\nBoth ksqlDB and ClickHouse provide Materialized View so I cannot decide which is better: \\&lt;/p&gt;\n\n&lt;p&gt;- ksqlDB: Maybe when reboot, replaying changelog to get newest data take times ? &lt;a href=\"https://www.confluent.io/blog/how-real-time-materialized-views-work-with-ksqldb/#replaying-from-changelogs\"&gt;Animated blog&lt;/a&gt; . It need populates data to ClickHouse DW too.&lt;/p&gt;\n\n&lt;p&gt;- ClickHouse: Hmmm I dont know. Seem compaction better. &lt;a href=\"https://clickhouse.com/docs/en/sql-reference/statements/create/view#materialized-view\"&gt;ClickHouse doc&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I appreciate any comments. Tks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?auto=webp&amp;s=b3d69b2b1fe2e737d3cd99f3c114278d4c50a82e", "width": 748, "height": 748}, "resolutions": [{"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57d65fa68561d4f6f912018b5ae267ab3c0f9e0f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8086b50841c4d24f99750485eb329e3f56d35bff", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cbff01b67c1d4013ec32d347a00d51b1b2a85038", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7dbd0345f9d81ac9c34b1f2983c6b68c40eed63", "width": 640, "height": 640}], "variants": {}, "id": "UkEnmWaASEGNKtlwlJXUEo3JbKitP8i5PMlm8kh0bPE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ywnnb1", "is_robot_indexable": true, "report_reasons": null, "author": "0123hoang", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywnnb1/where_to_place_materialized_view/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywnnb1/where_to_place_materialized_view/", "subreddit_subscribers": 80138, "created_utc": 1668585912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s157s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scalability, Allocation, and Processing of Data in Multitenant Database Architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 42, "top_awarded_type": null, "hide_score": false, "name": "t3_ywnkgv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/elVFrc0Mo2zTlGedFF7V4b2jxmjuCrPtYsfGDAyofT4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668585635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stratoflow.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stratoflow.com/data-scalability-allocation-processing-multitenancy/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?auto=webp&amp;s=75187a188b2d172c458b0ffe3853aa44d2f1cb8b", "width": 2000, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec136e4a83b3644f0bf63c52f1fc98a6ae436282", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3ba3e71f239b010297f2b09e81eb1ec6f4c3625b", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ae6a1ffc867781e34898039d54314873f03270a2", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e14f25812eea540557f794db4b2f88a3424b7e0f", "width": 640, "height": 192}, {"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4eb4579027d16589844a1b290776127e2cc8a48e", "width": 960, "height": 288}, {"url": "https://external-preview.redd.it/qio9sP2MqXS7bL8WeNEafyr1p8RDjEYh3IQOBhdwBBY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01c59e533788e1c95fd8522e8ee04f5b5fc74503", "width": 1080, "height": 324}], "variants": {}, "id": "RcR2zEpex6L6Lwxn4yXwPmxyP6WEkTHpN_gLD9o1olg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ywnkgv", "is_robot_indexable": true, "report_reasons": null, "author": "TheRobak333", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywnkgv/scalability_allocation_and_processing_of_data_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stratoflow.com/data-scalability-allocation-processing-multitenancy/", "subreddit_subscribers": 80138, "created_utc": 1668585635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently use python operator and have a bunch of processes that would run at same time. We don't want the processes to contend for resources and one high memory process bringing down the entire airflow server. How can this be handled in Airflow? \n\nIs kubernates operator right solution for managing resources effectively? How are things handled in Airflow in your organization? Thanks.", "author_fullname": "t2_jfqnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is your Airflow architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yxe8au", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668652943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently use python operator and have a bunch of processes that would run at same time. We don&amp;#39;t want the processes to contend for resources and one high memory process bringing down the entire airflow server. How can this be handled in Airflow? &lt;/p&gt;\n\n&lt;p&gt;Is kubernates operator right solution for managing resources effectively? How are things handled in Airflow in your organization? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yxe8au", "is_robot_indexable": true, "report_reasons": null, "author": "curidpostn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yxe8au/what_is_your_airflow_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yxe8au/what_is_your_airflow_architecture/", "subreddit_subscribers": 80138, "created_utc": 1668652943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tomorrow I'm hosting [Ergest Xheblati](https://www.linkedin.com/in/ergestxheblati/) (Data Architect &amp; Author of [*Minimum Viable SQL Patterns*](https://ergestx.gumroad.com/l/sqlpatterns)) for a data modeling workshop - [How to Design a Lasting Business Blueprint](https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;utm_source=reddit&amp;utm_medium=social&amp;utm_content=ergest-workshop-data-modeling)  \n\n\nIt's a workshop. Not a webinar. There's no SaaS tool being sold. It's an honest, educational opportunity hosted by a data architect with 15+ years experience.   \n\n\nIn this workshop, Ergest will teach:  \n\ud83c\udfaf How to conceptually model a fictional SaaS business (Create a conceptual model BEFORE the physical implementation)\n\n\ud83c\udfaf How the modeling approaches above will effect said SaaS business (One Big Table, Start Schema, Activity Schema, Data Vault, etc.)\n\n\ud83c\udfaf Why you might choose one approach or another (and the tradeoffs between them)\n\n\ud83c\udfaf How to move from one approach to the next if circumstances change  \n\n\nIf this interests you, sign up [here](https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;utm_source=reddit&amp;utm_medium=social&amp;utm_content=ergest-workshop-data-modeling).", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Workshop (A workshop, not a webinar w/ subjective hot takes \ud83e\udd23)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx10ab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668621819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tomorrow I&amp;#39;m hosting &lt;a href=\"https://www.linkedin.com/in/ergestxheblati/\"&gt;Ergest Xheblati&lt;/a&gt; (Data Architect &amp;amp; Author of &lt;a href=\"https://ergestx.gumroad.com/l/sqlpatterns\"&gt;&lt;em&gt;Minimum Viable SQL Patterns&lt;/em&gt;&lt;/a&gt;) for a data modeling workshop - &lt;a href=\"https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;amp;utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_content=ergest-workshop-data-modeling\"&gt;How to Design a Lasting Business Blueprint&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a workshop. Not a webinar. There&amp;#39;s no SaaS tool being sold. It&amp;#39;s an honest, educational opportunity hosted by a data architect with 15+ years experience.   &lt;/p&gt;\n\n&lt;p&gt;In this workshop, Ergest will teach:&lt;br/&gt;\n\ud83c\udfaf How to conceptually model a fictional SaaS business (Create a conceptual model BEFORE the physical implementation)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfaf How the modeling approaches above will effect said SaaS business (One Big Table, Start Schema, Activity Schema, Data Vault, etc.)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfaf Why you might choose one approach or another (and the tradeoffs between them)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfaf How to move from one approach to the next if circumstances change  &lt;/p&gt;\n\n&lt;p&gt;If this interests you, sign up &lt;a href=\"https://www.operationalanalytics.club/events/data-modeling-how-to-design-a-lasting-business-blueprint-w-ergest-xheblati?utm_campaign=Parker%20Rogers%20-%20Organic%20Social%20Campaign&amp;amp;utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_content=ergest-workshop-data-modeling\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yx10ab", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx10ab/data_modeling_workshop_a_workshop_not_a_webinar_w/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx10ab/data_modeling_workshop_a_workshop_not_a_webinar_w/", "subreddit_subscribers": 80138, "created_utc": 1668621819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "HI all,\n\n&amp;#x200B;\n\nI'm getting to the point where I'm starting to apply for data engineer roles. I am currently an application engineer that utilizes SQL in order to perform necessary tasks. In terms of SQL, we utilize basic queries such as select, update, delete, joins, cases, creating SQL scripts, etc. in a Microsoft SQL Server. Unfortunately, this does not give me any experience that translates to data engineering other than utilizing SQL.\n\nI also obtained a Bachelor's in Computer Science degree where Python was our main language. \n\nSo far, I've learned about Power Bi, DBT, ETL, etc. through udemy courses or YouTube videos. Obviously, I don't have real-world experience with this yet. \n\nI just wanted to know if there is anything else I can do to make myself a better candidate. Are there any courses that will steer me in the right direction? How much more studying do I need to do? I've seen people go straight into the field out of college and learned these skillsets on the job. \n\nthank you!", "author_fullname": "t2_7gkhxmgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I prepare for job interviews especially those that require to take home challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx086z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668620189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m getting to the point where I&amp;#39;m starting to apply for data engineer roles. I am currently an application engineer that utilizes SQL in order to perform necessary tasks. In terms of SQL, we utilize basic queries such as select, update, delete, joins, cases, creating SQL scripts, etc. in a Microsoft SQL Server. Unfortunately, this does not give me any experience that translates to data engineering other than utilizing SQL.&lt;/p&gt;\n\n&lt;p&gt;I also obtained a Bachelor&amp;#39;s in Computer Science degree where Python was our main language. &lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve learned about Power Bi, DBT, ETL, etc. through udemy courses or YouTube videos. Obviously, I don&amp;#39;t have real-world experience with this yet. &lt;/p&gt;\n\n&lt;p&gt;I just wanted to know if there is anything else I can do to make myself a better candidate. Are there any courses that will steer me in the right direction? How much more studying do I need to do? I&amp;#39;ve seen people go straight into the field out of college and learned these skillsets on the job. &lt;/p&gt;\n\n&lt;p&gt;thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yx086z", "is_robot_indexable": true, "report_reasons": null, "author": "SnooWalruses7164", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx086z/how_can_i_prepare_for_job_interviews_especially/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx086z/how_can_i_prepare_for_job_interviews_especially/", "subreddit_subscribers": 80138, "created_utc": 1668620189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently interviewing for a DE position and was invited to the next stage which is a live coding session with some members in the existing team. From the sounds of it it's going to be very casual, just doing some coding problems in Java and observing my coding practices and cooperation skills and i will be allowed to use the internet or ask question.\n\nI am very new to this with only just under 2 years of experience and currently working for a company without any real supervision - so nobody has ever been there to assess my work and nobody really cared how I did it as soon as it performed the way it has to. And also I had never had experience coding together with someone.\n\nSo my question really is what would be the best way to prepare for it? And what do you think they be assessing/ paying attention to? It all just sounds too easy to be true and I am scared Im gonna make a full of myself.\n\nThank you so much in advance!", "author_fullname": "t2_588bawm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach a live coding session during an interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywz8x6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668618209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently interviewing for a DE position and was invited to the next stage which is a live coding session with some members in the existing team. From the sounds of it it&amp;#39;s going to be very casual, just doing some coding problems in Java and observing my coding practices and cooperation skills and i will be allowed to use the internet or ask question.&lt;/p&gt;\n\n&lt;p&gt;I am very new to this with only just under 2 years of experience and currently working for a company without any real supervision - so nobody has ever been there to assess my work and nobody really cared how I did it as soon as it performed the way it has to. And also I had never had experience coding together with someone.&lt;/p&gt;\n\n&lt;p&gt;So my question really is what would be the best way to prepare for it? And what do you think they be assessing/ paying attention to? It all just sounds too easy to be true and I am scared Im gonna make a full of myself.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ywz8x6", "is_robot_indexable": true, "report_reasons": null, "author": "nastya_stark", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywz8x6/how_to_approach_a_live_coding_session_during_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywz8x6/how_to_approach_a_live_coding_session_during_an/", "subreddit_subscribers": 80138, "created_utc": 1668618209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently an analytics engineer working on a side project to help break into a data engineering role. I\u2019m dockerizing my pipeline while developing on my local machine, but I was curious to see what best practices are when deploying a pipeline to cloud? In the case with AWS, would you take your dockerized app and install it on an EC2 instance (seems like this would be redundant), or would you manually install all dependencies directly on an EC2 instance and ditch docker altogether in a prod environment?\n\nI\u2019m still figuring everything out so please let me know if I am butchering any common sense logic.", "author_fullname": "t2_bwp6e1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it best practice to use Docker with cloud VMs, or only during development on local machine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywz6fs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668618070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently an analytics engineer working on a side project to help break into a data engineering role. I\u2019m dockerizing my pipeline while developing on my local machine, but I was curious to see what best practices are when deploying a pipeline to cloud? In the case with AWS, would you take your dockerized app and install it on an EC2 instance (seems like this would be redundant), or would you manually install all dependencies directly on an EC2 instance and ditch docker altogether in a prod environment?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m still figuring everything out so please let me know if I am butchering any common sense logic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywz6fs", "is_robot_indexable": true, "report_reasons": null, "author": "wild_bill34", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywz6fs/is_it_best_practice_to_use_docker_with_cloud_vms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywz6fs/is_it_best_practice_to_use_docker_with_cloud_vms/", "subreddit_subscribers": 80138, "created_utc": 1668618070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8](https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Introduction to Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywxzq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668615674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8\"&gt;https://medium.com/@memphis-dev/an-introduction-to-data-mesh-b885a92646a8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?auto=webp&amp;s=5df084b961ca67ef4b875bdafe05ee0dc02a529a", "width": 1200, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2932d9ca5538cf9e7987ea5defc90d8db21d9d4", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3108462afb44d08064dc1c7716950f90afa8d552", "width": 216, "height": 184}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=033b10566bc1c68678dda368a4e9693f89672e67", "width": 320, "height": 273}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6677cbcdfbd6611efac4705cf67d0877a7b19cb1", "width": 640, "height": 546}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ba9cba3302d93d040da6cae3f4fe55b64ab54a5", "width": 960, "height": 819}, {"url": "https://external-preview.redd.it/9tj_YSzwdaW9DIs9SNOy_BfxOszR_U_r_F-lck6Cy6o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8284f1945c08155cd1e9b6b260685063ec0f901a", "width": 1080, "height": 921}], "variants": {}, "id": "eaYixETYqrtg_QSgOGZ9uK-0oKhDzDSheNCmQpS0PRk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ywxzq6", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywxzq6/an_introduction_to_data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywxzq6/an_introduction_to_data_mesh/", "subreddit_subscribers": 80138, "created_utc": 1668615674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "together with Eric we are experimenting on new formats for the Data Stack Show.  \n\n\nShop talks are small conversations between me and Eric where we discuss a topic. We try to keep it short and fun.  \n\n\nthe idea is to use these as conversation starters with a broader audience. It would be amazing to hear from you and open a public discussion on the topic!\n\n&amp;#x200B;\n\nCheck the Shop talk here:\n\n[https://datastackshow.com/podcast/shop-talk-what-coalesced-at-coalesce/](https://datastackshow.com/podcast/shop-talk-what-coalesced-at-coalesce/)", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happened at Coalesce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywixcg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668570713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;together with Eric we are experimenting on new formats for the Data Stack Show.  &lt;/p&gt;\n\n&lt;p&gt;Shop talks are small conversations between me and Eric where we discuss a topic. We try to keep it short and fun.  &lt;/p&gt;\n\n&lt;p&gt;the idea is to use these as conversation starters with a broader audience. It would be amazing to hear from you and open a public discussion on the topic!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Check the Shop talk here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datastackshow.com/podcast/shop-talk-what-coalesced-at-coalesce/\"&gt;https://datastackshow.com/podcast/shop-talk-what-coalesced-at-coalesce/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?auto=webp&amp;s=34de8ecb2dda95ced12ebd7c21053e1e7981ba1d", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e577c0d8f3a992b1dc57675a3d26252ad81247a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1763e65c857ad2771645d4ea3c2e850f17bfccef", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d90b0dbd576e3eba2f0ad686163a85121f65603", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f5971a1ba699a90ffd3b8a8cfbdc3fd309954682", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0f89730a35d8dbeffc76af7828edd89f296f4ce7", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Deqlntlo9qb5vgHPqHMHWcvNrdzsWAxeZ0GCv4dKMO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b71ab8f712333f16f45b3c81feba003de6126689", "width": 1080, "height": 607}], "variants": {}, "id": "_yoscnXb1RFxtTuBZnbzDMJHCehvluaPTHyNfrCbMkw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ywixcg", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywixcg/what_happened_at_coalesce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywixcg/what_happened_at_coalesce/", "subreddit_subscribers": 80138, "created_utc": 1668570713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nCurrently I have 2+ yoe, a master\u2019s degree in engineering ( non-CS) and have been working in a F500 modern data stack company for 2 years. I started as a data analyst ( Covid lack of options), and have been a data engineer ( promoted from junior to mid level recently).  I currently make 93k. \n\nI was searching for new jobs and I have been interviewing pretty well with leetcode for sql/ python. I received one offer for 121k which was immediately revoked because the team decided \u201cto go in a different direction\u201d this week. I received a second offer for a tax preparation small firm for 132k, but I found our they are being  acquired by a Private Equity firm. The offer is great and I would learn a lot, but I feel conflicted as the PE firm was fined multiple times for medication theft/fraud by the NHS. I think I will reject the offer and wait for a less ethical fraught \noffer? Thoughts", "author_fullname": "t2_tsrtqcem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ethical Concerns with Offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yx1r12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668623344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Currently I have 2+ yoe, a master\u2019s degree in engineering ( non-CS) and have been working in a F500 modern data stack company for 2 years. I started as a data analyst ( Covid lack of options), and have been a data engineer ( promoted from junior to mid level recently).  I currently make 93k. &lt;/p&gt;\n\n&lt;p&gt;I was searching for new jobs and I have been interviewing pretty well with leetcode for sql/ python. I received one offer for 121k which was immediately revoked because the team decided \u201cto go in a different direction\u201d this week. I received a second offer for a tax preparation small firm for 132k, but I found our they are being  acquired by a Private Equity firm. The offer is great and I would learn a lot, but I feel conflicted as the PE firm was fined multiple times for medication theft/fraud by the NHS. I think I will reject the offer and wait for a less ethical fraught \noffer? Thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yx1r12", "is_robot_indexable": true, "report_reasons": null, "author": "CookingGoBlue", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yx1r12/ethical_concerns_with_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yx1r12/ethical_concerns_with_offer/", "subreddit_subscribers": 80138, "created_utc": 1668623344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lxcst0yt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Big Data Books for Beginners to Advanced to Read in 2022 -", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_ywlwfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BzZADJALuXceaatRPx0ehLSVmtgBng8c471KbRE9Dlc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668579808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "codingvidya.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://codingvidya.com/best-big-data-books/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_om_0P904dbMyuMnNLnl7NJEEus7vr55_PLK7PjZJBA.jpg?auto=webp&amp;s=65e636a53127ab0ce887487fcbe0571d02473b6a", "width": 550, "height": 407}, "resolutions": [{"url": "https://external-preview.redd.it/_om_0P904dbMyuMnNLnl7NJEEus7vr55_PLK7PjZJBA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25d4be4ea96e8b29b7e030cc28a8766b76793361", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/_om_0P904dbMyuMnNLnl7NJEEus7vr55_PLK7PjZJBA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cedff60b14d6c78a9b65c304104c88da67664a0a", "width": 216, "height": 159}, {"url": "https://external-preview.redd.it/_om_0P904dbMyuMnNLnl7NJEEus7vr55_PLK7PjZJBA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d9f67471e832247dfc4ff8d27c5d73198933b8cc", "width": 320, "height": 236}], "variants": {}, "id": "q3FROqkR_qlUAN14HUHaWthCdGH4uA58ui0Eo_pK4SU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ywlwfw", "is_robot_indexable": true, "report_reasons": null, "author": "Lakshmireddys", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywlwfw/best_big_data_books_for_beginners_to_advanced_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://codingvidya.com/best-big-data-books/", "subreddit_subscribers": 80138, "created_utc": 1668579808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For on ongoing blog series about AWS cloud computing, a new post just got published! This time you will learn about the Simple Storage Service S3. It's an object store and one of the most essential services of AWS. \n\n[https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373](https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373)", "author_fullname": "t2_3di0zmcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Simple Storage Service - S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ywx7bz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1668614108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For on ongoing blog series about AWS cloud computing, a new post just got published! This time you will learn about the Simple Storage Service S3. It&amp;#39;s an object store and one of the most essential services of AWS. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373\"&gt;https://erwinschleier.medium.com/aws-simple-storage-service-s3-32ad25d77373&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?auto=webp&amp;s=76157e72d5fa325f969674de8d937b707e82a9c9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a81d0bbd7684d987ee985f2fd56ba142393be51c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e98e7a07131f09ec2fa4d2ea5ab203c33b013c5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c57778b500a5ce0ced8df1fd086cc428aae77747", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c21c14ab1c3ca06899bf28e0b3fd293d8dd689ab", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a8b34c649db8a185db2eb0ca6c02a272deed349", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/glHzZ_bfOaIdtR2Y4_oWR-mX9yTW_zRkAYOBIlmROTY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1eb2653c7e920f3261387f50c014eb834b27d4fb", "width": 1080, "height": 1080}], "variants": {}, "id": "14PTcHLZhsWzPYIRL1KFxfSWbZxysOVvupddjIWQQfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ywx7bz", "is_robot_indexable": true, "report_reasons": null, "author": "EdgarHuber", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ywx7bz/aws_simple_storage_service_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ywx7bz/aws_simple_storage_service_s3/", "subreddit_subscribers": 80138, "created_utc": 1668614108.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}