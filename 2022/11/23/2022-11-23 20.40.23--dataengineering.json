{"kind": "Listing", "data": {"after": "t3_z2bw2f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm still confused about the difference and use cases for a data warehouse and data lake. In my understanding what differs a database and data warehouse is OLTP and OLAP. While a database is more transaction and consitency focused, a data warehouse is optimized for big queries which makes it efficient for searching through big data. But why would I use a Data Warehouse like for example the Synapse Warehouse in Azure when I can create a Databricks solution with it's Lakehouse Architecture and Delta Tables that provide ACID? As far as I understand a Data Lake is just a dump for non relational data but you can still load from it since there a connector for Power BI also without the delta layer. So why not load directly from the data lake instead of putting the tables in a data warehouse as a intermediary step? Further, it is recommended to have around 3-4 stages (raw, curated, enriched), making the data lake also structured.  Another point is that a data Warehouse is very costy in Azure at least, while a data lake is quite cheap, so I don't really see the value. Can someone perhaps elaborate? Thanks!", "author_fullname": "t2_bgbrbly9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Data Warehouse and Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2jh8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669191348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still confused about the difference and use cases for a data warehouse and data lake. In my understanding what differs a database and data warehouse is OLTP and OLAP. While a database is more transaction and consitency focused, a data warehouse is optimized for big queries which makes it efficient for searching through big data. But why would I use a Data Warehouse like for example the Synapse Warehouse in Azure when I can create a Databricks solution with it&amp;#39;s Lakehouse Architecture and Delta Tables that provide ACID? As far as I understand a Data Lake is just a dump for non relational data but you can still load from it since there a connector for Power BI also without the delta layer. So why not load directly from the data lake instead of putting the tables in a data warehouse as a intermediary step? Further, it is recommended to have around 3-4 stages (raw, curated, enriched), making the data lake also structured.  Another point is that a data Warehouse is very costy in Azure at least, while a data lake is quite cheap, so I don&amp;#39;t really see the value. Can someone perhaps elaborate? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2jh8f", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Inspection3886", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2jh8f/difference_between_data_warehouse_and_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2jh8f/difference_between_data_warehouse_and_data_lake/", "subreddit_subscribers": 80779, "created_utc": 1669191348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently had an introductory interview for a Data Engineering position and was told that the next step of the process would be a take home project. I\u2019m usually ok with these as they\u2019re like 2-3 hours max of my time, and I greatly prefer this to live coding exercises.\n\nI was pretty flabbergasted when I received the assignment and was told that it was expected it would take me up to 8 hours to complete. The assignment itself makes sense and I\u2019m sure it would take *some* time, but I\u2019m unwilling to spend 8 hours or more on something when there\u2019s a possibility of just being ghosted after. \n\nMy question is: is this common? What is the average amount of time that these take-home projects usually take for Data Engineering roles?\n\nEDIT: additional context is that I applied to this job out of curiosity/exploring DE as a potential career path, I definitely won't be moving forward with this place since I can get exposure to DE through my current role but just more curious if crazy requests like this are commonplace in the DE interview process.\n\nEDIT 2: I will not be sharing the assignment or the data itself, please don't message me to ask :) what I will share is that the employer in question is a sports team and the assignment involves working with tabular and video data about specific elements of the game and its players.", "author_fullname": "t2_xi9z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8 hour take home project for interview\u2026is this normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2c5y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669228328.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669168811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had an introductory interview for a Data Engineering position and was told that the next step of the process would be a take home project. I\u2019m usually ok with these as they\u2019re like 2-3 hours max of my time, and I greatly prefer this to live coding exercises.&lt;/p&gt;\n\n&lt;p&gt;I was pretty flabbergasted when I received the assignment and was told that it was expected it would take me up to 8 hours to complete. The assignment itself makes sense and I\u2019m sure it would take &lt;em&gt;some&lt;/em&gt; time, but I\u2019m unwilling to spend 8 hours or more on something when there\u2019s a possibility of just being ghosted after. &lt;/p&gt;\n\n&lt;p&gt;My question is: is this common? What is the average amount of time that these take-home projects usually take for Data Engineering roles?&lt;/p&gt;\n\n&lt;p&gt;EDIT: additional context is that I applied to this job out of curiosity/exploring DE as a potential career path, I definitely won&amp;#39;t be moving forward with this place since I can get exposure to DE through my current role but just more curious if crazy requests like this are commonplace in the DE interview process.&lt;/p&gt;\n\n&lt;p&gt;EDIT 2: I will not be sharing the assignment or the data itself, please don&amp;#39;t message me to ask :) what I will share is that the employer in question is a sports team and the assignment involves working with tabular and video data about specific elements of the game and its players.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z2c5y9", "is_robot_indexable": true, "report_reasons": null, "author": "don_draper97", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2c5y9/8_hour_take_home_project_for_interviewis_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2c5y9/8_hour_take_home_project_for_interviewis_this/", "subreddit_subscribers": 80779, "created_utc": 1669168811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So much of this field is open source and I can't help but feel so thankful for it all. I was able to get a job in this field by working on projects in my own time with tools like python, airflow, postgres, and spark, all of which are open source and well documented. It took me a few years but I finally started contributing to some of these source codes with some (albeit minor) changes.", "author_fullname": "t2_b41hohwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we take a moment to appreciate how much of dataengineering is open source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2wigd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669227889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So much of this field is open source and I can&amp;#39;t help but feel so thankful for it all. I was able to get a job in this field by working on projects in my own time with tools like python, airflow, postgres, and spark, all of which are open source and well documented. It took me a few years but I finally started contributing to some of these source codes with some (albeit minor) changes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "z2wigd", "is_robot_indexable": true, "report_reasons": null, "author": "Gutscazerk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/z2wigd/can_we_take_a_moment_to_appreciate_how_much_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2wigd/can_we_take_a_moment_to_appreciate_how_much_of/", "subreddit_subscribers": 80779, "created_utc": 1669227889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a personal git that I use for everything and once a project is complete I make them public. My current job I got partially because of my git where I did a simple etl process from Strava.\n\nI'm working again on a portfolio and while I am a DE I feel out of practice so I want to see what others have had success with and apply similar projects for my next excursion into the market.", "author_fullname": "t2_m6djt7ei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a personal project get them a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2po9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669211526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a personal git that I use for everything and once a project is complete I make them public. My current job I got partially because of my git where I did a simple etl process from Strava.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working again on a portfolio and while I am a DE I feel out of practice so I want to see what others have had success with and apply similar projects for my next excursion into the market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z2po9u", "is_robot_indexable": true, "report_reasons": null, "author": "ophidiophobia_py_dev", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2po9u/anyone_have_a_personal_project_get_them_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2po9u/anyone_have_a_personal_project_get_them_a_job/", "subreddit_subscribers": 80779, "created_utc": 1669211526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The startup I work for recently hired a data product manager. From what I have seen on job descriptions of data PMs, it is becoming increasingly confusing what the mandate is. I know the responsibilities for this role vary between orgs and data teams but I\u2019m just curious what kind of impact you have seen PMs make to data product development.", "author_fullname": "t2_230njnwz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What has your experience been with non-technical data product managers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2odlb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669210730.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669208017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The startup I work for recently hired a data product manager. From what I have seen on job descriptions of data PMs, it is becoming increasingly confusing what the mandate is. I know the responsibilities for this role vary between orgs and data teams but I\u2019m just curious what kind of impact you have seen PMs make to data product development.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2odlb", "is_robot_indexable": true, "report_reasons": null, "author": "metrd", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2odlb/what_has_your_experience_been_with_nontechnical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2odlb/what_has_your_experience_been_with_nontechnical/", "subreddit_subscribers": 80779, "created_utc": 1669208017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "can anyone pls explain what Apache Iceberg is in simplest possible way?", "author_fullname": "t2_d6qq8lqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Apache Iceberg?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2w3dj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669226910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;can anyone pls explain what Apache Iceberg is in simplest possible way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2w3dj", "is_robot_indexable": true, "report_reasons": null, "author": "NegativeTip2384", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2w3dj/what_is_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2w3dj/what_is_apache_iceberg/", "subreddit_subscribers": 80779, "created_utc": 1669226910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm evaluating airflow deployments options for simple personal data integration. \n\nAs the hypotheticals, we need to be able to hit REST APIs from personal health data services like Fitbit, MyFitnessPal, and similar and then do a simple storage load to S3. I estimate this can happen for all services within 1 hour of compute daily.\n\nSo far, my evaluation of the minimums looks to be something like this: \n\n1. GCP's Cloud Composer @ 730 hours/month w/ 3 workers (required), 1 scheduler, n1-standard vCPU, 10GB network, +persistent disk costs = $390/month\n\n2. AWS MWAA small @ 730 hours/month w/ 1 worker, 2 schedulers (required), 1GB database &amp; data storage = $359/month.\n\n3. AWS EC2 instance w/ airflow running as a local service on a t4g.large @ 730 hours/month w/ 2cpus &amp; 8gb memory, 32gb disk = $34/month\n\n4. AWS Fargate (example 1 on this page) @ 5 tasks daily, 60min duration, 2 vcpu, 8gb memory, 32gb disk, and x86 architecture = $18/month\n\nAre there other options I should be considering? So far it seems like the managed services are just way more expensive then they are worth for anything like a personal project. \n\nThanks.", "author_fullname": "t2_1icoacpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a place that I can run airflow cheap enough to use personally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z24hf8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669149944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m evaluating airflow deployments options for simple personal data integration. &lt;/p&gt;\n\n&lt;p&gt;As the hypotheticals, we need to be able to hit REST APIs from personal health data services like Fitbit, MyFitnessPal, and similar and then do a simple storage load to S3. I estimate this can happen for all services within 1 hour of compute daily.&lt;/p&gt;\n\n&lt;p&gt;So far, my evaluation of the minimums looks to be something like this: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;GCP&amp;#39;s Cloud Composer @ 730 hours/month w/ 3 workers (required), 1 scheduler, n1-standard vCPU, 10GB network, +persistent disk costs = $390/month&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;AWS MWAA small @ 730 hours/month w/ 1 worker, 2 schedulers (required), 1GB database &amp;amp; data storage = $359/month.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;AWS EC2 instance w/ airflow running as a local service on a t4g.large @ 730 hours/month w/ 2cpus &amp;amp; 8gb memory, 32gb disk = $34/month&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;AWS Fargate (example 1 on this page) @ 5 tasks daily, 60min duration, 2 vcpu, 8gb memory, 32gb disk, and x86 architecture = $18/month&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Are there other options I should be considering? So far it seems like the managed services are just way more expensive then they are worth for anything like a personal project. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z24hf8", "is_robot_indexable": true, "report_reasons": null, "author": "0_to_1", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z24hf8/is_there_a_place_that_i_can_run_airflow_cheap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z24hf8/is_there_a_place_that_i_can_run_airflow_cheap/", "subreddit_subscribers": 80779, "created_utc": 1669149944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nMy company has an ADF pipeline for bringing files from our network drive into our Snowflake enterprise data warehouse.  It works fine, is driven off a control table in snowflake that stores the parameters for each pipeline like retention time, file location, upsert keys, destination db. This pipeline additionally writes the data from snowflake to sql server to preserve some old analytic reporting, logs auditing info, and sends failure notifications\n\nThere has been talk of abandoning this pipeline and using snowpipe instead with schema inference and stages to take advantage of built in snowflake functionality (suggested by another data engineer). Can anyone speak to their experience with snowpipe vs adf? The transition to using snowpipe will take several months and likely deprecate a lot of the ADF work. I am most interested in what has worked well for other companies and less interested in utilizing built in snowflake features just for the sake of it. I have very little experience with snowpipe which is why I'm posting \n\nMany thanks", "author_fullname": "t2_7lyjqy22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flatfile ingestion into Snowflake: ADF vs Snowpipe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z23w9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669155170.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669148564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;My company has an ADF pipeline for bringing files from our network drive into our Snowflake enterprise data warehouse.  It works fine, is driven off a control table in snowflake that stores the parameters for each pipeline like retention time, file location, upsert keys, destination db. This pipeline additionally writes the data from snowflake to sql server to preserve some old analytic reporting, logs auditing info, and sends failure notifications&lt;/p&gt;\n\n&lt;p&gt;There has been talk of abandoning this pipeline and using snowpipe instead with schema inference and stages to take advantage of built in snowflake functionality (suggested by another data engineer). Can anyone speak to their experience with snowpipe vs adf? The transition to using snowpipe will take several months and likely deprecate a lot of the ADF work. I am most interested in what has worked well for other companies and less interested in utilizing built in snowflake features just for the sake of it. I have very little experience with snowpipe which is why I&amp;#39;m posting &lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z23w9h", "is_robot_indexable": true, "report_reasons": null, "author": "kitkatbar_2314", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z23w9h/flatfile_ingestion_into_snowflake_adf_vs_snowpipe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z23w9h/flatfile_ingestion_into_snowflake_adf_vs_snowpipe/", "subreddit_subscribers": 80779, "created_utc": 1669148564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \n\n\nDo you happen to know any good discounts that would be relevant to data engineering?\n\nI'm considering subscribing to KodeKloud for devops related material. Any experience?", "author_fullname": "t2_27cwkjid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black friday deals 2022 for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2ugoa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669223092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;Do you happen to know any good discounts that would be relevant to data engineering?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering subscribing to KodeKloud for devops related material. Any experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2ugoa", "is_robot_indexable": true, "report_reasons": null, "author": "Usurper__", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2ugoa/black_friday_deals_2022_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2ugoa/black_friday_deals_2022_for_data_engineering/", "subreddit_subscribers": 80779, "created_utc": 1669223092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I was presented with an interesting project this week. It was obviously assigned to me because we have a small data team (3) so I do a little bit of everything.\n\nBut based on this problem I am going to write up, if you were a manager or team lead or just anyone working with Data who would you go in order to solve this issue.\n\nPROBLEM : \n\nData Warehouse has some changes that have been made to some of the tables.\n\nIn order to monitor the new ETL PROCESS , (data source )_test and (data sink)_test. There are two databases which are on the same SQL server instance that references these databases but in their normal form without the _test after their name.\n\nMany of the stored procedures are fully qualified and they reference the specific databases on the server. There is about 50 of them. Instead of going into every single stored procedure manually and replacing Source with Source_Test manually you have been asked to implement dynamic solution.\n\nThe reason for this is because these stored procs are called by an SSIS package that holds parameters on a project level, so the variable's can be set in SQL Server using the environmental variables. At run time someone can enter the original database name and the name of whatever their test database is.\n\nSOLUTION :\nHere is what I did to fix this. Wrote a stored procedure in T-SQL that looks through every stored procedure on the server and replaces every mention of Source with Source_Test. It only look for information to the left of the first period in a fully qualified DB reference (which usually contains two periods) so it only looks at the database name. If the stored proc contains code that references Source they are all changed to Source_Test within the code of the stored procedure.\n\nThen I put this stored procedure at the top of a workflow in SSIS so it's the first thing the package commits. It uses the global variables in the SSIS project to hold the names of the input striking and output string for the search and replace proc.\n\nThen after the rename , all the processes in the SSIS package excute and then the same stored procedure is executed again, only with the input and output variables reversed. So everything goes back to normal.\n\n\nIve done this specific task in job titles completely different from the one I hold now. If you had this problem where would it go to ? Straight to Data Engineering ? Or would an analyst look at it first. Or Database Developer, DBA. The list goes on. But if you worked in a large department with people of all different data centric titles who would you assign this to ?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Based on this problem who on your data team would you go to in order to develop a solution ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2uchh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669222820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was presented with an interesting project this week. It was obviously assigned to me because we have a small data team (3) so I do a little bit of everything.&lt;/p&gt;\n\n&lt;p&gt;But based on this problem I am going to write up, if you were a manager or team lead or just anyone working with Data who would you go in order to solve this issue.&lt;/p&gt;\n\n&lt;p&gt;PROBLEM : &lt;/p&gt;\n\n&lt;p&gt;Data Warehouse has some changes that have been made to some of the tables.&lt;/p&gt;\n\n&lt;p&gt;In order to monitor the new ETL PROCESS , (data source )_test and (data sink)_test. There are two databases which are on the same SQL server instance that references these databases but in their normal form without the _test after their name.&lt;/p&gt;\n\n&lt;p&gt;Many of the stored procedures are fully qualified and they reference the specific databases on the server. There is about 50 of them. Instead of going into every single stored procedure manually and replacing Source with Source_Test manually you have been asked to implement dynamic solution.&lt;/p&gt;\n\n&lt;p&gt;The reason for this is because these stored procs are called by an SSIS package that holds parameters on a project level, so the variable&amp;#39;s can be set in SQL Server using the environmental variables. At run time someone can enter the original database name and the name of whatever their test database is.&lt;/p&gt;\n\n&lt;p&gt;SOLUTION :\nHere is what I did to fix this. Wrote a stored procedure in T-SQL that looks through every stored procedure on the server and replaces every mention of Source with Source_Test. It only look for information to the left of the first period in a fully qualified DB reference (which usually contains two periods) so it only looks at the database name. If the stored proc contains code that references Source they are all changed to Source_Test within the code of the stored procedure.&lt;/p&gt;\n\n&lt;p&gt;Then I put this stored procedure at the top of a workflow in SSIS so it&amp;#39;s the first thing the package commits. It uses the global variables in the SSIS project to hold the names of the input striking and output string for the search and replace proc.&lt;/p&gt;\n\n&lt;p&gt;Then after the rename , all the processes in the SSIS package excute and then the same stored procedure is executed again, only with the input and output variables reversed. So everything goes back to normal.&lt;/p&gt;\n\n&lt;p&gt;Ive done this specific task in job titles completely different from the one I hold now. If you had this problem where would it go to ? Straight to Data Engineering ? Or would an analyst look at it first. Or Database Developer, DBA. The list goes on. But if you worked in a large department with people of all different data centric titles who would you assign this to ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2uchh", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2uchh/based_on_this_problem_who_on_your_data_team_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2uchh/based_on_this_problem_who_on_your_data_team_would/", "subreddit_subscribers": 80779, "created_utc": 1669222820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am studying software engineering and i have branched out to mobile app development.\n\nI figured out that i am not attracted to the branch that i chose and started to look in other options for my career. After watching few videos and reading articles about data engineering i figured i could give it a try. I still got few months untill mandatory internships where i would like to try and enroll in a company as a data engineer intern.\n\nAt the moment i know little about it. I can write simple SQL queries and work with PhpMyAdmin.\n\nSince there is black friday sales on udemy i spent quite abit looking for good courses. But since my budget is limited its hard for me to choose what to get and learn until mandatory internship.\n\n&amp;#x200B;\n\nMy pick right now is:\n\n \"The Complete SQL Bootcamp 2022: Go from Zero to Hero\"\n\n&amp;#x200B;\n\nThough i for sure need more courses.\n\n what courses should i get and or maybe an advice for someone thinking about this career path\n\nand what it takes to actually get an internship in a company", "author_fullname": "t2_inkm25xd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to get into Data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2sz95", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669219604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am studying software engineering and i have branched out to mobile app development.&lt;/p&gt;\n\n&lt;p&gt;I figured out that i am not attracted to the branch that i chose and started to look in other options for my career. After watching few videos and reading articles about data engineering i figured i could give it a try. I still got few months untill mandatory internships where i would like to try and enroll in a company as a data engineer intern.&lt;/p&gt;\n\n&lt;p&gt;At the moment i know little about it. I can write simple SQL queries and work with PhpMyAdmin.&lt;/p&gt;\n\n&lt;p&gt;Since there is black friday sales on udemy i spent quite abit looking for good courses. But since my budget is limited its hard for me to choose what to get and learn until mandatory internship.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My pick right now is:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The Complete SQL Bootcamp 2022: Go from Zero to Hero&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Though i for sure need more courses.&lt;/p&gt;\n\n&lt;p&gt;what courses should i get and or maybe an advice for someone thinking about this career path&lt;/p&gt;\n\n&lt;p&gt;and what it takes to actually get an internship in a company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z2sz95", "is_robot_indexable": true, "report_reasons": null, "author": "That_Material_4468", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2sz95/wanting_to_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2sz95/wanting_to_get_into_data_engineering/", "subreddit_subscribers": 80779, "created_utc": 1669219604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data engineer interview tomorrow. help\n\nHey guys, I have an interview tomorrow and im so short on time to prepare. This is related to data analytics but I've been preparing for Web development the last couple of months, hence im kind of clueless rn. Talking to a senior, they told they gave a case study and asked to tell what method to take and stuff\n\nAny guide or a small pdf to go through? My interview is tomorrow lol", "author_fullname": "t2_7hqz83jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview for a fresher", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2rs2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669216762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data engineer interview tomorrow. help&lt;/p&gt;\n\n&lt;p&gt;Hey guys, I have an interview tomorrow and im so short on time to prepare. This is related to data analytics but I&amp;#39;ve been preparing for Web development the last couple of months, hence im kind of clueless rn. Talking to a senior, they told they gave a case study and asked to tell what method to take and stuff&lt;/p&gt;\n\n&lt;p&gt;Any guide or a small pdf to go through? My interview is tomorrow lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z2rs2z", "is_robot_indexable": true, "report_reasons": null, "author": "GreenFinance5867", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2rs2z/interview_for_a_fresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2rs2z/interview_for_a_fresher/", "subreddit_subscribers": 80779, "created_utc": 1669216762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the title, and if not what are the differences?", "author_fullname": "t2_a7urc8tl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Solution Architecture a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2p2vg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669209938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title, and if not what are the differences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2p2vg", "is_robot_indexable": true, "report_reasons": null, "author": "Taylankab", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2p2vg/is_solution_architecture_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2p2vg/is_solution_architecture_a_data_engineer/", "subreddit_subscribers": 80779, "created_utc": 1669209938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nHello, \n\nSuppose I have a dag with a few simple tasks. One of which  is it to run a python script that pulls data from an API and inserts into a sql db. A parameter for pulling the desired data from the API depends on an input for the week youd like to pull from. In this case theres 17 weeks and I want to catchup from the 1st week to the 10th week (weeks 11-17 havent happened yet). Im curious how I can manage the catchups/backfills to dynamically run such that airflow is able to understand we have missing weeks and be able to input the necessary weeks into the python script. Hopefully that makes sense", "author_fullname": "t2_qtssrdk7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow parameterized backfill", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z23t4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669148362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;Suppose I have a dag with a few simple tasks. One of which  is it to run a python script that pulls data from an API and inserts into a sql db. A parameter for pulling the desired data from the API depends on an input for the week youd like to pull from. In this case theres 17 weeks and I want to catchup from the 1st week to the 10th week (weeks 11-17 havent happened yet). Im curious how I can manage the catchups/backfills to dynamically run such that airflow is able to understand we have missing weeks and be able to input the necessary weeks into the python script. Hopefully that makes sense&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z23t4k", "is_robot_indexable": true, "report_reasons": null, "author": "Primary-Self-6836", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z23t4k/airflow_parameterized_backfill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z23t4k/airflow_parameterized_backfill/", "subreddit_subscribers": 80779, "created_utc": 1669148362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If someone was going to start their own business are software engineers better positioned? I spend a lot of my day using SQL to answer queries which I feel like is only useful once you have enough data at a certain scale? In order to build your own business does software engineering offer more value in terms of creating your own website and stuff? Or is data analysis, and building pipelines equally valuable?", "author_fullname": "t2_31hbmows", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How helpful are data engineering skills in starting your own business vs software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2yx7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669233648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If someone was going to start their own business are software engineers better positioned? I spend a lot of my day using SQL to answer queries which I feel like is only useful once you have enough data at a certain scale? In order to build your own business does software engineering offer more value in terms of creating your own website and stuff? Or is data analysis, and building pipelines equally valuable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2yx7j", "is_robot_indexable": true, "report_reasons": null, "author": "rob121212111", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2yx7j/how_helpful_are_data_engineering_skills_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2yx7j/how_helpful_are_data_engineering_skills_in/", "subreddit_subscribers": 80779, "created_utc": 1669233648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a S3 bucket that has files continuously streamed into it about individuals data. How can I aggregate all this data into one file? Is there a service for this, also is there a way to do this in databricks too?", "author_fullname": "t2_wqszb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to compact many small files into one bigger file in AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2x9og", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669229673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a S3 bucket that has files continuously streamed into it about individuals data. How can I aggregate all this data into one file? Is there a service for this, also is there a way to do this in databricks too?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2x9og", "is_robot_indexable": true, "report_reasons": null, "author": "miridian19", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2x9og/how_to_compact_many_small_files_into_one_bigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2x9og/how_to_compact_many_small_files_into_one_bigger/", "subreddit_subscribers": 80779, "created_utc": 1669229673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Automated Data Lineage Keeps Pipelines Running at Grupo Botic\u00e1rio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_z2wi8z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/T78_QLP0DRBSZcE-r1n5M4rbKIMpDnRrYZj7WMj7cqM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669227875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/how-grupo-botic%C3%A1rio-keep-their-pipelines-running-with-automated-data-lineage-30a2b034f2f7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?auto=webp&amp;s=019daaf6856f2f29605ba6d016d7b16e08905d69", "width": 1200, "height": 716}, "resolutions": [{"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=570730bcae5672333227e4348caff70617291d51", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef08cacd55cf8b716763ee2a32ab4689eab53a82", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a2a0ea641d49ab2ada982e319b94c7684a3bc5d", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df640bdad348ae94331121372b054c85d22115f1", "width": 640, "height": 381}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=af343b4f55ad17c71ab9f4e30fbe6f7e38f5d7a7", "width": 960, "height": 572}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=076ce839845b79691a8097779d828d6903a8169c", "width": 1080, "height": 644}], "variants": {}, "id": "yCGfNy__xepDRU6IGnoy5fTqaGuySJVbpaN6_iodtTo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z2wi8z", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2wi8z/how_automated_data_lineage_keeps_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/how-grupo-botic%C3%A1rio-keep-their-pipelines-running-with-automated-data-lineage-30a2b034f2f7", "subreddit_subscribers": 80779, "created_utc": 1669227875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!  I have been recently working with a time series dataset that had at least 30% or more null values depending on the column. Assuming that  information existed prior to the date of the last null value we should be able to fill in those values using an average estimator. I was interested in filling these values, but was not sure what might be the best approach since the data was changing over time either in a positive or negative direction and thought that perhaps using methods that I had previously used for classification such as filling with median or mean would not produce accurate results. While examining the the data and looking for a possible solution to filling these values I remembered that by using Annual Growth Rate I could determine missing values by determining the rate of change between the given values then using the increase or decrease formula depending on the direction of the values given. Seeing as how I could not find this being done online I went ahead and attempted this in a Colab notebook and came up with the following proof of concept.\n\nI still have some questions about the usability of this method, but believe it may be a feasible solution for filling missing values in a time series.", "author_fullname": "t2_n2zasjis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using AAGR to determine missing values in a time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_z2bkys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8uTZEPbnahwiqjDjwjz2f9SJj3cC5MBTGfuGcyftGB0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669167159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!  I have been recently working with a time series dataset that had at least 30% or more null values depending on the column. Assuming that  information existed prior to the date of the last null value we should be able to fill in those values using an average estimator. I was interested in filling these values, but was not sure what might be the best approach since the data was changing over time either in a positive or negative direction and thought that perhaps using methods that I had previously used for classification such as filling with median or mean would not produce accurate results. While examining the the data and looking for a possible solution to filling these values I remembered that by using Annual Growth Rate I could determine missing values by determining the rate of change between the given values then using the increase or decrease formula depending on the direction of the values given. Seeing as how I could not find this being done online I went ahead and attempted this in a Colab notebook and came up with the following proof of concept.&lt;/p&gt;\n\n&lt;p&gt;I still have some questions about the usability of this method, but believe it may be a feasible solution for filling missing values in a time series.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/lifeofbaka/US-Energy-Timeseries/blob/main/US_Energy.ipynb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?auto=webp&amp;s=e62d90faeb8e0ddafb25db873e1ce956735eca11", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2e828a2420f69cf30b6b2ac76032a7a3dd1c62a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d33faa26bb4ec7e5a33a47c3cf2f337c7b5a01c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f4215d41a6a6a27a552c023ba602b9a02e348dae", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f558bed87a3edd11a005edd746a57474a8e93322", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=733b79d1d1eaf24da41797f6f6fc1d099ec3eafc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d2c6429e737a40044a69003be89df8c19cd163d", "width": 1080, "height": 540}], "variants": {}, "id": "KQI7jHpzUxS9sbS-aD-2Uj8ZJIoGfbxzoUtFCi4BwA0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "z2bkys", "is_robot_indexable": true, "report_reasons": null, "author": "DarthKermit-65", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2bkys/using_aagr_to_determine_missing_values_in_a_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/lifeofbaka/US-Energy-Timeseries/blob/main/US_Energy.ipynb", "subreddit_subscribers": 80779, "created_utc": 1669167159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently we are set up in BQ with a pseudo relational model that doesn't really fit any standard architectures. I was advocating to refactor everything to a Star or Snowflake schema because that's what I'm familiar with. I have heard 0 things about it, good or bad.", "author_fullname": "t2_7wm26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery users, has anyone gone all in and converted your warehouse to the Dremel model and nested tables? What's your experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2973o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669160790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we are set up in BQ with a pseudo relational model that doesn&amp;#39;t really fit any standard architectures. I was advocating to refactor everything to a Star or Snowflake schema because that&amp;#39;s what I&amp;#39;m familiar with. I have heard 0 things about it, good or bad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2973o", "is_robot_indexable": true, "report_reasons": null, "author": "Landoperk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2973o/bigquery_users_has_anyone_gone_all_in_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2973o/bigquery_users_has_anyone_gone_all_in_and/", "subreddit_subscribers": 80779, "created_utc": 1669160790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5tz7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benthos Studio - A modern take on Yahoo Pipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2ypd5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669233139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "studio.benthos.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://studio.benthos.dev", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "z2ypd5", "is_robot_indexable": true, "report_reasons": null, "author": "mihaitodor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2ypd5/benthos_studio_a_modern_take_on_yahoo_pipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://studio.benthos.dev", "subreddit_subscribers": 80779, "created_utc": 1669233139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good day, fellow data people! I'm an experienced data engineer seeking some advice from the community with regards to the volunteering opportunities. I'm particularly interested in the fields of ocean conservation as well as the monitoring of the near earth objects. Does anyone have experience in such topics or could recommend a good organisation? What do you think would be the best way to get involved? \n\nP.S if you are aware of any opportunities in the field of planet conservation or any other cause you feel requires more attention in general please write about it as well.", "author_fullname": "t2_eovvnrn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering for good", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2yf3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669232446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day, fellow data people! I&amp;#39;m an experienced data engineer seeking some advice from the community with regards to the volunteering opportunities. I&amp;#39;m particularly interested in the fields of ocean conservation as well as the monitoring of the near earth objects. Does anyone have experience in such topics or could recommend a good organisation? What do you think would be the best way to get involved? &lt;/p&gt;\n\n&lt;p&gt;P.S if you are aware of any opportunities in the field of planet conservation or any other cause you feel requires more attention in general please write about it as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2yf3f", "is_robot_indexable": true, "report_reasons": null, "author": "MrBurnzs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2yf3f/data_engineering_for_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2yf3f/data_engineering_for_good/", "subreddit_subscribers": 80779, "created_utc": 1669232446.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nAt the company I am working at, we are using an outdated licensed solution that I would like to replace, because it's causing us a lot of troubles.\n\n  \nDo you think that Apache Airflow could be a good replacement to send/receive files from an sftp endpoint ?\n\nWould you have any other alternatives ?", "author_fullname": "t2_10vw8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Airflow] As a Managed File Transfer solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2sio2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669218530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;At the company I am working at, we are using an outdated licensed solution that I would like to replace, because it&amp;#39;s causing us a lot of troubles.&lt;/p&gt;\n\n&lt;p&gt;Do you think that Apache Airflow could be a good replacement to send/receive files from an sftp endpoint ?&lt;/p&gt;\n\n&lt;p&gt;Would you have any other alternatives ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2sio2", "is_robot_indexable": true, "report_reasons": null, "author": "MoiSanh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2sio2/airflow_as_a_managed_file_transfer_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2sio2/airflow_as_a_managed_file_transfer_solution/", "subreddit_subscribers": 80779, "created_utc": 1669218530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm troubleshooting a pipeline created by a senior that changed company.\n\nThis Pipeline has a dataflow from l0.TableA to l2.TableA. .\n\nThe alter row settings has an option of \" Upsert if \" \"true()\"\n\n\nWhat I'm trying to understand is :\n\n- on which column or condition he decides to alter the row?\n- Does it compare each row of l0.TableA with l2.TableA and if it exist it overwrites l0 row into l2 row, if not it adds l0 row ?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alter Row Conditions in Upsert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2m9pc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669201430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m troubleshooting a pipeline created by a senior that changed company.&lt;/p&gt;\n\n&lt;p&gt;This Pipeline has a dataflow from l0.TableA to l2.TableA. .&lt;/p&gt;\n\n&lt;p&gt;The alter row settings has an option of &amp;quot; Upsert if &amp;quot; &amp;quot;true()&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m trying to understand is :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;on which column or condition he decides to alter the row?&lt;/li&gt;\n&lt;li&gt;Does it compare each row of l0.TableA with l2.TableA and if it exist it overwrites l0 row into l2 row, if not it adds l0 row ?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2m9pc", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2m9pc/alter_row_conditions_in_upsert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2m9pc/alter_row_conditions_in_upsert/", "subreddit_subscribers": 80779, "created_utc": 1669201430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking at the source code for a Flink application and there are underscores everywhere in the Scala code for transformations. I like Scala but that stuff is super unintuitive. Can someone explain to me this example I saw on the Flink homepage (for the KeyedStream -&gt; DataStream reduction):\n\n`keyedStream.reduce { _ + _ } `", "author_fullname": "t2_7mdudcx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone teach me what _ in Scala means?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2fkrt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669178658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking at the source code for a Flink application and there are underscores everywhere in the Scala code for transformations. I like Scala but that stuff is super unintuitive. Can someone explain to me this example I saw on the Flink homepage (for the KeyedStream -&amp;gt; DataStream reduction):&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;keyedStream.reduce { _ + _ }&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2fkrt", "is_robot_indexable": true, "report_reasons": null, "author": "OldManWhoYellsAtX", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2fkrt/can_someone_teach_me_what_in_scala_means/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2fkrt/can_someone_teach_me_what_in_scala_means/", "subreddit_subscribers": 80779, "created_utc": 1669178658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently looking into building a data pipeline in GCP using google composer that moves data from an on prem oracle db to BQ. I\u2019m able to access the db in python if I were to run a script manually while connected to the vpn. However, when trying to run the script as a test in cloud functions while my PC is off it would fail since it cannot connect to vpn. Does anyone have experience connecting to company data programmatically that requires to be connected to vpn? Thanks !", "author_fullname": "t2_edr3jh4p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessing on prem work data programmatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2bw2f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669168036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently looking into building a data pipeline in GCP using google composer that moves data from an on prem oracle db to BQ. I\u2019m able to access the db in python if I were to run a script manually while connected to the vpn. However, when trying to run the script as a test in cloud functions while my PC is off it would fail since it cannot connect to vpn. Does anyone have experience connecting to company data programmatically that requires to be connected to vpn? Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2bw2f", "is_robot_indexable": true, "report_reasons": null, "author": "babababooskio", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2bw2f/accessing_on_prem_work_data_programmatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2bw2f/accessing_on_prem_work_data_programmatically/", "subreddit_subscribers": 80779, "created_utc": 1669168036.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}