{"kind": "Listing", "data": {"after": "t3_z2yf3f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm still confused about the difference and use cases for a data warehouse and data lake. In my understanding what differs a database and data warehouse is OLTP and OLAP. While a database is more transaction and consitency focused, a data warehouse is optimized for big queries which makes it efficient for searching through big data. But why would I use a Data Warehouse like for example the Synapse Warehouse in Azure when I can create a Databricks solution with it's Lakehouse Architecture and Delta Tables that provide ACID? As far as I understand a Data Lake is just a dump for non relational data but you can still load from it since there a connector for Power BI also without the delta layer. So why not load directly from the data lake instead of putting the tables in a data warehouse as a intermediary step? Further, it is recommended to have around 3-4 stages (raw, curated, enriched), making the data lake also structured.  Another point is that a data Warehouse is very costy in Azure at least, while a data lake is quite cheap, so I don't really see the value. Can someone perhaps elaborate? Thanks!", "author_fullname": "t2_bgbrbly9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Data Warehouse and Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2jh8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669191348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still confused about the difference and use cases for a data warehouse and data lake. In my understanding what differs a database and data warehouse is OLTP and OLAP. While a database is more transaction and consitency focused, a data warehouse is optimized for big queries which makes it efficient for searching through big data. But why would I use a Data Warehouse like for example the Synapse Warehouse in Azure when I can create a Databricks solution with it&amp;#39;s Lakehouse Architecture and Delta Tables that provide ACID? As far as I understand a Data Lake is just a dump for non relational data but you can still load from it since there a connector for Power BI also without the delta layer. So why not load directly from the data lake instead of putting the tables in a data warehouse as a intermediary step? Further, it is recommended to have around 3-4 stages (raw, curated, enriched), making the data lake also structured.  Another point is that a data Warehouse is very costy in Azure at least, while a data lake is quite cheap, so I don&amp;#39;t really see the value. Can someone perhaps elaborate? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2jh8f", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Inspection3886", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2jh8f/difference_between_data_warehouse_and_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2jh8f/difference_between_data_warehouse_and_data_lake/", "subreddit_subscribers": 80784, "created_utc": 1669191348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So much of this field is open source and I can't help but feel so thankful for it all. I was able to get a job in this field by working on projects in my own time with tools like python, airflow, postgres, and spark, all of which are open source and well documented. It took me a few years but I finally started contributing to some of these source codes with some (albeit minor) changes.", "author_fullname": "t2_b41hohwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we take a moment to appreciate how much of dataengineering is open source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2wigd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669227889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So much of this field is open source and I can&amp;#39;t help but feel so thankful for it all. I was able to get a job in this field by working on projects in my own time with tools like python, airflow, postgres, and spark, all of which are open source and well documented. It took me a few years but I finally started contributing to some of these source codes with some (albeit minor) changes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "z2wigd", "is_robot_indexable": true, "report_reasons": null, "author": "Gutscazerk", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/z2wigd/can_we_take_a_moment_to_appreciate_how_much_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2wigd/can_we_take_a_moment_to_appreciate_how_much_of/", "subreddit_subscribers": 80784, "created_utc": 1669227889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently had an introductory interview for a Data Engineering position and was told that the next step of the process would be a take home project. I\u2019m usually ok with these as they\u2019re like 2-3 hours max of my time, and I greatly prefer this to live coding exercises.\n\nI was pretty flabbergasted when I received the assignment and was told that it was expected it would take me up to 8 hours to complete. The assignment itself makes sense and I\u2019m sure it would take *some* time, but I\u2019m unwilling to spend 8 hours or more on something when there\u2019s a possibility of just being ghosted after. \n\nMy question is: is this common? What is the average amount of time that these take-home projects usually take for Data Engineering roles?\n\nEDIT: additional context is that I applied to this job out of curiosity/exploring DE as a potential career path, I definitely won't be moving forward with this place since I can get exposure to DE through my current role but just more curious if crazy requests like this are commonplace in the DE interview process.\n\nEDIT 2: I will not be sharing the assignment or the data itself, please don't message me to ask :) what I will share is that the employer in question is a sports team and the assignment involves working with tabular and video data about specific elements of the game and its players.", "author_fullname": "t2_xi9z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8 hour take home project for interview\u2026is this normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2c5y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669228328.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669168811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had an introductory interview for a Data Engineering position and was told that the next step of the process would be a take home project. I\u2019m usually ok with these as they\u2019re like 2-3 hours max of my time, and I greatly prefer this to live coding exercises.&lt;/p&gt;\n\n&lt;p&gt;I was pretty flabbergasted when I received the assignment and was told that it was expected it would take me up to 8 hours to complete. The assignment itself makes sense and I\u2019m sure it would take &lt;em&gt;some&lt;/em&gt; time, but I\u2019m unwilling to spend 8 hours or more on something when there\u2019s a possibility of just being ghosted after. &lt;/p&gt;\n\n&lt;p&gt;My question is: is this common? What is the average amount of time that these take-home projects usually take for Data Engineering roles?&lt;/p&gt;\n\n&lt;p&gt;EDIT: additional context is that I applied to this job out of curiosity/exploring DE as a potential career path, I definitely won&amp;#39;t be moving forward with this place since I can get exposure to DE through my current role but just more curious if crazy requests like this are commonplace in the DE interview process.&lt;/p&gt;\n\n&lt;p&gt;EDIT 2: I will not be sharing the assignment or the data itself, please don&amp;#39;t message me to ask :) what I will share is that the employer in question is a sports team and the assignment involves working with tabular and video data about specific elements of the game and its players.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z2c5y9", "is_robot_indexable": true, "report_reasons": null, "author": "don_draper97", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2c5y9/8_hour_take_home_project_for_interviewis_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2c5y9/8_hour_take_home_project_for_interviewis_this/", "subreddit_subscribers": 80784, "created_utc": 1669168811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a personal git that I use for everything and once a project is complete I make them public. My current job I got partially because of my git where I did a simple etl process from Strava.\n\nI'm working again on a portfolio and while I am a DE I feel out of practice so I want to see what others have had success with and apply similar projects for my next excursion into the market.", "author_fullname": "t2_m6djt7ei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a personal project get them a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2po9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669211526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a personal git that I use for everything and once a project is complete I make them public. My current job I got partially because of my git where I did a simple etl process from Strava.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working again on a portfolio and while I am a DE I feel out of practice so I want to see what others have had success with and apply similar projects for my next excursion into the market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z2po9u", "is_robot_indexable": true, "report_reasons": null, "author": "ophidiophobia_py_dev", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2po9u/anyone_have_a_personal_project_get_them_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2po9u/anyone_have_a_personal_project_get_them_a_job/", "subreddit_subscribers": 80784, "created_utc": 1669211526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The startup I work for recently hired a data product manager. From what I have seen on job descriptions of data PMs, it is becoming increasingly confusing what the mandate is. I know the responsibilities for this role vary between orgs and data teams but I\u2019m just curious what kind of impact you have seen PMs make to data product development.", "author_fullname": "t2_230njnwz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What has your experience been with non-technical data product managers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2odlb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669210730.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669208017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The startup I work for recently hired a data product manager. From what I have seen on job descriptions of data PMs, it is becoming increasingly confusing what the mandate is. I know the responsibilities for this role vary between orgs and data teams but I\u2019m just curious what kind of impact you have seen PMs make to data product development.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2odlb", "is_robot_indexable": true, "report_reasons": null, "author": "metrd", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2odlb/what_has_your_experience_been_with_nontechnical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2odlb/what_has_your_experience_been_with_nontechnical/", "subreddit_subscribers": 80784, "created_utc": 1669208017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "can anyone pls explain what Apache Iceberg is in simplest possible way?", "author_fullname": "t2_d6qq8lqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Apache Iceberg?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2w3dj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669226910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;can anyone pls explain what Apache Iceberg is in simplest possible way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2w3dj", "is_robot_indexable": true, "report_reasons": null, "author": "NegativeTip2384", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2w3dj/what_is_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2w3dj/what_is_apache_iceberg/", "subreddit_subscribers": 80784, "created_utc": 1669226910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Automated Data Lineage Keeps Pipelines Running at Grupo Botic\u00e1rio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_z2wi8z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/T78_QLP0DRBSZcE-r1n5M4rbKIMpDnRrYZj7WMj7cqM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669227875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/how-grupo-botic%C3%A1rio-keep-their-pipelines-running-with-automated-data-lineage-30a2b034f2f7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?auto=webp&amp;s=019daaf6856f2f29605ba6d016d7b16e08905d69", "width": 1200, "height": 716}, "resolutions": [{"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=570730bcae5672333227e4348caff70617291d51", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef08cacd55cf8b716763ee2a32ab4689eab53a82", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a2a0ea641d49ab2ada982e319b94c7684a3bc5d", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df640bdad348ae94331121372b054c85d22115f1", "width": 640, "height": 381}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=af343b4f55ad17c71ab9f4e30fbe6f7e38f5d7a7", "width": 960, "height": 572}, {"url": "https://external-preview.redd.it/KwUVVj-Lj3japZjYzQLFVAL9CKvcFC27twdUxBMI9o0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=076ce839845b79691a8097779d828d6903a8169c", "width": 1080, "height": 644}], "variants": {}, "id": "yCGfNy__xepDRU6IGnoy5fTqaGuySJVbpaN6_iodtTo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z2wi8z", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2wi8z/how_automated_data_lineage_keeps_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/how-grupo-botic%C3%A1rio-keep-their-pipelines-running-with-automated-data-lineage-30a2b034f2f7", "subreddit_subscribers": 80784, "created_utc": 1669227875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \n\n\nDo you happen to know any good discounts that would be relevant to data engineering?\n\nI'm considering subscribing to KodeKloud for devops related material. Any experience?", "author_fullname": "t2_27cwkjid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Black friday deals 2022 for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2ugoa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669223092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;Do you happen to know any good discounts that would be relevant to data engineering?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering subscribing to KodeKloud for devops related material. Any experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2ugoa", "is_robot_indexable": true, "report_reasons": null, "author": "Usurper__", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2ugoa/black_friday_deals_2022_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2ugoa/black_friday_deals_2022_for_data_engineering/", "subreddit_subscribers": 80784, "created_utc": 1669223092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am studying software engineering and i have branched out to mobile app development.\n\nI figured out that i am not attracted to the branch that i chose and started to look in other options for my career. After watching few videos and reading articles about data engineering i figured i could give it a try. I still got few months untill mandatory internships where i would like to try and enroll in a company as a data engineer intern.\n\nAt the moment i know little about it. I can write simple SQL queries and work with PhpMyAdmin.\n\nSince there is black friday sales on udemy i spent quite abit looking for good courses. But since my budget is limited its hard for me to choose what to get and learn until mandatory internship.\n\n&amp;#x200B;\n\nMy pick right now is:\n\n \"The Complete SQL Bootcamp 2022: Go from Zero to Hero\"\n\n&amp;#x200B;\n\nThough i for sure need more courses.\n\n what courses should i get and or maybe an advice for someone thinking about this career path\n\nand what it takes to actually get an internship in a company", "author_fullname": "t2_inkm25xd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to get into Data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2sz95", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669219604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am studying software engineering and i have branched out to mobile app development.&lt;/p&gt;\n\n&lt;p&gt;I figured out that i am not attracted to the branch that i chose and started to look in other options for my career. After watching few videos and reading articles about data engineering i figured i could give it a try. I still got few months untill mandatory internships where i would like to try and enroll in a company as a data engineer intern.&lt;/p&gt;\n\n&lt;p&gt;At the moment i know little about it. I can write simple SQL queries and work with PhpMyAdmin.&lt;/p&gt;\n\n&lt;p&gt;Since there is black friday sales on udemy i spent quite abit looking for good courses. But since my budget is limited its hard for me to choose what to get and learn until mandatory internship.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My pick right now is:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The Complete SQL Bootcamp 2022: Go from Zero to Hero&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Though i for sure need more courses.&lt;/p&gt;\n\n&lt;p&gt;what courses should i get and or maybe an advice for someone thinking about this career path&lt;/p&gt;\n\n&lt;p&gt;and what it takes to actually get an internship in a company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z2sz95", "is_robot_indexable": true, "report_reasons": null, "author": "That_Material_4468", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2sz95/wanting_to_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2sz95/wanting_to_get_into_data_engineering/", "subreddit_subscribers": 80784, "created_utc": 1669219604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data engineer interview tomorrow. help\n\nHey guys, I have an interview tomorrow and im so short on time to prepare. This is related to data analytics but I've been preparing for Web development the last couple of months, hence im kind of clueless rn. Talking to a senior, they told they gave a case study and asked to tell what method to take and stuff\n\nAny guide or a small pdf to go through? My interview is tomorrow lol", "author_fullname": "t2_7hqz83jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview for a fresher", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2rs2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669216762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data engineer interview tomorrow. help&lt;/p&gt;\n\n&lt;p&gt;Hey guys, I have an interview tomorrow and im so short on time to prepare. This is related to data analytics but I&amp;#39;ve been preparing for Web development the last couple of months, hence im kind of clueless rn. Talking to a senior, they told they gave a case study and asked to tell what method to take and stuff&lt;/p&gt;\n\n&lt;p&gt;Any guide or a small pdf to go through? My interview is tomorrow lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "z2rs2z", "is_robot_indexable": true, "report_reasons": null, "author": "GreenFinance5867", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2rs2z/interview_for_a_fresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2rs2z/interview_for_a_fresher/", "subreddit_subscribers": 80784, "created_utc": 1669216762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If someone was going to start their own business are software engineers better positioned? I spend a lot of my day using SQL to answer queries which I feel like is only useful once you have enough data at a certain scale? In order to build your own business does software engineering offer more value in terms of creating your own website and stuff? Or is data analysis, and building pipelines equally valuable?", "author_fullname": "t2_31hbmows", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How helpful are data engineering skills in starting your own business vs software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2yx7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669233648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If someone was going to start their own business are software engineers better positioned? I spend a lot of my day using SQL to answer queries which I feel like is only useful once you have enough data at a certain scale? In order to build your own business does software engineering offer more value in terms of creating your own website and stuff? Or is data analysis, and building pipelines equally valuable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2yx7j", "is_robot_indexable": true, "report_reasons": null, "author": "rob121212111", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2yx7j/how_helpful_are_data_engineering_skills_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2yx7j/how_helpful_are_data_engineering_skills_in/", "subreddit_subscribers": 80784, "created_utc": 1669233648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a S3 bucket that has files continuously streamed into it about individuals data. How can I aggregate all this data into one file? Is there a service for this, also is there a way to do this in databricks too?", "author_fullname": "t2_wqszb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to compact many small files into one bigger file in AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2x9og", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669229673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a S3 bucket that has files continuously streamed into it about individuals data. How can I aggregate all this data into one file? Is there a service for this, also is there a way to do this in databricks too?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2x9og", "is_robot_indexable": true, "report_reasons": null, "author": "miridian19", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2x9og/how_to_compact_many_small_files_into_one_bigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2x9og/how_to_compact_many_small_files_into_one_bigger/", "subreddit_subscribers": 80784, "created_utc": 1669229673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I was presented with an interesting project this week. It was obviously assigned to me because we have a small data team (3) so I do a little bit of everything.\n\nBut based on this problem I am going to write up, if you were a manager or team lead or just anyone working with Data who would you go in order to solve this issue.\n\nPROBLEM : \n\nData Warehouse has some changes that have been made to some of the tables.\n\nIn order to monitor the new ETL PROCESS , (data source )_test and (data sink)_test. There are two databases which are on the same SQL server instance that references these databases but in their normal form without the _test after their name.\n\nMany of the stored procedures are fully qualified and they reference the specific databases on the server. There is about 50 of them. Instead of going into every single stored procedure manually and replacing Source with Source_Test manually you have been asked to implement dynamic solution.\n\nThe reason for this is because these stored procs are called by an SSIS package that holds parameters on a project level, so the variable's can be set in SQL Server using the environmental variables. At run time someone can enter the original database name and the name of whatever their test database is.\n\nSOLUTION :\nHere is what I did to fix this. Wrote a stored procedure in T-SQL that looks through every stored procedure on the server and replaces every mention of Source with Source_Test. It only look for information to the left of the first period in a fully qualified DB reference (which usually contains two periods) so it only looks at the database name. If the stored proc contains code that references Source they are all changed to Source_Test within the code of the stored procedure.\n\nThen I put this stored procedure at the top of a workflow in SSIS so it's the first thing the package commits. It uses the global variables in the SSIS project to hold the names of the input striking and output string for the search and replace proc.\n\nThen after the rename , all the processes in the SSIS package excute and then the same stored procedure is executed again, only with the input and output variables reversed. So everything goes back to normal.\n\n\nIve done this specific task in job titles completely different from the one I hold now. If you had this problem where would it go to ? Straight to Data Engineering ? Or would an analyst look at it first. Or Database Developer, DBA. The list goes on. But if you worked in a large department with people of all different data centric titles who would you assign this to ?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Based on this problem who on your data team would you go to in order to develop a solution ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2uchh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669222820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was presented with an interesting project this week. It was obviously assigned to me because we have a small data team (3) so I do a little bit of everything.&lt;/p&gt;\n\n&lt;p&gt;But based on this problem I am going to write up, if you were a manager or team lead or just anyone working with Data who would you go in order to solve this issue.&lt;/p&gt;\n\n&lt;p&gt;PROBLEM : &lt;/p&gt;\n\n&lt;p&gt;Data Warehouse has some changes that have been made to some of the tables.&lt;/p&gt;\n\n&lt;p&gt;In order to monitor the new ETL PROCESS , (data source )_test and (data sink)_test. There are two databases which are on the same SQL server instance that references these databases but in their normal form without the _test after their name.&lt;/p&gt;\n\n&lt;p&gt;Many of the stored procedures are fully qualified and they reference the specific databases on the server. There is about 50 of them. Instead of going into every single stored procedure manually and replacing Source with Source_Test manually you have been asked to implement dynamic solution.&lt;/p&gt;\n\n&lt;p&gt;The reason for this is because these stored procs are called by an SSIS package that holds parameters on a project level, so the variable&amp;#39;s can be set in SQL Server using the environmental variables. At run time someone can enter the original database name and the name of whatever their test database is.&lt;/p&gt;\n\n&lt;p&gt;SOLUTION :\nHere is what I did to fix this. Wrote a stored procedure in T-SQL that looks through every stored procedure on the server and replaces every mention of Source with Source_Test. It only look for information to the left of the first period in a fully qualified DB reference (which usually contains two periods) so it only looks at the database name. If the stored proc contains code that references Source they are all changed to Source_Test within the code of the stored procedure.&lt;/p&gt;\n\n&lt;p&gt;Then I put this stored procedure at the top of a workflow in SSIS so it&amp;#39;s the first thing the package commits. It uses the global variables in the SSIS project to hold the names of the input striking and output string for the search and replace proc.&lt;/p&gt;\n\n&lt;p&gt;Then after the rename , all the processes in the SSIS package excute and then the same stored procedure is executed again, only with the input and output variables reversed. So everything goes back to normal.&lt;/p&gt;\n\n&lt;p&gt;Ive done this specific task in job titles completely different from the one I hold now. If you had this problem where would it go to ? Straight to Data Engineering ? Or would an analyst look at it first. Or Database Developer, DBA. The list goes on. But if you worked in a large department with people of all different data centric titles who would you assign this to ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2uchh", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2uchh/based_on_this_problem_who_on_your_data_team_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2uchh/based_on_this_problem_who_on_your_data_team_would/", "subreddit_subscribers": 80784, "created_utc": 1669222820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5tz7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benthos Studio - A modern take on Yahoo Pipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2ypd5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1669233139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "studio.benthos.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://studio.benthos.dev", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "z2ypd5", "is_robot_indexable": true, "report_reasons": null, "author": "mihaitodor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2ypd5/benthos_studio_a_modern_take_on_yahoo_pipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://studio.benthos.dev", "subreddit_subscribers": 80784, "created_utc": 1669233139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the title, and if not what are the differences?", "author_fullname": "t2_a7urc8tl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Solution Architecture a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2p2vg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669209938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title, and if not what are the differences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2p2vg", "is_robot_indexable": true, "report_reasons": null, "author": "Taylankab", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2p2vg/is_solution_architecture_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2p2vg/is_solution_architecture_a_data_engineer/", "subreddit_subscribers": 80784, "created_utc": 1669209938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!  I have been recently working with a time series dataset that had at least 30% or more null values depending on the column. Assuming that  information existed prior to the date of the last null value we should be able to fill in those values using an average estimator. I was interested in filling these values, but was not sure what might be the best approach since the data was changing over time either in a positive or negative direction and thought that perhaps using methods that I had previously used for classification such as filling with median or mean would not produce accurate results. While examining the the data and looking for a possible solution to filling these values I remembered that by using Annual Growth Rate I could determine missing values by determining the rate of change between the given values then using the increase or decrease formula depending on the direction of the values given. Seeing as how I could not find this being done online I went ahead and attempted this in a Colab notebook and came up with the following proof of concept.\n\nI still have some questions about the usability of this method, but believe it may be a feasible solution for filling missing values in a time series.", "author_fullname": "t2_n2zasjis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using AAGR to determine missing values in a time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_z2bkys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8uTZEPbnahwiqjDjwjz2f9SJj3cC5MBTGfuGcyftGB0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669167159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!  I have been recently working with a time series dataset that had at least 30% or more null values depending on the column. Assuming that  information existed prior to the date of the last null value we should be able to fill in those values using an average estimator. I was interested in filling these values, but was not sure what might be the best approach since the data was changing over time either in a positive or negative direction and thought that perhaps using methods that I had previously used for classification such as filling with median or mean would not produce accurate results. While examining the the data and looking for a possible solution to filling these values I remembered that by using Annual Growth Rate I could determine missing values by determining the rate of change between the given values then using the increase or decrease formula depending on the direction of the values given. Seeing as how I could not find this being done online I went ahead and attempted this in a Colab notebook and came up with the following proof of concept.&lt;/p&gt;\n\n&lt;p&gt;I still have some questions about the usability of this method, but believe it may be a feasible solution for filling missing values in a time series.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/lifeofbaka/US-Energy-Timeseries/blob/main/US_Energy.ipynb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?auto=webp&amp;s=e62d90faeb8e0ddafb25db873e1ce956735eca11", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2e828a2420f69cf30b6b2ac76032a7a3dd1c62a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d33faa26bb4ec7e5a33a47c3cf2f337c7b5a01c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f4215d41a6a6a27a552c023ba602b9a02e348dae", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f558bed87a3edd11a005edd746a57474a8e93322", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=733b79d1d1eaf24da41797f6f6fc1d099ec3eafc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/UPyObv-tEwtHImTjwqNe5-FOCiBkJedMRmTfKMiJK1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d2c6429e737a40044a69003be89df8c19cd163d", "width": 1080, "height": 540}], "variants": {}, "id": "KQI7jHpzUxS9sbS-aD-2Uj8ZJIoGfbxzoUtFCi4BwA0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "z2bkys", "is_robot_indexable": true, "report_reasons": null, "author": "DarthKermit-65", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2bkys/using_aagr_to_determine_missing_values_in_a_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/lifeofbaka/US-Energy-Timeseries/blob/main/US_Energy.ipynb", "subreddit_subscribers": 80784, "created_utc": 1669167159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently we are set up in BQ with a pseudo relational model that doesn't really fit any standard architectures. I was advocating to refactor everything to a Star or Snowflake schema because that's what I'm familiar with. I have heard 0 things about it, good or bad.", "author_fullname": "t2_7wm26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery users, has anyone gone all in and converted your warehouse to the Dremel model and nested tables? What's your experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2973o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669160790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we are set up in BQ with a pseudo relational model that doesn&amp;#39;t really fit any standard architectures. I was advocating to refactor everything to a Star or Snowflake schema because that&amp;#39;s what I&amp;#39;m familiar with. I have heard 0 things about it, good or bad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "z2973o", "is_robot_indexable": true, "report_reasons": null, "author": "Landoperk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2973o/bigquery_users_has_anyone_gone_all_in_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2973o/bigquery_users_has_anyone_gone_all_in_and/", "subreddit_subscribers": 80784, "created_utc": 1669160790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a 1st in computer science with 6 months of experience as a full stack developer (including sql and ssms experience which I have enjoyed a lot). However I don't like working at this company: the tech stack is outdated and I am just more interested in data science/analysis than development.\n\nI live in a village in the midlands so remote work is a must for me, or at most hybrid in a nearby city. What sort of things should I look out for in job posts? I want a comfy job but also one where I can learn a lot, and really I just want to start my career as a data analyst/engineer in a good way. I do have experience with Python and SQL as I've already mentioned.\n\nHas anyone been in a similar position? Any advice for me? How is the Job market at the moment. \n\nThank you!", "author_fullname": "t2_bxlsv6fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job market in the UK for an entry level position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z3050u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669236572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 1st in computer science with 6 months of experience as a full stack developer (including sql and ssms experience which I have enjoyed a lot). However I don&amp;#39;t like working at this company: the tech stack is outdated and I am just more interested in data science/analysis than development.&lt;/p&gt;\n\n&lt;p&gt;I live in a village in the midlands so remote work is a must for me, or at most hybrid in a nearby city. What sort of things should I look out for in job posts? I want a comfy job but also one where I can learn a lot, and really I just want to start my career as a data analyst/engineer in a good way. I do have experience with Python and SQL as I&amp;#39;ve already mentioned.&lt;/p&gt;\n\n&lt;p&gt;Has anyone been in a similar position? Any advice for me? How is the Job market at the moment. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "z3050u", "is_robot_indexable": true, "report_reasons": null, "author": "isopropyla", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3050u/job_market_in_the_uk_for_an_entry_level_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3050u/job_market_in_the_uk_for_an_entry_level_position/", "subreddit_subscribers": 80784, "created_utc": 1669236572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,  this is my new article about linked services and dataset using data factory and discuss why is the pipeline important for companies.enjoy reading \n https://link.medium.com/CayOY2aZ9ub", "author_fullname": "t2_7ssutue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z3020n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669236365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,  this is my new article about linked services and dataset using data factory and discuss why is the pipeline important for companies.enjoy reading \n &lt;a href=\"https://link.medium.com/CayOY2aZ9ub\"&gt;https://link.medium.com/CayOY2aZ9ub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fmckk0lx1xrLKLn7ngn62DVESgxgHHwVKdPraLxUrXQ.jpg?auto=webp&amp;s=b4e674d87490587249c0334ea2bb3ae6472c5fba", "width": 501, "height": 294}, "resolutions": [{"url": "https://external-preview.redd.it/Fmckk0lx1xrLKLn7ngn62DVESgxgHHwVKdPraLxUrXQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc53e5fdb1d86f8a7b9c05edd97f9e37474a86a9", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/Fmckk0lx1xrLKLn7ngn62DVESgxgHHwVKdPraLxUrXQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f05abbbdef700cc44b969f11b142b4c10211e88", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/Fmckk0lx1xrLKLn7ngn62DVESgxgHHwVKdPraLxUrXQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c6ffd7ae2657bb883394f9f438a7360af890de98", "width": 320, "height": 187}], "variants": {}, "id": "quQh0DJf5BJio-XlPJ3JeE6-TySuu8DtGiZYrpsHlCo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "z3020n", "is_robot_indexable": true, "report_reasons": null, "author": "Ansam93", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z3020n/azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z3020n/azure_data_factory/", "subreddit_subscribers": 80784, "created_utc": 1669236365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been tasked with building a data catalog, and it feels like both AWS Glue and Databricks Unity Catalog can achieve similar results of identifying tables and columns in a s3 data lake. Does anyone have experience working with these tools or advice on which one would be more suitable?", "author_fullname": "t2_bubki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue vs Databricks Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2zsjm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669235730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been tasked with building a data catalog, and it feels like both AWS Glue and Databricks Unity Catalog can achieve similar results of identifying tables and columns in a s3 data lake. Does anyone have experience working with these tools or advice on which one would be more suitable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2zsjm", "is_robot_indexable": true, "report_reasons": null, "author": "Chapstic1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2zsjm/aws_glue_vs_databricks_unity_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2zsjm/aws_glue_vs_databricks_unity_catalog/", "subreddit_subscribers": 80784, "created_utc": 1669235730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nAt the company I am working at, we are using an outdated licensed solution that I would like to replace, because it's causing us a lot of troubles.\n\n  \nDo you think that Apache Airflow could be a good replacement to send/receive files from an sftp endpoint ?\n\nWould you have any other alternatives ?", "author_fullname": "t2_10vw8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Airflow] As a Managed File Transfer solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2sio2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669218530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;At the company I am working at, we are using an outdated licensed solution that I would like to replace, because it&amp;#39;s causing us a lot of troubles.&lt;/p&gt;\n\n&lt;p&gt;Do you think that Apache Airflow could be a good replacement to send/receive files from an sftp endpoint ?&lt;/p&gt;\n\n&lt;p&gt;Would you have any other alternatives ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2sio2", "is_robot_indexable": true, "report_reasons": null, "author": "MoiSanh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2sio2/airflow_as_a_managed_file_transfer_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2sio2/airflow_as_a_managed_file_transfer_solution/", "subreddit_subscribers": 80784, "created_utc": 1669218530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm troubleshooting a pipeline created by a senior that changed company.\n\nThis Pipeline has a dataflow from l0.TableA to l2.TableA. .\n\nThe alter row settings has an option of \" Upsert if \" \"true()\"\n\n\nWhat I'm trying to understand is :\n\n- on which column or condition he decides to alter the row?\n- Does it compare each row of l0.TableA with l2.TableA and if it exist it overwrites l0 row into l2 row, if not it adds l0 row ?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alter Row Conditions in Upsert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2m9pc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669201430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m troubleshooting a pipeline created by a senior that changed company.&lt;/p&gt;\n\n&lt;p&gt;This Pipeline has a dataflow from l0.TableA to l2.TableA. .&lt;/p&gt;\n\n&lt;p&gt;The alter row settings has an option of &amp;quot; Upsert if &amp;quot; &amp;quot;true()&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m trying to understand is :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;on which column or condition he decides to alter the row?&lt;/li&gt;\n&lt;li&gt;Does it compare each row of l0.TableA with l2.TableA and if it exist it overwrites l0 row into l2 row, if not it adds l0 row ?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2m9pc", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2m9pc/alter_row_conditions_in_upsert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2m9pc/alter_row_conditions_in_upsert/", "subreddit_subscribers": 80784, "created_utc": 1669201430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently looking into building a data pipeline in GCP using google composer that moves data from an on prem oracle db to BQ. I\u2019m able to access the db in python if I were to run a script manually while connected to the vpn. However, when trying to run the script as a test in cloud functions while my PC is off it would fail since it cannot connect to vpn. Does anyone have experience connecting to company data programmatically that requires to be connected to vpn? Thanks !", "author_fullname": "t2_edr3jh4p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessing on prem work data programmatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2bw2f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669168036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently looking into building a data pipeline in GCP using google composer that moves data from an on prem oracle db to BQ. I\u2019m able to access the db in python if I were to run a script manually while connected to the vpn. However, when trying to run the script as a test in cloud functions while my PC is off it would fail since it cannot connect to vpn. Does anyone have experience connecting to company data programmatically that requires to be connected to vpn? Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2bw2f", "is_robot_indexable": true, "report_reasons": null, "author": "babababooskio", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2bw2f/accessing_on_prem_work_data_programmatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2bw2f/accessing_on_prem_work_data_programmatically/", "subreddit_subscribers": 80784, "created_utc": 1669168036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "### Current pipeline is as follows:\n\n**Run Pipeline**\n\n1. Download data from Snowflake to Local (in parallel)\n2. Run Transformation Model \n3. Upload outputs of model to Snowflake\n\n### Issue:\n\nThere isn't a backfill proof system set up, and I'd like to implement that. What I'm looking at doing is capturing the input data in Azure Blob (cold storage), capturing the transformation model (either the folder system itself, or the git hash so it can be traced back to it's respective repo version), as well as capturing the output data in Azure, too.\n\n\n### My solution:\n\n**Run Pipeline**\n\n1. **CAPTURE Input Data** Snowflake &gt; External Stage &gt; Azure Blob\n2. Download data from Snowflake to Local (in parallel)\n3. **CAPTURE Model Image** Local &gt; Azure Blob (hash or folder)\n4. Run Transformation Model\n5. Upload outputs of model to Snowflake\n6. **CAPTURE Output Data** Snowflake &gt; External Stage &gt; Azure Blob\n\nWould this be a viable, efficient solution? The data will also be available locally for the AKS instance the model is running in, so another option would be to upload this data locally to Azure Blob before the pod winds down. Any ideas on a better way to do this before I proceed?", "author_fullname": "t2_8y4c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best method to backfill this pipeline (Snowflake, Blob Storage)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z28rru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669160683.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669159740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h3&gt;Current pipeline is as follows:&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;Run Pipeline&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Download data from Snowflake to Local (in parallel)&lt;/li&gt;\n&lt;li&gt;Run Transformation Model &lt;/li&gt;\n&lt;li&gt;Upload outputs of model to Snowflake&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h3&gt;Issue:&lt;/h3&gt;\n\n&lt;p&gt;There isn&amp;#39;t a backfill proof system set up, and I&amp;#39;d like to implement that. What I&amp;#39;m looking at doing is capturing the input data in Azure Blob (cold storage), capturing the transformation model (either the folder system itself, or the git hash so it can be traced back to it&amp;#39;s respective repo version), as well as capturing the output data in Azure, too.&lt;/p&gt;\n\n&lt;h3&gt;My solution:&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;Run Pipeline&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;CAPTURE Input Data&lt;/strong&gt; Snowflake &amp;gt; External Stage &amp;gt; Azure Blob&lt;/li&gt;\n&lt;li&gt;Download data from Snowflake to Local (in parallel)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CAPTURE Model Image&lt;/strong&gt; Local &amp;gt; Azure Blob (hash or folder)&lt;/li&gt;\n&lt;li&gt;Run Transformation Model&lt;/li&gt;\n&lt;li&gt;Upload outputs of model to Snowflake&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CAPTURE Output Data&lt;/strong&gt; Snowflake &amp;gt; External Stage &amp;gt; Azure Blob&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Would this be a viable, efficient solution? The data will also be available locally for the AKS instance the model is running in, so another option would be to upload this data locally to Azure Blob before the pod winds down. Any ideas on a better way to do this before I proceed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z28rru", "is_robot_indexable": true, "report_reasons": null, "author": "azazazazaz3", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/z28rru/best_method_to_backfill_this_pipeline_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z28rru/best_method_to_backfill_this_pipeline_snowflake/", "subreddit_subscribers": 80784, "created_utc": 1669159740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good day, fellow data people! I'm an experienced data engineer seeking some advice from the community with regards to the volunteering opportunities. I'm particularly interested in the fields of ocean conservation as well as the monitoring of the near earth objects. Does anyone have experience in such topics or could recommend a good organisation? What do you think would be the best way to get involved? \n\nP.S if you are aware of any opportunities in the field of planet conservation or any other cause you feel requires more attention in general please write about it as well.", "author_fullname": "t2_eovvnrn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering for good", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z2yf3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669232446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day, fellow data people! I&amp;#39;m an experienced data engineer seeking some advice from the community with regards to the volunteering opportunities. I&amp;#39;m particularly interested in the fields of ocean conservation as well as the monitoring of the near earth objects. Does anyone have experience in such topics or could recommend a good organisation? What do you think would be the best way to get involved? &lt;/p&gt;\n\n&lt;p&gt;P.S if you are aware of any opportunities in the field of planet conservation or any other cause you feel requires more attention in general please write about it as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "z2yf3f", "is_robot_indexable": true, "report_reasons": null, "author": "MrBurnzs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/z2yf3f/data_engineering_for_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/z2yf3f/data_engineering_for_good/", "subreddit_subscribers": 80784, "created_utc": 1669232446.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}