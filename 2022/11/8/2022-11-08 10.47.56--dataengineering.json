{"kind": "Listing", "data": {"after": "t3_yp2r0g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?", "author_fullname": "t2_3ydamall", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are all my colleagues so weird", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp0q06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667855856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp0q06", "is_robot_indexable": true, "report_reasons": null, "author": "masta_beta69", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "subreddit_subscribers": 79247, "created_utc": 1667855856.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: Databricks vs. Snowflake - Who wins?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_yp5mbh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u_xxC_eXXOHvqK1P-bJYUEzxhxy2jS-mcrCUqSLOtYY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667866364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n3y26kqadmy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n3y26kqadmy91.png?auto=webp&amp;s=b24fdc9cc0ae55fe276059b797ff46f2af4df245", "width": 1472, "height": 995}, "resolutions": [{"url": "https://preview.redd.it/n3y26kqadmy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec7844e199a4f24ead9d3d2479ffd65e9107fd56", "width": 108, "height": 73}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ff6de90cb1af595399cf1f8027f32a804a6bbd7", "width": 216, "height": 146}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bfefd9ae47cd5cd0b1b547ff6efb2525f504d2b", "width": 320, "height": 216}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=00df4c6972e23d3d804d46f840d4d25e97610f33", "width": 640, "height": 432}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=780cf785bdc2bad8d94a25432795f137306ac787", "width": 960, "height": 648}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=62ed016f2c09205aa0c2beb47e18b0c9648c44b5", "width": 1080, "height": 730}], "variants": {}, "id": "oxyzXQH15HgTuA2-TcKRbh7Hg9z5CqYLONC7V8GiWtY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp5mbh", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp5mbh/discussion_databricks_vs_snowflake_who_wins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n3y26kqadmy91.png", "subreddit_subscribers": 79247, "created_utc": 1667866364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When is it better to use each one of these? \nAlso is there a way to perform zero-copy/in-memory transformation from pyArrow to pySpark? I can't find any info on both of these topics.", "author_fullname": "t2_dlui0uup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyArrow vs pySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_you1os", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667842313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When is it better to use each one of these? \nAlso is there a way to perform zero-copy/in-memory transformation from pyArrow to pySpark? I can&amp;#39;t find any info on both of these topics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "you1os", "is_robot_indexable": true, "report_reasons": null, "author": "XtremeBanana333", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/you1os/pyarrow_vs_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/you1os/pyarrow_vs_pyspark/", "subreddit_subscribers": 79247, "created_utc": 1667842313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://github.com/brexhq/substation](https://github.com/brexhq/substation)\n\nOur team recently released a project called Substation ([announcement here](https://medium.com/brexeng/announcing-substation-188d049d979b)) that can be used to create modular, serverless data pipelines (ETL).\n\nI'm the project lead so if anyone has any questions or feedback, then please let me know!", "author_fullname": "t2_kuumsieq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Substation: serverless data pipeline toolkit written in Go", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoqsw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667835895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/brexhq/substation\"&gt;https://github.com/brexhq/substation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Our team recently released a project called Substation (&lt;a href=\"https://medium.com/brexeng/announcing-substation-188d049d979b\"&gt;announcement here&lt;/a&gt;) that can be used to create modular, serverless data pipelines (ETL).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the project lead so if anyone has any questions or feedback, then please let me know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?auto=webp&amp;s=3cfa8d8d4f194782471777e21245a2c919692039", "width": 640, "height": 320}, "resolutions": [{"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ddb598de628cfd93d71f8ce4c42f6644f8727af", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f1a2c8c4b6377019bd6d53a44f7b4fa1d674523", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc76bdcfa8838602d4bb282df5c6cf49a7979f7e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f5bb3fae94b00071c6beabe9b650d67c6761d4e", "width": 640, "height": 320}], "variants": {}, "id": "xv1e5O9fm8KLjRaTRRPYd9oJCEFoBjTun2Ww3C8XHpQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yoqsw1", "is_robot_indexable": true, "report_reasons": null, "author": "jshlbrd-brex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoqsw1/substation_serverless_data_pipeline_toolkit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoqsw1/substation_serverless_data_pipeline_toolkit/", "subreddit_subscribers": 79247, "created_utc": 1667835895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.\n\nI can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.\n\nWhat kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?", "author_fullname": "t2_wd6qw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Practice Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyfp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.&lt;/p&gt;\n\n&lt;p&gt;I can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.&lt;/p&gt;\n\n&lt;p&gt;What kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yoyfp2", "is_robot_indexable": true, "report_reasons": null, "author": "valentincalomme", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "subreddit_subscribers": 79247, "created_utc": 1667851177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing a lot of commuting at the moment and have. Fair few credits on audible to burn through. Any recommendations for books?\n\nI\u2019ve got DDIA, which I\u2019ve been listening to, but any others people could recommend?", "author_fullname": "t2_7x058oej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Audible books for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoj16d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667817907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing a lot of commuting at the moment and have. Fair few credits on audible to burn through. Any recommendations for books?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got DDIA, which I\u2019ve been listening to, but any others people could recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yoj16d", "is_robot_indexable": true, "report_reasons": null, "author": "Kensarim", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoj16d/audible_books_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoj16d/audible_books_for_de/", "subreddit_subscribers": 79247, "created_utc": 1667817907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.  \nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  \n\n\n* Design patterns &amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.\n* Testing: Mostly unit tests.\n* APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.\n* Errors &amp; Monitoring &amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp; logs.\n* System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)\n* RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?", "author_fullname": "t2_1yf128eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much software engineering knowledge should a data engineer know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfb1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667895269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.&lt;br/&gt;\nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Design patterns &amp;amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.&lt;/li&gt;\n&lt;li&gt;Testing: Mostly unit tests.&lt;/li&gt;\n&lt;li&gt;APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.&lt;/li&gt;\n&lt;li&gt;Errors &amp;amp; Monitoring &amp;amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp;amp; logs.&lt;/li&gt;\n&lt;li&gt;System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)&lt;/li&gt;\n&lt;li&gt;RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypfb1m", "is_robot_indexable": true, "report_reasons": null, "author": "glyphack", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "subreddit_subscribers": 79247, "created_utc": 1667895269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently running BQ but the cost is increasing a lot, so besides optimizing stuff, we would like to move to a tool where the pricing is fixed, like in Redshift, and doesn't incur more charges for running more queries.\n\nFixed in terms of hourly/yearly price, no matter how many queries you run in that specific time span. So in Redshift, you can get a medium cluster and be 24h running intensive queries that it'll cost the same as if you are running queries for 3h.\n\nWhat are other alternatives? I discard Snowflake for the same reasons as BQ. Databricks? EMR equivalent in Google Cloud? Managed Trino (don't even know if this is an option)? We need to stick to Google Cloud or SaaS", "author_fullname": "t2_qzfin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I like Redshift pricing model, but can't use AWS. Alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yop5ar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667834685.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667832524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently running BQ but the cost is increasing a lot, so besides optimizing stuff, we would like to move to a tool where the pricing is fixed, like in Redshift, and doesn&amp;#39;t incur more charges for running more queries.&lt;/p&gt;\n\n&lt;p&gt;Fixed in terms of hourly/yearly price, no matter how many queries you run in that specific time span. So in Redshift, you can get a medium cluster and be 24h running intensive queries that it&amp;#39;ll cost the same as if you are running queries for 3h.&lt;/p&gt;\n\n&lt;p&gt;What are other alternatives? I discard Snowflake for the same reasons as BQ. Databricks? EMR equivalent in Google Cloud? Managed Trino (don&amp;#39;t even know if this is an option)? We need to stick to Google Cloud or SaaS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yop5ar", "is_robot_indexable": true, "report_reasons": null, "author": "L3GOLAS234", "discussion_type": null, "num_comments": 21, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yop5ar/i_like_redshift_pricing_model_but_cant_use_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yop5ar/i_like_redshift_pricing_model_but_cant_use_aws/", "subreddit_subscribers": 79247, "created_utc": 1667832524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?\n\nMy use case is I have data stored in Snowflake and I have users (that don't know SQL at all and not willing to learn) use Snowpark and they're able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it's very convenient.\n\nIs there something similar that could be used if let's say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? \n\nI want to avoid Databricks Connect because it's janky as hell and I don't want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.\n\nThe Databricks SQL odbc for python is less cumbersome but it's really just a different way to pass SQL statements.\n\nAnyone have ideas on this?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpark equivalent on Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yov7r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667844746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?&lt;/p&gt;\n\n&lt;p&gt;My use case is I have data stored in Snowflake and I have users (that don&amp;#39;t know SQL at all and not willing to learn) use Snowpark and they&amp;#39;re able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it&amp;#39;s very convenient.&lt;/p&gt;\n\n&lt;p&gt;Is there something similar that could be used if let&amp;#39;s say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? &lt;/p&gt;\n\n&lt;p&gt;I want to avoid Databricks Connect because it&amp;#39;s janky as hell and I don&amp;#39;t want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.&lt;/p&gt;\n\n&lt;p&gt;The Databricks SQL odbc for python is less cumbersome but it&amp;#39;s really just a different way to pass SQL statements.&lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yov7r8", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "subreddit_subscribers": 79247, "created_utc": 1667844746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to choose between 2 internships  (Europe) :\n- One paid 1500\u20ac/month, no work from home possible, and more importantly no hiring possible after the internship.\n- One paid 1200\u20ac/month, 2 days / week WFH, hiring after the internship.\n\nThe content of the two internships are quite the same, however I'm afraid of not being able to get a good DE job after my internship, as I wont have a lot of experience (only 5 or 6 months). I really enjoy WFH so it could be really great if I could get a full remote position, but again I have no idea how hard it is to get those positions.\n\nWhat do you think of it?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it to get a DE junior (full remote ?) position after an internship ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoqaf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667834850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to choose between 2 internships  (Europe) :\n- One paid 1500\u20ac/month, no work from home possible, and more importantly no hiring possible after the internship.\n- One paid 1200\u20ac/month, 2 days / week WFH, hiring after the internship.&lt;/p&gt;\n\n&lt;p&gt;The content of the two internships are quite the same, however I&amp;#39;m afraid of not being able to get a good DE job after my internship, as I wont have a lot of experience (only 5 or 6 months). I really enjoy WFH so it could be really great if I could get a full remote position, but again I have no idea how hard it is to get those positions.&lt;/p&gt;\n\n&lt;p&gt;What do you think of it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yoqaf6", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoqaf6/how_hard_is_it_to_get_a_de_junior_full_remote/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoqaf6/how_hard_is_it_to_get_a_de_junior_full_remote/", "subreddit_subscribers": 79247, "created_utc": 1667834850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I migrate my project from key-value storage to column based database and also leveraging ARM based VMs. Speed, cost and compression in Clickhouse is fascinating.  A good example of using right tech in a right place. Not everything is great in Clickhouse but all issues were manageable. \n\n[https://medium.com/@Gaploid/how-i-migrate-to-clickhouse-and-speedup-my-backend-7x-and-decrease-cost-by-6x-part-1-2553251a9059](https://medium.com/@Gaploid/how-i-migrate-to-clickhouse-and-speedup-my-backend-7x-and-decrease-cost-by-6x-part-1-2553251a9059)\n\nBonus comparison Clickhouse on AMD vs ARM\n\nhttps://preview.redd.it/n5d0ql0faiy91.png?width=900&amp;format=png&amp;auto=webp&amp;s=ec539e041e88e4ef6b1e2b0dc020bb9ac735c079", "author_fullname": "t2_ho9zq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A story of migration to ClickHouse: gaining 7x at speed and decrease cost by 6x", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n5d0ql0faiy91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/n5d0ql0faiy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0273b21b7d2fefd78e81b70792bb0bee2d8baec"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/n5d0ql0faiy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7234b7e4fc885f91b1c5fe037628ac9250cc24d5"}, {"y": 254, "x": 320, "u": "https://preview.redd.it/n5d0ql0faiy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=be0c33b0f648326a123669f06bcf3a8f66ecfffc"}, {"y": 508, "x": 640, "u": "https://preview.redd.it/n5d0ql0faiy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2e4a7beea97ec3ff143572a5a194e6185d58bef6"}], "s": {"y": 715, "x": 900, "u": "https://preview.redd.it/n5d0ql0faiy91.png?width=900&amp;format=png&amp;auto=webp&amp;s=ec539e041e88e4ef6b1e2b0dc020bb9ac735c079"}, "id": "n5d0ql0faiy91"}}, "name": "t3_yoiqfr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5oV6SQJF8spt318rgOtyfDw4TmF41579r_fRrm7XOso.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1667816916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I migrate my project from key-value storage to column based database and also leveraging ARM based VMs. Speed, cost and compression in Clickhouse is fascinating.  A good example of using right tech in a right place. Not everything is great in Clickhouse but all issues were manageable. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@Gaploid/how-i-migrate-to-clickhouse-and-speedup-my-backend-7x-and-decrease-cost-by-6x-part-1-2553251a9059\"&gt;https://medium.com/@Gaploid/how-i-migrate-to-clickhouse-and-speedup-my-backend-7x-and-decrease-cost-by-6x-part-1-2553251a9059&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Bonus comparison Clickhouse on AMD vs ARM&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n5d0ql0faiy91.png?width=900&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec539e041e88e4ef6b1e2b0dc020bb9ac735c079\"&gt;https://preview.redd.it/n5d0ql0faiy91.png?width=900&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec539e041e88e4ef6b1e2b0dc020bb9ac735c079&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?auto=webp&amp;s=923d464f6d2d7dcc7cde1a3e193c8f192a8c559f", "width": 1200, "height": 902}, "resolutions": [{"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dad9110aaf58a2e67574e80b16a26b3503a1b96e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3c1b5313555fd343edd5d2c418bf649ac848298a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6bf11cd91f65ee5188c6dea4f5d1f59c3a5f732", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10f314a77ec8daf6f7a22d96b37bc8d912e0f44c", "width": 640, "height": 481}, {"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=48298183fe94a1935c006b27232ff1e101b985b9", "width": 960, "height": 721}, {"url": "https://external-preview.redd.it/od6NN6eiGA0iMCHOds7j0RY46RrDApT0oI2S8Y3uapc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6476106d76c1ea0068fbda23547e25cc406ffd9d", "width": 1080, "height": 811}], "variants": {}, "id": "WfuW4Idgmplm_vU5njU2I2ujo3RpXivguOa2XLCrIIE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yoiqfr", "is_robot_indexable": true, "report_reasons": null, "author": "Gaploid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoiqfr/a_story_of_migration_to_clickhouse_gaining_7x_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoiqfr/a_story_of_migration_to_clickhouse_gaining_7x_at/", "subreddit_subscribers": 79247, "created_utc": 1667816916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am creating a project to use for my portfolio but I have some questions regarding best practices during the ETL process vs what I know so far.\n\nI am extracting data from an API, I want to transform this data and store it in a cloud hosted db.\n\nWhat would be the real-life solution to transforming this? What ive learned so far is that I extract the data with requests, store it as raw file (csv?) and start transforming it from there to a clean version of the file (also csv?) and then go through the load process.\n\nSo my first questions are:\n\nWhy should I make turn them into CSV? or any other format? I can do all my transformations using pandas without actually every persisting any file, or is this purely for backup? And is CSV the standard to go to? why not just JSON format?\n\nWhat is the convention (real-life) of keeping these CSV files after I loaded them? Do i delete them right after? Do I delete them after x amount of time.\n\nSorry I know a bunch of questions but any help would be appreciated. thanks!", "author_fullname": "t2_6kipsr88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advise on ETL project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yotj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667841280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am creating a project to use for my portfolio but I have some questions regarding best practices during the ETL process vs what I know so far.&lt;/p&gt;\n\n&lt;p&gt;I am extracting data from an API, I want to transform this data and store it in a cloud hosted db.&lt;/p&gt;\n\n&lt;p&gt;What would be the real-life solution to transforming this? What ive learned so far is that I extract the data with requests, store it as raw file (csv?) and start transforming it from there to a clean version of the file (also csv?) and then go through the load process.&lt;/p&gt;\n\n&lt;p&gt;So my first questions are:&lt;/p&gt;\n\n&lt;p&gt;Why should I make turn them into CSV? or any other format? I can do all my transformations using pandas without actually every persisting any file, or is this purely for backup? And is CSV the standard to go to? why not just JSON format?&lt;/p&gt;\n\n&lt;p&gt;What is the convention (real-life) of keeping these CSV files after I loaded them? Do i delete them right after? Do I delete them after x amount of time.&lt;/p&gt;\n\n&lt;p&gt;Sorry I know a bunch of questions but any help would be appreciated. thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yotj3u", "is_robot_indexable": true, "report_reasons": null, "author": "Brontonomo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yotj3u/advise_on_etl_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yotj3u/advise_on_etl_project/", "subreddit_subscribers": 79247, "created_utc": 1667841280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just finished Head First SQL from awesomedataengineering and wondering where to go from here? To the next resource in the SQL section? Work on my own project? Move on to Python, then work on my own project? Any advice is helpful.", "author_fullname": "t2_blmtd0p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I follow awesomedataengineering or the dataengineering wiki?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoqtem", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667835922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just finished Head First SQL from awesomedataengineering and wondering where to go from here? To the next resource in the SQL section? Work on my own project? Move on to Python, then work on my own project? Any advice is helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yoqtem", "is_robot_indexable": true, "report_reasons": null, "author": "DisastrousChain7189", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoqtem/how_do_i_follow_awesomedataengineering_or_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoqtem/how_do_i_follow_awesomedataengineering_or_the/", "subreddit_subscribers": 79247, "created_utc": 1667835922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you or your company were involved in a **cloud database migration**, what cloud solution did you use?\n\n[View Poll](https://www.reddit.com/poll/yom9qv)", "author_fullname": "t2_gjrwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did you use for Cloud Database Migration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yom9qv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667826281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you or your company were involved in a &lt;strong&gt;cloud database migration&lt;/strong&gt;, what cloud solution did you use?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/yom9qv\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yom9qv", "is_robot_indexable": true, "report_reasons": null, "author": "prutwo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1668258281044, "options": [{"text": "Snowflake", "id": "19658179"}, {"text": "Redshift", "id": "19658180"}, {"text": "BigQuery", "id": "19658181"}, {"text": "Azure SQL Data Warehouse (Synapse)", "id": "19658182"}, {"text": "Databricks", "id": "19658183"}, {"text": "Other (please leave in comments)", "id": "19658184"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 175, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yom9qv/what_did_you_use_for_cloud_database_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/yom9qv/what_did_you_use_for_cloud_database_migration/", "subreddit_subscribers": 79247, "created_utc": 1667826281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:\n\n1. [secor](https://github.com/pinterest/secor): Seems a bit on the older side\n2. [Connector](https://github.com/aiven/gcs-connector-for-apache-kafka): Low Amount of Users\n\nAny open source tools you can recommend?", "author_fullname": "t2_f4rnp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka to GCS Persistence Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypans5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667880401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/pinterest/secor\"&gt;secor&lt;/a&gt;: Seems a bit on the older side&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/aiven/gcs-connector-for-apache-kafka\"&gt;Connector&lt;/a&gt;: Low Amount of Users&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any open source tools you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?auto=webp&amp;s=41465a6192d02528bbce28a0914098d4ae9c191a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b36284feae726cd6ec1107a93bc66c9ed005efc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f642609effe2dc5f8c969b20912f31196849bac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cc256df7c45f940fbf3c0ea344dddf49ad1133a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec7e1944e22ca9344c565b8fca772354317fa12", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bb9921cfd43f2a399ef142495769d5a8c20c8178", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a1913e065c316d6750d2d29a5539610836f654f", "width": 1080, "height": 540}], "variants": {}, "id": "Y0XtgNrn0-zLnBkJhTDof8YJNRcL7t-Bf2Zsb9CpNqc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypans5", "is_robot_indexable": true, "report_reasons": null, "author": "alwaysSearching23", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "subreddit_subscribers": 79247, "created_utc": 1667880401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. \n\nThanks", "author_fullname": "t2_6dym6exn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning material for Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp9uyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667878069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp9uyi", "is_robot_indexable": true, "report_reasons": null, "author": "StatusStar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "subreddit_subscribers": 79247, "created_utc": 1667878069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.\n\nI know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.\n\nWanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?\n\nTable volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.", "author_fullname": "t2_3x9g7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replication to new schema across RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp44pc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667862772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.&lt;/p&gt;\n\n&lt;p&gt;I know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.&lt;/p&gt;\n\n&lt;p&gt;Wanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?&lt;/p&gt;\n\n&lt;p&gt;Table volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp44pc", "is_robot_indexable": true, "report_reasons": null, "author": "iwenttocharlenes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "subreddit_subscribers": 79247, "created_utc": 1667862772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends.\n\nThere are a few hundred unhealthy videos among a few thousand videos\n\nHow can I bulk-check them?\n\nGoal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files", "author_fullname": "t2_teoa5nr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk video health check? (macOS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp1ky4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667857644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends.&lt;/p&gt;\n\n&lt;p&gt;There are a few hundred unhealthy videos among a few thousand videos&lt;/p&gt;\n\n&lt;p&gt;How can I bulk-check them?&lt;/p&gt;\n\n&lt;p&gt;Goal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp1ky4", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Chemistry7585", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp1ky4/bulk_video_health_check_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp1ky4/bulk_video_health_check_macos/", "subreddit_subscribers": 79247, "created_utc": 1667857644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which part of data science is likely to automate? Eg. Data collecting, storage, transformation or labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyxfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667852148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoyxfi", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "subreddit_subscribers": 79247, "created_utc": 1667852148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nI want to ask the ground realities of DE in Canada. What type of interviews are there and what a candidate should prepare to capture the very entry level DE job with handsome salary. Any other info/advice is also welcome. \nThanks in advance. \n\nP.S i am planning to move Canada and i am a software engineer with 10 years of experience.", "author_fullname": "t2_7r5xenrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview process for associate/entry level DE in Canada", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yojwk9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667820343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI want to ask the ground realities of DE in Canada. What type of interviews are there and what a candidate should prepare to capture the very entry level DE job with handsome salary. Any other info/advice is also welcome. \nThanks in advance. &lt;/p&gt;\n\n&lt;p&gt;P.S i am planning to move Canada and i am a software engineer with 10 years of experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "yojwk9", "is_robot_indexable": true, "report_reasons": null, "author": "Heavy_End_2971", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yojwk9/interview_process_for_associateentry_level_de_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yojwk9/interview_process_for_associateentry_level_de_in/", "subreddit_subscribers": 79247, "created_utc": 1667820343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_smq1w5ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inside the mind of a frontend developer: Hero section", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_yphewm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F-ZogjAxsvpfJkO1qIW-4z80vl6FHjb2FVGFHqC_uBY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667901419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ishadeed.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ishadeed.com/article/inside-frontend-developer-mind-hero-section/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?auto=webp&amp;s=43b81e3ba5f1de29205e4072700b2f94ebbce3ac", "width": 2400, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=16df64eb6897a6baaac38c8b7e49fea389e4c97d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=519e717eef399ea63f945a27fc8f8e158b2c5a33", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6704353833638fa62830f7e20439091a0c320b1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7019f5ed98de63c7fcc78b825746523ee2b83d80", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e77364cab671d2e9869d11ee575961da227bdb3f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Kskh6Q0QmCLEwrN6e8a9aF8X9Txyv5tOdLlyL09Ib80.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ccab78df16fc2054c1eff6fa86d28f49747f1f93", "width": 1080, "height": 540}], "variants": {}, "id": "ngPRnu9LGjwF8HDTNlcGbGAfxE5vUowOw6tws4HrBnE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yphewm", "is_robot_indexable": true, "report_reasons": null, "author": "alodiasaradith07", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yphewm/inside_the_mind_of_a_frontend_developer_hero/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ishadeed.com/article/inside-frontend-developer-mind-hero-section/", "subreddit_subscribers": 79247, "created_utc": 1667901419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Parallelization in Databricks is pretty simple. You can just use this code:  \n[https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/](https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/)\n\nI wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a gold standard when it comes to parallelization using databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfpky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667896405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parallelization in Databricks is pretty simple. You can just use this code:&lt;br/&gt;\n&lt;a href=\"https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/\"&gt;https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?auto=webp&amp;s=c1c56f4b127f9a67fce6e84a3a0743ab6f6b65eb", "width": 1081, "height": 642}, "resolutions": [{"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fda048159fdf7c1a06db01b52d2e7c94b9ac3d1d", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d779118465b89e224fdb37b3c5818935a31c6f0", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d1860336c49b9c46bc81fb83ef91703be7b757f", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35a9e8e4cab2d7252076b75a4507e6bda234d727", "width": 640, "height": 380}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad3a32aba85ddb91a39fd5847d4945df6c867941", "width": 960, "height": 570}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e47573429a4037e21316279354d0024451140d7b", "width": 1080, "height": 641}], "variants": {}, "id": "04iDH-CVszurLQEs2iwnfG3C5m3CZ7nzpSC3OWOVSR0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ypfpky", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "subreddit_subscribers": 79247, "created_utc": 1667896405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm from a South Asian country and I have been trying to land remote job opportunities in countries such as Australia, Canada, and a few countries. I have tried via Toptal, Turing, LinkedIn, Vanhack, SEEK, DBT slack channel and managed to have an interview twice, once from Germany and the other from Canada. The interview with the German company was good but could not move to the next step. With the Canadian startup company, I had the first interview with the CEO, the second with a DE, and the third with the acting Chief Operating Officer. I messed up the interview with the COO because I'm a more technical person and sometimes reply with silly answers to simple questions.\n\n1. I'm still looking for areas to improve my resume, could you please review it? [https://imgur.com/a/XGDmET4](https://imgur.com/a/XGDmET4)\n2. Are there other places to look for remote jobs for citizens from South Asian countries?\n3. How can I improve answering simple non-technical questions?\n4. I'm asking $45/hr for my work, is it much to ask?", "author_fullname": "t2_ablvw8qg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume and other advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypc19d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667884592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a South Asian country and I have been trying to land remote job opportunities in countries such as Australia, Canada, and a few countries. I have tried via Toptal, Turing, LinkedIn, Vanhack, SEEK, DBT slack channel and managed to have an interview twice, once from Germany and the other from Canada. The interview with the German company was good but could not move to the next step. With the Canadian startup company, I had the first interview with the CEO, the second with a DE, and the third with the acting Chief Operating Officer. I messed up the interview with the COO because I&amp;#39;m a more technical person and sometimes reply with silly answers to simple questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m still looking for areas to improve my resume, could you please review it? &lt;a href=\"https://imgur.com/a/XGDmET4\"&gt;https://imgur.com/a/XGDmET4&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Are there other places to look for remote jobs for citizens from South Asian countries?&lt;/li&gt;\n&lt;li&gt;How can I improve answering simple non-technical questions?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m asking $45/hr for my work, is it much to ask?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?auto=webp&amp;s=802f53834b910a0dd1525a0111bc7b168981b07d", "width": 1656, "height": 7017}, "resolutions": [{"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=355c282b4675528fa4d7ca01a68bf6737cddb1fa", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1258367fa5cd88d5e2a5a2dbe000b52ba6c686a7", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=642fb2a461cca994ee8acf2908cd7cb4248a00b7", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=61db1b207fb28c913fcc46fe3428b5d5c077df59", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d11cbb36d7c91fca0b9bb77a014081055a3d514", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99dc919c334278f6eda4203408beec663e683cce", "width": 1080, "height": 2160}], "variants": {}, "id": "nLGXN79p6Ht9ihcfpKW9uGcE1peE9pTYBbSZg0T7z7I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ypc19d", "is_robot_indexable": true, "report_reasons": null, "author": "sherocksme", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypc19d/resume_and_other_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypc19d/resume_and_other_advice/", "subreddit_subscribers": 79247, "created_utc": 1667884592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4cc8quyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - memphisdev/memphis-broker: Memphis is an Open-Source, Real-Time Data Processing Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ypboc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0Pglx59Ymn-_DxBtB_LL-EkNUbwhhJ7LZ7Vp0Xb6RBo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667883519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/memphisdev/memphis-broker", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypboc6", "is_robot_indexable": true, "report_reasons": null, "author": "hooopo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypboc6/github_memphisdevmemphisbroker_memphis_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/memphisdev/memphis-broker", "subreddit_subscribers": 79247, "created_utc": 1667883519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Free Live Workshop] Data, Meet Ops: How to delight &amp; retain customers with trustworthy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yp2r0g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nf8l7Lr65pDGSXwbC3irv9IX0jm8vcxMCUE4rY0LEHQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667859967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getcensus.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getcensus.com/events/data-meet-ops?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=Data%2C+Meet+Ops+Series&amp;utm_content=reddit-nate-c-post", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?auto=webp&amp;s=7b75d4e51e3ff9b4710047f1e7e67c5e20859a77", "width": 1501, "height": 786}, "resolutions": [{"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=faef6b2ae33453046b3270ec956bbf245f6db357", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e1d6509282e394ec4ae7316408ff042ee32db66", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=192185294bd2d0e38b2c3e94630b774206fb62da", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=97f1c7def96fef63cc5a911cd6f8239423f4b24f", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61e0c1f75022cee8897d82af5cafb5b80d20338e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfee45ea9e4ddc74b54733feebb8061845e6f796", "width": 1080, "height": 565}], "variants": {}, "id": "wcW-ojCgr1kd4NXkbVucJOBAXtYF6xvEMJqqZMM1SqE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yp2r0g", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp2r0g/free_live_workshop_data_meet_ops_how_to_delight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getcensus.com/events/data-meet-ops?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=Data%2C+Meet+Ops+Series&amp;utm_content=reddit-nate-c-post", "subreddit_subscribers": 79247, "created_utc": 1667859967.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}