{"kind": "Listing", "data": {"after": "t3_yoy6o2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?", "author_fullname": "t2_3ydamall", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are all my colleagues so weird", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp0q06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667855856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp0q06", "is_robot_indexable": true, "report_reasons": null, "author": "masta_beta69", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "subreddit_subscribers": 79281, "created_utc": 1667855856.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: Databricks vs. Snowflake - Who wins?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_yp5mbh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u_xxC_eXXOHvqK1P-bJYUEzxhxy2jS-mcrCUqSLOtYY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667866364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n3y26kqadmy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n3y26kqadmy91.png?auto=webp&amp;s=b24fdc9cc0ae55fe276059b797ff46f2af4df245", "width": 1472, "height": 995}, "resolutions": [{"url": "https://preview.redd.it/n3y26kqadmy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec7844e199a4f24ead9d3d2479ffd65e9107fd56", "width": 108, "height": 73}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ff6de90cb1af595399cf1f8027f32a804a6bbd7", "width": 216, "height": 146}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bfefd9ae47cd5cd0b1b547ff6efb2525f504d2b", "width": 320, "height": 216}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=00df4c6972e23d3d804d46f840d4d25e97610f33", "width": 640, "height": 432}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=780cf785bdc2bad8d94a25432795f137306ac787", "width": 960, "height": 648}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=62ed016f2c09205aa0c2beb47e18b0c9648c44b5", "width": 1080, "height": 730}], "variants": {}, "id": "oxyzXQH15HgTuA2-TcKRbh7Hg9z5CqYLONC7V8GiWtY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp5mbh", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp5mbh/discussion_databricks_vs_snowflake_who_wins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n3y26kqadmy91.png", "subreddit_subscribers": 79281, "created_utc": 1667866364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.  \nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  \n\n\n* Design patterns &amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.\n* Testing: Mostly unit tests.\n* APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.\n* Errors &amp; Monitoring &amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp; logs.\n* System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)\n* RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?", "author_fullname": "t2_1yf128eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much software engineering knowledge should a data engineer know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfb1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667895269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.&lt;br/&gt;\nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Design patterns &amp;amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.&lt;/li&gt;\n&lt;li&gt;Testing: Mostly unit tests.&lt;/li&gt;\n&lt;li&gt;APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.&lt;/li&gt;\n&lt;li&gt;Errors &amp;amp; Monitoring &amp;amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp;amp; logs.&lt;/li&gt;\n&lt;li&gt;System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)&lt;/li&gt;\n&lt;li&gt;RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypfb1m", "is_robot_indexable": true, "report_reasons": null, "author": "glyphack", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "subreddit_subscribers": 79281, "created_utc": 1667895269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When is it better to use each one of these? \nAlso is there a way to perform zero-copy/in-memory transformation from pyArrow to pySpark? I can't find any info on both of these topics.", "author_fullname": "t2_dlui0uup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyArrow vs pySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_you1os", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667842313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When is it better to use each one of these? \nAlso is there a way to perform zero-copy/in-memory transformation from pyArrow to pySpark? I can&amp;#39;t find any info on both of these topics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "you1os", "is_robot_indexable": true, "report_reasons": null, "author": "XtremeBanana333", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/you1os/pyarrow_vs_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/you1os/pyarrow_vs_pyspark/", "subreddit_subscribers": 79281, "created_utc": 1667842313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.\n\nI can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.\n\nWhat kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?", "author_fullname": "t2_wd6qw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Practice Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyfp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.&lt;/p&gt;\n\n&lt;p&gt;I can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.&lt;/p&gt;\n\n&lt;p&gt;What kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yoyfp2", "is_robot_indexable": true, "report_reasons": null, "author": "valentincalomme", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "subreddit_subscribers": 79281, "created_utc": 1667851177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?\n\nMy use case is I have data stored in Snowflake and I have users (that don't know SQL at all and not willing to learn) use Snowpark and they're able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it's very convenient.\n\nIs there something similar that could be used if let's say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? \n\nI want to avoid Databricks Connect because it's janky as hell and I don't want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.\n\nThe Databricks SQL odbc for python is less cumbersome but it's really just a different way to pass SQL statements.\n\nAnyone have ideas on this?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpark equivalent on Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yov7r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667844746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?&lt;/p&gt;\n\n&lt;p&gt;My use case is I have data stored in Snowflake and I have users (that don&amp;#39;t know SQL at all and not willing to learn) use Snowpark and they&amp;#39;re able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it&amp;#39;s very convenient.&lt;/p&gt;\n\n&lt;p&gt;Is there something similar that could be used if let&amp;#39;s say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? &lt;/p&gt;\n\n&lt;p&gt;I want to avoid Databricks Connect because it&amp;#39;s janky as hell and I don&amp;#39;t want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.&lt;/p&gt;\n\n&lt;p&gt;The Databricks SQL odbc for python is less cumbersome but it&amp;#39;s really just a different way to pass SQL statements.&lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yov7r8", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "subreddit_subscribers": 79281, "created_utc": 1667844746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qc1e9enq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Connector Catalog: Our team kept getting questions about which ETL vendors provide connectors to which sources. So we built an ongoing catalog to help you easily search for and find the connectors you need! Check it out and use for free: connectorcatalog.com. Hope this is helpful", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_ypmk48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fOqG2BN7uiCmw3o8xDBppGSmSkzwhlBSgrTGlO0fzpA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667914868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/htagp2l9dqy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/htagp2l9dqy91.png?auto=webp&amp;s=24e4a69b8983105bdd1a63ef2f519c220e990048", "width": 2774, "height": 1442}, "resolutions": [{"url": "https://preview.redd.it/htagp2l9dqy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f514408590bc22f18f09dced3fbb1f1a13944a4e", "width": 108, "height": 56}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b22504b373da0550a3bc0fe61a8f2e372ba84667", "width": 216, "height": 112}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=53756ee372614dd9de047c16dbd1dbb2736b3686", "width": 320, "height": 166}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=25d3f46991c4a4672e0bd6cd91a91f2890956641", "width": 640, "height": 332}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a382914a854019d0a1b168bd529b3f6f89427ef5", "width": 960, "height": 499}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f49d715768a8b380a9849f2a3d77e0fd47e05ae", "width": 1080, "height": 561}], "variants": {}, "id": "dvzW3yrABFZ3pNLtwDBanHdFjDLksWcaY6LJKhAv848"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypmk48", "is_robot_indexable": true, "report_reasons": null, "author": "alorentz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypmk48/etl_connector_catalog_our_team_kept_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/htagp2l9dqy91.png", "subreddit_subscribers": 79281, "created_utc": 1667914868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4cc8quyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - memphisdev/memphis-broker: Memphis is an Open-Source, Real-Time Data Processing Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ypboc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0Pglx59Ymn-_DxBtB_LL-EkNUbwhhJ7LZ7Vp0Xb6RBo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667883519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/memphisdev/memphis-broker", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypboc6", "is_robot_indexable": true, "report_reasons": null, "author": "hooopo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypboc6/github_memphisdevmemphisbroker_memphis_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/memphisdev/memphis-broker", "subreddit_subscribers": 79281, "created_utc": 1667883519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:\n\n1. [secor](https://github.com/pinterest/secor): Seems a bit on the older side\n2. [Connector](https://github.com/aiven/gcs-connector-for-apache-kafka): Low Amount of Users\n\nAny open source tools you can recommend?", "author_fullname": "t2_f4rnp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka to GCS Persistence Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypans5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667880401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/pinterest/secor\"&gt;secor&lt;/a&gt;: Seems a bit on the older side&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/aiven/gcs-connector-for-apache-kafka\"&gt;Connector&lt;/a&gt;: Low Amount of Users&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any open source tools you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?auto=webp&amp;s=41465a6192d02528bbce28a0914098d4ae9c191a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b36284feae726cd6ec1107a93bc66c9ed005efc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f642609effe2dc5f8c969b20912f31196849bac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cc256df7c45f940fbf3c0ea344dddf49ad1133a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec7e1944e22ca9344c565b8fca772354317fa12", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bb9921cfd43f2a399ef142495769d5a8c20c8178", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a1913e065c316d6750d2d29a5539610836f654f", "width": 1080, "height": 540}], "variants": {}, "id": "Y0XtgNrn0-zLnBkJhTDof8YJNRcL7t-Bf2Zsb9CpNqc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypans5", "is_robot_indexable": true, "report_reasons": null, "author": "alwaysSearching23", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "subreddit_subscribers": 79281, "created_utc": 1667880401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which part of data science is likely to automate? Eg. Data collecting, storage, transformation or labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyxfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667852148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoyxfi", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "subreddit_subscribers": 79281, "created_utc": 1667852148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am creating a project to use for my portfolio but I have some questions regarding best practices during the ETL process vs what I know so far.\n\nI am extracting data from an API, I want to transform this data and store it in a cloud hosted db.\n\nWhat would be the real-life solution to transforming this? What ive learned so far is that I extract the data with requests, store it as raw file (csv?) and start transforming it from there to a clean version of the file (also csv?) and then go through the load process.\n\nSo my first questions are:\n\nWhy should I make turn them into CSV? or any other format? I can do all my transformations using pandas without actually every persisting any file, or is this purely for backup? And is CSV the standard to go to? why not just JSON format?\n\nWhat is the convention (real-life) of keeping these CSV files after I loaded them? Do i delete them right after? Do I delete them after x amount of time.\n\nSorry I know a bunch of questions but any help would be appreciated. thanks!", "author_fullname": "t2_6kipsr88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advise on ETL project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yotj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667841280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am creating a project to use for my portfolio but I have some questions regarding best practices during the ETL process vs what I know so far.&lt;/p&gt;\n\n&lt;p&gt;I am extracting data from an API, I want to transform this data and store it in a cloud hosted db.&lt;/p&gt;\n\n&lt;p&gt;What would be the real-life solution to transforming this? What ive learned so far is that I extract the data with requests, store it as raw file (csv?) and start transforming it from there to a clean version of the file (also csv?) and then go through the load process.&lt;/p&gt;\n\n&lt;p&gt;So my first questions are:&lt;/p&gt;\n\n&lt;p&gt;Why should I make turn them into CSV? or any other format? I can do all my transformations using pandas without actually every persisting any file, or is this purely for backup? And is CSV the standard to go to? why not just JSON format?&lt;/p&gt;\n\n&lt;p&gt;What is the convention (real-life) of keeping these CSV files after I loaded them? Do i delete them right after? Do I delete them after x amount of time.&lt;/p&gt;\n\n&lt;p&gt;Sorry I know a bunch of questions but any help would be appreciated. thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yotj3u", "is_robot_indexable": true, "report_reasons": null, "author": "Brontonomo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yotj3u/advise_on_etl_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yotj3u/advise_on_etl_project/", "subreddit_subscribers": 79281, "created_utc": 1667841280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all! We\u2019re using Airflow at my job to orchestrate our data pipelines and I had a question regarding how y\u2019all are handling creations of schemas and/or tables for your data warehouse in your infrastructure !\n\nDo you mostly do it through your data pipeline as a step, or do you have a separate automated process that handles the creations ? \n\nI\u2019m currently in the process of reworking most of our utilities and I have been researching the best way to go through this process as I\u2019m not the biggest fan of having a task run every time for table creation if it doesn\u2019t exist. \n\nThanks in advance !", "author_fullname": "t2_38zkx7ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Warehouse Schema/Table automated creation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypjw89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667908427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! We\u2019re using Airflow at my job to orchestrate our data pipelines and I had a question regarding how y\u2019all are handling creations of schemas and/or tables for your data warehouse in your infrastructure !&lt;/p&gt;\n\n&lt;p&gt;Do you mostly do it through your data pipeline as a step, or do you have a separate automated process that handles the creations ? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently in the process of reworking most of our utilities and I have been researching the best way to go through this process as I\u2019m not the biggest fan of having a task run every time for table creation if it doesn\u2019t exist. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypjw89", "is_robot_indexable": true, "report_reasons": null, "author": "DrSnakee95", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypjw89/warehouse_schematable_automated_creation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypjw89/warehouse_schematable_automated_creation/", "subreddit_subscribers": 79281, "created_utc": 1667908427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Parallelization in Databricks is pretty simple. You can just use this code:  \n[https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/](https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/)\n\nI wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a gold standard when it comes to parallelization using databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfpky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667896405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parallelization in Databricks is pretty simple. You can just use this code:&lt;br/&gt;\n&lt;a href=\"https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/\"&gt;https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?auto=webp&amp;s=c1c56f4b127f9a67fce6e84a3a0743ab6f6b65eb", "width": 1081, "height": 642}, "resolutions": [{"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fda048159fdf7c1a06db01b52d2e7c94b9ac3d1d", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d779118465b89e224fdb37b3c5818935a31c6f0", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d1860336c49b9c46bc81fb83ef91703be7b757f", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35a9e8e4cab2d7252076b75a4507e6bda234d727", "width": 640, "height": 380}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad3a32aba85ddb91a39fd5847d4945df6c867941", "width": 960, "height": 570}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e47573429a4037e21316279354d0024451140d7b", "width": 1080, "height": 641}], "variants": {}, "id": "04iDH-CVszurLQEs2iwnfG3C5m3CZ7nzpSC3OWOVSR0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ypfpky", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "subreddit_subscribers": 79281, "created_utc": 1667896405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. \n\nThanks", "author_fullname": "t2_6dym6exn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning material for Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp9uyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667878069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp9uyi", "is_robot_indexable": true, "report_reasons": null, "author": "StatusStar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "subreddit_subscribers": 79281, "created_utc": 1667878069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.\n\nI know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.\n\nWanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?\n\nTable volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.", "author_fullname": "t2_3x9g7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replication to new schema across RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp44pc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667862772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.&lt;/p&gt;\n\n&lt;p&gt;I know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.&lt;/p&gt;\n\n&lt;p&gt;Wanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?&lt;/p&gt;\n\n&lt;p&gt;Table volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp44pc", "is_robot_indexable": true, "report_reasons": null, "author": "iwenttocharlenes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "subreddit_subscribers": 79281, "created_utc": 1667862772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends.\n\nThere are a few hundred unhealthy videos among a few thousand videos\n\nHow can I bulk-check them?\n\nGoal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files", "author_fullname": "t2_teoa5nr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk video health check? (macOS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp1ky4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667857644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends.&lt;/p&gt;\n\n&lt;p&gt;There are a few hundred unhealthy videos among a few thousand videos&lt;/p&gt;\n\n&lt;p&gt;How can I bulk-check them?&lt;/p&gt;\n\n&lt;p&gt;Goal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp1ky4", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Chemistry7585", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp1ky4/bulk_video_health_check_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp1ky4/bulk_video_health_check_macos/", "subreddit_subscribers": 79281, "created_utc": 1667857644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a Junior DE working on a project to backfill historical log data that our apps generated going back to 2017 (about \\~5.5 TB of data). The files are gzipped and there is one file per day per product. We have a data stream set up now which is ingesting todays files into Redshift.  \n\n\nI'm looking for some input or advice on paths I may take. The only approach that I've thought of so far is to:  \n1. Generate an S3 Inventory Report\n\n2. Write a Lambda that would send objects from the report to an S3 Batch Operation  \n\n\n* The questions I have are:  \nCan you send objects to a data stream when using S3 Batch Operations  \nIs the data stream needed for this one time load  \n\n\nIs there a more effective/efficient approach?", "author_fullname": "t2_4tpsvglz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Approach to loading historical log data using S3 Batch Operations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoygm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Junior DE working on a project to backfill historical log data that our apps generated going back to 2017 (about ~5.5 TB of data). The files are gzipped and there is one file per day per product. We have a data stream set up now which is ingesting todays files into Redshift.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some input or advice on paths I may take. The only approach that I&amp;#39;ve thought of so far is to:&lt;br/&gt;\n1. Generate an S3 Inventory Report&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Write a Lambda that would send objects from the report to an S3 Batch Operation&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The questions I have are:&lt;br/&gt;\nCan you send objects to a data stream when using S3 Batch Operations&lt;br/&gt;\nIs the data stream needed for this one time load&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is there a more effective/efficient approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoygm4", "is_robot_indexable": true, "report_reasons": null, "author": "cazual_penguin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoygm4/approach_to_loading_historical_log_data_using_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoygm4/approach_to_loading_historical_log_data_using_s3/", "subreddit_subscribers": 79281, "created_utc": 1667851216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an analytics engineering position interview on Friday. And other possible interviews coming up shortly. I've done some self-study on SQL on personal time and currently use it in my current role as  BI Analyst. Today, I subscribed to Stratascratch  and hope to start grinding out problems. Prior, I had made an effort to read *SQL Fundamentals* by Itzik Ben-Gan focusing mainly on the portions I currently use my role.\n\nBeing that I have an interview approaching Friday. What should be my main focus? Should I try to grind out Stratascratch or review some concepts? \n\nWhat do you guys recommend?", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for SQL portion for analytics engineering position(s). What should be my focus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ypp4ye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667920511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an analytics engineering position interview on Friday. And other possible interviews coming up shortly. I&amp;#39;ve done some self-study on SQL on personal time and currently use it in my current role as  BI Analyst. Today, I subscribed to Stratascratch  and hope to start grinding out problems. Prior, I had made an effort to read &lt;em&gt;SQL Fundamentals&lt;/em&gt; by Itzik Ben-Gan focusing mainly on the portions I currently use my role.&lt;/p&gt;\n\n&lt;p&gt;Being that I have an interview approaching Friday. What should be my main focus? Should I try to grind out Stratascratch or review some concepts? &lt;/p&gt;\n\n&lt;p&gt;What do you guys recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ypp4ye", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypp4ye/preparing_for_sql_portion_for_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypp4ye/preparing_for_sql_portion_for_analytics/", "subreddit_subscribers": 79281, "created_utc": 1667920511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is-it possible to create a data source in denodo from a microsoft sharepoint (List) by using the query.iqy generated when we use the feature \"export to excel\" ?", "author_fullname": "t2_t4dkdc3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Denodo &lt;=&gt; Sharepoint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yponds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is-it possible to create a data source in denodo from a microsoft sharepoint (List) by using the query.iqy generated when we use the feature &amp;quot;export to excel&amp;quot; ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yponds", "is_robot_indexable": true, "report_reasons": null, "author": "Moosh_Be", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yponds/denodo_sharepoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yponds/denodo_sharepoint/", "subreddit_subscribers": 79281, "created_utc": 1667919482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With certain companies/industries still growing their data capabilities, and other companies/industries scaling back the headcount, how is this affecting your feelings about job switching?\n\nI've found it to be difficult to truly gauge how current business is doing at the companies and the direction of their data team during interviews.", "author_fullname": "t2_a2hwqab5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the current job market affect likelihood of switching companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypoeqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667918949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With certain companies/industries still growing their data capabilities, and other companies/industries scaling back the headcount, how is this affecting your feelings about job switching?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found it to be difficult to truly gauge how current business is doing at the companies and the direction of their data team during interviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypoeqt", "is_robot_indexable": true, "report_reasons": null, "author": "Crumbsinmypack", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypoeqt/does_the_current_job_market_affect_likelihood_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypoeqt/does_the_current_job_market_affect_likelihood_of/", "subreddit_subscribers": 79281, "created_utc": 1667918949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading a tech newsletter the other day and came across [SPL](http://c.raqsoft.com/article/1640597143990?utm_source=tldr&amp;utm_medium=email-paid&amp;utm_campaign=gl-wb-2022-06-22-execute-SQL-without-RDB&amp;utm_term=camp-gl&amp;utm_content=execute-SQL-without-RDB). I was surprised to not find much online about others using it. It seems to me like a viable solution for making API calls more declarative, which could be nice. Is anyone using this in any projects? If so, are you working with it on the command line or through something like a python API?", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SPL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yplh49", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667912368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading a tech newsletter the other day and came across &lt;a href=\"http://c.raqsoft.com/article/1640597143990?utm_source=tldr&amp;amp;utm_medium=email-paid&amp;amp;utm_campaign=gl-wb-2022-06-22-execute-SQL-without-RDB&amp;amp;utm_term=camp-gl&amp;amp;utm_content=execute-SQL-without-RDB\"&gt;SPL&lt;/a&gt;. I was surprised to not find much online about others using it. It seems to me like a viable solution for making API calls more declarative, which could be nice. Is anyone using this in any projects? If so, are you working with it on the command line or through something like a python API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?auto=webp&amp;s=64c95fdac1da4c0b0d9d07d8c8b3d937a95dcc1e", "width": 720, "height": 377}, "resolutions": [{"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=817d4e7f2d4fc5899b50457f4d41e7432e24ff02", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1527decf123172a807b16dbbb5fd69e3f608ded9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=067583090b65ac6cb23c19d05eeb6037a8025653", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f18931ce9c4ef7e6787db84c6d498e7aae2afe4", "width": 640, "height": 335}], "variants": {}, "id": "CsekJbW__-1RAOvhmJbiKWzgN3MMqENzNxsyLD4wPVc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yplh49", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yplh49/spl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yplh49/spl/", "subreddit_subscribers": 79281, "created_utc": 1667912368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. If you work with data, I am sure that you heard something about metrics. I wrote an article where I compare two approaches (about metrics definition). I would appreciate your feedback! Thanks! \u2764\ufe0f\n\n[https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3](https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to write good metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypkmra", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667910291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. If you work with data, I am sure that you heard something about metrics. I wrote an article where I compare two approaches (about metrics definition). I would appreciate your feedback! Thanks! \u2764\ufe0f&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3\"&gt;https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?auto=webp&amp;s=5265a42727701f60a712216232b956f56f96a546", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0952d3e6429ba1ec1c3cbdd8e8c287d2f905e71b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e73bc700b9a6ac39ef702edbd6d4f7fdcb58db95", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d2dc00e2b2fa5c48ae09308d311907ebe188b7a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=16f5d80fe864329673314bb01345f837f7ce697c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fae43295fcd2bbda8aa7053ca3812cae5d43521b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeab5c7c25bf0f63e774731af7f4c7e693c68368", "width": 1080, "height": 567}], "variants": {}, "id": "lXVNCTBPoVnk8P4ZguwDS7tvo-uIAeq_FJ8eO-EqtRg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ypkmra", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypkmra/how_to_write_good_metrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypkmra/how_to_write_good_metrics/", "subreddit_subscribers": 79281, "created_utc": 1667910291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm from a South Asian country and I have been trying to land remote job opportunities in countries such as Australia, Canada, and a few countries. I have tried via Toptal, Turing, LinkedIn, Vanhack, SEEK, DBT slack channel and managed to have an interview twice, once from Germany and the other from Canada. The interview with the German company was good but could not move to the next step. With the Canadian startup company, I had the first interview with the CEO, the second with a DE, and the third with the acting Chief Operating Officer. I messed up the interview with the COO because I'm a more technical person and sometimes reply with silly answers to simple questions.\n\n1. I'm still looking for areas to improve my resume, could you please review it? [https://imgur.com/a/XGDmET4](https://imgur.com/a/XGDmET4)\n2. Are there other places to look for remote jobs for citizens from South Asian countries?\n3. How can I improve answering simple non-technical questions?\n4. I'm asking $45/hr for my work, is it much to ask?", "author_fullname": "t2_ablvw8qg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume and other advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypc19d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667884592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a South Asian country and I have been trying to land remote job opportunities in countries such as Australia, Canada, and a few countries. I have tried via Toptal, Turing, LinkedIn, Vanhack, SEEK, DBT slack channel and managed to have an interview twice, once from Germany and the other from Canada. The interview with the German company was good but could not move to the next step. With the Canadian startup company, I had the first interview with the CEO, the second with a DE, and the third with the acting Chief Operating Officer. I messed up the interview with the COO because I&amp;#39;m a more technical person and sometimes reply with silly answers to simple questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m still looking for areas to improve my resume, could you please review it? &lt;a href=\"https://imgur.com/a/XGDmET4\"&gt;https://imgur.com/a/XGDmET4&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Are there other places to look for remote jobs for citizens from South Asian countries?&lt;/li&gt;\n&lt;li&gt;How can I improve answering simple non-technical questions?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m asking $45/hr for my work, is it much to ask?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?auto=webp&amp;s=802f53834b910a0dd1525a0111bc7b168981b07d", "width": 1656, "height": 7017}, "resolutions": [{"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=355c282b4675528fa4d7ca01a68bf6737cddb1fa", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1258367fa5cd88d5e2a5a2dbe000b52ba6c686a7", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=642fb2a461cca994ee8acf2908cd7cb4248a00b7", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=61db1b207fb28c913fcc46fe3428b5d5c077df59", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d11cbb36d7c91fca0b9bb77a014081055a3d514", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99dc919c334278f6eda4203408beec663e683cce", "width": 1080, "height": 2160}], "variants": {}, "id": "nLGXN79p6Ht9ihcfpKW9uGcE1peE9pTYBbSZg0T7z7I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ypc19d", "is_robot_indexable": true, "report_reasons": null, "author": "sherocksme", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypc19d/resume_and_other_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypc19d/resume_and_other_advice/", "subreddit_subscribers": 79281, "created_utc": 1667884592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Free Live Workshop] Data, Meet Ops: How to delight &amp; retain customers with trustworthy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yp2r0g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nf8l7Lr65pDGSXwbC3irv9IX0jm8vcxMCUE4rY0LEHQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667859967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getcensus.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getcensus.com/events/data-meet-ops?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=Data%2C+Meet+Ops+Series&amp;utm_content=reddit-nate-c-post", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?auto=webp&amp;s=7b75d4e51e3ff9b4710047f1e7e67c5e20859a77", "width": 1501, "height": 786}, "resolutions": [{"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=faef6b2ae33453046b3270ec956bbf245f6db357", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e1d6509282e394ec4ae7316408ff042ee32db66", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=192185294bd2d0e38b2c3e94630b774206fb62da", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=97f1c7def96fef63cc5a911cd6f8239423f4b24f", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61e0c1f75022cee8897d82af5cafb5b80d20338e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfee45ea9e4ddc74b54733feebb8061845e6f796", "width": 1080, "height": 565}], "variants": {}, "id": "wcW-ojCgr1kd4NXkbVucJOBAXtYF6xvEMJqqZMM1SqE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yp2r0g", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp2r0g/free_live_workshop_data_meet_ops_how_to_delight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getcensus.com/events/data-meet-ops?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=Data%2C+Meet+Ops+Series&amp;utm_content=reddit-nate-c-post", "subreddit_subscribers": 79281, "created_utc": 1667859967.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, I am running into problems with running PySpark along with Kafka. \"spark.readStream\" functions don't work for my apps whatever I try to run it with. I have tried methods that included Docker containers with Kafka but they do not work. I am not too familiar with neither of these frameworks and I do not want to spend another few hours fighting with them, therefore I would like to ask you if you could send any guide with solution that works 100% for you.  \n\n\nMy sole requirement is that it has to work with Windows/WSL.", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for ways to integrate PySpark with Kafka locally on Windows/WSL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoy6o2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667850628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I am running into problems with running PySpark along with Kafka. &amp;quot;spark.readStream&amp;quot; functions don&amp;#39;t work for my apps whatever I try to run it with. I have tried methods that included Docker containers with Kafka but they do not work. I am not too familiar with neither of these frameworks and I do not want to spend another few hours fighting with them, therefore I would like to ask you if you could send any guide with solution that works 100% for you.  &lt;/p&gt;\n\n&lt;p&gt;My sole requirement is that it has to work with Windows/WSL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yoy6o2", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoy6o2/looking_for_ways_to_integrate_pyspark_with_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoy6o2/looking_for_ways_to_integrate_pyspark_with_kafka/", "subreddit_subscribers": 79281, "created_utc": 1667850628.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}