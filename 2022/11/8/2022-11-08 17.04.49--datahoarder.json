{"kind": "Listing", "data": {"after": "t3_ypp022", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_c9yytte1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After 4 months of researching my first 50TB NAS is running. Thank you.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_ypeuey", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RQhSJXNR-Y_ln3KTEEJEW31qAMKhfOBddnVCr5VG438.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667893977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/58ufyeclnoy91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?auto=webp&amp;s=2c0be2afe7c17805c8031208d7630ecd2bb03495", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38cc627fb9c7be01951be9bff943071442a71b8e", "width": 108, "height": 144}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3f577150474a042253908a9aaf1c6ce95c77d94", "width": 216, "height": 288}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6ad278aec414805e39b8a61277021ddef593acd", "width": 320, "height": 426}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=76d74ee42102ae02f02df3713cde29de231e4e7c", "width": 640, "height": 853}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0043c8103b700c1308fb4dd82b07574a50f5ff11", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/58ufyeclnoy91.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=152a18dee29c28875fa8481c054f13cef1d27016", "width": 1080, "height": 1440}], "variants": {}, "id": "QzfTHmHU1fPnXtElQTxW0lCMyit-GMN_ZtGOzsE-jGs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypeuey", "is_robot_indexable": true, "report_reasons": null, "author": "slavsetup", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypeuey/after_4_months_of_researching_my_first_50tb_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/58ufyeclnoy91.jpg", "subreddit_subscribers": 652440, "created_utc": 1667893977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "consider this question without using a faraday cage apparatus to protect it &amp; also consider using one. Let's talk about both approaches.-Thanks.  EDIT: I should have mentioned a cloud in the list too.", "author_fullname": "t2_nvkg0kma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you have an offline harddrive, SSHD, SSD, USB, or SD card, can EMP or a solar flare damage them? Which one would be least likely to be damaged? Also...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypam3s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667881966.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667880268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;consider this question without using a faraday cage apparatus to protect it &amp;amp; also consider using one. Let&amp;#39;s talk about both approaches.-Thanks.  EDIT: I should have mentioned a cloud in the list too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypam3s", "is_robot_indexable": true, "report_reasons": null, "author": "FuckReddit442", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypam3s/if_you_have_an_offline_harddrive_sshd_ssd_usb_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypam3s/if_you_have_an_offline_harddrive_sshd_ssd_usb_or/", "subreddit_subscribers": 652440, "created_utc": 1667880268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It was disappointing that I was struggling to find well seeded or existing classic release Linux distros that were so easy to find when they were first released.\n\nThen I discovered Usenet. My eyes have been opened.", "author_fullname": "t2_b8r6aj5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After years of hoarding, and then several years without, I felt like I missed out on the golden age.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypnmbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Editable Flair", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667917216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It was disappointing that I was struggling to find well seeded or existing classic release Linux distros that were so easy to find when they were first released.&lt;/p&gt;\n\n&lt;p&gt;Then I discovered Usenet. My eyes have been opened.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "ypnmbt", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Professional3832", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypnmbt/after_years_of_hoarding_and_then_several_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypnmbt/after_years_of_hoarding_and_then_several_years/", "subreddit_subscribers": 652440, "created_utc": 1667917216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My question is essentially the title and mostly comes from idle curiosity. Do they not make 2.5\" CMR drives anymore? I know seagate has one in their EXOS lineup ($600 for 2TB here... Sheesh) and a couple models from 2015~2017 seem to be CMR but that's about it. I knew 4TB+ was all SMR but I thought a few 1TB or 2TB models would still be CMR.\n\nThe reason I'm asking (which makes less sense the more I think about it) is because I was looking for some cheap local storage for an SFF secondary build. The drive is expected to write 300~500GB and read ~1.5x that amount per day. If the drive was SMR and randomly kept dropping to 15MBps, I'd be better of just accessing the data from the network instead.\n\nTBW is where I ran into my first issue. Regular laptop HDDs (the one's I was expecting to find) are only rated for 55TB/Y. My estimated usage blows that out of the water meaning I should be looking at the EXOS lineup with 550TB/Y. But those are so expensive I'd be better off getting a decent SSD instead.\n\nNow I have to figure out if I want to save $100, forgo the SSD and just read the data from my server instead of buying an SSD and caching data locally...", "author_fullname": "t2_q6dz0zvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do 2.5\" CMR drives just not exist anymore?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypik0j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667904745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My question is essentially the title and mostly comes from idle curiosity. Do they not make 2.5&amp;quot; CMR drives anymore? I know seagate has one in their EXOS lineup ($600 for 2TB here... Sheesh) and a couple models from 2015~2017 seem to be CMR but that&amp;#39;s about it. I knew 4TB+ was all SMR but I thought a few 1TB or 2TB models would still be CMR.&lt;/p&gt;\n\n&lt;p&gt;The reason I&amp;#39;m asking (which makes less sense the more I think about it) is because I was looking for some cheap local storage for an SFF secondary build. The drive is expected to write 300~500GB and read ~1.5x that amount per day. If the drive was SMR and randomly kept dropping to 15MBps, I&amp;#39;d be better of just accessing the data from the network instead.&lt;/p&gt;\n\n&lt;p&gt;TBW is where I ran into my first issue. Regular laptop HDDs (the one&amp;#39;s I was expecting to find) are only rated for 55TB/Y. My estimated usage blows that out of the water meaning I should be looking at the EXOS lineup with 550TB/Y. But those are so expensive I&amp;#39;d be better off getting a decent SSD instead.&lt;/p&gt;\n\n&lt;p&gt;Now I have to figure out if I want to save $100, forgo the SSD and just read the data from my server instead of buying an SSD and caching data locally...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "vTrueNAS 72TB ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypik0j", "is_robot_indexable": true, "report_reasons": null, "author": "KRS_88", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypik0j/do_25_cmr_drives_just_not_exist_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypik0j/do_25_cmr_drives_just_not_exist_anymore/", "subreddit_subscribers": 652440, "created_utc": 1667904745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought an external SSD from Cricial (model X8) and just checked the serial number in their software as part of testing it for defects.  \n\n\nTurns out the serial number from the software does not match the one printed on the box and the ssd.   \n\n\nIt could make sense though since it is basically a P1 SSD in the enclosure but need to make sure if this is normal.   \n\n\nIn short, the serial number on the box and SSD are the same but the serial number viewed from software is different", "author_fullname": "t2_2eil511t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External SSD (Crucial X8) has a different serial number showing in software than the box and even the one printed on te ssd case. Is this normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypayb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667881252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought an external SSD from Cricial (model X8) and just checked the serial number in their software as part of testing it for defects.  &lt;/p&gt;\n\n&lt;p&gt;Turns out the serial number from the software does not match the one printed on the box and the ssd.   &lt;/p&gt;\n\n&lt;p&gt;It could make sense though since it is basically a P1 SSD in the enclosure but need to make sure if this is normal.   &lt;/p&gt;\n\n&lt;p&gt;In short, the serial number on the box and SSD are the same but the serial number viewed from software is different&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypayb0", "is_robot_indexable": true, "report_reasons": null, "author": "N3n9fjj299fj3y", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypayb0/external_ssd_crucial_x8_has_a_different_serial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypayb0/external_ssd_crucial_x8_has_a_different_serial/", "subreddit_subscribers": 652440, "created_utc": 1667881252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know of a good 3.5\" to 5.25\" adapter for the new WD screw hole standard that the 14TB drives use? \n\nI just recently bought 4, 14TB drives and ran out of 3.5 bays to use in my Enthoo Pro 1 and would like to put the 3, 5.25 bays to work.\n\nThanks", "author_fullname": "t2_5hsmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3.5\" to 5.25\" Adapter for Shucked Easystore 14TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp50x7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667864840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a good 3.5&amp;quot; to 5.25&amp;quot; adapter for the new WD screw hole standard that the 14TB drives use? &lt;/p&gt;\n\n&lt;p&gt;I just recently bought 4, 14TB drives and ran out of 3.5 bays to use in my Enthoo Pro 1 and would like to put the 3, 5.25 bays to work.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yp50x7", "is_robot_indexable": true, "report_reasons": null, "author": "SuperBio", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yp50x7/35_to_525_adapter_for_shucked_easystore_14tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yp50x7/35_to_525_adapter_for_shucked_easystore_14tb/", "subreddit_subscribers": 652440, "created_utc": 1667864840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends. I get no error from the player.\n\nThere are a few hundred unhealthy videos among a few thousand videos\n\nHow can I bulk-check them?\n\nGoal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files", "author_fullname": "t2_teoa5nr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk video health check? (macOS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp32wi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667867016.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667860638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends. I get no error from the player.&lt;/p&gt;\n\n&lt;p&gt;There are a few hundred unhealthy videos among a few thousand videos&lt;/p&gt;\n\n&lt;p&gt;How can I bulk-check them?&lt;/p&gt;\n\n&lt;p&gt;Goal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yp32wi", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Chemistry7585", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yp32wi/bulk_video_health_check_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yp32wi/bulk_video_health_check_macos/", "subreddit_subscribers": 652440, "created_utc": 1667860638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "as the title says, I have some films on my drive that are missing metadata (title, author, that kinda stuff) and have been wondering if any of you know a tool that can add that to them automatically, kinda like Uniconverter does with its metadata fixer tool but for free. I don't know if this is the right sub for this but any help would be appreciated!\n\nedit: I'm on windows btw.", "author_fullname": "t2_1ovofknf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "add metadata to movie files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yozc8b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667883999.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667853011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;as the title says, I have some films on my drive that are missing metadata (title, author, that kinda stuff) and have been wondering if any of you know a tool that can add that to them automatically, kinda like Uniconverter does with its metadata fixer tool but for free. I don&amp;#39;t know if this is the right sub for this but any help would be appreciated!&lt;/p&gt;\n\n&lt;p&gt;edit: I&amp;#39;m on windows btw.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yozc8b", "is_robot_indexable": true, "report_reasons": null, "author": "gagaboom", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yozc8b/add_metadata_to_movie_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yozc8b/add_metadata_to_movie_files/", "subreddit_subscribers": 652440, "created_utc": 1667853011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a tool that helps you keep a clean directory structure by setting your own rules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yov84t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7bolrppf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rust", "selftext": "https://github.com/Unoqwy/shinydir\n\nI spent the weekend making this tool that can report any misplaced files in your system according to rules you set. This is useful to keep you in check and avoid postponing organizing directories for months.\n\nFor now, it's able to **check directories and report misplaced files** and **automatically move according to rules you set**. Both features are quite configurable (e.g. you can use the auto-move feature to make monthly directories), you can check out the README. There is certainly room for improvement on how rules are defined- if you can think of a better way, feel free to share it.\n\nI've been programming in Rust for a while but this is my first published crate, any feedback is appreciated \ud83d\ude42\n\nhttps://github.com/Unoqwy/shinydir/blob/master/demo/demo.gif", "author_fullname": "t2_7bolrppf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "shinydir: A CLI tool to enforce clean directories by setting rules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rust", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ynynnj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667760141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rust", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/Unoqwy/shinydir\"&gt;https://github.com/Unoqwy/shinydir&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I spent the weekend making this tool that can report any misplaced files in your system according to rules you set. This is useful to keep you in check and avoid postponing organizing directories for months.&lt;/p&gt;\n\n&lt;p&gt;For now, it&amp;#39;s able to &lt;strong&gt;check directories and report misplaced files&lt;/strong&gt; and &lt;strong&gt;automatically move according to rules you set&lt;/strong&gt;. Both features are quite configurable (e.g. you can use the auto-move feature to make monthly directories), you can check out the README. There is certainly room for improvement on how rules are defined- if you can think of a better way, feel free to share it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been programming in Rust for a while but this is my first published crate, any feedback is appreciated \ud83d\ude42&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Unoqwy/shinydir/blob/master/demo/demo.gif\"&gt;https://github.com/Unoqwy/shinydir/blob/master/demo/demo.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?auto=webp&amp;s=c6e7ce66f30b2a6cb835dd0e7ea3e52c2080ffbf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e0c48942b39ca669d349dbc0f821a5784f1de6a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e1cc8c24ff3dd78b7ced85078fa4cd016af5054b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1bfe4613a7e692702a3a96d1aa5de984d0f756e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=47e41927da39ef60b5d98926c6c59bd4b8d8b9e1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=41e1dbe4575cd3a377480a750be8e42cf0d42139", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f192cd11f57c3c3554eb0d93f8c5533ac09d220", "width": 1080, "height": 540}], "variants": {}, "id": "-Y352YSCAoPydWY6geEwvPhr5g8OPhMDZd3G7QVMizs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s7lj", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ynynnj", "is_robot_indexable": true, "report_reasons": null, "author": "Unoqwy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rust/comments/ynynnj/shinydir_a_cli_tool_to_enforce_clean_directories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/rust/comments/ynynnj/shinydir_a_cli_tool_to_enforce_clean_directories/", "subreddit_subscribers": 206032, "created_utc": 1667760141.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1667844768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rust", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/rust/comments/ynynnj/shinydir_a_cli_tool_to_enforce_clean_directories/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?auto=webp&amp;s=c6e7ce66f30b2a6cb835dd0e7ea3e52c2080ffbf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e0c48942b39ca669d349dbc0f821a5784f1de6a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e1cc8c24ff3dd78b7ced85078fa4cd016af5054b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1bfe4613a7e692702a3a96d1aa5de984d0f756e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=47e41927da39ef60b5d98926c6c59bd4b8d8b9e1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=41e1dbe4575cd3a377480a750be8e42cf0d42139", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/FwjCcF3ncwS4NZwMdKj9jTUyJ23aGgzAqWo5ZGmN_yg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f192cd11f57c3c3554eb0d93f8c5533ac09d220", "width": 1080, "height": 540}], "variants": {}, "id": "-Y352YSCAoPydWY6geEwvPhr5g8OPhMDZd3G7QVMizs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yov84t", "is_robot_indexable": true, "report_reasons": null, "author": "Unoqwy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_ynynnj", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yov84t/i_made_a_tool_that_helps_you_keep_a_clean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rust/comments/ynynnj/shinydir_a_cli_tool_to_enforce_clean_directories/", "subreddit_subscribers": 652440, "created_utc": 1667844768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Source code: https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py\n\nWindows executable: https://github.com/n0x5/scripts/releases/tag/google_vision_v2\n\nThis script uploads an image to the Google Cloud Vision AI and then saves the entire result in a .json file in the same folder as the image. The downside is you need a google account and billing enabled in Google Cloud dashboard, but there are 1000 requests / month for free which is pretty usable IMO.\n\nThe resulting .json file looks like this: https://i.imgur.com/lCQBYH5.png\n\nYou can pass 2 parameters:\n\n--file &lt;filepath&gt; - for single image recognition\n\n--folder &lt;folderpath&gt; for recursive scan of an entire folder.\n\nI also created an .exe that doesn't need Python or the libraries installed. It is compiled with pyinstaller. \n\nSetup guide:\n\n1) Go to https://console.developers.google.com/\n\n2) Click 'Credentials' in left side menu\n\n3) Create \"create credentials\" - &gt; \"OAuth client ID\"\n\n4) Select \"Desktop app\" in \"Application type\". Use any name you want, mine is \"Desktop client 1\"\n\n5) Go back to the Credentials main page and click the Download OAuth client link to the left of the \"Desktop client 1\" in the list.\n\n6) The .json file downloads in browser, so just rename it to \"credentials.json\" and place it in the same folder as Vision_API_V2.py/exe and then run it with --file to a single file to initiate.\n\n7) The browser will open to a Google page to authorize the app to access the account, click accept etc. Finished.\n\nSetup guide for python:\n\nIf you don't want to use the executable and you don't have Python you have to go to www.python.org, download the latest version, then run the following command:\n\n    pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nAfter this you should follow the earlier guide to setup Google OAuth.\n\nAlso some extra info:\n\nI wasn't sure what format or database to save it to, so I thought it's better to just save the .json as it is from google because no matter what the format, you need some sort of program to parse it anyway (although the .json is just a text file you can open in text editor). I did think about creating some kind of browser/UI but open to any suggestions for how to store it or how to parse it or any other things. Thanks", "author_fullname": "t2_378xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a script to recursively scan an image folder to Google Vision AI for image recognition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yppphp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667921706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Source code: &lt;a href=\"https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py\"&gt;https://github.com/n0x5/scripts/blob/master/Google_Vision_API.py&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Windows executable: &lt;a href=\"https://github.com/n0x5/scripts/releases/tag/google_vision_v2\"&gt;https://github.com/n0x5/scripts/releases/tag/google_vision_v2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This script uploads an image to the Google Cloud Vision AI and then saves the entire result in a .json file in the same folder as the image. The downside is you need a google account and billing enabled in Google Cloud dashboard, but there are 1000 requests / month for free which is pretty usable IMO.&lt;/p&gt;\n\n&lt;p&gt;The resulting .json file looks like this: &lt;a href=\"https://i.imgur.com/lCQBYH5.png\"&gt;https://i.imgur.com/lCQBYH5.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can pass 2 parameters:&lt;/p&gt;\n\n&lt;p&gt;--file &amp;lt;filepath&amp;gt; - for single image recognition&lt;/p&gt;\n\n&lt;p&gt;--folder &amp;lt;folderpath&amp;gt; for recursive scan of an entire folder.&lt;/p&gt;\n\n&lt;p&gt;I also created an .exe that doesn&amp;#39;t need Python or the libraries installed. It is compiled with pyinstaller. &lt;/p&gt;\n\n&lt;p&gt;Setup guide:&lt;/p&gt;\n\n&lt;p&gt;1) Go to &lt;a href=\"https://console.developers.google.com/\"&gt;https://console.developers.google.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2) Click &amp;#39;Credentials&amp;#39; in left side menu&lt;/p&gt;\n\n&lt;p&gt;3) Create &amp;quot;create credentials&amp;quot; - &amp;gt; &amp;quot;OAuth client ID&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;4) Select &amp;quot;Desktop app&amp;quot; in &amp;quot;Application type&amp;quot;. Use any name you want, mine is &amp;quot;Desktop client 1&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;5) Go back to the Credentials main page and click the Download OAuth client link to the left of the &amp;quot;Desktop client 1&amp;quot; in the list.&lt;/p&gt;\n\n&lt;p&gt;6) The .json file downloads in browser, so just rename it to &amp;quot;credentials.json&amp;quot; and place it in the same folder as Vision_API_V2.py/exe and then run it with --file to a single file to initiate.&lt;/p&gt;\n\n&lt;p&gt;7) The browser will open to a Google page to authorize the app to access the account, click accept etc. Finished.&lt;/p&gt;\n\n&lt;p&gt;Setup guide for python:&lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t want to use the executable and you don&amp;#39;t have Python you have to go to &lt;a href=\"http://www.python.org\"&gt;www.python.org&lt;/a&gt;, download the latest version, then run the following command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;After this you should follow the earlier guide to setup Google OAuth.&lt;/p&gt;\n\n&lt;p&gt;Also some extra info:&lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t sure what format or database to save it to, so I thought it&amp;#39;s better to just save the .json as it is from google because no matter what the format, you need some sort of program to parse it anyway (although the .json is just a text file you can open in text editor). I did think about creating some kind of browser/UI but open to any suggestions for how to store it or how to parse it or any other things. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?auto=webp&amp;s=c01c055b663941fe246888572be1bf8be8a7a520", "width": 681, "height": 771}, "resolutions": [{"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=099014c1e935a6ae87abe7dd725cde5ca5b4fc68", "width": 108, "height": 122}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e199c542005f3799ad9cf24eb0a0f437acd7a67", "width": 216, "height": 244}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=420a13a82cbd157af63aa8d94d15e65220611697", "width": 320, "height": 362}, {"url": "https://external-preview.redd.it/58lLBZWBn8ZQDBYUtBVYgCEOjYmZKxM3laULJHC7FVU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2bbe4578b3feb1d6d8b1a80a9f1892bd1f56027", "width": 640, "height": 724}], "variants": {}, "id": "Ch5PxhWuk4icRlGEXHG3CoUrcSxfmnWtCOcXnvvSr3I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yppphp", "is_robot_indexable": true, "report_reasons": null, "author": "ouija", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yppphp/i_created_a_script_to_recursively_scan_an_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yppphp/i_created_a_script_to_recursively_scan_an_image/", "subreddit_subscribers": 652440, "created_utc": 1667921706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there any issue running a NAS drive by itself in a home PC? I have the ability to get both new for a heavy discounted price, but wanted to know if there's some reason I shouldn't use a Red NAS drive by itself. I really don't plan to use more than 8TB and I can live with 6, but since both are about the same price for me I figured I'd get the extra 2TB assuming there's no weird issue NAS would cause me. It's mainly a movie, TV, and audio book drive.\n\nBoth have 256 cache and run at 7200 rpm", "author_fullname": "t2_pmvtsac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Red Plus NAS 8TB vs Black 6TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypnsee", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667917584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any issue running a NAS drive by itself in a home PC? I have the ability to get both new for a heavy discounted price, but wanted to know if there&amp;#39;s some reason I shouldn&amp;#39;t use a Red NAS drive by itself. I really don&amp;#39;t plan to use more than 8TB and I can live with 6, but since both are about the same price for me I figured I&amp;#39;d get the extra 2TB assuming there&amp;#39;s no weird issue NAS would cause me. It&amp;#39;s mainly a movie, TV, and audio book drive.&lt;/p&gt;\n\n&lt;p&gt;Both have 256 cache and run at 7200 rpm&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypnsee", "is_robot_indexable": true, "report_reasons": null, "author": "non_degenerate_furry", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypnsee/wd_red_plus_nas_8tb_vs_black_6tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypnsee/wd_red_plus_nas_8tb_vs_black_6tb/", "subreddit_subscribers": 652440, "created_utc": 1667917584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to expand my hoard with a lot of ebooks, as I recently got an older iPad and want to get back into reading. I know Kaggle has a WikiBooks dataset but I was thinking more like sci-fi/fantasy stuff. Anyone know of good sources to start a digital library?", "author_fullname": "t2_mr4t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good place to find large collections of ebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypn5m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to expand my hoard with a lot of ebooks, as I recently got an older iPad and want to get back into reading. I know Kaggle has a WikiBooks dataset but I was thinking more like sci-fi/fantasy stuff. Anyone know of good sources to start a digital library?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1PB goal", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypn5m3", "is_robot_indexable": true, "report_reasons": null, "author": "grabmyrooster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/ypn5m3/good_place_to_find_large_collections_of_ebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypn5m3/good_place_to_find_large_collections_of_ebooks/", "subreddit_subscribers": 652440, "created_utc": 1667916203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just have to download the title of every game I come across, even if it's just part of an email advertisement.  I burned through a 4tb drive in 3 months once.  I was thinking make a list of games I come across, up to maybe 25, wait a week and see if I still want them.  The silly thing is that these will probably be on trackers or 5 cents on steam in 10 years, but my hoarding tells me I can't take that risk.  Strangely I'm not too worried about my organic burnt bluray data discs going bad - maybe I just threw my arms up and figured it was impossible, impractical or too expensive to transfer off them.\n\nOh yeah, I'll never play them but \"Don't download until you're cleared your backlog\" doesn't work.  I tell myself when I get too old to go outside and do much, I can play them all then.  If I can't e.g get an xbox 360 game that I could easily have gotten 10 years ago I get pretty mad at myself.", "author_fullname": "t2_d5sfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategy to deal with my datahoarding? (Mainly games)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypl5e7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667911566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just have to download the title of every game I come across, even if it&amp;#39;s just part of an email advertisement.  I burned through a 4tb drive in 3 months once.  I was thinking make a list of games I come across, up to maybe 25, wait a week and see if I still want them.  The silly thing is that these will probably be on trackers or 5 cents on steam in 10 years, but my hoarding tells me I can&amp;#39;t take that risk.  Strangely I&amp;#39;m not too worried about my organic burnt bluray data discs going bad - maybe I just threw my arms up and figured it was impossible, impractical or too expensive to transfer off them.&lt;/p&gt;\n\n&lt;p&gt;Oh yeah, I&amp;#39;ll never play them but &amp;quot;Don&amp;#39;t download until you&amp;#39;re cleared your backlog&amp;quot; doesn&amp;#39;t work.  I tell myself when I get too old to go outside and do much, I can play them all then.  If I can&amp;#39;t e.g get an xbox 360 game that I could easily have gotten 10 years ago I get pretty mad at myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypl5e7", "is_robot_indexable": true, "report_reasons": null, "author": "bluejeans90210", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypl5e7/strategy_to_deal_with_my_datahoarding_mainly_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypl5e7/strategy_to_deal_with_my_datahoarding_mainly_games/", "subreddit_subscribers": 652440, "created_utc": 1667911566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any fellow brits taking advantage of the 20% off WD Red Plus drives this week from Western Digital store? or waiting for Black Friday/Cyber Monday deals?\n\nCoupon: REDMEMBERS\n\nThanks.", "author_fullname": "t2_5zzb2oat", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[UK] WD members only coupon offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypdx4j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667890887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any fellow brits taking advantage of the 20% off WD Red Plus drives this week from Western Digital store? or waiting for Black Friday/Cyber Monday deals?&lt;/p&gt;\n\n&lt;p&gt;Coupon: REDMEMBERS&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypdx4j", "is_robot_indexable": true, "report_reasons": null, "author": "rectoid247", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypdx4j/uk_wd_members_only_coupon_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypdx4j/uk_wd_members_only_coupon_offer/", "subreddit_subscribers": 652440, "created_utc": 1667890887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried looking at this on the internet, but have found several conflicting answers. I'd like to use a 4tb or 8tb External HDD for some old video project files that I just don't need quick immediate access to. I'd just like to put it on there, and then forget about it until I maybe need it for something. Each video project with all assets is about 10gb.\n\n&amp;#x200B;\n\nNot necessarily looking in to like a NAS or second pc or something like that.\n\n&amp;#x200B;\n\nIf I go through with this, would leaving it plugged in or unplugged be okay?", "author_fullname": "t2_jc7km0ri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using an External HDD for mass storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp2c12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667859151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried looking at this on the internet, but have found several conflicting answers. I&amp;#39;d like to use a 4tb or 8tb External HDD for some old video project files that I just don&amp;#39;t need quick immediate access to. I&amp;#39;d just like to put it on there, and then forget about it until I maybe need it for something. Each video project with all assets is about 10gb.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not necessarily looking in to like a NAS or second pc or something like that.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If I go through with this, would leaving it plugged in or unplugged be okay?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yp2c12", "is_robot_indexable": true, "report_reasons": null, "author": "Initial-Complex7477", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yp2c12/using_an_external_hdd_for_mass_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yp2c12/using_an_external_hdd_for_mass_storage/", "subreddit_subscribers": 652440, "created_utc": 1667859151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u2ets22i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there OCR software for scanned physical census documents? (example below, documents are accessible so can retake)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_yovlwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/v0dVJP6qsP3uV_2MVNwmiGhJlRy2QAfVMJYcpU9J_Po.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667845516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/j0ycmpa8nky91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/j0ycmpa8nky91.png?auto=webp&amp;s=73e40834acb5e609a2ccca58c6bd2505c666e09a", "width": 1712, "height": 944}, "resolutions": [{"url": "https://preview.redd.it/j0ycmpa8nky91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=118778c9d8beb41068ea744fb4648e48469cf229", "width": 108, "height": 59}, {"url": "https://preview.redd.it/j0ycmpa8nky91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=90b51ebada3f41fb535acda040862d4e285bc4bf", "width": 216, "height": 119}, {"url": "https://preview.redd.it/j0ycmpa8nky91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f120e03083ca455ff883a287c9b09753f0b05df3", "width": 320, "height": 176}, {"url": "https://preview.redd.it/j0ycmpa8nky91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=34668649c369e5c704691415e1cf52bbe4e389c0", "width": 640, "height": 352}, {"url": "https://preview.redd.it/j0ycmpa8nky91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=54758b1fda60057c03d7bdd01d0c86a4e1f31859", "width": 960, "height": 529}, {"url": "https://preview.redd.it/j0ycmpa8nky91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=feb135abbd497be5a7300ca85e81ee0f56ebdcfa", "width": 1080, "height": 595}], "variants": {}, "id": "-YiBkHCQeUOa4g1SP5uGS7K5CoVyJnaciWZbW2zmoPY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yovlwf", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Calendar4413", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yovlwf/is_there_ocr_software_for_scanned_physical_census/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/j0ycmpa8nky91.png", "subreddit_subscribers": 652440, "created_utc": 1667845516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\\-Thanks.", "author_fullname": "t2_nvkg0kma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I read that SSD's last the longest? compared to Hard drives? So does this mean they are the better investment? Is there something better than SSD? -Thanks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yppxz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667922219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;-Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yppxz4", "is_robot_indexable": true, "report_reasons": null, "author": "FuckReddit442", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yppxz4/i_read_that_ssds_last_the_longest_compared_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yppxz4/i_read_that_ssds_last_the_longest_compared_to/", "subreddit_subscribers": 652440, "created_utc": 1667922219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Had a drive fail in my 6x4TB raidz1 pool today and wondering the best way to insure I save my data. There is no other backup of the data (I know, shame me) and the drives are old and some are smr so another failure during resilver is possible.\n\nNow the data is a mix of music, movies and photos. The photos account for around 1 TB, music a few hundred gigs and movies about 13TB. The photos are most important as I can't replace those of I lose them but the music and movies could be replaced tho it would be a pain.\n\nMy thought is to copy the photos to another pool while this one is still degraded and then resilver the pool. If i lose a drive while copying it wasn't going to survive the resilver anyways and I get some of my data, if the copy completes and then a drive dies in resilver I save my photos which is what I care most about.\n\nAny flaws with this plan? Is there a better way to go about this?", "author_fullname": "t2_fpuhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Degraded Z1 zpool and copying data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ypperd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667921071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had a drive fail in my 6x4TB raidz1 pool today and wondering the best way to insure I save my data. There is no other backup of the data (I know, shame me) and the drives are old and some are smr so another failure during resilver is possible.&lt;/p&gt;\n\n&lt;p&gt;Now the data is a mix of music, movies and photos. The photos account for around 1 TB, music a few hundred gigs and movies about 13TB. The photos are most important as I can&amp;#39;t replace those of I lose them but the music and movies could be replaced tho it would be a pain.&lt;/p&gt;\n\n&lt;p&gt;My thought is to copy the photos to another pool while this one is still degraded and then resilver the pool. If i lose a drive while copying it wasn&amp;#39;t going to survive the resilver anyways and I get some of my data, if the copy completes and then a drive dies in resilver I save my photos which is what I care most about.&lt;/p&gt;\n\n&lt;p&gt;Any flaws with this plan? Is there a better way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypperd", "is_robot_indexable": true, "report_reasons": null, "author": "TKFT_ExTr3m3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypperd/degraded_z1_zpool_and_copying_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypperd/degraded_z1_zpool_and_copying_data/", "subreddit_subscribers": 652440, "created_utc": 1667921071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm archiving my DVDs to plex but I wanna keep the backups in case but also eliminate the bulky DVD boxes. Anyone know the BEST way to keep DVDs protected? any DVD wallet you recommend?", "author_fullname": "t2_13lu9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best way to protect DVD scratches??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ypp0mm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667920259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m archiving my DVDs to plex but I wanna keep the backups in case but also eliminate the bulky DVD boxes. Anyone know the BEST way to keep DVDs protected? any DVD wallet you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypp0mm", "is_robot_indexable": true, "report_reasons": null, "author": "electrowiz64", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypp0mm/best_way_to_protect_dvd_scratches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypp0mm/best_way_to_protect_dvd_scratches/", "subreddit_subscribers": 652440, "created_utc": 1667920259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When I finished grad school, one of the few perks I got was a google account with unlimited storage for both email and Google Drive. At the time, it was going to last essentially forever. But Google changed its deals with educational customers, and they're discontinuing the Google Drive portion.\n\nI've got about 1.5 TB of junk up there, but it's my junk. I need to move it somewhere cloud based b/c I share a ton of it, and I'm not a fan of Dropbox. I've done the usual search of comparisons and such, but I thought I'd ask here if the sub has suggestions for a semi-casual alternative to Google Drive that isn't ridiculously expensive. (To me \"ridiculous\" is more than $10/month. $100/year for a few TBs seems manageable.) But I do share those files a lot with folk, so I'd hope it would be something easy to share and reasonably intuitive to organize.\n\nSo... do you guys have favorites?", "author_fullname": "t2_8nnfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to Google Drive for multiple TBs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yporcc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I finished grad school, one of the few perks I got was a google account with unlimited storage for both email and Google Drive. At the time, it was going to last essentially forever. But Google changed its deals with educational customers, and they&amp;#39;re discontinuing the Google Drive portion.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got about 1.5 TB of junk up there, but it&amp;#39;s my junk. I need to move it somewhere cloud based b/c I share a ton of it, and I&amp;#39;m not a fan of Dropbox. I&amp;#39;ve done the usual search of comparisons and such, but I thought I&amp;#39;d ask here if the sub has suggestions for a semi-casual alternative to Google Drive that isn&amp;#39;t ridiculously expensive. (To me &amp;quot;ridiculous&amp;quot; is more than $10/month. $100/year for a few TBs seems manageable.) But I do share those files a lot with folk, so I&amp;#39;d hope it would be something easy to share and reasonably intuitive to organize.&lt;/p&gt;\n\n&lt;p&gt;So... do you guys have favorites?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "yporcc", "is_robot_indexable": true, "report_reasons": null, "author": "mummifiedstalin", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/yporcc/alternatives_to_google_drive_for_multiple_tbs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/yporcc/alternatives_to_google_drive_for_multiple_tbs/", "subreddit_subscribers": 652440, "created_utc": 1667919702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had an issue and I fee like there are too many brilliant people on this sub for there to not be some kind of solution or recommendation for it.    \n\n\nI'm looking to setup a tagging and indexing system for my documents collection and was wondering if anyone could recommend the best software approach. I have several TB worth of documents (PDF, Doc, txt, and Epub etc.) as well as video (avi, mp4, m4v), images (png, jpg, tif), and audio files and I want away to \n\n* Filter by file type(s)\n* Manually assign tags to them and filter by those tags\n* Have a way to index specific files (mostly the document files), so that their contents are also searchable. \n\nHas anyone created a system that could do this? Was this a custom solution or is there existing software?", "author_fullname": "t2_9dk8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a tagging and search system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypopme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had an issue and I fee like there are too many brilliant people on this sub for there to not be some kind of solution or recommendation for it.    &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to setup a tagging and indexing system for my documents collection and was wondering if anyone could recommend the best software approach. I have several TB worth of documents (PDF, Doc, txt, and Epub etc.) as well as video (avi, mp4, m4v), images (png, jpg, tif), and audio files and I want away to &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Filter by file type(s)&lt;/li&gt;\n&lt;li&gt;Manually assign tags to them and filter by those tags&lt;/li&gt;\n&lt;li&gt;Have a way to index specific files (mostly the document files), so that their contents are also searchable. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Has anyone created a system that could do this? Was this a custom solution or is there existing software?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypopme", "is_robot_indexable": true, "report_reasons": null, "author": "funke75", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypopme/setting_up_a_tagging_and_search_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypopme/setting_up_a_tagging_and_search_system/", "subreddit_subscribers": 652440, "created_utc": 1667919613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nFirst time posting here and just wanted some opinions.  \n\nSo I'm cleaning out my IT closet and found a perfectly good old PC.  Nothing special just the unit I used to get thru college.\n\nI'm thinking of implementing TruNAS on it.  It is a i3 2gen intel with 16gigs ram.  I figured I'd throw a couple SSD in it and just use it as a NAS. No GPU and plane jane heat sync.\n\nDo you guys think it will work? What type of performance do you think I can get out of it? (i'll be storing movies, music on it)  What CPU works best for it?", "author_fullname": "t2_6g3iru0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old PC into a NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypmhyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667914731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;First time posting here and just wanted some opinions.  &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m cleaning out my IT closet and found a perfectly good old PC.  Nothing special just the unit I used to get thru college.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of implementing TruNAS on it.  It is a i3 2gen intel with 16gigs ram.  I figured I&amp;#39;d throw a couple SSD in it and just use it as a NAS. No GPU and plane jane heat sync.&lt;/p&gt;\n\n&lt;p&gt;Do you guys think it will work? What type of performance do you think I can get out of it? (i&amp;#39;ll be storing movies, music on it)  What CPU works best for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypmhyk", "is_robot_indexable": true, "report_reasons": null, "author": "KaiSimple", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypmhyk/old_pc_into_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypmhyk/old_pc_into_a_nas/", "subreddit_subscribers": 652440, "created_utc": 1667914731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking to archive our Town\u2019s public Facebook page, is this possible? I saw archive-it can do this but requires one of their paid services. Curious if there are any other services that can assist in this.", "author_fullname": "t2_gfvtm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving Public Facebook Page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypj64k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667906449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to archive our Town\u2019s public Facebook page, is this possible? I saw archive-it can do this but requires one of their paid services. Curious if there are any other services that can assist in this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypj64k", "is_robot_indexable": true, "report_reasons": null, "author": "marcachusetts", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypj64k/archiving_public_facebook_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypj64k/archiving_public_facebook_page/", "subreddit_subscribers": 652440, "created_utc": 1667906449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had pretty good luck with used HDDs over the years, and I have a set of tests I run when I get them in that lets me feel comfortable using them.  \n  \nOn the other hand, a used (flash) SSD is easy enough to deal with.  \n  \nBut tonight I won an auction for a \"user refurbished\" Optane p4800x drive.  \nThe price was low enough to justify the hassle of playing the real/fake, DOA, shady refurbishment dance considering Ebay's policies. (~$0.27/GiB).  \n  \n### Questions  \n  \n1. Do I treat it like a flash SSD and just check the SMART values for time/errors/%used?  \n  \n2. Are there any more intensive tests that I should do?  \n  \n3. I'm assuming that if things work when I plug it in, the drive itself isn't likely to have been directly tampered with like a fake low-end SSD. Is this a reasonable assumption? Or should I go through the process of doing a full drive write?  \n  \n4. Assuming everything else checks out, what do you all consider \"reasonable use %\" on an enterprise Optane drive?  \n  \n   Getting a Flash SSD with 15-20% usage remaining would be an instant **NOPE**. But this is an Optane drive.  \n  \n   I'm planning on using it as a system drive for my primary machine in a new build. If the drive reports it is 80% used up, then it still has ~8 **PETABYTES** of writes left. For reference, that is more than 13x a fresh [Samsung 980 PRO 1TB](https://semiconductor.samsung.com/resources/data-sheet/Samsung-NVMe-SSD-980-PRO-Data-Sheet_Rev.2.1.pdf). Does that seem completely reasonable?  \n  \n   But I don't have any experience with Optane drives that have more than 5% use. Either everything is fine, or it has literally exploded.  \n  \n   (Literally. Not figuratively. I've lost 3x of the little 16GB drives in external USB enclosures with a spark and a pop. There are solder splatters on the inside of the enclosure and the board is scorched. And I also lost my precious 118GB drive that I'm STILL fighting to get replaced. The enclosure manufacturer insists they are not responsible for replacing a drive that their enclosure damages. Amazon is being less than helpful.)  \n  \n   Is there anything I should look for in a drive with heavy usage? Are there different kinds of failures to look out for?  \n  \n----------  \n  \nAt the end of the day this is still a serious expense, even if it WAS way underpriced. So I'm looking for as much information as I can get so I have as much of the return/DOA period as possible to test things.  \n  \nThanks", "author_fullname": "t2_c4ozd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] How would you test a used Optane drive. (Not HDD or NAND SSD)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypbfuf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667882749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had pretty good luck with used HDDs over the years, and I have a set of tests I run when I get them in that lets me feel comfortable using them.  &lt;/p&gt;\n\n&lt;p&gt;On the other hand, a used (flash) SSD is easy enough to deal with.  &lt;/p&gt;\n\n&lt;p&gt;But tonight I won an auction for a &amp;quot;user refurbished&amp;quot; Optane p4800x drive.&lt;br/&gt;\nThe price was low enough to justify the hassle of playing the real/fake, DOA, shady refurbishment dance considering Ebay&amp;#39;s policies. (~$0.27/GiB).  &lt;/p&gt;\n\n&lt;h3&gt;Questions&lt;/h3&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Do I treat it like a flash SSD and just check the SMART values for time/errors/%used?  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are there any more intensive tests that I should do?  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;m assuming that if things work when I plug it in, the drive itself isn&amp;#39;t likely to have been directly tampered with like a fake low-end SSD. Is this a reasonable assumption? Or should I go through the process of doing a full drive write?  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Assuming everything else checks out, what do you all consider &amp;quot;reasonable use %&amp;quot; on an enterprise Optane drive?  &lt;/p&gt;\n\n&lt;p&gt;Getting a Flash SSD with 15-20% usage remaining would be an instant &lt;strong&gt;NOPE&lt;/strong&gt;. But this is an Optane drive.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using it as a system drive for my primary machine in a new build. If the drive reports it is 80% used up, then it still has ~8 &lt;strong&gt;PETABYTES&lt;/strong&gt; of writes left. For reference, that is more than 13x a fresh &lt;a href=\"https://semiconductor.samsung.com/resources/data-sheet/Samsung-NVMe-SSD-980-PRO-Data-Sheet_Rev.2.1.pdf\"&gt;Samsung 980 PRO 1TB&lt;/a&gt;. Does that seem completely reasonable?  &lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t have any experience with Optane drives that have more than 5% use. Either everything is fine, or it has literally exploded.  &lt;/p&gt;\n\n&lt;p&gt;(Literally. Not figuratively. I&amp;#39;ve lost 3x of the little 16GB drives in external USB enclosures with a spark and a pop. There are solder splatters on the inside of the enclosure and the board is scorched. And I also lost my precious 118GB drive that I&amp;#39;m STILL fighting to get replaced. The enclosure manufacturer insists they are not responsible for replacing a drive that their enclosure damages. Amazon is being less than helpful.)  &lt;/p&gt;\n\n&lt;p&gt;Is there anything I should look for in a drive with heavy usage? Are there different kinds of failures to look out for?  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;At the end of the day this is still a serious expense, even if it WAS way underpriced. So I&amp;#39;m looking for as much information as I can get so I have as much of the return/DOA period as possible to test things.  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypbfuf", "is_robot_indexable": true, "report_reasons": null, "author": "Prophes0r", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypbfuf/question_how_would_you_test_a_used_optane_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypbfuf/question_how_would_you_test_a_used_optane_drive/", "subreddit_subscribers": 652440, "created_utc": 1667882749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nI\u2019m looking for a website that can grab embedded videos found in any given page and provide a direct link for it. This way I can use my Documents app (works like a download manager) to download the link directly. I only have access to my iphone so I can only use it to make the downloads. I tried keepvid.to but they\u2019re impossibly slow and simply not practical. Aloha app works well at grabbing and downloading but they\u2019re also extremely slow, even after paying their bullshit subscription to \u201cboost\u201d speed. Would really appreciate if someone knows of a website that can grab embedded videos and provide a direct link. Thanks!", "author_fullname": "t2_20cjb0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedded video link grabber?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ypp022", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667920224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for a website that can grab embedded videos found in any given page and provide a direct link for it. This way I can use my Documents app (works like a download manager) to download the link directly. I only have access to my iphone so I can only use it to make the downloads. I tried keepvid.to but they\u2019re impossibly slow and simply not practical. Aloha app works well at grabbing and downloading but they\u2019re also extremely slow, even after paying their bullshit subscription to \u201cboost\u201d speed. Would really appreciate if someone knows of a website that can grab embedded videos and provide a direct link. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "ypp022", "is_robot_indexable": true, "report_reasons": null, "author": "warmlobster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/ypp022/embedded_video_link_grabber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/ypp022/embedded_video_link_grabber/", "subreddit_subscribers": 652440, "created_utc": 1667920224.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}