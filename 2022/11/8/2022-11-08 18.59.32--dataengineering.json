{"kind": "Listing", "data": {"after": "t3_yoy6o2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?", "author_fullname": "t2_3ydamall", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are all my colleagues so weird", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp0q06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667855856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp0q06", "is_robot_indexable": true, "report_reasons": null, "author": "masta_beta69", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "subreddit_subscribers": 79293, "created_utc": 1667855856.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.  \nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  \n\n\n* Design patterns &amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.\n* Testing: Mostly unit tests.\n* APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.\n* Errors &amp; Monitoring &amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp; logs.\n* System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)\n* RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?", "author_fullname": "t2_1yf128eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much software engineering knowledge should a data engineer know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfb1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667895269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.&lt;br/&gt;\nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Design patterns &amp;amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.&lt;/li&gt;\n&lt;li&gt;Testing: Mostly unit tests.&lt;/li&gt;\n&lt;li&gt;APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.&lt;/li&gt;\n&lt;li&gt;Errors &amp;amp; Monitoring &amp;amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp;amp; logs.&lt;/li&gt;\n&lt;li&gt;System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)&lt;/li&gt;\n&lt;li&gt;RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypfb1m", "is_robot_indexable": true, "report_reasons": null, "author": "glyphack", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "subreddit_subscribers": 79293, "created_utc": 1667895269.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: Databricks vs. Snowflake - Who wins?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_yp5mbh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u_xxC_eXXOHvqK1P-bJYUEzxhxy2jS-mcrCUqSLOtYY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667866364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n3y26kqadmy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n3y26kqadmy91.png?auto=webp&amp;s=b24fdc9cc0ae55fe276059b797ff46f2af4df245", "width": 1472, "height": 995}, "resolutions": [{"url": "https://preview.redd.it/n3y26kqadmy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec7844e199a4f24ead9d3d2479ffd65e9107fd56", "width": 108, "height": 73}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ff6de90cb1af595399cf1f8027f32a804a6bbd7", "width": 216, "height": 146}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bfefd9ae47cd5cd0b1b547ff6efb2525f504d2b", "width": 320, "height": 216}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=00df4c6972e23d3d804d46f840d4d25e97610f33", "width": 640, "height": 432}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=780cf785bdc2bad8d94a25432795f137306ac787", "width": 960, "height": 648}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=62ed016f2c09205aa0c2beb47e18b0c9648c44b5", "width": 1080, "height": 730}], "variants": {}, "id": "oxyzXQH15HgTuA2-TcKRbh7Hg9z5CqYLONC7V8GiWtY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp5mbh", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp5mbh/discussion_databricks_vs_snowflake_who_wins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n3y26kqadmy91.png", "subreddit_subscribers": 79293, "created_utc": 1667866364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.\n\nI can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.\n\nWhat kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?", "author_fullname": "t2_wd6qw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Practice Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyfp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.&lt;/p&gt;\n\n&lt;p&gt;I can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.&lt;/p&gt;\n\n&lt;p&gt;What kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yoyfp2", "is_robot_indexable": true, "report_reasons": null, "author": "valentincalomme", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "subreddit_subscribers": 79293, "created_utc": 1667851177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?\n\nMy use case is I have data stored in Snowflake and I have users (that don't know SQL at all and not willing to learn) use Snowpark and they're able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it's very convenient.\n\nIs there something similar that could be used if let's say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? \n\nI want to avoid Databricks Connect because it's janky as hell and I don't want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.\n\nThe Databricks SQL odbc for python is less cumbersome but it's really just a different way to pass SQL statements.\n\nAnyone have ideas on this?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpark equivalent on Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yov7r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667844746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?&lt;/p&gt;\n\n&lt;p&gt;My use case is I have data stored in Snowflake and I have users (that don&amp;#39;t know SQL at all and not willing to learn) use Snowpark and they&amp;#39;re able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it&amp;#39;s very convenient.&lt;/p&gt;\n\n&lt;p&gt;Is there something similar that could be used if let&amp;#39;s say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? &lt;/p&gt;\n\n&lt;p&gt;I want to avoid Databricks Connect because it&amp;#39;s janky as hell and I don&amp;#39;t want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.&lt;/p&gt;\n\n&lt;p&gt;The Databricks SQL odbc for python is less cumbersome but it&amp;#39;s really just a different way to pass SQL statements.&lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yov7r8", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "subreddit_subscribers": 79293, "created_utc": 1667844746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qc1e9enq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Connector Catalog: Our team kept getting questions about which ETL vendors provide connectors to which sources. So we built an ongoing catalog to help you easily search for and find the connectors you need! Check it out and use for free: connectorcatalog.com. Hope this is helpful", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_ypmk48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fOqG2BN7uiCmw3o8xDBppGSmSkzwhlBSgrTGlO0fzpA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667914868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/htagp2l9dqy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/htagp2l9dqy91.png?auto=webp&amp;s=24e4a69b8983105bdd1a63ef2f519c220e990048", "width": 2774, "height": 1442}, "resolutions": [{"url": "https://preview.redd.it/htagp2l9dqy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f514408590bc22f18f09dced3fbb1f1a13944a4e", "width": 108, "height": 56}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b22504b373da0550a3bc0fe61a8f2e372ba84667", "width": 216, "height": 112}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=53756ee372614dd9de047c16dbd1dbb2736b3686", "width": 320, "height": 166}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=25d3f46991c4a4672e0bd6cd91a91f2890956641", "width": 640, "height": 332}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a382914a854019d0a1b168bd529b3f6f89427ef5", "width": 960, "height": 499}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f49d715768a8b380a9849f2a3d77e0fd47e05ae", "width": 1080, "height": 561}], "variants": {}, "id": "dvzW3yrABFZ3pNLtwDBanHdFjDLksWcaY6LJKhAv848"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypmk48", "is_robot_indexable": true, "report_reasons": null, "author": "alorentz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypmk48/etl_connector_catalog_our_team_kept_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/htagp2l9dqy91.png", "subreddit_subscribers": 79293, "created_utc": 1667914868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4cc8quyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - memphisdev/memphis-broker: Memphis is an Open-Source, Real-Time Data Processing Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ypboc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0Pglx59Ymn-_DxBtB_LL-EkNUbwhhJ7LZ7Vp0Xb6RBo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667883519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/memphisdev/memphis-broker", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypboc6", "is_robot_indexable": true, "report_reasons": null, "author": "hooopo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypboc6/github_memphisdevmemphisbroker_memphis_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/memphisdev/memphis-broker", "subreddit_subscribers": 79293, "created_utc": 1667883519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:\n\n1. [secor](https://github.com/pinterest/secor): Seems a bit on the older side\n2. [Connector](https://github.com/aiven/gcs-connector-for-apache-kafka): Low Amount of Users\n\nAny open source tools you can recommend?", "author_fullname": "t2_f4rnp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka to GCS Persistence Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypans5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667880401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/pinterest/secor\"&gt;secor&lt;/a&gt;: Seems a bit on the older side&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/aiven/gcs-connector-for-apache-kafka\"&gt;Connector&lt;/a&gt;: Low Amount of Users&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any open source tools you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?auto=webp&amp;s=41465a6192d02528bbce28a0914098d4ae9c191a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b36284feae726cd6ec1107a93bc66c9ed005efc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f642609effe2dc5f8c969b20912f31196849bac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cc256df7c45f940fbf3c0ea344dddf49ad1133a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec7e1944e22ca9344c565b8fca772354317fa12", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bb9921cfd43f2a399ef142495769d5a8c20c8178", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a1913e065c316d6750d2d29a5539610836f654f", "width": 1080, "height": 540}], "variants": {}, "id": "Y0XtgNrn0-zLnBkJhTDof8YJNRcL7t-Bf2Zsb9CpNqc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypans5", "is_robot_indexable": true, "report_reasons": null, "author": "alwaysSearching23", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "subreddit_subscribers": 79293, "created_utc": 1667880401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which part of data science is likely to automate? Eg. Data collecting, storage, transformation or labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyxfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667852148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoyxfi", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "subreddit_subscribers": 79293, "created_utc": 1667852148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With certain companies/industries still growing their data capabilities, and other companies/industries scaling back the headcount, how is this affecting your feelings about job switching?\n\nI've found it to be difficult to truly gauge how current business is doing at the companies and the direction of their data team during interviews.", "author_fullname": "t2_a2hwqab5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the current job market affect likelihood of switching companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypoeqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667918949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With certain companies/industries still growing their data capabilities, and other companies/industries scaling back the headcount, how is this affecting your feelings about job switching?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found it to be difficult to truly gauge how current business is doing at the companies and the direction of their data team during interviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypoeqt", "is_robot_indexable": true, "report_reasons": null, "author": "Crumbsinmypack", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypoeqt/does_the_current_job_market_affect_likelihood_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypoeqt/does_the_current_job_market_affect_likelihood_of/", "subreddit_subscribers": 79293, "created_utc": 1667918949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all! We\u2019re using Airflow at my job to orchestrate our data pipelines and I had a question regarding how y\u2019all are handling creations of schemas and/or tables for your data warehouse in your infrastructure !\n\nDo you mostly do it through your data pipeline as a step, or do you have a separate automated process that handles the creations ? \n\nI\u2019m currently in the process of reworking most of our utilities and I have been researching the best way to go through this process as I\u2019m not the biggest fan of having a task run every time for table creation if it doesn\u2019t exist. \n\nThanks in advance !", "author_fullname": "t2_38zkx7ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Warehouse Schema/Table automated creation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypjw89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667908427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! We\u2019re using Airflow at my job to orchestrate our data pipelines and I had a question regarding how y\u2019all are handling creations of schemas and/or tables for your data warehouse in your infrastructure !&lt;/p&gt;\n\n&lt;p&gt;Do you mostly do it through your data pipeline as a step, or do you have a separate automated process that handles the creations ? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently in the process of reworking most of our utilities and I have been researching the best way to go through this process as I\u2019m not the biggest fan of having a task run every time for table creation if it doesn\u2019t exist. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypjw89", "is_robot_indexable": true, "report_reasons": null, "author": "DrSnakee95", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypjw89/warehouse_schematable_automated_creation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypjw89/warehouse_schematable_automated_creation/", "subreddit_subscribers": 79293, "created_utc": 1667908427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Parallelization in Databricks is pretty simple. You can just use this code:  \n[https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/](https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/)\n\nI wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a gold standard when it comes to parallelization using databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfpky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667896405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parallelization in Databricks is pretty simple. You can just use this code:&lt;br/&gt;\n&lt;a href=\"https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/\"&gt;https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?auto=webp&amp;s=c1c56f4b127f9a67fce6e84a3a0743ab6f6b65eb", "width": 1081, "height": 642}, "resolutions": [{"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fda048159fdf7c1a06db01b52d2e7c94b9ac3d1d", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d779118465b89e224fdb37b3c5818935a31c6f0", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d1860336c49b9c46bc81fb83ef91703be7b757f", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35a9e8e4cab2d7252076b75a4507e6bda234d727", "width": 640, "height": 380}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad3a32aba85ddb91a39fd5847d4945df6c867941", "width": 960, "height": 570}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e47573429a4037e21316279354d0024451140d7b", "width": 1080, "height": 641}], "variants": {}, "id": "04iDH-CVszurLQEs2iwnfG3C5m3CZ7nzpSC3OWOVSR0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ypfpky", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "subreddit_subscribers": 79293, "created_utc": 1667896405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. \n\nThanks", "author_fullname": "t2_6dym6exn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning material for Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp9uyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667878069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp9uyi", "is_robot_indexable": true, "report_reasons": null, "author": "StatusStar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "subreddit_subscribers": 79293, "created_utc": 1667878069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.\n\nI know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.\n\nWanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?\n\nTable volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.", "author_fullname": "t2_3x9g7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replication to new schema across RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp44pc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667862772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.&lt;/p&gt;\n\n&lt;p&gt;I know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.&lt;/p&gt;\n\n&lt;p&gt;Wanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?&lt;/p&gt;\n\n&lt;p&gt;Table volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp44pc", "is_robot_indexable": true, "report_reasons": null, "author": "iwenttocharlenes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "subreddit_subscribers": 79293, "created_utc": 1667862772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a Junior DE working on a project to backfill historical log data that our apps generated going back to 2017 (about \\~5.5 TB of data). The files are gzipped and there is one file per day per product. We have a data stream set up now which is ingesting todays files into Redshift.  \n\n\nI'm looking for some input or advice on paths I may take. The only approach that I've thought of so far is to:  \n1. Generate an S3 Inventory Report\n\n2. Write a Lambda that would send objects from the report to an S3 Batch Operation  \n\n\n* The questions I have are:  \nCan you send objects to a data stream when using S3 Batch Operations  \nIs the data stream needed for this one time load  \n\n\nIs there a more effective/efficient approach?", "author_fullname": "t2_4tpsvglz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Approach to loading historical log data using S3 Batch Operations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoygm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Junior DE working on a project to backfill historical log data that our apps generated going back to 2017 (about ~5.5 TB of data). The files are gzipped and there is one file per day per product. We have a data stream set up now which is ingesting todays files into Redshift.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some input or advice on paths I may take. The only approach that I&amp;#39;ve thought of so far is to:&lt;br/&gt;\n1. Generate an S3 Inventory Report&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Write a Lambda that would send objects from the report to an S3 Batch Operation&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The questions I have are:&lt;br/&gt;\nCan you send objects to a data stream when using S3 Batch Operations&lt;br/&gt;\nIs the data stream needed for this one time load&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is there a more effective/efficient approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoygm4", "is_robot_indexable": true, "report_reasons": null, "author": "cazual_penguin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoygm4/approach_to_loading_historical_log_data_using_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoygm4/approach_to_loading_historical_log_data_using_s3/", "subreddit_subscribers": 79293, "created_utc": 1667851216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our finance department have brought in SAP Business ByDesign and are engaging an external consultancy for reporting.  \n\nDue to the extortionate quote they\u2019ve received, I\u2019ve been tasked with trying to offer an internal solution.\n\nI can\u2019t find any SAP documentation on how to connect to their cloud databases.\n\nBest I can find is an Excel connector.\n\nAll suggestions appreciated", "author_fullname": "t2_6pc6xjl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting data from SAP Analytics Cloud. Anyone here have experience with this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yps473", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667926915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our finance department have brought in SAP Business ByDesign and are engaging an external consultancy for reporting.  &lt;/p&gt;\n\n&lt;p&gt;Due to the extortionate quote they\u2019ve received, I\u2019ve been tasked with trying to offer an internal solution.&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t find any SAP documentation on how to connect to their cloud databases.&lt;/p&gt;\n\n&lt;p&gt;Best I can find is an Excel connector.&lt;/p&gt;\n\n&lt;p&gt;All suggestions appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yps473", "is_robot_indexable": true, "report_reasons": null, "author": "tawaiii", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yps473/extracting_data_from_sap_analytics_cloud_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yps473/extracting_data_from_sap_analytics_cloud_anyone/", "subreddit_subscribers": 79293, "created_utc": 1667926915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm designing a data platform with a Data Warehouse using Synapse, and Power BI as the frontend. Datalake for staging, and SQL pool as dwh. Pretty straightforward solution.\n\nNormally I set up the user access in Power BI, using AD groups, report access through Audiences and if necessary RLS.\n\nThis client has users that want access directly to the dwh and possibly datalake. This means setting up the security in Power BI won't suffice. What are my options for setting up security in the backend, and transferring these rules to Power BI?", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Access Security for Synapse with Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yprec2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667925279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m designing a data platform with a Data Warehouse using Synapse, and Power BI as the frontend. Datalake for staging, and SQL pool as dwh. Pretty straightforward solution.&lt;/p&gt;\n\n&lt;p&gt;Normally I set up the user access in Power BI, using AD groups, report access through Audiences and if necessary RLS.&lt;/p&gt;\n\n&lt;p&gt;This client has users that want access directly to the dwh and possibly datalake. This means setting up the security in Power BI won&amp;#39;t suffice. What are my options for setting up security in the backend, and transferring these rules to Power BI?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yprec2", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yprec2/access_security_for_synapse_with_power_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yprec2/access_security_for_synapse_with_power_bi/", "subreddit_subscribers": 79293, "created_utc": 1667925279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an analytics engineering position interview on Friday. And other possible interviews coming up shortly. I've done some self-study on SQL on personal time and currently use it in my current role as  BI Analyst. Today, I subscribed to Stratascratch  and hope to start grinding out problems. Prior, I had made an effort to read *SQL Fundamentals* by Itzik Ben-Gan focusing mainly on the portions I currently use my role.\n\nBeing that I have an interview approaching Friday. What should be my main focus? Should I try to grind out Stratascratch or review some concepts? \n\nWhat do you guys recommend?", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for SQL portion for analytics engineering position(s). What should be my focus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypp4ye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667920511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an analytics engineering position interview on Friday. And other possible interviews coming up shortly. I&amp;#39;ve done some self-study on SQL on personal time and currently use it in my current role as  BI Analyst. Today, I subscribed to Stratascratch  and hope to start grinding out problems. Prior, I had made an effort to read &lt;em&gt;SQL Fundamentals&lt;/em&gt; by Itzik Ben-Gan focusing mainly on the portions I currently use my role.&lt;/p&gt;\n\n&lt;p&gt;Being that I have an interview approaching Friday. What should be my main focus? Should I try to grind out Stratascratch or review some concepts? &lt;/p&gt;\n\n&lt;p&gt;What do you guys recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "ypp4ye", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypp4ye/preparing_for_sql_portion_for_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypp4ye/preparing_for_sql_portion_for_analytics/", "subreddit_subscribers": 79293, "created_utc": 1667920511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is-it possible to create a data source in denodo from a microsoft sharepoint (List) by using the query.iqy generated when we use the feature \"export to excel\" ?", "author_fullname": "t2_t4dkdc3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Denodo &lt;=&gt; Sharepoint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yponds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is-it possible to create a data source in denodo from a microsoft sharepoint (List) by using the query.iqy generated when we use the feature &amp;quot;export to excel&amp;quot; ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yponds", "is_robot_indexable": true, "report_reasons": null, "author": "Moosh_Be", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yponds/denodo_sharepoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yponds/denodo_sharepoint/", "subreddit_subscribers": 79293, "created_utc": 1667919482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While reading about Airflow, the DAG stuff felt exactly similar to the topological sort algorithm.  \n\nP.S: I am new to airflow.", "author_fullname": "t2_ii16zylj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I call airflow an implementation of the Topological sort algorithm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypniq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While reading about Airflow, the DAG stuff felt exactly similar to the topological sort algorithm.  &lt;/p&gt;\n\n&lt;p&gt;P.S: I am new to airflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypniq2", "is_robot_indexable": true, "report_reasons": null, "author": "ZENDRO_hex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypniq2/can_i_call_airflow_an_implementation_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypniq2/can_i_call_airflow_an_implementation_of_the/", "subreddit_subscribers": 79293, "created_utc": 1667916999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading a tech newsletter the other day and came across [SPL](http://c.raqsoft.com/article/1640597143990?utm_source=tldr&amp;utm_medium=email-paid&amp;utm_campaign=gl-wb-2022-06-22-execute-SQL-without-RDB&amp;utm_term=camp-gl&amp;utm_content=execute-SQL-without-RDB). I was surprised to not find much online about others using it. It seems to me like a viable solution for making API calls more declarative, which could be nice. Is anyone using this in any projects? If so, are you working with it on the command line or through something like a python API?", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SPL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yplh49", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667912368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading a tech newsletter the other day and came across &lt;a href=\"http://c.raqsoft.com/article/1640597143990?utm_source=tldr&amp;amp;utm_medium=email-paid&amp;amp;utm_campaign=gl-wb-2022-06-22-execute-SQL-without-RDB&amp;amp;utm_term=camp-gl&amp;amp;utm_content=execute-SQL-without-RDB\"&gt;SPL&lt;/a&gt;. I was surprised to not find much online about others using it. It seems to me like a viable solution for making API calls more declarative, which could be nice. Is anyone using this in any projects? If so, are you working with it on the command line or through something like a python API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?auto=webp&amp;s=64c95fdac1da4c0b0d9d07d8c8b3d937a95dcc1e", "width": 720, "height": 377}, "resolutions": [{"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=817d4e7f2d4fc5899b50457f4d41e7432e24ff02", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1527decf123172a807b16dbbb5fd69e3f608ded9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=067583090b65ac6cb23c19d05eeb6037a8025653", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f18931ce9c4ef7e6787db84c6d498e7aae2afe4", "width": 640, "height": 335}], "variants": {}, "id": "CsekJbW__-1RAOvhmJbiKWzgN3MMqENzNxsyLD4wPVc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yplh49", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yplh49/spl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yplh49/spl/", "subreddit_subscribers": 79293, "created_utc": 1667912368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. If you work with data, I am sure that you heard something about metrics. I wrote an article where I compare two approaches (about metrics definition). I would appreciate your feedback! Thanks! \u2764\ufe0f\n\n[https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3](https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to write good metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypkmra", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667910291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. If you work with data, I am sure that you heard something about metrics. I wrote an article where I compare two approaches (about metrics definition). I would appreciate your feedback! Thanks! \u2764\ufe0f&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3\"&gt;https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?auto=webp&amp;s=5265a42727701f60a712216232b956f56f96a546", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0952d3e6429ba1ec1c3cbdd8e8c287d2f905e71b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e73bc700b9a6ac39ef702edbd6d4f7fdcb58db95", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d2dc00e2b2fa5c48ae09308d311907ebe188b7a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=16f5d80fe864329673314bb01345f837f7ce697c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fae43295fcd2bbda8aa7053ca3812cae5d43521b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeab5c7c25bf0f63e774731af7f4c7e693c68368", "width": 1080, "height": 567}], "variants": {}, "id": "lXVNCTBPoVnk8P4ZguwDS7tvo-uIAeq_FJ8eO-EqtRg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ypkmra", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypkmra/how_to_write_good_metrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypkmra/how_to_write_good_metrics/", "subreddit_subscribers": 79293, "created_utc": 1667910291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm from a South Asian country and I have been trying to land remote job opportunities in countries such as Australia, Canada, and a few countries. I have tried via Toptal, Turing, LinkedIn, Vanhack, SEEK, DBT slack channel and managed to have an interview twice, once from Germany and the other from Canada. The interview with the German company was good but could not move to the next step. With the Canadian startup company, I had the first interview with the CEO, the second with a DE, and the third with the acting Chief Operating Officer. I messed up the interview with the COO because I'm a more technical person and sometimes reply with silly answers to simple questions.\n\n1. I'm still looking for areas to improve my resume, could you please review it? [https://imgur.com/a/XGDmET4](https://imgur.com/a/XGDmET4)\n2. Are there other places to look for remote jobs for citizens from South Asian countries?\n3. How can I improve answering simple non-technical questions?\n4. I'm asking $45/hr for my work, is it much to ask?", "author_fullname": "t2_ablvw8qg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume and other advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypc19d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667884592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a South Asian country and I have been trying to land remote job opportunities in countries such as Australia, Canada, and a few countries. I have tried via Toptal, Turing, LinkedIn, Vanhack, SEEK, DBT slack channel and managed to have an interview twice, once from Germany and the other from Canada. The interview with the German company was good but could not move to the next step. With the Canadian startup company, I had the first interview with the CEO, the second with a DE, and the third with the acting Chief Operating Officer. I messed up the interview with the COO because I&amp;#39;m a more technical person and sometimes reply with silly answers to simple questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m still looking for areas to improve my resume, could you please review it? &lt;a href=\"https://imgur.com/a/XGDmET4\"&gt;https://imgur.com/a/XGDmET4&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Are there other places to look for remote jobs for citizens from South Asian countries?&lt;/li&gt;\n&lt;li&gt;How can I improve answering simple non-technical questions?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m asking $45/hr for my work, is it much to ask?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?auto=webp&amp;s=802f53834b910a0dd1525a0111bc7b168981b07d", "width": 1656, "height": 7017}, "resolutions": [{"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=355c282b4675528fa4d7ca01a68bf6737cddb1fa", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1258367fa5cd88d5e2a5a2dbe000b52ba6c686a7", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=642fb2a461cca994ee8acf2908cd7cb4248a00b7", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=61db1b207fb28c913fcc46fe3428b5d5c077df59", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d11cbb36d7c91fca0b9bb77a014081055a3d514", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/_6_G8KzSzo1ZEwYphNyrj5MiVxCGK8Obu4C4VUL6mkY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99dc919c334278f6eda4203408beec663e683cce", "width": 1080, "height": 2160}], "variants": {}, "id": "nLGXN79p6Ht9ihcfpKW9uGcE1peE9pTYBbSZg0T7z7I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "ypc19d", "is_robot_indexable": true, "report_reasons": null, "author": "sherocksme", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypc19d/resume_and_other_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypc19d/resume_and_other_advice/", "subreddit_subscribers": 79293, "created_utc": 1667884592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Free Live Workshop] Data, Meet Ops: How to delight &amp; retain customers with trustworthy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_yp2r0g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nf8l7Lr65pDGSXwbC3irv9IX0jm8vcxMCUE4rY0LEHQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667859967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getcensus.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getcensus.com/events/data-meet-ops?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=Data%2C+Meet+Ops+Series&amp;utm_content=reddit-nate-c-post", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?auto=webp&amp;s=7b75d4e51e3ff9b4710047f1e7e67c5e20859a77", "width": 1501, "height": 786}, "resolutions": [{"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=faef6b2ae33453046b3270ec956bbf245f6db357", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e1d6509282e394ec4ae7316408ff042ee32db66", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=192185294bd2d0e38b2c3e94630b774206fb62da", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=97f1c7def96fef63cc5a911cd6f8239423f4b24f", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61e0c1f75022cee8897d82af5cafb5b80d20338e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/lggHsKj3GcBfr9vUAThMWFoajxs5bDW0CIW2EzdJOx4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfee45ea9e4ddc74b54733feebb8061845e6f796", "width": 1080, "height": 565}], "variants": {}, "id": "wcW-ojCgr1kd4NXkbVucJOBAXtYF6xvEMJqqZMM1SqE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yp2r0g", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp2r0g/free_live_workshop_data_meet_ops_how_to_delight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getcensus.com/events/data-meet-ops?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=Data%2C+Meet+Ops+Series&amp;utm_content=reddit-nate-c-post", "subreddit_subscribers": 79293, "created_utc": 1667859967.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, I am running into problems with running PySpark along with Kafka. \"spark.readStream\" functions don't work for my apps whatever I try to run it with. I have tried methods that included Docker containers with Kafka but they do not work. I am not too familiar with neither of these frameworks and I do not want to spend another few hours fighting with them, therefore I would like to ask you if you could send any guide with solution that works 100% for you.  \n\n\nMy sole requirement is that it has to work with Windows/WSL.", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for ways to integrate PySpark with Kafka locally on Windows/WSL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoy6o2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667850628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I am running into problems with running PySpark along with Kafka. &amp;quot;spark.readStream&amp;quot; functions don&amp;#39;t work for my apps whatever I try to run it with. I have tried methods that included Docker containers with Kafka but they do not work. I am not too familiar with neither of these frameworks and I do not want to spend another few hours fighting with them, therefore I would like to ask you if you could send any guide with solution that works 100% for you.  &lt;/p&gt;\n\n&lt;p&gt;My sole requirement is that it has to work with Windows/WSL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yoy6o2", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoy6o2/looking_for_ways_to_integrate_pyspark_with_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoy6o2/looking_for_ways_to_integrate_pyspark_with_kafka/", "subreddit_subscribers": 79293, "created_utc": 1667850628.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}