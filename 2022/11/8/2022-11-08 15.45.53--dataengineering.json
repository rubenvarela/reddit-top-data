{"kind": "Listing", "data": {"after": "t3_ypniq2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?", "author_fullname": "t2_3ydamall", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are all my colleagues so weird", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp0q06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667855856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it a prerequisite that you have to be awkward and talk over people in meeting to work in this industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp0q06", "is_robot_indexable": true, "report_reasons": null, "author": "masta_beta69", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp0q06/why_are_all_my_colleagues_so_weird/", "subreddit_subscribers": 79272, "created_utc": 1667855856.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: Databricks vs. Snowflake - Who wins?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_yp5mbh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u_xxC_eXXOHvqK1P-bJYUEzxhxy2jS-mcrCUqSLOtYY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667866364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n3y26kqadmy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n3y26kqadmy91.png?auto=webp&amp;s=b24fdc9cc0ae55fe276059b797ff46f2af4df245", "width": 1472, "height": 995}, "resolutions": [{"url": "https://preview.redd.it/n3y26kqadmy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec7844e199a4f24ead9d3d2479ffd65e9107fd56", "width": 108, "height": 73}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ff6de90cb1af595399cf1f8027f32a804a6bbd7", "width": 216, "height": 146}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bfefd9ae47cd5cd0b1b547ff6efb2525f504d2b", "width": 320, "height": 216}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=00df4c6972e23d3d804d46f840d4d25e97610f33", "width": 640, "height": 432}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=780cf785bdc2bad8d94a25432795f137306ac787", "width": 960, "height": 648}, {"url": "https://preview.redd.it/n3y26kqadmy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=62ed016f2c09205aa0c2beb47e18b0c9648c44b5", "width": 1080, "height": 730}], "variants": {}, "id": "oxyzXQH15HgTuA2-TcKRbh7Hg9z5CqYLONC7V8GiWtY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yp5mbh", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp5mbh/discussion_databricks_vs_snowflake_who_wins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n3y26kqadmy91.png", "subreddit_subscribers": 79272, "created_utc": 1667866364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.  \nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  \n\n\n* Design patterns &amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.\n* Testing: Mostly unit tests.\n* APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.\n* Errors &amp; Monitoring &amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp; logs.\n* System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)\n* RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?", "author_fullname": "t2_1yf128eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much software engineering knowledge should a data engineer know?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfb1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667895269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to create a curriculum for the DE path to help other programmers prepare for Data Engineering. Some SE topics are required to learn because they are generally useful when developing software. I want to hand-pick some important topics for someone who is just getting started, It\u2019s important to only pick topics that will be useful in DE.&lt;br/&gt;\nIf someone wants to study data engineering, how much of the following SE-related stuff do you think is required?  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Design patterns &amp;amp; Principles like KISS and YAGNI: books like pragmatic programmer have a handful of these.&lt;/li&gt;\n&lt;li&gt;Testing: Mostly unit tests.&lt;/li&gt;\n&lt;li&gt;APIs: I assume only basic REST knowledge is enough to get the concept, and people can learn other methods like Grpc and GraphQL on the job.&lt;/li&gt;\n&lt;li&gt;Errors &amp;amp; Monitoring &amp;amp; Tracing: Being able to log correctly, send metrics where needed and write code that can be debugged if it crashes with traces &amp;amp; logs.&lt;/li&gt;\n&lt;li&gt;System Design: Keep in mind the simple techniques like caching and scaling, Plus some other examples like how you design X(Do you know any good resource on this?)&lt;/li&gt;\n&lt;li&gt;RDBMS: I never used more than SQL and ORM knowledge myself. Please suggest which areas you think are important. Is RDBMS internals relevant? Is ACID relevant?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypfb1m", "is_robot_indexable": true, "report_reasons": null, "author": "glyphack", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfb1m/how_much_software_engineering_knowledge_should_a/", "subreddit_subscribers": 79272, "created_utc": 1667895269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When is it better to use each one of these? \nAlso is there a way to perform zero-copy/in-memory transformation from pyArrow to pySpark? I can't find any info on both of these topics.", "author_fullname": "t2_dlui0uup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyArrow vs pySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_you1os", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667842313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When is it better to use each one of these? \nAlso is there a way to perform zero-copy/in-memory transformation from pyArrow to pySpark? I can&amp;#39;t find any info on both of these topics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "you1os", "is_robot_indexable": true, "report_reasons": null, "author": "XtremeBanana333", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/you1os/pyarrow_vs_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/you1os/pyarrow_vs_pyspark/", "subreddit_subscribers": 79272, "created_utc": 1667842313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://github.com/brexhq/substation](https://github.com/brexhq/substation)\n\nOur team recently released a project called Substation ([announcement here](https://medium.com/brexeng/announcing-substation-188d049d979b)) that can be used to create modular, serverless data pipelines (ETL).\n\nI'm the project lead so if anyone has any questions or feedback, then please let me know!", "author_fullname": "t2_kuumsieq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Substation: serverless data pipeline toolkit written in Go", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoqsw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667835895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/brexhq/substation\"&gt;https://github.com/brexhq/substation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Our team recently released a project called Substation (&lt;a href=\"https://medium.com/brexeng/announcing-substation-188d049d979b\"&gt;announcement here&lt;/a&gt;) that can be used to create modular, serverless data pipelines (ETL).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the project lead so if anyone has any questions or feedback, then please let me know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?auto=webp&amp;s=3cfa8d8d4f194782471777e21245a2c919692039", "width": 640, "height": 320}, "resolutions": [{"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ddb598de628cfd93d71f8ce4c42f6644f8727af", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f1a2c8c4b6377019bd6d53a44f7b4fa1d674523", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc76bdcfa8838602d4bb282df5c6cf49a7979f7e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8Zw2s3HB35q64h3kHf-7EjhHWqFlZGa2rb3NokdMzlM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f5bb3fae94b00071c6beabe9b650d67c6761d4e", "width": 640, "height": 320}], "variants": {}, "id": "xv1e5O9fm8KLjRaTRRPYd9oJCEFoBjTun2Ww3C8XHpQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "yoqsw1", "is_robot_indexable": true, "report_reasons": null, "author": "jshlbrd-brex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoqsw1/substation_serverless_data_pipeline_toolkit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoqsw1/substation_serverless_data_pipeline_toolkit/", "subreddit_subscribers": 79272, "created_utc": 1667835895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.\n\nI can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.\n\nWhat kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?", "author_fullname": "t2_wd6qw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Practice Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyfp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from an ML/Data Science background and find it difficult to truly improve my data engineering skills.&lt;/p&gt;\n\n&lt;p&gt;I can find lists of technologies and related online courses, but these rarely move the needle as they typically only work with toy datasets.&lt;/p&gt;\n\n&lt;p&gt;What kind of practical, real-life, data engineering projects would you recommend to someone who is looking for an excuse to work with technologies they want to gain experience in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yoyfp2", "is_robot_indexable": true, "report_reasons": null, "author": "valentincalomme", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyfp2/data_engineering_practice_projects/", "subreddit_subscribers": 79272, "created_utc": 1667851177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?\n\nMy use case is I have data stored in Snowflake and I have users (that don't know SQL at all and not willing to learn) use Snowpark and they're able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it's very convenient.\n\nIs there something similar that could be used if let's say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? \n\nI want to avoid Databricks Connect because it's janky as hell and I don't want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.\n\nThe Databricks SQL odbc for python is less cumbersome but it's really just a different way to pass SQL statements.\n\nAnyone have ideas on this?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpark equivalent on Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yov7r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667844746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I almost feel silly asking this but is there an equivalent pythonic, non-spark dependent API for Databricks?&lt;/p&gt;\n\n&lt;p&gt;My use case is I have data stored in Snowflake and I have users (that don&amp;#39;t know SQL at all and not willing to learn) use Snowpark and they&amp;#39;re able to do a lot of what they want in a very pythonic way. Apart from forcing python 3.8 it&amp;#39;s very convenient.&lt;/p&gt;\n\n&lt;p&gt;Is there something similar that could be used if let&amp;#39;s say the data was in Delta Lake, I used whatever type of Databricks compute, cluster or SQL endpoint. Where I can write pythonic code to have my cluster run computation and return the result to my local session? &lt;/p&gt;\n\n&lt;p&gt;I want to avoid Databricks Connect because it&amp;#39;s janky as hell and I don&amp;#39;t want users to have to mess around with setting up local spark/Hadoop/PySpark/Java/environment vars.&lt;/p&gt;\n\n&lt;p&gt;The Databricks SQL odbc for python is less cumbersome but it&amp;#39;s really just a different way to pass SQL statements.&lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yov7r8", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yov7r8/snowpark_equivalent_on_databricks/", "subreddit_subscribers": 79272, "created_utc": 1667844746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to choose between 2 internships  (Europe) :\n- One paid 1500\u20ac/month, no work from home possible, and more importantly no hiring possible after the internship.\n- One paid 1200\u20ac/month, 2 days / week WFH, hiring after the internship.\n\nThe content of the two internships are quite the same, however I'm afraid of not being able to get a good DE job after my internship, as I wont have a lot of experience (only 5 or 6 months). I really enjoy WFH so it could be really great if I could get a full remote position, but again I have no idea how hard it is to get those positions.\n\nWhat do you think of it?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it to get a DE junior (full remote ?) position after an internship ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoqaf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667834850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to choose between 2 internships  (Europe) :\n- One paid 1500\u20ac/month, no work from home possible, and more importantly no hiring possible after the internship.\n- One paid 1200\u20ac/month, 2 days / week WFH, hiring after the internship.&lt;/p&gt;\n\n&lt;p&gt;The content of the two internships are quite the same, however I&amp;#39;m afraid of not being able to get a good DE job after my internship, as I wont have a lot of experience (only 5 or 6 months). I really enjoy WFH so it could be really great if I could get a full remote position, but again I have no idea how hard it is to get those positions.&lt;/p&gt;\n\n&lt;p&gt;What do you think of it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yoqaf6", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoqaf6/how_hard_is_it_to_get_a_de_junior_full_remote/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoqaf6/how_hard_is_it_to_get_a_de_junior_full_remote/", "subreddit_subscribers": 79272, "created_utc": 1667834850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just finished Head First SQL from awesomedataengineering and wondering where to go from here? To the next resource in the SQL section? Work on my own project? Move on to Python, then work on my own project? Any advice is helpful.", "author_fullname": "t2_blmtd0p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I follow awesomedataengineering or the dataengineering wiki?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoqtem", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667835922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just finished Head First SQL from awesomedataengineering and wondering where to go from here? To the next resource in the SQL section? Work on my own project? Move on to Python, then work on my own project? Any advice is helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yoqtem", "is_robot_indexable": true, "report_reasons": null, "author": "DisastrousChain7189", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoqtem/how_do_i_follow_awesomedataengineering_or_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoqtem/how_do_i_follow_awesomedataengineering_or_the/", "subreddit_subscribers": 79272, "created_utc": 1667835922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:\n\n1. [secor](https://github.com/pinterest/secor): Seems a bit on the older side\n2. [Connector](https://github.com/aiven/gcs-connector-for-apache-kafka): Low Amount of Users\n\nAny open source tools you can recommend?", "author_fullname": "t2_f4rnp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka to GCS Persistence Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypans5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667880401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking around for an open source tool that would transfer data from kafka to GCS. Tools I have found online so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/pinterest/secor\"&gt;secor&lt;/a&gt;: Seems a bit on the older side&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/aiven/gcs-connector-for-apache-kafka\"&gt;Connector&lt;/a&gt;: Low Amount of Users&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any open source tools you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?auto=webp&amp;s=41465a6192d02528bbce28a0914098d4ae9c191a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b36284feae726cd6ec1107a93bc66c9ed005efc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f642609effe2dc5f8c969b20912f31196849bac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cc256df7c45f940fbf3c0ea344dddf49ad1133a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ec7e1944e22ca9344c565b8fca772354317fa12", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bb9921cfd43f2a399ef142495769d5a8c20c8178", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Pq2SngV39xLXkqUCfVxAVwdjdPOe9fCuqFMst6h5vsY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a1913e065c316d6750d2d29a5539610836f654f", "width": 1080, "height": 540}], "variants": {}, "id": "Y0XtgNrn0-zLnBkJhTDof8YJNRcL7t-Bf2Zsb9CpNqc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypans5", "is_robot_indexable": true, "report_reasons": null, "author": "alwaysSearching23", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypans5/kafka_to_gcs_persistence_tools/", "subreddit_subscribers": 79272, "created_utc": 1667880401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which part of data science is likely to automate? Eg. Data collecting, storage, transformation or labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoyxfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667852148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering which part is likely to be automated. If you are automating these parts, how? Are you adding a tool to your data stack or solving it by yourself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoyxfi", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoyxfi/which_part_of_data_science_is_likely_to_automate/", "subreddit_subscribers": 79272, "created_utc": 1667852148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am creating a project to use for my portfolio but I have some questions regarding best practices during the ETL process vs what I know so far.\n\nI am extracting data from an API, I want to transform this data and store it in a cloud hosted db.\n\nWhat would be the real-life solution to transforming this? What ive learned so far is that I extract the data with requests, store it as raw file (csv?) and start transforming it from there to a clean version of the file (also csv?) and then go through the load process.\n\nSo my first questions are:\n\nWhy should I make turn them into CSV? or any other format? I can do all my transformations using pandas without actually every persisting any file, or is this purely for backup? And is CSV the standard to go to? why not just JSON format?\n\nWhat is the convention (real-life) of keeping these CSV files after I loaded them? Do i delete them right after? Do I delete them after x amount of time.\n\nSorry I know a bunch of questions but any help would be appreciated. thanks!", "author_fullname": "t2_6kipsr88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advise on ETL project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yotj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667841280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am creating a project to use for my portfolio but I have some questions regarding best practices during the ETL process vs what I know so far.&lt;/p&gt;\n\n&lt;p&gt;I am extracting data from an API, I want to transform this data and store it in a cloud hosted db.&lt;/p&gt;\n\n&lt;p&gt;What would be the real-life solution to transforming this? What ive learned so far is that I extract the data with requests, store it as raw file (csv?) and start transforming it from there to a clean version of the file (also csv?) and then go through the load process.&lt;/p&gt;\n\n&lt;p&gt;So my first questions are:&lt;/p&gt;\n\n&lt;p&gt;Why should I make turn them into CSV? or any other format? I can do all my transformations using pandas without actually every persisting any file, or is this purely for backup? And is CSV the standard to go to? why not just JSON format?&lt;/p&gt;\n\n&lt;p&gt;What is the convention (real-life) of keeping these CSV files after I loaded them? Do i delete them right after? Do I delete them after x amount of time.&lt;/p&gt;\n\n&lt;p&gt;Sorry I know a bunch of questions but any help would be appreciated. thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yotj3u", "is_robot_indexable": true, "report_reasons": null, "author": "Brontonomo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yotj3u/advise_on_etl_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yotj3u/advise_on_etl_project/", "subreddit_subscribers": 79272, "created_utc": 1667841280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qc1e9enq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Connector Catalog: Our team kept getting questions about which ETL vendors provide connectors to which sources. So we built an ongoing catalog to help you easily search for and find the connectors you need! Check it out and use for free: connectorcatalog.com. Hope this is helpful", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_ypmk48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fOqG2BN7uiCmw3o8xDBppGSmSkzwhlBSgrTGlO0fzpA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667914868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/htagp2l9dqy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/htagp2l9dqy91.png?auto=webp&amp;s=24e4a69b8983105bdd1a63ef2f519c220e990048", "width": 2774, "height": 1442}, "resolutions": [{"url": "https://preview.redd.it/htagp2l9dqy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f514408590bc22f18f09dced3fbb1f1a13944a4e", "width": 108, "height": 56}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b22504b373da0550a3bc0fe61a8f2e372ba84667", "width": 216, "height": 112}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=53756ee372614dd9de047c16dbd1dbb2736b3686", "width": 320, "height": 166}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=25d3f46991c4a4672e0bd6cd91a91f2890956641", "width": 640, "height": 332}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a382914a854019d0a1b168bd529b3f6f89427ef5", "width": 960, "height": 499}, {"url": "https://preview.redd.it/htagp2l9dqy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f49d715768a8b380a9849f2a3d77e0fd47e05ae", "width": 1080, "height": 561}], "variants": {}, "id": "dvzW3yrABFZ3pNLtwDBanHdFjDLksWcaY6LJKhAv848"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypmk48", "is_robot_indexable": true, "report_reasons": null, "author": "alorentz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypmk48/etl_connector_catalog_our_team_kept_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/htagp2l9dqy91.png", "subreddit_subscribers": 79272, "created_utc": 1667914868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading a tech newsletter the other day and came across [SPL](http://c.raqsoft.com/article/1640597143990?utm_source=tldr&amp;utm_medium=email-paid&amp;utm_campaign=gl-wb-2022-06-22-execute-SQL-without-RDB&amp;utm_term=camp-gl&amp;utm_content=execute-SQL-without-RDB). I was surprised to not find much online about others using it. It seems to me like a viable solution for making API calls more declarative, which could be nice. Is anyone using this in any projects? If so, are you working with it on the command line or through something like a python API?", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SPL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yplh49", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667912368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading a tech newsletter the other day and came across &lt;a href=\"http://c.raqsoft.com/article/1640597143990?utm_source=tldr&amp;amp;utm_medium=email-paid&amp;amp;utm_campaign=gl-wb-2022-06-22-execute-SQL-without-RDB&amp;amp;utm_term=camp-gl&amp;amp;utm_content=execute-SQL-without-RDB\"&gt;SPL&lt;/a&gt;. I was surprised to not find much online about others using it. It seems to me like a viable solution for making API calls more declarative, which could be nice. Is anyone using this in any projects? If so, are you working with it on the command line or through something like a python API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?auto=webp&amp;s=64c95fdac1da4c0b0d9d07d8c8b3d937a95dcc1e", "width": 720, "height": 377}, "resolutions": [{"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=817d4e7f2d4fc5899b50457f4d41e7432e24ff02", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1527decf123172a807b16dbbb5fd69e3f608ded9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=067583090b65ac6cb23c19d05eeb6037a8025653", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-lc9WgCYoNA8sqEKg0lhIKgAmM1U4F539vdC6JMDARk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f18931ce9c4ef7e6787db84c6d498e7aae2afe4", "width": 640, "height": 335}], "variants": {}, "id": "CsekJbW__-1RAOvhmJbiKWzgN3MMqENzNxsyLD4wPVc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yplh49", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yplh49/spl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yplh49/spl/", "subreddit_subscribers": 79272, "created_utc": 1667912368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. If you work with data, I am sure that you heard something about metrics. I wrote an article where I compare two approaches (about metrics definition). I would appreciate your feedback! Thanks! \u2764\ufe0f\n\n[https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3](https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to write good metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypkmra", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667910291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. If you work with data, I am sure that you heard something about metrics. I wrote an article where I compare two approaches (about metrics definition). I would appreciate your feedback! Thanks! \u2764\ufe0f&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3\"&gt;https://medium.com/gooddata-developers/gooddata-and-dbt-metrics-aa8edd3da4e3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?auto=webp&amp;s=5265a42727701f60a712216232b956f56f96a546", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0952d3e6429ba1ec1c3cbdd8e8c287d2f905e71b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e73bc700b9a6ac39ef702edbd6d4f7fdcb58db95", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d2dc00e2b2fa5c48ae09308d311907ebe188b7a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=16f5d80fe864329673314bb01345f837f7ce697c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fae43295fcd2bbda8aa7053ca3812cae5d43521b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/V6MM97mwtaEqH-jSa9t6gaRbgE5so2KTAG40NCcDBHA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeab5c7c25bf0f63e774731af7f4c7e693c68368", "width": 1080, "height": 567}], "variants": {}, "id": "lXVNCTBPoVnk8P4ZguwDS7tvo-uIAeq_FJ8eO-EqtRg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "ypkmra", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypkmra/how_to_write_good_metrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypkmra/how_to_write_good_metrics/", "subreddit_subscribers": 79272, "created_utc": 1667910291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all! We\u2019re using Airflow at my job to orchestrate our data pipelines and I had a question regarding how y\u2019all are handling creations of schemas and/or tables for your data warehouse in your infrastructure !\n\nDo you mostly do it through your data pipeline as a step, or do you have a separate automated process that handles the creations ? \n\nI\u2019m currently in the process of reworking most of our utilities and I have been researching the best way to go through this process as I\u2019m not the biggest fan of having a task run every time for table creation if it doesn\u2019t exist. \n\nThanks in advance !", "author_fullname": "t2_38zkx7ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Warehouse Schema/Table automated creation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypjw89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667908427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! We\u2019re using Airflow at my job to orchestrate our data pipelines and I had a question regarding how y\u2019all are handling creations of schemas and/or tables for your data warehouse in your infrastructure !&lt;/p&gt;\n\n&lt;p&gt;Do you mostly do it through your data pipeline as a step, or do you have a separate automated process that handles the creations ? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently in the process of reworking most of our utilities and I have been researching the best way to go through this process as I\u2019m not the biggest fan of having a task run every time for table creation if it doesn\u2019t exist. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypjw89", "is_robot_indexable": true, "report_reasons": null, "author": "DrSnakee95", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypjw89/warehouse_schematable_automated_creation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypjw89/warehouse_schematable_automated_creation/", "subreddit_subscribers": 79272, "created_utc": 1667908427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Parallelization in Databricks is pretty simple. You can just use this code:  \n[https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/](https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/)\n\nI wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a gold standard when it comes to parallelization using databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ypfpky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667896405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parallelization in Databricks is pretty simple. You can just use this code:&lt;br/&gt;\n&lt;a href=\"https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/\"&gt;https://transform365.blog/2020/06/21/run-same-databricks-notebook-for-multiple-times-in-parallel-concurrently-using-python/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is an even better way to manage the load. To minimize cost and maximize efficiency.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?auto=webp&amp;s=c1c56f4b127f9a67fce6e84a3a0743ab6f6b65eb", "width": 1081, "height": 642}, "resolutions": [{"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fda048159fdf7c1a06db01b52d2e7c94b9ac3d1d", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d779118465b89e224fdb37b3c5818935a31c6f0", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d1860336c49b9c46bc81fb83ef91703be7b757f", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35a9e8e4cab2d7252076b75a4507e6bda234d727", "width": 640, "height": 380}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad3a32aba85ddb91a39fd5847d4945df6c867941", "width": 960, "height": 570}, {"url": "https://external-preview.redd.it/KEbG99bUn66dcZq2NkL1MUab1JEovwpYdzQ1S9-gqSE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e47573429a4037e21316279354d0024451140d7b", "width": 1080, "height": 641}], "variants": {}, "id": "04iDH-CVszurLQEs2iwnfG3C5m3CZ7nzpSC3OWOVSR0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ypfpky", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypfpky/is_there_a_gold_standard_when_it_comes_to/", "subreddit_subscribers": 79272, "created_utc": 1667896405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4cc8quyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - memphisdev/memphis-broker: Memphis is an Open-Source, Real-Time Data Processing Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_ypboc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0Pglx59Ymn-_DxBtB_LL-EkNUbwhhJ7LZ7Vp0Xb6RBo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667883519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/memphisdev/memphis-broker", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ypboc6", "is_robot_indexable": true, "report_reasons": null, "author": "hooopo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypboc6/github_memphisdevmemphisbroker_memphis_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/memphisdev/memphis-broker", "subreddit_subscribers": 79272, "created_utc": 1667883519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. \n\nThanks", "author_fullname": "t2_6dym6exn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning material for Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp9uyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667878069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to get total understanding of Apache Airflow for my next project. Looking for advise for any course/ material to ramp up my understanding. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp9uyi", "is_robot_indexable": true, "report_reasons": null, "author": "StatusStar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp9uyi/learning_material_for_airflow/", "subreddit_subscribers": 79272, "created_utc": 1667878069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.\n\nI know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.\n\nWanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?\n\nTable volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.", "author_fullname": "t2_3x9g7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replication to new schema across RDBMS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp44pc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667862772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I want to move data from a legacy schema on one RDBMS to a new schema on a new RDBMS.  These support an internal application we are rebuilding.  Some of the features on the new application will go live before we are fully off the old application, so I need to be able to move data between them.&lt;/p&gt;\n\n&lt;p&gt;I know ELT is typically used in a data warehouse setting, but for the ease of use I was interested in using some of the popular tools to accomplish this here.  In particular was considering using Fivetran to move data and dbt for transforming and writing to the target.&lt;/p&gt;\n\n&lt;p&gt;Wanted to get the temperature on this approach -- is it full steam ahead, an absolute no go, somewhere in between?  If not your first choice, what do you think might be a better one, and why?&lt;/p&gt;\n\n&lt;p&gt;Table volumes are pretty low right now--DB is a couple of gigs / highest number of rows would be a 6 digit number of rows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp44pc", "is_robot_indexable": true, "report_reasons": null, "author": "iwenttocharlenes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp44pc/replication_to_new_schema_across_rdbms/", "subreddit_subscribers": 79272, "created_utc": 1667862772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends.\n\nThere are a few hundred unhealthy videos among a few thousand videos\n\nHow can I bulk-check them?\n\nGoal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files", "author_fullname": "t2_teoa5nr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk video health check? (macOS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yp1ky4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667857644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, it seems like a video is 10 minutes long, but its actually 2 minutes long because its kind of corrupt (this is a recovered file). I can play the video using video regular players. After 2 minutes, it just ends.&lt;/p&gt;\n\n&lt;p&gt;There are a few hundred unhealthy videos among a few thousand videos&lt;/p&gt;\n\n&lt;p&gt;How can I bulk-check them?&lt;/p&gt;\n\n&lt;p&gt;Goal: Identify unhealthy movies. Write their filename and folder info into a text file. Then remove the files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yp1ky4", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Chemistry7585", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yp1ky4/bulk_video_health_check_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yp1ky4/bulk_video_health_check_macos/", "subreddit_subscribers": 79272, "created_utc": 1667857644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a Junior DE working on a project to backfill historical log data that our apps generated going back to 2017 (about \\~5.5 TB of data). The files are gzipped and there is one file per day per product. We have a data stream set up now which is ingesting todays files into Redshift.  \n\n\nI'm looking for some input or advice on paths I may take. The only approach that I've thought of so far is to:  \n1. Generate an S3 Inventory Report\n\n2. Write a Lambda that would send objects from the report to an S3 Batch Operation  \n\n\n* The questions I have are:  \nCan you send objects to a data stream when using S3 Batch Operations  \nIs the data stream needed for this one time load  \n\n\nIs there a more effective/efficient approach?", "author_fullname": "t2_4tpsvglz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Approach to loading historical log data using S3 Batch Operations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yoygm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667851216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Junior DE working on a project to backfill historical log data that our apps generated going back to 2017 (about ~5.5 TB of data). The files are gzipped and there is one file per day per product. We have a data stream set up now which is ingesting todays files into Redshift.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some input or advice on paths I may take. The only approach that I&amp;#39;ve thought of so far is to:&lt;br/&gt;\n1. Generate an S3 Inventory Report&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Write a Lambda that would send objects from the report to an S3 Batch Operation&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The questions I have are:&lt;br/&gt;\nCan you send objects to a data stream when using S3 Batch Operations&lt;br/&gt;\nIs the data stream needed for this one time load&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is there a more effective/efficient approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yoygm4", "is_robot_indexable": true, "report_reasons": null, "author": "cazual_penguin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yoygm4/approach_to_loading_historical_log_data_using_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yoygm4/approach_to_loading_historical_log_data_using_s3/", "subreddit_subscribers": 79272, "created_utc": 1667851216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is-it possible to create a data source in denodo from a microsoft sharepoint (List) by using the query.iqy generated when we use the feature \"export to excel\" ?", "author_fullname": "t2_t4dkdc3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Denodo &lt;=&gt; Sharepoint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yponds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667919482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is-it possible to create a data source in denodo from a microsoft sharepoint (List) by using the query.iqy generated when we use the feature &amp;quot;export to excel&amp;quot; ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yponds", "is_robot_indexable": true, "report_reasons": null, "author": "Moosh_Be", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yponds/denodo_sharepoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yponds/denodo_sharepoint/", "subreddit_subscribers": 79272, "created_utc": 1667919482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With certain companies/industries still growing their data capabilities, and other companies/industries scaling back the headcount, how is this affecting your feelings about job switching?\n\nI've found it to be difficult to truly gauge how current business is doing at the companies and the direction of their data team during interviews.", "author_fullname": "t2_a2hwqab5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the current job market affect likelihood of switching companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ypoeqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667918949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With certain companies/industries still growing their data capabilities, and other companies/industries scaling back the headcount, how is this affecting your feelings about job switching?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found it to be difficult to truly gauge how current business is doing at the companies and the direction of their data team during interviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ypoeqt", "is_robot_indexable": true, "report_reasons": null, "author": "Crumbsinmypack", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypoeqt/does_the_current_job_market_affect_likelihood_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypoeqt/does_the_current_job_market_affect_likelihood_of/", "subreddit_subscribers": 79272, "created_utc": 1667918949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While reading about Airflow, the DAG stuff felt exactly similar to the topological sort algorithm.  \n\nP.S: I am new to airflow.", "author_fullname": "t2_ii16zylj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I call airflow an implementation of the Topological sort algorithm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_ypniq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667916999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While reading about Airflow, the DAG stuff felt exactly similar to the topological sort algorithm.  &lt;/p&gt;\n\n&lt;p&gt;P.S: I am new to airflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ypniq2", "is_robot_indexable": true, "report_reasons": null, "author": "ZENDRO_hex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ypniq2/can_i_call_airflow_an_implementation_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ypniq2/can_i_call_airflow_an_implementation_of_the/", "subreddit_subscribers": 79272, "created_utc": 1667916999.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}