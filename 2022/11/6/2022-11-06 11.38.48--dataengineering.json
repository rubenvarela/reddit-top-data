{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The ones you feel are critical, but are missing, especially if the pipeline was developed by beginners.", "author_fullname": "t2_g4v8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you share some of the best software engineering practices you can apply to data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymz0oh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667666190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The ones you feel are critical, but are missing, especially if the pipeline was developed by beginners.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymz0oh", "is_robot_indexable": true, "report_reasons": null, "author": "swapripper", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymz0oh/can_you_share_some_of_the_best_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymz0oh/can_you_share_some_of_the_best_software/", "subreddit_subscribers": 79046, "created_utc": 1667666190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "According to Statista, nearly half of the emails sent worldwide are spam. In 2021, it was estimated that nearly 319.6 billion emails were sent and received daily.\n\nThough Gmail marks most of the emails as spam, still we receive bunch of marketing and promotional emails. I have tried to develope the datapipeline to see from what all domains, I receive emails daily. I have created dashboard where I can see all these stats and I can go and block the particular domains which makes my task lil easier instead of going through each and every email and blocking.\n\nTech Stack :\n\nPython\n\nAirflow\n\nGrafana\n\n&amp;#x200B;\n\nDashboard Link : [https://snapshots.raintank.io/dashboard/snapshot/E3bVrLkkPYU0XzpfjPRbwZXsLCMlwg7t](https://snapshots.raintank.io/dashboard/snapshot/E3bVrLkkPYU0XzpfjPRbwZXsLCMlwg7t)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[Dash Board](https://preview.redd.it/d7oeprsn09y91.png?width=2742&amp;format=png&amp;auto=webp&amp;s=91692867b9920c391d5eeaa62085576f1ee89950)\n\nGitHub :\n\n[https://github.com/amrgb50/MANAGE-GMAIL](https://github.com/amrgb50/MANAGE-GMAIL)\n\n&amp;#x200B;\n\n[App Flow](https://preview.redd.it/dck7scg8l8y91.png?width=1804&amp;format=png&amp;auto=webp&amp;s=0b4400dfd0678a46ea01f00d295f8b7f7f7b3580)\n\n&amp;#x200B;\n\nImprovements and next plan :\n\n1. I am learning docker and kubernetes. So next step will be containerizing this app and run in cloud.\n2. Implementing DQ checks.\n\nAny and all feedback is absolutely welcome! This is my first project and trying to hone my skills for DE profession. Please feel free to provide any feedback!", "author_fullname": "t2_r1secbn2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Project - Gmail Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dck7scg8l8y91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0dffff623ebbfe409250ebbd80ff2bd8b5476d0a"}, {"y": 75, "x": 216, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9338350505ff672e7c568fe6ec6b54704a9f2b9"}, {"y": 112, "x": 320, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed630de193a5457c786ad9150370411478fe37c9"}, {"y": 224, "x": 640, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=71b32d4b65f2edc862a1aeb21e883d2b67690cd5"}, {"y": 337, "x": 960, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=af6ea7275d0952d7482e1084aca994d3ebb40c28"}, {"y": 379, "x": 1080, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f5c385593044b6e139d5e6f3e91a21a043642d92"}], "s": {"y": 634, "x": 1804, "u": "https://preview.redd.it/dck7scg8l8y91.png?width=1804&amp;format=png&amp;auto=webp&amp;s=0b4400dfd0678a46ea01f00d295f8b7f7f7b3580"}, "id": "dck7scg8l8y91"}, "d7oeprsn09y91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a62fbdcecabd64c9eb2c5ff12db1bfc7f3be889"}, {"y": 109, "x": 216, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d1fc6d9815ee21d54a95ffca3c2bfa9c0571b3a"}, {"y": 162, "x": 320, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=537fb6930ff4972f62c4a567d5dce5ba5c4bb13d"}, {"y": 325, "x": 640, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf753896251acf68d97b36c6a6d9090b7563f1d7"}, {"y": 488, "x": 960, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2582ab372832bde0cb2d494bb57d2a45dd27d53a"}, {"y": 549, "x": 1080, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=31300bad910245f3a11c3033f61ae2cf767d0ff7"}], "s": {"y": 1396, "x": 2742, "u": "https://preview.redd.it/d7oeprsn09y91.png?width=2742&amp;format=png&amp;auto=webp&amp;s=91692867b9920c391d5eeaa62085576f1ee89950"}, "id": "d7oeprsn09y91"}}, "name": "t3_yndu7k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gVA8P5cPQOCY8cnD5k6J0X-TP9LodqhJdW4tDlBKY0s.jpg", "edited": 1667704672.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667700565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to Statista, nearly half of the emails sent worldwide are spam. In 2021, it was estimated that nearly 319.6 billion emails were sent and received daily.&lt;/p&gt;\n\n&lt;p&gt;Though Gmail marks most of the emails as spam, still we receive bunch of marketing and promotional emails. I have tried to develope the datapipeline to see from what all domains, I receive emails daily. I have created dashboard where I can see all these stats and I can go and block the particular domains which makes my task lil easier instead of going through each and every email and blocking.&lt;/p&gt;\n\n&lt;p&gt;Tech Stack :&lt;/p&gt;\n\n&lt;p&gt;Python&lt;/p&gt;\n\n&lt;p&gt;Airflow&lt;/p&gt;\n\n&lt;p&gt;Grafana&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Dashboard Link : &lt;a href=\"https://snapshots.raintank.io/dashboard/snapshot/E3bVrLkkPYU0XzpfjPRbwZXsLCMlwg7t\"&gt;https://snapshots.raintank.io/dashboard/snapshot/E3bVrLkkPYU0XzpfjPRbwZXsLCMlwg7t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d7oeprsn09y91.png?width=2742&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=91692867b9920c391d5eeaa62085576f1ee89950\"&gt;Dash Board&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/amrgb50/MANAGE-GMAIL\"&gt;https://github.com/amrgb50/MANAGE-GMAIL&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dck7scg8l8y91.png?width=1804&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b4400dfd0678a46ea01f00d295f8b7f7f7b3580\"&gt;App Flow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Improvements and next plan :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I am learning docker and kubernetes. So next step will be containerizing this app and run in cloud.&lt;/li&gt;\n&lt;li&gt;Implementing DQ checks.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any and all feedback is absolutely welcome! This is my first project and trying to hone my skills for DE profession. Please feel free to provide any feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "yndu7k", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Log-2723", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yndu7k/data_engineering_project_gmail_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yndu7k/data_engineering_project_gmail_manager/", "subreddit_subscribers": 79046, "created_utc": 1667700565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I\u2019m looking for learning resources to create CI/CD processes for our Azure Databricks and GitHub repo. Is GitHub Actions the answer? Any recommendations or help is appreciated.", "author_fullname": "t2_a0qsnkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD with Databricks and GitHub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymr04r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667646735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I\u2019m looking for learning resources to create CI/CD processes for our Azure Databricks and GitHub repo. Is GitHub Actions the answer? Any recommendations or help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymr04r", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Membership-8", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymr04r/cicd_with_databricks_and_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymr04r/cicd_with_databricks_and_github/", "subreddit_subscribers": 79046, "created_utc": 1667646735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a python script that pulls data using an API and loads a table onto an amazon rds database and i\u2019m using mysql to query the database and then creating a tableau dashboard using the information. Would i be able to use airflow to trigger the python script to update the database and then run the mysql queries and update the dashboard?", "author_fullname": "t2_sfg62", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should i use airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yn7t0y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667685968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a python script that pulls data using an API and loads a table onto an amazon rds database and i\u2019m using mysql to query the database and then creating a tableau dashboard using the information. Would i be able to use airflow to trigger the python script to update the database and then run the mysql queries and update the dashboard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yn7t0y", "is_robot_indexable": true, "report_reasons": null, "author": "2teknical", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yn7t0y/should_i_use_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yn7t0y/should_i_use_airflow/", "subreddit_subscribers": 79046, "created_utc": 1667685968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have never worked with data larger than 50GB and am wondering how dashboards like Tableau, which have a 15gb extract limit, visualize 2TB+ data? \n\nThe common steps I've taken are to roll-up dates from days to months (maybe need to do months to quarters), reduce the number of columns to minimum needed, and filter further into a collection of themed fragment tables (by one nun-null dimension). \n\nWondering how others handle the fragmentation of TB+ data size for dashboard output tools like Tableau that have limited extract sizes.", "author_fullname": "t2_7y3cr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle TB data aggregations for dashboard extracts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yndujd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667700592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have never worked with data larger than 50GB and am wondering how dashboards like Tableau, which have a 15gb extract limit, visualize 2TB+ data? &lt;/p&gt;\n\n&lt;p&gt;The common steps I&amp;#39;ve taken are to roll-up dates from days to months (maybe need to do months to quarters), reduce the number of columns to minimum needed, and filter further into a collection of themed fragment tables (by one nun-null dimension). &lt;/p&gt;\n\n&lt;p&gt;Wondering how others handle the fragmentation of TB+ data size for dashboard output tools like Tableau that have limited extract sizes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yndujd", "is_robot_indexable": true, "report_reasons": null, "author": "SevenEyes", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yndujd/how_do_you_handle_tb_data_aggregations_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yndujd/how_do_you_handle_tb_data_aggregations_for/", "subreddit_subscribers": 79046, "created_utc": 1667700592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a working professional and want to get the certification in 7 days \nHoping that's reasonable.\n\nI have no cloud experience but have completed the virtual 5 day training", "author_fullname": "t2_f836ym4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what's the best roadmap for DP-900 after completing Microsoft training? Thinking of taking runes YouTube course or what else ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymt58v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667652892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a working professional and want to get the certification in 7 days \nHoping that&amp;#39;s reasonable.&lt;/p&gt;\n\n&lt;p&gt;I have no cloud experience but have completed the virtual 5 day training&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ymt58v", "is_robot_indexable": true, "report_reasons": null, "author": "Aggravating_Wind8365", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymt58v/whats_the_best_roadmap_for_dp900_after_completing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymt58v/whats_the_best_roadmap_for_dp900_after_completing/", "subreddit_subscribers": 79046, "created_utc": 1667652892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am seeing a new trend online with universities offering  \"Micromasters\" and Professional Certificates that are only 4-6 months. Technically my Data Science degree from Syracuse is a Micro Masters since it's only 5 graduate level courses.\n\nI'd love to finish it but the program is rather expensive Bout $3500 a course and I'd need 6 more classes to get it.\n\nIve been browsing edX.org because I took their Introduction to Computer Science course taught by MIT professors and really enjoyed it. Learned lots of computer science  concepts as well as learning Python.\n\nI'm seeing quite a few Data Engineering programs on there but browsing though them some seem a bit to basic.\n\nIf you look at this program it's only $1000 or so and is 14  courses and says you can finish it in a year doing 2-3 hours a week but obviously you can finish it much faster since the program is your own pace.\n\nThe link I here  https://www.edx.org/professional-certificate/ibm-data-engineering\n\nHowever this is the description for their SQL for Data Engineering Courses \n\n```\nSQL Concepts for Data Engineers\n\nIn this short course you will learn additional\nSQL concepts such as views, stored\nprocedures, transactions and joins.\n\n```\nNot only is this not what I would consider SQL for Data Engineering but it Also seems rather simple. Joins, views thats\nThe stuff you learn in Intro to SQL courses. If I do this program I'd prolly just blast through it in one afternoon.\n\nBut then there are classes like this that seem very useful \n```\nBuilding ETL and Data Pipelines with Bash, Airflow and Kafka\n\n2\u20134 hours per week, for 5 weeks\n\nThis course provides you with practical skills to build and manage data pipelines and Extract, Transform, Load (ETL) processes using shell scripts, Airflow and Kafka.\n\nView the course\n\n```\nOr all of these \n\n```\n\nLinux Commands &amp; Shell Scripting\n\n3\u20134 hours per week, for 1 weeks\n\nThis\u00a0mini-course describes shell commands and how to use the advanced features of the Bash shell to automate complicated database tasks. For those not familiar with shell scripting, this course provides an overview of common Linux Shell Commands and shell scripting basics.\n\nView the course\n\nRelational Database Administration (DBA)\n\n2\u20133 hours per week, for 8 weeks\n\nThis course helps you develop the foundational skills required to perform the role of a Database Administrator (DBA) including designing, implementing, securing, maintaining, troubleshooting and automating databases such as MySQL, PostgreSQL and Db2.\n\nView the course\n\nBuilding ETL and Data Pipelines with Bash, Airflow and Kafka\n\n2\u20134 hours per week, for 5 weeks\n\nThis course provides you with practical skills to build and manage data pipelines and Extract, Transform, Load (ETL) processes using shell scripts, Airflow and Kafka.\n\nView the course\n\nData Warehousing and BI Analytics\n\n2\u20133 hours per week, for 6 weeks\n\nThis course introduces you to designing, implementing and populating a data warehouse and analyzing its data using SQL &amp; Business Intelligence (BI) tools.\n\nView the course\n\nNoSQL Database Basics\n\n2\u20133 hours per week, for 5 weeks\n\nThis course introduces you to the fundamentals of NoSQL, including the four key non-relational database categories. By the end of the course you will have hands-on skills for working with MongoDB, Cassandra and IBM Cloudant NoSQL databases.\n\nView the course\n\nBig Data, Hadoop, and Spark Basics\n\n2\u20133 hours per week, for 6 weeks\n\nThis course provides foundational big data practitioner knowledge and analytical skills using popular big data tools, including Hadoop and Spark. Learn and practice your big data skills hands-on.\n\nView the course\n\nApache Spark for Data Engineering and Machine Learning\n\n2\u20133 hours per week, for 3 weeks\n\nThis short course introduces you to the fundamentals of Data Engineering and Machine Learning with Apache Spark, including Spark Structured Streaming,\u00a0ETL for Machine Learning (ML) Pipelines,\u00a0and Spark ML. By the end of the course, you will have hands-on experience applying Spark skills to ETL and ML workflows.\n\nView the course\n\n ```\nAnd this is just one program \n\nMIT has one too that's a bit more expensive but still super reasonable. https://executive-ed.xpro.mit.edu/professional-certificate-data-engineering\n\n\n\n\nEither way I think I'll be taking one of these courses  or another similar one somewhere else to expand my skill set just out of SQL Server, Basic Python, SSIS and SSAS,  Azure and good ol Excel the world's greatest database.\n\nIf anyone else here would like to look into these programs and read through the curriculums and try to determine which program is the best and even have a group of us take it together that would be really cool . We can make a Git Hub for it and everything and work on some of the more challenging projects together.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Degree/Certificate programs for Data Engineering.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yngvld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1667710168.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667709845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am seeing a new trend online with universities offering  &amp;quot;Micromasters&amp;quot; and Professional Certificates that are only 4-6 months. Technically my Data Science degree from Syracuse is a Micro Masters since it&amp;#39;s only 5 graduate level courses.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to finish it but the program is rather expensive Bout $3500 a course and I&amp;#39;d need 6 more classes to get it.&lt;/p&gt;\n\n&lt;p&gt;Ive been browsing edX.org because I took their Introduction to Computer Science course taught by MIT professors and really enjoyed it. Learned lots of computer science  concepts as well as learning Python.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeing quite a few Data Engineering programs on there but browsing though them some seem a bit to basic.&lt;/p&gt;\n\n&lt;p&gt;If you look at this program it&amp;#39;s only $1000 or so and is 14  courses and says you can finish it in a year doing 2-3 hours a week but obviously you can finish it much faster since the program is your own pace.&lt;/p&gt;\n\n&lt;p&gt;The link I here  &lt;a href=\"https://www.edx.org/professional-certificate/ibm-data-engineering\"&gt;https://www.edx.org/professional-certificate/ibm-data-engineering&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However this is the description for their SQL for Data Engineering Courses &lt;/p&gt;\n\n&lt;p&gt;```\nSQL Concepts for Data Engineers&lt;/p&gt;\n\n&lt;p&gt;In this short course you will learn additional\nSQL concepts such as views, stored\nprocedures, transactions and joins.&lt;/p&gt;\n\n&lt;p&gt;```\nNot only is this not what I would consider SQL for Data Engineering but it Also seems rather simple. Joins, views thats\nThe stuff you learn in Intro to SQL courses. If I do this program I&amp;#39;d prolly just blast through it in one afternoon.&lt;/p&gt;\n\n&lt;p&gt;But then there are classes like this that seem very useful \n```\nBuilding ETL and Data Pipelines with Bash, Airflow and Kafka&lt;/p&gt;\n\n&lt;p&gt;2\u20134 hours per week, for 5 weeks&lt;/p&gt;\n\n&lt;p&gt;This course provides you with practical skills to build and manage data pipelines and Extract, Transform, Load (ETL) processes using shell scripts, Airflow and Kafka.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;```\nOr all of these &lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;Linux Commands &amp;amp; Shell Scripting&lt;/p&gt;\n\n&lt;p&gt;3\u20134 hours per week, for 1 weeks&lt;/p&gt;\n\n&lt;p&gt;This\u00a0mini-course describes shell commands and how to use the advanced features of the Bash shell to automate complicated database tasks. For those not familiar with shell scripting, this course provides an overview of common Linux Shell Commands and shell scripting basics.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;Relational Database Administration (DBA)&lt;/p&gt;\n\n&lt;p&gt;2\u20133 hours per week, for 8 weeks&lt;/p&gt;\n\n&lt;p&gt;This course helps you develop the foundational skills required to perform the role of a Database Administrator (DBA) including designing, implementing, securing, maintaining, troubleshooting and automating databases such as MySQL, PostgreSQL and Db2.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;Building ETL and Data Pipelines with Bash, Airflow and Kafka&lt;/p&gt;\n\n&lt;p&gt;2\u20134 hours per week, for 5 weeks&lt;/p&gt;\n\n&lt;p&gt;This course provides you with practical skills to build and manage data pipelines and Extract, Transform, Load (ETL) processes using shell scripts, Airflow and Kafka.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;Data Warehousing and BI Analytics&lt;/p&gt;\n\n&lt;p&gt;2\u20133 hours per week, for 6 weeks&lt;/p&gt;\n\n&lt;p&gt;This course introduces you to designing, implementing and populating a data warehouse and analyzing its data using SQL &amp;amp; Business Intelligence (BI) tools.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;NoSQL Database Basics&lt;/p&gt;\n\n&lt;p&gt;2\u20133 hours per week, for 5 weeks&lt;/p&gt;\n\n&lt;p&gt;This course introduces you to the fundamentals of NoSQL, including the four key non-relational database categories. By the end of the course you will have hands-on skills for working with MongoDB, Cassandra and IBM Cloudant NoSQL databases.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;Big Data, Hadoop, and Spark Basics&lt;/p&gt;\n\n&lt;p&gt;2\u20133 hours per week, for 6 weeks&lt;/p&gt;\n\n&lt;p&gt;This course provides foundational big data practitioner knowledge and analytical skills using popular big data tools, including Hadoop and Spark. Learn and practice your big data skills hands-on.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;Apache Spark for Data Engineering and Machine Learning&lt;/p&gt;\n\n&lt;p&gt;2\u20133 hours per week, for 3 weeks&lt;/p&gt;\n\n&lt;p&gt;This short course introduces you to the fundamentals of Data Engineering and Machine Learning with Apache Spark, including Spark Structured Streaming,\u00a0ETL for Machine Learning (ML) Pipelines,\u00a0and Spark ML. By the end of the course, you will have hands-on experience applying Spark skills to ETL and ML workflows.&lt;/p&gt;\n\n&lt;p&gt;View the course&lt;/p&gt;\n\n&lt;p&gt;```\nAnd this is just one program &lt;/p&gt;\n\n&lt;p&gt;MIT has one too that&amp;#39;s a bit more expensive but still super reasonable. &lt;a href=\"https://executive-ed.xpro.mit.edu/professional-certificate-data-engineering\"&gt;https://executive-ed.xpro.mit.edu/professional-certificate-data-engineering&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Either way I think I&amp;#39;ll be taking one of these courses  or another similar one somewhere else to expand my skill set just out of SQL Server, Basic Python, SSIS and SSAS,  Azure and good ol Excel the world&amp;#39;s greatest database.&lt;/p&gt;\n\n&lt;p&gt;If anyone else here would like to look into these programs and read through the curriculums and try to determine which program is the best and even have a group of us take it together that would be really cool . We can make a Git Hub for it and everything and work on some of the more challenging projects together.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?auto=webp&amp;s=97515d509296f883a009858015c0ac346717d04c", "width": 1134, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f02e1392c5a0328ceb56526065a4e93579b2b5d", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cdbc3c367cdd8fa57faadd371159537a3dbe0a80", "width": 216, "height": 128}, {"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=92fffb3c6fe9342496cad163d3d6cc68a976eda5", "width": 320, "height": 190}, {"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7967c13350a6b98d7c0291c5c31ebef04a6afaca", "width": 640, "height": 380}, {"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=948b3eefeda76aa731968b75ce65948cb290b648", "width": 960, "height": 571}, {"url": "https://external-preview.redd.it/4EJYmWa3ftloTyhO2bqOr8kGnBIW5VOLoBZdVhsJTZ0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=efb47c31a31727ed5b8c3fc103ad2c306a3fc746", "width": 1080, "height": 642}], "variants": {}, "id": "I6YIO-70iBGhizTbOgRrkR_gC460yPGOSFOIvNw-6Yg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "yngvld", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yngvld/degreecertificate_programs_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yngvld/degreecertificate_programs_for_data_engineering/", "subreddit_subscribers": 79046, "created_utc": 1667709845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI'm trying to design some table with standardized data from multiple sources, in the most effective way.\n\nI'm working with Postgres and the current design is as following:\n\n1. The \\`main\\` schema has dimension tables (for example \\`units\\`, \\`currencies\\` and \\`countries\\`)\n2. Every source has it's own schema with dimension tables for the same columns (units, currencies and countries)\n3. In every schema, the dimension tables have an additional column \\`main\\_id\\` that is null at first, and requires an analyst to map the source's value to the corresponding one in our main schema. (For example, \\`US\\` in in source #1 should be mapped to \\`United States\\` in the main schema).\n4. There are materialized views in the \\`main\\` schema, unioning the data from every source, taking the \\`main\\_id\\` value of every dimension in every source. BUT, if some row in a source has a value who's \\`main\\_id\\` is still null (meaning, it wasn't mapped), then this row is filtered out.\n\n&amp;#x200B;\n\n[Architecture](https://preview.redd.it/cass3z81y7y91.png?width=1496&amp;format=png&amp;auto=webp&amp;s=8fa7821595d5209d88c91a3ca31f5bf8ba1852b8)\n\nSo currently, if new data is introduced into a source or if a new value is mapped, I just need to refresh the materialized views and the new data will be accessible in the mviews.\n\nNow I need those mviews to be actual tables and I'm wondering what the best way is to keep them up to date.\n\n1. Should I have a stored procedure per schema, inserting new data into the main tables? I could call it manually after a mapping is done or it could be triggered every few minutes\n2. Should I have a Python script implement the insertion logic?\n3. Should I have a trigger on every insert (data tables) / update (the mapping tables) to insert the data to the main tables? (I don't love triggers because they add hidden complexity)\n\n&amp;#x200B;\n\nAny other ideas will be very appreciated!\n\n&amp;#x200B;\n\nThanks :)", "author_fullname": "t2_74d9mi1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Standardization after Dimension Mapping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cass3z81y7y91": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/cass3z81y7y91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=92f10bde1d25385db89dc4af94c3256f562a5191"}, {"y": 163, "x": 216, "u": "https://preview.redd.it/cass3z81y7y91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a7ad4f4ef294944932c452ffd1485bcbf66fae14"}, {"y": 242, "x": 320, "u": "https://preview.redd.it/cass3z81y7y91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=05470d433a30d114dc8c6cb516daeefc2193c1bd"}, {"y": 485, "x": 640, "u": "https://preview.redd.it/cass3z81y7y91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=870d7161fdd07754e1e02847d902ffb080676d8b"}, {"y": 727, "x": 960, "u": "https://preview.redd.it/cass3z81y7y91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8ac16404696df978a5b4ec337bb21363a5c7afb2"}, {"y": 818, "x": 1080, "u": "https://preview.redd.it/cass3z81y7y91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=328e2bf9fabb349af65e96c3c88ed31fa42d4b2b"}], "s": {"y": 1134, "x": 1496, "u": "https://preview.redd.it/cass3z81y7y91.png?width=1496&amp;format=png&amp;auto=webp&amp;s=8fa7821595d5209d88c91a3ca31f5bf8ba1852b8"}, "id": "cass3z81y7y91"}}, "name": "t3_ynajp4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G5rUXvTKrIZLmKTvZAZ5UBVEIBMAZBcQonqapI6C4Wg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667691991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to design some table with standardized data from multiple sources, in the most effective way.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with Postgres and the current design is as following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The `main` schema has dimension tables (for example `units`, `currencies` and `countries`)&lt;/li&gt;\n&lt;li&gt;Every source has it&amp;#39;s own schema with dimension tables for the same columns (units, currencies and countries)&lt;/li&gt;\n&lt;li&gt;In every schema, the dimension tables have an additional column `main_id` that is null at first, and requires an analyst to map the source&amp;#39;s value to the corresponding one in our main schema. (For example, `US` in in source #1 should be mapped to `United States` in the main schema).&lt;/li&gt;\n&lt;li&gt;There are materialized views in the `main` schema, unioning the data from every source, taking the `main_id` value of every dimension in every source. BUT, if some row in a source has a value who&amp;#39;s `main_id` is still null (meaning, it wasn&amp;#39;t mapped), then this row is filtered out.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cass3z81y7y91.png?width=1496&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8fa7821595d5209d88c91a3ca31f5bf8ba1852b8\"&gt;Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So currently, if new data is introduced into a source or if a new value is mapped, I just need to refresh the materialized views and the new data will be accessible in the mviews.&lt;/p&gt;\n\n&lt;p&gt;Now I need those mviews to be actual tables and I&amp;#39;m wondering what the best way is to keep them up to date.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I have a stored procedure per schema, inserting new data into the main tables? I could call it manually after a mapping is done or it could be triggered every few minutes&lt;/li&gt;\n&lt;li&gt;Should I have a Python script implement the insertion logic?&lt;/li&gt;\n&lt;li&gt;Should I have a trigger on every insert (data tables) / update (the mapping tables) to insert the data to the main tables? (I don&amp;#39;t love triggers because they add hidden complexity)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any other ideas will be very appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ynajp4", "is_robot_indexable": true, "report_reasons": null, "author": "Helpful_Artist1439", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynajp4/data_standardization_after_dimension_mapping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ynajp4/data_standardization_after_dimension_mapping/", "subreddit_subscribers": 79046, "created_utc": 1667691991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for books/blogs/courses that helped you to advance further from an intermediate level. Secret resources that almost felt like cheat-codes after learning it. The ones that you don't see being talked about much.", "author_fullname": "t2_g4v8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most underrated/unknown resources that helped you upskill?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymyw76", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667665911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for books/blogs/courses that helped you to advance further from an intermediate level. Secret resources that almost felt like cheat-codes after learning it. The ones that you don&amp;#39;t see being talked about much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ymyw76", "is_robot_indexable": true, "report_reasons": null, "author": "swapripper", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymyw76/what_are_the_most_underratedunknown_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymyw76/what_are_the_most_underratedunknown_resources/", "subreddit_subscribers": 79046, "created_utc": 1667665911.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8c13n8vj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Pandas Functions That Help You Understand a Dataset Completely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_yn570b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7o0tOYgJlf16b_a8KzPtwXhYSe6EgJF5XOo5k36TiDQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667680027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/techtofreedom/10-pandas-functions-that-help-you-understand-a-dataset-completely-b7de7e7e14ab", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?auto=webp&amp;s=a7cb64a1167a1a4517d6c0646e0d42d86d6c9002", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bab686777db435ff29d6b80b47f7e49f2eb63b0", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98b03ee58005d02b067bf6f2dbf2e13ea231fed0", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b65026aa876f83b83419f635bff0ae7e64ba241", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9f7dab2817ff400f9fcbe7efcaba57f45f0b4fcd", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc1fc64115c345320d8a157bad9d55ca7b985f4f", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/pURynvTum1PfB1n80TuI1gA5AZdgZEsoBN7Om_56MDw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d84077ad712c6dfe401df4cd3d8f9bb38bda57e", "width": 1080, "height": 720}], "variants": {}, "id": "7wBi4n5WKWMEkMStw6hzcfzdIhpwvwBWmosCaE4JK94"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "yn570b", "is_robot_indexable": true, "report_reasons": null, "author": "yangzhou1993", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yn570b/10_pandas_functions_that_help_you_understand_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/techtofreedom/10-pandas-functions-that-help-you-understand-a-dataset-completely-b7de7e7e14ab", "subreddit_subscribers": 79046, "created_utc": 1667680027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nWould you recommend me to apply for google STEP or some real intern program at google?\n\nMy CV: [https://ibb.co/R9vMNPf](https://ibb.co/R9vMNPf)", "author_fullname": "t2_t5tmlvv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apply to google STEP or 'real' internship at google?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yn55oi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1667679931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;Would you recommend me to apply for google STEP or some real intern program at google?&lt;/p&gt;\n\n&lt;p&gt;My CV: &lt;a href=\"https://ibb.co/R9vMNPf\"&gt;https://ibb.co/R9vMNPf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8lpUvTVfQiPnccMXPZMlvhgoj2Ev98Y946j8Wzy39go.jpg?auto=webp&amp;s=9eceb005322fac3cc5491e4ed7a9595b674dc91c", "width": 765, "height": 1019}, "resolutions": [{"url": "https://external-preview.redd.it/8lpUvTVfQiPnccMXPZMlvhgoj2Ev98Y946j8Wzy39go.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c4c35e1d727a58e6fa484261d8a842a12bf0e0e9", "width": 108, "height": 143}, {"url": "https://external-preview.redd.it/8lpUvTVfQiPnccMXPZMlvhgoj2Ev98Y946j8Wzy39go.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6676fe5254e76ff797dccdd79aa258ab64950e42", "width": 216, "height": 287}, {"url": "https://external-preview.redd.it/8lpUvTVfQiPnccMXPZMlvhgoj2Ev98Y946j8Wzy39go.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d2ee0a0d0bcb4d2d75de59d0124eeab5c4c5774", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/8lpUvTVfQiPnccMXPZMlvhgoj2Ev98Y946j8Wzy39go.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8863f65182a7ed706c4e3100c682c482937441f", "width": 640, "height": 852}], "variants": {}, "id": "KdPcVejIeM09FUZ8-3u4srYV1GigHnD3bFF-2Ga9d28"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "yn55oi", "is_robot_indexable": true, "report_reasons": null, "author": "cs_phil", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yn55oi/apply_to_google_step_or_real_internship_at_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yn55oi/apply_to_google_step_or_real_internship_at_google/", "subreddit_subscribers": 79046, "created_utc": 1667679931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Passed AZ, DP and SC. Just got an entry level role as a data engineer for our synapse platform. It\u2019s just been handed over to us and no one entirely knows how to use it. I\u2019m basically going to be maintaining and adding to it. \n\nCan anyone give any tips/advice for taking on this role. This is purely an Azure Synapse role. \n\nI\u2019ve got a pretty basic understanding, branch creation, moving the code to prod. But anything else I don\u2019t know. Best way to learn?", "author_fullname": "t2_173udy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some tips for moving into a DE entry level role - Synapse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yn47dq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667677729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Passed AZ, DP and SC. Just got an entry level role as a data engineer for our synapse platform. It\u2019s just been handed over to us and no one entirely knows how to use it. I\u2019m basically going to be maintaining and adding to it. &lt;/p&gt;\n\n&lt;p&gt;Can anyone give any tips/advice for taking on this role. This is purely an Azure Synapse role. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got a pretty basic understanding, branch creation, moving the code to prod. But anything else I don\u2019t know. Best way to learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yn47dq", "is_robot_indexable": true, "report_reasons": null, "author": "prodigypro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yn47dq/some_tips_for_moving_into_a_de_entry_level_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yn47dq/some_tips_for_moving_into_a_de_entry_level_role/", "subreddit_subscribers": 79046, "created_utc": 1667677729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Requirements:\n- All datasets to have a primary key named \u201cid\u201d before SQL MERGE \n- Some datasets already contain pk named \u201cid\u201d\n- Some datasets contain pk named \u201cId\u201d\n- Some datasets contain pk named \u201cotherId\u201d\n- Some datasets do not contain a pk but contain other \u201cids\u201d and a JSON record which can be hashed to form a unique surrogate key\n\nShould I define the PK in the datasets and enhance each row during extraction to conform?\n\nThis is an ELT pipeline so I want to do as little in Python as necessary to enable faster deployment of new connectors to new APIs down the road.", "author_fullname": "t2_ltzfd6pc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you like to define primary keys during ETL / ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yn2sw2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667674506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Requirements:\n- All datasets to have a primary key named \u201cid\u201d before SQL MERGE \n- Some datasets already contain pk named \u201cid\u201d\n- Some datasets contain pk named \u201cId\u201d\n- Some datasets contain pk named \u201cotherId\u201d\n- Some datasets do not contain a pk but contain other \u201cids\u201d and a JSON record which can be hashed to form a unique surrogate key&lt;/p&gt;\n\n&lt;p&gt;Should I define the PK in the datasets and enhance each row during extraction to conform?&lt;/p&gt;\n\n&lt;p&gt;This is an ELT pipeline so I want to do as little in Python as necessary to enable faster deployment of new connectors to new APIs down the road.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yn2sw2", "is_robot_indexable": true, "report_reasons": null, "author": "FactMuncher", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yn2sw2/how_do_you_like_to_define_primary_keys_during_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yn2sw2/how_do_you_like_to_define_primary_keys_during_etl/", "subreddit_subscribers": 79046, "created_utc": 1667674506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3ns5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Requesting C&amp;C on DE diagram of a basic data platform setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": true, "name": "t3_ynlt5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fs8I1FnHI6qNjQo_IvZkb_RkM2xRBdmvKEXQnKxb9uE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1667727772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rpn8b0dwecy91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rpn8b0dwecy91.png?auto=webp&amp;s=46546085a2bad7f56c746d1610a2e0adfc07c813", "width": 1767, "height": 1172}, "resolutions": [{"url": "https://preview.redd.it/rpn8b0dwecy91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=73d69a851401188543a70875abf6ce2fa93d379a", "width": 108, "height": 71}, {"url": "https://preview.redd.it/rpn8b0dwecy91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f505f7c1a5ec9b8e886989ea119335f8e3fc4c19", "width": 216, "height": 143}, {"url": "https://preview.redd.it/rpn8b0dwecy91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7247754881d4ce807da9551f68921ca3dd848585", "width": 320, "height": 212}, {"url": "https://preview.redd.it/rpn8b0dwecy91.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=accea3bc97449a68c1c2300bc9cc90422d7ccbea", "width": 640, "height": 424}, {"url": "https://preview.redd.it/rpn8b0dwecy91.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b7f11004bece30826b951fc935ed1762acad18ed", "width": 960, "height": 636}, {"url": "https://preview.redd.it/rpn8b0dwecy91.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96cf6b11462ae5520230effed5336400bfcb28ff", "width": 1080, "height": 716}], "variants": {}, "id": "jFdDtZUCIPdJ8cRx-lMI32tmEfC_EmQ8s2lRwWH25yA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ynlt5c", "is_robot_indexable": true, "report_reasons": null, "author": "fico86", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynlt5c/requesting_cc_on_de_diagram_of_a_basic_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rpn8b0dwecy91.png", "subreddit_subscribers": 79046, "created_utc": 1667727772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m building a framework for getting data into or out of Snowflake using Python. It\u2019s just bare bones and will be extended over time.\n\nI\u2019m looking for name suggestions. Pipewire has already been used. The current \u2018Python Ingress/Egress Framework\u2019 is just a bit, well, sh!t.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Name suggestions: Pipeline Framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ynl2hg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667724969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m building a framework for getting data into or out of Snowflake using Python. It\u2019s just bare bones and will be extended over time.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for name suggestions. Pipewire has already been used. The current \u2018Python Ingress/Egress Framework\u2019 is just a bit, well, sh!t.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ynl2hg", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynl2hg/name_suggestions_pipeline_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ynl2hg/name_suggestions_pipeline_framework/", "subreddit_subscribers": 79046, "created_utc": 1667724969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently came across articles where it was stated external tokenisation does not work with large amount of data and can slow down the overall data load time in the pipeline. If anyone can link anything as to why or explain why tokenisation will not work at scale?", "author_fullname": "t2_62ee3cao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Snowflake\u2019s external tokenisation work at scale (huge amount on data)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ynkvk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667724184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently came across articles where it was stated external tokenisation does not work with large amount of data and can slow down the overall data load time in the pipeline. If anyone can link anything as to why or explain why tokenisation will not work at scale?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ynkvk7", "is_robot_indexable": true, "report_reasons": null, "author": "dotslash06", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynkvk7/can_snowflakes_external_tokenisation_work_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ynkvk7/can_snowflakes_external_tokenisation_work_at/", "subreddit_subscribers": 79046, "created_utc": 1667724184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nso I am a PM for a ML product and we are running into scaling trouble. The product uses K8s to scale horizontally and the Pods needs to run initially some OLAP queries one currently a PostGre instance. Aggregation is used.\n\nIt will have ~ 100 tables and each table will have ~ 400 Million rows growing 210k rows each day. There are just a few columns ~ 15 with either integer or strings.\n\nOptions I see is:\n- Use Connection Pooling and Read Replicas -&gt; could this be sufficient already?\n- Use Snowflake and it\u2019s auto scale feature and let the scheduler do the coordination work -&gt; heard snowflake is however bad for many concurrent short lived connections?\n- Use Citus Hyperscale -&gt; Engineers told me this is super expensive on Azure hence no option probably?\n- Put stuff low level on the Storage with suitable partitioning and then directly read files from there. -&gt; High development effort and one creates a solution for a problem that should normally be already solved better by some technology I assume?\n- Spark is for whatever reason no option for us according to the engineers.\n\nWhat is your take? How would you go about this scaling bottleneck and rearchitecture?\n\nThanks a lot for reading!", "author_fullname": "t2_cg3vl4i3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What DB/Storage to choose with K8s, OLAP queries and a lot of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ynkrjv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667723754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;so I am a PM for a ML product and we are running into scaling trouble. The product uses K8s to scale horizontally and the Pods needs to run initially some OLAP queries one currently a PostGre instance. Aggregation is used.&lt;/p&gt;\n\n&lt;p&gt;It will have ~ 100 tables and each table will have ~ 400 Million rows growing 210k rows each day. There are just a few columns ~ 15 with either integer or strings.&lt;/p&gt;\n\n&lt;p&gt;Options I see is:\n- Use Connection Pooling and Read Replicas -&amp;gt; could this be sufficient already?\n- Use Snowflake and it\u2019s auto scale feature and let the scheduler do the coordination work -&amp;gt; heard snowflake is however bad for many concurrent short lived connections?\n- Use Citus Hyperscale -&amp;gt; Engineers told me this is super expensive on Azure hence no option probably?\n- Put stuff low level on the Storage with suitable partitioning and then directly read files from there. -&amp;gt; High development effort and one creates a solution for a problem that should normally be already solved better by some technology I assume?\n- Spark is for whatever reason no option for us according to the engineers.&lt;/p&gt;\n\n&lt;p&gt;What is your take? How would you go about this scaling bottleneck and rearchitecture?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ynkrjv", "is_robot_indexable": true, "report_reasons": null, "author": "DataDemystifier", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynkrjv/what_dbstorage_to_choose_with_k8s_olap_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ynkrjv/what_dbstorage_to_choose_with_k8s_olap_queries/", "subreddit_subscribers": 79046, "created_utc": 1667723754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been learning DE for a few weeks now hoping to eventually land a job but I still have some concerns.\n\nMy impression is that DE is similar to DevOps where you're only given attention when something breaks and your superior needs you to fix it ASAP. When everything is working as expected, you are rarely recognized for your good work.\n\nWhen something goes wrong, you're the person that everyone points their finger at and blames. You're expected to be a jack of all trades developer while at the same time being a master DE developer. Basically, you need to know a lot of shit\n\nWhile doing my research about the field, I came across another reddit post where people were mentioning that working as a DE was stressful AF.", "author_fullname": "t2_yex15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is DE one of those thankless jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ynkjno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667722915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been learning DE for a few weeks now hoping to eventually land a job but I still have some concerns.&lt;/p&gt;\n\n&lt;p&gt;My impression is that DE is similar to DevOps where you&amp;#39;re only given attention when something breaks and your superior needs you to fix it ASAP. When everything is working as expected, you are rarely recognized for your good work.&lt;/p&gt;\n\n&lt;p&gt;When something goes wrong, you&amp;#39;re the person that everyone points their finger at and blames. You&amp;#39;re expected to be a jack of all trades developer while at the same time being a master DE developer. Basically, you need to know a lot of shit&lt;/p&gt;\n\n&lt;p&gt;While doing my research about the field, I came across another reddit post where people were mentioning that working as a DE was stressful AF.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ynkjno", "is_robot_indexable": true, "report_reasons": null, "author": "desperate-1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynkjno/is_de_one_of_those_thankless_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ynkjno/is_de_one_of_those_thankless_jobs/", "subreddit_subscribers": 79046, "created_utc": 1667722915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working as a data engineer in a non-tech company. My day to day work involves fetching data from various internal sources like API, Data warehouse, Data lake, operational tables to name a few. After fetching the data, I transform it according to the business requirements and load it to whatever target the end users want it in. Finally, the data scientists create the dashboard as per end user requirements using the data from my target destination. \n\nJust to be clear, I have not been criticized, warned or questioned about my work. However, I just want to start demonstrating the value of my work to business users. It seems like the folks who create the final dashboard on my data find it relatively easier to show the value of their work to end business users.", "author_fullname": "t2_t6oufyru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to increase my visibility to business users as a data engineer? It seems like the final dashboard creators have a higher visibility and find it relatively easier to show the value of their work to end buisness users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymuxae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667657182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working as a data engineer in a non-tech company. My day to day work involves fetching data from various internal sources like API, Data warehouse, Data lake, operational tables to name a few. After fetching the data, I transform it according to the business requirements and load it to whatever target the end users want it in. Finally, the data scientists create the dashboard as per end user requirements using the data from my target destination. &lt;/p&gt;\n\n&lt;p&gt;Just to be clear, I have not been criticized, warned or questioned about my work. However, I just want to start demonstrating the value of my work to business users. It seems like the folks who create the final dashboard on my data find it relatively easier to show the value of their work to end business users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ymuxae", "is_robot_indexable": true, "report_reasons": null, "author": "MatchCaseFirst", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymuxae/how_to_increase_my_visibility_to_business_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymuxae/how_to_increase_my_visibility_to_business_users/", "subreddit_subscribers": 79046, "created_utc": 1667657182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have hosted Apache superset on Azure web app for PoC purpose \n\nIf you are using it in your company , where you are hosting it for production\n\nVirtual Machine ? Kubernetes ? Preset ?", "author_fullname": "t2_dgq3lsfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Superset hosting platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ymtt2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667654581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have hosted Apache superset on Azure web app for PoC purpose &lt;/p&gt;\n\n&lt;p&gt;If you are using it in your company , where you are hosting it for production&lt;/p&gt;\n\n&lt;p&gt;Virtual Machine ? Kubernetes ? Preset ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "ymtt2v", "is_robot_indexable": true, "report_reasons": null, "author": "authentichooman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ymtt2v/apache_superset_hosting_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ymtt2v/apache_superset_hosting_platform/", "subreddit_subscribers": 79046, "created_utc": 1667654581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have wondered (since I am studying) if it is worth investing more years of my life in something that can be very competitive and difficult and with poor pay, existential doubt", "author_fullname": "t2_rzm8vs2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The future for data engineering is promising? or is it perhaps excessive work with little pay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ynhgwu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667711791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have wondered (since I am studying) if it is worth investing more years of my life in something that can be very competitive and difficult and with poor pay, existential doubt&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ynhgwu", "is_robot_indexable": true, "report_reasons": null, "author": "IlustriousCap", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ynhgwu/the_future_for_data_engineering_is_promising_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ynhgwu/the_future_for_data_engineering_is_promising_or/", "subreddit_subscribers": 79046, "created_utc": 1667711791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there opportunities for career progression?", "author_fullname": "t2_ecofamsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is de a dead end field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yneoqh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.18, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1667703052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there opportunities for career progression?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "yneoqh", "is_robot_indexable": true, "report_reasons": null, "author": "Flat_Selection1105", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yneoqh/is_de_a_dead_end_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yneoqh/is_de_a_dead_end_field/", "subreddit_subscribers": 79046, "created_utc": 1667703052.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}