{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a few things that take about 10-12 minutes to run and I often find myself distracted on social media. I'd like to be productive during those moments, what do you do?", "author_fullname": "t2_2ybwalr8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do while you wait for stuff to run?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu4j0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668352681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few things that take about 10-12 minutes to run and I often find myself distracted on social media. I&amp;#39;d like to be productive during those moments, what do you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yu4j0v", "is_robot_indexable": true, "report_reasons": null, "author": "spidertonic", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yu4j0v/what_do_you_do_while_you_wait_for_stuff_to_run/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yu4j0v/what_do_you_do_while_you_wait_for_stuff_to_run/", "subreddit_subscribers": 819242, "created_utc": 1668352681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI've been thinking a lot about my data science career and I was wondering if there's a universal opinion on becoming a generalist vs a specialist.\n\nTo give you some context, I have worked extensively on images and videos for 7+ years (a lot of deep learning) and a few months ago, I shifted to tabular data (fraud detection). Here are some of my observations.\n\n1. I enjoy solving problems in images, text, video and audio domains compared to anything else (Thanks to my background in signal and image processing). I am not very fond of other domains. \n\n2. I understand that solving a fraud problem is intellectually very challenging and the stakes are high. I also know that I'm going out of my comfort zone (which is a good thing) and exploring areas outside of computer vision.\n\n3. I'm facing the explore and exploit dilemma. I can exploit my experience in deep learning, specialize in it, and become a \"subject matter expert\" (whatever that means) in computer vision, audio data etc. This will involve going deep down the rabbit hole in these areas. \n\n4. There's the other option of becoming a jack of all trades, get good experience in other domains and work on projects outside my comfort zone. This may also involve obtaining a lot of domain and business knowledge.\n\nHowever, my career interests are within the computer vision domain. I'm ready to explore and grow within this field. I don't want to be a jack of all trades and work on every possible domain in data science.\n\nHaving said that, what are your opinions and thoughts on becoming a generalist and a specialist? What's more sustainable in the long run? Also, if I wish to grow to the level of a CTO (in a decade or so), what extra skills should I supplement myself with?", "author_fullname": "t2_7aj1qm5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specialist vs generalist in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ytr2ua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668311587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking a lot about my data science career and I was wondering if there&amp;#39;s a universal opinion on becoming a generalist vs a specialist.&lt;/p&gt;\n\n&lt;p&gt;To give you some context, I have worked extensively on images and videos for 7+ years (a lot of deep learning) and a few months ago, I shifted to tabular data (fraud detection). Here are some of my observations.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I enjoy solving problems in images, text, video and audio domains compared to anything else (Thanks to my background in signal and image processing). I am not very fond of other domains. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I understand that solving a fraud problem is intellectually very challenging and the stakes are high. I also know that I&amp;#39;m going out of my comfort zone (which is a good thing) and exploring areas outside of computer vision.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;m facing the explore and exploit dilemma. I can exploit my experience in deep learning, specialize in it, and become a &amp;quot;subject matter expert&amp;quot; (whatever that means) in computer vision, audio data etc. This will involve going deep down the rabbit hole in these areas. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;There&amp;#39;s the other option of becoming a jack of all trades, get good experience in other domains and work on projects outside my comfort zone. This may also involve obtaining a lot of domain and business knowledge.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However, my career interests are within the computer vision domain. I&amp;#39;m ready to explore and grow within this field. I don&amp;#39;t want to be a jack of all trades and work on every possible domain in data science.&lt;/p&gt;\n\n&lt;p&gt;Having said that, what are your opinions and thoughts on becoming a generalist and a specialist? What&amp;#39;s more sustainable in the long run? Also, if I wish to grow to the level of a CTO (in a decade or so), what extra skills should I supplement myself with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ytr2ua", "is_robot_indexable": true, "report_reasons": null, "author": "madhav1113", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ytr2ua/specialist_vs_generalist_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ytr2ua/specialist_vs_generalist_in_data_science/", "subreddit_subscribers": 819242, "created_utc": 1668311587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I worked in industry for 7+ years, as a software developer role. Then to enhance my career I enrolled in Computer Science post grad program in one of top universities. Transiting from SDE role to data science role was also one of my goals. I will complete my post grad soon. \n\nNow am confused whether I should target roles with title \"Data Analyst\" or \"Data Science\". My initial understanding is that data analyst deal less with actual models tweaking or machine learning algorithms / concepts than data scientist. \nI have few precise doubts:\n\n1. Will data analyst profile be substantially poor choice than data science profile? If yes why?\n\n2. I heard that a lot of non CS grads take up data analyst role. So is it something that CS post grad wont enjoy?\n\n3. How hard it is to transit to from data analyst to data scientist? \n\nPS: It may help to answer above question if you understand what I enjoyed in the past. I enjoyed developing complex applications / systems in my SDE jobs. I also enjoyed algorithms, data structures and competitive programming. Currently I have developed interest in reinforcement learning and language models.", "author_fullname": "t2_aaamk24y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What role should a Computer Science post grad look for: Data science vs data analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yu3nkg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668350724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I worked in industry for 7+ years, as a software developer role. Then to enhance my career I enrolled in Computer Science post grad program in one of top universities. Transiting from SDE role to data science role was also one of my goals. I will complete my post grad soon. &lt;/p&gt;\n\n&lt;p&gt;Now am confused whether I should target roles with title &amp;quot;Data Analyst&amp;quot; or &amp;quot;Data Science&amp;quot;. My initial understanding is that data analyst deal less with actual models tweaking or machine learning algorithms / concepts than data scientist. \nI have few precise doubts:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Will data analyst profile be substantially poor choice than data science profile? If yes why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I heard that a lot of non CS grads take up data analyst role. So is it something that CS post grad wont enjoy?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How hard it is to transit to from data analyst to data scientist? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;PS: It may help to answer above question if you understand what I enjoyed in the past. I enjoyed developing complex applications / systems in my SDE jobs. I also enjoyed algorithms, data structures and competitive programming. Currently I have developed interest in reinforcement learning and language models.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yu3nkg", "is_robot_indexable": true, "report_reasons": null, "author": "SnooHabits4550", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yu3nkg/what_role_should_a_computer_science_post_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yu3nkg/what_role_should_a_computer_science_post_grad/", "subreddit_subscribers": 819242, "created_utc": 1668350724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm embedded as a DS in a department (administrative support for manufacturing) and I see my main task as: making existing processes more efficient. I see a lot of inefficiencies with regard to data housekeeping and data integrity - people just use what works (one point is: shared MSOffice documents) but there is no established best practices of how to deal with the data / data integrity. People used to save data in a shared drive, nowadays they do the same - just in Sharepoint. There's backups, yes, but if stuff gets lost over time, then it will probably just stay lost - unless someone remembers that a specific document should exist and where it should be.\n\nI could definitely automate a lot of stuff for the admin part of processes and establish better structural practices. Plus, my fingers are actually itching to do something about it because I see a huge potential gain in efficiency. However, I'm somewhat wary that I'll be cast as the \"Excel guy\" (which did happen to my predecessor) and that I'll be inundated with these office and automatisation requests. I don't mind doing these kind of tasks as I like to help and enable people. It also makes for great self-advertising and networking. But I'd also love to work towards helping get a higher level of data maturity for the department and I see potentially turning a \"DS function\" into a \"automating office function\" as entirely counterproductive on a more strategic horizon - both for my personal career and for the department's benefit. I'm halfway sure that for my salary level it's not necessarily the optimal investment of my time for the company's benefit, either.\n\nI also actually see some responsibility of the individuals to learn these things and some the responsibility of the department to have someone who addresses these questions. I mean, if the pain isn't large enough to prompt people to look for a better solution, should I really wake sleeping dogs? I'm also worried that when the really interesting projects come that I'll have to much \"clutter\" to deal with.\n\nHave you had a similar experience and can you maybe share how you dealt with these opposing strategies of \"mere technical automatisation\" vs. \"establishing improved data standards and best practices from a more strategic viewpoint\".\n\nI'd welcome your insight.\n\n&amp;#x200B;\n\n\\[Edit: minor corrections\\]", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you see \"office data\" problems as part of your responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ytysfm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668358898.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668338276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m embedded as a DS in a department (administrative support for manufacturing) and I see my main task as: making existing processes more efficient. I see a lot of inefficiencies with regard to data housekeeping and data integrity - people just use what works (one point is: shared MSOffice documents) but there is no established best practices of how to deal with the data / data integrity. People used to save data in a shared drive, nowadays they do the same - just in Sharepoint. There&amp;#39;s backups, yes, but if stuff gets lost over time, then it will probably just stay lost - unless someone remembers that a specific document should exist and where it should be.&lt;/p&gt;\n\n&lt;p&gt;I could definitely automate a lot of stuff for the admin part of processes and establish better structural practices. Plus, my fingers are actually itching to do something about it because I see a huge potential gain in efficiency. However, I&amp;#39;m somewhat wary that I&amp;#39;ll be cast as the &amp;quot;Excel guy&amp;quot; (which did happen to my predecessor) and that I&amp;#39;ll be inundated with these office and automatisation requests. I don&amp;#39;t mind doing these kind of tasks as I like to help and enable people. It also makes for great self-advertising and networking. But I&amp;#39;d also love to work towards helping get a higher level of data maturity for the department and I see potentially turning a &amp;quot;DS function&amp;quot; into a &amp;quot;automating office function&amp;quot; as entirely counterproductive on a more strategic horizon - both for my personal career and for the department&amp;#39;s benefit. I&amp;#39;m halfway sure that for my salary level it&amp;#39;s not necessarily the optimal investment of my time for the company&amp;#39;s benefit, either.&lt;/p&gt;\n\n&lt;p&gt;I also actually see some responsibility of the individuals to learn these things and some the responsibility of the department to have someone who addresses these questions. I mean, if the pain isn&amp;#39;t large enough to prompt people to look for a better solution, should I really wake sleeping dogs? I&amp;#39;m also worried that when the really interesting projects come that I&amp;#39;ll have to much &amp;quot;clutter&amp;quot; to deal with.&lt;/p&gt;\n\n&lt;p&gt;Have you had a similar experience and can you maybe share how you dealt with these opposing strategies of &amp;quot;mere technical automatisation&amp;quot; vs. &amp;quot;establishing improved data standards and best practices from a more strategic viewpoint&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d welcome your insight.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;[Edit: minor corrections]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ytysfm", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ytysfm/do_you_see_office_data_problems_as_part_of_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ytysfm/do_you_see_office_data_problems_as_part_of_your/", "subreddit_subscribers": 819242, "created_utc": 1668338276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My career path was: Data Analyst Intern (7 months) -&gt; Software Engineer (2yrs, pretty much a data engineer) -&gt; Data Scientist (got title/role change after starting DS masters). All at an R&amp;D company. \n\nI got very little traction for any data roles up until getting the DS title. Now, I am considered for basically every data job I apply for, whether it be Data Engineer/Scientist or even Data Manager. \n\nDid anyone else experience this? I felt like I crossed some sort of invisible barrier after finally getting the full blown DS title\u2026and my previous SWE title is only helping\u2026", "author_fullname": "t2_b7eqz4bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone\u2019s Career Prospects Improve After Finally Getting the \u201cData Scientist\u201d Title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yttf4j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668319641.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668319458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My career path was: Data Analyst Intern (7 months) -&amp;gt; Software Engineer (2yrs, pretty much a data engineer) -&amp;gt; Data Scientist (got title/role change after starting DS masters). All at an R&amp;amp;D company. &lt;/p&gt;\n\n&lt;p&gt;I got very little traction for any data roles up until getting the DS title. Now, I am considered for basically every data job I apply for, whether it be Data Engineer/Scientist or even Data Manager. &lt;/p&gt;\n\n&lt;p&gt;Did anyone else experience this? I felt like I crossed some sort of invisible barrier after finally getting the full blown DS title\u2026and my previous SWE title is only helping\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yttf4j", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Box228", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yttf4j/anyones_career_prospects_improve_after_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yttf4j/anyones_career_prospects_improve_after_finally/", "subreddit_subscribers": 819242, "created_utc": 1668319458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an application where I have a dataframe of input data and a dataframe of labels.  I want to do PCA on the samples of my input df because I know I have tons of repetitive (not exactly the same but close) data.  How can I do PCA so that I know which samples I should keep?\n\nI've been looking at sklearn.decomposition.PCA, one of its attributes being explained\\_variance\\_ratio\\_ which returns the percentage of variance covered by each component: it does not say that this is sorted, but when I print it out it appears to be sorted from most to least.\n\nDoes this mean that my first samples are what I should take, am I using this correctly? While I can see why the first sample may contain most of the variance relative to each following sample, it is not intuitive to me that the explained variance ratio should be sorted on its own (e.g. it seems like 20 samples in there could be another sample that is highly informative / has very high variance).\n\nEDIT: My main goal is to determine which sensor measurements I can drop, as I have very dense arrays of many sensors and they all record almost exactly the same thing.  It seems like there should be a way to find out which of these sensors are entirely/mostly redundant", "author_fullname": "t2_31lmg3kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do PCA and now which rows to keep?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yueg3f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1668375446.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668373990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an application where I have a dataframe of input data and a dataframe of labels.  I want to do PCA on the samples of my input df because I know I have tons of repetitive (not exactly the same but close) data.  How can I do PCA so that I know which samples I should keep?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking at sklearn.decomposition.PCA, one of its attributes being explained_variance_ratio_ which returns the percentage of variance covered by each component: it does not say that this is sorted, but when I print it out it appears to be sorted from most to least.&lt;/p&gt;\n\n&lt;p&gt;Does this mean that my first samples are what I should take, am I using this correctly? While I can see why the first sample may contain most of the variance relative to each following sample, it is not intuitive to me that the explained variance ratio should be sorted on its own (e.g. it seems like 20 samples in there could be another sample that is highly informative / has very high variance).&lt;/p&gt;\n\n&lt;p&gt;EDIT: My main goal is to determine which sensor measurements I can drop, as I have very dense arrays of many sensors and they all record almost exactly the same thing.  It seems like there should be a way to find out which of these sensors are entirely/mostly redundant&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yueg3f", "is_robot_indexable": true, "report_reasons": null, "author": "Amun-Aion", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yueg3f/how_to_do_pca_and_now_which_rows_to_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yueg3f/how_to_do_pca_and_now_which_rows_to_keep/", "subreddit_subscribers": 819242, "created_utc": 1668373990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI am curious on how you document which experiments and with which features you have conducted? Lets say I have the following:\n\n1. Feature Group A:\n\n\\- Feature 1, Feature 2, Feature 3\n\n2. Feature Group B:\n\n\\- Feature 4, Feature 5, Feature 6,\n\nand I conducted 3 experiments:\n\n1. Experiment 1: All features from group A\n2. Experiment 2: All features from group B\n3. Experiment 3: All features from group A plus Feature 4\n\nWould you happen to know a graphical way of representing this?", "author_fullname": "t2_6jl0wpxq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Experiment Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ytxiqn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668334320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am curious on how you document which experiments and with which features you have conducted? Lets say I have the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Feature Group A:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- Feature 1, Feature 2, Feature 3&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Feature Group B:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- Feature 4, Feature 5, Feature 6,&lt;/p&gt;\n\n&lt;p&gt;and I conducted 3 experiments:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Experiment 1: All features from group A&lt;/li&gt;\n&lt;li&gt;Experiment 2: All features from group B&lt;/li&gt;\n&lt;li&gt;Experiment 3: All features from group A plus Feature 4&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Would you happen to know a graphical way of representing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ytxiqn", "is_robot_indexable": true, "report_reasons": null, "author": "Bulky-Author-3223", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ytxiqn/feature_experiment_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ytxiqn/feature_experiment_management/", "subreddit_subscribers": 819242, "created_utc": 1668334320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm really new into this world and I guess this popular internet test maybe uses some kind of clustering algorithms with k-values and etc. But I can't understand how they weight every answer to specify the output(in mbti, the output would be your personality for example).\nThere are also some test that told you \"you are 60% x and 40% y. Con you uses clustering to define porcentages too? Or are they super deterministic and result in just one \"group\" as output?. \n\nHopes you can understand :P I'm not english-native so it's kinda hard to explain the idea haha.", "author_fullname": "t2_15bk9ml2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what kind of algorithm uses internet test as mbti test?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ytjroa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1668290745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m really new into this world and I guess this popular internet test maybe uses some kind of clustering algorithms with k-values and etc. But I can&amp;#39;t understand how they weight every answer to specify the output(in mbti, the output would be your personality for example).\nThere are also some test that told you &amp;quot;you are 60% x and 40% y. Con you uses clustering to define porcentages too? Or are they super deterministic and result in just one &amp;quot;group&amp;quot; as output?. &lt;/p&gt;\n\n&lt;p&gt;Hopes you can understand :P I&amp;#39;m not english-native so it&amp;#39;s kinda hard to explain the idea haha.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ytjroa", "is_robot_indexable": true, "report_reasons": null, "author": "ElRockNOmurio", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ytjroa/what_kind_of_algorithm_uses_internet_test_as_mbti/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ytjroa/what_kind_of_algorithm_uses_internet_test_as_mbti/", "subreddit_subscribers": 819242, "created_utc": 1668290745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7uwwf65z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone explain to me this LSTM architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 19, "top_awarded_type": null, "hide_score": false, "name": "t3_yu4joy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/coeQLZSopOQhti2RHOMcV0YjP_aa3_Y-7h8JNQJ_P_U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1668352723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/7phpqqqljqz91.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/7phpqqqljqz91.jpg?auto=webp&amp;s=14274eef8ada49469a08794b1feb79102b7a0970", "width": 592, "height": 83}, "resolutions": [{"url": "https://preview.redd.it/7phpqqqljqz91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e78e50e9e51f51aa7b410758f4bf9e9b610ace7e", "width": 108, "height": 15}, {"url": "https://preview.redd.it/7phpqqqljqz91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=31603b9922bafc73ad72b44a37b196096696e960", "width": 216, "height": 30}, {"url": "https://preview.redd.it/7phpqqqljqz91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebce348b5bf6f36d439d2c02c14b4e523d79a975", "width": 320, "height": 44}], "variants": {}, "id": "RjMJFXi144Y9i0kWXmBru4Ay-PdwGoD094ZgsKZIr40"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "yu4joy", "is_robot_indexable": true, "report_reasons": null, "author": "Hamdi_bks", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yu4joy/can_someone_explain_to_me_this_lstm_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/7phpqqqljqz91.jpg", "subreddit_subscribers": 819242, "created_utc": 1668352723.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}