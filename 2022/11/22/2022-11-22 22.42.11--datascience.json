{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_xyd63e", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "is_gallery": true, "title": "Memory Profiling for Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "media_metadata": {"o1je1kri4h1a1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/o1je1kri4h1a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=0948bbce2cbe59ee6cbc7f80a1ca7ecd6f841c21"}, {"y": 106, "x": 216, "u": "https://preview.redd.it/o1je1kri4h1a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=3f9f14f37a0db4b90ce163f06f13bf83f9e576a9"}, {"y": 157, "x": 320, "u": "https://preview.redd.it/o1je1kri4h1a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=74813f295dda0ae55457f2f87410984b1b36b22c"}, {"y": 314, "x": 640, "u": "https://preview.redd.it/o1je1kri4h1a1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=28304c38f46d911cc3471266dafa96a74e4ecab9"}], "s": {"y": 344, "gif": "https://i.redd.it/o1je1kri4h1a1.gif", "mp4": "https://preview.redd.it/o1je1kri4h1a1.gif?format=mp4&amp;s=d6f7a8287c6e43e071a74a6251b7e43a6cfa8e0a", "x": 699}, "id": "o1je1kri4h1a1"}, "itpvolfh4h1a1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/itpvolfh4h1a1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=3db61faee529f0f1f1bcf6e398f326276b0f3c8a"}, {"y": 106, "x": 216, "u": "https://preview.redd.it/itpvolfh4h1a1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=85e8e5050131767fad2e29701c5567e8ac288388"}, {"y": 157, "x": 320, "u": "https://preview.redd.it/itpvolfh4h1a1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=9b1f0573311099be478633e4d86e6a03ccfa89a4"}, {"y": 314, "x": 640, "u": "https://preview.redd.it/itpvolfh4h1a1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=55bc804ce01f314cd5ecfbfdb281c6bc719bd055"}], "s": {"y": 344, "gif": "https://i.redd.it/itpvolfh4h1a1.gif", "mp4": "https://preview.redd.it/itpvolfh4h1a1.gif?format=mp4&amp;s=87e31dd10cd085cd2d03a06b001b10526249852e", "x": 699}, "id": "itpvolfh4h1a1"}}, "name": "t3_z1pk16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 274, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"outbound_url": "https://github.com/reloadware/reloadium", "media_id": "itpvolfh4h1a1", "id": 211618961}, {"outbound_url": "https://github.com/reloadware/reloadium", "media_id": "o1je1kri4h1a1", "id": 211618962}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 274, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/Q6KiqcD_nuyww-nrOJvyQ6x3GcIVFyPZDHGn4izAV5Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669110391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 1, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/z1pk16", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "z1pk16", "is_robot_indexable": true, "report_reasons": null, "author": "thapasaan", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1pk16/memory_profiling_for_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/reloadware/reloadium", "subreddit_subscribers": 821070, "created_utc": 1669110391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3mavxi2q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spotted in the wild! This WILL be on the test!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 49, "top_awarded_type": null, "hide_score": false, "name": "t3_z1vrtc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 101, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/glsZGD7ODCN7HVgAiienxaDFYVhk3b6mVKELG8ExvNI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669129301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gbr0prhd6k1a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gbr0prhd6k1a1.png?auto=webp&amp;s=81099bbf61581319ad6d8e0f40f7a580e510ab1a", "width": 1080, "height": 379}, "resolutions": [{"url": "https://preview.redd.it/gbr0prhd6k1a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c136faaa64c76e7abcfb6a5aa3c1df3a496f0898", "width": 108, "height": 37}, {"url": "https://preview.redd.it/gbr0prhd6k1a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2f5d21ead5b17638e1ae437e5f1190e7e68a4b4", "width": 216, "height": 75}, {"url": "https://preview.redd.it/gbr0prhd6k1a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=655c4061acb0cbfb882dd25e1398b002f9ac0d10", "width": 320, "height": 112}, {"url": "https://preview.redd.it/gbr0prhd6k1a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9327553c159972b19f393a834f850a3a07cdc795", "width": 640, "height": 224}, {"url": "https://preview.redd.it/gbr0prhd6k1a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a646d94ef1a882085c66122b29f3169f0ae49a82", "width": 960, "height": 336}, {"url": "https://preview.redd.it/gbr0prhd6k1a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29d97c9beb4ae16e7f22863a2e81f671e421d81b", "width": 1080, "height": 379}], "variants": {}, "id": "Urn8U04r48k3FWtocIO3ZbKS5Fx09xrWfjlvpRfiYKU"}], "enabled": true}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1vrtc", "is_robot_indexable": true, "report_reasons": null, "author": "RandyThompsonDC", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1vrtc/spotted_in_the_wild_this_will_be_on_the_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gbr0prhd6k1a1.png", "subreddit_subscribers": 821070, "created_utc": 1669129301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a set of distributions and I need to tell which distribution is the most consistent, meaning which one has values that are all very close.\n\nFinding the distribution with the smallest standard deviation came to mind, but there are sometimes major outliers that shouldn\u2019t be removed unless necessary.\n\nAnyone have any ideas? Thanks for your time", "author_fullname": "t2_8wi0rk4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you tell which distribution is has the most consistent values?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1gkk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669080522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a set of distributions and I need to tell which distribution is the most consistent, meaning which one has values that are all very close.&lt;/p&gt;\n\n&lt;p&gt;Finding the distribution with the smallest standard deviation came to mind, but there are sometimes major outliers that shouldn\u2019t be removed unless necessary.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any ideas? Thanks for your time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1gkk2", "is_robot_indexable": true, "report_reasons": null, "author": "pizzagarrett", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1gkk2/how_would_you_tell_which_distribution_is_has_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1gkk2/how_would_you_tell_which_distribution_is_has_the/", "subreddit_subscribers": 821070, "created_utc": 1669080522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I keep seeing posts/comments making fun of it", "author_fullname": "t2_9mpmbpc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serious: What's a harmonic mean and why does everyone joke about it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z23mvw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669147960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep seeing posts/comments making fun of it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z23mvw", "is_robot_indexable": true, "report_reasons": null, "author": "anonynimiti", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z23mvw/serious_whats_a_harmonic_mean_and_why_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z23mvw/serious_whats_a_harmonic_mean_and_why_does/", "subreddit_subscribers": 821070, "created_utc": 1669147960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently working for a large engineering company, usually based in the European HQ office (where all the Data &amp; AI/Engineering team sits), but now based out of sales office in South America on a 6 month secondment.\n\nI am essentially the link between the local sales offices (in 8 countries across the Americas) and HQ, where all the digital product development is done. I document the current data collection processes and attempt to drive traction for various digital offerings that are in development. I am in constant communication with multiple internal teams and external customers.\n\nI have a masters in Data Science &amp; Analytics, but also 3 years of sales experience - if that puts my background in perspective.\n\nAnyway, would like to tidy up my CV and am struggling what job title this would constitute. My direct report says I am an \"Evangelist\" but not a fan of that classification.\n\nAny suggestions are welcome!", "author_fullname": "t2_fmj4170y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my job title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1buws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669068437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working for a large engineering company, usually based in the European HQ office (where all the Data &amp;amp; AI/Engineering team sits), but now based out of sales office in South America on a 6 month secondment.&lt;/p&gt;\n\n&lt;p&gt;I am essentially the link between the local sales offices (in 8 countries across the Americas) and HQ, where all the digital product development is done. I document the current data collection processes and attempt to drive traction for various digital offerings that are in development. I am in constant communication with multiple internal teams and external customers.&lt;/p&gt;\n\n&lt;p&gt;I have a masters in Data Science &amp;amp; Analytics, but also 3 years of sales experience - if that puts my background in perspective.&lt;/p&gt;\n\n&lt;p&gt;Anyway, would like to tidy up my CV and am struggling what job title this would constitute. My direct report says I am an &amp;quot;Evangelist&amp;quot; but not a fan of that classification.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions are welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1buws", "is_robot_indexable": true, "report_reasons": null, "author": "shadowgroover", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1buws/what_is_my_job_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1buws/what_is_my_job_title/", "subreddit_subscribers": 821070, "created_utc": 1669068437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone\n\nI've got a question about feature importance. You can have this number fairly easily from the RandomForestClassifier method, but eventually some of those feature are 'more imoprtant' or 'more significant' for one label than the other. The 'more significant' could be in the sense of having bigger values of these feature in one label and less in the other, but I think with Random Forest is not that straightforward, as it could be for some linear model.\n\nMy question is: Is there a way to classify features in the sense of being more significant to labels?", "author_fullname": "t2_9fji0j3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature importance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1qs2k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669115005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a question about feature importance. You can have this number fairly easily from the RandomForestClassifier method, but eventually some of those feature are &amp;#39;more imoprtant&amp;#39; or &amp;#39;more significant&amp;#39; for one label than the other. The &amp;#39;more significant&amp;#39; could be in the sense of having bigger values of these feature in one label and less in the other, but I think with Random Forest is not that straightforward, as it could be for some linear model.&lt;/p&gt;\n\n&lt;p&gt;My question is: Is there a way to classify features in the sense of being more significant to labels?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1qs2k", "is_robot_indexable": true, "report_reasons": null, "author": "nico142857", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1qs2k/feature_importance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1qs2k/feature_importance/", "subreddit_subscribers": 821070, "created_utc": 1669115005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks, \n\nI'm currently Big 4 auditor with 2+ years of experience wanting to switch to data analyst/scientist role. \n\nI am studying Harvard's CS50 course (I'm on halfway), then I want to study Google's Data analyst certificate, and build up my portfolio. Question is should I continue CS50? I really enjoy it but I looking at problem sets I realized that data analysis is much more related to me due to audit work, than pure coding / software engineering.\n\nAny advice is appreciated, cheers!", "author_fullname": "t2_349zd20m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career switch from Big4 audit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1mam8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669097917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently Big 4 auditor with 2+ years of experience wanting to switch to data analyst/scientist role. &lt;/p&gt;\n\n&lt;p&gt;I am studying Harvard&amp;#39;s CS50 course (I&amp;#39;m on halfway), then I want to study Google&amp;#39;s Data analyst certificate, and build up my portfolio. Question is should I continue CS50? I really enjoy it but I looking at problem sets I realized that data analysis is much more related to me due to audit work, than pure coding / software engineering.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated, cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1mam8", "is_robot_indexable": true, "report_reasons": null, "author": "ag_9702", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1mam8/career_switch_from_big4_audit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1mam8/career_switch_from_big4_audit/", "subreddit_subscribers": 821070, "created_utc": 1669097917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In a team as described in the title, what are the type of roles this team would benefit from?\n\nI'm currently employed as a Data Analyst, but the company has decided to make the stakeholders responsible themselves of the DA tasks. Therefore I am required to take on a new role, which I can either form myself or copy other known roles, such as Data Engineer, which I'm not interested in, at all. I've been doing it (Data Engineering) for about half a year, and it simply doesn't suit me.\n\nSo, I've been instructed by my manager to come up with a list of possible responsibilities another role in our team could have. And frankly, I'm quite clueless. All I know of are Data Engineers, Data Scientists, Data Analysts, Product Owners and scrum masters. And to be honest, I'm nowhere near a Data Scientist (this is my first position as a professional in Data Science - previous experience is Electrical Engineering), and the other roles are not technical enough.\n\nDo you know of any other role that resembles Data Analysts, which could provide value to a global Data Team?", "author_fullname": "t2_6ae9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Roles in a global Data Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z241x2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669148948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a team as described in the title, what are the type of roles this team would benefit from?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently employed as a Data Analyst, but the company has decided to make the stakeholders responsible themselves of the DA tasks. Therefore I am required to take on a new role, which I can either form myself or copy other known roles, such as Data Engineer, which I&amp;#39;m not interested in, at all. I&amp;#39;ve been doing it (Data Engineering) for about half a year, and it simply doesn&amp;#39;t suit me.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;ve been instructed by my manager to come up with a list of possible responsibilities another role in our team could have. And frankly, I&amp;#39;m quite clueless. All I know of are Data Engineers, Data Scientists, Data Analysts, Product Owners and scrum masters. And to be honest, I&amp;#39;m nowhere near a Data Scientist (this is my first position as a professional in Data Science - previous experience is Electrical Engineering), and the other roles are not technical enough.&lt;/p&gt;\n\n&lt;p&gt;Do you know of any other role that resembles Data Analysts, which could provide value to a global Data Team?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z241x2", "is_robot_indexable": true, "report_reasons": null, "author": "gerdes88", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z241x2/roles_in_a_global_data_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z241x2/roles_in_a_global_data_team/", "subreddit_subscribers": 821070, "created_utc": 1669148948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHey guys,\n\nI work for an airline company, where we install kiosks at the airports to help customers check-in.\n\nThe process involves scanning your passport to find your booking, but some passengers don't place their passports correctly on the kiosk scanner, which gives an error. To reduce this, my team is thinking of installing a video message into kiosk to show how customers can scan their passports correctly.\n\nOne thing to note is that apart from this error, there can be several other errors that can occur at different stages of the process, but my team is just focusing on the mentioned error.\n\nMe, as an analyst want, to do AB testing to determine if the video messages actually help reduce the errors or not. To measure this, I have thought of 2 metrics--\n\n1. Count of main error between control and treatment kiosks\n2. Count of main error/successful transactions\n3. Count of main error/ all errors\n\nIs there anything that I should take care of before using z-test, or test of proportions when doing hypothesis testing, after considering distribution, sample size, variance, etc.\n\nAny inputs will be much appreciated.", "author_fullname": "t2_4dkekwkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AB Testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2247y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669144461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I work for an airline company, where we install kiosks at the airports to help customers check-in.&lt;/p&gt;\n\n&lt;p&gt;The process involves scanning your passport to find your booking, but some passengers don&amp;#39;t place their passports correctly on the kiosk scanner, which gives an error. To reduce this, my team is thinking of installing a video message into kiosk to show how customers can scan their passports correctly.&lt;/p&gt;\n\n&lt;p&gt;One thing to note is that apart from this error, there can be several other errors that can occur at different stages of the process, but my team is just focusing on the mentioned error.&lt;/p&gt;\n\n&lt;p&gt;Me, as an analyst want, to do AB testing to determine if the video messages actually help reduce the errors or not. To measure this, I have thought of 2 metrics--&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Count of main error between control and treatment kiosks&lt;/li&gt;\n&lt;li&gt;Count of main error/successful transactions&lt;/li&gt;\n&lt;li&gt;Count of main error/ all errors&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there anything that I should take care of before using z-test, or test of proportions when doing hypothesis testing, after considering distribution, sample size, variance, etc.&lt;/p&gt;\n\n&lt;p&gt;Any inputs will be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z2247y", "is_robot_indexable": true, "report_reasons": null, "author": "Horror-Career-335", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z2247y/ab_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z2247y/ab_testing/", "subreddit_subscribers": 821070, "created_utc": 1669144461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It\u2019s so difficult to build an unbiased model to classify a rare event since machine learning algorithms will learn to classify the majority class so much better. This [blog post](https://www.tonic.ai/blog/how-to-solve-the-problem-of-imbalanced-datasets-meet-djinn-by-tonic) shows how a new AI-powered data synthesizer tool, Djinn, can upsample synthetic data even better than SMOTE and SMOTE-NC. Using neural network generative models, it has a powerful ability to learn and mimic real data super quickly and integrates seamlessly with Jupyter Notebook.\n\nFull disclosure: I recently joined [Tonic.ai](http://tonic.ai/) as their first Data Science Evangelist, but I also can say that I genuinely think this product is amazing and a game-changer for data scientists.\n\nHappy to connect and chat all things data synthesis!", "author_fullname": "t2_uck476wk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Solve the Problem of Imbalanced Datasets: Meet Djinn by Tonic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z21d7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669142716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s so difficult to build an unbiased model to classify a rare event since machine learning algorithms will learn to classify the majority class so much better. This &lt;a href=\"https://www.tonic.ai/blog/how-to-solve-the-problem-of-imbalanced-datasets-meet-djinn-by-tonic\"&gt;blog post&lt;/a&gt; shows how a new AI-powered data synthesizer tool, Djinn, can upsample synthetic data even better than SMOTE and SMOTE-NC. Using neural network generative models, it has a powerful ability to learn and mimic real data super quickly and integrates seamlessly with Jupyter Notebook.&lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I recently joined &lt;a href=\"http://tonic.ai/\"&gt;Tonic.ai&lt;/a&gt; as their first Data Science Evangelist, but I also can say that I genuinely think this product is amazing and a game-changer for data scientists.&lt;/p&gt;\n\n&lt;p&gt;Happy to connect and chat all things data synthesis!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?auto=webp&amp;s=394e062e81933bfa54a14e82371bbf87fb0a299a", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66ce5d329b79cfdf090c9973eff93d0061c47637", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1365269c6e95b7605a29b9ced1c458ab6c4076e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a15e5c9ac714be1d7f1fa69f1467cf7d2a3b031", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=75ce4a81d67fa45c1e62e22e98a0b7800b28dc7a", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d52fbc925330f28f6eff9b99c31885591861badb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/07A7Pp3JwC0_6k0LUnSrNTL28tJiLN6qr5u_W_dsOZM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8be5f231314a736d005cacb02fd41eea0afb5f4e", "width": 1080, "height": 607}], "variants": {}, "id": "HiHWaG0eEUX4YydPwGfIlS1KsscmPnuuuqUEOMnparE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z21d7f", "is_robot_indexable": true, "report_reasons": null, "author": "Djinn_Tonic4DataSci", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z21d7f/how_to_solve_the_problem_of_imbalanced_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z21d7f/how_to_solve_the_problem_of_imbalanced_datasets/", "subreddit_subscribers": 821070, "created_utc": 1669142716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello I was trying to run my GANs model but ran into a ram limit. Are there any alternatives out there?", "author_fullname": "t2_b5gjod8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Colab running into 32 gb ram limit. Alternative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z26bj0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669154093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello I was trying to run my GANs model but ran into a ram limit. Are there any alternatives out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z26bj0", "is_robot_indexable": true, "report_reasons": null, "author": "bi11yg04t", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z26bj0/colab_running_into_32_gb_ram_limit_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z26bj0/colab_running_into_32_gb_ram_limit_alternative/", "subreddit_subscribers": 821070, "created_utc": 1669154093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, so I work for a company which generates a lot of alerts on some known time series data/metrics they monitor. The alerts come from multiple sources and are of different type.\n\nNow obviously some of that are related and I have created mechanisms (statistical ones) which can group them up based on certain logical methods. \nThis was done to reduce the manual overhead of looking at all alerts individually. We also added the feature to club some alerts into a group and give them a name based on the type of event it is manually (so that they can be used as labels if we want to automate this in the future using ML/DL)\n\nWell now I have been asked to come up with a ML methodology to do exactly that, where if we recieve a certain set of alerts which are similar in nature to some previously classified group then they be automatically grouped. I have come up with some ideas on how to approach this problem but all of them have some overhead issues. \n\nHas anyone ever worked on something similar? I see that there are products out there which kind of do this but how should one go about in approaching such a problem? Any help is appreciated.", "author_fullname": "t2_3tz33csd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Auto classify known events", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1w4lx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669130171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, so I work for a company which generates a lot of alerts on some known time series data/metrics they monitor. The alerts come from multiple sources and are of different type.&lt;/p&gt;\n\n&lt;p&gt;Now obviously some of that are related and I have created mechanisms (statistical ones) which can group them up based on certain logical methods. \nThis was done to reduce the manual overhead of looking at all alerts individually. We also added the feature to club some alerts into a group and give them a name based on the type of event it is manually (so that they can be used as labels if we want to automate this in the future using ML/DL)&lt;/p&gt;\n\n&lt;p&gt;Well now I have been asked to come up with a ML methodology to do exactly that, where if we recieve a certain set of alerts which are similar in nature to some previously classified group then they be automatically grouped. I have come up with some ideas on how to approach this problem but all of them have some overhead issues. &lt;/p&gt;\n\n&lt;p&gt;Has anyone ever worked on something similar? I see that there are products out there which kind of do this but how should one go about in approaching such a problem? Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1w4lx", "is_robot_indexable": true, "report_reasons": null, "author": "akshayb7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1w4lx/auto_classify_known_events/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1w4lx/auto_classify_known_events/", "subreddit_subscribers": 821070, "created_utc": 1669130171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a degree in applied ds (called something else at my school) and starting my masters next year but I have nothing on my GitHub to show for.\n\nI did some small projects I did for my undergrad but they are really not worthy to put on my portfolio (1 project was for a exploratory data analysis for some geographical data, we were trying to take census data and determine where to open up a cannabis dispensary which sucked, and the other project was comparing different classifiers using the CiFAR10 dataset)\n\nI do know pandas and seaborn matplotlib and some ML packages like Tensor flow and pytorch.\n\nAre there some things that are seen as necessary to have on a GitHub portfolio as a new hire trying to get into DS?", "author_fullname": "t2_6517fxym", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some GitHub portfolio essentials that employers want to see?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z265tg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669153720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a degree in applied ds (called something else at my school) and starting my masters next year but I have nothing on my GitHub to show for.&lt;/p&gt;\n\n&lt;p&gt;I did some small projects I did for my undergrad but they are really not worthy to put on my portfolio (1 project was for a exploratory data analysis for some geographical data, we were trying to take census data and determine where to open up a cannabis dispensary which sucked, and the other project was comparing different classifiers using the CiFAR10 dataset)&lt;/p&gt;\n\n&lt;p&gt;I do know pandas and seaborn matplotlib and some ML packages like Tensor flow and pytorch.&lt;/p&gt;\n\n&lt;p&gt;Are there some things that are seen as necessary to have on a GitHub portfolio as a new hire trying to get into DS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z265tg", "is_robot_indexable": true, "report_reasons": null, "author": "supfuh", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z265tg/what_are_some_github_portfolio_essentials_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z265tg/what_are_some_github_portfolio_essentials_that/", "subreddit_subscribers": 821070, "created_utc": 1669153720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Tl;Dr: How can I learn ml,dl and big data technologies like Hadoop, spark etc without following tutorials?\n\nI have basics in numpy, pandas, matplotlib, seaborne and sklearn.\n\nI have also built some basic ml models \n\nI worked on one deep learning model which is a Seq2Seq model for a chatbot. I used pytorch for this.\n\nThe thing is I feel like I don't know much and everything I did was using tutorials.\n\nHow can I learn machine learning, deep learning and the technologies used in big data on my own without much assistance from tutorials?\n\nI want to be confident with my skills and doing tutorials is easy but not giving me confidence. \n\nWhereas I am not able to pick advanced projects and do them on my own.", "author_fullname": "t2_6p5j7n43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Request] Can anyone suggest me what I should do at this point to progress?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1ypyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669136447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tl;Dr: How can I learn ml,dl and big data technologies like Hadoop, spark etc without following tutorials?&lt;/p&gt;\n\n&lt;p&gt;I have basics in numpy, pandas, matplotlib, seaborne and sklearn.&lt;/p&gt;\n\n&lt;p&gt;I have also built some basic ml models &lt;/p&gt;\n\n&lt;p&gt;I worked on one deep learning model which is a Seq2Seq model for a chatbot. I used pytorch for this.&lt;/p&gt;\n\n&lt;p&gt;The thing is I feel like I don&amp;#39;t know much and everything I did was using tutorials.&lt;/p&gt;\n\n&lt;p&gt;How can I learn machine learning, deep learning and the technologies used in big data on my own without much assistance from tutorials?&lt;/p&gt;\n\n&lt;p&gt;I want to be confident with my skills and doing tutorials is easy but not giving me confidence. &lt;/p&gt;\n\n&lt;p&gt;Whereas I am not able to pick advanced projects and do them on my own.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1ypyw", "is_robot_indexable": true, "report_reasons": null, "author": "3vikramk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1ypyw/request_can_anyone_suggest_me_what_i_should_do_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1ypyw/request_can_anyone_suggest_me_what_i_should_do_at/", "subreddit_subscribers": 821070, "created_utc": 1669136447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_30zub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building \u201cCoreTable\u201d and the OWID \u201cData Explorer\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_z1w29p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GpJ9HqYReZuv7r66UIZQfBQdSsYSS75ZztAToza5xB8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669130010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/presentation/d/1CgTbCPSYdKY2_oSvqV63GueIlUggnfdwGJhYgEvMTZI/edit?usp=sharing", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?auto=webp&amp;s=8f62e7faf0e258bbe31b04fa9bea060602fbc89a", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac67c535931e13612ba28ea14602c3ad5598b314", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f951b56aa34cdaf171bab45496dcb3c3728cc838", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4e18d490429963ed2f8633248e31b59493db926", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c3112b7093bc1670e79de5edea9bde2f641749a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8d7d706fdd6af5fafc5d398f9b76e9bbf8246571", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/7eeL-HEiEMMg3RumfQveT3PHWy3ataZceFEw5RtSTos.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb764715a5e9f3f5cc0dc0939bd1ce858b449a58", "width": 1080, "height": 567}], "variants": {}, "id": "xF8M5jQ0b7rgqKSPpo0RXae7ZEiy0Qv-3eOjo1BXauw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1w29p", "is_robot_indexable": true, "report_reasons": null, "author": "breck", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1w29p/building_coretable_and_the_owid_data_explorer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/presentation/d/1CgTbCPSYdKY2_oSvqV63GueIlUggnfdwGJhYgEvMTZI/edit?usp=sharing", "subreddit_subscribers": 821070, "created_utc": 1669130010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! It\u2019s sort of a novice question and if it\u2019s not the right place to post, please remove. \nBasically, I stay in a country with terrible pay when compared to global standards.\nAfter my master\u2019s program, myself and some colleagues started an analytics consulting business. We\u2019ve mostly focused on companies in my home country (it\u2019s been tough and not forthcoming) and we were looking at expanding the scope to other countries. Do you guys have any advice on how to go about this and what resources (websites, links etcetera) to look at? Basically, we need direction. \n\nThanks in advance.", "author_fullname": "t2_98tkj759", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using a Company to consult globally.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1oo77", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669106879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! It\u2019s sort of a novice question and if it\u2019s not the right place to post, please remove. \nBasically, I stay in a country with terrible pay when compared to global standards.\nAfter my master\u2019s program, myself and some colleagues started an analytics consulting business. We\u2019ve mostly focused on companies in my home country (it\u2019s been tough and not forthcoming) and we were looking at expanding the scope to other countries. Do you guys have any advice on how to go about this and what resources (websites, links etcetera) to look at? Basically, we need direction. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1oo77", "is_robot_indexable": true, "report_reasons": null, "author": "Loud_Ad_6272", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1oo77/using_a_company_to_consult_globally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1oo77/using_a_company_to_consult_globally/", "subreddit_subscribers": 821070, "created_utc": 1669106879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4w9ht3ao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daily Price Averages - used Fleet Car Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_z1fiv3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bPz9LUqzMEVA4RyvLSNc2O6N2SuaUpCQb-LPupN32Xg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669077624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "fleetcardeal.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.fleetcardeal.com/market-trends", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?auto=webp&amp;s=b8456d4fc558ac8de10a53f3c46c5fedb112ab29", "width": 1860, "height": 1041}, "resolutions": [{"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=637609b84a61098d603bfdc87e40f01cbe68acfa", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d54190569bda1721a4f569af4cd0aa034b73d6b", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a78305411d47d60b09288ba2dd91d7af7c68b7a", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0771b1a8ed933d594c2f4f9be69e58f36f3328de", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=20312ffbccdfbf9d4af353069b1364e21f5c6232", "width": 960, "height": 537}, {"url": "https://external-preview.redd.it/z-GZqcUNoc-t0BE1cUg03deL8YYHV1fpPr_1Z5hwEf8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3091ab81ef10d15f077d809310ff34c49d9316b2", "width": 1080, "height": 604}], "variants": {}, "id": "_VHR_lYr7xWSsOpTdzrxg0SY8maRU4vdF3RPNktl6_k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1fiv3", "is_robot_indexable": true, "report_reasons": null, "author": "andesouz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1fiv3/daily_price_averages_used_fleet_car_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.fleetcardeal.com/market-trends", "subreddit_subscribers": 821070, "created_utc": 1669077624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI am currently writing my master thesis. The topic revolves around Machine Learning models and electricity grids. I would like to include a chapter in my thesis explaining the various models I am working with. I am looking for resources to take inspiration from in explaining and also, if it includes, the many equations and images that I can use. (Of course I would cite everything).\n\nSpecifically the models I want to touch one are:\n\n1. Random Forest Regression\n2. Support Vector Regression\n3. Decision Tree Regression\n4. Gradient Bossing Regression\n5. Multi-layer Perceptron\n\nAny introductory papers, blogs or GitHub repositories would be very helpful. I tried blogs like \"Towards Data Science\" and \"Medium\" but I end up finding myself just clawing through the clutter most of the time, time I don't have (grad school. am I right?)\n\nThanks! and Cheers!", "author_fullname": "t2_jjoie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources or blogs for basic Machine Learning concepts explanation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1r6vw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669116418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I am currently writing my master thesis. The topic revolves around Machine Learning models and electricity grids. I would like to include a chapter in my thesis explaining the various models I am working with. I am looking for resources to take inspiration from in explaining and also, if it includes, the many equations and images that I can use. (Of course I would cite everything).&lt;/p&gt;\n\n&lt;p&gt;Specifically the models I want to touch one are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Random Forest Regression&lt;/li&gt;\n&lt;li&gt;Support Vector Regression&lt;/li&gt;\n&lt;li&gt;Decision Tree Regression&lt;/li&gt;\n&lt;li&gt;Gradient Bossing Regression&lt;/li&gt;\n&lt;li&gt;Multi-layer Perceptron&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any introductory papers, blogs or GitHub repositories would be very helpful. I tried blogs like &amp;quot;Towards Data Science&amp;quot; and &amp;quot;Medium&amp;quot; but I end up finding myself just clawing through the clutter most of the time, time I don&amp;#39;t have (grad school. am I right?)&lt;/p&gt;\n\n&lt;p&gt;Thanks! and Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "z1r6vw", "is_robot_indexable": true, "report_reasons": null, "author": "sloerewth", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z1r6vw/resources_or_blogs_for_basic_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z1r6vw/resources_or_blogs_for_basic_machine_learning/", "subreddit_subscribers": 821070, "created_utc": 1669116418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "From what I gather the job market in Toronto is hard to break into, especially right now. What are some jobs I could to help transition into this field? Anything where I make 20$/hr+ would be enough, I have a double major in math and physics and some co-op experience as a software developer.", "author_fullname": "t2_uhejfmve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jobs for transitioning into Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z2033d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669139704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I gather the job market in Toronto is hard to break into, especially right now. What are some jobs I could to help transition into this field? Anything where I make 20$/hr+ would be enough, I have a double major in math and physics and some co-op experience as a software developer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "z2033d", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Personality9181", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/z2033d/jobs_for_transitioning_into_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/z2033d/jobs_for_transitioning_into_data_science/", "subreddit_subscribers": 821070, "created_utc": 1669139704.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}