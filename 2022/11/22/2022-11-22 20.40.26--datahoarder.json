{"kind": "Listing", "data": {"after": "t3_z1x6fl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know what I'm asking is alot but I feel like what I'm asking should be a very common request for anyone doing basic YouTube archiving of descriptions and comments.\n\nI'm looking for something like:\n\nRoot folder having the yt-dlp exe then in same directory folders created with the YouTube channel name\n\nYouTube channel name &gt; Folder with name as the video title &gt; mp4, description as txt, comments\n\nRepeat folder generation for each video on the YouTube channel\n\nEdit: It seems this post is getting alot of attention from people wanting to do exactly this. After a couple hours I figured it out:\n\n yt-dlp --get-comments --print-to-file \"%(comments)#j\" \"%(channel)s/%(title)s/%(title)s.comments.json\" --write-description URL HERE -o %(channel)s/%(title)s/%(title)s.%(ext)s \n\nFrom my understanding this will do everything you need along with populating a json file that contains info like keywords on the video, upload date etc. You can open it in Firefox. If you only want the video, description and comments itself then you can add --no-write-info-json to the command. Thus it would be:\n\nyt-dlp --no-write-info-json --get-comments --print-to-file \"%(comments)#j\" \"%(channel)s/%(title)s/%(title)s.comments.json\" --write-description URL HERE -o %(channel)s/%(title)s/%(title)s.%(ext)s\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_93nw00ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone got a yt-dlp command for getting a channels video, description and comments into separate folders for each video downloaded?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1pewc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 159, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 159, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669149013.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669109827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know what I&amp;#39;m asking is alot but I feel like what I&amp;#39;m asking should be a very common request for anyone doing basic YouTube archiving of descriptions and comments.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for something like:&lt;/p&gt;\n\n&lt;p&gt;Root folder having the yt-dlp exe then in same directory folders created with the YouTube channel name&lt;/p&gt;\n\n&lt;p&gt;YouTube channel name &amp;gt; Folder with name as the video title &amp;gt; mp4, description as txt, comments&lt;/p&gt;\n\n&lt;p&gt;Repeat folder generation for each video on the YouTube channel&lt;/p&gt;\n\n&lt;p&gt;Edit: It seems this post is getting alot of attention from people wanting to do exactly this. After a couple hours I figured it out:&lt;/p&gt;\n\n&lt;p&gt;yt-dlp --get-comments --print-to-file &amp;quot;%(comments)#j&amp;quot; &amp;quot;%(channel)s/%(title)s/%(title)s.comments.json&amp;quot; --write-description URL HERE -o %(channel)s/%(title)s/%(title)s.%(ext)s &lt;/p&gt;\n\n&lt;p&gt;From my understanding this will do everything you need along with populating a json file that contains info like keywords on the video, upload date etc. You can open it in Firefox. If you only want the video, description and comments itself then you can add --no-write-info-json to the command. Thus it would be:&lt;/p&gt;\n\n&lt;p&gt;yt-dlp --no-write-info-json --get-comments --print-to-file &amp;quot;%(comments)#j&amp;quot; &amp;quot;%(channel)s/%(title)s/%(title)s.comments.json&amp;quot; --write-description URL HERE -o %(channel)s/%(title)s/%(title)s.%(ext)s&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1pewc", "is_robot_indexable": true, "report_reasons": null, "author": "sunshinesontv", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1pewc/anyone_got_a_ytdlp_command_for_getting_a_channels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1pewc/anyone_got_a_ytdlp_command_for_getting_a_channels/", "subreddit_subscribers": 655621, "created_utc": 1669109827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Articles like this:[https://phys.org/news/2009-09-ge-1tb-dvd-sized-disks-emerging.html](https://phys.org/news/2009-09-ge-1tb-dvd-sized-disks-emerging.html) Or this: [https://arstechnica.com/gadgets/2007/08/new-dvd-sized-disc-to-hold-terabytes-of-data/](https://arstechnica.com/gadgets/2007/08/new-dvd-sized-disc-to-hold-terabytes-of-data/)\n\nDo those even exist?", "author_fullname": "t2_50fpwuu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are 1TB DVDs for sale anywhere? I've seen multiple articles talking about them, but the articles are all from like 2009. Did anything become of these DVDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1b8uh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1669067049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Articles like this:&lt;a href=\"https://phys.org/news/2009-09-ge-1tb-dvd-sized-disks-emerging.html\"&gt;https://phys.org/news/2009-09-ge-1tb-dvd-sized-disks-emerging.html&lt;/a&gt; Or this: &lt;a href=\"https://arstechnica.com/gadgets/2007/08/new-dvd-sized-disc-to-hold-terabytes-of-data/\"&gt;https://arstechnica.com/gadgets/2007/08/new-dvd-sized-disc-to-hold-terabytes-of-data/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do those even exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8G4zLTg4xijUk8Jp_FuFXgXu4HrIX7crklv35tVnEJg.jpg?auto=webp&amp;s=e11c46a2081cc99a0df1edca777849225e0f4e31", "width": 205, "height": 203}, "resolutions": [{"url": "https://external-preview.redd.it/8G4zLTg4xijUk8Jp_FuFXgXu4HrIX7crklv35tVnEJg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b696fd0644150393bfd53c366c8da55728bd197", "width": 108, "height": 106}], "variants": {}, "id": "kv1u9pCjNvQQIqO87E_sO301aMCEHcDJK5WLvq3ZpoE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1b8uh", "is_robot_indexable": true, "report_reasons": null, "author": "Voldy256", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1b8uh/are_1tb_dvds_for_sale_anywhere_ive_seen_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1b8uh/are_1tb_dvds_for_sale_anywhere_ive_seen_multiple/", "subreddit_subscribers": 655621, "created_utc": 1669067049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m totally stumped by this one. I figure if anywhere has experience with this kind of thing, it\u2019s probably this sub. The drive is formatted as ExFAT if that helps. \n\nSo I accidentally pulled the USB connector out without properly ejecting first (this was on Mac OS X). Upon plugging it back in, it sees that there\u2019s a drive, but is unable to mount it. Disk Utility has a first aid feature that\u2019s supposed to be able to fix filesystem errors, but it doesn\u2019t even try, just immediately throws an error code (-69845). \n\nNow, this has happened before, and previously Windows was able to repair it. Not this time, though. Plugging it in on Windows I get a \u201cUSB device not recognized\u201d error. It can\u2019t even tell that it\u2019s a hard drive. It just shows up as \u201cunknown device\u201d. \n\nSo at this point I\u2019m panicking. But I have a laptop that runs Fedora Linux, so I try plugging it in\u2026 and it works! No problem whatsoever reading and writing. So that\u2019s great, but I mainly use it on Windows/OSX, so them not being able to recognize it is kind of a problem. Fedora also has a disk repair feature, but upon running it, it just says the drive is fine and there\u2019s nothing to repair. So I try again on OSX and Windows hoping it had solved itself, but again, neither can recognize it. \n\nWhat on earth is going on here? Why can only Linux read it, and is there a way of fixing this without having to backup, reformat, and reload the backup? Because currently it\u2019s my biggest hard drive, other than this I only have a few 1TB portable drives. Besides, clearly it\u2019s not *that* badly corrupted if Linux can read it, so that feels like a bit of a waste of time \n\nAny help would be appreciated.", "author_fullname": "t2_9jsyve1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4TB external hard drive corrupted, can\u2019t be read or repaired by any operating system I\u2019ve tried\u2026 except Fedora Linux, which reads it fine and sees nothing to repair", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z19gyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669064479.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669062921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m totally stumped by this one. I figure if anywhere has experience with this kind of thing, it\u2019s probably this sub. The drive is formatted as ExFAT if that helps. &lt;/p&gt;\n\n&lt;p&gt;So I accidentally pulled the USB connector out without properly ejecting first (this was on Mac OS X). Upon plugging it back in, it sees that there\u2019s a drive, but is unable to mount it. Disk Utility has a first aid feature that\u2019s supposed to be able to fix filesystem errors, but it doesn\u2019t even try, just immediately throws an error code (-69845). &lt;/p&gt;\n\n&lt;p&gt;Now, this has happened before, and previously Windows was able to repair it. Not this time, though. Plugging it in on Windows I get a \u201cUSB device not recognized\u201d error. It can\u2019t even tell that it\u2019s a hard drive. It just shows up as \u201cunknown device\u201d. &lt;/p&gt;\n\n&lt;p&gt;So at this point I\u2019m panicking. But I have a laptop that runs Fedora Linux, so I try plugging it in\u2026 and it works! No problem whatsoever reading and writing. So that\u2019s great, but I mainly use it on Windows/OSX, so them not being able to recognize it is kind of a problem. Fedora also has a disk repair feature, but upon running it, it just says the drive is fine and there\u2019s nothing to repair. So I try again on OSX and Windows hoping it had solved itself, but again, neither can recognize it. &lt;/p&gt;\n\n&lt;p&gt;What on earth is going on here? Why can only Linux read it, and is there a way of fixing this without having to backup, reformat, and reload the backup? Because currently it\u2019s my biggest hard drive, other than this I only have a few 1TB portable drives. Besides, clearly it\u2019s not &lt;em&gt;that&lt;/em&gt; badly corrupted if Linux can read it, so that feels like a bit of a waste of time &lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z19gyw", "is_robot_indexable": true, "report_reasons": null, "author": "HotEukaryoticMitosis", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z19gyw/4tb_external_hard_drive_corrupted_cant_be_read_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z19gyw/4tb_external_hard_drive_corrupted_cant_be_read_or/", "subreddit_subscribers": 655621, "created_utc": 1669062921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4h9uvu9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital Easy Store rap battle: new - is this noise normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_z1z7i1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/uc8b3ce1vk1a1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 607, "scrubber_media_url": "https://v.redd.it/uc8b3ce1vk1a1/DASH_96.mp4", "dash_url": "https://v.redd.it/uc8b3ce1vk1a1/DASHPlaylist.mpd?a=1671741625%2COTJjMDI2NTRkNDJmMjc2MWIzZTg0NzQzZWFlODdlMDliZjBiMThlZGJhMzFlNTc0Yzc4NDE5OGEyNWE1NzE1Mg%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/uc8b3ce1vk1a1/HLSPlaylist.m3u8?a=1671741625%2COWIwNjM1ZWU2NjUyZTE4NmU3NmE4YjAzMjczNTk4NWFjMGE0NjBmMDZiOTJmNzUwODBkODFjZjkzMThkYWEyZg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UJv1HTPNoZa-pfoymyuRA1vndNz4pa3CEIF9A_QET2M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1669137607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/uc8b3ce1vk1a1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?format=pjpg&amp;auto=webp&amp;s=d19e727c1256f9d0401b9a1e717d800c1b9b8623", "width": 1080, "height": 1920}, "resolutions": [{"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=781ca01674826cd0e726066b4849769a997f712d", "width": 108, "height": 192}, {"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9f29ae2870c133ef083f7435c307ec464660e074", "width": 216, "height": 384}, {"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=06a87dedfe7221dab699aace6c380c1fd17993ef", "width": 320, "height": 568}, {"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=294f62c3b5ceb3d655ef58a4d168602d7c886aa3", "width": 640, "height": 1137}, {"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=cf5f8cdc8edc2dc6e8a7728f54efd706ef88960a", "width": 960, "height": 1706}, {"url": "https://external-preview.redd.it/dGb9dpT8BhSr_CsxDjMsqVcS0DRViEkkRDqz8Slt2yo.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d17b9f0197beb3b9a4f19e2a3214b9e0c4d67b4e", "width": 1080, "height": 1920}], "variants": {}, "id": "AAQ4Ytv2loWDHtsunWm-GsTp17Jl3bqDwD972rc46H0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1z7i1", "is_robot_indexable": true, "report_reasons": null, "author": "robotinmybelly", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1z7i1/western_digital_easy_store_rap_battle_new_is_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/uc8b3ce1vk1a1", "subreddit_subscribers": 655621, "created_utc": 1669137607.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/uc8b3ce1vk1a1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 607, "scrubber_media_url": "https://v.redd.it/uc8b3ce1vk1a1/DASH_96.mp4", "dash_url": "https://v.redd.it/uc8b3ce1vk1a1/DASHPlaylist.mpd?a=1671741625%2COTJjMDI2NTRkNDJmMjc2MWIzZTg0NzQzZWFlODdlMDliZjBiMThlZGJhMzFlNTc0Yzc4NDE5OGEyNWE1NzE1Mg%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/uc8b3ce1vk1a1/HLSPlaylist.m3u8?a=1671741625%2COWIwNjM1ZWU2NjUyZTE4NmU3NmE4YjAzMjczNTk4NWFjMGE0NjBmMDZiOTJmNzUwODBkODFjZjkzMThkYWEyZg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, I was not sure if this belongs into the piracy Subreddit, sorry in advance.\n\n&amp;#x200B;\n\nI want to download all the pdfs from this website ([https://www.supersummary.com/all-study-guides/](https://www.supersummary.com/all-study-guides/)) that will be available to me as soon as I pay for my monthly subscription.\n\nEDIT: \n\n[I want to access each of those books on the following 500+ pages](https://preview.redd.it/eowcldem0j1a1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=24064b124c0cb881047762e093adc41a5cf2d406)\n\n&amp;#x200B;\n\n[After accessing the book the download pdf shall be executed and the pdf stored](https://preview.redd.it/8wy4g9wu0j1a1.png?width=1123&amp;format=png&amp;auto=webp&amp;s=c638f32ff37e5cd35b1c4939ce13bbf9037087d4)\n\nEdit over\n\nI tried HTtracker but it does not seem to work for me. Is it the right tool and I am just not using it properly? I have the feeling that it is not opening all the guides and does not try to download the pdfs but instead just downloads every link it can find without going into every link and checking again.\n\n&amp;#x200B;\n\nDo you think Wget will get the job done? If so, how would I have to use it?\n\n&amp;#x200B;\n\nThanks in advance and sorry for my english.", "author_fullname": "t2_7t54cpoe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download all downloadable pdfs from Website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eowcldem0j1a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9453f2b2f964c98c11e6c5c6f61432a189eb99e"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d236ca0681584fa29844e3c180f8fb5766863ff8"}, {"y": 195, "x": 320, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d5a19e855b941e2af206f7e61ddf731e49e6d274"}, {"y": 391, "x": 640, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2679d7a95191923c47d7eb9b87daca242163e472"}, {"y": 587, "x": 960, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=097c9c9e62c351b37a7310c37cecb448d73cf62e"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9944e5f0698aaf33ceb3d0dce605555ed21946fd"}], "s": {"y": 669, "x": 1093, "u": "https://preview.redd.it/eowcldem0j1a1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=24064b124c0cb881047762e093adc41a5cf2d406"}, "id": "eowcldem0j1a1"}, "8wy4g9wu0j1a1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7aacdc755ce663ce57e45a917d6e22c83a198949"}, {"y": 153, "x": 216, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9160e81efb87c0c04a018a8879a504b028ab418"}, {"y": 227, "x": 320, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b80ba063299cf0a838603fde996d6d6be9bf6a8c"}, {"y": 454, "x": 640, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=10aa5d1864289cbd962d94c4c519200f05c360de"}, {"y": 681, "x": 960, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0651ae9da9e4e659a7ba4c891c58dddd8cfab07e"}, {"y": 766, "x": 1080, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39888d3edaaa100237d3f8428c83a11fb92d8e64"}], "s": {"y": 797, "x": 1123, "u": "https://preview.redd.it/8wy4g9wu0j1a1.png?width=1123&amp;format=png&amp;auto=webp&amp;s=c638f32ff37e5cd35b1c4939ce13bbf9037087d4"}, "id": "8wy4g9wu0j1a1"}}, "name": "t3_z1w2m1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fg49qinMyPMnVrDe-T82vMIrXCEAxhfm6i8zyI6HELI.jpg", "edited": 1669133384.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669130036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I was not sure if this belongs into the piracy Subreddit, sorry in advance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to download all the pdfs from this website (&lt;a href=\"https://www.supersummary.com/all-study-guides/\"&gt;https://www.supersummary.com/all-study-guides/&lt;/a&gt;) that will be available to me as soon as I pay for my monthly subscription.&lt;/p&gt;\n\n&lt;p&gt;EDIT: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eowcldem0j1a1.png?width=1093&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=24064b124c0cb881047762e093adc41a5cf2d406\"&gt;I want to access each of those books on the following 500+ pages&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8wy4g9wu0j1a1.png?width=1123&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c638f32ff37e5cd35b1c4939ce13bbf9037087d4\"&gt;After accessing the book the download pdf shall be executed and the pdf stored&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit over&lt;/p&gt;\n\n&lt;p&gt;I tried HTtracker but it does not seem to work for me. Is it the right tool and I am just not using it properly? I have the feeling that it is not opening all the guides and does not try to download the pdfs but instead just downloads every link it can find without going into every link and checking again.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you think Wget will get the job done? If so, how would I have to use it?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance and sorry for my english.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1w2m1", "is_robot_indexable": true, "report_reasons": null, "author": "derinderhd", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1w2m1/download_all_downloadable_pdfs_from_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1w2m1/download_all_downloadable_pdfs_from_website/", "subreddit_subscribers": 655621, "created_utc": 1669130036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I currently have a two bay synology ds218j that isn\u2019t quite keeping pace any more with two 4tb drives. \nI was wondering if anyone in the community could let me know if the parts list below makes sense. I have the 10700k and ram on hand, and would hope to use the NAS for personal photo/video storage, document back up, and as a Plex server. \n\nhttps://pcpartpicker.com/list/xspbGL\n\nAny input is appreciated!", "author_fullname": "t2_woqnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dipping toe into DIY NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1u2a0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669124995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I currently have a two bay synology ds218j that isn\u2019t quite keeping pace any more with two 4tb drives. \nI was wondering if anyone in the community could let me know if the parts list below makes sense. I have the 10700k and ram on hand, and would hope to use the NAS for personal photo/video storage, document back up, and as a Plex server. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pcpartpicker.com/list/xspbGL\"&gt;https://pcpartpicker.com/list/xspbGL&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any input is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1u2a0", "is_robot_indexable": true, "report_reasons": null, "author": "SwedishishKSP", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1u2a0/dipping_toe_into_diy_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1u2a0/dipping_toe_into_diy_nas/", "subreddit_subscribers": 655621, "created_utc": 1669124995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nI have an Asmedia ASM1153E USB-to-SATA adapter that I need to upgrade the firmware on, but I've got a problem... I can't figure out what the versions mean.\n\nhttps://www.station-drivers.com/index.php/en/component/remository/Drivers/Asmedia/ASM-105x-115x-215x-(ASMT-xxxx)-Sata-USB-3.x-controllers/ASM2115-Sata-USB-3.0-controllers/lang,en-gb/\n\nThe versions listed here are:\n\n    140227_A1_29_01 (it's actually 140227_A1_59_01)\n    140508_21_67_01\n    140508_21_7B_01\n    140509_A1_82_00\n    140509_A1_82_80\n    140704_A1_A9_02\n    141125_21_AC_44\n    141125_21_C2_02\n    141126_A1_C4_80\n    141126_A1_EE_82\n\nMy adapter has version 140704_A1_00_00 on it.\n\nUnfortunately almost all of those firmwares were uploaded at the same time, so that's no help. The version names themselves are a little cryptic. They all start with 14xxxx, but some are duplicate. Some have _A1_ in the middle, some _21_. I just don't understand WTF is going on with these.\n\nThe archives on station-drivers comes with an application which does the flashing. I might be able to get some dates and info there, but that's going to be a lot of work to figure out.\n\nPluggable offers a hint here:  https://kb.plugable.com/data-storage/legacy-storage-products-firmware-and-downloads\n\nIt looks like the last two digits may be nothing more than a configuration code.\n\nIf anyone has a clue about this, it's going to be someone in this sub.", "author_fullname": "t2_b80f2w74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Asmedia ASM2115/ASM1153E USB-to-SATA firmware versions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1t2t2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669122215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an Asmedia ASM1153E USB-to-SATA adapter that I need to upgrade the firmware on, but I&amp;#39;ve got a problem... I can&amp;#39;t figure out what the versions mean.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.station-drivers.com/index.php/en/component/remository/Drivers/Asmedia/ASM-105x-115x-215x-(ASMT-xxxx)-Sata-USB-3.x-controllers/ASM2115-Sata-USB-3.0-controllers/lang,en-gb/\"&gt;https://www.station-drivers.com/index.php/en/component/remository/Drivers/Asmedia/ASM-105x-115x-215x-(ASMT-xxxx)-Sata-USB-3.x-controllers/ASM2115-Sata-USB-3.0-controllers/lang,en-gb/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The versions listed here are:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;140227_A1_29_01 (it&amp;#39;s actually 140227_A1_59_01)\n140508_21_67_01\n140508_21_7B_01\n140509_A1_82_00\n140509_A1_82_80\n140704_A1_A9_02\n141125_21_AC_44\n141125_21_C2_02\n141126_A1_C4_80\n141126_A1_EE_82\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My adapter has version 140704_A1_00_00 on it.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately almost all of those firmwares were uploaded at the same time, so that&amp;#39;s no help. The version names themselves are a little cryptic. They all start with 14xxxx, but some are duplicate. Some have &lt;em&gt;A1&lt;/em&gt; in the middle, some &lt;em&gt;21&lt;/em&gt;. I just don&amp;#39;t understand WTF is going on with these.&lt;/p&gt;\n\n&lt;p&gt;The archives on station-drivers comes with an application which does the flashing. I might be able to get some dates and info there, but that&amp;#39;s going to be a lot of work to figure out.&lt;/p&gt;\n\n&lt;p&gt;Pluggable offers a hint here:  &lt;a href=\"https://kb.plugable.com/data-storage/legacy-storage-products-firmware-and-downloads\"&gt;https://kb.plugable.com/data-storage/legacy-storage-products-firmware-and-downloads&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It looks like the last two digits may be nothing more than a configuration code.&lt;/p&gt;\n\n&lt;p&gt;If anyone has a clue about this, it&amp;#39;s going to be someone in this sub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1t2t2", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway9gk0k4k569", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1t2t2/understanding_asmedia_asm2115asm1153e_usbtosata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1t2t2/understanding_asmedia_asm2115asm1153e_usbtosata/", "subreddit_subscribers": 655621, "created_utc": 1669122215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there, I was wondering if it is possible (I guess yes)  to power more then 16 HDDs in one case with just one PSU?\n\nThe PSU I was looking at provides 4x 6Pin peripherals/Molex output. Once they are occupied I am limited to 16 HDDs? Can I just plug in a 6pin peripheral to sata cable into one of the empty 8pin PCI-E slots then?\n\nIf that is not the case I read about some adapters, which would that be ?\n\nHope to get some clarification.", "author_fullname": "t2_82bvqag6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to connect more then 16 HDDs?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1saon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669119980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I was wondering if it is possible (I guess yes)  to power more then 16 HDDs in one case with just one PSU?&lt;/p&gt;\n\n&lt;p&gt;The PSU I was looking at provides 4x 6Pin peripherals/Molex output. Once they are occupied I am limited to 16 HDDs? Can I just plug in a 6pin peripheral to sata cable into one of the empty 8pin PCI-E slots then?&lt;/p&gt;\n\n&lt;p&gt;If that is not the case I read about some adapters, which would that be ?&lt;/p&gt;\n\n&lt;p&gt;Hope to get some clarification.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1saon", "is_robot_indexable": true, "report_reasons": null, "author": "locopivo", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1saon/how_to_connect_more_then_16_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1saon/how_to_connect_more_then_16_hdds/", "subreddit_subscribers": 655621, "created_utc": 1669119980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Black Friday Sale got 3 WD MyBook 16TB of Amazon.\n\nSmart reports: WD160EDGZ-11B2DA0 which with some googling appear to be\n\n[Ultrastar DC HC550](https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc550-hdd#0F38461) =&gt; 7200RPM 512MB Cache 16TB SATA Datacenter Drives \n\n&amp;#x200B;\n\nSmart Reports these are new e.g. 0 hours of running\n\n \n\nTests still in USB case\n\nFIO SEQ WRITE \\[w=183MiB/s\\]\\[w=183 IOPS\\]\n\nFIO RAND READ WRITE \\[r=87.0MiB/s,w=15.0MiB/s\\]\\[r=87,w=15 IOPS\\]\n\n&amp;#x200B;\n\nSound on startup is very loud\n\nAll 3 make the same sounds.\n\nEvery 5 to 10 seconds it makes clicking, e.g. head moves.\n\n&amp;#x200B;\n\nAre these sounds normal ?\n\nhttps://reddit.com/link/z1oz7i/video/2zsmoviuwg1a1/player\n\nYou need to unmute the video player in the bottom right.\n\n&amp;#x200B;\n\nAdditional Smart Info\n\n    === START OF INFORMATION SECTION ===\n    Device Model:     WDC WD160EDGZ-11B2DA0\n    Serial Number:    XXXXXXX\n    LU WWN Device Id: 5 000cca XXXXXXXX\n    Firmware Version: 85.00A85\n    User Capacity:    16,000,900,661,248 bytes [16.0 TB]\n    Sector Sizes:     512 bytes logical, 4096 bytes physical\n    Rotation Rate:    7200 rpm\n    Form Factor:      3.5 inches\n    ATA Version is:   ACS-4 (unknown minor revision code: 0x009c)\n    SATA Version is:  SATA 3.3, 6.0 Gb/s (current: 6.0 Gb/s)\n    SMART support is: Available - device has SMART capability.\n    SMART support is: Enabled", "author_fullname": "t2_ugqmwogb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "16TB MyBook, are these dead or is the sound normal ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2zsmoviuwg1a1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/z1oz7i/asset/2zsmoviuwg1a1/DASHPlaylist.mpd?a=1671741625%2CZGRiY2ZjNmE5NWU5OWU1ZDM4NmFjMjEzMGJlMDUwZmQzODJhZjAwYzcyOTIxNzNjMTY0MjMzYWVjNmYxOTczOA%3D%3D&amp;v=1&amp;f=sd", "x": 652, "y": 480, "hlsUrl": "https://v.redd.it/link/z1oz7i/asset/2zsmoviuwg1a1/HLSPlaylist.m3u8?a=1671741625%2CMDhjM2Y1Y2RjNzM3NThkYTU0ZjJmMmQwOTg1ZGNkNGYzZWJiNzY1M2U4NDI3YzdiMWU4OTcxZGVhNjAyZjUyZA%3D%3D&amp;v=1&amp;f=sd", "id": "2zsmoviuwg1a1", "isGif": false}}, "name": "t3_z1oz7i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sV7NaZCKf-7QNFXLekm-j2z_p_5IKWVotkkap3c6lAo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1669108068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Black Friday Sale got 3 WD MyBook 16TB of Amazon.&lt;/p&gt;\n\n&lt;p&gt;Smart reports: WD160EDGZ-11B2DA0 which with some googling appear to be&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc550-hdd#0F38461\"&gt;Ultrastar DC HC550&lt;/a&gt; =&amp;gt; 7200RPM 512MB Cache 16TB SATA Datacenter Drives &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Smart Reports these are new e.g. 0 hours of running&lt;/p&gt;\n\n&lt;p&gt;Tests still in USB case&lt;/p&gt;\n\n&lt;p&gt;FIO SEQ WRITE [w=183MiB/s][w=183 IOPS]&lt;/p&gt;\n\n&lt;p&gt;FIO RAND READ WRITE [r=87.0MiB/s,w=15.0MiB/s][r=87,w=15 IOPS]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sound on startup is very loud&lt;/p&gt;\n\n&lt;p&gt;All 3 make the same sounds.&lt;/p&gt;\n\n&lt;p&gt;Every 5 to 10 seconds it makes clicking, e.g. head moves.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are these sounds normal ?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/z1oz7i/video/2zsmoviuwg1a1/player\"&gt;https://reddit.com/link/z1oz7i/video/2zsmoviuwg1a1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You need to unmute the video player in the bottom right.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additional Smart Info&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;=== START OF INFORMATION SECTION ===\nDevice Model:     WDC WD160EDGZ-11B2DA0\nSerial Number:    XXXXXXX\nLU WWN Device Id: 5 000cca XXXXXXXX\nFirmware Version: 85.00A85\nUser Capacity:    16,000,900,661,248 bytes [16.0 TB]\nSector Sizes:     512 bytes logical, 4096 bytes physical\nRotation Rate:    7200 rpm\nForm Factor:      3.5 inches\nATA Version is:   ACS-4 (unknown minor revision code: 0x009c)\nSATA Version is:  SATA 3.3, 6.0 Gb/s (current: 6.0 Gb/s)\nSMART support is: Available - device has SMART capability.\nSMART support is: Enabled\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?auto=webp&amp;s=7b5266a4b7850ca12f10f9d5c5ea8a25982f487b", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8aa1d31c8d98a27a8796a0644d44970bfaa9afdc", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=18815b6f860fa6b45b173c341e273ea1a4cc8fd7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=33ac811645ef97b5207a0ba93c4341dd4fd825a7", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fffa6cd68de2ab1bb99fd84af190353e837fea73", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2ef38853e7285770613106439118b666ec7191e", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/0j9eZPvjwYfsDvQnTwpiuWB4YJTFE5NSUeolTtnbVl4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5c572a2e47a065adaa72c1fe757b39020fe3d0", "width": 1080, "height": 1080}], "variants": {}, "id": "3QZ038wY_w9X3fckmGXL6jWuCT7uyghsRWeh5lGN0hQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1oz7i", "is_robot_indexable": true, "report_reasons": null, "author": "AcrobaticNight2855", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1oz7i/16tb_mybook_are_these_dead_or_is_the_sound_normal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1oz7i/16tb_mybook_are_these_dead_or_is_the_sound_normal/", "subreddit_subscribers": 655621, "created_utc": 1669108068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nI found myself scrolling through Github\u2019s \u201ctrending\u201d repos. Within the next hour, I stumbled across something called The Sherlock Project. Interesting, It had over 35k stars, must be pretty popular.\n\nI quickly cloned the repo and started toying around with it. It didn\u2019t take me long to realize the power of this tool. All I had to do was insert a username, and Wa Lah! I was looking at every social media website that was associated with the username. Not only that but direct links to the accounts.\n\nI started checking everyone's handles. This thing was freaky accurate. Not only that but it also spits out\u00a0NSFW\u00a0websites, which is outright hilarious. Welp, that was fun, time for bed.\n\nThe next day I open my laptop and a realization strikes me, who the hell is gonna know how to use this outside of a nerd like me? I mean, you gotta open up a terminal, clone the repo, download all the dependencies\u2026 Not very user friendly.\n\nWell, what if I made this into a web app? I was off to the races. Just a week later, I had stripped the CLI tool apart and spun up a simple little react app. It was a little buggy at first, but it worked. You could now enter a username on the web and get back all the handles and their links. Sweet!\n\nWhats next? Feel free to check it out and let me know what you think :)\n\n[www.handlefinder.com](https://www.handlefinder.com)\n\nHere is a link to the repo: [https://github.com/bnkc/handlefinder](https://github.com/bnkc/handlefinder)", "author_fullname": "t2_exxnp94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built an app that scans every social media network for your username", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z22hl1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669145332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found myself scrolling through Github\u2019s \u201ctrending\u201d repos. Within the next hour, I stumbled across something called The Sherlock Project. Interesting, It had over 35k stars, must be pretty popular.&lt;/p&gt;\n\n&lt;p&gt;I quickly cloned the repo and started toying around with it. It didn\u2019t take me long to realize the power of this tool. All I had to do was insert a username, and Wa Lah! I was looking at every social media website that was associated with the username. Not only that but direct links to the accounts.&lt;/p&gt;\n\n&lt;p&gt;I started checking everyone&amp;#39;s handles. This thing was freaky accurate. Not only that but it also spits out\u00a0NSFW\u00a0websites, which is outright hilarious. Welp, that was fun, time for bed.&lt;/p&gt;\n\n&lt;p&gt;The next day I open my laptop and a realization strikes me, who the hell is gonna know how to use this outside of a nerd like me? I mean, you gotta open up a terminal, clone the repo, download all the dependencies\u2026 Not very user friendly.&lt;/p&gt;\n\n&lt;p&gt;Well, what if I made this into a web app? I was off to the races. Just a week later, I had stripped the CLI tool apart and spun up a simple little react app. It was a little buggy at first, but it worked. You could now enter a username on the web and get back all the handles and their links. Sweet!&lt;/p&gt;\n\n&lt;p&gt;Whats next? Feel free to check it out and let me know what you think :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.handlefinder.com\"&gt;www.handlefinder.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is a link to the repo: &lt;a href=\"https://github.com/bnkc/handlefinder\"&gt;https://github.com/bnkc/handlefinder&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z22hl1", "is_robot_indexable": true, "report_reasons": null, "author": "bnkc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z22hl1/i_built_an_app_that_scans_every_social_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z22hl1/i_built_an_app_that_scans_every_social_media/", "subreddit_subscribers": 655621, "created_utc": 1669145332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for an NVMe which will have ability to say poweredon 24x7 without losing warranty!\n\nand I say that, because transcend to my surprise said that 220S (MTE220S) is losing warranty if it poweredon constantly.\n\nThe NVMes (3 of them, in 3 computers) started having issues accessing data! and lost data in all. Because they all died in 1 month of constant 24x7 power on.\n\nThe total TBW was 1TB out of 2.2PB \n\nI am surprised with all this. and I want to use 3 NVMes. I expect 200TBW in 5 years so that is not a prob.\n\nI want not to lose my warranty because they are just powered on! \n\n&amp;#x200B;\n\nThey will be installed on 3 NUCs\n\nI can give more info on Transcend's replies! never had this before in my life.", "author_fullname": "t2_4jrc56r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NVMe for 24x7 use (low TBW)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1uul9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669127018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for an NVMe which will have ability to say poweredon 24x7 without losing warranty!&lt;/p&gt;\n\n&lt;p&gt;and I say that, because transcend to my surprise said that 220S (MTE220S) is losing warranty if it poweredon constantly.&lt;/p&gt;\n\n&lt;p&gt;The NVMes (3 of them, in 3 computers) started having issues accessing data! and lost data in all. Because they all died in 1 month of constant 24x7 power on.&lt;/p&gt;\n\n&lt;p&gt;The total TBW was 1TB out of 2.2PB &lt;/p&gt;\n\n&lt;p&gt;I am surprised with all this. and I want to use 3 NVMes. I expect 200TBW in 5 years so that is not a prob.&lt;/p&gt;\n\n&lt;p&gt;I want not to lose my warranty because they are just powered on! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;They will be installed on 3 NUCs&lt;/p&gt;\n\n&lt;p&gt;I can give more info on Transcend&amp;#39;s replies! never had this before in my life.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1uul9", "is_robot_indexable": true, "report_reasons": null, "author": "Billiaz", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1uul9/nvme_for_24x7_use_low_tbw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1uul9/nvme_for_24x7_use_low_tbw/", "subreddit_subscribers": 655621, "created_utc": 1669127018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just ordered 2x 2tb 980 evos to add to my current 1tb 980 evo, and an Asus hyper m.2 x16 gen 4 pcie card to drop them into. I\u2019ve been editing weddings and they are about 2.5-3tb in size so I need to make all 3 drives into a pool, and i need it to be fast. \n\nIs storage spaces the best way to do that? \n\nI don\u2019t need any sort of backup or raid on the pool since the files are already backed up on multiple HDD\u2019s.\n\nThanks in advance!", "author_fullname": "t2_qorzx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to merge multiple M.2\u2019s into a pool and retain speed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1ksye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669092951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just ordered 2x 2tb 980 evos to add to my current 1tb 980 evo, and an Asus hyper m.2 x16 gen 4 pcie card to drop them into. I\u2019ve been editing weddings and they are about 2.5-3tb in size so I need to make all 3 drives into a pool, and i need it to be fast. &lt;/p&gt;\n\n&lt;p&gt;Is storage spaces the best way to do that? &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t need any sort of backup or raid on the pool since the files are already backed up on multiple HDD\u2019s.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1ksye", "is_robot_indexable": true, "report_reasons": null, "author": "Rdenauto", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1ksye/best_way_to_merge_multiple_m2s_into_a_pool_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1ksye/best_way_to_merge_multiple_m2s_into_a_pool_and/", "subreddit_subscribers": 655621, "created_utc": 1669092951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 8 external Seagate drives from last year, I will need to shuck 5 for my new NAS (TERRAMASTER F5-221).\n\nIs there anyway to find out the exact drives name/type inside before opening them ? Ideally using linux... Else, I can still move them to my work laptop to check...\n\nFinally, which types should I better use for my nas ?\n\n**EDIT:** I used some command and got these serials but I am not sure which model they refer to:\n```\nE: ID_SERIAL_SHORT=NAABXLMQ\nE: ID_SERIAL_SHORT=NAABXL9P\nE: ID_SERIAL_SHORT=NAABXLVM\nE: ID_SERIAL_SHORT=NAABZ8LJ\nE: ID_SERIAL_SHORT=NAABZ8K4\nE: ID_SERIAL_SHORT=NAABZ9L5\nE: ID_SERIAL_SHORT=NAABZBCS\nE: ID_SERIAL_SHORT=NAABZBE5\n```", "author_fullname": "t2_bukfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Expansion 14TB: check drives model before Shucking ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1vybq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669130305.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669129744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 8 external Seagate drives from last year, I will need to shuck 5 for my new NAS (TERRAMASTER F5-221).&lt;/p&gt;\n\n&lt;p&gt;Is there anyway to find out the exact drives name/type inside before opening them ? Ideally using linux... Else, I can still move them to my work laptop to check...&lt;/p&gt;\n\n&lt;p&gt;Finally, which types should I better use for my nas ?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; I used some command and got these serials but I am not sure which model they refer to:\n&lt;code&gt;\nE: ID_SERIAL_SHORT=NAABXLMQ\nE: ID_SERIAL_SHORT=NAABXL9P\nE: ID_SERIAL_SHORT=NAABXLVM\nE: ID_SERIAL_SHORT=NAABZ8LJ\nE: ID_SERIAL_SHORT=NAABZ8K4\nE: ID_SERIAL_SHORT=NAABZ9L5\nE: ID_SERIAL_SHORT=NAABZBCS\nE: ID_SERIAL_SHORT=NAABZBE5\n&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1vybq", "is_robot_indexable": true, "report_reasons": null, "author": "dEnissay", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1vybq/seagate_expansion_14tb_check_drives_model_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1vybq/seagate_expansion_14tb_check_drives_model_before/", "subreddit_subscribers": 655621, "created_utc": 1669129744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When I run this command (without needing to specify each path) outside of a cronjob it runs fine with both the audio and video merged in the correct format, but when I run inside a cronjob it separates the audio and video into separate formats. I'm pretty sure ffmpeg is required for the merging part so that's why I tried including that path as well. \n\n`45 14 * * * /opt/homebrew/bin/yt-dlp /opt/homebrew/bin/ffmpeg  yt-dlp --cookies /Users/admin/Movies/YoutubeCookies.txt --download-archive FILE3 -P /Users/admin/Movies/YoutubeBackup --write-auto-subs --sub-format \"srt\" -f bv+ba/b \"https://www.youtube.com/playlist?list=LL\" `", "author_fullname": "t2_93rkx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issues running command as a cronjob vs a regular terminal command", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1sw4w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669121708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I run this command (without needing to specify each path) outside of a cronjob it runs fine with both the audio and video merged in the correct format, but when I run inside a cronjob it separates the audio and video into separate formats. I&amp;#39;m pretty sure ffmpeg is required for the merging part so that&amp;#39;s why I tried including that path as well. &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;45 14 * * * /opt/homebrew/bin/yt-dlp /opt/homebrew/bin/ffmpeg  yt-dlp --cookies /Users/admin/Movies/YoutubeCookies.txt --download-archive FILE3 -P /Users/admin/Movies/YoutubeBackup --write-auto-subs --sub-format &amp;quot;srt&amp;quot; -f bv+ba/b &amp;quot;https://www.youtube.com/playlist?list=LL&amp;quot;&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1sw4w", "is_robot_indexable": true, "report_reasons": null, "author": "klnadler", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1sw4w/issues_running_command_as_a_cronjob_vs_a_regular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1sw4w/issues_running_command_as_a_cronjob_vs_a_regular/", "subreddit_subscribers": 655621, "created_utc": 1669121708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not interested in doing this for memes/content, but am curious if memes/content exist for this. There aren't any disc changers made anymore that connect directly to a PC, and the few that were made don't have blu-ray discs. Now you can certainly hack one together but I'm curious about the feasibility of connecting 100+ disc drives to one computer. \n\nSomeone got 24 drives working here: https://www.reddit.com/r/DataHoarder/comments/uqdgal/setting_up_a_dvd_duplicatorripper/\n\nBut am curious if there are any other examples.", "author_fullname": "t2_2kooznfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any projects try to maximize amount of connected disc drivers to one computer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1b8o8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669067037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not interested in doing this for memes/content, but am curious if memes/content exist for this. There aren&amp;#39;t any disc changers made anymore that connect directly to a PC, and the few that were made don&amp;#39;t have blu-ray discs. Now you can certainly hack one together but I&amp;#39;m curious about the feasibility of connecting 100+ disc drives to one computer. &lt;/p&gt;\n\n&lt;p&gt;Someone got 24 drives working here: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/uqdgal/setting_up_a_dvd_duplicatorripper/\"&gt;https://www.reddit.com/r/DataHoarder/comments/uqdgal/setting_up_a_dvd_duplicatorripper/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But am curious if there are any other examples.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1b8o8", "is_robot_indexable": true, "report_reasons": null, "author": "dstillloading", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1b8o8/any_projects_try_to_maximize_amount_of_connected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1b8o8/any_projects_try_to_maximize_amount_of_connected/", "subreddit_subscribers": 655621, "created_utc": 1669067037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Today I discovered a Netflix API for authenticated users, potentially highest quality media rips, along with a script to decrypt them.\n\n...aaand it's gone.", "author_fullname": "t2_a810j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Goodbye Shakti API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_z21muy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669143359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today I discovered a Netflix API for authenticated users, potentially highest quality media rips, along with a script to decrypt them.&lt;/p&gt;\n\n&lt;p&gt;...aaand it&amp;#39;s gone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "z21muy", "is_robot_indexable": true, "report_reasons": null, "author": "randmr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z21muy/goodbye_shakti_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z21muy/goodbye_shakti_api/", "subreddit_subscribers": 655621, "created_utc": 1669143359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a pair of CS 500s that were old hardware from work that was decommissioned and I was allowed to take home for home lab and Virtual lab work. only problem is one of them has a problem with the management GUI and Nimble support said it needs to be upgraded as its on a 3.8OS. they recommend upgrading to 5.0.10 however HPE will not give me the OS without a support contract.... and the device is past EOL so they wont let me get a support contract on it. is there anyone out there that has a 5.X version of the OS or even a 4.X as it would be an upgrade over what's on it right now.\n\nonly other option is if there is a way to pull an OS off one nimble to install on another.", "author_fullname": "t2_d2q4fw9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Legacy Storage Array OS - Nimble CS500", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1zsy3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669139018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a pair of CS 500s that were old hardware from work that was decommissioned and I was allowed to take home for home lab and Virtual lab work. only problem is one of them has a problem with the management GUI and Nimble support said it needs to be upgraded as its on a 3.8OS. they recommend upgrading to 5.0.10 however HPE will not give me the OS without a support contract.... and the device is past EOL so they wont let me get a support contract on it. is there anyone out there that has a 5.X version of the OS or even a 4.X as it would be an upgrade over what&amp;#39;s on it right now.&lt;/p&gt;\n\n&lt;p&gt;only other option is if there is a way to pull an OS off one nimble to install on another.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1zsy3", "is_robot_indexable": true, "report_reasons": null, "author": "Mimic_Woods", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1zsy3/legacy_storage_array_os_nimble_cs500/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1zsy3/legacy_storage_array_os_nimble_cs500/", "subreddit_subscribers": 655621, "created_utc": 1669139018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently move around the world living in AirBNB's and would like to move to a physical setup. Is that managable and realistic to bring around or what's a viable solution to protect my data?", "author_fullname": "t2_79i0jc78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Data Hoard as a Digital Nomad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1zc8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669137925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently move around the world living in AirBNB&amp;#39;s and would like to move to a physical setup. Is that managable and realistic to bring around or what&amp;#39;s a viable solution to protect my data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1zc8l", "is_robot_indexable": true, "report_reasons": null, "author": "septaseven", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1zc8l/how_to_data_hoard_as_a_digital_nomad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1zc8l/how_to_data_hoard_as_a_digital_nomad/", "subreddit_subscribers": 655621, "created_utc": 1669137925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Need a couple high(ish) capacity drives (14-20TB) and was wondering how serverpartdeals is. I did search on reddit and it seems people like them quite a bit. Thanks!", "author_fullname": "t2_dahbpb7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you used serverpartdeals to be refurbished drives? How was your experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1ygsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669135833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need a couple high(ish) capacity drives (14-20TB) and was wondering how serverpartdeals is. I did search on reddit and it seems people like them quite a bit. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1ygsj", "is_robot_indexable": true, "report_reasons": null, "author": "v-a-g", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1ygsj/have_you_used_serverpartdeals_to_be_refurbished/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1ygsj/have_you_used_serverpartdeals_to_be_refurbished/", "subreddit_subscribers": 655621, "created_utc": 1669135833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nBelow are my specs for my headless home server, I want to move away from my drobo 5c and was hoping for some assistance. I'm pretty comfortable with windows, and I am hoping to see if I can stick with it, but am open to other suggestions. I will hopefully buy 5 14tb WD easystore externals to shuck and put in my case. My Drobo 5c has 5 drives in it, 3 12tb drives, 2 8tb drives in it and about 27\u00a0TB of 36 TB full. I want to use stable bit to use it for the 5 14tb drives, but not sure what to do with my old drives? Sell them? Use them as a backup? Add them to the same pc as a different pool, or add to the same pool? Any way to have the drives sleep when not in use? What's the best way to transfer all the data in a quick, efficient and safe way? Open to any suggestions.\n\n\nSpecs:\n\n i5-10400\n16gb ram\n512gb nvme SSD\nDrobo 5C", "author_fullname": "t2_3hr19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading Storage on home server, few concerns/questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1wjo5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669131189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Below are my specs for my headless home server, I want to move away from my drobo 5c and was hoping for some assistance. I&amp;#39;m pretty comfortable with windows, and I am hoping to see if I can stick with it, but am open to other suggestions. I will hopefully buy 5 14tb WD easystore externals to shuck and put in my case. My Drobo 5c has 5 drives in it, 3 12tb drives, 2 8tb drives in it and about 27\u00a0TB of 36 TB full. I want to use stable bit to use it for the 5 14tb drives, but not sure what to do with my old drives? Sell them? Use them as a backup? Add them to the same pc as a different pool, or add to the same pool? Any way to have the drives sleep when not in use? What&amp;#39;s the best way to transfer all the data in a quick, efficient and safe way? Open to any suggestions.&lt;/p&gt;\n\n&lt;p&gt;Specs:&lt;/p&gt;\n\n&lt;p&gt;i5-10400\n16gb ram\n512gb nvme SSD\nDrobo 5C&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1wjo5", "is_robot_indexable": true, "report_reasons": null, "author": "xelu01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1wjo5/upgrading_storage_on_home_server_few/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1wjo5/upgrading_storage_on_home_server_few/", "subreddit_subscribers": 655621, "created_utc": 1669131189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "They seem to be the best two that do what I want/need.\n\nCurious if anyone has thoughts on either? Thoughts? Opinions? How about recovery?\n\nThings I want that they have:\n\n* LAN device syncing\n* encrypted backups to S3\n* file name encryption (Syncovery does; can't find in Syncback Pro)\n* monitoring disk for file changes\n* email notification\n\nI saw one other posts about this but it is 6 years old so I thought I would try a new one.", "author_fullname": "t2_5wpob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Syncovery and/or SyncBackPro and willing to share their thoughts -- especially about recovery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1w8zl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669130467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They seem to be the best two that do what I want/need.&lt;/p&gt;\n\n&lt;p&gt;Curious if anyone has thoughts on either? Thoughts? Opinions? How about recovery?&lt;/p&gt;\n\n&lt;p&gt;Things I want that they have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;LAN device syncing&lt;/li&gt;\n&lt;li&gt;encrypted backups to S3&lt;/li&gt;\n&lt;li&gt;file name encryption (Syncovery does; can&amp;#39;t find in Syncback Pro)&lt;/li&gt;\n&lt;li&gt;monitoring disk for file changes&lt;/li&gt;\n&lt;li&gt;email notification&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I saw one other posts about this but it is 6 years old so I thought I would try a new one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1w8zl", "is_robot_indexable": true, "report_reasons": null, "author": "imthenachoman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1w8zl/has_anyone_used_syncovery_andor_syncbackpro_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1w8zl/has_anyone_used_syncovery_andor_syncbackpro_and/", "subreddit_subscribers": 655621, "created_utc": 1669130467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How can I know if an HDD is what it really says it is on the badge? Can SMART values, model information, serial number etc. for drives be easily altered? For example can I 100% trust power-on hours SMART reporting or could it have been tampered with?\n\nAnd if it can be tampered with how common is this for HDDs? I know there are a lot of 20 bucks \"2 tb\" usb drives...", "author_fullname": "t2_r687it3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to check if a HDD is geniune?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1tbfz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669122901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I know if an HDD is what it really says it is on the badge? Can SMART values, model information, serial number etc. for drives be easily altered? For example can I 100% trust power-on hours SMART reporting or could it have been tampered with?&lt;/p&gt;\n\n&lt;p&gt;And if it can be tampered with how common is this for HDDs? I know there are a lot of 20 bucks &amp;quot;2 tb&amp;quot; usb drives...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1tbfz", "is_robot_indexable": true, "report_reasons": null, "author": "lemmeanon", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1tbfz/how_to_check_if_a_hdd_is_geniune/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1tbfz/how_to_check_if_a_hdd_is_geniune/", "subreddit_subscribers": 655621, "created_utc": 1669122901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nI have my 240 GB SSD for 3 years and according to CrystalDiskInfo out of the 150 TB of total writes it has already written 26 TB. It seems a bit big to me.\n\nI think I could do better than that or at least I have to with my next SSD.\n\nIs the a way to find out exactly what writes how much to my SSD?\n\nI guess it's not possible to find out afterwards, but is there a way to track it for a few days and see the results?\n\nThanks in advance! :)\n\n&amp;#x200B;", "author_fullname": "t2_ndvksoss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to find out the sources of most writes on my SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1nvzz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669103818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I have my 240 GB SSD for 3 years and according to CrystalDiskInfo out of the 150 TB of total writes it has already written 26 TB. It seems a bit big to me.&lt;/p&gt;\n\n&lt;p&gt;I think I could do better than that or at least I have to with my next SSD.&lt;/p&gt;\n\n&lt;p&gt;Is the a way to find out exactly what writes how much to my SSD?&lt;/p&gt;\n\n&lt;p&gt;I guess it&amp;#39;s not possible to find out afterwards, but is there a way to track it for a few days and see the results?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1nvzz", "is_robot_indexable": true, "report_reasons": null, "author": "PackedTrebuchet", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1nvzz/is_there_a_way_to_find_out_the_sources_of_most/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1nvzz/is_there_a_way_to_find_out_the_sources_of_most/", "subreddit_subscribers": 655621, "created_utc": 1669103818.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not talking about a simple bracket that mounts two 2.5 inch hard drives in the same space as a 3.5 inch drive, but one with circuitry that transparently RAIDs the two drives and presents them as one drive to the SATA port, either as a RAID 0 or RAID 1. That way I can fit two 2.5 inch drives into a normal drive bay where the bay only has one SATA port. I tried searching for it but couldn't find anything, though I didn't really know what keywords to use. Does something like this exist?\n\nMy dream device would be a SATA splitter that makes it so two drives can be attached to the same SATA port and both individually addressable by the OS, is that even possible with the protocol? I know SAS can do it but can SATA?", "author_fullname": "t2_1h1hfeve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does a 3.5 inch hard drive adapter exist that takes two 2.5 drives in RAID?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1ksgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1669093182.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669092905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not talking about a simple bracket that mounts two 2.5 inch hard drives in the same space as a 3.5 inch drive, but one with circuitry that transparently RAIDs the two drives and presents them as one drive to the SATA port, either as a RAID 0 or RAID 1. That way I can fit two 2.5 inch drives into a normal drive bay where the bay only has one SATA port. I tried searching for it but couldn&amp;#39;t find anything, though I didn&amp;#39;t really know what keywords to use. Does something like this exist?&lt;/p&gt;\n\n&lt;p&gt;My dream device would be a SATA splitter that makes it so two drives can be attached to the same SATA port and both individually addressable by the OS, is that even possible with the protocol? I know SAS can do it but can SATA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "z1ksgn", "is_robot_indexable": true, "report_reasons": null, "author": "AgreeableLandscape3", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/z1ksgn/does_a_35_inch_hard_drive_adapter_exist_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1ksgn/does_a_35_inch_hard_drive_adapter_exist_that/", "subreddit_subscribers": 655621, "created_utc": 1669092905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do you test drives?  I got a deal on some factory refurbished drives, what tools should I run on them?", "author_fullname": "t2_d1ic8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Refurbished Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_z1x6fl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1669132711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you test drives?  I got a deal on some factory refurbished drives, what tools should I run on them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "128TB UnRAID &amp; 72TB Synology", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "z1x6fl", "is_robot_indexable": true, "report_reasons": null, "author": "hacnstein", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/z1x6fl/refurbished_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/z1x6fl/refurbished_drives/", "subreddit_subscribers": 655621, "created_utc": 1669132711.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}