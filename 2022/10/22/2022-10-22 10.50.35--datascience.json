{"kind": "Listing", "data": {"after": "t3_yahrw1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Is it just me or has the job hunt gotten more competitive in the last year? I was on a temporary team last year and was hunting for DS and some DA positions throughout. I was relatively picky, but was consistently receiving offers (and able to negotiate).\n\nThe one I landed on ended up laying me off after a few months and since then the search has been a lot harder. So far out of 19 places I've screened with (or been sent an assessment from) I've had 8 ghosts and 7 rejections. The feedback has been inconsistent, but more so than last year I am hearing back that they just went with another candidate or that others were farther along in the process. This is particularly distressing for me since I am way less picky than I was and having a hard time with positions I feel I am over-qualified for.\n\nAre others experiencing the same thing? Is this just a combination of more people looking after lay-offs and fewer open positions?", "author_fullname": "t2_tjfy4w2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it just me or has the job hunt gotten more competitive in the last year?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya09sq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 193, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 193, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666375386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just me or has the job hunt gotten more competitive in the last year? I was on a temporary team last year and was hunting for DS and some DA positions throughout. I was relatively picky, but was consistently receiving offers (and able to negotiate).&lt;/p&gt;\n\n&lt;p&gt;The one I landed on ended up laying me off after a few months and since then the search has been a lot harder. So far out of 19 places I&amp;#39;ve screened with (or been sent an assessment from) I&amp;#39;ve had 8 ghosts and 7 rejections. The feedback has been inconsistent, but more so than last year I am hearing back that they just went with another candidate or that others were farther along in the process. This is particularly distressing for me since I am way less picky than I was and having a hard time with positions I feel I am over-qualified for.&lt;/p&gt;\n\n&lt;p&gt;Are others experiencing the same thing? Is this just a combination of more people looking after lay-offs and fewer open positions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "ya09sq", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Mind9435", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya09sq/is_it_just_me_or_has_the_job_hunt_gotten_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya09sq/is_it_just_me_or_has_the_job_hunt_gotten_more/", "subreddit_subscribers": 814780, "created_utc": 1666375386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for four years in a datalab in a huge financial company.\nThey recruited a hardcore mathematician and asked him to build a team of ten data scientists.\nFour years later we have around 50 models in production, with 30 deep neural networks (10 transformers) for OCR, speech to text, NLP, complex risk modeling, and so on.\nAll is monitored very, very tightly and our codebase is super clean. \nI never met an other data scientist with such KPIs.\nIs that as rare as I think?", "author_fullname": "t2_585reb98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my lab as advanced as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9zd87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666373126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for four years in a datalab in a huge financial company.\nThey recruited a hardcore mathematician and asked him to build a team of ten data scientists.\nFour years later we have around 50 models in production, with 30 deep neural networks (10 transformers) for OCR, speech to text, NLP, complex risk modeling, and so on.\nAll is monitored very, very tightly and our codebase is super clean. \nI never met an other data scientist with such KPIs.\nIs that as rare as I think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9zd87", "is_robot_indexable": true, "report_reasons": null, "author": "abstract000", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9zd87/is_my_lab_as_advanced_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9zd87/is_my_lab_as_advanced_as_i_think/", "subreddit_subscribers": 814780, "created_utc": 1666373126.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. \n\nAny suggestions appreciated!\n\nEdit: to the people saying \u2018just don\u2019t\u2019, I need to learn this for a university course I\u2019m taking so don\u2019t exactly have a choice, and also it does seem like a useful skill to have.", "author_fullname": "t2_n11qkmhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best advice for being able to code machine learning algorithms from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9uc61", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666381312.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: to the people saying \u2018just don\u2019t\u2019, I need to learn this for a university course I\u2019m taking so don\u2019t exactly have a choice, and also it does seem like a useful skill to have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9uc61", "is_robot_indexable": true, "report_reasons": null, "author": "el_el_99", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9uc61/best_advice_for_being_able_to_code_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9uc61/best_advice_for_being_able_to_code_machine/", "subreddit_subscribers": 814780, "created_utc": 1666360443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm aware that the Data Science job market is generally broken down into 3 fields related to use application of data (leaving out Data Engineer for the moment):\n\n1. Data Analyst: Primarily focused on providing analyses of end result data, often using dashboards, or perhaps some statistical analysis. Traditional primary skills: Dashboarding, data munging and data analysis.\n2. Data Scientist: Primarily focused on creating structure and meaning out of large datasets, often with a focus on using math, perhaps machine learning etc, creating novel predictive models etc. Traditional Primary Skills: Math, data munging, data analysis, machine learning.\n3. Machine Learning Engineer: Focused on understanding and implementing machine learning/statistical models into software systems. Traditional Primary Skills: Software Engineering, some math, machine learning.\n\nI went from a career of software engineering (C#, .Net, SQL web development) for 10 years,  did a huge pivot and became a medical practitioner (got a doctorate), pivoted back to data analysis, Power BI, and then into Data Science/Machine Learning exploration. Currently advanced to a relatively high level in Data Analysis/BI (head up a team of analysts, was COO as a smaller org) at a large health agency. But I've worked at a startup being the primary \"data scientist\", am familiar with machine learning algorithms from deep learning to decision trees to NLP (my current passion area), where I was integrating that stuff with their main software. Currently most of the ML stuff is do is side/passion project exploration, and while I'm far from creating ML models/frameworks on my own, I am very capable of picking one up from GitHub or existing packages and implementing it against novel often messy data in Python to pull out results and put it into practice either working into other datasets or even creating APIs etc.\n\nSo I'm this weird blend of a good amount of subject matter expertise, software development knowledge, BI/Data Analysis (though my stats/math skills I'd only classify as intermediate) and ML familiarity (mostly conceptual/application).\n\nI feel like the best application of my skills is around application, taking data with underlying meaning, applying subject matter expertise and potentially leveraging ML models (NLP in particular) and putting that all together to present novel meaning in user understandable language.\n\nBut I feel like I get rejected for Data Scientist roles out of hand for lack of math background, for ML engineer roles for not having enough recent software/ML dev experience in particular on large software projects, and even from some Data Analysis jobs for not having enough of a robust math background (I was rejected at the last round of an interview by a senior DS for not being able to sufficiently describe a \"complex analysis\" I'd done and at another one for doing a take home project where they intended for linear optimization to be used, and I build a fully functional python program using heuristics within the 3 hours timeframe, including generating sample data). But I also feel like I don't just fall into the 60-80k a year drag and drop dashboard maker category.\n\nMaybe it's just the artifact of being older (with now 20+ years work experience) but I feel like I don't fit cleanly into any of the cookie cutter data roles. Anyone have any thoughts on how to position myself and/or where I should focus? I have a hard time taking nitty gritty core math classes as I'm a very results/practical outcomes focused person so glaze over if I can't quickly see the applications (and honestly don't see many in the roles I've been in), though I've tried!\n\nAny thoughts are welcome, thanks for the help!", "author_fullname": "t2_ize99svx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What am I?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yaa6vv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666401097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m aware that the Data Science job market is generally broken down into 3 fields related to use application of data (leaving out Data Engineer for the moment):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Analyst: Primarily focused on providing analyses of end result data, often using dashboards, or perhaps some statistical analysis. Traditional primary skills: Dashboarding, data munging and data analysis.&lt;/li&gt;\n&lt;li&gt;Data Scientist: Primarily focused on creating structure and meaning out of large datasets, often with a focus on using math, perhaps machine learning etc, creating novel predictive models etc. Traditional Primary Skills: Math, data munging, data analysis, machine learning.&lt;/li&gt;\n&lt;li&gt;Machine Learning Engineer: Focused on understanding and implementing machine learning/statistical models into software systems. Traditional Primary Skills: Software Engineering, some math, machine learning.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I went from a career of software engineering (C#, .Net, SQL web development) for 10 years,  did a huge pivot and became a medical practitioner (got a doctorate), pivoted back to data analysis, Power BI, and then into Data Science/Machine Learning exploration. Currently advanced to a relatively high level in Data Analysis/BI (head up a team of analysts, was COO as a smaller org) at a large health agency. But I&amp;#39;ve worked at a startup being the primary &amp;quot;data scientist&amp;quot;, am familiar with machine learning algorithms from deep learning to decision trees to NLP (my current passion area), where I was integrating that stuff with their main software. Currently most of the ML stuff is do is side/passion project exploration, and while I&amp;#39;m far from creating ML models/frameworks on my own, I am very capable of picking one up from GitHub or existing packages and implementing it against novel often messy data in Python to pull out results and put it into practice either working into other datasets or even creating APIs etc.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m this weird blend of a good amount of subject matter expertise, software development knowledge, BI/Data Analysis (though my stats/math skills I&amp;#39;d only classify as intermediate) and ML familiarity (mostly conceptual/application).&lt;/p&gt;\n\n&lt;p&gt;I feel like the best application of my skills is around application, taking data with underlying meaning, applying subject matter expertise and potentially leveraging ML models (NLP in particular) and putting that all together to present novel meaning in user understandable language.&lt;/p&gt;\n\n&lt;p&gt;But I feel like I get rejected for Data Scientist roles out of hand for lack of math background, for ML engineer roles for not having enough recent software/ML dev experience in particular on large software projects, and even from some Data Analysis jobs for not having enough of a robust math background (I was rejected at the last round of an interview by a senior DS for not being able to sufficiently describe a &amp;quot;complex analysis&amp;quot; I&amp;#39;d done and at another one for doing a take home project where they intended for linear optimization to be used, and I build a fully functional python program using heuristics within the 3 hours timeframe, including generating sample data). But I also feel like I don&amp;#39;t just fall into the 60-80k a year drag and drop dashboard maker category.&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s just the artifact of being older (with now 20+ years work experience) but I feel like I don&amp;#39;t fit cleanly into any of the cookie cutter data roles. Anyone have any thoughts on how to position myself and/or where I should focus? I have a hard time taking nitty gritty core math classes as I&amp;#39;m a very results/practical outcomes focused person so glaze over if I can&amp;#39;t quickly see the applications (and honestly don&amp;#39;t see many in the roles I&amp;#39;ve been in), though I&amp;#39;ve tried!&lt;/p&gt;\n\n&lt;p&gt;Any thoughts are welcome, thanks for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yaa6vv", "is_robot_indexable": true, "report_reasons": null, "author": "_Darthus_", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yaa6vv/what_am_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yaa6vv/what_am_i/", "subreddit_subscribers": 814780, "created_utc": 1666401097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TL;DR**: I am looking for datasets of which the attributes can be intuitively visualized (e.g. as a matrix. an image, a diagram, etc.) and are easy to individually select (e.g. by dragging over the matrix/image). What's more, it should be a dataset with which t-SNE has some difficulty, and of which some conceptual clusters are erroneously merged or separated in the embedding.\n\nI am developing an adaptation of t-SNE \u2014 specifically [Linear complexity t-SNE](https://arxiv.org/abs/1805.10817) \u2014 that allows users to manipulate embeddings on-the-fly, which hopefully results in more intuitive embeddings. To this end, the two main tools are the dragging and fixing of datapoints, and the altering/shaping of clusters by changing the high-dimensional similarities. As an example of the latter, imagine one apparent cluster in a t-SNE embedding of which the user suspects or knows it to consist of two or more \"actual\"/conceptual clusters. t-SNE likely hasn't been able to separate them due to the discriminatory attributes (i.e. the high dimensions on which those conceptual clusters differ the most) being a minority within the dataset's high dimensions. In such a case, the user should be able to select all datapoints in this erroneously merged cluster in the embedding, select the discriminatory attributes in a visualization summarizing the selected datapoints, and let t-SNE adapt the similarities in such a way that:\n\n\\- inter-similarities (between datapoints from different conceptual clusters) are reduced by a lot\n\n\\- intra-similatities (between datapoints from the same conceptual cluster) are reduced very little\n\nNow, I am looking for datasets with which I can demonstrate this feature. Suitable datasets have attributes that can be intuitively visualized and are individually selectable. Grayscale image datasets such as MNIST are an example. [Here is a premature version of my t-SNE adaptation on the MNIST dataset.](https://imgur.com/HWX4tcA)\n\nI select datapoints belonging to digits 4 and 9 (which are always clustered together, even when reseeding), and then I select the attributes that are most discriminatory (i.e. the top portion of the 9) in the attribute visualization. After I let t-SNE adapt the similarities, those two clusters are less \"clingy\" than before. It doesn't work great yet, but it's still a work in progress.\n\nAny suggestions for datasets that exhibit this problem, or directions for where to look, or ideas to go about this, are very much appreciated! :)", "author_fullname": "t2_t9kjuxcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for datasets that demonstrate my t-SNE adaptation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9u411", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666359844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: I am looking for datasets of which the attributes can be intuitively visualized (e.g. as a matrix. an image, a diagram, etc.) and are easy to individually select (e.g. by dragging over the matrix/image). What&amp;#39;s more, it should be a dataset with which t-SNE has some difficulty, and of which some conceptual clusters are erroneously merged or separated in the embedding.&lt;/p&gt;\n\n&lt;p&gt;I am developing an adaptation of t-SNE \u2014 specifically &lt;a href=\"https://arxiv.org/abs/1805.10817\"&gt;Linear complexity t-SNE&lt;/a&gt; \u2014 that allows users to manipulate embeddings on-the-fly, which hopefully results in more intuitive embeddings. To this end, the two main tools are the dragging and fixing of datapoints, and the altering/shaping of clusters by changing the high-dimensional similarities. As an example of the latter, imagine one apparent cluster in a t-SNE embedding of which the user suspects or knows it to consist of two or more &amp;quot;actual&amp;quot;/conceptual clusters. t-SNE likely hasn&amp;#39;t been able to separate them due to the discriminatory attributes (i.e. the high dimensions on which those conceptual clusters differ the most) being a minority within the dataset&amp;#39;s high dimensions. In such a case, the user should be able to select all datapoints in this erroneously merged cluster in the embedding, select the discriminatory attributes in a visualization summarizing the selected datapoints, and let t-SNE adapt the similarities in such a way that:&lt;/p&gt;\n\n&lt;p&gt;- inter-similarities (between datapoints from different conceptual clusters) are reduced by a lot&lt;/p&gt;\n\n&lt;p&gt;- intra-similatities (between datapoints from the same conceptual cluster) are reduced very little&lt;/p&gt;\n\n&lt;p&gt;Now, I am looking for datasets with which I can demonstrate this feature. Suitable datasets have attributes that can be intuitively visualized and are individually selectable. Grayscale image datasets such as MNIST are an example. &lt;a href=\"https://imgur.com/HWX4tcA\"&gt;Here is a premature version of my t-SNE adaptation on the MNIST dataset.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I select datapoints belonging to digits 4 and 9 (which are always clustered together, even when reseeding), and then I select the attributes that are most discriminatory (i.e. the top portion of the 9) in the attribute visualization. After I let t-SNE adapt the similarities, those two clusters are less &amp;quot;clingy&amp;quot; than before. It doesn&amp;#39;t work great yet, but it&amp;#39;s still a work in progress.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for datasets that exhibit this problem, or directions for where to look, or ideas to go about this, are very much appreciated! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?auto=webp&amp;s=2fb89e309feb632f8c77e3799ffeeba2632dff91", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4487ad05943c379444fa77e699cd9ad3120def13", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=20a0986040c4f2aa358e6646a9d3b5eeee792ec7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af91664967c7413e5ab38b805d325574d72f28bb", "width": 320, "height": 168}], "variants": {}, "id": "2ks1rghdg_X7SUQoVJwcwQn5lNVuDasYXEelboAJbSs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9u411", "is_robot_indexable": true, "report_reasons": null, "author": "ZykeNaggs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9u411/suggestions_for_datasets_that_demonstrate_my_tsne/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9u411/suggestions_for_datasets_that_demonstrate_my_tsne/", "subreddit_subscribers": 814780, "created_utc": 1666359844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If so what were you doing and why did you decide to use them?", "author_fullname": "t2_oonv5wgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ever used Reinforcement Learning or Genetic Algorithms in your work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9s1dv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666354024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If so what were you doing and why did you decide to use them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9s1dv", "is_robot_indexable": true, "report_reasons": null, "author": "throwayaist", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9s1dv/ever_used_reinforcement_learning_or_genetic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9s1dv/ever_used_reinforcement_learning_or_genetic/", "subreddit_subscribers": 814780, "created_utc": 1666354024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I scanned the FAQ and saw the salary ranges.\n\nMy contract during covid was $75/hr no benefits and was short term renewed at $80.  This new position wants to offer me $60/hr no benefits and I would go onto a 1099, which would cost me an extra 8% in taxes.  I held that previous contract for two years and I felt that it established my going rate.\n\nIndustry. Not a FAANG.\n\nI'm not going to overshare, but I am in my late 30s and know all the things and have done all the things.\n\nI'm seriously considering declining the offer and continuing my search, but I wanted to see if the internet hivemind thinks I'm being ridiculous and that $120k for industry is standard.", "author_fullname": "t2_4arel3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lowball or unrealistic expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya406p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666384520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I scanned the FAQ and saw the salary ranges.&lt;/p&gt;\n\n&lt;p&gt;My contract during covid was $75/hr no benefits and was short term renewed at $80.  This new position wants to offer me $60/hr no benefits and I would go onto a 1099, which would cost me an extra 8% in taxes.  I held that previous contract for two years and I felt that it established my going rate.&lt;/p&gt;\n\n&lt;p&gt;Industry. Not a FAANG.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not going to overshare, but I am in my late 30s and know all the things and have done all the things.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seriously considering declining the offer and continuing my search, but I wanted to see if the internet hivemind thinks I&amp;#39;m being ridiculous and that $120k for industry is standard.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "ya406p", "is_robot_indexable": true, "report_reasons": null, "author": "Kegheimer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya406p/lowball_or_unrealistic_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya406p/lowball_or_unrealistic_expectations/", "subreddit_subscribers": 814780, "created_utc": 1666384520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to find a good data conference to take the DS and DE on my team to. Someone recommended DataDay in Texas, wondering if anyone here been to that. Or if there are other options worth looking into? \nI would prefer it to be in Austin, Chicago or Vegas.\n\nThanks in advanced!", "author_fullname": "t2_16kgog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data conference recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya2aro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666380342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find a good data conference to take the DS and DE on my team to. Someone recommended DataDay in Texas, wondering if anyone here been to that. Or if there are other options worth looking into? \nI would prefer it to be in Austin, Chicago or Vegas.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advanced!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya2aro", "is_robot_indexable": true, "report_reasons": null, "author": "balpby1989", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya2aro/data_conference_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya2aro/data_conference_recommendations/", "subreddit_subscribers": 814780, "created_utc": 1666380342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data scientists who have experience in the conservation field, what tools could be used to monitor and track specific individuals while working on a given terrain?\n\nWe have a large list of documented animal encounters, but we have no idea how to use that to our advantage.", "author_fullname": "t2_t7mbx7jy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science applied to species monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9wzzx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666367079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data scientists who have experience in the conservation field, what tools could be used to monitor and track specific individuals while working on a given terrain?&lt;/p&gt;\n\n&lt;p&gt;We have a large list of documented animal encounters, but we have no idea how to use that to our advantage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9wzzx", "is_robot_indexable": true, "report_reasons": null, "author": "ruelass", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9wzzx/data_science_applied_to_species_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9wzzx/data_science_applied_to_species_monitoring/", "subreddit_subscribers": 814780, "created_utc": 1666367079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. \n\nAny suggestions appreciated!", "author_fullname": "t2_n11qkmhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best advice for being able to code machine learning algorithms from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9uc02", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9uc02", "is_robot_indexable": true, "report_reasons": null, "author": "el_el_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9uc02/best_advice_for_being_able_to_code_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9uc02/best_advice_for_being_able_to_code_machine/", "subreddit_subscribers": 814780, "created_utc": 1666360431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am new to data science, and im hoping this is the right forum for this. I have a configuration of honeypots that are collecting logs of attack interactions across the world. I'm looking to see the regional differences in attacks and to carry out some other interesting analysis that may be interesting.\n\n\nHow would folks here tackle this challenge? What additional insights into the problem do you need?", "author_fullname": "t2_3p9b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing Network logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9xn8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666368710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data science, and im hoping this is the right forum for this. I have a configuration of honeypots that are collecting logs of attack interactions across the world. I&amp;#39;m looking to see the regional differences in attacks and to carry out some other interesting analysis that may be interesting.&lt;/p&gt;\n\n&lt;p&gt;How would folks here tackle this challenge? What additional insights into the problem do you need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9xn8c", "is_robot_indexable": true, "report_reasons": null, "author": "godlee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9xn8c/analyzing_network_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9xn8c/analyzing_network_logs/", "subreddit_subscribers": 814780, "created_utc": 1666368710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi,\n\nI got assessment to complete, and the question says provide rationale and evidence supporting your answer.\n\nDoes anyone know how to provide evidence from data?", "author_fullname": "t2_8u1rdy19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data rationale and evidence.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yaiei1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666428457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I got assessment to complete, and the question says provide rationale and evidence supporting your answer.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know how to provide evidence from data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yaiei1", "is_robot_indexable": true, "report_reasons": null, "author": "0n_lsd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yaiei1/data_rationale_and_evidence/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yaiei1/data_rationale_and_evidence/", "subreddit_subscribers": 814780, "created_utc": 1666428457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Update: added a demo \"Core Trading System\" to feed the main system and be able to visualize some data. The demo will be connecting to real-time data from Coinbase and Binance\n\nSo now, you can run it and test it with no issues.\n\ngithub opensource project: VisualHFT\n\n[https://github.com/silahian/VisualHFT](https://github.com/silahian/VisualHFT)", "author_fullname": "t2_401yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VisualHFT: visualizing market microstructure analytics (opensource)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya4gqw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666385663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Update: added a demo &amp;quot;Core Trading System&amp;quot; to feed the main system and be able to visualize some data. The demo will be connecting to real-time data from Coinbase and Binance&lt;/p&gt;\n\n&lt;p&gt;So now, you can run it and test it with no issues.&lt;/p&gt;\n\n&lt;p&gt;github opensource project: VisualHFT&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/silahian/VisualHFT\"&gt;https://github.com/silahian/VisualHFT&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?auto=webp&amp;s=3e04f857871da5e72c50a41f1a1029d65a111b29", "width": 1167, "height": 685}, "resolutions": [{"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3a59bee0550fe5c977df1e3e106079029c53d10", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b70e2431ec5da1aaa05bdb42dad37cc4da05713b", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=03e17f7edd67ba5e928386597bedc973f9da1c11", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db60e7c6d69d21f73767aa12e3e65fa96ff6eb24", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c0070e2f36178c893771b7e4034381c8d448f18c", "width": 960, "height": 563}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f882782124d375b783a8621bc2fd91dc92994270", "width": 1080, "height": 633}], "variants": {}, "id": "XmMPn7Cn7AgVSPrK1BHlCQptRWcI9F4-rYALOHjDTT0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya4gqw", "is_robot_indexable": true, "report_reasons": null, "author": "silahian", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya4gqw/visualhft_visualizing_market_microstructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya4gqw/visualhft_visualizing_market_microstructure/", "subreddit_subscribers": 814780, "created_utc": 1666385663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone here have any idea what type of questions can come in a 15 minute SQL SHL Test\nAny help is greatly appreciated. Thanks!\n\nPS: I have never in my life used SQL in any form.", "author_fullname": "t2_46i5sfp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL SHL Assessment Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tucd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666359139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here have any idea what type of questions can come in a 15 minute SQL SHL Test\nAny help is greatly appreciated. Thanks!&lt;/p&gt;\n\n&lt;p&gt;PS: I have never in my life used SQL in any form.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9tucd", "is_robot_indexable": true, "report_reasons": null, "author": "yashsingh0105", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9tucd/sql_shl_assessment_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9tucd/sql_shl_assessment_test/", "subreddit_subscribers": 814780, "created_utc": 1666359139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Happens to be a transformer that solves tabular problems in a second without the need to fit a model in the traditional manner. It radiccaly differs from other ML methods and supposedly outperforms gradient based trees with HPO... Seems really like a different paradigm from good old fit and predict.", "author_fullname": "t2_4tmb276q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "thoughts on TabPFN?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9safl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666354783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happens to be a transformer that solves tabular problems in a second without the need to fit a model in the traditional manner. It radiccaly differs from other ML methods and supposedly outperforms gradient based trees with HPO... Seems really like a different paradigm from good old fit and predict.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9safl", "is_robot_indexable": true, "report_reasons": null, "author": "CHADvier", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9safl/thoughts_on_tabpfn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9safl/thoughts_on_tabpfn/", "subreddit_subscribers": 814780, "created_utc": 1666354783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h7j37iyw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "career shift help I am a fresh civil engineer graduate wants to shift to programming (data analysis)should i go back to college or study on my own ?25 years old", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yafdn6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666417443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yafdn6", "is_robot_indexable": true, "report_reasons": null, "author": "AbdelrahmanSAMY98", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yafdn6/career_shift_help_i_am_a_fresh_civil_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yafdn6/career_shift_help_i_am_a_fresh_civil_engineer/", "subreddit_subscribers": 814780, "created_utc": 1666417443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working full time earning $85 per hour with all other benefits.\n\nI just want to know if it's applicable to work on a full time contract, $120 hr with health care,  at the same time?\n\nAny legal issue, time management issue?\nTwo companies are not competitive and in different industries. \n\nThanks!", "author_fullname": "t2_12x43b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "full time employee ability to work on a full time contract?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9yq4l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666381161.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666371474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working full time earning $85 per hour with all other benefits.&lt;/p&gt;\n\n&lt;p&gt;I just want to know if it&amp;#39;s applicable to work on a full time contract, $120 hr with health care,  at the same time?&lt;/p&gt;\n\n&lt;p&gt;Any legal issue, time management issue?\nTwo companies are not competitive and in different industries. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9yq4l", "is_robot_indexable": true, "report_reasons": null, "author": "janicewa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9yq4l/full_time_employee_ability_to_work_on_a_full_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9yq4l/full_time_employee_ability_to_work_on_a_full_time/", "subreddit_subscribers": 814780, "created_utc": 1666371474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for confidence.\n\n&amp;#x200B;\n\nThere's another ways to optimize this algorithm?", "author_fullname": "t2_768gsz2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FPGrowth about doubts [PySpark]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9ta6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for confidence.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s another ways to optimize this algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9ta6h", "is_robot_indexable": true, "report_reasons": null, "author": "suneirl1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9ta6h/fpgrowth_about_doubts_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9ta6h/fpgrowth_about_doubts_pyspark/", "subreddit_subscribers": 814780, "created_utc": 1666357654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are people's experiences using outsourcing platforms for data collecting and labelling like Mechanical Turk, Appen, Scale AI etc?\n\nI have long considered using them but can't vouch for the quality of the data collected so I would love to hear from other who have used them first hand. Thanks!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crowdsourcing data collection and labelling - good or bad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9t6wi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are people&amp;#39;s experiences using outsourcing platforms for data collecting and labelling like Mechanical Turk, Appen, Scale AI etc?&lt;/p&gt;\n\n&lt;p&gt;I have long considered using them but can&amp;#39;t vouch for the quality of the data collected so I would love to hear from other who have used them first hand. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9t6wi", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9t6wi/crowdsourcing_data_collection_and_labelling_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9t6wi/crowdsourcing_data_collection_and_labelling_good/", "subreddit_subscribers": 814780, "created_utc": 1666357403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Working at a startup and worried that I am not ready to get a new job if I get laid off. How do you keep yourself ready?", "author_fullname": "t2_3yclh0lo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep yourself ready in a tough job market like the current one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yajqsn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666433009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working at a startup and worried that I am not ready to get a new job if I get laid off. How do you keep yourself ready?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yajqsn", "is_robot_indexable": true, "report_reasons": null, "author": "vishalw007", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yajqsn/how_to_keep_yourself_ready_in_a_tough_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yajqsn/how_to_keep_yourself_ready_in_a_tough_job_market/", "subreddit_subscribers": 814780, "created_utc": 1666433009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6cuqwhar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc4b Hi guys, I created a job board website. You can find Data Science jobs, list jobs, subscribe to filtered jobs emails and post a job. Everything is free now!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_yaijkf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W0hdVCOSqrY0tjwlVte0oF-KAz2i8Y0fU8zVbz6xoro.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666428946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "jobalerts.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://jobalerts.me/Data-Science-Jobs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?auto=webp&amp;s=cf913c3cfae27e6703b1b57cd7c31b61e429da2a", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf930e92c2bd5179dbc6d0bb00a7161dfe8aad17", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b96a730ba86b6a7665d2b0671500e718f2c3de34", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=842d64c97f32fceb13579047f7f89a37b38e4b7f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c6b56455d7a5641cde0d924ebff77724a371ffe", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5ee8b188ba68d54bc0ff60cab5d2655fdd4205ec", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/V9WOnmnZ_1WfUa8YM8B4KNraF1g9Us3dz_oTHzXSmPs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2208a49dc3fd2e5faa4172c41a924c2408c12ea6", "width": 1080, "height": 564}], "variants": {}, "id": "nDD3faVUwmtKJ_d83_cg3UYPEXisw8Xyz8WT_ec0wJ0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "yaijkf", "is_robot_indexable": true, "report_reasons": null, "author": "zeydankapili", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yaijkf/hi_guys_i_created_a_job_board_website_you_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://jobalerts.me/Data-Science-Jobs", "subreddit_subscribers": 814780, "created_utc": 1666428946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a daily task which is sending email daily in the morning, I used to email the screenshot of my report. I planned to automate this through python. So i got my three dataframes ready. Here's how i can place it in a each dataframe in each container. Suggest me how I can do that", "author_fullname": "t2_9r5qrevk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple Pandas Dataframe into the one HTML page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya02pk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666374918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a daily task which is sending email daily in the morning, I used to email the screenshot of my report. I planned to automate this through python. So i got my three dataframes ready. Here&amp;#39;s how i can place it in a each dataframe in each container. Suggest me how I can do that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya02pk", "is_robot_indexable": true, "report_reasons": null, "author": "Fabro_vaz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya02pk/multiple_pandas_dataframe_into_the_one_html_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya02pk/multiple_pandas_dataframe_into_the_one_html_page/", "subreddit_subscribers": 814780, "created_utc": 1666374918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there\n\nWhat do you guys think about using a ML  model to find statistical differences between populations? Let me explain my particular case:\n\nI have a dataset of 56 cells (more to come) coming from 4 different patients (target variable) with different illness conditions, each cell has \\~22 numerical features and our aim is to find differences among the patients (one being the control). Since looking for correlations between features and statistical differences become too overwhelming and tedious, I thought of training a interpretable ML model and use it to discover which properties have the cell of each patient, There is no intention/value to make future predictions. The 2 best performing models were Logistic Regresion and a Random Forest with AOC &gt; 0.9 and F1-score &gt; 0.9 (trained with the whole dataset an 10-fold CV). Afterwards I use the SHAP-values and permutation feature importance to see which features and values intervals are more characteristic for each patient. Although there is a bit of discrepancy between the order of the most important features given by LogReg and RForest, there is good agreement for the most important features at each case. I found this method superior to PCA since some features add little to the global variance but are important for a particular patient.\n\nThis is exploratory research, so the main question to answer with this approach is: is the good performing model a good way of finding whether cells coming from different illnesses are different?\n\nWhat do you think about this practice? have you used it in your work?\n\nCheers\u00a1", "author_fullname": "t2_a96dnkj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using a model to find statistical differences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9yuhu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666376861.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666371777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there&lt;/p&gt;\n\n&lt;p&gt;What do you guys think about using a ML  model to find statistical differences between populations? Let me explain my particular case:&lt;/p&gt;\n\n&lt;p&gt;I have a dataset of 56 cells (more to come) coming from 4 different patients (target variable) with different illness conditions, each cell has ~22 numerical features and our aim is to find differences among the patients (one being the control). Since looking for correlations between features and statistical differences become too overwhelming and tedious, I thought of training a interpretable ML model and use it to discover which properties have the cell of each patient, There is no intention/value to make future predictions. The 2 best performing models were Logistic Regresion and a Random Forest with AOC &amp;gt; 0.9 and F1-score &amp;gt; 0.9 (trained with the whole dataset an 10-fold CV). Afterwards I use the SHAP-values and permutation feature importance to see which features and values intervals are more characteristic for each patient. Although there is a bit of discrepancy between the order of the most important features given by LogReg and RForest, there is good agreement for the most important features at each case. I found this method superior to PCA since some features add little to the global variance but are important for a particular patient.&lt;/p&gt;\n\n&lt;p&gt;This is exploratory research, so the main question to answer with this approach is: is the good performing model a good way of finding whether cells coming from different illnesses are different?&lt;/p&gt;\n\n&lt;p&gt;What do you think about this practice? have you used it in your work?&lt;/p&gt;\n\n&lt;p&gt;Cheers\u00a1&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9yuhu", "is_robot_indexable": true, "report_reasons": null, "author": "Ale_Campoy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9yuhu/using_a_model_to_find_statistical_differences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9yuhu/using_a_model_to_find_statistical_differences/", "subreddit_subscribers": 814780, "created_utc": 1666371777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am new in this sub, and I am not sure if it is self-promotion, but I just wanted to learn if my model could be a new product or not. \n\nI spent a lot of time finding near-duplicates on multiple data records. That s why I build a model which finds near duplicate records from various tables/CSV and flags them according to the difference score. So I can filter these records and handle them. For example, one branch puts a user ID like \u201c0001763,\u201d and the other one uses \u201cxxx1763, 01763, (branchid)1763\u201d. \n\nSo, do you think that kind of model could be helpful for other companies? \n\nNote: let me know if it a self promotion, I will not do that again.", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model detects duplicate records", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tqsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666358896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new in this sub, and I am not sure if it is self-promotion, but I just wanted to learn if my model could be a new product or not. &lt;/p&gt;\n\n&lt;p&gt;I spent a lot of time finding near-duplicates on multiple data records. That s why I build a model which finds near duplicate records from various tables/CSV and flags them according to the difference score. So I can filter these records and handle them. For example, one branch puts a user ID like \u201c0001763,\u201d and the other one uses \u201cxxx1763, 01763, (branchid)1763\u201d. &lt;/p&gt;\n\n&lt;p&gt;So, do you think that kind of model could be helpful for other companies? &lt;/p&gt;\n\n&lt;p&gt;Note: let me know if it a self promotion, I will not do that again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9tqsq", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9tqsq/model_detects_duplicate_records/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9tqsq/model_detects_duplicate_records/", "subreddit_subscribers": 814780, "created_utc": 1666358896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Need to learn pytorch for my thesis (have some experience with keras &amp; tf). What sources do you recommend to learn pytorch / how have you learned it? Any recommendations are very appreciated! :) \n\nI'm also very fine to block the whole weekend (and possibly longer) to learn the basics, if that is necessary.", "author_fullname": "t2_4d143ffg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any source recommendation to learn PyTorch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yahrw1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666426119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to learn pytorch for my thesis (have some experience with keras &amp;amp; tf). What sources do you recommend to learn pytorch / how have you learned it? Any recommendations are very appreciated! :) &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also very fine to block the whole weekend (and possibly longer) to learn the basics, if that is necessary.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yahrw1", "is_robot_indexable": true, "report_reasons": null, "author": "hardwareDE", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yahrw1/any_source_recommendation_to_learn_pytorch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yahrw1/any_source_recommendation_to_learn_pytorch/", "subreddit_subscribers": 814780, "created_utc": 1666426119.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}