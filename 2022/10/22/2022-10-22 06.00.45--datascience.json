{"kind": "Listing", "data": {"after": "t3_y9n94g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been quite demotivated in my job for a couple of months now and I feel like I need a place to vent.  I started a data science career 4 years ago transitioning from an engineering (not software) background. My first job was at a rather large company (2000+ fte) but it is mostly tech company so it was quite a good experience. I grew my knowledge quite fast and was loving it but after 18 months or so I feel like we had reached the ceiling of our impact as a team and we were just kind of doing marginal improvements and trying to find other projects to work on without success. \n\nI left the job after 2 years and started at a small company (30 fte) as the only and first data scientist with complete greenfield. Although the company is small, it has many users and a lot of data and I saw an opportunity to make large impact quickly. Now a year later, I have build and experimented with just about everything I could think of but the impact has only been marginal. If I was the owner of this company I would say data science is not worth the cost. I'm now at a point where I think companies are very eager to hire people to do ML / Data science without understanding that it's not always generating value for the business.\n\nAt the same time, I'm realising I enjoy more all the engineering type tasks that I do over modelling or analysis to a point that I'm considering applying for SE type jobs rather than continuing in DS. \n\nHas anyone here been through the same or similar thought process?", "author_fullname": "t2_5bqdqy1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demotivated in my career - thinking of leaving data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9pohn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 177, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 177, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666346622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been quite demotivated in my job for a couple of months now and I feel like I need a place to vent.  I started a data science career 4 years ago transitioning from an engineering (not software) background. My first job was at a rather large company (2000+ fte) but it is mostly tech company so it was quite a good experience. I grew my knowledge quite fast and was loving it but after 18 months or so I feel like we had reached the ceiling of our impact as a team and we were just kind of doing marginal improvements and trying to find other projects to work on without success. &lt;/p&gt;\n\n&lt;p&gt;I left the job after 2 years and started at a small company (30 fte) as the only and first data scientist with complete greenfield. Although the company is small, it has many users and a lot of data and I saw an opportunity to make large impact quickly. Now a year later, I have build and experimented with just about everything I could think of but the impact has only been marginal. If I was the owner of this company I would say data science is not worth the cost. I&amp;#39;m now at a point where I think companies are very eager to hire people to do ML / Data science without understanding that it&amp;#39;s not always generating value for the business.&lt;/p&gt;\n\n&lt;p&gt;At the same time, I&amp;#39;m realising I enjoy more all the engineering type tasks that I do over modelling or analysis to a point that I&amp;#39;m considering applying for SE type jobs rather than continuing in DS. &lt;/p&gt;\n\n&lt;p&gt;Has anyone here been through the same or similar thought process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9pohn", "is_robot_indexable": true, "report_reasons": null, "author": "FewBoss5", "discussion_type": null, "num_comments": 96, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9pohn/demotivated_in_my_career_thinking_of_leaving_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9pohn/demotivated_in_my_career_thinking_of_leaving_data/", "subreddit_subscribers": 814745, "created_utc": 1666346622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Is it just me or has the job hunt gotten more competitive in the last year? I was on a temporary team last year and was hunting for DS and some DA positions throughout. I was relatively picky, but was consistently receiving offers (and able to negotiate).\n\nThe one I landed on ended up laying me off after a few months and since then the search has been a lot harder. So far out of 19 places I've screened with (or been sent an assessment from) I've had 8 ghosts and 7 rejections. The feedback has been inconsistent, but more so than last year I am hearing back that they just went with another candidate or that others were farther along in the process. This is particularly distressing for me since I am way less picky than I was and having a hard time with positions I feel I am over-qualified for.\n\nAre others experiencing the same thing? Is this just a combination of more people looking after lay-offs and fewer open positions?", "author_fullname": "t2_tjfy4w2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it just me or has the job hunt gotten more competitive in the last year?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya09sq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 159, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 159, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666375386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just me or has the job hunt gotten more competitive in the last year? I was on a temporary team last year and was hunting for DS and some DA positions throughout. I was relatively picky, but was consistently receiving offers (and able to negotiate).&lt;/p&gt;\n\n&lt;p&gt;The one I landed on ended up laying me off after a few months and since then the search has been a lot harder. So far out of 19 places I&amp;#39;ve screened with (or been sent an assessment from) I&amp;#39;ve had 8 ghosts and 7 rejections. The feedback has been inconsistent, but more so than last year I am hearing back that they just went with another candidate or that others were farther along in the process. This is particularly distressing for me since I am way less picky than I was and having a hard time with positions I feel I am over-qualified for.&lt;/p&gt;\n\n&lt;p&gt;Are others experiencing the same thing? Is this just a combination of more people looking after lay-offs and fewer open positions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "ya09sq", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Mind9435", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya09sq/is_it_just_me_or_has_the_job_hunt_gotten_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya09sq/is_it_just_me_or_has_the_job_hunt_gotten_more/", "subreddit_subscribers": 814745, "created_utc": 1666375386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for four years in a datalab in a huge financial company.\nThey recruited a hardcore mathematician and asked him to build a team of ten data scientists.\nFour years later we have around 50 models in production, with 30 deep neural networks (10 transformers) for OCR, speech to text, NLP, complex risk modeling, and so on.\nAll is monitored very, very tightly and our codebase is super clean. \nI never met an other data scientist with such KPIs.\nIs that as rare as I think?", "author_fullname": "t2_585reb98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my lab as advanced as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9zd87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666373126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for four years in a datalab in a huge financial company.\nThey recruited a hardcore mathematician and asked him to build a team of ten data scientists.\nFour years later we have around 50 models in production, with 30 deep neural networks (10 transformers) for OCR, speech to text, NLP, complex risk modeling, and so on.\nAll is monitored very, very tightly and our codebase is super clean. \nI never met an other data scientist with such KPIs.\nIs that as rare as I think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9zd87", "is_robot_indexable": true, "report_reasons": null, "author": "abstract000", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9zd87/is_my_lab_as_advanced_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9zd87/is_my_lab_as_advanced_as_i_think/", "subreddit_subscribers": 814745, "created_utc": 1666373126.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. \n\nAny suggestions appreciated!\n\nEdit: to the people saying \u2018just don\u2019t\u2019, I need to learn this for a university course I\u2019m taking so don\u2019t exactly have a choice, and also it does seem like a useful skill to have.", "author_fullname": "t2_n11qkmhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best advice for being able to code machine learning algorithms from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9uc61", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666381312.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: to the people saying \u2018just don\u2019t\u2019, I need to learn this for a university course I\u2019m taking so don\u2019t exactly have a choice, and also it does seem like a useful skill to have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9uc61", "is_robot_indexable": true, "report_reasons": null, "author": "el_el_99", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9uc61/best_advice_for_being_able_to_code_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9uc61/best_advice_for_being_able_to_code_machine/", "subreddit_subscribers": 814745, "created_utc": 1666360443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TL;DR**: I am looking for datasets of which the attributes can be intuitively visualized (e.g. as a matrix. an image, a diagram, etc.) and are easy to individually select (e.g. by dragging over the matrix/image). What's more, it should be a dataset with which t-SNE has some difficulty, and of which some conceptual clusters are erroneously merged or separated in the embedding.\n\nI am developing an adaptation of t-SNE \u2014 specifically [Linear complexity t-SNE](https://arxiv.org/abs/1805.10817) \u2014 that allows users to manipulate embeddings on-the-fly, which hopefully results in more intuitive embeddings. To this end, the two main tools are the dragging and fixing of datapoints, and the altering/shaping of clusters by changing the high-dimensional similarities. As an example of the latter, imagine one apparent cluster in a t-SNE embedding of which the user suspects or knows it to consist of two or more \"actual\"/conceptual clusters. t-SNE likely hasn't been able to separate them due to the discriminatory attributes (i.e. the high dimensions on which those conceptual clusters differ the most) being a minority within the dataset's high dimensions. In such a case, the user should be able to select all datapoints in this erroneously merged cluster in the embedding, select the discriminatory attributes in a visualization summarizing the selected datapoints, and let t-SNE adapt the similarities in such a way that:\n\n\\- inter-similarities (between datapoints from different conceptual clusters) are reduced by a lot\n\n\\- intra-similatities (between datapoints from the same conceptual cluster) are reduced very little\n\nNow, I am looking for datasets with which I can demonstrate this feature. Suitable datasets have attributes that can be intuitively visualized and are individually selectable. Grayscale image datasets such as MNIST are an example. [Here is a premature version of my t-SNE adaptation on the MNIST dataset.](https://imgur.com/HWX4tcA)\n\nI select datapoints belonging to digits 4 and 9 (which are always clustered together, even when reseeding), and then I select the attributes that are most discriminatory (i.e. the top portion of the 9) in the attribute visualization. After I let t-SNE adapt the similarities, those two clusters are less \"clingy\" than before. It doesn't work great yet, but it's still a work in progress.\n\nAny suggestions for datasets that exhibit this problem, or directions for where to look, or ideas to go about this, are very much appreciated! :)", "author_fullname": "t2_t9kjuxcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for datasets that demonstrate my t-SNE adaptation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9u411", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666359844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: I am looking for datasets of which the attributes can be intuitively visualized (e.g. as a matrix. an image, a diagram, etc.) and are easy to individually select (e.g. by dragging over the matrix/image). What&amp;#39;s more, it should be a dataset with which t-SNE has some difficulty, and of which some conceptual clusters are erroneously merged or separated in the embedding.&lt;/p&gt;\n\n&lt;p&gt;I am developing an adaptation of t-SNE \u2014 specifically &lt;a href=\"https://arxiv.org/abs/1805.10817\"&gt;Linear complexity t-SNE&lt;/a&gt; \u2014 that allows users to manipulate embeddings on-the-fly, which hopefully results in more intuitive embeddings. To this end, the two main tools are the dragging and fixing of datapoints, and the altering/shaping of clusters by changing the high-dimensional similarities. As an example of the latter, imagine one apparent cluster in a t-SNE embedding of which the user suspects or knows it to consist of two or more &amp;quot;actual&amp;quot;/conceptual clusters. t-SNE likely hasn&amp;#39;t been able to separate them due to the discriminatory attributes (i.e. the high dimensions on which those conceptual clusters differ the most) being a minority within the dataset&amp;#39;s high dimensions. In such a case, the user should be able to select all datapoints in this erroneously merged cluster in the embedding, select the discriminatory attributes in a visualization summarizing the selected datapoints, and let t-SNE adapt the similarities in such a way that:&lt;/p&gt;\n\n&lt;p&gt;- inter-similarities (between datapoints from different conceptual clusters) are reduced by a lot&lt;/p&gt;\n\n&lt;p&gt;- intra-similatities (between datapoints from the same conceptual cluster) are reduced very little&lt;/p&gt;\n\n&lt;p&gt;Now, I am looking for datasets with which I can demonstrate this feature. Suitable datasets have attributes that can be intuitively visualized and are individually selectable. Grayscale image datasets such as MNIST are an example. &lt;a href=\"https://imgur.com/HWX4tcA\"&gt;Here is a premature version of my t-SNE adaptation on the MNIST dataset.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I select datapoints belonging to digits 4 and 9 (which are always clustered together, even when reseeding), and then I select the attributes that are most discriminatory (i.e. the top portion of the 9) in the attribute visualization. After I let t-SNE adapt the similarities, those two clusters are less &amp;quot;clingy&amp;quot; than before. It doesn&amp;#39;t work great yet, but it&amp;#39;s still a work in progress.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for datasets that exhibit this problem, or directions for where to look, or ideas to go about this, are very much appreciated! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?auto=webp&amp;s=2fb89e309feb632f8c77e3799ffeeba2632dff91", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4487ad05943c379444fa77e699cd9ad3120def13", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=20a0986040c4f2aa358e6646a9d3b5eeee792ec7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rs-7zBct4DbJHhqWTYy8l79pMSxBRnuTjuP_c3PoEfY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af91664967c7413e5ab38b805d325574d72f28bb", "width": 320, "height": 168}], "variants": {}, "id": "2ks1rghdg_X7SUQoVJwcwQn5lNVuDasYXEelboAJbSs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9u411", "is_robot_indexable": true, "report_reasons": null, "author": "ZykeNaggs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9u411/suggestions_for_datasets_that_demonstrate_my_tsne/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9u411/suggestions_for_datasets_that_demonstrate_my_tsne/", "subreddit_subscribers": 814745, "created_utc": 1666359844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If so what were you doing and why did you decide to use them?", "author_fullname": "t2_oonv5wgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ever used Reinforcement Learning or Genetic Algorithms in your work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9s1dv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666354024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If so what were you doing and why did you decide to use them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9s1dv", "is_robot_indexable": true, "report_reasons": null, "author": "throwayaist", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9s1dv/ever_used_reinforcement_learning_or_genetic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9s1dv/ever_used_reinforcement_learning_or_genetic/", "subreddit_subscribers": 814745, "created_utc": 1666354024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to find a good data conference to take the DS and DE on my team to. Someone recommended DataDay in Texas, wondering if anyone here been to that. Or if there are other options worth looking into? \nI would prefer it to be in Austin, Chicago or Vegas.\n\nThanks in advanced!", "author_fullname": "t2_16kgog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data conference recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya2aro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666380342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find a good data conference to take the DS and DE on my team to. Someone recommended DataDay in Texas, wondering if anyone here been to that. Or if there are other options worth looking into? \nI would prefer it to be in Austin, Chicago or Vegas.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advanced!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya2aro", "is_robot_indexable": true, "report_reasons": null, "author": "balpby1989", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya2aro/data_conference_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya2aro/data_conference_recommendations/", "subreddit_subscribers": 814745, "created_utc": 1666380342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data scientists who have experience in the conservation field, what tools could be used to monitor and track specific individuals while working on a given terrain?\n\nWe have a large list of documented animal encounters, but we have no idea how to use that to our advantage.", "author_fullname": "t2_t7mbx7jy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science applied to species monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9wzzx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666367079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data scientists who have experience in the conservation field, what tools could be used to monitor and track specific individuals while working on a given terrain?&lt;/p&gt;\n\n&lt;p&gt;We have a large list of documented animal encounters, but we have no idea how to use that to our advantage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9wzzx", "is_robot_indexable": true, "report_reasons": null, "author": "ruelass", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9wzzx/data_science_applied_to_species_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9wzzx/data_science_applied_to_species_monitoring/", "subreddit_subscribers": 814745, "created_utc": 1666367079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I scanned the FAQ and saw the salary ranges.\n\nMy contract during covid was $75/hr no benefits and was short term renewed at $80.  This new position wants to offer me $60/hr no benefits and I would go onto a 1099, which would cost me an extra 8% in taxes.  I held that previous contract for two years and I felt that it established my going rate.\n\nIndustry. Not a FAANG.\n\nI'm not going to overshare, but I am in my late 30s and know all the things and have done all the things.\n\nI'm seriously considering declining the offer and continuing my search, but I wanted to see if the internet hivemind thinks I'm being ridiculous and that $120k for industry is standard.", "author_fullname": "t2_4arel3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lowball or unrealistic expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya406p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666384520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I scanned the FAQ and saw the salary ranges.&lt;/p&gt;\n\n&lt;p&gt;My contract during covid was $75/hr no benefits and was short term renewed at $80.  This new position wants to offer me $60/hr no benefits and I would go onto a 1099, which would cost me an extra 8% in taxes.  I held that previous contract for two years and I felt that it established my going rate.&lt;/p&gt;\n\n&lt;p&gt;Industry. Not a FAANG.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not going to overshare, but I am in my late 30s and know all the things and have done all the things.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seriously considering declining the offer and continuing my search, but I wanted to see if the internet hivemind thinks I&amp;#39;m being ridiculous and that $120k for industry is standard.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "ya406p", "is_robot_indexable": true, "report_reasons": null, "author": "Kegheimer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya406p/lowball_or_unrealistic_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya406p/lowball_or_unrealistic_expectations/", "subreddit_subscribers": 814745, "created_utc": 1666384520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am new to data science, and im hoping this is the right forum for this. I have a configuration of honeypots that are collecting logs of attack interactions across the world. I'm looking to see the regional differences in attacks and to carry out some other interesting analysis that may be interesting.\n\n\nHow would folks here tackle this challenge? What additional insights into the problem do you need?", "author_fullname": "t2_3p9b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing Network logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9xn8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666368710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data science, and im hoping this is the right forum for this. I have a configuration of honeypots that are collecting logs of attack interactions across the world. I&amp;#39;m looking to see the regional differences in attacks and to carry out some other interesting analysis that may be interesting.&lt;/p&gt;\n\n&lt;p&gt;How would folks here tackle this challenge? What additional insights into the problem do you need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9xn8c", "is_robot_indexable": true, "report_reasons": null, "author": "godlee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9xn8c/analyzing_network_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9xn8c/analyzing_network_logs/", "subreddit_subscribers": 814745, "created_utc": 1666368710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. \n\nAny suggestions appreciated!", "author_fullname": "t2_n11qkmhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best advice for being able to code machine learning algorithms from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9uc02", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title. I feel like I kind of grasp the concepts theoretically but once I start trying to code them in Python I have no idea where to start. And btw I\u2019m not talking about using sklearn etc I mean writing an algorithm to implement a decision tree for example. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9uc02", "is_robot_indexable": true, "report_reasons": null, "author": "el_el_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9uc02/best_advice_for_being_able_to_code_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9uc02/best_advice_for_being_able_to_code_machine/", "subreddit_subscribers": 814745, "created_utc": 1666360431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Update: added a demo \"Core Trading System\" to feed the main system and be able to visualize some data. The demo will be connecting to real-time data from Coinbase and Binance\n\nSo now, you can run it and test it with no issues.\n\ngithub opensource project: VisualHFT\n\n[https://github.com/silahian/VisualHFT](https://github.com/silahian/VisualHFT)", "author_fullname": "t2_401yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VisualHFT: visualizing market microstructure analytics (opensource)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya4gqw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666385663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Update: added a demo &amp;quot;Core Trading System&amp;quot; to feed the main system and be able to visualize some data. The demo will be connecting to real-time data from Coinbase and Binance&lt;/p&gt;\n\n&lt;p&gt;So now, you can run it and test it with no issues.&lt;/p&gt;\n\n&lt;p&gt;github opensource project: VisualHFT&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/silahian/VisualHFT\"&gt;https://github.com/silahian/VisualHFT&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?auto=webp&amp;s=3e04f857871da5e72c50a41f1a1029d65a111b29", "width": 1167, "height": 685}, "resolutions": [{"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3a59bee0550fe5c977df1e3e106079029c53d10", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b70e2431ec5da1aaa05bdb42dad37cc4da05713b", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=03e17f7edd67ba5e928386597bedc973f9da1c11", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db60e7c6d69d21f73767aa12e3e65fa96ff6eb24", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c0070e2f36178c893771b7e4034381c8d448f18c", "width": 960, "height": 563}, {"url": "https://external-preview.redd.it/XBfaGNn_PR5413dLIUsSbWyMZlZ22augwhz8wXIQSsE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f882782124d375b783a8621bc2fd91dc92994270", "width": 1080, "height": 633}], "variants": {}, "id": "XmMPn7Cn7AgVSPrK1BHlCQptRWcI9F4-rYALOHjDTT0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya4gqw", "is_robot_indexable": true, "report_reasons": null, "author": "silahian", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya4gqw/visualhft_visualizing_market_microstructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya4gqw/visualhft_visualizing_market_microstructure/", "subreddit_subscribers": 814745, "created_utc": 1666385663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone here have any idea what type of questions can come in a 15 minute SQL SHL Test\nAny help is greatly appreciated. Thanks!\n\nPS: I have never in my life used SQL in any form.", "author_fullname": "t2_46i5sfp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL SHL Assessment Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tucd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666359139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here have any idea what type of questions can come in a 15 minute SQL SHL Test\nAny help is greatly appreciated. Thanks!&lt;/p&gt;\n\n&lt;p&gt;PS: I have never in my life used SQL in any form.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9tucd", "is_robot_indexable": true, "report_reasons": null, "author": "yashsingh0105", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9tucd/sql_shl_assessment_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9tucd/sql_shl_assessment_test/", "subreddit_subscribers": 814745, "created_utc": 1666359139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Happens to be a transformer that solves tabular problems in a second without the need to fit a model in the traditional manner. It radiccaly differs from other ML methods and supposedly outperforms gradient based trees with HPO... Seems really like a different paradigm from good old fit and predict.", "author_fullname": "t2_4tmb276q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "thoughts on TabPFN?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9safl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666354783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happens to be a transformer that solves tabular problems in a second without the need to fit a model in the traditional manner. It radiccaly differs from other ML methods and supposedly outperforms gradient based trees with HPO... Seems really like a different paradigm from good old fit and predict.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9safl", "is_robot_indexable": true, "report_reasons": null, "author": "CHADvier", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9safl/thoughts_on_tabpfn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9safl/thoughts_on_tabpfn/", "subreddit_subscribers": 814745, "created_utc": 1666354783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working full time earning $85 per hour with all other benefits.\n\nI just want to know if it's applicable to work on a full time contract, $120 hr with health care,  at the same time?\n\nAny legal issue, time management issue?\nTwo companies are not competitive and in different industries. \n\nThanks!", "author_fullname": "t2_12x43b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "full time employee ability to work on a full time contract?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9yq4l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666381161.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666371474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working full time earning $85 per hour with all other benefits.&lt;/p&gt;\n\n&lt;p&gt;I just want to know if it&amp;#39;s applicable to work on a full time contract, $120 hr with health care,  at the same time?&lt;/p&gt;\n\n&lt;p&gt;Any legal issue, time management issue?\nTwo companies are not competitive and in different industries. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9yq4l", "is_robot_indexable": true, "report_reasons": null, "author": "janicewa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9yq4l/full_time_employee_ability_to_work_on_a_full_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9yq4l/full_time_employee_ability_to_work_on_a_full_time/", "subreddit_subscribers": 814745, "created_utc": 1666371474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for confidence.\n\n&amp;#x200B;\n\nThere's another ways to optimize this algorithm?", "author_fullname": "t2_768gsz2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FPGrowth about doubts [PySpark]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9ta6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for confidence.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s another ways to optimize this algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9ta6h", "is_robot_indexable": true, "report_reasons": null, "author": "suneirl1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9ta6h/fpgrowth_about_doubts_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9ta6h/fpgrowth_about_doubts_pyspark/", "subreddit_subscribers": 814745, "created_utc": 1666357654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are people's experiences using outsourcing platforms for data collecting and labelling like Mechanical Turk, Appen, Scale AI etc?\n\nI have long considered using them but can't vouch for the quality of the data collected so I would love to hear from other who have used them first hand. Thanks!", "author_fullname": "t2_5lfzc2mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crowdsourcing data collection and labelling - good or bad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9t6wi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are people&amp;#39;s experiences using outsourcing platforms for data collecting and labelling like Mechanical Turk, Appen, Scale AI etc?&lt;/p&gt;\n\n&lt;p&gt;I have long considered using them but can&amp;#39;t vouch for the quality of the data collected so I would love to hear from other who have used them first hand. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9t6wi", "is_robot_indexable": true, "report_reasons": null, "author": "fourcornerclub", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9t6wi/crowdsourcing_data_collection_and_labelling_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9t6wi/crowdsourcing_data_collection_and_labelling_good/", "subreddit_subscribers": 814745, "created_utc": 1666357403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I'm a full stack developer currently and I'm building my start-up towards climate change! I've built up a community platform so far. I'm looking forward to work on a content recommendation system towards climate positive content for the platform.\n\nI so far have a postgresql database for my backend which has a \n\n- Posts model with information like the time, user location (because it's a local community platform), post category (like reddit flairs)\n\n- Likes model with who liked and time\n- Reports model\n- And comments model \n\nI've had earlier theoretical experience with supervised learning and few of the basic concepts. I'm looking to know what are the few concepts/tools I need to know to begin tinkering with this data", "author_fullname": "t2_179j4b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I begin my journey with DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yad233", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666409859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m a full stack developer currently and I&amp;#39;m building my start-up towards climate change! I&amp;#39;ve built up a community platform so far. I&amp;#39;m looking forward to work on a content recommendation system towards climate positive content for the platform.&lt;/p&gt;\n\n&lt;p&gt;I so far have a postgresql database for my backend which has a &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Posts model with information like the time, user location (because it&amp;#39;s a local community platform), post category (like reddit flairs)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Likes model with who liked and time&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Reports model&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;And comments model &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve had earlier theoretical experience with supervised learning and few of the basic concepts. I&amp;#39;m looking to know what are the few concepts/tools I need to know to begin tinkering with this data&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yad233", "is_robot_indexable": true, "report_reasons": null, "author": "DarkAbhi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yad233/how_do_i_begin_my_journey_with_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yad233/how_do_i_begin_my_journey_with_ds/", "subreddit_subscribers": 814745, "created_utc": 1666409859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a daily task which is sending email daily in the morning, I used to email the screenshot of my report. I planned to automate this through python. So i got my three dataframes ready. Here's how i can place it in a each dataframe in each container. Suggest me how I can do that", "author_fullname": "t2_9r5qrevk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple Pandas Dataframe into the one HTML page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya02pk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666374918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a daily task which is sending email daily in the morning, I used to email the screenshot of my report. I planned to automate this through python. So i got my three dataframes ready. Here&amp;#39;s how i can place it in a each dataframe in each container. Suggest me how I can do that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya02pk", "is_robot_indexable": true, "report_reasons": null, "author": "Fabro_vaz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya02pk/multiple_pandas_dataframe_into_the_one_html_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya02pk/multiple_pandas_dataframe_into_the_one_html_page/", "subreddit_subscribers": 814745, "created_utc": 1666374918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there\n\nWhat do you guys think about using a ML  model to find statistical differences between populations? Let me explain my particular case:\n\nI have a dataset of 56 cells (more to come) coming from 4 different patients (target variable) with different illness conditions, each cell has \\~22 numerical features and our aim is to find differences among the patients (one being the control). Since looking for correlations between features and statistical differences become too overwhelming and tedious, I thought of training a interpretable ML model and use it to discover which properties have the cell of each patient, There is no intention/value to make future predictions. The 2 best performing models were Logistic Regresion and a Random Forest with AOC &gt; 0.9 and F1-score &gt; 0.9 (trained with the whole dataset an 10-fold CV). Afterwards I use the SHAP-values and permutation feature importance to see which features and values intervals are more characteristic for each patient. Although there is a bit of discrepancy between the order of the most important features given by LogReg and RForest, there is good agreement for the most important features at each case. I found this method superior to PCA since some features add little to the global variance but are important for a particular patient.\n\nThis is exploratory research, so the main question to answer with this approach is: is the good performing model a good way of finding whether cells coming from different illnesses are different?\n\nWhat do you think about this practice? have you used it in your work?\n\nCheers\u00a1", "author_fullname": "t2_a96dnkj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using a model to find statistical differences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9yuhu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666376861.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666371777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there&lt;/p&gt;\n\n&lt;p&gt;What do you guys think about using a ML  model to find statistical differences between populations? Let me explain my particular case:&lt;/p&gt;\n\n&lt;p&gt;I have a dataset of 56 cells (more to come) coming from 4 different patients (target variable) with different illness conditions, each cell has ~22 numerical features and our aim is to find differences among the patients (one being the control). Since looking for correlations between features and statistical differences become too overwhelming and tedious, I thought of training a interpretable ML model and use it to discover which properties have the cell of each patient, There is no intention/value to make future predictions. The 2 best performing models were Logistic Regresion and a Random Forest with AOC &amp;gt; 0.9 and F1-score &amp;gt; 0.9 (trained with the whole dataset an 10-fold CV). Afterwards I use the SHAP-values and permutation feature importance to see which features and values intervals are more characteristic for each patient. Although there is a bit of discrepancy between the order of the most important features given by LogReg and RForest, there is good agreement for the most important features at each case. I found this method superior to PCA since some features add little to the global variance but are important for a particular patient.&lt;/p&gt;\n\n&lt;p&gt;This is exploratory research, so the main question to answer with this approach is: is the good performing model a good way of finding whether cells coming from different illnesses are different?&lt;/p&gt;\n\n&lt;p&gt;What do you think about this practice? have you used it in your work?&lt;/p&gt;\n\n&lt;p&gt;Cheers\u00a1&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9yuhu", "is_robot_indexable": true, "report_reasons": null, "author": "Ale_Campoy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9yuhu/using_a_model_to_find_statistical_differences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9yuhu/using_a_model_to_find_statistical_differences/", "subreddit_subscribers": 814745, "created_utc": 1666371777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am new in this sub, and I am not sure if it is self-promotion, but I just wanted to learn if my model could be a new product or not. \n\nI spent a lot of time finding near-duplicates on multiple data records. That s why I build a model which finds near duplicate records from various tables/CSV and flags them according to the difference score. So I can filter these records and handle them. For example, one branch puts a user ID like \u201c0001763,\u201d and the other one uses \u201cxxx1763, 01763, (branchid)1763\u201d. \n\nSo, do you think that kind of model could be helpful for other companies? \n\nNote: let me know if it a self promotion, I will not do that again.", "author_fullname": "t2_5ddglx8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model detects duplicate records", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tqsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666358896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new in this sub, and I am not sure if it is self-promotion, but I just wanted to learn if my model could be a new product or not. &lt;/p&gt;\n\n&lt;p&gt;I spent a lot of time finding near-duplicates on multiple data records. That s why I build a model which finds near duplicate records from various tables/CSV and flags them according to the difference score. So I can filter these records and handle them. For example, one branch puts a user ID like \u201c0001763,\u201d and the other one uses \u201cxxx1763, 01763, (branchid)1763\u201d. &lt;/p&gt;\n\n&lt;p&gt;So, do you think that kind of model could be helpful for other companies? &lt;/p&gt;\n\n&lt;p&gt;Note: let me know if it a self promotion, I will not do that again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9tqsq", "is_robot_indexable": true, "report_reasons": null, "author": "alka_irl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9tqsq/model_detects_duplicate_records/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9tqsq/model_detects_duplicate_records/", "subreddit_subscribers": 814745, "created_utc": 1666358896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there,\n\nI've been working with Data Science/Machine Learning/Linear Programming etc for almost 5 years now. Basically the \"too mathematical for software developers/data engineers, too much code for maths/science folks\" category- you know the gist.\n\nWhat I have noticed is that Data Science either gets treated as a traditional software development team or a BI team. Both of which I think are quite bad. Of course there's a surge of MLOps which is \"standardising\" shipping and maintaining ML in production, but it doesn't focus too much on actually developing the models. \n\n**Software Development treatment:** Here you lose a lot of flexibility in experimentation, research, model exploration and frankly the failure rate in Data Science projects is relatively high compared to other fields in tech (some things just can't be solved with ML/maths, or simply it is not worth it). Normal software development timelines don't make sense in most cases especially since you rely a lot on backend/data engineers/frontend/product before you even start a project.\n\n**BI treatment:** Well you have 500 scripts, notebooks, analysis spread all around you. There's very little code reviews, basic software development procedures, it's basically the wild west \ud83e\udd20. The infrastructure  gets built by people who have very little clue (or time) about any of this. Retraining, deployment are a nightmare. Whatever benefit you get in actually have in building the models, you surely loose all of it as soon as your work gets into production. \n\nHow do your teams function and structure the work around this? Do you feel this is a bit chaotic or am I the only one? What tools are you using? I know this is a very broad topic but just wondering.  \n\n\nP.S I am very new to reddit not a clue on how this works.", "author_fullname": "t2_mjsxuw53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exposure to professional Data Science and Machine Learning frameworks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9phdb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666346006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working with Data Science/Machine Learning/Linear Programming etc for almost 5 years now. Basically the &amp;quot;too mathematical for software developers/data engineers, too much code for maths/science folks&amp;quot; category- you know the gist.&lt;/p&gt;\n\n&lt;p&gt;What I have noticed is that Data Science either gets treated as a traditional software development team or a BI team. Both of which I think are quite bad. Of course there&amp;#39;s a surge of MLOps which is &amp;quot;standardising&amp;quot; shipping and maintaining ML in production, but it doesn&amp;#39;t focus too much on actually developing the models. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Software Development treatment:&lt;/strong&gt; Here you lose a lot of flexibility in experimentation, research, model exploration and frankly the failure rate in Data Science projects is relatively high compared to other fields in tech (some things just can&amp;#39;t be solved with ML/maths, or simply it is not worth it). Normal software development timelines don&amp;#39;t make sense in most cases especially since you rely a lot on backend/data engineers/frontend/product before you even start a project.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;BI treatment:&lt;/strong&gt; Well you have 500 scripts, notebooks, analysis spread all around you. There&amp;#39;s very little code reviews, basic software development procedures, it&amp;#39;s basically the wild west \ud83e\udd20. The infrastructure  gets built by people who have very little clue (or time) about any of this. Retraining, deployment are a nightmare. Whatever benefit you get in actually have in building the models, you surely loose all of it as soon as your work gets into production. &lt;/p&gt;\n\n&lt;p&gt;How do your teams function and structure the work around this? Do you feel this is a bit chaotic or am I the only one? What tools are you using? I know this is a very broad topic but just wondering.  &lt;/p&gt;\n\n&lt;p&gt;P.S I am very new to reddit not a clue on how this works.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9phdb", "is_robot_indexable": true, "report_reasons": null, "author": "olderthanyoda", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9phdb/exposure_to_professional_data_science_and_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9phdb/exposure_to_professional_data_science_and_machine/", "subreddit_subscribers": 814745, "created_utc": 1666346006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all data scientists,\nWhat is the best cpu (amd or intel) for heavy data analysis/science projects? I need to decide which is better to do advanced data stuff. The go to is desktop. Is latest cpu really important or not? I need advice related to senior level advanced data project but not for noob/dummy level. There is no limit for my budget. So how can I choose and consider about cpu specs? Also I wanna know more about maximum &amp; minimum requirement for cpu types especially designed for data analysis. Apart from other pc specs, how can you decide which cpu is most suitable for DS professionals? Please, I seriously need your specific &amp; detailed answers! Sorry for my bad english. Thanks for help.", "author_fullname": "t2_eqi1utf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for cpu consideration (for data science applications)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_yab1r8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666403683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all data scientists,\nWhat is the best cpu (amd or intel) for heavy data analysis/science projects? I need to decide which is better to do advanced data stuff. The go to is desktop. Is latest cpu really important or not? I need advice related to senior level advanced data project but not for noob/dummy level. There is no limit for my budget. So how can I choose and consider about cpu specs? Also I wanna know more about maximum &amp;amp; minimum requirement for cpu types especially designed for data analysis. Apart from other pc specs, how can you decide which cpu is most suitable for DS professionals? Please, I seriously need your specific &amp;amp; detailed answers! Sorry for my bad english. Thanks for help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "yab1r8", "is_robot_indexable": true, "report_reasons": null, "author": "Lucky_Strawberry_185", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/yab1r8/advice_for_cpu_consideration_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/yab1r8/advice_for_cpu_consideration_for_data_science/", "subreddit_subscribers": 814745, "created_utc": 1666403683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone have good resources for practice problems that specifically cover pandas and SQL? It\u2019s for faang adjacent company. I freeze up in interviews and need to practice beforehand otherwise I will forget everything I know lol.", "author_fullname": "t2_4xhvqofl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practice sets for tech screening in python and sql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya581f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666387541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have good resources for practice problems that specifically cover pandas and SQL? It\u2019s for faang adjacent company. I freeze up in interviews and need to practice beforehand otherwise I will forget everything I know lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "ya581f", "is_robot_indexable": true, "report_reasons": null, "author": "gengarvibes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/ya581f/practice_sets_for_tech_screening_in_python_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/ya581f/practice_sets_for_tech_screening_in_python_and_sql/", "subreddit_subscribers": 814745, "created_utc": 1666387541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear all, \n\nI started working on this dataset that has these features : \n\n\\- ball\\_position (x,y,z) (3 features) \n\n\\- ball\\_velocity (x,y,z) (3 features)\n\nThe velocity can be negative. \n\nI am feeling confident in normalizing, using the common minmax normalization, the coordinates.   \nBut when it comes to the velocity, I have no physics background and I do not know if that would hurt the future results. \n\nI do not believe that it will cause any issues, as we are only re scaling the distribution between 0 and 1. But I just wanted to know your guidelines on normalization. When should I worry about if I should do it or not, when can I do it with my eyes closed. \n\n&amp;#x200B;\n\nThank you very much !", "author_fullname": "t2_11fpam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Normalization and Scaling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9n94g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666338310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all, &lt;/p&gt;\n\n&lt;p&gt;I started working on this dataset that has these features : &lt;/p&gt;\n\n&lt;p&gt;- ball_position (x,y,z) (3 features) &lt;/p&gt;\n\n&lt;p&gt;- ball_velocity (x,y,z) (3 features)&lt;/p&gt;\n\n&lt;p&gt;The velocity can be negative. &lt;/p&gt;\n\n&lt;p&gt;I am feeling confident in normalizing, using the common minmax normalization, the coordinates.&lt;br/&gt;\nBut when it comes to the velocity, I have no physics background and I do not know if that would hurt the future results. &lt;/p&gt;\n\n&lt;p&gt;I do not believe that it will cause any issues, as we are only re scaling the distribution between 0 and 1. But I just wanted to know your guidelines on normalization. When should I worry about if I should do it or not, when can I do it with my eyes closed. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you very much !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "y9n94g", "is_robot_indexable": true, "report_reasons": null, "author": "Frizzoux", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/y9n94g/normalization_and_scaling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/y9n94g/normalization_and_scaling/", "subreddit_subscribers": 814745, "created_utc": 1666338310.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}