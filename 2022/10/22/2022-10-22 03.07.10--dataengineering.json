{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It is a recession after all, isn't it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y9xa2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 227, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 227, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oKhcYT0kIgJcwFqz5o_KuYTtbuks9ofkJd2gX1UvKRs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666367817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i2wm18ghl6v91.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i2wm18ghl6v91.png?auto=webp&amp;s=ea915027b60d524ac456c1ae90335b5605cd876c", "width": 500, "height": 700}, "resolutions": [{"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=88aea7b9b817bbb1c3cb4c226a7274851c200e12", "width": 108, "height": 151}, {"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=36bfd2db4d1f91e47db03ef656138c63ef3fefee", "width": 216, "height": 302}, {"url": "https://preview.redd.it/i2wm18ghl6v91.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cef543faf1211c6409322b8f1605f7edd5d6fdc", "width": 320, "height": 448}], "variants": {}, "id": "E403cU_KwdNMd3cN_f8qQqaVwWeirvnKva-C1_w0xdw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "y9xa2k", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9xa2k/it_is_a_recession_after_all_isnt_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i2wm18ghl6v91.png", "subreddit_subscribers": 77321, "created_utc": 1666367817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys , I\u2019m a complete noob in this field. So far I\u2019ve worked mostly on Frontend projects. I\u2019ve worked a little with AWS data modelling for a small app and had a course where we covered relational databases and concepts under that umbrella, an example being table normalization. \n\nI\u2019m currently enrolled in a systems analysis and design course , and am reading the following textbooks to learn by myself \n\n-  computer organization and design - David Patterson \n- computer architecture : a quantitative approach - also by Patterson \n- parallel computer architecture - David culler \n\n\nCan I also start reading designing data intensive applications. Am I going about this the right way? Utilizing the right materials? Some guidance from you experienced folks would be lovely. Thank you \ud83d\ude4f\ud83c\udffc", "author_fullname": "t2_k6wgicc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just picked up the book \u201cDesigning Data Intensive Applications\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9ujpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666360970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys , I\u2019m a complete noob in this field. So far I\u2019ve worked mostly on Frontend projects. I\u2019ve worked a little with AWS data modelling for a small app and had a course where we covered relational databases and concepts under that umbrella, an example being table normalization. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently enrolled in a systems analysis and design course , and am reading the following textbooks to learn by myself &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; computer organization and design - David Patterson &lt;/li&gt;\n&lt;li&gt;computer architecture : a quantitative approach - also by Patterson &lt;/li&gt;\n&lt;li&gt;parallel computer architecture - David culler &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Can I also start reading designing data intensive applications. Am I going about this the right way? Utilizing the right materials? Some guidance from you experienced folks would be lovely. Thank you \ud83d\ude4f\ud83c\udffc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9ujpz", "is_robot_indexable": true, "report_reasons": null, "author": "arib_kamal", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9ujpz/just_picked_up_the_book_designing_data_intensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9ujpz/just_picked_up_the_book_designing_data_intensive/", "subreddit_subscribers": 77321, "created_utc": 1666360970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mainly an analytics engineer, so I live in dbt and almost exclusively use SQL. I do know some python, and can write simple cloud functions on GCP, but I don't know any other languages such as C++ or Java.\n\nI'm asking because it looks like Python and SQL might be enough for most roles, and I'm using that as a basis for which classes to take in the future for a MSCS. Not sure the time spent learning C++ or Java at this point in my life (I'm 37) would have any benefits in DE. I could see the benefits if I wanted to be a software engineer or if I was personally interested in learning those languages, but I'm not for either of those cases.\n\nAm I missing out on anything?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I missing out on anything by not learning languages like C++ or Java?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9r8cv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666351668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mainly an analytics engineer, so I live in dbt and almost exclusively use SQL. I do know some python, and can write simple cloud functions on GCP, but I don&amp;#39;t know any other languages such as C++ or Java.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking because it looks like Python and SQL might be enough for most roles, and I&amp;#39;m using that as a basis for which classes to take in the future for a MSCS. Not sure the time spent learning C++ or Java at this point in my life (I&amp;#39;m 37) would have any benefits in DE. I could see the benefits if I wanted to be a software engineer or if I was personally interested in learning those languages, but I&amp;#39;m not for either of those cases.&lt;/p&gt;\n\n&lt;p&gt;Am I missing out on anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9r8cv", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9r8cv/am_i_missing_out_on_anything_by_not_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9r8cv/am_i_missing_out_on_anything_by_not_learning/", "subreddit_subscribers": 77321, "created_utc": 1666351668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things #datacentricAI.\n\nToday we launched Out-of-Distribution Detection now natively supported in cleanlab 2.1 to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data -- **it's only one line of code to use.**\n\n[Our algorithms detect out-of-distribution data like this \\\\\"3\\\\\" included in a clothing dataset](https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719)\n\nWhat makes our out-of-distribution package different?\n\nMany complex OOD detection algorithms exist but they are only applicable to specific data types. The `cleanlab.outlier`package works as effectively as these complex methods, but also works with any type of data for which either a feature embedding or trained classifier is available.\n\n`cleanlab.outlier`is:\n\n* [Open-source](https://github.com/cleanlab/cleanlab) and free to use\n* [Research published](https://arxiv.org/abs/2207.03061) \\+ few-lines-of-code [tutorials](https://docs.cleanlab.ai/stable/tutorials/outliers.html)\n* [Benchmarked](https://github.com/cleanlab/ood-detection-benchmarks) to show superior performance in the landscape of OOD methods.\n\nHave fun using `cleanlab.outlier`!\n\nBlog: [https://cleanlab.ai/blog/outlier-detection/](https://cleanlab.ai/blog/outlier-detection/)", "author_fullname": "t2_5v7p3x0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting Out-of-Distribution Datapoints via Embeddings or Predictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wvrdnaeca6v91": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25f828eb4762b0a2f6c9a6b6b435957fecb722df"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b4db33bc957ca22f5b155f23db507e6e4942b9d"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=072dec9d0a87cfd85f880d2f5fe3009703c3ccb1"}, {"y": 254, "x": 640, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51e5f51a39dbdf934523c16010986d4a36c2ec31"}], "s": {"y": 286, "x": 720, "u": "https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719"}, "id": "wvrdnaeca6v91"}}, "name": "t3_y9vu5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LTGb2mWFn7620r2Ky06d3e-fFSnjgc9BECIudHN2UL0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666364163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of you will likely find this useful -- our open-source team has spent the last few years building out the much-needed standard python framework for all things #datacentricAI.&lt;/p&gt;\n\n&lt;p&gt;Today we launched Out-of-Distribution Detection now natively supported in cleanlab 2.1 to help you automatically find and remove outliers in your datasets so you can train models and perform analytics on reliable data -- &lt;strong&gt;it&amp;#39;s only one line of code to use.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wvrdnaeca6v91.jpg?width=720&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d406cbf3cbaf568735e2f0f1e3a1b705e0e52719\"&gt;Our algorithms detect out-of-distribution data like this \\&amp;quot;3\\&amp;quot; included in a clothing dataset&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What makes our out-of-distribution package different?&lt;/p&gt;\n\n&lt;p&gt;Many complex OOD detection algorithms exist but they are only applicable to specific data types. The &lt;code&gt;cleanlab.outlier&lt;/code&gt;package works as effectively as these complex methods, but also works with any type of data for which either a feature embedding or trained classifier is available.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;cleanlab.outlier&lt;/code&gt;is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;Open-source&lt;/a&gt; and free to use&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://arxiv.org/abs/2207.03061\"&gt;Research published&lt;/a&gt; + few-lines-of-code &lt;a href=\"https://docs.cleanlab.ai/stable/tutorials/outliers.html\"&gt;tutorials&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/cleanlab/ood-detection-benchmarks\"&gt;Benchmarked&lt;/a&gt; to show superior performance in the landscape of OOD methods.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Have fun using &lt;code&gt;cleanlab.outlier&lt;/code&gt;!&lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://cleanlab.ai/blog/outlier-detection/\"&gt;https://cleanlab.ai/blog/outlier-detection/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9vu5f", "is_robot_indexable": true, "report_reasons": null, "author": "jonas__m", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9vu5f/detecting_outofdistribution_datapoints_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9vu5f/detecting_outofdistribution_datapoints_via/", "subreddit_subscribers": 77321, "created_utc": 1666364163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Be honest. Hop on that burner if you need to.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats something that you don\u2019t understand but are too afraid to admit because you don\u2019t want to look like an imposter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya7bly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666393014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Be honest. Hop on that burner if you need to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ya7bly", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya7bly/whats_something_that_you_dont_understand_but_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya7bly/whats_something_that_you_dont_understand_but_are/", "subreddit_subscribers": 77321, "created_utc": 1666393014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, on 27th October [Memphis.dev](https://github.com/memphisdev/memphis-broker) is co-hosting  A roundtable around the current trends and challenges of data streaming, design decisions, tech stacks, and use cases. \n\nPure knowledge sharing with the local community of devs and data engineers. \n\n810 7th Ave \u00b7 New York, NY.\n\n&amp;#x200B;\n\nAll data enthusiasts are welcome to join \n\nRSVP \n\n[https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/](https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NYC Data Engineering Meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9n17i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1666337482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, on 27th October &lt;a href=\"https://github.com/memphisdev/memphis-broker\"&gt;Memphis.dev&lt;/a&gt; is co-hosting  A roundtable around the current trends and challenges of data streaming, design decisions, tech stacks, and use cases. &lt;/p&gt;\n\n&lt;p&gt;Pure knowledge sharing with the local community of devs and data engineers. &lt;/p&gt;\n\n&lt;p&gt;810 7th Ave \u00b7 New York, NY.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;All data enthusiasts are welcome to join &lt;/p&gt;\n\n&lt;p&gt;RSVP &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/\"&gt;https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/288432501/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?auto=webp&amp;s=7227dddf662629d580f2e430eeaa2ae7294e47ed", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dcdc025b6b3954b0c2714b519db2547e7ead491", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=902b11284debb4eadeba71f4551344bc40315415", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53f00cfe89098449638e871f4fd704e82f812323", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2baf0c623ee36336ec2367e3798b342c620f62dc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76d99efca5f389a98a9f349d4b1771a36ecdf6dd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/l32tznZytf9fpdInpK9reilxI--2jixkZZJA4JS1pM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed456664e401712061ce47dcc47505d0a6c93b34", "width": 1080, "height": 607}], "variants": {}, "id": "hYBYKmUFkskiOV8szz3ckSx7rnZYTEJIAAkPfkZc44g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9n17i", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9n17i/nyc_data_engineering_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9n17i/nyc_data_engineering_meetup/", "subreddit_subscribers": 77321, "created_utc": 1666337482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing Data Contracts - a Practical Example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_y9syna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sUxnzUmX5-KHSfKI_rEuAPgRyhUKu675HFW7tjuByvs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666356766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@danthelion/implementing-data-contracts-82800b9186b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?auto=webp&amp;s=46aca62508288c55d4151a2b4c79056d669b5f41", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4c6a017cbcaee64ea9102da3b7c415c2f49c1ee", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af1f37d75a8b5aa5733ae45cb3c34ef19be1e5e7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6Mr0mYy8Gg0tPZqsHyY9x5-rUfaIxHEqsxzTI3PJ84E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6c333d9371ef51b59ae929055e0b6ed99ede1b3", "width": 320, "height": 240}], "variants": {}, "id": "SthwCf5cEOddOPntr6QX8ASnB7BHgI2TWTwV92DR34w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9syna", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9syna/implementing_data_contracts_a_practical_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@danthelion/implementing-data-contracts-82800b9186b", "subreddit_subscribers": 77321, "created_utc": 1666356766.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have this large .zip that takes 2 hours to unzip the whole thing. I really only need the .csv files. Is there a way in ADF to only unzip .csv files?", "author_fullname": "t2_sirnldvp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to ONLY unzip .csv files in Azure Data Factory?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9qrty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666350222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this large .zip that takes 2 hours to unzip the whole thing. I really only need the .csv files. Is there a way in ADF to only unzip .csv files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9qrty", "is_robot_indexable": true, "report_reasons": null, "author": "powerBIGuy14", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9qrty/is_it_possible_to_only_unzip_csv_files_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9qrty/is_it_possible_to_only_unzip_csv_files_in_azure/", "subreddit_subscribers": 77321, "created_utc": 1666350222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A step-by-step tutorial on how to manipulate a table in your data lake by writing a custom plugin with VDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 101, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tnx4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VktSmWAXSaU5490oJOKYByY2EkGyxQyZpFoLXT6JZ28.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666358687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/how-to-create-a-data-formatting-plugin-in-vdk-dc5f1c7d206d", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?auto=webp&amp;s=9c6ee1cb4d0e111f2fd2b6a740d3818417e2d9bf", "width": 1200, "height": 868}, "resolutions": [{"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78eaacf59b0f26cfe059b3d02ea5c296f966fcfd", "width": 108, "height": 78}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f93d5c28f98253a461a53f3e2ffedd7f1bb2059", "width": 216, "height": 156}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf5d2bfe012cd1bdae16c0e174eb19c00b268082", "width": 320, "height": 231}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=802ec9e6f14a0491bbbf05f7026d113fca68a813", "width": 640, "height": 462}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bb47fc5725f7e87ee87bff57c23a07c5a8bb5c5", "width": 960, "height": 694}, {"url": "https://external-preview.redd.it/HdOer84WK3nZFBIZjKT4tZtNHXM20Dd-gOkrR1gu-w8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a43c0e61cbad31f6dd6341a746afd17dd9d9e57b", "width": 1080, "height": 781}], "variants": {}, "id": "tq11CeUSiRIQW_qQxnKqt69H0JFY8X4v98kqRCps8Ko"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "y9tnx4", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tnx4/a_stepbystep_tutorial_on_how_to_manipulate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/how-to-create-a-data-formatting-plugin-in-vdk-dc5f1c7d206d", "subreddit_subscribers": 77321, "created_utc": 1666358687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I never heard this terminology until I started working with SQL. When we would have a really gnarly query that we needed to optimize or reverse engineer someone on my team said \"oh yeah this one a real bear\".\n\nSo what exactly does this mean a task that is very tedious and time consuming ? Or is there more to it.", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it mean when a DE project (or any SWE) is considered a real \"bear\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tjl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666358371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I never heard this terminology until I started working with SQL. When we would have a really gnarly query that we needed to optimize or reverse engineer someone on my team said &amp;quot;oh yeah this one a real bear&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So what exactly does this mean a task that is very tedious and time consuming ? Or is there more to it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9tjl2", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tjl2/what_does_it_mean_when_a_de_project_or_any_swe_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9tjl2/what_does_it_mean_when_a_de_project_or_any_swe_is/", "subreddit_subscribers": 77321, "created_utc": 1666358371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_zia33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataProfiler: What's in your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_y9s1xi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F8KDao-juHDzXtQClxdta0TEIIU-2KV9y2k-l4Zz5hg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1666354073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/capitalone/DataProfiler", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?auto=webp&amp;s=327e8583f46a92e6f036839bac1fa10b05b95ccf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6cb43643da4623a7da30465744962cb59af79f2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c164acaa39fc7f477204b047d60da0d7993c9fa7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a862497065014c055a6e110eea07da17fb897f8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=07e0cf9ec9e34a1afb631903f1e1d173675bb848", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cba7e8e8f13df0d85542e07f74bf8d00df89c649", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HlEdNMV-y2rTFX-aWd6KSkwfZthKlH3wHbOo37OAGhU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69949c0002fba768f523a591dc2bd7be90efa38f", "width": 1080, "height": 540}], "variants": {}, "id": "7a2QHIt4QoH5Js0QM9-04MSSFPNASZaYeOw6r4hZ9z8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "y9s1xi", "is_robot_indexable": true, "report_reasons": null, "author": "fitz_n_fitz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9s1xi/dataprofiler_whats_in_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/capitalone/DataProfiler", "subreddit_subscribers": 77321, "created_utc": 1666354073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for support/confidence.\n\n&amp;#x200B;\n\nThere's another ways to optimize this algorithm?", "author_fullname": "t2_768gsz2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FPGrowth and PySpark optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9tapl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666366020.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666357696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I had some questions around FPGrowth at PySpark, i using a dataset around 20M, but i facing some issues when i tried to visualize some rules (memory errors), probably because they are creating a lot of rules even when i limited the thresholds for support/confidence.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s another ways to optimize this algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9tapl", "is_robot_indexable": true, "report_reasons": null, "author": "suneirl1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9tapl/fpgrowth_and_pyspark_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9tapl/fpgrowth_and_pyspark_optimization/", "subreddit_subscribers": 77321, "created_utc": 1666357696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So Airbyte creates data pipelines for me in an easy way. There's a cloud option and a self-host open source option.\n\nLet's say I create a pipeline in Airbyte. Let's say that this pipeline requires some CPU compute and RAM. Where is this CPU and RAM coming from? Is it on the same instance as the Airbyte app? Or do I have to create EC2/Lambda functions somewhere else and let Airbyte control them?", "author_fullname": "t2_l5aep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does the compute come from when I use Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9lbtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666331611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So Airbyte creates data pipelines for me in an easy way. There&amp;#39;s a cloud option and a self-host open source option.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I create a pipeline in Airbyte. Let&amp;#39;s say that this pipeline requires some CPU compute and RAM. Where is this CPU and RAM coming from? Is it on the same instance as the Airbyte app? Or do I have to create EC2/Lambda functions somewhere else and let Airbyte control them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9lbtf", "is_robot_indexable": true, "report_reasons": null, "author": "joel1234512", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9lbtf/where_does_the_compute_come_from_when_i_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9lbtf/where_does_the_compute_come_from_when_i_use/", "subreddit_subscribers": 77321, "created_utc": 1666331611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am planning to take this certification since our company offers free vouchers.\n\nTo those who passed this exam, how long did you review? So i can come up with an estimated schedule for me. Also, how's the difficulty of the exam?\n\nThanks in advance!", "author_fullname": "t2_kh03mlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Professional Data Engineer Certificate - how long did you review?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9iaip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666322217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to take this certification since our company offers free vouchers.&lt;/p&gt;\n\n&lt;p&gt;To those who passed this exam, how long did you review? So i can come up with an estimated schedule for me. Also, how&amp;#39;s the difficulty of the exam?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y9iaip", "is_robot_indexable": true, "report_reasons": null, "author": "keemi01", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9iaip/google_professional_data_engineer_certificate_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9iaip/google_professional_data_engineer_certificate_how/", "subreddit_subscribers": 77321, "created_utc": 1666322217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Overlapping classes are requiring a group project involving a database and R project. \n\nInterested to hear what you would work on? Group size is 6 people. We have experience with SQL(intermediate), R (basics), and Azure(novices). \n\nI have 2 years of undergrad coding background in Java, Python, C#, and C++. \n\nTimeline is 4 weeks to complete. \n\nWould love to hear suggestions on interesting projects you all would suggest! Not looking to just do the bare minimum but want to work on something really cool!", "author_fullname": "t2_4u1haote", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for interesting graduate level group project involving Azure Database and R.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_yac2ix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666406806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Overlapping classes are requiring a group project involving a database and R project. &lt;/p&gt;\n\n&lt;p&gt;Interested to hear what you would work on? Group size is 6 people. We have experience with SQL(intermediate), R (basics), and Azure(novices). &lt;/p&gt;\n\n&lt;p&gt;I have 2 years of undergrad coding background in Java, Python, C#, and C++. &lt;/p&gt;\n\n&lt;p&gt;Timeline is 4 weeks to complete. &lt;/p&gt;\n\n&lt;p&gt;Would love to hear suggestions on interesting projects you all would suggest! Not looking to just do the bare minimum but want to work on something really cool!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "yac2ix", "is_robot_indexable": true, "report_reasons": null, "author": "Mooshmo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/yac2ix/looking_for_interesting_graduate_level_group/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/yac2ix/looking_for_interesting_graduate_level_group/", "subreddit_subscribers": 77321, "created_utc": 1666406806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as part of a small data team that consists of mainly non-technical folks. A lot of my work for the past year has been around automating our internal process and a few external data reliability and validation needs for our platform. \n\nI\u2019m responsible for most of the code and pipelines that the data team uses which run on Azure DevOps as well as some automated month end reporting for other teams and our clients. Main programming language is Python (Libraries commonly used are Pandas, numpy, selenium,openpyxl, simple_salesforce and a few select api to access data stored on third party provisioned services), SQL, Salesforce queries, Power Query for Power BI manipulation. \n\nRecently I have been integrating a lot more Azure services into our workflow, the goal around this is to reduce the dependence of the team on excel and the need to constantly pull large amounts of the same data from the db during pipeline runs. The main services I have included are Azure Storage (blobs), Azure functions, Key Valult and Azure Api management.\n\nI have two certifications: Azure Data Engineer (Dp203) and Azure Adminstrator (Az104). Also prepping for Azure Devops Cert (Az 400).\n\nMy current title is Data Analyst, however I feel like it does not really capture all the things that I do. It\u2019s not something I am overly hang up on however I would like to know based on the above info what would the appropriate title be?", "author_fullname": "t2_dkq68c2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the title of my role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya45g8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666384885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as part of a small data team that consists of mainly non-technical folks. A lot of my work for the past year has been around automating our internal process and a few external data reliability and validation needs for our platform. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m responsible for most of the code and pipelines that the data team uses which run on Azure DevOps as well as some automated month end reporting for other teams and our clients. Main programming language is Python (Libraries commonly used are Pandas, numpy, selenium,openpyxl, simple_salesforce and a few select api to access data stored on third party provisioned services), SQL, Salesforce queries, Power Query for Power BI manipulation. &lt;/p&gt;\n\n&lt;p&gt;Recently I have been integrating a lot more Azure services into our workflow, the goal around this is to reduce the dependence of the team on excel and the need to constantly pull large amounts of the same data from the db during pipeline runs. The main services I have included are Azure Storage (blobs), Azure functions, Key Valult and Azure Api management.&lt;/p&gt;\n\n&lt;p&gt;I have two certifications: Azure Data Engineer (Dp203) and Azure Adminstrator (Az104). Also prepping for Azure Devops Cert (Az 400).&lt;/p&gt;\n\n&lt;p&gt;My current title is Data Analyst, however I feel like it does not really capture all the things that I do. It\u2019s not something I am overly hang up on however I would like to know based on the above info what would the appropriate title be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "ya45g8", "is_robot_indexable": true, "report_reasons": null, "author": "MajiYaKuoshaVyombo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya45g8/what_is_the_title_of_my_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya45g8/what_is_the_title_of_my_role/", "subreddit_subscribers": 77321, "created_utc": 1666384885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have fun task of trying to centralize several disparate systems that I\u2019ve inherited and was trying to explain the problem to several business users. One of the \u201cveterans\u201d insists we should just pass SSN\u2019s across systems (in part because it is stored in several of these systems already).\n\nMy initial and gut stance is this is a horrible idea fraught with compliance issues but my background isn\u2019t super deep in regulatory.\n\nAm I wrong on this stance and does anyone have recommendations/laws/regulations to leverage to make my case", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using PII (SSN) as link between several systems\u2019 data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya3c8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666382912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have fun task of trying to centralize several disparate systems that I\u2019ve inherited and was trying to explain the problem to several business users. One of the \u201cveterans\u201d insists we should just pass SSN\u2019s across systems (in part because it is stored in several of these systems already).&lt;/p&gt;\n\n&lt;p&gt;My initial and gut stance is this is a horrible idea fraught with compliance issues but my background isn\u2019t super deep in regulatory.&lt;/p&gt;\n\n&lt;p&gt;Am I wrong on this stance and does anyone have recommendations/laws/regulations to leverage to make my case&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "ya3c8x", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya3c8x/using_pii_ssn_as_link_between_several_systems_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya3c8x/using_pii_ssn_as_link_between_several_systems_data/", "subreddit_subscribers": 77321, "created_utc": 1666382912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, is there anyone here who is, works with, or knows a good amount about the role of an Ontology Specialist? I\u2019m currently in a bit of a dilema, in a good way. I\u2019m a recent software engineering bootcamp graduate who has received two separate job offers over the past week. One is Django/AWS developer at a start-up company and the other is an Ontology Specialist at a company that works closely with a big tech company that I won\u2019t name here. I think it\u2019s worth mentioning more of my background that seems to align with the Ontology Specialist role. Before pursuing software engineering, I got an undergrad in Linguistics and took many Philosophy courses while in college. As a part of the bootcamp, I built two full-stack capstone projects that incorporated NLP with Python\u2019s NLTK library to extract Sentiment Analysis data and insights from news stories and artist lyrics. Although I genuinely enjoy software development, working on the data portion of these projects definitely the most enjoyable part of my entire experience during the bootcamp. \n\nAfter speaking with the company and googling a bit, I now know a little bit more about what the role of an Ontology Specialist entails, but there\u2019s still a lot that remains ambiguous to me. The interviewer did say that the Ontology Specialist position could work just fine for someone trying to get into the field of software engineering, but they did warn me that I wouldn\u2019t be writing too much actual code. Honestly, the position sounds very interesting and like it could open doors to certain areas that I frankly think are more interesting than software engineering, such as NLP and Machine Learning. \n\nI\u2019m just worried that if I don\u2019t like this sort of work after a year and want to go back to mainly software engineering, that it would be almost equally as hard for me to get a job as a software engineer as it is right now, as I wouldn\u2019t have gained really any hands on experience in software engineering. Is this a valid fear? And a few more questions:\n\n1. Is the opportunity for remote work as well as promotions and raises just as good for an Ontology Specialist as it is for a software engineer? \n2. What fields would it be possibly to transition into if I find I don\u2019t really enjoy the Ontology Specialist position? For instance, would this open up some opportunities to work in Machine Learning down the road?\n3. Lastly, if anyone here is or has worked with Ontology Specialists and could explain to me a little more about their experience, or even grant me a 10-15 minute informational interview, that\u2019d be fantastic. During my interview with the company I was able to learn a bit, but we didn\u2019t get too much time and I was still left with a lot of questions. \n\nThanks everyone.", "author_fullname": "t2_6bdkgnq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recent SWE Bootcamp grad offered job as Ontology Specialist. Could use some guidance and clarification.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9z49y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666372488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, is there anyone here who is, works with, or knows a good amount about the role of an Ontology Specialist? I\u2019m currently in a bit of a dilema, in a good way. I\u2019m a recent software engineering bootcamp graduate who has received two separate job offers over the past week. One is Django/AWS developer at a start-up company and the other is an Ontology Specialist at a company that works closely with a big tech company that I won\u2019t name here. I think it\u2019s worth mentioning more of my background that seems to align with the Ontology Specialist role. Before pursuing software engineering, I got an undergrad in Linguistics and took many Philosophy courses while in college. As a part of the bootcamp, I built two full-stack capstone projects that incorporated NLP with Python\u2019s NLTK library to extract Sentiment Analysis data and insights from news stories and artist lyrics. Although I genuinely enjoy software development, working on the data portion of these projects definitely the most enjoyable part of my entire experience during the bootcamp. &lt;/p&gt;\n\n&lt;p&gt;After speaking with the company and googling a bit, I now know a little bit more about what the role of an Ontology Specialist entails, but there\u2019s still a lot that remains ambiguous to me. The interviewer did say that the Ontology Specialist position could work just fine for someone trying to get into the field of software engineering, but they did warn me that I wouldn\u2019t be writing too much actual code. Honestly, the position sounds very interesting and like it could open doors to certain areas that I frankly think are more interesting than software engineering, such as NLP and Machine Learning. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just worried that if I don\u2019t like this sort of work after a year and want to go back to mainly software engineering, that it would be almost equally as hard for me to get a job as a software engineer as it is right now, as I wouldn\u2019t have gained really any hands on experience in software engineering. Is this a valid fear? And a few more questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is the opportunity for remote work as well as promotions and raises just as good for an Ontology Specialist as it is for a software engineer? &lt;/li&gt;\n&lt;li&gt;What fields would it be possibly to transition into if I find I don\u2019t really enjoy the Ontology Specialist position? For instance, would this open up some opportunities to work in Machine Learning down the road?&lt;/li&gt;\n&lt;li&gt;Lastly, if anyone here is or has worked with Ontology Specialists and could explain to me a little more about their experience, or even grant me a 10-15 minute informational interview, that\u2019d be fantastic. During my interview with the company I was able to learn a bit, but we didn\u2019t get too much time and I was still left with a lot of questions. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks everyone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9z49y", "is_robot_indexable": true, "report_reasons": null, "author": "sammyhats", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9z49y/recent_swe_bootcamp_grad_offered_job_as_ontology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9z49y/recent_swe_bootcamp_grad_offered_job_as_ontology/", "subreddit_subscribers": 77321, "created_utc": 1666372488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm creating a Spark DataFrame from a list of tuples using PySpark. The list can be relatively large. And with larger lists, the time could increase significantly. Most of what I've read on creating DataFrames in spark uses external files like CSV files. So I was wondering if there were any best practices I employ when creating a DataFrames from a list of tuples. \n\nI did some profiling on the various methods I have. And it looks like the majority of the time is spent creating the DataFrame. I've sped up this process somewhat by using a schema when I create the DataFrame. But this is as far as I've been able to take the optimizations.", "author_fullname": "t2_2ntu9i1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark: Creating a DataFrame from a list of tuples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9yehm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666370634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m creating a Spark DataFrame from a list of tuples using PySpark. The list can be relatively large. And with larger lists, the time could increase significantly. Most of what I&amp;#39;ve read on creating DataFrames in spark uses external files like CSV files. So I was wondering if there were any best practices I employ when creating a DataFrames from a list of tuples. &lt;/p&gt;\n\n&lt;p&gt;I did some profiling on the various methods I have. And it looks like the majority of the time is spent creating the DataFrame. I&amp;#39;ve sped up this process somewhat by using a schema when I create the DataFrame. But this is as far as I&amp;#39;ve been able to take the optimizations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y9yehm", "is_robot_indexable": true, "report_reasons": null, "author": "ineffablol", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9yehm/pyspark_creating_a_dataframe_from_a_list_of_tuples/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9yehm/pyspark_creating_a_dataframe_from_a_list_of_tuples/", "subreddit_subscribers": 77321, "created_utc": 1666370634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an option to do one of these 2 and I was wondering which role would be more beneficial for my data engineering career, Business Analyst or ETL tester role?\n\n&amp;#x200B;\n\nThanks for any insight!", "author_fullname": "t2_tjxw4oe5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is better, Business Analyst or ETL Tester role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y9qmaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666349749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an option to do one of these 2 and I was wondering which role would be more beneficial for my data engineering career, Business Analyst or ETL tester role?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y9qmaq", "is_robot_indexable": true, "report_reasons": null, "author": "de_juggin95", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y9qmaq/what_is_better_business_analyst_or_etl_tester_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y9qmaq/what_is_better_business_analyst_or_etl_tester_role/", "subreddit_subscribers": 77321, "created_utc": 1666349749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nEdilitics is a turnkey Data &amp; Analytics solution with an aim to optimise business practices and decision making throughout the value chain. \nWe have developed the solution with a focus on reducing the work load of the code literate and enabling those without code literacy to perform data analytics with ease. \n\n\nThe Problem:\n\n- Eliminate dependency on multiple teams, tools and programming languages to effectively perform data analytics.\n- Provide access to analytics ready data without the need to create and maintain lengthy scripts.\n- Build a one-stop solution to connect the entire organisation to a single source of truth.\n\n\n\n\nThe Solution:\n\n- Integration : an end-to-end data pipeline that enables you to easily pull data from all your sources to the warehouse.\n- Transformation : to better organise your data and make it useable by both humans and systems. \n- Visualisation : graphically represent patterns in data and share with internal as well as external stakeholders. \n- Machine Learning : to analyse and make data-driven recommendations and decisions based on historical data.", "author_fullname": "t2_9o1sdswe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feed back: app.edilitics.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya5wn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666389282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edilitics is a turnkey Data &amp;amp; Analytics solution with an aim to optimise business practices and decision making throughout the value chain. \nWe have developed the solution with a focus on reducing the work load of the code literate and enabling those without code literacy to perform data analytics with ease. &lt;/p&gt;\n\n&lt;p&gt;The Problem:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Eliminate dependency on multiple teams, tools and programming languages to effectively perform data analytics.&lt;/li&gt;\n&lt;li&gt;Provide access to analytics ready data without the need to create and maintain lengthy scripts.&lt;/li&gt;\n&lt;li&gt;Build a one-stop solution to connect the entire organisation to a single source of truth.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The Solution:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Integration : an end-to-end data pipeline that enables you to easily pull data from all your sources to the warehouse.&lt;/li&gt;\n&lt;li&gt;Transformation : to better organise your data and make it useable by both humans and systems. &lt;/li&gt;\n&lt;li&gt;Visualisation : graphically represent patterns in data and share with internal as well as external stakeholders. &lt;/li&gt;\n&lt;li&gt;Machine Learning : to analyse and make data-driven recommendations and decisions based on historical data.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ya5wn0", "is_robot_indexable": true, "report_reasons": null, "author": "New_Name_6954", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya5wn0/feed_back_appediliticscom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya5wn0/feed_back_appediliticscom/", "subreddit_subscribers": 77321, "created_utc": 1666389282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There were quite a few posts and comments recently about Snowflake. Some folks compare Snowflake with evil companies like Oracle and IBM.\n\nAs a big fan of Snowflake (I do not work for them and have no interest in promoting them) and someone who was very skeptical about Snowflake hype, I am very very very curious there this hate is coming from and it is biased towards other products and vendors (and we know quite a lot of people here promote vendors they work for).\n\nI would like to hear why you hate Snowflake so much and what product you love instead.\n\nHere a few reasons why I felt in love with Snowflake and why I do not hesitate to recommend it to my piers. I do have extensive background working with traditional RDBMS, EDW platforms and Big Data/Hadoop/Spark/Kafka and all the zoo.\n\nFirst off, Snowflake supports all 3 big cloud providers so you can move to another cloud and you cannot really do that with BigQuery or Redshift or Synapse. Yes, it is proprietary tech, and no, you cannot change their source code (but how often you have done it with other platforms??) but at least you are not locked on one cloud. A lot of companies who hire new CEOs/CTOs, love to start cloud migration projects and you never know which cloud you will end up using tomorrow.\n\nSecond, Snowflake does not keep your data hostage. They make it super easy to get data out of Snowflake. In fact, they help you do that by eating egress costs. You pay 0$ for outbound egress as long as you are moving data in the same region/cloud provider. Very easy to backup your snowflake tables to S3/Blob with literally one command and that command is very fast and efficient.\n\nThird, performance is amazing. A lot of time you get sub-second response time - Presto, Athena, Hive, Databricks, Spark etc. can only dream about such performance. ANSI SQL compatibility helps a lot to port queries from other data platforms. Amazing query plan that helps you tweak performance of queries (good luck understanding Databricks execution profile!)\n\nFourth, the stupid thing just works out of the box. No indexes, no clustering or partitioning, no primary keys. No special-type tables or special-type data types. Just load data and enjoy.\n\nFifth, while real-time is tough with Snowflake and it is more like 5-10 second near real-time, they had UPSERT capabilities and Snowpipe long before Databricks had delta lake. A lot of distributed systems still to date do not have DELETE or UPDATE capabilities.\n\nLast, but not least. People were building data lakes and data warehouses BOTH on Snowflake when data lakehouse (what a stupid term) was not coined by Databricks. It is very efficient as data lake because storage is dirt cheap and they support semi-structured data as well. With snowpark addition, this takes this to the next level but I am personally not sold on snowpark idea and I still love Spark. But if you look at what others do, they force you to build separate data lake and separate DW so you end up with two systems not one.\n\nYou get a host of countless other features that simple not possible in many other competing products. Dropped a table by accident and it was not on your daily backup? No problem, just run UNDROP TABLE command.\n\nWant to go back in time to query your table as it was 30 days ago? no worries, use time-travel and point-in-time query feature.\n\nWant to share your production environment data with non-production environment for development and testing? Just a few more commands to run and you get a virtual copy of your production databases in your non-prod snowflake account. You do not pay double price for storage since only metadata is shared.\n\nOh, and speaking of storage price - did you see how cheap it is?\n\nNow one popular complaint - but Snowflake is $$$. Correct, that is if you are lazy #$% who does not read documentation and does not use all the great features that Snowflake gives YOU to help you spend less money.  VDW auto-suspend, caching, instant resize of compute cluster, automated multi-clustering to deal with concurrency during peak time, materialized views (very limited IMHO because they do not support joins but new dynamic tables feature should solve this problem nicely).\n\nNow, it is not perfect by any means. I personally would love to see these features in future:\n\n1. ability to enforce primary keys natively\n2. simple visual UI to run, schedule and monitor SQL queries, with simple dependencies. Snowflake tasks are pretty bad and get really messy over time. I do not want to deal with external schedulers just to run simple Snowflake queries in sequence.\n3. security model is confusing and can get quite messy if you do not think it through from beginning. I am not sure what they were thinking here by not implementing simple RBAC model. But on a bright side, they give all everything you need to build your own custom model / roles.\n4. a lot of usability issues with UI though it is getting better. I mean common, no auto completion for SQL?? Fortunately, they have new UI Snowsight that has it but not all the features of the old UI are available there so depending on what you do you have to switch between old and new UI.\n\nBut as you can see these are pretty minor things.\n\nLet's go - tell me why you hate it and what do you think works better in this world.\n\nThanks!", "author_fullname": "t2_5a55k9k4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question to Snowflake haters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya587h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1666389949.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666387554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There were quite a few posts and comments recently about Snowflake. Some folks compare Snowflake with evil companies like Oracle and IBM.&lt;/p&gt;\n\n&lt;p&gt;As a big fan of Snowflake (I do not work for them and have no interest in promoting them) and someone who was very skeptical about Snowflake hype, I am very very very curious there this hate is coming from and it is biased towards other products and vendors (and we know quite a lot of people here promote vendors they work for).&lt;/p&gt;\n\n&lt;p&gt;I would like to hear why you hate Snowflake so much and what product you love instead.&lt;/p&gt;\n\n&lt;p&gt;Here a few reasons why I felt in love with Snowflake and why I do not hesitate to recommend it to my piers. I do have extensive background working with traditional RDBMS, EDW platforms and Big Data/Hadoop/Spark/Kafka and all the zoo.&lt;/p&gt;\n\n&lt;p&gt;First off, Snowflake supports all 3 big cloud providers so you can move to another cloud and you cannot really do that with BigQuery or Redshift or Synapse. Yes, it is proprietary tech, and no, you cannot change their source code (but how often you have done it with other platforms??) but at least you are not locked on one cloud. A lot of companies who hire new CEOs/CTOs, love to start cloud migration projects and you never know which cloud you will end up using tomorrow.&lt;/p&gt;\n\n&lt;p&gt;Second, Snowflake does not keep your data hostage. They make it super easy to get data out of Snowflake. In fact, they help you do that by eating egress costs. You pay 0$ for outbound egress as long as you are moving data in the same region/cloud provider. Very easy to backup your snowflake tables to S3/Blob with literally one command and that command is very fast and efficient.&lt;/p&gt;\n\n&lt;p&gt;Third, performance is amazing. A lot of time you get sub-second response time - Presto, Athena, Hive, Databricks, Spark etc. can only dream about such performance. ANSI SQL compatibility helps a lot to port queries from other data platforms. Amazing query plan that helps you tweak performance of queries (good luck understanding Databricks execution profile!)&lt;/p&gt;\n\n&lt;p&gt;Fourth, the stupid thing just works out of the box. No indexes, no clustering or partitioning, no primary keys. No special-type tables or special-type data types. Just load data and enjoy.&lt;/p&gt;\n\n&lt;p&gt;Fifth, while real-time is tough with Snowflake and it is more like 5-10 second near real-time, they had UPSERT capabilities and Snowpipe long before Databricks had delta lake. A lot of distributed systems still to date do not have DELETE or UPDATE capabilities.&lt;/p&gt;\n\n&lt;p&gt;Last, but not least. People were building data lakes and data warehouses BOTH on Snowflake when data lakehouse (what a stupid term) was not coined by Databricks. It is very efficient as data lake because storage is dirt cheap and they support semi-structured data as well. With snowpark addition, this takes this to the next level but I am personally not sold on snowpark idea and I still love Spark. But if you look at what others do, they force you to build separate data lake and separate DW so you end up with two systems not one.&lt;/p&gt;\n\n&lt;p&gt;You get a host of countless other features that simple not possible in many other competing products. Dropped a table by accident and it was not on your daily backup? No problem, just run UNDROP TABLE command.&lt;/p&gt;\n\n&lt;p&gt;Want to go back in time to query your table as it was 30 days ago? no worries, use time-travel and point-in-time query feature.&lt;/p&gt;\n\n&lt;p&gt;Want to share your production environment data with non-production environment for development and testing? Just a few more commands to run and you get a virtual copy of your production databases in your non-prod snowflake account. You do not pay double price for storage since only metadata is shared.&lt;/p&gt;\n\n&lt;p&gt;Oh, and speaking of storage price - did you see how cheap it is?&lt;/p&gt;\n\n&lt;p&gt;Now one popular complaint - but Snowflake is $$$. Correct, that is if you are lazy #$% who does not read documentation and does not use all the great features that Snowflake gives YOU to help you spend less money.  VDW auto-suspend, caching, instant resize of compute cluster, automated multi-clustering to deal with concurrency during peak time, materialized views (very limited IMHO because they do not support joins but new dynamic tables feature should solve this problem nicely).&lt;/p&gt;\n\n&lt;p&gt;Now, it is not perfect by any means. I personally would love to see these features in future:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;ability to enforce primary keys natively&lt;/li&gt;\n&lt;li&gt;simple visual UI to run, schedule and monitor SQL queries, with simple dependencies. Snowflake tasks are pretty bad and get really messy over time. I do not want to deal with external schedulers just to run simple Snowflake queries in sequence.&lt;/li&gt;\n&lt;li&gt;security model is confusing and can get quite messy if you do not think it through from beginning. I am not sure what they were thinking here by not implementing simple RBAC model. But on a bright side, they give all everything you need to build your own custom model / roles.&lt;/li&gt;\n&lt;li&gt;a lot of usability issues with UI though it is getting better. I mean common, no auto completion for SQL?? Fortunately, they have new UI Snowsight that has it but not all the features of the old UI are available there so depending on what you do you have to switch between old and new UI.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;But as you can see these are pretty minor things.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s go - tell me why you hate it and what do you think works better in this world.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ya587h", "is_robot_indexable": true, "report_reasons": null, "author": "koteikin", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya587h/question_to_snowflake_haters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya587h/question_to_snowflake_haters/", "subreddit_subscribers": 77321, "created_utc": 1666387554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you know what it usually is in a company?", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ratio data / software engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_ya4rew", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1666386399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you know what it usually is in a company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "ya4rew", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/ya4rew/ratio_data_software_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/ya4rew/ratio_data_software_engineer/", "subreddit_subscribers": 77321, "created_utc": 1666386399.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}