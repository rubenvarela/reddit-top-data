{"kind": "Listing", "data": {"after": "t3_y2cr28", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am organising an evening workshop aimed at last year university students (mostly technical profiles). The goal is to make them warm for a career in data engineering. Or at least give them a taste of what it is (not) about. \n\nIf you have organised or joined such a similar event, what topics/tools/platform worked or did not work? Any suggestions?  \n\n\nWhat I had in mind: create a small story where they are part of a data team under time pressure to deliver: introduce them to Pyspark (core concepts),  let them play in Databricks, provide bad quality data, let them schedule a job on it. During this, other persona's would pop up (architects, product owners, data scientists) that will alter the scope slightly and let them reflect on how they did it.", "author_fullname": "t2_cnfdjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for 2-3h workshop for students on data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1xia7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665560609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am organising an evening workshop aimed at last year university students (mostly technical profiles). The goal is to make them warm for a career in data engineering. Or at least give them a taste of what it is (not) about. &lt;/p&gt;\n\n&lt;p&gt;If you have organised or joined such a similar event, what topics/tools/platform worked or did not work? Any suggestions?  &lt;/p&gt;\n\n&lt;p&gt;What I had in mind: create a small story where they are part of a data team under time pressure to deliver: introduce them to Pyspark (core concepts),  let them play in Databricks, provide bad quality data, let them schedule a job on it. During this, other persona&amp;#39;s would pop up (architects, product owners, data scientists) that will alter the scope slightly and let them reflect on how they did it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y1xia7", "is_robot_indexable": true, "report_reasons": null, "author": "brunocou", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1xia7/ideas_for_23h_workshop_for_students_on_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1xia7/ideas_for_23h_workshop_for_students_on_data/", "subreddit_subscribers": 76223, "created_utc": 1665560609.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "GitLab describes itself as \"an open core company\", meaning the company \"openly shares more information than most companies and is public by default, meaning our projects, [strategy](https://about.gitlab.com/company/strategy/), [direction](https://about.gitlab.com/direction/#vision) and [metrics](https://about.gitlab.com/company/okrs/) are discussed openly and can be found within our website\".\n\nFor example, their Data Team have a [public repository](https://gitlab.com/gitlab-data/analytics), with a bunch of information on how they organize DAGs, machine learning projects, system configuration, etc.\n\nAre there any other companies that do the same or similar? I learned a lot by reading GitLab's repository, so it'd be nice to see other examples in the industry.", "author_fullname": "t2_7iesagha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any open corporate Data Team repositories / projects besides GitLab?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1jp0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665520614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;GitLab describes itself as &amp;quot;an open core company&amp;quot;, meaning the company &amp;quot;openly shares more information than most companies and is public by default, meaning our projects, &lt;a href=\"https://about.gitlab.com/company/strategy/\"&gt;strategy&lt;/a&gt;, &lt;a href=\"https://about.gitlab.com/direction/#vision\"&gt;direction&lt;/a&gt; and &lt;a href=\"https://about.gitlab.com/company/okrs/\"&gt;metrics&lt;/a&gt; are discussed openly and can be found within our website&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;For example, their Data Team have a &lt;a href=\"https://gitlab.com/gitlab-data/analytics\"&gt;public repository&lt;/a&gt;, with a bunch of information on how they organize DAGs, machine learning projects, system configuration, etc.&lt;/p&gt;\n\n&lt;p&gt;Are there any other companies that do the same or similar? I learned a lot by reading GitLab&amp;#39;s repository, so it&amp;#39;d be nice to see other examples in the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Dmj4euH2v22sDnW9EpiI9A5UhdvfmjNiO_caO7CURZE.jpg?auto=webp&amp;s=a95e6a070a3cb4615617d068e648ce993276adc5", "width": 875, "height": 612}, "resolutions": [{"url": "https://external-preview.redd.it/Dmj4euH2v22sDnW9EpiI9A5UhdvfmjNiO_caO7CURZE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa6a845f12f061d63f992a52d1a5d40bafb503eb", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/Dmj4euH2v22sDnW9EpiI9A5UhdvfmjNiO_caO7CURZE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d5d1ed6ae127d023682bb3d785fe334d2d42074", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/Dmj4euH2v22sDnW9EpiI9A5UhdvfmjNiO_caO7CURZE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e96d508a03cb2c1f5ba5b80263b50798bed7fbc", "width": 320, "height": 223}, {"url": "https://external-preview.redd.it/Dmj4euH2v22sDnW9EpiI9A5UhdvfmjNiO_caO7CURZE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=245c24a4dd667f604f6f892e8811df6fc582df37", "width": 640, "height": 447}], "variants": {}, "id": "v9bukcUTEDutaePTQidDeR95NYA8AyYs-tp2j6EyUkc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y1jp0k", "is_robot_indexable": true, "report_reasons": null, "author": "Pop-Huge", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1jp0k/are_there_any_open_corporate_data_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1jp0k/are_there_any_open_corporate_data_team/", "subreddit_subscribers": 76223, "created_utc": 1665520614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted a few days ago about my experience interviewing for my first Data Engineering position and some advice I had for others who are going through the process right now. But I also want to share a bizzare experience that happened to me for one the positions I was in the process of interviewing for.\n\nApplied for the position of Data Engineer at a fairly large healthcare software company. Initial screening with recruiter went good, then they asked me to do a video interview where there was a series of questions and I would record a 2-3 minute response for each of them. This was my first time doing something like this so it was a little awkward but luckily they gave you 2 chances to re record it. Anyway that went well next came the technical challenge.\n\nBasically had to sign up for one of those hacker rank things, questions were 8 SQL and 2 Python questions of varying difficulty. SQL questions were fairly easy about joins and commiting transactions , stuff like if transaction A is open and Transaction B commits what is the result of the query. One SQL question was more advanced about the difference between a Clustered and Non Clustered index and how they differ on the disk. First Python question was simple but the second one loaded up some interactive web IDE and gave you a cvs file to sort through and perform some transformations which I did with pandas. The timer for all of this was an hour and I finished with a few minutes left. The final Python question definitely took the most time out of any of them.\n\nAnyway I get invited to a video interview with the team and it went great. Seemed like some really cool guys to work with and they outlined what I would be doing , how they used an Agile methodology used Dev Ops for source control and versioning. Most of the Data Engineering work was related to SSIS and Azure Data Factory. \n\nI really thought I was going to get an offer and then a week or two later they contacted me and said they had a new CIO or whatever and they were no longer hiring for a Data engineer but instead for someone to supervise a team of Data Engineers who would be working out of India. They said I would also have to keep the hours there some days which I don't even know what they are but I said sure whatever I'm still interested so I scheduled another interview.\n\nSecond interview was with the same guys and they themselves didn't seem to happy about the situation because instead of hiring a data engineer to work on their team they were now trying to fill the role of someone who would be a team leader and liason for a team of data engineers that was outsourced to a company that uses talent from India and other countries. I was real honest with them that I didnt have any team leading experience and had only worked on small teams of 3-4 developers in the past myself. I definitely was no longer a good fit for this role and I had already accepted a soft offer for a diff position but would have considered this one if the salary difference was significant. \n\nBut anyway I never heard back from them and received kind of a generic rejection letter in my Updates folder in GMAIL. I definitely would have loved the original job and the guys on the team seemed really cool but this was definitely a strange experience. Has anything like this ever happened to anyone else ?", "author_fullname": "t2_dfcot0zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering job title/duties changed mid interview process.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1jpxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665520680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted a few days ago about my experience interviewing for my first Data Engineering position and some advice I had for others who are going through the process right now. But I also want to share a bizzare experience that happened to me for one the positions I was in the process of interviewing for.&lt;/p&gt;\n\n&lt;p&gt;Applied for the position of Data Engineer at a fairly large healthcare software company. Initial screening with recruiter went good, then they asked me to do a video interview where there was a series of questions and I would record a 2-3 minute response for each of them. This was my first time doing something like this so it was a little awkward but luckily they gave you 2 chances to re record it. Anyway that went well next came the technical challenge.&lt;/p&gt;\n\n&lt;p&gt;Basically had to sign up for one of those hacker rank things, questions were 8 SQL and 2 Python questions of varying difficulty. SQL questions were fairly easy about joins and commiting transactions , stuff like if transaction A is open and Transaction B commits what is the result of the query. One SQL question was more advanced about the difference between a Clustered and Non Clustered index and how they differ on the disk. First Python question was simple but the second one loaded up some interactive web IDE and gave you a cvs file to sort through and perform some transformations which I did with pandas. The timer for all of this was an hour and I finished with a few minutes left. The final Python question definitely took the most time out of any of them.&lt;/p&gt;\n\n&lt;p&gt;Anyway I get invited to a video interview with the team and it went great. Seemed like some really cool guys to work with and they outlined what I would be doing , how they used an Agile methodology used Dev Ops for source control and versioning. Most of the Data Engineering work was related to SSIS and Azure Data Factory. &lt;/p&gt;\n\n&lt;p&gt;I really thought I was going to get an offer and then a week or two later they contacted me and said they had a new CIO or whatever and they were no longer hiring for a Data engineer but instead for someone to supervise a team of Data Engineers who would be working out of India. They said I would also have to keep the hours there some days which I don&amp;#39;t even know what they are but I said sure whatever I&amp;#39;m still interested so I scheduled another interview.&lt;/p&gt;\n\n&lt;p&gt;Second interview was with the same guys and they themselves didn&amp;#39;t seem to happy about the situation because instead of hiring a data engineer to work on their team they were now trying to fill the role of someone who would be a team leader and liason for a team of data engineers that was outsourced to a company that uses talent from India and other countries. I was real honest with them that I didnt have any team leading experience and had only worked on small teams of 3-4 developers in the past myself. I definitely was no longer a good fit for this role and I had already accepted a soft offer for a diff position but would have considered this one if the salary difference was significant. &lt;/p&gt;\n\n&lt;p&gt;But anyway I never heard back from them and received kind of a generic rejection letter in my Updates folder in GMAIL. I definitely would have loved the original job and the guys on the team seemed really cool but this was definitely a strange experience. Has anything like this ever happened to anyone else ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y1jpxw", "is_robot_indexable": true, "report_reasons": null, "author": "DrRedmondNYC", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1jpxw/data_engineering_job_titleduties_changed_mid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1jpxw/data_engineering_job_titleduties_changed_mid/", "subreddit_subscribers": 76223, "created_utc": 1665520680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nMy company uses Flyway and we currently keep track of data and schema changes. Here's my simple question: could this be done differently? What do you guys use at your company? Do you just take regular dumps/snapshots? Do you use other tools? Do you keep track of both data and schema?\n\nMany thanks", "author_fullname": "t2_17f8xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database version control: how do you do it at your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y26s3q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665588159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;My company uses Flyway and we currently keep track of data and schema changes. Here&amp;#39;s my simple question: could this be done differently? What do you guys use at your company? Do you just take regular dumps/snapshots? Do you use other tools? Do you keep track of both data and schema?&lt;/p&gt;\n\n&lt;p&gt;Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y26s3q", "is_robot_indexable": true, "report_reasons": null, "author": "goglobal01", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y26s3q/database_version_control_how_do_you_do_it_at_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y26s3q/database_version_control_how_do_you_do_it_at_your/", "subreddit_subscribers": 76223, "created_utc": 1665588159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_h30vc65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your process for deploying a data pipeline from a notebook, running it, and managing it in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_y2bl65", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 22, "domain": "i.redd.it", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RroEsmI7CJi1Jay3z_IgPGAUtA7a54WP5JTv3MRwsP0.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1665599540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/pq04w47z4ft91.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?auto=webp&amp;s=60c30264e541d7e8eebe102734a42bb4264850b2", "width": 500, "height": 585}, "resolutions": [{"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d83cc0f1f5a4e715ab30e00387bf6d1db27e0e5d", "width": 108, "height": 126}, {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c38d6c3bbbc2e8e3f20a4525872acba72a16c01", "width": 216, "height": 252}, {"url": "https://preview.redd.it/pq04w47z4ft91.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e0ce26b863772d37918629d7050bcabe32cc416", "width": 320, "height": 374}], "variants": {}, "id": "pqAyKsDleORYu-ooOQsVqG1tMO87jQIXYM7Is2K6-3w"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y2bl65", "is_robot_indexable": true, "report_reasons": null, "author": "jnkwok", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2bl65/whats_your_process_for_deploying_a_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/pq04w47z4ft91.jpg", "subreddit_subscribers": 76223, "created_utc": 1665599540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Planning to build a whole bunch of data pipelines for a new project, which would all be in Python. This is a first for me, as I'm used to creating a simple script or using some GUI based tool. \n\nHow would you structure a Git repo of data pipelines that are all written in Python? Let's say I'm pulling data from 3 different sources, `Apple`, `Banana`, and `Cherry`. Would you have 3 different python files like `apple.py`, `banana.py`, and `cherry.py` all called by `main.py`?\n\nDo you all recommend having a `data` folder as well? I wouldn't publish any data online but for the sake of the repo, should I create a folder?\n\nAny other tips in terms of repo structure and management for data engineering? Would love any and all suggestions!", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you structure a data pipeline repo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y22iyt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665577450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to build a whole bunch of data pipelines for a new project, which would all be in Python. This is a first for me, as I&amp;#39;m used to creating a simple script or using some GUI based tool. &lt;/p&gt;\n\n&lt;p&gt;How would you structure a Git repo of data pipelines that are all written in Python? Let&amp;#39;s say I&amp;#39;m pulling data from 3 different sources, &lt;code&gt;Apple&lt;/code&gt;, &lt;code&gt;Banana&lt;/code&gt;, and &lt;code&gt;Cherry&lt;/code&gt;. Would you have 3 different python files like &lt;code&gt;apple.py&lt;/code&gt;, &lt;code&gt;banana.py&lt;/code&gt;, and &lt;code&gt;cherry.py&lt;/code&gt; all called by &lt;code&gt;main.py&lt;/code&gt;?&lt;/p&gt;\n\n&lt;p&gt;Do you all recommend having a &lt;code&gt;data&lt;/code&gt; folder as well? I wouldn&amp;#39;t publish any data online but for the sake of the repo, should I create a folder?&lt;/p&gt;\n\n&lt;p&gt;Any other tips in terms of repo structure and management for data engineering? Would love any and all suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y22iyt", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y22iyt/how_would_you_structure_a_data_pipeline_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y22iyt/how_would_you_structure_a_data_pipeline_repo/", "subreddit_subscribers": 76223, "created_utc": 1665577450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in Azure Databricks and I'm trying to increase the frequency at which an ADF pipeline can be run from daily to hourly.  This ADF pipeline has a Databricks connector as part of it because it accepts values from a control table and runs both dynamically and in parallel.  This can take around 20 minutes to run using a single cluster.  \n\nThe step I'm trying to overcome right now is the spin up time for said cluster, so I found pools.  But, being really honest, not quite sure how these work and no matter what I've tried, the execution time barely improves.\n\nWhat I've tried and questions:\n\n* I've created the linked service which calls the pool rather than the cluster.  This seems to be working fine.  I'm using the Standard_f8 compute optimised, 16GB, 8 cores instance.\n\n* Created a Databricks pool and attached clusters to it.  For some strange reason, when the ADF pipeline begins adding jobs, the clusters don't spin up and remain in a terminated state.  Is this expected behaviour?\n\n* For the pool, I have set the min idle to be 0.  Ideally, I'd have this pool kick off, have the clusters be ready to go for 8 hours per day, and then spin itself down overnight.\n\n* I have tried both on demand and spot with no decrease in spin up time.  \n\nFrom what I understand, a pool works by distributing workloads across different clusters based on what is and is not available.  I get the feeling there is something I am fundamentally not getting with how pools work.  \n\nShould I be seeing these clusters not spin up at all when a pool is called despite being attached to a pool?\n\nIs this the right approach to decreasing cluster spin up time in Databricks?\n\nThank you!", "author_fullname": "t2_2gp1vrnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks pools - attached clusters not spinning up. Is this expected behaviour?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1zkau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665568040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in Azure Databricks and I&amp;#39;m trying to increase the frequency at which an ADF pipeline can be run from daily to hourly.  This ADF pipeline has a Databricks connector as part of it because it accepts values from a control table and runs both dynamically and in parallel.  This can take around 20 minutes to run using a single cluster.  &lt;/p&gt;\n\n&lt;p&gt;The step I&amp;#39;m trying to overcome right now is the spin up time for said cluster, so I found pools.  But, being really honest, not quite sure how these work and no matter what I&amp;#39;ve tried, the execution time barely improves.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;ve tried and questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;ve created the linked service which calls the pool rather than the cluster.  This seems to be working fine.  I&amp;#39;m using the Standard_f8 compute optimised, 16GB, 8 cores instance.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Created a Databricks pool and attached clusters to it.  For some strange reason, when the ADF pipeline begins adding jobs, the clusters don&amp;#39;t spin up and remain in a terminated state.  Is this expected behaviour?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;For the pool, I have set the min idle to be 0.  Ideally, I&amp;#39;d have this pool kick off, have the clusters be ready to go for 8 hours per day, and then spin itself down overnight.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I have tried both on demand and spot with no decrease in spin up time.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;From what I understand, a pool works by distributing workloads across different clusters based on what is and is not available.  I get the feeling there is something I am fundamentally not getting with how pools work.  &lt;/p&gt;\n\n&lt;p&gt;Should I be seeing these clusters not spin up at all when a pool is called despite being attached to a pool?&lt;/p&gt;\n\n&lt;p&gt;Is this the right approach to decreasing cluster spin up time in Databricks?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Shitty Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1zkau", "is_robot_indexable": true, "report_reasons": null, "author": "MikeDoesEverything", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/y1zkau/databricks_pools_attached_clusters_not_spinning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1zkau/databricks_pools_attached_clusters_not_spinning/", "subreddit_subscribers": 76223, "created_utc": 1665568040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm looking for interesting Data architecture/engineering writers/YouTubers/Twitter profiles to follow and learn from/ could you please share with who are your favorite ones to follow?", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data influencers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1zeve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665567496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m looking for interesting Data architecture/engineering writers/YouTubers/Twitter profiles to follow and learn from/ could you please share with who are your favorite ones to follow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1zeve", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1zeve/data_influencers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1zeve/data_influencers/", "subreddit_subscribers": 76223, "created_utc": 1665567496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL;DR:** Open discussion on the dbt semantic/metrics layer.\n\nLast year Drew Banin, co-founder of dbt labs, [gave a talk on the metrics layer and dbt](https://www.getdbt.com/coalesce-2021/keynote-the-metrics-system/).  \nThat got me curious, thinking where dbt will take this. As time went by they released more information and their view on the topic.  \n\n\nDrew recently wrote [another post](https://www.getdbt.com/blog/dbt-semantic-layer/) on the metrics layer. This time the blog included a lot more details. I found that the fact that dbt are adding an additional server is interesting. It seems like this is the first time that dbt forces users to use dbt-cloud to use this feature. The server is meant to translate \"dbt-sql\" on the fly. I.e the server will be a gateway between applications and the data warehouse.\n\n    select *\n    from {{ metrics.calculate(\n        metric('dbt_cloud_weekly_active_users'),\n        dimensions=['country'],\n        grain='day' ) }}\n\nI believe that this approach will be problematic. There are quite a few companies that use dbt-core with other infrastructure (e.g AirFlow/dbt/BigQuery). These companies will either have to avoid the dbt metrics feature or migrate to dbt cloud.\n\nI would love to hear your thoughts on this subject. Do you think this direction makes sense for dbt? \n\n  \nFor reference the following companies are also working on similar solutions (not dbt bound though):  \n\\- [https://cube.dev/](https://cube.dev/)  \n\\- [https://transform.co/](https://transform.co/)  \nI'm sure there are more, feel free to comment with more companies if relevant.\n\nAnother interesting note is that AirBnB Minerva 2.0 is another metrics layer solution that [is expected to be open sourced soon](https://www.youtube.com/watch?v=ksWwdYwXhh0&amp;ab_channel=Databricks).", "author_fullname": "t2_ayp5oyir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on dbt semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y21vbv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665575578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Open discussion on the dbt semantic/metrics layer.&lt;/p&gt;\n\n&lt;p&gt;Last year Drew Banin, co-founder of dbt labs, &lt;a href=\"https://www.getdbt.com/coalesce-2021/keynote-the-metrics-system/\"&gt;gave a talk on the metrics layer and dbt&lt;/a&gt;.&lt;br/&gt;\nThat got me curious, thinking where dbt will take this. As time went by they released more information and their view on the topic.  &lt;/p&gt;\n\n&lt;p&gt;Drew recently wrote &lt;a href=\"https://www.getdbt.com/blog/dbt-semantic-layer/\"&gt;another post&lt;/a&gt; on the metrics layer. This time the blog included a lot more details. I found that the fact that dbt are adding an additional server is interesting. It seems like this is the first time that dbt forces users to use dbt-cloud to use this feature. The server is meant to translate &amp;quot;dbt-sql&amp;quot; on the fly. I.e the server will be a gateway between applications and the data warehouse.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select *\nfrom {{ metrics.calculate(\n    metric(&amp;#39;dbt_cloud_weekly_active_users&amp;#39;),\n    dimensions=[&amp;#39;country&amp;#39;],\n    grain=&amp;#39;day&amp;#39; ) }}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I believe that this approach will be problematic. There are quite a few companies that use dbt-core with other infrastructure (e.g AirFlow/dbt/BigQuery). These companies will either have to avoid the dbt metrics feature or migrate to dbt cloud.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this subject. Do you think this direction makes sense for dbt? &lt;/p&gt;\n\n&lt;p&gt;For reference the following companies are also working on similar solutions (not dbt bound though):&lt;br/&gt;\n- &lt;a href=\"https://cube.dev/\"&gt;https://cube.dev/&lt;/a&gt;&lt;br/&gt;\n- &lt;a href=\"https://transform.co/\"&gt;https://transform.co/&lt;/a&gt;&lt;br/&gt;\nI&amp;#39;m sure there are more, feel free to comment with more companies if relevant.&lt;/p&gt;\n\n&lt;p&gt;Another interesting note is that AirBnB Minerva 2.0 is another metrics layer solution that &lt;a href=\"https://www.youtube.com/watch?v=ksWwdYwXhh0&amp;amp;ab_channel=Databricks\"&gt;is expected to be open sourced soon&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?auto=webp&amp;s=dfc29c57589489096a4172be53a7237f8e720649", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83e6030b4172723c3902545e997edee3e930e50b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a44afdb7aed4b0db8a8ecc89b53fd218ea9da9b9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8d6d3f9ace8a844df49ae9ff0a4ff1f41fef6e4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f07025ee9435d59b059999381d5064c5c9a9a698", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6fb6989c7570cf2ccbd01ccf6f06e4c0d967750f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ZtXtwr-MU0uJMWStzwnNfFnNqpbDZIEYEcSS42tJrRQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c83abae37378fe05150706ae68c21dc8d194e4bc", "width": 1080, "height": 565}], "variants": {}, "id": "jVsOAHLBrwfbtrK38DWITA6Aj8-KgJYuBOuRaB8V9Z8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y21vbv", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Dog_614", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y21vbv/thoughts_on_dbt_semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y21vbv/thoughts_on_dbt_semantic_layer/", "subreddit_subscribers": 76223, "created_utc": 1665575578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Starting a project with GCS, Bigquery and Looker Studio (hate the new name) and wondering thoughts on switching plans from dbt to dataform. Haven't started transforms yet.\n\nUsing contractors.", "author_fullname": "t2_4d8caxd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dataform re-released - reconsider dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1t5oi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665546061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting a project with GCS, Bigquery and Looker Studio (hate the new name) and wondering thoughts on switching plans from dbt to dataform. Haven&amp;#39;t started transforms yet.&lt;/p&gt;\n\n&lt;p&gt;Using contractors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y1t5oi", "is_robot_indexable": true, "report_reasons": null, "author": "realistdreamer69", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1t5oi/dataform_rereleased_reconsider_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1t5oi/dataform_rereleased_reconsider_dbt/", "subreddit_subscribers": 76223, "created_utc": 1665546061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data engineer interview, any tips?\n\nI have an interview tomorrow for a big company for a data engineer position.\nMy backgroud is limited to sql development (8+ years).\nI have some knowledge with python, (1+ years).\n\nI am azure certified (dp-200), but no profissional experience. \n\nThe position asks for hadoop knowledge and apache spark, which i know only the basics.\n\nAny tips that can give me a chance? They are searching for a middle level data engineer.", "author_fullname": "t2_7ablek9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips for data engineer interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1nfr1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665529959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data engineer interview, any tips?&lt;/p&gt;\n\n&lt;p&gt;I have an interview tomorrow for a big company for a data engineer position.\nMy backgroud is limited to sql development (8+ years).\nI have some knowledge with python, (1+ years).&lt;/p&gt;\n\n&lt;p&gt;I am azure certified (dp-200), but no profissional experience. &lt;/p&gt;\n\n&lt;p&gt;The position asks for hadoop knowledge and apache spark, which i know only the basics.&lt;/p&gt;\n\n&lt;p&gt;Any tips that can give me a chance? They are searching for a middle level data engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1nfr1", "is_robot_indexable": true, "report_reasons": null, "author": "Al3xPxPx", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1nfr1/tips_for_data_engineer_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1nfr1/tips_for_data_engineer_interview/", "subreddit_subscribers": 76223, "created_utc": 1665529959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently part of data team on a retail company on migration, and I want to focus on a dataops roll that cover some technical areas but idk where start\n\nActually this is my first experience on IT so I need the basic to pro stuff or roadmap to start\n\nI reading some books like fundamental of data Engineer  and some blogs like dataops cookbook from data kitchen's  is my next read\n\n\nAny resources to learn dataops?? Or specific tools \nSorry for my bad ingles", "author_fullname": "t2_9pzeqq4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dataops from pm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y27odn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665590318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently part of data team on a retail company on migration, and I want to focus on a dataops roll that cover some technical areas but idk where start&lt;/p&gt;\n\n&lt;p&gt;Actually this is my first experience on IT so I need the basic to pro stuff or roadmap to start&lt;/p&gt;\n\n&lt;p&gt;I reading some books like fundamental of data Engineer  and some blogs like dataops cookbook from data kitchen&amp;#39;s  is my next read&lt;/p&gt;\n\n&lt;p&gt;Any resources to learn dataops?? Or specific tools \nSorry for my bad ingles&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y27odn", "is_robot_indexable": true, "report_reasons": null, "author": "Icy_Cricket_779", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y27odn/dataops_from_pm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y27odn/dataops_from_pm/", "subreddit_subscribers": 76223, "created_utc": 1665590318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y\u2019all! \n\nMy team and I are working on building a pipeline to migrate data from an Oracle database residing on a non-AWS cloud to AWS RDS. \n\nAny tool recommendations? We have already looked into AWS RDS, but I\u2019m wondering if there\u2019s a native tool that\u2019ll work better than that.", "author_fullname": "t2_78dddb58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas on cloud Oracle migration tools to AWS RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2691z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665586897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all! &lt;/p&gt;\n\n&lt;p&gt;My team and I are working on building a pipeline to migrate data from an Oracle database residing on a non-AWS cloud to AWS RDS. &lt;/p&gt;\n\n&lt;p&gt;Any tool recommendations? We have already looked into AWS RDS, but I\u2019m wondering if there\u2019s a native tool that\u2019ll work better than that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2691z", "is_robot_indexable": true, "report_reasons": null, "author": "Both-Trainer-1308", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2691z/ideas_on_cloud_oracle_migration_tools_to_aws_rds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2691z/ideas_on_cloud_oracle_migration_tools_to_aws_rds/", "subreddit_subscribers": 76223, "created_utc": 1665586897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're starting to move our applications from SSIS to ADF and Databricks. I'm going to end up doing most of the work and so the first thing that I want to do is setup our environment variables.\n\nWe use the environment variables in SSIS to store our connection information. That way the Dev environment only has the connection information to the Dev resources. Then when the SSIS package is run, it points to the Dev DB, Dev FTP, etc. Likewise for PPR and PRD. The variables can include an address, username, PW, token, private key, etc.\n\nMy question is, are there best practices about doing this in Azure? My first thought was to use the Data Vault, and to connect from each application to get the login info. But is it appropriate to use the Data Vault for this? Also, is it possible to have the Data Vault have the same name in each environment? Otherwise, our code would have to be in each environment to know which vault to call, right?", "author_fullname": "t2_8u4k0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for ADF and Databricks for Environment variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y255cl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665584246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re starting to move our applications from SSIS to ADF and Databricks. I&amp;#39;m going to end up doing most of the work and so the first thing that I want to do is setup our environment variables.&lt;/p&gt;\n\n&lt;p&gt;We use the environment variables in SSIS to store our connection information. That way the Dev environment only has the connection information to the Dev resources. Then when the SSIS package is run, it points to the Dev DB, Dev FTP, etc. Likewise for PPR and PRD. The variables can include an address, username, PW, token, private key, etc.&lt;/p&gt;\n\n&lt;p&gt;My question is, are there best practices about doing this in Azure? My first thought was to use the Data Vault, and to connect from each application to get the login info. But is it appropriate to use the Data Vault for this? Also, is it possible to have the Data Vault have the same name in each environment? Otherwise, our code would have to be in each environment to know which vault to call, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y255cl", "is_robot_indexable": true, "report_reasons": null, "author": "yoelbenyossef", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y255cl/best_practices_for_adf_and_databricks_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y255cl/best_practices_for_adf_and_databricks_for/", "subreddit_subscribers": 76223, "created_utc": 1665584246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Databases implement materialized views differently. My understanding of how Postgres implements a materialized view is that it builds a cached version of the view results and then refreshes them when the \"refresh materialized view\" statement is used.\n\nGiven that, what advantages does this provide over a drop/create table?\n\nHere's what I can think of, are there others?\n\n* Dependancies retain relationships. This wouldn't be possible with drop/create.\n* Data is always available. There's no moment in time where you may be referencing the view and the data isn't there like there is with a drop/create.", "author_fullname": "t2_roqmtvoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Advantage to Using Postgres Materialized Views vs Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y24bym", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665582171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Databases implement materialized views differently. My understanding of how Postgres implements a materialized view is that it builds a cached version of the view results and then refreshes them when the &amp;quot;refresh materialized view&amp;quot; statement is used.&lt;/p&gt;\n\n&lt;p&gt;Given that, what advantages does this provide over a drop/create table?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I can think of, are there others?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dependancies retain relationships. This wouldn&amp;#39;t be possible with drop/create.&lt;/li&gt;\n&lt;li&gt;Data is always available. There&amp;#39;s no moment in time where you may be referencing the view and the data isn&amp;#39;t there like there is with a drop/create.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y24bym", "is_robot_indexable": true, "report_reasons": null, "author": "goatslikelawns", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y24bym/any_advantage_to_using_postgres_materialized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y24bym/any_advantage_to_using_postgres_materialized/", "subreddit_subscribers": 76223, "created_utc": 1665582171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can I clean up city and postcode/zipcodes in a db. We have pretty shit unclean cities/postcodes and would like to clean using sql. We would this be a macros etc. recommendations please.", "author_fullname": "t2_t1crgsxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clean up City and Zipcode/Postcode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2cxkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665602724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I clean up city and postcode/zipcodes in a db. We have pretty shit unclean cities/postcodes and would like to clean using sql. We would this be a macros etc. recommendations please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2cxkv", "is_robot_indexable": true, "report_reasons": null, "author": "throwme-ariver", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2cxkv/how_to_clean_up_city_and_zipcodepostcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2cxkv/how_to_clean_up_city_and_zipcodepostcode/", "subreddit_subscribers": 76223, "created_utc": 1665602724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is long. I hope it\u2019s ok for the sub.\n\nI\u2019ve made some other posts in this sub about not liking my job, but it\u2019s really coming to a head. Last night, as I was lying in bed not able to sleep, I thought about the most convenient place to jump off and kill myself, which is my apartment building as it has roof access. I don\u2019t like this. I haven\u2019t had thoughts like these in a long time, and they\u2019ve always come along with bad life circumstances. I\u2019ve worked through them before with therapy and other life changes. Unfortunately, therapy is not an option right now because of insurance problems. On the surface, I\u2019ve had much harder times in my life, but something about where I\u2019m at right now is just grinding away my will to live.\n\nI\u2019m a junior data engineer. Data engineering is fine, though I\u2019ve been applying to analyst roles because I studied statistics and I really enjoyed that and want to pursue it. I say junior only because I\u2019m 1 year in to my career in my 30s after finally finding a path that seemed like it could work for me, but I\u2019m the only data engineer at my company.\n\nThis company is small and doesn\u2019t know what data engineering is. I was hired as an analyst and quickly found there were no analyses to be done. The role is a strange combination of high-level programming and problem solving, as well as tedious administrative work that I truly hate. We don\u2019t use the cloud.\n\nMy day-to-day is doing almost nothing. I work perhaps a couple of hours a week now. The bulk of what little work I get now is this tedious administrative work. My boss has told me flat out that there are no more big projects in mind. There is nowhere to be promoted to, and there are no mentors or peers in the data space. Consequently, there also seem to be no opportunities for networking in that space.\n\nI\u2019m haven\u2019t been allowed to work from home because it\u2019s apparently against the views of upper management. My office doesn\u2019t have a window looking outside (only to other office space). The pay is insultingly bad and I\u2019m embarrassed to tell people what I do and where I work because of these conditions. The company appears to have no intention of investing in me or the position. I\u2019ve asked for things and been met with silence.\n\nI used to do landscaping and construction, and while I hated those jobs, I\u2019m so miserable in this that I sometimes fantasize about going up to foremen on sites nearby and asking for work, because at least then I\u2019m outside and busy. The pay is so bad at my job it wouldn\u2019t be much of a downgrade in that respect, which is further depressing.\n\nMostly, Monday to Friday I sit in a room and convince myself not to walk out.\n\nOne of my strengths is I\u2019m a very proactive person. I\u2019ve spent the past 5 or 6 months applying for other jobs. I\u2019m currently interviewing for one, and I\u2019m wound up to the gills from the stress. I\u2019m waiting to hear back from them after the second round, with a third and final being the next hopeful step. In dozens, perhaps over 100 applications in these months, this is only the 3rd job I\u2019ve landed an interview for, and both other times I was rejected after the second round. Really, I\u2019ve been applying to jobs for over 3 years\u2014since before I finished my degree\u2014with scattered breaks so I wouldn\u2019t lose my mind because I\u2019ve had such a bad time with it. I don\u2019t know if I\u2019m just bad at it, or my luck is bad, or both, but I swear to God I can\u2019t take applying to jobs for much longer. I\u2019ve thought about becoming a monk.\n\nI\u2019ve read books, tried online courses for professional development, talked to friends. I feel stuck and increasingly hopeless. I know comparison is the thief of joy, but when I see people 10+ years my junior who landed better jobs right out of college I get sad and frustrated. Even a number of friends of mine in my graduating class landed better gigs (and yes, I\u2019ve asked them about jobs a number of times). I took this position out of desperation because all I could find before the pandemic was a job in a warehouse. I need help, encouragement, anything to get me through and out of this, because I feel like a complete fish out of water gasping for air.", "author_fullname": "t2_hi7ajwhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having a job crisis, help needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y2b8rg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665598727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is long. I hope it\u2019s ok for the sub.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve made some other posts in this sub about not liking my job, but it\u2019s really coming to a head. Last night, as I was lying in bed not able to sleep, I thought about the most convenient place to jump off and kill myself, which is my apartment building as it has roof access. I don\u2019t like this. I haven\u2019t had thoughts like these in a long time, and they\u2019ve always come along with bad life circumstances. I\u2019ve worked through them before with therapy and other life changes. Unfortunately, therapy is not an option right now because of insurance problems. On the surface, I\u2019ve had much harder times in my life, but something about where I\u2019m at right now is just grinding away my will to live.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a junior data engineer. Data engineering is fine, though I\u2019ve been applying to analyst roles because I studied statistics and I really enjoyed that and want to pursue it. I say junior only because I\u2019m 1 year in to my career in my 30s after finally finding a path that seemed like it could work for me, but I\u2019m the only data engineer at my company.&lt;/p&gt;\n\n&lt;p&gt;This company is small and doesn\u2019t know what data engineering is. I was hired as an analyst and quickly found there were no analyses to be done. The role is a strange combination of high-level programming and problem solving, as well as tedious administrative work that I truly hate. We don\u2019t use the cloud.&lt;/p&gt;\n\n&lt;p&gt;My day-to-day is doing almost nothing. I work perhaps a couple of hours a week now. The bulk of what little work I get now is this tedious administrative work. My boss has told me flat out that there are no more big projects in mind. There is nowhere to be promoted to, and there are no mentors or peers in the data space. Consequently, there also seem to be no opportunities for networking in that space.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m haven\u2019t been allowed to work from home because it\u2019s apparently against the views of upper management. My office doesn\u2019t have a window looking outside (only to other office space). The pay is insultingly bad and I\u2019m embarrassed to tell people what I do and where I work because of these conditions. The company appears to have no intention of investing in me or the position. I\u2019ve asked for things and been met with silence.&lt;/p&gt;\n\n&lt;p&gt;I used to do landscaping and construction, and while I hated those jobs, I\u2019m so miserable in this that I sometimes fantasize about going up to foremen on sites nearby and asking for work, because at least then I\u2019m outside and busy. The pay is so bad at my job it wouldn\u2019t be much of a downgrade in that respect, which is further depressing.&lt;/p&gt;\n\n&lt;p&gt;Mostly, Monday to Friday I sit in a room and convince myself not to walk out.&lt;/p&gt;\n\n&lt;p&gt;One of my strengths is I\u2019m a very proactive person. I\u2019ve spent the past 5 or 6 months applying for other jobs. I\u2019m currently interviewing for one, and I\u2019m wound up to the gills from the stress. I\u2019m waiting to hear back from them after the second round, with a third and final being the next hopeful step. In dozens, perhaps over 100 applications in these months, this is only the 3rd job I\u2019ve landed an interview for, and both other times I was rejected after the second round. Really, I\u2019ve been applying to jobs for over 3 years\u2014since before I finished my degree\u2014with scattered breaks so I wouldn\u2019t lose my mind because I\u2019ve had such a bad time with it. I don\u2019t know if I\u2019m just bad at it, or my luck is bad, or both, but I swear to God I can\u2019t take applying to jobs for much longer. I\u2019ve thought about becoming a monk.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read books, tried online courses for professional development, talked to friends. I feel stuck and increasingly hopeless. I know comparison is the thief of joy, but when I see people 10+ years my junior who landed better jobs right out of college I get sad and frustrated. Even a number of friends of mine in my graduating class landed better gigs (and yes, I\u2019ve asked them about jobs a number of times). I took this position out of desperation because all I could find before the pandemic was a job in a warehouse. I need help, encouragement, anything to get me through and out of this, because I feel like a complete fish out of water gasping for air.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y2b8rg", "is_robot_indexable": true, "report_reasons": null, "author": "FreeJazzClub", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2b8rg/having_a_job_crisis_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2b8rg/having_a_job_crisis_help_needed/", "subreddit_subscribers": 76223, "created_utc": 1665598727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello my name is Kevin and I am researching DataOps requirements for long established companies in my master thesis .\n\nIt would be highly appreciated if you could take a few minutes to answer the following survey.\n\n[https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J](https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J)\n\nFor every participant who completes the survey, I will donate 1 USD (up to 250 USD total) to non-profit orginasations!\n\nThank you very much!\n\nAnd sorry for reposting it in several channels :/ :)\n\nPS: The data will of course be collected anonymously and made open source available.\n\nPPS: Feel free to send feedback via email to: kevin.haferkamp001\\[at\\]stud.fh-dortmund.de", "author_fullname": "t2_5x4osqvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey for my master thesis researching requirements for DataOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y26z6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665588628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello my name is Kevin and I am researching DataOps requirements for long established companies in my master thesis .&lt;/p&gt;\n\n&lt;p&gt;It would be highly appreciated if you could take a few minutes to answer the following survey.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J\"&gt;https://www.survio.com/survey/d/C8E2A1E8Z8A8F7Q6J&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For every participant who completes the survey, I will donate 1 USD (up to 250 USD total) to non-profit orginasations!&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n\n&lt;p&gt;And sorry for reposting it in several channels :/ :)&lt;/p&gt;\n\n&lt;p&gt;PS: The data will of course be collected anonymously and made open source available.&lt;/p&gt;\n\n&lt;p&gt;PPS: Feel free to send feedback via email to: kevin.haferkamp001[at]stud.fh-dortmund.de&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?auto=webp&amp;s=1e087b87112002c59b1ebd8c0eb159786d0df0c6", "width": 1080, "height": 568}, "resolutions": [{"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=020413bf8b4e8e9797ef349a4f34bae4fb3c8810", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4ef4b280d22eda5f07b71ae61a9a3621587e7c5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e135a5f19a6434878d48639dc191b6b0c76ab9f4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dfc11c5f3b8c851d06f497858db799c74e2e7825", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee18e1089cda68d44ffcd9293bd0d1128e5f25e8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZyqcBI8AbuLGZanb_6IB7MAlXzV91s2nG4HXUJtUv7o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8717d4d176d398ad9ce10f65d3298b3fc1a427d1", "width": 1080, "height": 568}], "variants": {}, "id": "SLrlrRC8ZiSJm8LQFtEyZBxll7XimBa4aHiYcbWt7pI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y26z6a", "is_robot_indexable": true, "report_reasons": null, "author": "khaferkamp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y26z6a/survey_for_my_master_thesis_researching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y26z6a/survey_for_my_master_thesis_researching/", "subreddit_subscribers": 76223, "created_utc": 1665588628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an extremely large Hive table that stores e-commerce data for multiple stores.\n\nThis table has one row per sale. Each row included the store Id, the buyer Id and information about the order such as the order amount and date. \n\nI\u2019d like to run a pipeline that uses this order data to create cohort groups out of these customers. \n\nI think the most useful way for this data to be represented is one row per storeId, buyerId combination with a column that has an array of all of the orders between that buyer and store (order history).  \n\nThen I\u2019d like to run 12 different cohorting jobs that each query this table for the same data. \n\nI\u2019m wondering what query pattern I can use so this can be done efficiently because each of these jobs takes 2 hours and I\u2019d like to complete all 12 within a few hours and preferably in parallel.", "author_fullname": "t2_9n9rgzkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help solve this challenge for ingesting big data from massive table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1vpru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665554252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an extremely large Hive table that stores e-commerce data for multiple stores.&lt;/p&gt;\n\n&lt;p&gt;This table has one row per sale. Each row included the store Id, the buyer Id and information about the order such as the order amount and date. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to run a pipeline that uses this order data to create cohort groups out of these customers. &lt;/p&gt;\n\n&lt;p&gt;I think the most useful way for this data to be represented is one row per storeId, buyerId combination with a column that has an array of all of the orders between that buyer and store (order history).  &lt;/p&gt;\n\n&lt;p&gt;Then I\u2019d like to run 12 different cohorting jobs that each query this table for the same data. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering what query pattern I can use so this can be done efficiently because each of these jobs takes 2 hours and I\u2019d like to complete all 12 within a few hours and preferably in parallel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1vpru", "is_robot_indexable": true, "report_reasons": null, "author": "Agentdoubleo97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1vpru/help_solve_this_challenge_for_ingesting_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1vpru/help_solve_this_challenge_for_ingesting_big_data/", "subreddit_subscribers": 76223, "created_utc": 1665554252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data scientist trying to explore the data engineering field. My current project is to implement predictive maintenance. Before the prediction model can be trained, my team would need to install all the related sensors and I would need to store the sensors readings on cloud so it can be used as training data later.\n\nMy question, what is the best way to store the sensors log?\n\nMy initial thought was to connect the IoT devices with AWS Kinesis Data Stream and use AWS Kinesis Firehose to dump everything into the S3 bucket as CSV. Maybe partition it by device ID and date. What do you guys think?", "author_fullname": "t2_2nkat5ah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data logging for IoT devices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_y1myyy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 0, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": "", "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1665532552.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665528727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data scientist trying to explore the data engineering field. My current project is to implement predictive maintenance. Before the prediction model can be trained, my team would need to install all the related sensors and I would need to store the sensors readings on cloud so it can be used as training data later.&lt;/p&gt;\n\n&lt;p&gt;My question, what is the best way to store the sensors log?&lt;/p&gt;\n\n&lt;p&gt;My initial thought was to connect the IoT devices with AWS Kinesis Data Stream and use AWS Kinesis Firehose to dump everything into the S3 bucket as CSV. Maybe partition it by device ID and date. What do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "call_to_action": "", "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y1myyy", "is_robot_indexable": true, "report_reasons": null, "author": "kurkurzz", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1myyy/data_logging_for_iot_devices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1myyy/data_logging_for_iot_devices/", "subreddit_subscribers": 76223, "created_utc": 1665528727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nWe use FiveTran to ingest data from Salesforce. We have tables with over 19m records. Our Dev/Stg/Prd data warehouse environments all leverage Prod transactional data.\n\nWe would like to move to a model where our Stg environment uses data from the Stg transactional system, but that means syncing Salesforce Stg through FiveTran as well as Prd.\n\nThe challenge is that the Salesforce team do a full refresh of the Stg environment with sanitized Prd data each quarter. This means over 19m records from our largest table coming in 'new' every 3 months. Stg is going to end up costing considerably more that Prd.\n\nDoes anyone else have this problem, and how have you got around it (if that is possible)?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FiveTran - handling staging db refresh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1mkul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665527687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;We use FiveTran to ingest data from Salesforce. We have tables with over 19m records. Our Dev/Stg/Prd data warehouse environments all leverage Prod transactional data.&lt;/p&gt;\n\n&lt;p&gt;We would like to move to a model where our Stg environment uses data from the Stg transactional system, but that means syncing Salesforce Stg through FiveTran as well as Prd.&lt;/p&gt;\n\n&lt;p&gt;The challenge is that the Salesforce team do a full refresh of the Stg environment with sanitized Prd data each quarter. This means over 19m records from our largest table coming in &amp;#39;new&amp;#39; every 3 months. Stg is going to end up costing considerably more that Prd.&lt;/p&gt;\n\n&lt;p&gt;Does anyone else have this problem, and how have you got around it (if that is possible)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1mkul", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1mkul/fivetran_handling_staging_db_refresh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1mkul/fivetran_handling_staging_db_refresh/", "subreddit_subscribers": 76223, "created_utc": 1665527687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking into abstracting Segment's analytics.js by wrapping into a fresh install of Google Tag Manager. Naturally, Segment advises against this. But I'm interested in testing other event collection approaches (e.g. [https://snowplow.io/](https://snowplow.io/)).\n\n2 questions:\n\n1. With several quarters of Segment data in our warehouse already, will there be any change in anonymous-id association that will require a remapping of identity downstream in our data model? i.e. if anonymousId ########-####-####-####-############ (aka \\`123\\`) was tracked with Segment's analytics.js first, would Google Tag Manager's load of Segment's analytics.js recognize the same user on a subsequent identify(), page() or track() call?\n2. Ideally we write all the event data to a single table (ala [atomic.events](https://atomic.events) in Snowplow); doing so will break our Segment data warehouse as currently implemented (dozens of databases, with some having hundreds of event tables and views)... has anyone achieved success in \"migrating\" from an admittedly poor Segment install to something more rationalized, or a single table?\n\nThanks!", "author_fullname": "t2_122u9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Segment analytics.js --&gt; wrapping into Google Tag Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1k89l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1665521912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking into abstracting Segment&amp;#39;s analytics.js by wrapping into a fresh install of Google Tag Manager. Naturally, Segment advises against this. But I&amp;#39;m interested in testing other event collection approaches (e.g. &lt;a href=\"https://snowplow.io/\"&gt;https://snowplow.io/&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;2 questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;With several quarters of Segment data in our warehouse already, will there be any change in anonymous-id association that will require a remapping of identity downstream in our data model? i.e. if anonymousId ########-####-####-####-############ (aka `123`) was tracked with Segment&amp;#39;s analytics.js first, would Google Tag Manager&amp;#39;s load of Segment&amp;#39;s analytics.js recognize the same user on a subsequent identify(), page() or track() call?&lt;/li&gt;\n&lt;li&gt;Ideally we write all the event data to a single table (ala &lt;a href=\"https://atomic.events\"&gt;atomic.events&lt;/a&gt; in Snowplow); doing so will break our Segment data warehouse as currently implemented (dozens of databases, with some having hundreds of event tables and views)... has anyone achieved success in &amp;quot;migrating&amp;quot; from an admittedly poor Segment install to something more rationalized, or a single table?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?auto=webp&amp;s=b3cf5e629da0e533a4c8e36495ff8f57780448bc", "width": 1200, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69d03f05c1da825aa532755d7d70c712da14c4fc", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7974cdcd416165dd9a1b2396b047878b37444e80", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c632fb1c9f1cd7398851ad46f436ffb8d0dbfe8a", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65f53b024f56bc254d79dea9d785f2b5b87d7068", "width": 640, "height": 356}, {"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e4d7d6aa6d8340bc4d244effe11615308114e449", "width": 960, "height": 534}, {"url": "https://external-preview.redd.it/QBB-gr3nNw1aA0PaiinCWyA1AuCCpxOLYQF8plCWZeA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a109d4c166901d466d7ea0344298bb8d4a7be6c4", "width": 1080, "height": 601}], "variants": {}, "id": "oWhbWhNNYP9ha9W9EtygDW6rGOmRjvnY_WYZnhiiPOs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1k89l", "is_robot_indexable": true, "report_reasons": null, "author": "they_go_low_we_go_hi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1k89l/segment_analyticsjs_wrapping_into_google_tag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1k89l/segment_analyticsjs_wrapping_into_google_tag/", "subreddit_subscribers": 76223, "created_utc": 1665521912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all, long time lurker, first time poster.\n\nLong story short I am serving as an advisor at a tech start up and I deal with large amount of data that needs to be transformed / modeled upon and have the insights delivered via reports/dashboards.\n\nI'm currently tasked with building and deploying various models that , the only problem is my programming knowledge is limited to Pandas / SkLearn / Numpy &amp;  SQL (Correlated Subqueries / Window Functions / Joins etc.) and doing analysis and building models in Jupyter notebooks.\n\nAs far as building a pipeline with the tool currently available to me ( Google Big Query for storing and querying Data / Colab Notebooks for Python / Tableau/Plotly ), i'm not even sure where to start as I don't even known how to work with data outside the pandas environment. I don't want to build garbage that will have to be completely overhauled by an engineer we hire in a couple months.\n\nWould appreciate any help on how to make the most of my current toolset to build a ML pipeline that is relatively robust.\n\nEdit: Are there any github repos with example code / tutorials that a are useful for getting up to basics on building such things in python?", "author_fullname": "t2_5kk1i9ou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help filling in gaps in knowledge!!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_y1j88b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665519506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, long time lurker, first time poster.&lt;/p&gt;\n\n&lt;p&gt;Long story short I am serving as an advisor at a tech start up and I deal with large amount of data that needs to be transformed / modeled upon and have the insights delivered via reports/dashboards.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently tasked with building and deploying various models that , the only problem is my programming knowledge is limited to Pandas / SkLearn / Numpy &amp;amp;  SQL (Correlated Subqueries / Window Functions / Joins etc.) and doing analysis and building models in Jupyter notebooks.&lt;/p&gt;\n\n&lt;p&gt;As far as building a pipeline with the tool currently available to me ( Google Big Query for storing and querying Data / Colab Notebooks for Python / Tableau/Plotly ), i&amp;#39;m not even sure where to start as I don&amp;#39;t even known how to work with data outside the pandas environment. I don&amp;#39;t want to build garbage that will have to be completely overhauled by an engineer we hire in a couple months.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any help on how to make the most of my current toolset to build a ML pipeline that is relatively robust.&lt;/p&gt;\n\n&lt;p&gt;Edit: Are there any github repos with example code / tutorials that a are useful for getting up to basics on building such things in python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "y1j88b", "is_robot_indexable": true, "report_reasons": null, "author": "limjimsthegod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1j88b/need_help_filling_in_gaps_in_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1j88b/need_help_filling_in_gaps_in_knowledge/", "subreddit_subscribers": 76223, "created_utc": 1665519506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We do this so that we can create data models that use attributes from both application data and 3rd party data.  \n\n\nFor example, everyday we build a dimension table from the production users table and we join all their website activity after loading it from Amplitude\u2019s API.\n\nhttps://reddit.com/link/y1j5lu/video/isr7o6qii8t91/player", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you exporting your prod DB tables to your data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"isr7o6qii8t91": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/y1j5lu/asset/isr7o6qii8t91/DASHPlaylist.mpd?a=1668199878%2CM2I3OTZkY2JmNjNlMTBmZDIyYmZhNjI3NDQ1MTBlNzk2NWRiMjY0OTJmOWEyMDA1NjM2OGEwODIzMDgzOGEwMg%3D%3D&amp;v=1&amp;f=sd", "x": 551, "y": 720, "hlsUrl": "https://v.redd.it/link/y1j5lu/asset/isr7o6qii8t91/HLSPlaylist.m3u8?a=1668199878%2CN2UyYzc3OTI5YmViOTViODU5MmU3NzIyMDg1ZDFhMmRjMDQwNDIyOTYzMzg4YTVkZDBjN2M4ODc0ZmU1NjAzZA%3D%3D&amp;v=1&amp;f=sd", "id": "isr7o6qii8t91", "isGif": false}}, "name": "t3_y1j5lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_h30vc65", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665519336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We do this so that we can create data models that use attributes from both application data and 3rd party data.  &lt;/p&gt;\n\n&lt;p&gt;For example, everyday we build a dimension table from the production users table and we join all their website activity after loading it from Amplitude\u2019s API.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/y1j5lu/video/isr7o6qii8t91/player\"&gt;https://reddit.com/link/y1j5lu/video/isr7o6qii8t91/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "y1j5lu", "is_robot_indexable": true, "report_reasons": null, "author": "jnkwok", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y1j5lu/how_are_you_exporting_your_prod_db_tables_to_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y1j5lu/how_are_you_exporting_your_prod_db_tables_to_your/", "subreddit_subscribers": 76223, "created_utc": 1665519336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From what I see (at least in my city), most of the \"data engineer\" offers that I see are in fact data scientist / analyst jobs, and I really enjoy coding and dont want to do DS. I'm afraid to waste my time trying DE just to realize that I dont code as much as I want. Am I wrong ?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I get into DE if I enjoy coding ? (DE ~= data science ?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_y2cr28", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1665602301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I see (at least in my city), most of the &amp;quot;data engineer&amp;quot; offers that I see are in fact data scientist / analyst jobs, and I really enjoy coding and dont want to do DS. I&amp;#39;m afraid to waste my time trying DE just to realize that I dont code as much as I want. Am I wrong ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "y2cr28", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/y2cr28/should_i_get_into_de_if_i_enjoy_coding_de_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/y2cr28/should_i_get_into_de_if_i_enjoy_coding_de_data/", "subreddit_subscribers": 76223, "created_utc": 1665602301.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}